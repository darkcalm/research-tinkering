{
  "totalHits": 1104,
  "limit": 1,
  "offset": 0,
  "results": [
    {
      "acceptedDate": "",
      "arxivId": "1810.11613",
      "authors": [
        {
          "name": "Barbarossa, Sergio"
        },
        {
          "name": "Chen, Tianyi"
        },
        {
          "name": "Giannakis, Georgios B."
        },
        {
          "name": "Wang, Xin"
        },
        {
          "name": "Zhang, Zhi-Li"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Barbarossa, Sergio",
        "Wang, Xin",
        "Chen, Tianyi",
        "Giannakis, Georgios B.",
        "Zhang, Zhi-Li"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/195777516"
      ],
      "createdDate": "2019-02-06T06:45:57",
      "dataProviders": [
        {
          "id": 144,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/144",
          "logo": "https://api.core.ac.uk/data-providers/144/logo"
        },
        {
          "id": 1084,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/1084",
          "logo": "https://api.core.ac.uk/data-providers/1084/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "Internet-of-Things (IoT) envisions an intelligent infrastructure of networked\nsmart devices offering task-specific monitoring and control services. The\nunique features of IoT include extreme heterogeneity, massive number of\ndevices, and unpredictable dynamics partially due to human interaction. These\ncall for foundational innovations in network design and management. Ideally, it\nshould allow efficient adaptation to changing environments, and low-cost\nimplementation scalable to massive number of devices, subject to stringent\nlatency constraints. To this end, the overarching goal of this paper is to\noutline a unified framework for online learning and management policies in IoT\nthrough joint advances in communication, networking, learning, and\noptimization. From the network architecture vantage point, the unified\nframework leverages a promising fog architecture that enables smart devices to\nhave proximity access to cloud functionalities at the network edge, along the\ncloud-to-things continuum. From the algorithmic perspective, key innovations\ntarget online approaches adaptive to different degrees of nonstationarity in\nIoT dynamics, and their scalable model-free implementation under limited\nfeedback that motivates blind or bandit approaches. The proposed framework\naspires to offer a stepping stone that leads to systematic designs and analysis\nof task-specific learning and management schemes for IoT, along with a host of\nnew research directions to build on.Comment: Submitted on June 15 to Proceeding of IEEE Special Issue on Adaptive\n  and Scalable Communication Network",
      "documentType": "research",
      "doi": "10.1109/jproc.2019.2896243",
      "downloadUrl": "https://core.ac.uk/download/195777516.pdf",
      "fieldOfStudy": null,
      "fullText": "1Learning and Management for Internet-of-Things:\nAccounting for Adaptivity and Scalability\nTianyi Chen, Sergio Barbarossa, Xin Wang, Georgios B. Giannakis, and Zhi-Li Zhang\nAbstract\u2014Internet-of-Things (IoT) envisions an intelligent in-\nfrastructure of networked smart devices offering task-specific\nmonitoring and control services. The unique features of IoT\ninclude extreme heterogeneity, massive number of devices, and\nunpredictable dynamics partially due to human interaction. These\ncall for foundational innovations in network design and manage-\nment. Ideally, it should allow efficient adaptation to changing\nenvironments, and low-cost implementation scalable to massive\nnumber of devices, subject to stringent latency constraints. To\nthis end, the overarching goal of this paper is to outline a unified\nframework for online learning and management policies in IoT\nthrough joint advances in communication, networking, learning,\nand optimization. From the network architecture vantage point,\nthe unified framework leverages a promising fog architecture that\nenables smart devices to have proximity access to cloud function-\nalities at the network edge, along the cloud-to-things continuum.\nFrom the algorithmic perspective, key innovations target online\napproaches adaptive to different degrees of nonstationarity in IoT\ndynamics, and their scalable model-free implementation under\nlimited feedback that motivates blind or bandit approaches. The\nproposed framework aspires to offer a stepping stone that leads\nto systematic designs and analysis of task-specific learning and\nmanagement schemes for IoT, along with a host of new research\ndirections to build on.\nIndex Terms\u2014Internet-of-Things, network resource allocation,\nmobile edge computing, stochastic optimization, online learning.\nI. INTRODUCTION\nThe past decade has witnessed a proliferation of connected\ndevices and objects, where the notion of Internet-of-Things\n(IoT) plays a central role in the envisioned technological\nadvances. Conceptually speaking, IoT foresees an intelligent\nnetwork infrastructure with ubiquitous smart devices - home\nautomation, interactive healthcare, and self-driving connected\nvehicles, are typical in IoT [7], [104]; see Fig. 1. Today, a\nnumber of IoT applications have already brought major benefits\nto many aspects of our daily life. The current generation\nof IoT can already afford an increasing amount of real-time\nThe work of T. Chen and G. B. Giannakis was supported by NSF 1509040,\n1508993, and 1711471. The work of S. Barbarossa was supported by the\nH2020 EUJ Project 5G-MiEdge, Nr. 723171. The work of X. Wang was\nsupported by the National Natural Science Foundation of China Grants No.\n61671154, the National Key Research and Development Program of China\nGrant 2017YFB0403402, and the Innovation Program of Shanghai Municipal\nScience and Technology Commission 17510710400. The work of Z.-L. Zhang\nwas supported by US DoD HDTRA1-14-1-0040, NSF 1411636 and 1617729.\nT. Chen and G. B. Giannakis are with the Digital Technology Center,\nUniversity of Minnesota, Minneapolis, MN 55455 USA. Emails: {chen3827,\ngeorgios}@umn.edu. S. Barbarossa is with the Department of Information\nEngineering, Electronics, and Telecommunications, Sapienza University of\nRome, 00184, Rome, Italy. E-mail: sergio.barbarossa@uniroma1.it. X. Wang\nis with the Shanghai Institute for Advanced Communication and Data Science,\nthe Key Laboratory for Information Science of Electromagnetic Waves (MoE),\nDepartment of Communication Science and Engineering, Fudan University,\nShanghai 200433, China. E-mail: xwang11@fudan.edu.cn. Z.-L. Zhang is with\nDepartment of Computer Science, University of Minnesota, Minneapolis, MN\n55455 USA. E-mail: zhang@cs.umn.edu.\nautomation, and thus intelligence toward the vision of real-\ntime IoT. However, despite the popularity of IoT, several\ncritical challenges must be addressed before embracing its\nfull potential [5], [86]. To this end, we highlight three key\nchallenges that are arguably expected to be at the epicenter of\nemerging IoT research fields.\nFig. 1:Internet of Everything[3].\nExtreme heterogeneity.\nThe computational and\ncommunication capacities of\nconnected devices differ due\nto differences in hardware\n(e.g., CPU frequency),\ncommunication protocol\n(e.g., ZigBee, WiFi), and\nenergy availability (e.g.,\nbattery level) [103]. The\ntasks carried out on various\ndevices are often considerably diverse, e.g., motion sensors\nmonitor human behavior in a smart home [60], while cameras\nare responsible for recognizing a suspicious behavior in a\ncrowded environment, or, vehicle plates in a parking garage.\nUnpredictable dynamics. Unlike many existing communica-\ntion, computing and networking platforms, the IoT dynam-\nics can stem from multiple sources, where adaptivity is not\nonly critical but also essential in designing hardware and\nmanagement protocols. Such sources entail human-in-the-loop\ndynamics in addition to physical objects [60], demand response\nin energy systems [40], and intelligent automotive applications\n[59]. In these applications, IoT dynamics are intertwined with\nor even partially determined by human behavior [34], [69],\n[73] - as such, high degree of adaptivity in the algorithm and\nhardware design is needed.\nScalability at the core. IoT entails an intelligent network\ninfrastructure with a massive number of devices. It is estimated\nthat by 2020, there will be more than 50 billion devices con-\nnected through the Internet [39], which highlights scalability as\na key challenge for IoT [7], [86]. Scalability is not only about\ncomputational efficiency, but also about lower communication\noverhead (e.g., how often a device needs to communicate\nwith the remote cloud center), as well as reduced information\nneeded (e.g., what type of information a device needs before\nmaking sensible decisions).\nFaced with these major IoT challenges, innovations in net-\nwork design and management are desired to enable efficient\nonline operations, and seamless co-existence of humans with\nthings [25]. Consequently, it is imperative to develop new tools\nfor IoT management that tap into diverse inference, signal\nprocessing, communications, and networking techniques, by\ndrawing from fields such as machine learning, optimization,\nar\nX\niv\n:1\n81\n0.\n11\n61\n3v\n1 \n [c\ns.S\nY]\n  2\n7 O\nct \n20\n18\n2and applied statistics. The novel expertise gleaned from these\nresearch areas, coupled with the solid analytical approach, are\nthe best credentials for succeeding in IoT research [86].\nFrom a network architecture perspective, to ensure the\ndesired user experience and meet heterogeneous service re-\nquirements, IoT tasks nowadays are no longer only supported\nby the cloud data centers, but also through a promising new\narchitecture termed edge computing, or in a broader sense fog\ncomputing. This architecture distributes computation, commu-\nnication, and storage closer to the end IoT devices and users,\nalong the cloud-to-things continuum [9], [10], [25], [61], [62],\n[94]. This shift of computing paradigms is further promoted\nby the advanced communication techniques emerging with\nstandards such as Narrowband-IoT (NB-IoT) [2], [4].\nGiven the huge volume of data in various IoT setups and the\nproliferation of learning and large-scale optimization advances,\na pertinent direction is prompted by asking the following\nquestion: Can we learn from historical data to improve the\nquality of network management policies in IoT? The rationale\nis that historical data contain statistics of the IoT environments\n[93], and learning from them can mitigate the uncertainty of\nfuture management tasks. Further armed with online adaptation\ncapability to reinforce the current policies, it is envisioned that\nlearn-and-adapt network management schemes can markedly\nimprove IoT user experience in terms of low service delay, high\nsystem resilience, and adaptivity [17], [21]. Toward this goal,\nthe present overview paper will outline an offline-aided online\napproach with markedly improved performance, by leveraging\nstatistical learning from historical samples.\nTaking a step further, online learning, with online con-\nvex optimization (OCO) as a special case, is an emerging\nmethodology for sequential decision making with light-weight\nimplementation and well documented merits, especially when\nthe environment (e.g., a sequence of convex costs) varies in\nan unknown and possibly adversarial manner [15], [109]. Tar-\ngeting a scalable solution in a prohibitively complex IoT envi-\nronment, this paper will also overview a new OCO framework\ndesigned for IoT, which further incorporates various forms of\nfeedback, physical constraints and performance metrics driven\nby IoT applications, relative to the standard settings [15],\n[43], [109]. Novel schemes tailored for this setting can lay\na solid analytical foundation to delineate the tradeoffs among\nalgorithm scalability, performance guarantees, and degree of\n(non-)stationarity present in the IoT environment [16], [19].\nThe rest of the paper is organized as follows. Section II\ndeals with the heterogeneity in IoT demand and QoS, along\nwith a unified formulation for dynamic IoT tasks. Section\nIII introduces methods for optimizing IoT performance under\ndifferent level of non-stationarity in IoT dynamics. Section\nIV summarizes scalable OCO-based schemes with different\nfeedback options. Finally, concluding remarks and possible\nfuture research directions are highlighted in Section V.\nNotation. Bold uppercase (lowercase) letters denote matrices\n(column vectors), while (\u00b7)> stands for transposition, and \u2016x\u2016\ndenotes the `2-norm of a vector x. The projection [a]+ :=\nmax{a,0} are defined entrywise. The indicator function 1(A)\ntakes value 1 when the event A happens, and 0 otherwise. O(x)\ndenotes big order of x, i.e., O(x)/x\u2192 1 as x\u2192 0; O\u02dc neglects\nthe lower-order terms with a polynomial log x rate; and o(x)\ndenotes small order of x, i.e., o(x)/x\u2192 0 as x\u2192 0.\nII. HETEROGENEITY IN IOT DEMAND AND QOS\nHeterogeneity is inherent in IoT, and it manifests itself across\ndifferent aspects, from application requirements and constraints\nto sensing and communication technologies.\nA. Heterogeneous applications\nThe range of IoT applications already spans several fields,\nand it is rapidly increasing. A few examples of applications\nare [4], [5], [104]: (i) lifestyles (wearable gadgets, gam-\ning, augmented/virtual reality, wellness); (ii) smart environ-\nments (homes, offices, cities); (iii) automotive (self-driving,\ntraffic monitoring, intelligent transportation systems, vehicle-\nto-vehicle communications); (iv) industrial (full automation\nand control, structure monitoring, logistic); (v) environmental\nmonitoring (pollution, global warming, waste management);\n(vi) healthcare (patient monitoring, body area networks, smart\nhealth, elderly care); and, (vii) security and surveillance. These\napplications are characterized by highly diverse requirements,\nin terms of data rate, latency, reliability, security, connectivity,\nmobility, etc. To illustrate the extreme variability of require-\nments, we note that virtual reality require latencies in the order\nof a few milliseconds and data rates in the order of 25 Mbps,\nwhile automated driving or certain industrial control applica-\ntions require latencies in the order of milliseconds and high\npacket transmission reliability (in the order of 99.999 percent).\nConversely, for environmental monitoring applications such as\nwaste management, an update frequency of one packet/hour is\nsufficient, with a tolerable delay of 30 minutes.\nA few paradigms are useful to outline the challenges facing\nIoT, and the potential of our approaches to addressing them.\nAutomated driving. The goal in this application is to enhance\nperception of an individual vehicle and thus improve safety.\nA common approach is to set up a cooperative perception\nsystem building on the information sharing between vehicles\nand roadside units (RSUs) [79]. The scope is to widen the\nvisibility of the individual vehicle to prevent that an object\nunseen by a single vehicle might cause an accident [48], [80].\nThe signals to be exchanged go from (low data rate) range mea-\nsurements to (high data rate) high definition maps generated by\nsensors mounted on each vehicle. The communication channels\nbetween vehicles are highly dynamic and hard to predict, while\nthe information available at each time slot can be outdated.\nNevertheless, the communication among vehicles and RSUs\nshould be performed in a reliable and timely manner to ensure\nthat emergency operations can take place in the due time.\nIntelligent transportation. A typical task in this application\nis to navigate a set of electric vehicles to their destination,\nby collecting along the way data about traffic, state of the\nbattery, and availability of parking slots. The objective here is\nto minimize fuel consumption and the time needed to reach\na certain destination, while ensuring that all vehicles find a\nproper refueling station for their batteries along the way. The\n3remaining time to destination is updated online, depending on\nthe time-varying traffic state, which is generally unpredictable.\nB. Heterogeneous technologies\nThe IoT ecosystem is composed of various components,\nwhose functionality falls within the following categories [5]:\nidentification, sensing, communication, computation, and ser-\nvices. Identification is crucial to assign a clear identity to each\nobject in the network. The role of sensing elements is to gather\ndata from the real world. Typically, sensors are integrated\nwith single board computers and TCP/IP functionalities to\ncreate IoT devices, such as Arduino or Raspberry PI, which\nare able to sense and send data to a decision entity. The\nrole of communication is to propagate information from the\nsensing elements to a decision entity, possibly distributed, and\nback to actuators. There is a plethora of very heterogeneous\ncommunication technologies that are in use in IoT. As a\nbroad classification, we can list: (i) short-range technologies to\nsupport machine-to-machine communications, like Bluetooth,\nIEEE 802.15.4 and ZigBee; (ii) long-range networks, like LoRa\nsupporting data rates of around 50 kbps over ranges up to 15\nKm, or SigFox using ultra-narrowband technologies to support\nultra-low power consumption and long ranges (up to 30-50\nKm in rural areas, 3-10 Km in urban areas), at the expenses\nof limited data rates; (iii) Low-power Wi-Fi, also called\nIEEE 802.11ah supporting data rates up to 347 Mbps; and,\n(iv) cellular networks. Current 4G cellular technologies, more\nspecifically the 3rd Generation Partnership Project Long-Term\nEvolution (3GPP LTE), represent the state-of-the art in mobile\ncommunications. However, LTE has been primarily designed\nfor broadband communications, and thus not optimized for the\nmachine-type communications (MTC) envisioned in IoT.\nTo partially overcome this discrepancy, 3GPP has introduced\nsome modifications to the standards to enable the deployment\nof massive smart connected devices and services such as those\nin smart cities or smart grids: eMTC [1] and NB-IoT [2]. But\na truly disruptive framework enabling an effective deployment\nof IoT is 5G communication networks, thanks to increased\ndata rate, reduced end-to-end latency, and improved coverage\nrelative to 4G [74]. The key features of 5G that are particularly\nsuitable for IoT are: (i) the integration of heterogeneous access\ntechnologies; (ii) virtualization of network functionalities; and,\n(iii) bringing cloud functionalities close to the end-user by\nintroducing mobile edge computing (MEC). While earlier\nnetwork generations have been designed as general purpose\nconnectivity platforms, the vision underlying 5G is to create\nan ecosystem for technical and business innovations involving\nvertical markets such as automotive, energy, agriculture, city\nmanagement, healthcare, manufacturing, and transportation.\nSince these services have very different requirements and\nconstraints, the key challenge of 5G is to design a single\nplatform being able to serve different purposes in an efficient\nway. The solution to tackle such a challenging question is\nnetwork slicing. At the basis of network slicing, there is\nnetwork function virtualization, which makes it possible to par-\ntition a single physical network into multiple virtual networks,\neach matched to its specific requirements and constraints.\nThis enables operators to provide networks on an as-a-service\nbasis, while meeting a wide range of use cases in parallel.\nVirtualization is going to play a key role also in IoT to\ncope with high heterogeneity of requirements as well as the\ncapabilities of devices. But being able to meet the stringent\nlatency requirements of IoT applications, virtualization needs\nto be coupled with a new architectural vision, enabled by MEC.\nC. Embedding IoT in the edge cloud\nEven within the sophisticated architecture of 5G networks,\nmeeting the stringent latency constraints required in some IoT\napplications over a wide area network can be still challenging,\nif not impossible. To guarantee low latencies, a popular solution\nis to bring cloud functionalities close to the end users through\nmobile (or multi-access) edge computing [44], [56].\nWith MEC, computation and storage resources are brought\nat the edge of the network, represented by the network access\npoints. In this way, delay-sensitive applications launched by\na mobile device can be offloaded to the nearest mobile edge\nhost (MEH), and the most popular contents can also be cached\nin MEHs to minimize downloading time [26], [27]. Bringing\ncomputation and storage resources at the edge of the network\nmakes it possible to guarantee low and stable delays. In\npractice, the applications launched by the user are executed\nby virtual machines running on nearby edge nodes, either\ncloudlets, exploiting a Wi-Fi connection [29], [49], or MEHs,\nusing cellular communication technologies [10]. The further\nextension of MEC is fog computing, where the edge of the\nnetwork can include devices as well, thus creating a continuum\nof devices able to sense, communicate and compute [12],\n[25]. A critical aspect in this scenario is mobility management\n[89]. To handle mobility while offering a seamless service\ncontinuity, it is necessary to migrate virtual machines quickly\nacross MEH. This is a critical step, because instantiating a\nconventional virtual machine can take times well beyond the\nlatencies required in some IoT applications.\nIn MEC or fog computing settings, communication, com-\nputation and storage resources can be seen as three aspects\nof a single system. From a user-centric perspective, what\nactually matters is the time needed to launch an application\nand receive the result back. The overall delay depends on\ncommunication time, computation time and the distribution of\ncontents across the network. This holistic vision calls for a joint\ndynamic optimization of communication, computation, and\ncaching resources [9]. An application where communication\nand computation resources are closely mingled is computation\noffloading. This is a fundamental mechanism to enable simple\ndevices to run sophisticated applications or to allow battery-\npowered devices to run their applications remotely to save en-\nergy and thus prolong battery lifetime. Computation offloading\nhas gained growing popularity recently. For single-user MEC,\nit has been studied in [50], [57], [61], [64]. The multi-user case\nwas addressed in [24], [82], and later extended to the dynamic\ncase, using stochastic optimization in [65], [81]. See recent\nsurveys [9], [10], [63] and references therein.\nD. Taming heterogeneity via a unified formulation\nWith various applications and technologies in mind, the goal\n4optimize\n{xt,\u2200t}\nT\u2211\nt=1\nf(xt; st) /IoT performance metrics\nsubject to\nT\u2211\nt=1\ng(xt; st) \u2264 0 /IoT long-term requirements\nxt \u2208 X (st), \u2200t /IoT short-term requirements\nPer slot t, IoT state dynamics st+1 = d(st,xt, \u03bet)\nPer slot t, find xt given information oracle Ot\n(1a)\n(1b)\n(1c)\n(1d)\n(1e)\nof this section is to put forth a unified model for IoT tasks that\nwill guide subsequent algorithmic development.\nUnifying models. Consider discrete time t \u2208 N, and a time\nhorizon of T slots. Per slot t, an IoT state variable st \u2208 Rp\nis defined, which characterizes all the critical parameters of\nthe IoT environment. Assuming certain amount of knowledge\nabout the environment, the IoT operator will make a decision\nxt \u2208 Rd, aiming to optimize task-specific performance, subject\nto different types of constraints. The decision xt can in turn\ndrive the next state st+1. To model such decision making pro-\ncesses, we consider a generic problem (1). The model here is\ngeneral. The slot duration can vary from tens of microseconds\nin wireless networks, a few milliseconds in automated driving,\ntens of seconds in intelligent transportation, to minutes or even\nhours in smart power networks; the state st can represent\nthe channel gain in wireless networks, the congestion level\nin data networks as well as transportation networks, and the\nrenewable generation, and energy prices in power networks;\nand the decision xt can include the transmitted power in\ncommunication, the size of data workloads, the number of\nvehicles, or the amount of energy. Regarding the objectives,\nconstraints and state dynamics in (1), we will highlight their\nIoT relevance, especially of interest to communication and\nnetworking communities.\nPerformance metrics. Given the state st and the decision xt,\nwe consider the IoT performance as a generic time-invariant\nfunction f(xt; st) (use ft(xt) interchangeably) depending on\nthe time-varying quantities st and xt. For MEC problem in\nSection II-C, f(xt; st) often represents the power consumption\naggregating over all devices, the aggregated delay, or the sys-\ntem throughput [10], [19], [94]. Another line of recent research\nstudies a new performance metric in MEC \u2014 age of informa-\ntion or age, which measures the timeliness of system status\nusing the elapsed time since the most recently received packet\nwas generated at its source [47]. Age of information is pertinent\nto mission-critical IoT applications [28], [88]. Furthermore, for\ntraffic assignment tasks in intelligent transportation, ft(xt) can\ncapture the overall fuel consumption, and the travel time of\nvehicles on the road [106]; for demand response in smart grids,\nit is related to user utility and power balancing cost depending\non the real-time energy prices [52], [54], [85], [97]; and for\napplications related to wireless communications, throughput or\nachievable rate also plays a critical role in the objective.\nShort-term constraints. The heterogeneous requirements in\nIoT are modeled via short-term and long-term constraints in\n(1). The short-term constraints are imposed to regulate xt in\naccordance to short-term requirements, which can be collected\nin a compact set X (st) \u2014 that is either continuous or discrete,\nand possibly depends on the IoT state st. As an example,\nconsider a MEC system composed of access points (APs),\nMEC servers, and mobile user equipment (UE). To meet the\nstringent latency requirement, the E2E latency of each UE\nshould be less than l\u00af, that is,\nltxt + l\nbk\nt + l\nexe\nt + l\nrx\nt \u2264 l\u00af (2)\nwhere i) ltxt is the time spent to send the program state and\ninput (encoded with bt bits) from UE to AP, e.g., ltxt = bt/rt,\nwith rt being the data rate (in bits/sec); ii) lbkt is the backhaul\nlatency between AP and MEC server, which appears when\nthe computations are performed in a server that is not co-\nlocated with the AP; iii) lexet is the server execution time\ndefined as lexet = ct/ut, where ct is the number of CPU cycles\nto be executed, and ut is the number of CPU cycles/second\nallocated by the MEC server to UE; and, iv) lrxt is the time\nfor the MEC server to send back the result to UE. With\nxt := {ut, rt} and st := {lbkt , lrxt , ct, bt} thus (2) included\nin X (st), selecting xt \u2208 X (st) guarantees the E2E latency\nrequirement in MEC. Short-term constraints also arise due\nto the physical limits of transmission lines and generators in\npower networks [40], transceivers in wireless communication\n[96], as well as vehicles in transportation networks [106].\nLong-term constraints. In some IoT applications, the short-\nterm constraints cannot accurately characterize the demand and\nrequirements. For the latency requirement in MEC, the short-\nterm constraint (2) makes implicit assumptions that i) no new\ntask is generated before the old tasks are completed; and, ii)\neach single task is carried out within an established time frame.\nThese assumptions may be restrictive in some cases. Consider\nalso a vehicle in the intelligent transportation application that\nmust arrive at its destination within a certain interval. To guar-\nantee on-time arrival, its long-term average speed instead of the\ninstantaneous speed needs to be lower bounded. The long-term\nconstraints are thus well-motivated to allow flexible adaptation\nof xt to temporal variations of service requirements. Given\nthe state st and the decision xt, they are modeled as a set of\npenalty functions g(xt; st) := [g1(xt; st), \u00b7 \u00b7 \u00b7 , gN (xt; st)]> in\n(1b). Ideally, we want the accumulated penalty over the entire\nhorizon below a certain threshold. For convenience, we let the\nthreshold to be 0 in (1b), which is without loss of generality\nsubject to a constant shift. Long-term constraints also appear in\nwireless networks where often the average transmit power and\nlink capacity are confined [96]. The challenge in dealing with\nlong-term constraints is that the future states st+1, \u00b7 \u00b7 \u00b7 , sT are\nnot known at slot t, which calls for adaptive optimization.\nState dynamics. One of the key challenges in IoT is its\nunpredictable dynamics. In (1), IoT dynamics are encoded\n5TABLE I: An overview of heterogeneous IoT settings considered.\nSection State dynamics st \u2192 st+1 Information oracle Ot\nSection III-A i.i.d. or Markovian f,g,X and {s1 \u00b7 \u00b7 \u00b7 , st}\nSection III-B Partially controlled Markovian f,g,X and {s1 \u00b7 \u00b7 \u00b7 , st}\nSection III-C Controlled Markovian f1(x1),g1(x1), \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121(xt\u22121) and {s1 \u00b7 \u00b7 \u00b7 , st}\nSection IV-A Generally non-stationary f1,g1, \u00b7 \u00b7 \u00b7 , ft\u22121,gt\u22121,X\nSection IV-B Generally non-stationary f1(x1),g1, \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121,X\nSection IV-C Generally non-stationary f1(x1),g1(x1), \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121(xt\u22121),X\nby a state transition function d which generates the next\nstate st+1 = d(st,xt, \u03bet) given st and xt as well as an\nexogenous variable \u03bet. In most cases, the exogenous variable\n\u03bet can be a random disturbance. For wireless communication\napplications where the state st represents the fading channel\nstate, then st+1 often does not depend on st and xt; that is,\nst+1 = d(\u03bet) := s\u00af + \u03bet, where s\u00af is the mean channel state,\nand \u03be1, \u00b7 \u00b7 \u00b7 , \u03beT are independent, identically distributed (i.i.d.)\nzero-mean random variables; see e.g., [38], [96]. Markovian\ndynamics are also common in modeling energy prices, renew-\nable generation processes [41], in which case st+1 = d(st, \u03bet)\ndepends on the current state st and an i.i.d. noise \u03bet but not\nxt. We refer to both st+1 = d(\u03bet) and st+1 = d(st, \u03bet), as\nnon-interactive dynamics. The decision xt can also play an\nimportant role in state transitions. Taking MEC as an example,\na queueing model is usually incorporated to keep trace of\nthe relevant quantities, such as the amount of remaining tasks\nthat need to be offloaded or processed. With {bt, ct, rt, ut}\ndefined below (2), we consider a transmission queue qtxt that\nquantifies the number of bits to be transmitted at slot t from\nUE, and a computation queue qexet that quantifies the amount of\ncomputation that needs to be completed for UE. If \u2206t denotes\nthe slot duration, the transmission queue evolves as\nqtxt+1 = max\n[\nqtxt \u2212 rt\u2206t, 0\n]\n+ bt (3)\nand the computation queue evolves as follows qexet+1 =\nmax [qexet \u2212 ut\u2206t, 0] + ct. In this case, the IoT state is\nst := {qtxt , qexet }, the decision is xt := {ut, rt}, and the\nexogenous variable is \u03bet := {bt, ct}. It then follows that\nst+1 = d(st,xt, \u03bet) \u2014 what we term interactive dynamics, or\nmore precisely, controlled Markovian dynamics if \u03bet is i.i.d. If\nthe communication and computation resources are sufficient,\nan ideal policy should guarantee the queue stability [71], [92].\nAccording to Little\u2019s law [77], the average execution delay\nexperienced by each UE is proportional to the average queue\nlengths. Hence, a meaningful problem can be minimizing the\naverage power, subject to the average delay constraints, which\nwill be discussed in Section III-B. State variables of this type\nalso include the location of a vehicle in the intelligent trans-\nportation or an unmanned aerial vehicle (UAV) that depends on\ntheir previous location and the current movement [42], [100],\n[101], and the energy level of a battery that depends on their\ninstantaneous (dis)charging amounts. More complex dynamics\nare also possible in IoT due to e.g., strategic human interactions\nand malicious attack [110]. In those cases, \u03bet can be a function\nof all the states s1, \u00b7 \u00b7 \u00b7 , st, or even completely arbitrary.\nAccessible information. While various objectives, constraints\nand state dynamics have been adopted to model heteroge-\nneous problems in IoT, the level of accessible information\ndirectly affects how to solve the resultant problem given\nlimited communication and computation resources \u2014 the\nepicenter of scalability barriers in IoT. Let the information\noracle Ot collect all the information available to the IoT\noperator before making decision xt. For cases where the\nobjectives and the constraints are easy-to-measure formulas\n(e.g., aggregated power, throughput, distance), we consider\nOt := {f,g,X , s1 \u00b7 \u00b7 \u00b7 , st} that includes the explicit form of\nfunctions {f,g}, set X and one-slot-ahead prediction st. In\nsome IoT settings however, i) the objective capturing user-\ncentric quantities, e.g., service latency or reliability, security\nrisk, and customer ratings, is hard to model; ii) the objective\ninvolving fast-varying quantities is hard to predict, e.g., the\nmillimeter wave links in 5G are prone to blocking events,\nthus hard to predict.; and, iii) even if modeling and predicting\nare possible in theory, the low-power smart devices may not\nafford the complexity of running statistical learning tools \u201con-\nthe-fly.\u201d In such cases, we consider a fully causal information\noracle Ot := {f1(x1),g1(x1), \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121(xt\u22121)}\nthat includes only the observed objective function values and\nconstraint penalties at previous slots. IoT scenarios between\nthese two extreme cases will also be discussed.\nIn Table I, we summarize the heterogeneous settings that\none may encounter in IoT. Targeting these settings, a set of\nsuitable solvers will be discussed in the subsequent sections.\nWhile the methodologies presented in this paper mainly focus\non stochastic optimization and online learning, approaches\nbased on other methodologies such as game theory and robust\noptimization can be also applied to solve similar problems.\nIII. ADAPTIVITY TO DYNAMIC IOT ENVIRONMENTS\nThis section introduces methods for optimizing IoT perfor-\nmance under the (asymptotically) stationary assumption on IoT\ndynamics relative to control decisions in the fast timescale.\nCorresponding to different types of state dynamics in Table I,\nwe outline three classes of management schemes; see Fig. 2.\nA. Leveraging statistical learning for IoT management\nAs the generic problem (1), consider the IoT operator makes\na per-slot decision xt, subject to the short-term constraints that\nare collected in a compact set X (st) parameterized by the IoT\nstate st \u2208 S, as well as the long-term constraints that are\nexpressed as a time-varying penalty function g(xt; st) \u2208 RN .\nWith the IoT cost f(xt; st), we wish to find a sequence of\ndecisions {xt} that minimize the expected limiting-average\ncost subject to the long-term and short-term constraints, i.e.,\nf\u2217 := minimize\n{xt\u2208X (st), \u2200t}\nlim\nT\u2192\u221e\n1\nT\nT\u2211\nt=1\nE [f(xt; st)] (4a)\n6!\"#$%&'\n(&\"%)&%'\n!\"#$%&'\n(&\"%)&%'\n!\"#$%&'\n!\"#$#%&#'()*+'&,(\"-$.\"/(''&#0\n!\"/(1&%&#'()*+'&,(\"-$.\"/(''&#0\n!\"#$%&'\n(&\"%)&%'\n!#\"&#'()*+'&,(\"-$.\"/(''&#0\nFig. 2: Three levels of interaction between IoT operator (learner) and\nnature corresponding to the three assumptions in Table I.\nsubject to lim\nT\u2192\u221e\n1\nT\nT\u2211\nt=1\nE [g(xt; st)] \u2264 0 (4b)\nwhere E is taken over the random state st, and possible\nrandomness we may opt to introduce in the decision xt.\nComparing with (1), the infinite time horizon and the limiting\naverage cost are used in (4) and throughout this section\nfor mathematical simplicity. Indeed, assuming st is i.i.d. or\ngenerally stationary, the dynamic problem (4) shares the same\noptimal objective value as the following static problem [71]\nf\u2217 := minimize\n{pi(st)\u2208X (st), st}\nE [f(pi(st); st)]\nsubject to E [g(pi(st); st)] \u2264 0.\n(5a)\n(5b)\nTo this end, our goal is to determine a possibly randomized\npolicy pi that given an IoT state st, generates xt = pi(st)\nso as to minimize the average cost subject to both long- and\nshort-term constraints in (5). The infinite-dimension functional\noptimization problem (5) is more tractable in its dual form,\nwhich entails a finite number of variables [17], [76]. With\n\u03bb \u2208 RN+ denoting the multipliers, the Lagrangian of (5)\nis L(pi,\u03bb) := E[L(pi(st),\u03bb; st)] where the instantaneous\n(per state) Lagrangian is L(pi(st),\u03bb; st) := f(pi(st); st) +\n\u03bb>g(pi(st); st). Correspondingly, the dual problem of (5) is\nmaximize\n\u03bb\u22650\nD(\u03bb) := E [D(\u03bb; st)] (6)\nwhere D(\u03bb; st) := minx\u2208X (st) L(x,\u03bb; st). With the optimal\n\u03bb\u2217 obtained for the dual problem (6), the optimal policy for\nthe problem (5) could be retrieved as\npi\u2217(st) := arg min\nx\u2208X (st)\nL(x,\u03bb\u2217; st). (7)\nThe ensemble problem (6) is difficult to solve since the\nprobability density distribution of st is usually unknown.\nTo find the optimal multipliers \u03bb\u2217 in an efficient manner,\nexisting methods mainly rely on the stochastic subgradient-\nbased (SGD) methods [38], [71], [96]. However, SGD is\nTime\n\u2026 \u2026\nFig. 3: Timescale splitting for offline-aided online SAGA operations.\nIterates {\u03bbt} generate actual IoT decision, while \u03bb1|t, . . . ,\u03bbK|t are\nK virtual iterates updated via (9) at slot t; and \u03bbt+1 := \u03bbK|t.\nknown to suffer from slow convergence, which implies that the\nIoT network needs to implement sufficient many suboptimal\ndecisions generated during the transient stage of SGD.\nFrom a different viewpoint, given the huge volume of histor-\nical data generated by IoT networks, (6) was first formulated in\n[17] as a statistical learning task involving both offline training\nand online operational phases. The rationale is that historical\ndata contain statistics of the IoT states, and learning from\nthem can aid coping with the uncertainty of future management\ntasks, leading to reduced transient time of adaptive algorithms.\nSpecifically, with a training set of N0 historical IoT state\nsamples S\u02c60 := {sn, 1 \u2264 n \u2264 N0} available offline, (6) can be\nrecast in an empirical form via sample averaging as\nmax\n\u03bb\u22650\nD\u02c6S\u02c60(\u03bb), with D\u02c6S\u02c60(\u03bb) :=\n1\nN0\nN0\u2211\nn=1\nD\u02c6n(\u03bb)\u2212 \u000f\n2\n\u2016\u03bb\u20162 (8)\nwhere D\u02c6n(\u03bb) := D(\u03bb; sn), and \u000f > 0 is a regulariza-\ntion constant typically used in statistical learning to boost\ngeneralization capability [93]. Note that while an `2-norm\nregularizer is adopted in (8), other forms of regularization (e.g.,\n`1 and total-variation norm) are also possible depending on a-\npriori knowledge. Note that here t has been replaced by n to\ndifferentiate historical data from data in online phases.\nViewing (8) as a (negated) empirical risk minimization\n(ERM) task, we can resort to the state-of-the-art optimiza-\ntion methods for ERM, e.g., SAGA [33], that enjoys fast\nconvergence and low complexity. Using SAGA, per iteration\nk, we evaluate a single summand of the empirical gradi-\nent, i.e., \u2207D\u02c6\u03bd(k)(\u03bbk) at the iterate \u03bbk, with sample index\n\u03bd(k) \u2208 {1, . . . , N0} selected uniformly at random. Thus,\nthe computational complexity of SAGA is that of a SGD\niteration for (8). Furthermore, SAGA stores a collection of the\noutdated gradients {\u2207oldD\u02c6n} for all samples, where \u2207oldD\u02c6n\nwas evaluated by \u03bbk[n] \u2014 the most recent iteration k[n] that\nsn was drawn; i.e., k[n] := sup{k\u2032 : \u03bd(k\u2032) =n, k\u2032<k}. SAGA\ncombines the fresh gradient with the stored ones as\n\u03bbk+1 =\n[\n\u03bbk+\u03b1\n(\n\u2207D\u02c6\u03bd(k)(\u03bbk)\u2212\u2207oldD\u02c6\u03bd(k) +\u2207oldD\u02c6S\u02c60\n)]+\n(9)\nwhere \u03b1 is the pre-defined stepsize, and the stored gradients\nare \u2207oldD\u02c6S\u02c60 := (1/N)\n\u2211N\nn=1\u2207oldD\u02c6n \u2212 \u000f\u03bbk.\nThe merits of SAGA lie in the fact that its gradient estimator\nin (9) is still unbiased as that with SGD. In addition to the\nunbiasedness however, SAGA\u2019s gradient estimator attains con-\nsiderably lower variance than SGD thanks to the contribution of\nthe stored previous gradients, which is now termed the variance\nreduction technique prevalent in large scale machine learning\ntasks. Needless to mention the encouraging empirical results,\nthe SAGA in (9) is provably convergent to the optimum of (8)\n7with the linear convergence rate [17], [33]\nE\u03bd\n[\nD\u02c6\u2217S\u02c60 \u2212 D\u02c6S\u02c60(\u03bbk)\n]\n= O(\u03c1k) (10)\nwhere D\u02c6\u2217S\u02c60 is the optimal objective of (8), and \u03c1 \u2208 (0, 1) is\nthe linear rate depending on the objective function of (8).\nHence, in the offline phase, we run KN0 SAGA iterations\n(9) on set S\u02c60 - on average K iterations per sample. In the online\nphase, initialized with the offline output, SAGA (we term\nonline SAGA) keeps acquiring data st with a growing training\nset S\u02c6t := S\u02c6t\u22121 \u222a st. At slot t, online SAGA is initialized with\nthe last iterate of slot t \u2212 1, and updates \u03bbt by running K\niterations (9); see Fig. 3. The IoT decision is generated using\nthe current \u03bbt by pit(st) = arg minx\u2208X (st) L(x,\u03bbt; st). This\nis the key idea of offline-aided online IoT operations.\nThe offline-aided online scheme is not simply heuristic. In\nfact, the learning performance can be rigorously quantified via\nseveral concentration results in the learning theory [93], which\nuniformly bound the discrepancy between the empirical loss\n(8) and the loss (6) with high probability (whp), i.e.,\nsup\n\u03bb\u22650\n|D(\u03bb)\u2212 D\u02c6S\u02c6t(\u03bb)| \u2264 Hs(Nt), whp (11)\nwhere Hs(Nt) bounds the statistical error induced by the finite\nsize Nt of the training set S\u02c6t. Under proper (so-termed mixing)\nconditions, the law of large numbers guarantees that Hs(Nt) is\ngenerally in the order of O(\u221a1/Nt) [93, Section 3.4]. On the\nother hand, let Ho(KNt) upper bound the optimization error\nof solving (8) with S\u02c6t due to running on average only finite\n(K) iterations per sample; i.e., D\u02c6\u2217S\u02c6t\u2212D\u02c6S\u02c6t(\u03bbt) \u2264 Ho(KNt).\nOnline SAGA aims at a \u201csweet-spot\u201d between affordable\ncomplexity (controlled by K) and desirable overall learning\nerror, which accounts for both the optimization and statis-\ntical errors Hs(Nt) + Ho(KNt). Specifically, if we select\nN0 \u2265 3\u03ba/4 with \u03ba denoting the condition number of (8), and\nK \u2265 6, the optimization error is bounded by Ho(KNt) \u2264\nHs(Nt) [17]. In fact, even with K = 1, online SAGA can\nstill guarantee that Ho(KNt) = O (Hs(Nt)). With the link\nbetween the optimal policy and the optimal multiplier (7) in\nmind, the key message here is that with sufficient historical\nsamples, online SAGA only requires running a small number\nof iterations per slot to bring the optimization error close\nto the statistical accuracy provided by the current training\nset. Recent works along this line also include [36], [45] that\nfocused on algorithms for piecewise stationary environments.\nLearning more complex policies for non-interactive settings\nhas been also studied by leveraging deep neural networks\n[87]. Possible future research along this line also includes\ndeveloping algorithms under the assumption of stationarity\nin high-order moments, which is also pertinent in practice.\nAlgorithms tailored for fully nonstationary settings will be\npresented in Section IV.\nB. Learn-and-adapt approaches in semi-interactive settings\nThe IoT environment in Section III-A is non-interactive,\nmeaning that the dynamic of st+1 in (5) does not change\naccording to xt. The IoT states can be also driven by decisions,\nwhich include the job queue length in a data center [18], the\nlane length in a transportation network [42], as well as the\nAdapt       to        \nand generate\nAdaptationLearning\nAdd current     , \nand update    \nIoT operationMonitor IoT state     \nand\nFig. 4: A learn-and-adapt diagram for IoT management.\nbattery level in a smart grid [85], [95]. This section considers\nthe case where such IoT states appear in the constraints, but not\nin the objectives, which we call the semi-interactive settings.\nConsider an IoT network represented as a directed graph\nG = (N , E) with nodes N := {1, . . . , N} and edges E :=\n{1, . . . , E}. The node-incidence matrix is formed with (n, e)\nentry A(n,e) = 1(\u22121) if link e enters (leaves) node n, and\nA(n,e) = 0, otherwise. With ct \u2208 RN+ collecting the exogenous\nresources of all nodes per slot t, xt \u2208 RE for the endogenous\nresources across edges, the aggregate resource is Axt + ct.\nConnecting with (5), ct is included in the IoT state st, and the\nconstraint becomes g(xt; st) = Axt + ct. With qt collecting\nall buffered resources at slot t, we wish to solve (4) with the\nadditional state dynamics and the long-term constraints as\nqt+1 = [qt +Axt + ct]\n+\n, \u2200t (12a)\nlim\nT\u2192\u221e\n(1/T )\n\u2211T\nt=1E [\u2016qt\u2016] <\u221e. (12b)\nDue to the extra constraints in (12), the optimal objective of\nthis new problem is at least f\u2217 in (4). Furthermore, the dynamic\nof the interactive state qt (a.k.a. queues) in (12a) also accounts\nfor the transient performance of an adaptive algorithm. To see\nthis, suppose that under pi\u2217, it holds that Api\u2217(st) + ct =\n0, \u2200st; and consider the convergence path of policy pit induced\nby \u03bbt as pi1 \u2192 pi2 \u2192 pi3 = . . . = piT = pi\u2217, along with\nApi1(s1) + c1 = 10 and Api2(s2) + c2 = 5. In this case, if\nq1 = 0, then we have q2 = 10 and q3 = . . . = qT = 15.\nThe simple example entails two variable insights: i) con-\nstraint violations incurred by the sub-optimal decisions during\nthe transient stage (e.g., pi1,pi2) accumulate via qt; and ii) once\naccumulated in the transient stage, qt will not decrease in the\nsteady state (e.g., pit, t \u2265 3). This explains the suboptimal\nperformance tradeoff of SGD for (4) with (12); see also [21].\nTo better control the interactive state qt, it suffices to:\nS1) reduce the transient time of the adaptive algorithm; and,\nS2) diminish qt accumulated during the transient stage.\nFollowing this two guidelines, we adopt a procedure in\nthe online phase that we term online learning-and-adaptation\n(named use LA-SAGA henceforth); see a diagram in Fig. 4.\nRegarding S1), LA-SAGA performs the offline-aided online\nlearning as that in Fig. 3, by growing the training set S\u02c6t\nbased on which it better learns \u03bbt; and for S2), LA-SAGA\nsuperimposes \u03bbt to the instantaneous state (buffered resources)\nqt, and comes up with an effective multiplier as\n\u03b8t\ufe38 \ufe37\ufe37 \ufe38\neffective multiplier\n= \u03bbt\ufe38 \ufe37\ufe37 \ufe38\nstatistical learning\n+ \u00b5qt \u2212 b\ufe38 \ufe37\ufe37 \ufe38\nsystem interaction\n(13)\n8where \u00b5 tunes emphasis to statistical versus interactive state\ninformation, and b is a constant that corrects the possible bias\nin the steady-state - the intuition will become transparent soon.\nBased on \u03b8t, the real-time IoT decision xt is obtained by\nminimizing the Lagrangian over X (st); that is,\npit(st) = xt := arg min\nx\u2208X (st)\nL(x,\u03b8t; st). (14)\nNote that different from stochastic allocation that is solely\nbased on the system feedback \u03b8t = \u00b5qt [71], and statistical\nlearning that only relies on \u03b8t = \u03bbt, LA-SAGA can take\nadvantage of both through the use of effective multiplier \u03b8t.\nTo grasp how the effective multiplier accounts for S2),\nsuppose that after sufficient learning processes, \u03bbt \u2248 \u03bb\u2217, and\nqt is large so that \u00b5qt \u2212 b \u001d 0. In this case, we have the\n\u201cshadow price\u201d \u03b8t \u001d \u03bb\u2217, and thus xt obtained through (14)\nwould ensure that Axt + ct < 0 so that qt+1 < qt via (12a).\nIntuitively speaking, \u03b8t will eventually oscillate around \u03bb\u2217, and\nthus qt will oscillate around b/\u00b5 - this also suggests a positive\nb, otherwise it leads to a biased \u03b8t \u2265 \u03bb\u2217 since qt \u2265 0.\nRigorous analysis demonstrate that through a proper selec-\ntion of the bias b = O\u02dc(\u221a\u00b5), \u03b8t will converge to the O(\u221a\u00b5)-\nneighborhood of \u03bb\u2217 for (6); formally, we have [17]\nlim\nT\u2192\u221e\n(1/T )\n\u2211T\nt=1E [f (xt; st)]\u2212 f\u2217 = O(\u00b5) (15a)\nlim\nT\u2192\u221e\n(1/T )\n\u2211T\nt=1E [\u2016qt\u2016] = O\u02dc (1/\n\u221a\n\u00b5) (15b)\nwhich asserts that LA-SAGA is O(\u00b5)-optimal with an average\nqueue length O\u02dc(1/\u221a\u00b5) - an elegant [O(\u00b5), O\u02dc(1/\u221a\u00b5)] tradeoff.\nComparing with the tradeoff [O(\u00b5),O(1/\u00b5)] under Lyapunov\noptimization in [71], LA-SAGA [17], [21] improves the per-\nformance in terms of constraint violations (queue lengths).\nThe idea of incorporating learning into network optimization\nis pioneered in [46]. However, the developed learning mecha-\nnism therein suffers from the curse of dimensionality. Targeting\nlarge-scale IoT networks, LA-SAGA can tackle settings with\ncontinuous S and X with possibly infinite elements, and still\nbe amenable to efficient and scalable online operations. The\nimportant implication of the learn-and-adapt scheme is that\nit can perform the optimal IoT management, with reduced\nresources and improved QoS, namely, reduced queueing delay\nin data centers [21], faster virtual network function placement\n[23], and lower congestion in transportation networks, or\nsmaller battery capacity in power grids [52].\nAs a closing remark of this subsection, note that while the\nproblem considered in the semi-interactive setting here ex-\nplicitly contains queueing-type constraints, the semi-interactive\nsettings in fact cover a broader class of problems in IoT. For\ninstance, throughput maximization in UAV-enabled wireless\nnetworks under trajectory constraints also belongs to the class\nof semi-interactive IoT settings [100], [105].\nC. Reinforcement learning for interactive IoT environments\nThe IoT environment considered in Section III-B is semi-\ninteractive in the sense that only the dynamic of qt+1 (but\nnot st+1) changes according to xt through (12a). To broaden\nthe scope of the unified framework, this subsection introduces\nmethods tailored for the fully interactive setups, where the\ndynamic of IoT state st that can appear both in the objectives\nand the constraints is driven by the decision xt. This set-\nting captures the trajectory optimization in UAV-aided mobile\ncommunications, e.g., [100], [105], the dynamic caching with\nlimited storage units, e.g., [78], and the route planning in\nintelligent transportation, e.g., [106].\nFor simplicity, consider an IoT environment with a finite\nstate space S, and a finite action space X . The interaction\nbetween the operator and the IoT environment is uniquely\ncaptured by the transition probability of going from the current\nstate s to the subsequent state s\u2032 under action x \u2208 X (s) \u2286 X ,\ngiven by [Px]ss\u2032 := P(st+1 = s|st = s\u2032,xt = x). Similar to\n(5), the goal is to determine a possibly randomized policy pi\nthat given a state st, generates xt = pi(st) so as to minimize\nthe total discounted cost1, that is\nminimize\n{pi(st)\u2208X (st), st}\nlim\nT\u2192\u221e\nE\n[\nT\u2211\nt=1\n\u03b3t\u22121f (pi(st); st)\n]\n(16)\nwhere \u03b3 \u2208 (0, 1) is a discounting factor, and E is taken over\nthe sample path of {st}, as well as the random policy pi.\nFor a fixed policy pi, the state value function is defined as\nVpi(s) := lim\nT\u2192\u221e\nE\n[\nT\u2211\nt=1\n\u03b3t\u22121f (pi(st); st)\n\u2223\u2223\u2223s1 = s] (17)\nand the state-action value function (so-termed Q-function) is\nQpi(s,x) := f (x; s)+\u03b3Es\u2032|s,x [Vpi(s\u2032)], where E is taken over\nthe one-step transition from the current state s to s\u2032 under\naction x. With the optimal policy pi\u2217, we have that2\npi\u2217(s) := arg min\nx\u2208X (s)\nQ\u2217(s,x) (18)\nand V \u2217(s) = Q\u2217(s,pi\u2217(s)). Furthermore, the optimality con-\ndition of (16) that is termed Bellman optimality equation can\nbe written as (e.g., [90])\nQ\u2217(s,x)=f (x; s)+\u03b3Es\u2032|s,x\n[\nmin\nx\u2032\u2208X (s)\nQ\u2217(s\u2032,x\u2032)\n]\n, \u2200x, s (19)\nwhich is a system of nonlinear equations of Q\u2217 \u2208 R|S|\u00d7|X|.\nSwitching the goal from (16) to the fixed point of the Bell-\nman optimality equation (19), a classical yet popular approach\nis the so-termed Q-learning algorithm [98]:\nS1) At slot t, select the decision xt by\npit(st) = xt :=\n{\narg min\nx\u2208X (st)\nQt (st,x) w.p. 1\u2212 \u000ft\nrandom x \u2208 X (st) w.p. \u000ft\n(20)\nwhere \u000ft > 0 is a pre-defined exploration constant, and st+1\nis generated according to P(st+1 = s) = [Pxt ]sts.\nS2) Update the state-action value function as\nQt+1(st,xt) =Qt(st,xt)\n\u2212\u03b1t\n(\nf (xt; st) + \u03b3 min\nx\u2208X (st+1)\nQt(st+1,x)\n)\n(21)\nwhere \u03b1t is a pre-defined stepsize. Note that different from\nSections III-A and III-B, the explicit form of the objective\n1For simplicity, the infinite horizon discounted formulation is considered \u2014\na slight mismatch with the generic one (1). Other formulations with constraints\nor average costs can be also considered with additional assumptions [6].\n2We interchangeably use Q\u2217(s,x) = Qpi\u2217 (s,x) and V \u2217(s) = Vpi\u2217 (s).\n9function f ( \u00b7 ; st) does not need to be known per slot t. Instead,\nonly the functions values {f (x\u03c4 ; s\u03c4 )}t\u03c4=1 along the trajectory\n(s1,x1), \u00b7 \u00b7 \u00b7 , (st,xt) are assumed to be known. With properly\nselected {\u000ft, \u03b1t}, the simple Q-learning algorithm is provably\nconvergent under the finite state and action spaces (a.k.a.\ntabular case) [90]. To date, convergence of Q-learning and\nits variants is mostly asserted for the tabular case.\nTo scale up Q-learning in the large-scale settings, recent\nefforts have been devoted to infer Q by minimizing the residual\nof the Bellman optimality equation (19); that is,\nmin\nQ\n\u2211\nx,s\n(\nQ(s,x)\u2212 f (x; s)\u2212 \u03b3Es\u2032|s,x\n[\nmin\nx\u2032\u2208X (s)\nQ(s\u2032,x\u2032)\n])2\n.\n(22)\nAlbeit its simple expression, several fundamental challenges\narise when solving this fitting problem (22):\nC1) the optimization scale can be prohibitively huge due to the\npossibly large state and action spaces;\nC2) the unknown conditional expectation Es\u2032|s,x inside the\nsquare loss prevents an easy unbiased gradient estimator; and,\nC3) the max operator inside the square loss introduces non-\nsmoothness and non-convexity when performing optimization.\nTo tackle C1), function approximation methods have been\nstudied using linear or nonlinear (random) basis functions\n[13], [84]. Roughly speaking, given a state-action pair (x, s)\nalong with its pre-defined feature vector \u03c6x,s \u2208 Rd, existing\napproaches will approximate the Q-function by Q(s,x) :=\nz>(\u03c6x,s)\u03b8, where z(\u03c6x,s) \u2208 R2D is a lifted feature vector\n(e.g., random features or outputs of deep neural networks)\ngenerated from \u03c6x,s and \u03b8 \u2208 R2D is the wanted parameter\nvector. To this end, the task of finding the |S| \u00d7 |A| function\n(matrix) Q reduces to finding the 2D-dimensional vector\n\u03b8. Along this line, several recent works based on primal-\ndual solvers have made significant progress on simultaneously\nresolving C1) and C2) [30], [99]. Regarding C3), while it is\nstill an active research area, approaches leveraging smoothing\ntechniques for nonsmooth functions in convex optimization\nhave shed light on promising remedies [31], [70].\nIn addition to value iteration-based methods such as Q-\nlearning, approaches based on direct policy search such as\npolicy gradients and actor-critic methods are also prevalent\nnowadays, e.g., [83], [91], [108]. This key idea behind policy\ngradient is to update the \u03b8-parametrized policy pi\u03b8 using the\ngradient of the discounted objective (16) with respect to the\npolicy parameters [91]. Convergence of the policy gradient\nwith deep neural networks or kernel-based function approx-\nimators is now better understood than Q-learning, along with\nthe limitations of policy gradient-based methods that arise from\ntheir high variance.\nWe conclude this section by remarking that approaches in\nlight of the offline-aided-online learning have also been studied\nfor (16) under the name of experience replay, which achieves\ntremendous success in various artificial intelligence tasks [68].\nIV. SCALABILITY IN ONLINE LEARNING FOR IOT\nThe IoT settings considered in Section III involve slow-\nvarying IoT dynamics that are (asymptotically) stationary rel-\native to the timescale of making decisions. In large-scale IoT\nNature:\nLearner:\nConstraint:\nLearner:\nLoss:\nA full-information IoT setting\nA semi-bandit IoT setting\nNature:\nLearner:\nA bandit IoT setting\nFig. 5: Three forms of feedback in IoT environments (termed nature)\ncorrespond to three different types of information oracle in Table I.\nhowever, real-time control and communications entail slow\nand fast time scales that prompt scalable online solvers for\ngenerally nonstationary settings \u2014 the topics of this section.\nIn addition to the general non-stationarity, special attention\nwill be given to approaches designed under limited informa-\ntion about the environment, or equivalently, solvers requiring\nlimited computation and communication resources to sense the\nenvironment. Corresponding to different information that may\nbe available in IoT, we outline three classes of scalable online\nlearning approaches; see also Fig. 5 for a comparison.\nA. Constrained online learning for IoT management\nConsider a finite time horizon T . Per slot t, the IoT operator\nselects an action xt from a known and fixed convex set\nX \u2286 Rd, and the IoT environment (a.k.a. nature in OCO) then\nreveals a loss ft : Rd \u2192 R, along with a time-varying (possibly\nadversarial) penalty function gt : Rd \u2192 RN . The latter leads\nto a time-varying constraint gt(x) \u2264 0, which is driven by the\nunknown IoT dynamics. As in (1), the goal here is to generate\na sequence of decisions that minimize the aggregate loss, and\nensure that the constraints are satisfied in the long term on\naverage. Specifically, we wish to solve\nminimize\n{xt\u2208X ,\u2200t}\nT\u2211\nt=1\nft(xt) subject to\nT\u2211\nt=1\ngt(xt) \u2264 0. (23)\nComparing with the generic problem (1), we keep the time-\nvarying IoT state st implicit in (23), e.g., ft(xt) := f(xt; st)\nand gt(xt) := g(xt; st), since the algorithms introduced in this\nsection may not need to directly sense the state st. For (23), if\n{ft,gt} are known and T is not prohibitively large, the optimal\ndecisions can be found using any off-the-shelf batch solver.\nAlong with the potentially high complexity of batch solvers, a\nkey challenge is that loss and constraint functions in dynamic\nIoT setups are often unknown before allocating resources, due\nto unpredictable channel blocking, in millimeter wave links,\ndue to the unpredictable routing, network congestion, device\nmalfunctions, and nowadays malicious attacks.\n10\nConsider an edge layer with low-power sensors; a fog\nwith N nodes in N ; and, a cloud with multiple computing\ncenters [25]. Per slot t, each node n collects data requests dnt\nfrom nearby sensors, and has to decide among three options:\ni) offloading an amount \u03c7nt (from d\nn\nt ) to the cloud;\nii) offloading xnmt to node m for collaborative computing; and,\niii) processing an amount xnnt using the in-situ fog servers.\nVariable xt consists of all the decisions in i) - iii); see Fig. 6.\nSupposing that each fog node has a local queue to buffer\nunserved workloads, a long-term constraint is imposed to\nensure that the cumulative amount of served workloads is no\nless than the arrived amount over T slots; that is,\nT\u2211\nt=1\ngnt (xt) \u22640, \u2200n\ngnt (xt) := d\nn\nt +\n\u2211\nm\u2208N inn\nxmnt \u2212\n\u2211\nm\u2208N outn\nxnmt \u2212 \u03c7nt \u2212 xnnt (24)\nwhere N inn (N outn ) is the set of fog nodes with in-coming (out-\ngoing) links to (from) node n. Clearly, amounts \u03c7nt , x\nnm\nt , and\nxnnt have caps depending on the communication protocols and\ncomputing cores in use. With x\u00af collecting all these caps, the\nfeasible set is X :={0 \u2264 xt \u2264 x\u00af}.\nAmong candidate figures of merit in optimizing xt, is\nnetwork delay of the online edge processing and offloading\ndecisions [9], [22]. Specifically, the latency associated with \u03c7nt\nis mainly due to the communication delay, which can be mod-\neled as a time-varying convex function lnt (\u03c7\nn\nt ). Likewise, the\ncommunication delay related to xnmt is denoted by l\nnm\nt (x\nnm\nt ).\nIn addition, latency pertaining to xnnt comes from its limited\ncomputation capability, which can be modeled as a function\nhnt (x\nnn\nt ) capturing dynamics during the computing processes.\nThe overall performance in allocating xt is quantified by\naggregate latency metrics. Those include computational (lt)\nand communication delays (ht), namely\nft(xt) :=\n\u2211\nn\u2208N\n(\nlnt (\u03c7\nn\nt ) +\n\u2211\nm\u2208N outn l\nnm\nt (x\nnm\nt ) +h\nn\nt (x\nnn\nt )\n)\n.(25)\nWhile the aggregate delay in some cases cannot directly\nreflect user experience, a viable alternative is the maximum\nof computational and communication delays; see e.g., [22].\nWhile the average-delay objective presumed in (23) may not\nbe the optimal performance metric in some mission critical\napplications, our formulation can also cover the probabilistic\ndelay requirements. The per-slot objective of the latter is an\nindicator function of the delay given by\nft(xt) :=\n\u2211\nn\u2208N\n1\n{(\nlnt (\u03c7\nn\nt ) +\n\u2211\nm\u2208N outn\nlnmt (x\nnm\nt ) + h\nn\nt (x\nnn\nt )\n)\n\u2264 l\u00af\n}\n(26)\nwhere l\u00af is a pre-defined upper bound of user delay. The price\npaid is that the resultant problem is nonconvex, which can be\ntackled by e.g., the approach in Section IV-C.\nWith ft(xt) as in (25) and constraints as in (24), the solution\nof (23) aims to minimize the aggregate delay, while serving\nall IoT demands in the long term. Looking forward, more\nintriguing is to find such an optimal strategy in a fully causal\nsetting, where {ft(xt), dnt } are unknown when deciding xt,\nEdges\nCloud center\nFog clusters\nEdges\nFig. 6: A diagram for mobile computation offloading: IoT devices at\nthe edge layer; fog clusters contain locally connected fog nodes, and\nthe data center in the cloud layer.\nbut are revealed at the end of slot t after deciding xt.\nTo gauge the performance of online decisions, static regret\nis adopted by OCO to measure how far the aggregate loss of\nan OCO algorithm is from the best fixed solution in hindsight\n[109]. Since a static regret relies on a rather coarse benchmark,\nwhich is less useful in dynamic IoT [16], we are motivated to\npursue the so-termed dynamic regret given by\nRegdT :=\nT\u2211\nt=1\nft(xt)\u2212\nT\u2211\nt=1\nft(x\n\u2217\nt ) (27a)\nwith x\u2217t \u2208 arg min\nx\u2208X\nft(x), subject to gt(x)\u22640 (27b)\nwhere the benchmark is now formed using the best sequence\n{x\u2217t } for the instantaneous problem, subject to the instan-\ntaneous constraint. The metric in (5) is more suitable for\nassessing performance of dynamic IoT networks than its static\ncounterpart in [109], because a sub-linear dynamic regret\nimplies a sub-linear static one, but the converse is not true.\nRegarding feasibility of online decisions, the dynamic fit is\nalso useful to quantify the accumulated violations, that is\nFitdT :=\n\u2225\u2225\u2225\u2225\u2225\n[\nT\u2211\nt=1\ngt(xt)\n]+\u2225\u2225\u2225\u2225\u2225. (28)\nThe long-term constraint implicitly assumes that the instanta-\nneous constraint violations can be compensated by subsequent\nstrictly feasible decisions, thus allowing adaptation of fog\ndecisions to the unknown dynamics of IoT user demands.\nUnder the metrics in (27) and (28), an ideal algorithm will\nbe one that achieves both sub-linear dynamic regret and sub-\nlinear dynamic fit. A sub-linear dynamic regret implies \u201cno-\nregret\u201d relative to the clairvoyant dynamic solution on the long-\nterm average; i.e., limT\u2192\u221eRegdT /T = 0, while a sub-linear\ndynamic fit indicates that the online strategy is also feasible\non average; i.e., limT\u2192\u221e FitdT /T = 0.\nWith \u03bb \u2208 RN+ denoting the Lagrange multiplier vector, the\nLagrangian of (23) is\nLt(x,\u03bb) := ft(x) + \u03bb>gt(x). (29)\nBuilding on (29), an online scheme termed modified saddle-\npoint (MOSP) approach has been developed first in [16] and\nlater in [102]. We use the low-complexity variant in [102] for\nthe subsequent illustration. Given xt and \u03bbt, the decision xt+1\nis\nxt+1 = PX (xt \u2212 \u03b1\u2207xLt(xt,\u03bbt)) (30)\n11\nwhere PX (y) := arg minx\u2208X \u2016x \u2212 y\u20162; \u03b1 is a pre-defined\nconstant; and, \u2207xLt(xt,\u03bbt) = \u2207ft(xt) +\u2207>gt(xt)\u03bbt is the\ngradient of Lt(x,\u03bbt) with respect to (w.r.t.) x. In addition, the\ndual update takes the modified online gradient ascent form\n\u03bbt+1 =\n[\n\u03bbt + \u00b5(gt(xt) +\u2207>gt(xt)(xt+1 \u2212 xt))\n]+\n(31)\nwhere \u00b5 is the stepsize, and gt(xt) the gradient of Lt(xt,\u03bb)\nw.r.t. \u03bb. Note that (31) is a modified gradient update since the\ndual variable is updated along the first-order approximation of\ngt(xt+1) at xt rather than the commonly used gt(xt).\nWith properly chosen stepsizes, MOSP enjoys dynamic\nregret and fit bounded by [16]\nRegdT =O\n(\nV(x\u22171:T )T\n1\n2\n)\nand FitdT = O\n(\nT\n1\n2\n)\n(32)\nwhere V(x\u22171:T ) is the accumulated variation of the per-slot\nminimizers x\u2217t in (27) given by V(x\u22171:T ) :=\n\u2211T\nt=1 \u2016x\u2217t\u2212x\u2217t\u22121\u2016.\nIn words, MOSP\u2019s dynamic fit is sub-linear, and its dynamic\nregret is also sub-linear, so long as the variation of the\nminimizers is slow enough; i.e., V(x\u22171:T ) = o(\n\u221a\nT ).\nRelevant approaches developed in similar settings also in-\nclude [11], [32], [55]. Specifically, OCO with switching cost\nhas been studied in [55], and feedback-based tracking algo-\nrithms have been developed in [11], [32].\nRemark 1 (Learning via task-adaptive stepsizes). The primal\nupdate (30) can be refined by adjusting each entry of the\ngradient using a per-entry stepsize in accordance with \u201ceach\nthing\u201d in IoT applications [22]. Such an adaptive stepsize can\nbe regarded as an inexpensive approximation of the Hessian\nused in the online Newton iteration [35]. Using edge computing\nas a paradigm, [22] showed that task-adaptive stepsizes can\nmarkedly reduce the network delay when the underlying IoT\ntasks are heterogeneous, where the resultant gradients could\nhave distinct orders of magnitude over different coordinates.\nB. Constrained convex bandit learning for IoT management\nThe online recursions (30) and (31) remain operational under\nthe premise that the loss functions are known, or, their gradients\nare readily available. Clearly, none of these assumptions is\nalways satisfied in IoT, because i) the loss function capturing\nuser dissatisfaction, e.g., service latency or reliability, can be\nhard to model in dynamic settings; and, ii) even if model-\ning is possible, the low-power devices may not afford the\ncomplexity of running statistical learning tools such as deep\nneural networks online. These considerations motivate online\nbandit saddle-point (BanSP) methods to broaden the scope of\nMOSP to IoT settings where the gradient is unavailable or\ncomputationally costly [19].\nThe key idea behind bandit learning is to construct (prefer-\nably stochastic) gradient estimates using limited function value\ninformation [37], [72]. Consider first a learner only observing\nthe value of ft(x) at a single point x per slot t. The crux is to\nconstruct a (possibly unbiased) estimate of the gradient using\nthis single piece of feedback - what is interestingly possible\nby one random function evaluation [37]. The intuition is easy\nto grasp in the one-dimensional case: For a binary variable u\ntaking values {\u22121, 1} equiprobably, and a small \u03b4 > 0, the\ndifference approximation of the derivative f \u2032t at x yields\nf \u2032t(x) \u2248\nft(x+ \u03b4)\u2212 ft(x\u2212 \u03b4)\n2\u03b4\n= Eu\n[u\n\u03b4\nft(x+ \u03b4u)\n]\n(33)\nwhere the equality follows from the definition of expectation.\nDropping Eu, the scaled single-value evaluation ft(x+\u03b4u)u/\u03b4\nis a nearly unbiased estimator of f \u2032t(x). Generalizing this\napproximation to higher dimensions, with a random vector u\ndrawn from the surface of a unit sphere, the scaled function\nevaluation at a perturbed point x + \u03b4u yields an estimate of\nthe gradient \u2207ft(x), given by [37]\n\u2207ft(x) \u2248 Eu\n[\nd\n\u03b4\nft(x+ \u03b4u)u\n]\n:= Eu\n[\n\u2207\u02c6ft(x)\n]\n(34)\nwhere we define one-point gradient \u2207\u02c6ft(x) := d\u03b4 ft(x+ \u03b4u)u.\nBuilding upon (34), consider the primal update (cf. (30))\nx\u02c6t+1 = P(1\u2212\u03b3)X\n(\nx\u02c6t \u2212 \u03b1\n(\n\u2207\u02c6ft(x\u02c6t) +\u2207>gt(x\u02c6t)\u03bbt\n))\n(35)\nwhere (1 \u2212 \u03b3)X := {(1 \u2212 \u03b3)x : x \u2208 X} is a subset of X ,\nand \u03b3 \u2208 [0, 1) is a pre-selected constant dependent on \u03b4. In\nthe full-information case, xt in (30) is the learner\u2019s action,\nwhereas in the bandit case the learner\u2019s action is xt := x\u02c6t+\u03b4ut,\nwhich is the point for function evaluation instead of x\u02c6t in (35).\nProjection in (35) is on a smaller convex set (1\u2212\u03b3)X in (35),\nwhich ensures feasibility of the perturbed xt \u2208 X . Similar to\n(31), the dual update of BanSP is given by\n\u03bbt+1 =\n[\n\u03bbt + \u00b5(gt(x\u02c6t) +\u2207>gt(x\u02c6t)(x\u02c6t+1 \u2212 x\u02c6t))\n]+\n(36)\nwhere x\u02c6t rather than xt is used in this update. Compared with\n(30)-(31), the updates (35)-(36) with one-point bandit feedback\ndo not increase computation or memory requirements; hence,\nthey provide a light-weight surrogate for MOSP to enable\ngradient-free online bandit IoT network optimization.\nIf the mild conditions in [19] are satisfied, the online\ndecisions generated by BanSP yield\nE\n[\nRegdT\n]\n=O\n(\nV(x\u22171:T )T\n3\n4\n)\nand E\n[\nFitdT\n]\n=O(T 34 ) (37)\nwhere E is taken over the sequence of the random actions xt\nwith randomness induced by {ut} perturbations.\nDepending on the underlying dynamics, BanSP can afford\none or multiple loss function evaluations (bandit feedback) per\nslot. If BanSP is endowed with M > 2 function evaluations,\nthe gradient estimate will be more accurate by querying the\nfunction values over M points in the neighborhood of x\u02c6t.\nIntuitively, the performance of BanSP will improve if multiple\nevaluations are available per slot. Indeed, the dynamic regret\nis provably O(V(x\u22171:T )T 12 ), and the dynamic fit FitdT =\nO(T 12 ) [19], which markedly improve upon their single-\npoint counterparts, and reduce to MOSP bounds in the full-\ninformation case (cf. (32)).\nC. Constrained multi-armed bandit learning\nThe salient assumption so far is that IoT decisions belong\nto a time-invariant convex set X . However, IoT devices usu-\nally exhibit time-varying connectivity to the backbone due to\nmobility and cyber attacks, while network configurations are\noften selected from pre-determined protocols. In this context,\n12\nFull informationSemi-banditBandit\nInformation\nL\no\nss\n i\nn\n (\n2\n3\n) \nF\ne\na\nsi\nb\nle\n s\ne\nt \no\nf \n(2\n3\n)\nN\no\nn\nc\no\nn\nv\ne\nx\n \nD\nis\nc\nre\nte\nC\no\nn\nv\ne\nx\nC\no\nn\nti\nn\nu\no\nu\ns\n \nEXP3SP\nBanSP MOSP\nTAOSP\nApplicability\nFig. 7: A summary of learning approaches corresponding to Fig. 5.\nmulti-armed bandit (MAB) methods can be employed to extend\nBanSP when X is time-varying and discrete [51], [53].\nConsider the discrete feasible set X := {x1, . . . ,xK} with\ntotal K possible actions (a.k.a. arms in MAB). To account for\ndynamics, only the actions in Xt \u2286 X are available per slot t;\ne.g., xt \u2208 Xt. The availability of actions could be stochastic,\nfollowing a certain probability distribution; or even adversarial,\nin which case nature can arbitrarily choose Xt.\nPer slot t, collect the objective values of all actions into\nvector ft := [ft(x1), . . . , ft(xK)]>, and likewise the con-\nstraints into matrix Gt :=[gt(x1), . . . ,gt(xK)]\u2208RN\u00d7K . If the\nlearner\u2019s strategy is to select an action xt = xk with k from a\ndistribution k \u223c pt \u2208 RK , then (23) can be re-formulated as\nan optimization problem over distributions {pt}, namely\nminimize\n{pt\u2208\u2206(Xt),\u2200t}\nT\u2211\nt=1\nf>t pt subject to\nT\u2211\nt=1\nGtpt \u2264 0 (38)\nwhere the Xt-supported \u201cprobability simplex\u201d is defined as\n\u2206(Xt) :=\n{ \u2211\nxk\u2208Xt\np(xk) = 1; p(xk) \u2265 0; p(xk) = 0,xk /\u2208 Xt\n}\n.\n(39)\nIt is worth mentioning that ft(xk) and gt(xk) are well defined\neven when the action xk /\u2208 Xt is not available, and the values\nft(x\nk) and gt(xk) are not revealed.\nIn order to employ an MOSP solver for (38), the gradient of\nthe associated Lagrangian is needed, meaning ft and Gt must\nbe known. The challenge is that such information is hardly\navailable in large-scale IoT settings, where one only knows\nft(xt) and gt(xt) given that xt is implemented. The time-\nvarying action set also prevents a direct implementation of\nBanSP to solve (38). To tackle such a challenging setting, a\nnovel EXP3SP algorithm was developed in our recent work\n[53] that builds on the elegant exponential-weight algorithm\nfor exploration and exploitation (EXP3) [8].\nPer slot t, the learner observes the action set Xt, and selects\nxt according to the current distribution pt given by\npt(x\nk) =\np\u02dct(x\nk)1(xk \u2208 Xt)\u2211\nxk\u2208X p\u02dct(xk)1(xk \u2208 Xt)\n, \u2200xk \u2208 X (40)\nwhere p\u02dct(xk) is the unnormalized weight of xk at slot t, the\nvalue of which will be specified later. Once ft(xt) and gt(xt)\n!\"#$%&'$#(\n)*&+&,#--.\n/01-'$,)\n&..*%\"#$\n0,.\n233-..$4'-\n5\n$,60+%&#$0\n,\n2')0+$#7%5\n.3&'&4$'$#(\n2')0+$#7%5\n&1&\"#$8$#(\nFig. 8: The tradeoff among modeling assumptions, accessible infor-\nmation, algorithm adaptivity, scalability and optimality guarantees.\nbecome available, unbiased estimates of ft and Gt are [53]\nf\u02c6t(x\nk) =\nft(x\nk)1(xt = x\nk)\npt(xk)\n, \u2200xk \u2208 X (41a)\ng\u02c6t(x\nk) =\ngt(x\nk)1(xt = x\nk)\npt(xk)\n, \u2200xk \u2208 X . (41b)\nAdopting the gradient estimators in (41), the primal update\nuses the exponential gradient recursion, namely, \u2200xk \u2208 X\np\u02dct+1(x\nk) = p\u02dct(x\nk) exp\n[\n\u2212\u00b5\n(\nf\u02c6t(x\nk) + \u03bb>t g\u02c6t(x\nk)\n)]\n. (42)\nThe weight p\u02dct+1 is in turn used to generate the action\ndistribution in the next slot (cf. (40)). The dual update is\n\u03bbt+1 =\n[\n\u03bbt + \u00b5\n(\nG\u02c6tpt \u2212 \u03b4\u00b5\u03bbt\n)]+\n(43)\nwhere \u03b4 is a tuned constant to ensure a bounded multiplier.\nIf Xt is stochastic, EXP3SP achieves both sub-linear regret\nand fit [53]. A robust modification of EXP3SP has been also\ndeveloped recently to cope with adversaries blocking access of\nIoT devices to their edge servers [51], while further securing\nedge computing and ensuring sub-linear regret and fit. A\nremark is now in order on a scalable rendition of EXP3SP.\nOur scalable online learning schemes are recapped in Fig. 7.\nV. LESSONS LEARNED AND THE ROAD AHEAD\nWe have presented a unified framework for deriving and\nanalyzing adaptive and scalable network design and resource\nallocation schemes for IoT. Leveraging the contemporary\ncommunication, networking and optimization advances, the\nresultant online learning and management policies not only\nfacilitate low-complexity and scalable implementations with\nlimited feedback, but also enjoy efficient adaptation to chang-\ning environments with analytical performance guarantees.\nThe proposed framework lays a solid analytical foundation to\ndelineate the tradeoffs among performance guarantees, degree\nof (non-)stationarity in modeling IoT dynamics, algorithm\nscalability, and levels of accessible information; see Fig. 8.\nModeling assumptions vs optimality guarantees. While both\ndeal with IoT management with unknown dynamics, the mod-\neling assumptions in Sections III and IV differ considerably.\nSpecifically, those in Section III assume a generally stationary\nIoT environment that corresponds to either the simplest i.i.d.\ncase, or to the Markovian case eventually converging to a\nstationary distribution. In contrast, the approaches in Section\nIV can afford arbitrary dynamics even those manipulated by\nadversaries. However, such minimal assumption does not come\nfor free. As a matter of fact, the performance guarantee in\nterms of the sublinear regret in Section IV is weaker than the\noptimality gap in Section III \u2014 see an analytical comparison in\n13\n[16]. Nevertheless, as the effectiveness of the optimal solution\nin Section III also depends on the discrepancy between the real\nIoT settings and the modeled stationary ones, the actual online\nperformance of these approaches requires further evaluation.\nThe vantage point of this overview opens up a number of\nexciting directions for future research.\nDistributed machine learning. Considering the massive\namount of mobile devices in IoT, centralized learning becomes\ncomputationally intractable, and also rises serious privacy con-\ncerns. To date, the widespread consensus is that besides data\ncenters at the cloud, future machine learning and artificial in-\ntelligence tasks have to be performed starting from the network\nedge, namely mobile devices. This is the overarching goal of\nthe emerging federated learning paradigm [66], [67]. Towards\nthis goal, future challenges and opportunities include reducing\nthe communication overhead during the distributed learning\nprocesses, and enhancing the robustness of learning algorithms\nunder adversarial attacks. Recent advances in the direction of\ncommunication-efficient learning include the adaptive commu-\nnication mechanism in [20] that enjoys the first provably bound\non the reduced number of communication rounds. Challenges\nof distributed learning also lie in asynchrony and delay intro-\nduced by e.g., IoT mobility and heterogeneity. Asynchronous\nparallel learning schemes are thus worth investigating by lever-\naging advances in static optimization settings [14], [75]. From\ndistributed machine learning to distributed control, multi-agent\nreinforcement learning will play a critical role in distributed\ncontrol for IoT [58]. A decentralized actor-critic algorithm has\nbeen recently developed in [108] for multi-agent reinforcement\nlearning over networked agents, and further generalized to\ntasks with large continuous state and action spaces [107].\nCommunication, computation and control co-design. The\npast decade has witnessed the convergence of the commu-\nnication and computing processes [10]. The current brief is\nthat next-generation communication networks should support\nemerging large-scale control applications in IoT with mil-\nlions of diverse devices over a large geographical area. This\ncalls for co-designing communication, computing, and control\nmechanisms. The challenges naturally arise in developing the\ndesired network architecture, the role of different network\nentities, pertinent performance metrics, and the corresponding\npolicies to simultaneously satisfy the timeliness, reliability and\nefficiency of all three intertwined systems.\nOver the decades, the focus of wireless communications has\nbeen anytime, anywhere, anyone connection of the humans,\nwhereas the emerging IoT paradigm largely extends the scope\nof wireless networking to connecting everything, along the\nhumans-to-things and things-to-things continuum. The IoT\nchallenges such as extreme heterogeneity, unpredictable dy-\nnamics and massive scale, call for game-changing innovations\nin network design and management. We hope that the proposed\nunified framework can serve as a stepping stone that leads\nto systematic designs and rigorous analysis of adaptive and\nscalable learning and management schemes for IoT, and a host\nof new research venues to pursue.\nREFERENCES\n[1] Further LTE Physical Layer Enhancements for MTC. Document RP-\n141660, 3GPP TSG RAN Meeting 65, Ericsson, Nokia, 2014.\n[2] Narrowband IoT (NB-IoT). document RP-151621, 3GPP TSG RAN\nMeeting 69, Qualcomm, 2015.\n[3] \u201cWhite paper: A new approach to IoT secu-\nrity,\u201d Jun. 2015. [Online]. Available: www.pubnub.com/blog/\n2015-06-29-white-paper-a-new-approach-to-iot-security/\n[4] G. A. Akpakwu, B. J. Silva, G. P. Hancke, and A. M. Abu-Mahfouz,\n\u201cA survey on 5G networks for the Internet of Things: Communication\ntechnologies and challenges,\u201d IEEE Access, vol. 6, pp. 3619\u20133647,\n2018.\n[5] A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari, and\nM. Ayyash, \u201cInternet of Things: A survey on enabling technologies,\nprotocols, and applications,\u201d IEEE Communications Surveys & Tutori-\nals, vol. 17, no. 4, pp. 2347\u20132376, 2015.\n[6] E. Altman, Constrained Markov decision processes. Boca Raton, FL:\nChapman & Hall, 1999.\n[7] L. Atzori, A. Iera, and G. Morabito, \u201cThe Internet of Things: A survey,\u201d\nComputer Networks, vol. 54, no. 15, pp. 2787\u20132805, Oct. 2010.\n[8] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire, \u201cThe non-\nstochastic multiarmed bandit problem,\u201d SIAM Journal on Computing,\nvol. 32, no. 1, pp. 48\u201377, 2002.\n[9] S. Barbarossa, S. Sardellitti, E. Ceci, and M. Merluzzi, \u201cThe edge\ncloud: A holistic view of communication, computation and caching,\u201d\nin Cooperative and Graph Signal Processing, P. Djuric and C. Richard,\nEds. Springer, 2018. [Online]. Available: arXivpreprint:1802.00700\n[10] S. Barbarossa, S. Sardellitti, and P. Di Lorenzo, \u201cCommunicating while\ncomputing: Distributed mobile cloud computing over 5G heterogeneous\nnetworks,\u201d IEEE Sig. Proc. Mag., vol. 31, no. 6, pp. 45\u201355, 2014.\n[11] A. Bernstein, E. Dall\u2019Anese, and A. Simonetto, \u201cOnline optimization\nwith feedback,\u201d arXiv preprint:1804.05159, Apr. 2018.\n[12] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli, \u201cFog computing and\nits role in the Internet of Things,\u201d in Proc. of the MCC workshop on\nMobile Cloud Comp. ACM, 2012, pp. 13\u201316.\n[13] L. Busoniu, R. Babuska, B. De Schutter, and D. Ernst, Reinforcement\nLearning and Dynamic Programming Using Function Approximators.\nBoca Raton, FL: Taylor & Francis Group, 2010.\n[14] L. Cannelli, F. Facchinei, V. Kungurtsev, and G. Scutari, \u201cAsynchronous\nparallel algorithms for nonconvex big-data optimization: Model and\nconvergence,\u201d arXiv preprint:1607.04818, Jul. 2016.\n[15] N. Cesa-Bianchi and G. Lugosi, Prediction, Learning, and Games.\nCambridge, UK: Cambridge University Press, 2006.\n[16] T. Chen, Q. Ling, and G. B. Giannakis, \u201cAn online convex optimization\napproach to proactive network resource allocation,\u201d IEEE Trans. Signal\nProcessing, vol. 65, no. 24, pp. 6350\u20136364, Dec. 2017.\n[17] T. Chen, A. Mokhtari, X. Wang, A. Ribeiro, and G. B. Giannakis,\n\u201cStochastic averaging for constrained optimization with application to\nonline resource allocation,\u201d IEEE Trans. Signal Processing, vol. 65,\nno. 12, pp. 3078\u20133093, Jun. 2017.\n[18] T. Chen, X. Wang, and G. B. Giannakis, \u201cCooling-aware energy and\nworkload management in data centers via stochastic optimization,\u201d\nIEEE J. Sel. Topics Signal Process., vol. 10, no. 2, pp. 402\u2013415, Mar.\n2016.\n[19] T. Chen and G. B. Giannakis, \u201cBandit convex optimization for scalable\nand dynamic IoT management,\u201d IEEE Internet Things J., May 2018,\nto appear. [Online]. Available: https://arxiv.org/pdf/1707.09060.pdf\n[20] T. Chen, G. B. Giannakis, T. Sun, and W. Yin, \u201cLAG: Lazily\naggregated gradient for communication-efficient distributed learning,\u201d\nin Proc. Advances in Neural Info. Process. Syst., Montreal, Canada,\nDec. 2018. [Online]. Available: arxiv.org/abs/1805.09965\n[21] T. Chen, Q. Ling, and G. B. Giannakis, \u201cLearn-and-adapt stochastic\ndual gradients for network resource allocation,\u201d IEEE Trans. Control of\nNetwork Systems, to appear, 2018.\n[22] T. Chen, Y. Shen, Q. Ling, and G. B. Giannakis, \u201cHeterogeneous online\nlearning for \u2018thing-adaptive\u2019 low-latency fog computing in IoT,\u201d IEEE\nInternet Things J., Oct. 2018, to appear.\n[23] X. Chen, W. Ni, T. Chen, I. B. Collings, X. Wang, R. P. Liu, and G. B.\nGiannakis, \u201cMulti-timescale online optimization of network function\nvirtualization for service chaining,\u201d arXiv preprint:1804.07051, Apr.\n2018.\n[24] X. Chen, L. Jiao, W. Li, and X. Fu, \u201cEfficient multi-user computa-\ntion offloading for mobile-edge cloud computing,\u201d IEEE/ACM Trans.\nNetworking, vol. 24, no. 5, pp. 2795\u20132808, 2016.\n[25] M. Chiang and T. Zhang, \u201cFog and IoT: An overview of research\nopportunities,\u201d IEEE Internet Things J., vol. 3, no. 6, pp. 854\u2013864,\n2016.\n14\n[26] W. Chu, M. Dehghan, J. C. Lui, D. Towsley, and Z.-L. Zhang, \u201cJoint\ncache resource allocation and request routing for in-network caching\nservices,\u201d Computer Networks, vol. 131, pp. 1\u201314, Feb. 2018.\n[27] W. Chu, M. Dehghan, D. Towsley, and Z.-L. Zhang, \u201cOn allocating\ncache resources to content providers,\u201d in Proc. ACM Conf. on Info.-\nCentric Netw., Kyoto, Japan, Sep. 2016, pp. 154\u2013159.\n[28] M. Costa, M. Codreanu, and A. Ephremides, \u201cOn the age of information\nin status update systems with packet management,\u201d IEEE Trans. Info.\nTheory, vol. 62, no. 4, pp. 1897\u20131910, Apr. 2016.\n[29] E. Cuervo, A. Balasubramanian, D.-k. Cho, A. Wolman, S. Saroiu,\nR. Chandra, and P. Bahl, \u201cMaui: making smartphones last longer with\ncode offload,\u201d in Proc. of Intl. Conf. on Mobile Systems, App., and\nServices, San Francisco, CA, Jun. 2010, pp. 49\u201362.\n[30] B. Dai, N. He, Y. Pan, B. Boots, and L. Song, \u201cLearning from\nconditional distributions via dual embeddings,\u201d in Proc. Intl. Conf. on\nArtificial Intelligence and Statistics, Fort Lauderdale, FL, Apr. 2017.\n[31] B. Dai, A. Shaw, L. Li, L. Xiao, N. He, J. Chen, and L. Song,\n\u201cSmoothed dual embedding control,\u201d in Proc. NIPS Symp. Deep Re-\ninforcement Learning, Long Beach, CA, Dec. 2017.\n[32] E. Dall\u2019Anese and A. Simonetto, \u201cOptimal power flow pursuit,\u201d IEEE\nTrans. Smart Grids, vol. 9, no. 2, pp. 942\u2013952, Mar. 2018.\n[33] A. Defazio, F. Bach, and S. Lacoste-Julien, \u201cSAGA: A fast incremental\ngradient method with support for non-strongly convex composite ob-\njectives,\u201d in Proc. Advances in Neural Info. Process. Syst., Montreal,\nCanada, Dec. 2014, pp. 1646\u20131654.\n[34] L. Duan, L. Huang, C. Langbort, A. Pozdnukhov, J. Walrand, and\nL. Zhang, \u201cHuman-in-the-loop mobile networks: a survey of recent\nadvancements,\u201d IEEE J. Sel. Areas Commun., vol. 35, no. 4, pp. 813\u2013\n831, Apr. 2017.\n[35] J. C. Duchi, E. Hazan, and Y. Singer, \u201cAdaptive subgradient methods\nfor online learning and stochastic optimization,\u201d Journal of Machine\nLearning Research, vol. 12, pp. 2121\u20132159, Jul. 2011.\n[36] M. Eisen, K. Gatsis, G. J. Pappas, and A. Ribeiro, \u201cLearning\nin wireless control systems over non-stationary channels,\u201d arXiv\npreprint:1803.01078, Mar. 2018.\n[37] A. D. Flaxman, A. T. Kalai, and H. B. McMahan, \u201cOnline convex\noptimization in the bandit setting: gradient descent without a gradient,\u201d\nin Proc. of ACM SODA, Vancouver, Canada, Jan. 2005, pp. 385\u2013394.\n[38] N. Gatsis, A. Ribeiro, and G. B. Giannakis, \u201cA class of convergent\nalgorithms for resource allocation in wireless fading networks,\u201d IEEE\nTrans. Wireless Commun., vol. 9, no. 5, pp. 1808\u20131823, May 2010.\n[39] B. Gerhardt, K. Griffin, and R. Klemann, \u201cUnlocking value in the frag-\nmented world of big data analytics,\u201d Cisco Internet Business Solutions\nGroup, Jun. 2012.\n[40] G. B. Giannakis, V. Kekatos, N. Gatsis, S.-J. Kim, H. Zhu, and B. F.\nWollenberg, \u201cMonitoring and optimization for power grids: A signal\nprocessing perspective,\u201d IEEE Sig. Proc. Mag., vol. 30, no. 5, pp. 107\u2013\n128, Sep. 2013.\n[41] A. M. Gonz\u00e1lez, A. M. S. Roque, and J. Garc\u00eda-Gonz\u00e1lez, \u201cModeling\nand forecasting electricity prices with input/output hidden Markov\nmodels,\u201d IEEE Trans. Power Syst., vol. 20, no. 1, pp. 13\u201324, Feb. 2005.\n[42] J. Gregoire, X. Qian, E. Frazzoli, A. de La Fortelle, and T. Wongpirom-\nsarn, \u201cCapacity-aware backpressure traffic signal control,\u201d IEEE Trans.\nControl of Network Systems, vol. 2, no. 2, pp. 164\u2013173, June 2015.\n[43] E. Hazan, \u201cIntroduction to online convex optimization,\u201d Found. and\nTrends in Mach. Learn., vol. 2, no. 3-4, pp. 157\u2013325, 2016.\n[44] Y. C. Hu, M. Patel, D. Sabella, N. Sprecher, and V. Young, \u201cMobile\nedge computing: A key technology towards 5G,\u201d ETSI white paper,\nvol. 11, no. 11, pp. 1\u201316, 2015.\n[45] L. Huang, \u201cReceding learning-aided control in stochastic networks,\u201d\nPerformance Evaluation, vol. 91, pp. 150\u2013169, Sep. 2015.\n[46] L. Huang, X. Liu, and X. Hao, \u201cThe power of online learning in\nstochastic network optimization,\u201d in Proc. ACM SIGMETRICS, vol. 42,\nno. 1, New York, NY, Jun. 2014, pp. 153\u2013165.\n[47] S. Kaul, R. Yates, and M. Gruteser, \u201cReal-time status: How often should\none update?\u201d in Proc. INFOCOM, Orlando, FL, Mar. 2012, pp. 2731\u2013\n2735.\n[48] S.-W. Kim, B. Qin, Z. J. Chong, X. Shen, W. Liu, M. H. Ang, E. Fraz-\nzoli, and D. Rus, \u201cMultivehicle cooperative driving using cooperative\nperception: Design and experimental validation,\u201d IEEE Transactions on\nIntelligent Transportation Systems, vol. 16, no. 2, pp. 663\u2013680, 2015.\n[49] S. Kosta, A. Aucinas, P. Hui, R. Mortier, and X. Zhang, \u201cThinkair:\nDynamic resource allocation and parallel execution in the cloud for\nmobile code offloading,\u201d in Infocom, 2012 Proceedings IEEE. IEEE,\n2012, pp. 945\u2013953.\n[50] J. Kwak, Y. Kim, J. Lee, and S. Chong, \u201cDream: Dynamic resource\nand task allocation for energy minimization in mobile cloud systems,\u201d\nIEEE J. Sel. Areas Commun., vol. 33, no. 12, pp. 2510\u20132523, 2015.\n[51] B. Li, T. Chen, X. Wang, and G. B. Giannakis, \u201cSecure edge computing\nin IoT via online learning,\u201d in Proc. Asilomar Conf. on Signals, Systems,\nand Computers, Pacific Grove, CA, Oct. 2018.\n[52] \u2014\u2014, \u201cReal-time energy management in microgrids with reduced bat-\ntery capacity requirements,\u201d IEEE Trans. Smart Grids, 2018, to appear.\n[53] \u2014\u2014, \u201cSleeping multi-armed bandit with constraints,\u201d in Proc. AAAI\nConf. Artificial Intelligence, Honolulu, HI, Jan. 2019 (submitted).\n[54] N. Li, L. Chen, and S. H. Low, \u201cOptimal demand response based on\nutility maximization in power networks,\u201d in Proc. IEEE Power and\nEnergy Society General Meeting, Detroit, MI, Jul. 2011, pp. 1\u20138.\n[55] Y. Li, G. Qu, and N. Li, \u201cOnline optimization with predictions and\nswitching costs: Fast algorithms and the fundamental limit,\u201d arXiv\npreprint:1801.07780, Jan. 2018.\n[56] B. Liang, Mobile Edge Computing. Cambridge, UK: Cambridge\nUniversity Press, 2017.\n[57] J. Liu, Y. Mao, J. Zhang, and K. B. Letaief, \u201cDelay-optimal computation\ntask scheduling for mobile-edge computing systems,\u201d in Proc. Intl.\nSymp. on Info. Theory, Barcelona, Spain, Jul. 2016, pp. 1451\u20131455.\n[58] R. Lowe, Y. Wu, A. Tamar, J. Harb, O. P. Abbeel, and I. Mordatch,\n\u201cMulti-agent actor-critic for mixed cooperative-competitive environ-\nments,\u201d in Proc. Advances in Neural Info. Process. Syst., Long Beach,\nCA, Dec. 2017, pp. 6379\u20136390.\n[59] N. Lu, N. Cheng, N. Zhang, X. Shen, and J. W. Mark, \u201cConnected\nvehicles: Solutions and challenges,\u201d IEEE Internet Things J., vol. 1,\nno. 4, pp. 289\u2013299, Aug. 2014.\n[60] D. Lymberopoulos, A. Bamis, and A. Savvides, \u201cExtracting spatiotem-\nporal human activity patterns in assisted living using a home sensor\nnetwork,\u201d Univ Access Info. Soc, vol. 10, no. 2, pp. 125\u2013138, 2011.\n[61] X. Lyu, W. Ni, H. Tian, R. P. Liu, X. Wang, G. B. Giannakis, and\nA. Paulraj, \u201cOptimal schedule of mobile edge computing for internet of\nthings using partial information,\u201d IEEE J. Sel. Areas Commun., vol. 35,\nno. 11, pp. 2606\u20132615, Nov. 2017.\n[62] P. Mach and Z. Becvar, \u201cMobile edge computing: A survey on archi-\ntecture and computation offloading,\u201d IEEE Comm. Surveys & Tutorials,\n2017, to appear.\n[63] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, \u201cMobile edge\ncomputing: Survey and research outlook,\u201d arXiv preprint:1701.01090,\nJan. 2017.\n[64] Y. Mao, J. Zhang, and K. B. Letaief, \u201cDynamic computation offloading\nfor mobile-edge computing with energy harvesting devices,\u201d IEEE J.\nSel. Areas Commun., vol. 34, no. 12, pp. 3590\u20133605, 2016.\n[65] Y. Mao, J. Zhang, S. Song, and K. B. Letaief, \u201cStochastic joint radio\nand computational resource management for multi-user mobile-edge\ncomputing systems,\u201d IEEE Trans. Wireless Commun., vol. 16, no. 9,\npp. 5994\u20136009, 2017.\n[66] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,\n\u201cCommunication-efficient learning of deep networks from decentralized\ndata,\u201d in Proc. Intl. Conf. Artificial Intell. and Stat., Fort Lauderdale,\nFL, Apr. 2017, pp. 1273\u20131282.\n[67] B. McMahan and D. Ramage, \u201cFederated learning: Collaborative\nmachine learning without centralized training data,\u201d Google Research\nBlog, Apr. 2017. [Online]. Available: https://research.googleblog.com/\n2017/04/federated-learning-collaborative.html\n[68] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski\net al., \u201cHuman-level control through deep reinforcement learning,\u201d\nNature, vol. 518, no. 7540, p. 529, Feb. 2015.\n[69] S. Munir, J. A. Stankovic, C.-J. M. Liang, and S. Lin, \u201cCyber physical\nsystem challenges for human-in-the-loop control.\u201d in Proc. Feedback\nComputing, San Jose, CA, Jun. 2013.\n[70] O. Nachum, M. Norouzi, K. Xu, and D. Schuurmans, \u201cBridging the\ngap between value and policy based reinforcement learning,\u201d in Proc.\nAdvances in Neural Info. Process. Syst., Long Beach, CA, Dec. 2017,\npp. 2772\u20132782.\n[71] M. J. Neely, \u201cStochastic network optimization with application to\ncommunication and queueing systems,\u201d Synthesis Lectures on Commu-\nnication Networks, vol. 3, no. 1, pp. 1\u2013211, 2010.\n[72] Y. Nesterov and V. Spokoiny, \u201cRandom gradient-free minimization of\nconvex functions,\u201d Foundations of Computational Mathematics, vol. 17,\nno. 2, pp. 527\u2013566, Apr. 2017.\n[73] D. S. Nunes, P. Zhang, and J. S. Silva, \u201cA survey on human-in-the-loop\napplications towards an Internet of all,\u201d IEEE Communications Surveys\n& Tutorials, vol. 17, no. 2, pp. 944\u2013965, Second quarter 2015.\n15\n[74] M. R. Palattella, M. Dohler, A. Grieco, G. Rizzo, J. Torsner, T. Engel,\nand L. Ladid, \u201cInternet of Things in the 5G era: Enablers, architecture,\nand business models,\u201d IEEE J. Sel. Areas Commun., vol. 34, no. 3, pp.\n510\u2013527, Mar. 2016.\n[75] Z. Peng, Y. Xu, M. Yan, and W. Yin, \u201cArock: an algorithmic framework\nfor asynchronous parallel coordinate updates,\u201d SIAM J. Sci. Comp.,\nvol. 38, no. 5, pp. 2851\u20132879, Sep. 2016.\n[76] A. Ribeiro, \u201cErgodic stochastic optimization algorithms for wireless\ncommunication and networking,\u201d IEEE Trans. Signal Process., vol. 58,\nno. 12, pp. 6369\u20136386, Dec. 2010.\n[77] S. M. Ross, Introduction to probability models. Academic Press, 2014.\n[78] A. Sadeghi, F. Sheikholeslami, and G. B. Giannakis, \u201cOptimal and\nscalable caching for 5G using reinforcement learning of space-time\npopularities,\u201d IEEE J. Sel. Topics Sig. Proc., vol. 12, no. 1, pp. 180\u2013190,\nFeb. 2018.\n[79] K. Sakaguchi and R. Fukatsu, \u201cCooperative perception realized by\nmillimeter-wave v2v for safe automated driving\u201e\u201d in Proc. Asia-Pacific\nMicrowave Conference, Kyoto, Japan, Nov. 2018.\n[80] K. Sakaguchi, T. Haustein, S. Barbarossa, E. C. Strinati, A. Clemente,\nG. Destino, A. P\u00e4rssinen, I. Kim, H. Chung, J. Kim et al., \u201cWhere,\nwhen, and how mmwave is used in 5g and beyond,\u201d IEICE Transactions\non Electronics, vol. 100, no. 10, pp. 790\u2013808, 2017.\n[81] S. Sardellitti, M. Merluzzi, and S. Barbarossa, \u201cOptimal association of\nmobile users to multi-access edge computing resources,\u201d in IEEE Int.\nConf. on Communications, Kansas City, MO, May 2018.\n[82] S. Sardellitti, G. Scutari, and S. Barbarossa, \u201cJoint optimization of radio\nand computational resources for multicell mobile-edge computing,\u201d\nIEEE Trans. on Signal and Info. Process. over Netw., vol. 1, no. 2,\npp. 89\u2013103, Feb. 2015.\n[83] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz, \u201cTrust\nregion policy optimization,\u201d in Proc. Intl. Conf. on Machine Learning,\nLille, France, Jul. 2015, pp. 1889\u20131897.\n[84] Y. Shen, T. Chen, and G. B. Giannakis, \u201cOnline ensemble multi-kernel\nlearning adaptive to non-stationary and adversarial environments,\u201d in\nProc. of Intl. Conf. on Artificial Intelligence and Statistics, Lanzarote,\nCanary Islands, Apr. 2018.\n[85] W. Shi, N. Li, C.-C. Chu, and R. Gadh, \u201cReal-time energy management\nin microgrids,\u201d IEEE Trans. Smart Grids, vol. 8, no. 1, pp. 228\u2013238,\nJan. 2017.\n[86] J. A. Stankovic, \u201cResearch directions for the Internet of Things,\u201d IEEE\nInternet of Things J., vol. 1, no. 1, pp. 3\u20139, Feb. 2014.\n[87] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos,\n\u201cLearning to optimize: Training deep neural networks for wireless\nresource management,\u201d arXiv preprint:1705.09412, May 2017.\n[88] Y. Sun, E. Uysal-Biyikoglu, R. D. Yates, C. E. Koksal, and N. B.\nShroff, \u201cUpdate or wait: How to keep your data fresh,\u201d IEEE Trans.\nInfo. Theory, vol. 63, no. 11, pp. 7492\u20137508, Nov. 2017.\n[89] Y. Sun, S. Zhou, and J. Xu, \u201cEmm: Energy-aware mobility management\nfor mobile edge computing in ultra dense networks,\u201d IEEE J. Sel. Areas\nCommun., vol. 35, no. 11, pp. 2637\u20132646, 2017.\n[90] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction,\nCambridge, MA, 1998.\n[91] R. S. Sutton, D. A. McAllester, S. P. Singh, and Y. Mansour, \u201cPolicy\ngradient methods for reinforcement learning with function approxima-\ntion,\u201d in Proc. Advances in Neural Info. Process. Syst., Denver, CO,\nDec. 2000, pp. 1057\u20131063.\n[92] L. Tassiulas and A. Ephremides, \u201cStability properties of constrained\nqueueing systems and scheduling policies for maximum throughput in\nmultihop radio networks,\u201d IEEE Trans. Automat. Contr., vol. 37, no. 12,\npp. 1936\u20131948, Dec. 1992.\n[93] V. Vapnik, The Nature of Statistical Learning Theory. New York City,\nNY: Springer Science & Business Media, 2000.\n[94] F. Wang, J. Xu, X. Wang, and S. Cui, \u201cJoint offloading and computing\noptimization in wireless powered mobile-edge computing systems,\u201d\nIEEE Trans. Wireless Commun., vol. 17, no. 3, pp. 1784\u20131797, Mar.\n2018.\n[95] X. Wang, X. Chen, T. Chen, L. Huang, and G. B. Giannakis, \u201cTwo-scale\nstochastic control for integrated multipoint communication systems with\nrenewables,\u201d IEEE Trans. Smart Grids, vol. 9, no. 3, pp. 1822\u20131834,\nMay 2018.\n[96] X. Wang, G. B. Giannakis, and A. G. Marques, \u201cA unified approach\nto QoS-guaranteed scheduling for channel-adaptive wireless networks,\u201d\nProc. IEEE, vol. 95, no. 12, pp. 2410\u20132431, Dec. 2007.\n[97] X. Wang, Y. Zhang, T. Chen, and G. B. Giannakis, \u201cDynamic energy\nmanagement for smart-grid-powered coordinated multipoint systems,\u201d\nIEEE J. Sel. Areas Commun., vol. 34, no. 5, pp. 1348\u20131359, May 2016.\n[98] C. J. Watkins and P. Dayan, \u201cQ-learning,\u201d Machine learning, vol. 8, no.\n3-4, pp. 279\u2013292, May 1992.\n[99] X. Wei, H. Yu, and M. J. Neely, \u201cOnline learning in weakly coupled\nmarkov decision processes: A convergence time study,\u201d in Proc. Sig-\nmetrics, Irvine, CA, Jun. 2018.\n[100] Q. Wu, Y. Zeng, and R. Zhang, \u201cJoint trajectory and communication\ndesign for multi-uav enabled wireless networks,\u201d IEEE Trans. Wireless\nCommun., vol. 17, no. 3, pp. 2109\u20132121, Mar. 2018.\n[101] J. Xu, Y. Zeng, and R. Zhang, \u201cUav-enabled wireless power transfer:\nTrajectory design and energy optimization,\u201d IEEE Trans. Wireless\nCommun., 2018, to appear.\n[102] H. Yu, M. Neely, and X. Wei, \u201cOnline convex optimization with\nstochastic constraints,\u201d in Proc. Advances in Neural Info. Process. Syst.,\nLong Beach, CA, Dec. 2017, pp. 1427\u20131437.\n[103] T. Zachariah, N. Klugman, B. Campbell, J. Adkins, N. Jackson, and\nP. Dutta, \u201cThe Internet of Things has a gateway problem,\u201d in Proc.\nACM HotMobile, Santa Fe, NM, Feb. 2015, pp. 27\u201332.\n[104] A. Zanella, N. Bui, A. Castellani, L. Vangelista, and M. Zorzi, \u201cInternet\nof Things for smart cities,\u201d IEEE Internet of Things Journal, vol. 1,\nno. 1, pp. 22\u201332, 2014.\n[105] Y. Zeng and R. Zhang, \u201cEnergy-efficient uav communication with\ntrajectory optimization,\u201d IEEE Trans. Wireless Commun., vol. 16, no. 6,\npp. 3747\u20133760, 2017.\n[106] J. Zhang, S. Pourazarm, C. G. Cassandras, and I. C. Paschalidis, \u201cThe\nprice of anarchy in transportation networks: Data-driven evaluation and\nreduction strategies,\u201d Proc. IEEE, vol. 106, no. 4, pp. 538\u2013553, Apr.\n2018.\n[107] K. Zhang, Z. Yang, and T. Basar, \u201cNetworked multi-agent reinforcement\nlearning in continuous spaces,\u201d in Proc. IEEE Conf. Decision and\nControl, Miami, FL, Dec. 2018, pp. 5872\u20135881.\n[108] K. Zhang, Z. Yang, H. Liu, T. Zhang, and T. Basar, \u201cFully decentralized\nmulti-agent reinforcement learning with networked agents,\u201d in Proc.\nIntl. Conf. Machine Learn., Stockholm, Sweden, 2018, pp. 5872\u20135881.\n[109] M. Zinkevich, \u201cOnline convex programming and generalized infinites-\nimal gradient ascent,\u201d in Proc. Intl. Conf. on Machine Learning,\nWashington D.C., Aug. 2003.\n[110] Y. Zou, J. Zhu, X. Wang, and L. Hanzo, \u201cA survey on wireless security:\nTechnical challenges, recent advances, and future trends,\u201d Proc. IEEE,\nvol. 104, no. 9, pp. 1727\u20131765, Sep. 2016.\n",
      "id": 54163871,
      "identifiers": [
        {
          "identifier": "1810.11613",
          "type": "ARXIV_ID"
        },
        {
          "identifier": "oai:iris.uniroma1.it:11573/1250684",
          "type": "OAI_ID"
        },
        {
          "identifier": "195777516",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:arxiv.org:1810.11613",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1109/jproc.2019.2896243",
          "type": "DOI"
        },
        {
          "identifier": "186282996",
          "type": "CORE_ID"
        }
      ],
      "title": "Learning and Management for Internet-of-Things: Accounting for\n  Adaptivity and Scalability",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:arxiv.org:1810.11613",
        "oai:iris.uniroma1.it:11573/1250684"
      ],
      "publishedDate": "2018-10-27T01:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "http://arxiv.org/abs/1810.11613",
        "https://iris.uniroma1.it/bitstream/11573/1250684/1/Chen_Learning_post-print_2019.pdf"
      ],
      "updatedDate": "2022-12-13T16:14:04",
      "yearPublished": 2018,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/195777516.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/195777516"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/195777516/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/195777516/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/54163871"
        }
      ]
    }
  ],
  "searchId": "6b2e6045350ac29d3c8eec38a158a513"
}