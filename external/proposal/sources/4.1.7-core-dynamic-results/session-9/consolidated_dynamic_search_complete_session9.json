{
  "metadata": {
    "session_id": 9,
    "timestamp": "2025-06-03T09:16:24.052392",
    "script_used": "tools/4.1.7.1_core_dynamic_search.py",
    "stage": "dynamic_search_complete",
    "relevance_criteria_source": "sources/4.1.7-relevance-criteria-session-latest/relevance_criteria_session-latest.json"
  },
  "summary": {
    "total_unique_papers_retrieved": 10
  },
  "papers": [
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": null,
        "authors": [
          {
            "name": "Qian, Y"
          },
          {
            "name": "Sharif, H"
          },
          {
            "name": "Tipper, D"
          },
          {
            "name": "Yan, Y"
          }
        ],
        "citationCount": 0,
        "contributors": [],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/12211338"
        ],
        "createdDate": "2013-07-19T16:53:52",
        "dataProviders": [
          {
            "id": 457,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/457",
            "logo": "https://api.core.ac.uk/data-providers/457/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "A communication infrastructure is an essential part to the success of the emerging smart grid. A scalable and pervasive communication infrastructure is crucial in both construction and operation of a smart grid. In this paper, we present the background and motivation of communication infrastructures in smart grid systems. We also summarize major requirements that smart grid communications must meet. From the experience of several industrial trials on smart grid with communication infrastructures, we expect that the traditional carbon fuel based power plants can cooperate with emerging distributed renewable energy such as wind, solar, etc, to reduce the carbon fuel consumption and consequent green house gas such as carbon dioxide emission. The consumers can minimize their expense on energy by adjusting their intelligent home appliance operations to avoid the peak hours and utilize the renewable energy instead. We further explore the challenges for a communication infrastructure as the part of a complex smart grid system. Since a smart grid system might have over millions of consumers and devices, the demand of its reliability and security is extremely critical. Through a communication infrastructure, a smart grid can improve power reliability and quality to eliminate electricity blackout. Security is a challenging issue since the on-going smart grid systems facing increasing vulnerabilities as more and more automation, remote monitoring/controlling and supervision entities are interconnected. \u00a9 1998-2012 IEEE",
        "documentType": "research",
        "doi": "10.1109/surv.2012.021312.00034",
        "downloadUrl": "https://core.ac.uk/download/12211338.pdf",
        "fieldOfStudy": "computer science",
        "fullText": "IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION 1A Survey on Smart Grid CommunicationInfrastructures: Motivations, Requirements andChallengesYe Yan, Yi Qian, Hamid Sharif, and David TipperAbstract\u2014A communication infrastructure is an essentialpart to the success of the emerging smart grid. A scalableand pervasive communication infrastructure is crucial in bothconstruction and operation of a smart grid. In this paper,we present the background and motivation of communicationinfrastructures in smart grid systems. We also summarize majorrequirements that smart grid communications must meet. Fromthe experience of several industrial trials on smart grid withcommunication infrastructures, we expect that the traditionalcarbon fuel based power plants can cooperate with emergingdistributed renewable energy such as wind, solar, etc, to reducethe carbon fuel consumption and consequent green house gassuch as carbon dioxide emission. The consumers can minimizetheir expense on energy by adjusting their intelligent homeappliance operations to avoid the peak hours and utilize therenewable energy instead. We further explore the challenges for acommunication infrastructure as the part of a complex smart gridsystem. Since a smart grid system might have over millions ofconsumers and devices, the demand of its reliability and securityis extremely critical. Through a communication infrastructure, asmart grid can improve power reliability and quality to eliminateelectricity blackout. Security is a challenging issue since theon-going smart grid systems facing increasing vulnerabilities asmore and more automation, remote monitoring/controlling andsupervision entities are interconnected.Index Terms\u2014Smart grid, communication infrastructure, in-telligent network, interconnected power system, monitoring,sensing, cyber securityI. BACKGROUNDSMART grid is a term referring to the next generationpower grid in which the electricity distribution and man-agement is upgraded by incorporating advanced two-waycommunications and pervasive computing capabilities for im-proved control, efficiency, reliability and safety. A smart griddelivers electricity between suppliers and consumers usingtwo-way digital technologies. It controls intelligent appliancesat consumers\u2019 home or building to save energy, reduce costand increase reliability, efficiency and transparency [1]. Asmart grid is expected to be a modernization of the legacyelectricity network. It provides monitoring, protecting andoptimizing automatically to operation of the interconnectedelements. It covers from traditional central generator and/orManuscript received 25 April 2011; revised 23 January 2012.Y. Yan, Y. Qian, and H. Sharif are with the Department of Com-puter and Electronics Engineering, University of Nebraska-Lincoln (e-mail:yqian@ieee.org).D. Tipper is with the Graduate Telecommunications and NetworkingProgram, University of Pittsburgh.Digital Object Identifier 10.1109/SURV.2012.021312.00034emerging renewal distributed generator through transmissionnetwork and distribution system to industrial consumer and/orhome users with their thermostats, electric vehicles, intelligentappliances [2]. A smart grid is characterized by the bi-directional connection of electricity and information flowsto create an automated, widely distributed delivery network.It incorporates the legacy electricity grid the benefits ofmodern communications to deliver real-time information andenable the near-instantaneous balance of supply and demandmanagement [3].Many technologies to be adopted by smart grid havealready been used in other industrial applications, such assensor networks in manufacturing and wireless networks intelecommunications, and are being adapted for use in newintelligent and interconnected paradigm. In general, smart gridcommunication technologies can be grouped into five keyareas: advanced components, sensing and measurement, im-proved interfaces and decision support, standards and groups,and integrated communications.Figure 1 illustrates a general architecture for smart gridcommunication infrastructures, which includes home areanetworks (HANs), business area networks (BANs), neigh-borhood area networks (NANs), data centers, and substationautomation integration systems [4]. Smart grids distribute elec-tricity between generators (both traditional power generationand distributed generation sources) and end users (industrial,commercial, residential consumers) using bi-directional infor-mation flow to control intelligent appliances at consumers\u2019side saving energy consumption and reducing the consequentexpense, meanwhile increasing system reliability and opera-tion transparency. With a communication infrastructure, thesmart metering/monitoring techniques can provide the real-time energy consumption as a feedback and correspond tothe demand to/from utilities. Network operation center canretrieve those customer power usage data and the on-linemarket pricing from data centers to optimize the electricitygeneration, distribution according to the energy consumption.In a complex smart grid system, through wide deploymentof new smart grid components and the convergence of existinginformation and control technologies applied in the legacypower grid, it can offer sustainable operations to both utilitiesand customers [5]. It can also enhance the efficiency of legacypower generation, transmission and distribution systems andpenetrate the usage of clean renewable energy by introducingmodern communication systems into smart grids.1553-877X/12/$25.00 c\u00a9 2012 IEEEThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.2 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONFig. 1. Smart Grid Communication Infrastructures [4]The cornerstone of a smart grid is the ability for multipleentities (e.g. intelligent devices, dedicated software, processes,control center, etc) to interact via a communication infrastruc-ture. It follows that the development of a reliable and per-vasive communication infrastructure represents crucial issuesin both structure and operation of smart grid communicationsystems [6], [7]. In this connection, a strategic requirementin supporting this process is the development of a reliablecommunication infrastructure for establishing robust real-timedata transportation through Wide Area Networks (WANs) tothe distribution feeder and customer level [8].Existing electrical utility WANs are based on a hybridof communication technologies including wired technologiessuch as fiber optics, power line communication (PLC) sys-tems, copper-wire line, and a variety of wireless technolo-gies (i.e. data communications in cellular networks suchas GSM/GPRS/WiMax/WLAN and Cognitive Radio [9]).They are designed to support some monitoring/controllingapplications as Supervisory Control and Data Acquisition(SCADA)/Energy Management Systems (EMS), DistributionManagement Systems (DMS), Enterprise Resource Plan-ning (ERP) systems, generation plant automation, distributionfeeder automation and physical security for facilities in widerange areas with very limited bandwidth and capacity in closednetworks.Many applications such as energy metering on the smartgrid, have emerged from a decade of research in wirelesssensor networks. However, the lack of an IP-based networkarchitecture precluded sensor networks from interoperatingwith the Internet, limiting their real-world impact. The IETFchartered the 6LoWPAN and RoLL working groups to specifystandards at various layers of the protocol stack with thegoal of connecting low-power devices to the Internet. In [10]the authors present the standards proposed by these workinggroups, and describe how the research community activelyparticipates in this process by influencing their design andproviding open source implementations.The new communication infrastructures should evolve to-ward nearly ubiquitous data transport networks able to han-dle power delivery applications along with vast amount ofnew data coming from the smart grid applications. Thesenetworks should be scalable, in order to support the presentand the future set of functions characterizing the emergingsmart grid communication technological platform, and highlypervasive in order to support the deployment of last-milecommunications (i.e. from a backbone to the terminal cus-tomers locations) [11]. In the rest of this section, we discussseveral key factors for smart grid systems including power linecommunications, distributed energy resources, smart metering,and monitoring and controlling.A. Power Line CommunicationsPower line communications (PLCs) uses the power feederline as communication media. First generation ripple controlsystems provide one-way communications, in which central-ized load control and peak shaving have been performedfor many years. The European standards body CENELECrestricted the use of frequencies between 3 kHz and 95 kHzfor two-way communications for electricity distributor use.A number of second generation PLC systems with low datarates were proposed in the 1990\u2019s, and Automatic MeterReading systems have been deployed based on this technology.Third generation systems based on OFDM with much higherdata rates are currently being developed and deployed forSmart Grids, Distribution Automation and Advanced MeteringManagement [12].With the development of smart grids, the PLC on thepower transmission and distribution networks have becomeone of the potential technologies to exchange the informationbetween the end users and the utilities. In order to providecommunication services with different priorities under thesmart grid environment, it is a must to design a PLC systemwith variable data rates supported, which means understandingof the PLC physical channel characteristics become vital. Thetesting results in [13] show that the main reason influencingthe reliable communication of high-speed data on power lineis the attenuation of the high-frequency signal, which exhibitsmore obviously in the branch of power line. It is almostimpossible to use the frequency range from 10 to 20 MHzfor the reliable communications from distribution transformerto end user, so it must be solved with the aid of means suchas the repeater and the modulation schemes.Beside the fact that feeder cables are not designed fordata transmission, they are also prone to be interfered bythe inverter\u2019s outcome. Therefore, PLC modems developedfor domestic applications may not be suitable. Limitationsand difficulties that obstruct transmission are revealed in [14].Also, it underlines the possibility of communicating in suchan environment and discusses the possible solutions such asthe use of a pulsewidth modulation filter to overcome thoselimitations.The majority of recent contributions have discussed PLC forhigh-data-rate applications like Internet access or multimediacommunication serving a relatively small number of users.However, it lacks the consideration with PLC as an enabler forsensing, control, and automation in large systems comprisingtens or even hundreds of components spread over relativelywide areas. In [15], the authors discussed communicationnetwork requirements common to such systems and presentedtransmission concepts for PLC to make use of the existingThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 3power transmission and/or distribution infrastructure resources(i.e., power lines) to meet these requirements. In [16] theauthors give an overview of DLC+VIT4IP (Distribution LineCarrier: Verification, Integration and Test of PLC Technologiesand IP Communication for Utilities), a EU funded projectunder the 7th Framework Programme (FP7) that aims toextend the existing PLC technologies by developing efficienttransport of IPv6 protocol, automatic measurement, configu-ration and management, and security. In addition, the projectDLC+VIT4IP also exploits frequency ranges up to 500 kHz,to support systems serving larger smart grid applications.B. Distributed Energy ResourcesThe legacy power generation and transmission concept isconverting to a massively distributed energy generation land-scape integrating an extensive number of variable and smallrenewable energy resources (DERs) such as wind [17]\u2013[19],solar [20]\u2013[22] installations with all their challenging effectson the smart grid.MetaPV [23] is a project demonstrated theprovision of electrical benefits from photovoltaics (PV) on alarge scale, showing the way toward cities powered by renew-able energy sources. The project also demonstrates enhancedcontrol capacities implemented into PV inverters, includingactive voltage control, low-voltage ride-through capability,autonomous grid operation, and interaction of distributionsystem control with PV systems. Smart control should enablean increase of the PV penetration in existing power grids andpromote the use of more renewable energy sources in citiesand industries at minimum additional investment costs. TheMetaPV project is funded by the European Commission inthe 7th Framework Programme, which consists of six partnersfrom four EU countries.New stakeholders (e.g. energy resource aggregators), moreflexibility for the consumers (energy market place), and totallynew concepts (loading of Electric Vehicles (EVs), usage ofEVs as flexible power storage) have to be respected. Innovativemonitoring and control concepts are required to operate thesedistributed energy resources in a reliable and safe way, so thecommunication technologies must support it. A key require-ment for facilitating the distributed production of future gridsis that communication and information are standardized toensure interoperability. For example, the IEC 61850 standard,which was originally aimed at substation automation, has beenexpanded to cover the monitoring and control of DERs. Byhaving a consistent and well-defined data model the standardenables a DER aggregator, such as a Virtual Power Plant(VPP), in communicating with a broad array of DERs. Ifthe data model of IEC 61850 is combined with a set ofcontemporary web protocols, it can result in a major shiftin how DERs can be accessed and coordinated. [24] describeshow IEC 61850 can benefit from the REpresentational StateTransfer (REST) service concept and how a server using thesetechnologies can be used to interface with DERs as diverse asEVs and micro Combined Heat and Power (\u00b5CHP) units.There are some works (e.g., [25]\u2013[27]) in integrating DERgeneration into the traditional centralized carbon fuel basedgeneration power grid. These energy sources include biomassetc. A key observation made in [25] is that existing powergrids were designed in a one-direction radial mode withoutconsidering the communication with the emerging distributedrenewable resource generation. In [26] it discussed the broaderimplications of the social acceptance of these new energy gen-eration technologies, as they represent a significant departurefrom incumbent approach of traditional monolithic large scaleenergy generation. In addition, the implications of regulatoryand economic factors also contribute to potential take-up andvarious deployment models to increase the adoption of thesedistributed renewable resource generators [27].Every DER includes an Electronic Power Processor (EPP)to govern the power exchange with the smart grid andSwitching Power Interface (SPI) to control the currents drawnfrom the smart grid. Such distributed EPPs and SPIs shouldperform cooperatively to take full advantage of smart gridpotentiality (exploitation of renewable energy sources, powerquality and transmission efficiency). To achieve this goal dif-ferent approaches can be adopted, depending on the availablecommunication capability. In [28] it discussed various controlsolutions applicable in absence of supervisory control, e.g.,in residential micro-grids, where communication is possiblebetween neighbor units only (surround control) or is notavailable at all (plug & play control). In micro-grids, wherenumber and type of DERs and loads is unpredictable and mayvary during time, cooperative operation can be achieved bysimple cross-communication among neighbor EPPs, withoutcentralized supervisor. In [29], it describes principles of co-operative operations with existing information and communi-cation architectures, which allows exploitation of micro-gridcapabilities without additional infrastructure investments.C. Smart MeteringThe Advanced Metering Infrastructure (AMI) is a key factorin the smart grid which is the architecture for automated,two-way communications between a smart utility meter and autility company. A smart meter is an advanced meter whichidentifies power consumption in much more detail than a con-ventional meter and communicates the collected informationback to the utility for load monitoring and billing purposes.Consumers can be informed of how much power they areusing so that they could control their power consumptionand the consequent carbon dioxide emission. By managingthe peak load through consumer participation, the utility willlikely provide electricity at lower and even rates for all.AMI has already gained great attraction within the industry,with the advantages in accuracy and process improvement ofon-line meter reading and control. In [30], additional benefitsare suggested to be gained in managing power quality andasset management with AMI. This paper also discussed howreliability, operational efficiency, and customer satisfaction canbe addressed with an AMI deployment. However, the benefitsof AMI are countered by increasing cyber security issues [31].The technologies require a communication infrastructure toprovide interconnectivity. Hence, the vulnerabilities that ex-pose other internetworking systems will ultimately lead tosecurity threats to AMI systems.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.4 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIOND. Monitoring and ControllingSCADA systems have been implemented to monitor andcontrol electrical power grids for decades. The industrialexperience shows that practical deployment of SCADA basedsystems may restrict it to the high voltage transmission net-works only. In [32] the authors made the observation thatexisting monitoring and control systems are restricted to the(high-voltage) transmission network and not suitable for largerscale monitoring and control of the entire electrical grid. Adistributed monitoring control system is proposed to managethe power grid. A grid computing solution is proposed toaddress these monitoring control needs and the results of theresearch for an off-line test environment is discussed. Thekey motivations also include the need to support sustainableand renewable energy source at the micro-generation level. AsSCADA systems evolve, there is much interest in exploringthe security vulnerabilities posed to these systems over com-munication network and/or internet technologies [33]\u2013[35].In [36], the solution applies existing Information andCommunication Technology (ICT) systems in a hierarchi-cal decomposition of the power grid into logical zones formonitoring and control. It outlines the impact to the controlcenter responsible for management and control of the electricalnetwork. It also proposes a framework for future control centerin order to monitor and manage the smart grid. The EUFP6 project ADINE [37] is based on the Active NetworkManagement (ANM) concept, where automation, ICT andpower electronics are used to integrate more distributed gener-ators by exploiting active resources instead of just reinforcingthe network. The resources are mobilized through ancillaryservices or requirements. Five enabling solutions within ANMare pushed forward in the project: Protection relay and faultlocation applications, coordinated protection planning, voltagecontrol with microturbine, centralized voltage control withSCADA/DMS.The rest of this paper is organized as follows: the keymotivations of smart grid communication infrastructures arediscussed in section II. Several industrial trials are shown insection III. The detailed requirements are presented in sectionIV. The challenges are discussed in section V. Conclusions aredrawn in section VI.II. MOTIVATIONSIn this section, we briefly highlight the key motivationsof communication infrastructures in smart grid systems. Asillustrated in Figure 2, the motivations are related to system,operation and environment aspects in emerging smart gridparadigm through communication infrastructures [38].A. Enhanced Customer ExperienceA key objective for communication infrastructures in smartgrid systems is to improve service reliability and quality tocustomers which includes reduced outage times when a powersystem is interrupted, improved notification of electricity net-work problems and providing customers with proper optionsand tools to understand and optimize their energy usage tocurtail the peak-hour usage to avoid power quality degradationor blackout [39].EnvironmentSystemOperationEnhanced Customer ExperienceIncreased ProductivityImproved UtilizationLower Carbon Fuel Consumption/Greenhouse Gas EmissionFacilitated Renewable Resource GenerationAdherence to Regulatory ConstraintsCommunication InfrastructureFig. 2. Motivations of Smart Grid Communication Infrastructures [38]B. Increased ProductivityIntelligent performance information and tools will allowutilities to undertake their current duties in a more efficientmanner, with longer term benefits coming from automatingthe smart grid. These gains in productivity will help to reducedeployment costs and operational costs in managing the smartgrid system [40].C. Improved UtilizationThe communication infrastructure in smart grid will pro-vide detailed real-time data on distributed energy generation,electricity transmission, power consumption and market price.This information allows the utility operators to improve theirdecision making processes by identifying which componentsare likely to fail and the replacement strategy online [41].D. Lower Carbon Fuel Consumption/Greenhouse Gas Emis-sionA smart grid has the potential to reduce electricity lossesin the network and limit growth in demand, due to embeddedmonitoring of the high, medium and low voltage networksthrough communication infrastructures, therefore, lower car-bon fuel consumption and greenhouse gas emission [42].E. Facilitated Renewable Resource GenerationA smart grid will enable options for renewable generationand provide customers with the awareness and capabilities toreduce their energy consumption on carbon fuel based power[43].F. Adherence to Regulatory ConstraintsNew regulatory demands include provisions for increasedlevels of asset data tracking (cost justification), and greaterreliability targeting the implementation of communicationinfrastructure in smart grid [44].This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 5Fig. 3. Energy Web Infrastructure [45]III. CASE STUDIESThe industry has recently undergone a significant trans-formation of their ICT systems to support both current andfuture business models of smart grid operations. Moreover,the power industry is transforming from the traditional modelsof business to embrace a number of new and enhancedtechnologies that support future smart grid operations. Thissection summaries several smart grid industry projects whichinclude energy web infrastructure for power generation andelectricity market information exchange, smart metering in-frastructure which support monitoring and retrieving bothreal-time and historical data, smart community for real-timepower consumption monitoring and managing, ZigBee-basedrecording system with capability for consumers to view andmanage their power consumption online, and future controlcenter for power generation and distribution managing anddeciding between utilities through public networks such asinternet.A. Energy WebThe increasing electricity demand and sustainable devel-opment of renewable energy resources offer opportunitiesfor both utilities, brokers, customers to participate into thedevelopment of the emerging energy web. The basic idea ofenergy web is to use the Internet to gain bandwidth, reliabilityand interconnection for the smart grid. It realizes the on-demand and demand response in local area by establishingthe balance of power generation and consumption.In Figure 3, each power generator is interconnected withan adapted power supplier which has the proper capability ofinterpreting the real-time price signal received from the energyweb infrastructure [45]. In order to match the consumption andgeneration, the participant strategy is adapted. In the powermarket model, each electricity user has option to become apower generator. The electricity price is generated real-timeand sent to every participants by utility operators using thesmart grid communication infrastructure from the electricitymarket. The electricity flows generated by the participantsare monitored in real-time mode by utility operators whoalso operate the real-time metering infrastructures such asautomatic meter reading (AMR) or AMI for establishingthe energy demand and supply balance. While the historicalrecords of both the power consumption and generation withtheir corresponding price are periodically sent to the relatedoffices of the participants for financial settlement.B. Smart Metering and InfrastructureBC Hydro [46] is launching a smart metering and infras-tructure (SMI) program. A multi-level common and integratedcommunication infrastructure to enable grid modernizationis planned as illustrated in Figure 4. That means the com-munication infrastructure will not only support automatedmeter readings, customer home appliance connections, butalso future distribution automation, substation automation andpossibly mobile workforce management and other advancedapplications which utilities could envision in the life span (20years) of AMI infrastructure. This conforms to the industryvision of integrating communication and IT networks with thepower delivery system, in order to provide system sensing andcontrol capability [47].This long term vision raises several key questions: Howmuch data traffic will flow in the network and how muchbandwidth should be planned for the communication network,especially for the wide area communication network? Howmuch of the legacy communication network for system controlpurposes (e.g., SCADA system) can be leveraged to deliver acost effective solution? These questions are addressed basedThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.6 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONFig. 4. High Level Common Communication Infrastructure Architecture [47]on the expected new applications and with communicationand control technology development and system life cycle costminimization in mind.C. Smart CommunityA smart community trial deploys automated metering de-vices into customer\u2019s household. It may include gas, waterand electricity automated metering. The smart communitytrial provides customers new tools to manage their energyconsumption hence reduce the related carbon footprint.Figure 5 provides an overview of the components. Thetrial involves the deployment to the scale of 1,000 housesthat communicate using WiMax to several IT systems whichmanage the reading of water, gas, and electricity. Customerscan access to an information portal via Home Area Networks(HAN). This may be accessed by an in-house display panelor the software based interfaces via the PDA, smart phone orhome personal computer.The home energy consumption is monitored by those ap-pliances enabled with intelligent chips which may support theremote control of appliances operation from Internet. Supportfor electrical vehicles will also be provided for home. The datagathered from this trial can be made available further to thepublic, universities, and researchers for the energy efficiencyand environmental protection.The detailed data on measurements, events, and faults canbe viewed in an example in [48]. In order to retrieve thehistorical measurement data, the solution will be able todisplay the topology of network at selected historical timepoints. While the high voltage transmission network is usuallyFig. 5. Smart Community: Automated Metering Infrastructure [48]static in terms of its network configuration, the medium andlow voltage networks are considerably more volatile. Hence,such a historical network view will provide further input tothe central control to assist in diagnosing network faults, andwill also assist operators and engineers in the design of thesmart grid communication infrastructure.D. A ZigBee-Based Recording SystemZigBee has been designed as a low-cost and low-power-consumption wireless communication standard by ZigBeeThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 7Fig. 6. System Architecture of a ZigBee-based Smart Meter RecordingSystem [53]Alliance [49]. The ZigBee application profile includes homeautomation, industrial plant monitoring, commercial build-ing automation, automatic meter reading, telecom servicese-commerce, wireless sensor networks, personal and home areanetworks [50]\u2013[52].A smart power-meter and a back-end processing systemare proposed in [53] to be equipped with ZigBee devicesand ZigBee coordinators respectively. With the automaticnetworking characteristic of ZigBee, smart power meter serv-ing as a node apparatus will communicate with the ZigBeecoordinator of rear-end processing system and ZigBee networkcan then be constructed to accomplish the meter-readingfunction. After the ZigBee network was constructed, the rear-end processing system can send the request commands to theZigBee coordinators and receive the power consumption dataand outage event data from the power meters. Therefore, theautomatic meter reading can be accomplished. The conceptof the proposed outage recording system is illustrated inFigure 6 while an example of real-time data acquisition isshown in [53].E. Future Control CenterIn [54], the authors proposed a vision to design and developthe next-generation monitoring, analysis, and control technolo-gies to move the industry towards a smarter transmission grid.As shown in Figure 7, the vision for future control centers,also referred to as smart control centers, can be a critical partof the overall framework of the future smart grid. This visionhas five key characteristics as discussed in the following.1) Human-Centered Online Monitoring: Human-centeredis the key characteristic of the next-generation monitoringfunctions in the future smart control centers. In this context,human-centered has two meanings: information-directed andcustomized. The next generation monitoring functions shallprovide operators useful information rather than raw data.With more and more deployment of monitoring devices (e.g.,equipment health sensors), it now has more data available tohelp system operators monitor the power system conditionin real time. However, more data does not necessarily meanmore information. We need to transform the huge volume ofdata into useful information. It is the operators responsibilityto define what information is needed. Since the informationis presented to system operators who are human beings,the monitoring functions shall employ advanced visualizationtechniques with the goal of helping each operator to digestinformation quickly.2) Comprehensive Online Analysis: The next-generationonline analysis functions shall help system operators deter-mine comprehensive operating boundaries in real time. Com-prehensive operating boundaries include both thermal limitsand stability (voltage stability and transient stability) limits.The next-generation online analysis functions shall ap-ply a comprehensive approach to help system operators de-termine the operating boundaries. Comprehensive approachmeans combination of a simulation-based approach and ameasurement-based approach.3) From Reactive Analysis to Proactive Analysis: Thepresent online analysis is based on the current operatingcondition. This does not consider future system conditions.In the future, online analysis shall take a proactive approachto perform look-ahead simulation on the future system condi-tions.The integration of renewable energy sources will introducemore uncertainties into the power system. With the abilityto foresee potential problems, the next-generation proactiveonline analysis will optimize resources (such as demandresponse and energy storage) in order to improve reliabilityand achieve economic operation.By enabling sufficient foresight, the next-generation anal-ysis functions allow system operators to take a proactiveapproach to develop optimal control strategies and mitigationplans.4) From Isolated Protection and Control Strategy to Coor-dinated Protection and Control Strategy: Traditionally, eachcontrol scheme is designed to solve a particular problem.The parameters were developed based on offline simulationsand largely remain fixed. There is a lack of coordinationamong protection and control systems. As modern powersystems have become more interconnected with increasingstress levels, each disturbance may cause multiple protectionand control schemes to respond. There may exist negativeinteractions that can worsen system conditions, which presentchallenges and risks in system operations.When a power system experiences a disturbance, the nextgeneration coordinated protection and control systems willperform according to the optimal control strategies developedby online security assessment and shall quickly bring thesystem to a stable operating condition with minimum controlefforts.5) Self-Healing System Control: The current restorationplans are developed through offline studies based on as-sumptions regarding likely scenarios. However, the restorationstrategy developed from such studies may not work wellThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.8 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONFig. 7. Scopes of Future Control Center [54]following a blackout because the real operational situation mayvary from the assumed scenarios.When part or all of the power system is blacked out, thenext generation self-healing control scheme shall effectivelyrestore the system and bring it back to a normal operatingcondition.IV. REQUIREMENTSMonitoring/sensing, communication and control are thethree fundamental building blocks that will convert a powerdistribution system into a smart grid. Monitoring/sensing willhave the ability to detect malfunctions or deviations fromnormal operational ranges that would warrant actions. Further,since in a smart grid, a point of electricity consumption canalso become a point of generation, the sensing process willbe closely linked with the metering process. Communicationswill allow inputs from sensors to be conveyed to the control el-ements in the smart grid which will generate control messagesfor transmission to various points in the smart grid resultingin appropriate actions. The communication infrastructure hasto be robust enough to accept inputs from a user and make itan integral part of the process. By the same token, the usermust be capable of getting the appropriate level of informationfrom the smart grid. The major requirements for smart gridcommunication infrastructures are discussed in the rest of thissection.A. QoSIn order to realize a practical smart grid communicationinfrastructure, it is necessary to have guaranteed Quality ofService (QoS) for the communication and networking tech-nology used in the smart grid, ranging from power generation,transmission, distribution, to the customer applications.1) Latency: The real-time operational data communicationsin smart grid include online sensor/meter reading and powersystem control signals. The communication is characterizedby the fact that most of interactions must take place in realtime, with hard time bound. The communication require-ments define the design of the technical solutions. For real-time sensing/metering purposes, reading messages should betransmitted within a very short time frame. For instance, themaximum allowed time is in the range of 12-20 ms, dependingon the type of protection scheme which origins from thefact that the disconnection of fault current should withinapproximately 100 ms. Power System Control signals mainlyinclude supervisory control of the power process on secondaryor higher levels. These systems are of the kind SCADA/EMS.Measured values must not be older than 15 seconds, whenarriving at the control center. Breaking information shallarrive no later than 2 seconds after the emergency event hasoccurred [55].2) Bandwidth: As more and more interconnected intelli-gent elements are added to the electricity network with theevolution of the smart grid, the communication infrastruc-ture should be able to transport more and more messagessimultaneously without severe effect on latency. The networkbandwidth must increase faster than the demand of theseinterconnected intelligent elements in the network.C. H. Hauser et al. concluded in [56] that a 10 millisecondaverage latency for a 400 bit message using a T1 line willresult in a utilization of only 6% of the T1 bandwidth. In [55]the authors modeled the communication bandwidth require-ments for a moderate size electricity distribution system. Inthis model, a distribution substation is connected to 10,000feeders and each feeder connects to 10 customers. Assumingthat every electric meter generates a message every secondto the distribution substation, the total is 100,000 messagesper second. The feeders themselves will generate messagesto each other and to the distribution substation. The authorsin [55] modeled the messages in the smart grid arriving atservers located at the control center as M/M/1 traffic. Then,the transmission line bandwidth is evaluated over 100 Mbpsthrough the M/M/1 queuing model. It can be observed that thissituation results in a very poor bandwidth utilization of thetransmission facilities as well. Unfortunately, a higher levelof utilization will not permit meeting the assumed latencyconstraint.B. InteroperabilityInteroperability of a smart grid is the ability of diversesystems to work together, use the compatible parts, exchangeinformation or equipment from each other, and work coop-eratively to perform tasks. It enables integration, effectivecooperation, and two-way communications among the manyinterconnected elements of the smart grid. The National Insti-tute for Standards and Technology (NIST) works as the firstInternational Coordinator for smart grid interoperability [57].NIST developed a framework that includes protocols andstandards for information management to achieve interoper-ability of smart grid devices and systems [58]. NIST hasdeveloped a three phase approach to identify smart grid stan-dards. Phase 1 addresses the engagement of stakeholders ina participatory public process to identify applicable standardsand gaps in currently available standards and priorities for newstandardization activities, ending with the final publication ofthe framework report after public comments have been incor-porated. Phase 2 will establish a private-public partnership andform a smart grid interoperability panel to drive longer-termprogress. Phase 3 will develop and implement a frameworkfor testing and certification of how standards are implementedin smart grid devices, systems, and processes.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 9Fig. 8. NIST Conceptual Model [59]As illustrated in Figure 8, the NIST conceptual referencemodel identifies seven domains as bulk generation, trans-mission, distribution, markets, operations, service providers,and customers and major actors and applications within each.The reference model also identifies interfaces among domainsand actors and applications over which information mustbe exchanged and for which interoperability standards areneeded.For years, the utility industry has been using optical portcommunications, defined by ANSI C12.18, and telephonemodem communications, defined by ANSI C12.21, to getmetering data, defined by ANSI C12.19, from the field tothe back office. While the two communication standards havebeen employed to great success, the missing was a standardmethod for using true network communications for exchangingthe data. Recent work has completed by ANSI C12.22, astandard for interfacing the data communication networks, aswell as updating the optical port and modem communicationstandards. This set of standards offers the industry an open andcomprehensive protocol suite to transport the newly reviseddata standard, ANSI C12.19 [60].C. ScalabilityA smart grid communication infrastructure needs the scala-bility of accommodating more and more devices and servicesinto it and more end-user interaction real-time monitoringof energy meters. As discussed by Lobo et al. [61], anIP-based network will provide an effective solution for thecommunication needs of the smart grid. An IP-based networkas the backbone makes use of new technologies independent ofthe service implemented by the distributed network operator.The cost of deployment and maintenance can be reducedsignificantly using IP-based technologies.D. SecurityAccording to the Electric Power Research Institute (EPRI),one of the emergent requirements facing the smart grid devel-opment is related to cyber security of systems. As indicatedin the EPRI report [62], cyber security is a critical issuedue to the increasing potential of cyber attacks and incidentsagainst this critical sector as it becomes more and moreinterconnected. Cyber security must address not only delib-erate attacks, such as from disgruntled employees, industrialespionage, and terrorists, but also inadvertent compromises ofthe information infrastructure due to user errors, equipmentfailures, and natural disasters. Vulnerabilities might allowan attacker to penetrate a network, gain access to controlsoftware, and alter load conditions to destabilize the grid inunpredictable ways.There are many organizations working on the developmentof smart grid security requirements including North Amer-ican Electrical Reliability Corporation-Critical InfrastructureProtection (NERC-CIP), ISA, IEEE (1402), the National In-frastructure Protection Plan (NIPP), and NIST [63].One prominent source of requirements is the Smart GridInteroperability Panel (SGiP) Cyber Security Working Group,previously NIST Cyber Security Coordination Task Group(CSCTG). NIST CSCTG was established to ensure the con-sistency in the cyber security requirements across all thesmart grid domains and components. The draft document fromthe CSWG, NIST interagency Report (NIST IR) 7628 [64],continues to evolve. NIST and DoE Gridwise ArchitectureCouncil (GWAC) [65] has established Domain Expert WorkingGroups (DEWGs) [66]: Home-to-Grid (H2G), Building-to-Grid (B2G), Industrial-to-Grid (I2G), Transmission and Dis-tribution (T&D) and Business and Policy (B&P). Furthermore,many other standards may apply, including ISO 17799 [67],FIPS 201 [68], other NIST SPs, and DISA Security TechnicalImplementation Guides (STIGs) [69]. Working with standardsbodies, such as NIST and others, will be extremely importantto ensure a highly secure, scalable, consistently deployedsmart grid communication system, as these standards bodieswill drive the security requirements of the smart grid commu-nication systems [70].One thing is consistent among the various standards bodies:the security of the smart grid communications will stronglydepend on authentication, authorization, and privacy technolo-gies. Privacy technologies are well matured. Federal Infor-mation Processing Standard (FIPS) has approved AdvancedEncryption Standard (AES) and Triple Data Encryption Algo-rithm (3DES) solutions, offering strong security and high per-formance, are readily available. The specific privacy solutionsrequired will depend on the type of communication resourcebeing protected. As a specific example, NIST has determinedthat 3DES solution will likely become insecure by the year2030. Considering that utility components are expected to havelong lifetimes, AES would be the preferred solution for newcomponents. However, it is expected the legacy functionalitysuch as 3DES must be supported for system compatibility,therefore there is a risk of compromising the system [71].Wireless links will be secured with technologies from wellknown standards such as 802.11i [72] and 802.16e [73].Different wireless protocols have varying degrees of securitymechanisms. Wired links will be secured with the technologiessuch as firewalls, virtual private networks (VPN) and IPSec.Higher layer security mechanism such as Secure Shell (SSH)and Security Socket Layer (SSL)/Transport Layer Security(TLS) should also be used. System architects and designersoften identify the need for and specify the use of secureprotocols, such as SSH and IPSec, but then skip the detailsassociated with establishing security associations between endpoints of communications. Such an approach is likely to resultin a system where the necessary procedures for secure keymanagement can quickly become an operational nightmare. ItThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.10 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONis due to the fact that, when system architects do not developan integrated and comprehensive key management scheme,customers may be provided with few key management options,and often resort to manually pre-configuring symmetric keys.This approach is simple for the system designers, but it canbe very expensive for the system owner/operator.What has been learned from years of deploying and oper-ating large secure network communication systems is that theefforts required to provision symmetric keys into thousandsof devices can be too expensive or insecure. The developmentof key and trust management schemes for large networkdeployments is required; these systems can be leveraged fromother industries, such as mobile radio systems and Associa-tion of Public-Safety Communications Officials (APCO) radiosystems. Several APCO-deployed systems provide statewidewireless coverage, with tens of thousands of secure de-vices [74]. Trust management systems, based on public-keyinfrastructure (PKI) technology, could be customized specifi-cally for smart grid operators, easing the burden of providingsecurity which adheres to the standards and guidelines that areknown to be secure.All of the above technologies rely on some sort of keymanagement. Considering that the smart grid will containmillions of devices, spread across hundreds of organizations,the key management systems used must be scalable to ex-traordinary levels. Further, key management must offer strongsecurity (authentication and authorization), inter-organizationinteroperability, and the highest possible levels of efficiencyto ensure that unnecessary cost due to overhead, provisioning,and maintenance are minimized. It is likely that new keymanagement systems (specialized to meet the requirementsof smart grid) will be needed.E. StandardizationThe smart grid involves various standards in many fieldssuch as power generation, delivery and control besides com-munications. IEEE has recently taken the initiative to definethese standards and write guidelines on how the smart gridshould operate using the latest technology in power engi-neering, control, communications, and information technology.The standards group that was created is known as the IEEEP2030 group [75]. Three task forces were formed to tackle dis-tribution systems including the integration of different energysources, transmission substations, load side requirements, andcyber security. These task forces will focus on power engineer-ing technology, information technology, and communicationtechnology. The power engineering technology group willwork on the functional requirements of interoperability, draw-ing on various existing and ongoing efforts by groups such asInternational Society of Automation (ISA) and InternationalElectrotechnical Commission (IEC). IEC TC57 WG13 [76]is currently drafting the new international standards for usein improving overall transmission grid reliability and security.This work directly supports the NIST smart grid interoperabil-ity.The information technology group will look at the issuesof privacy, security, data integrity, interfaces, and interoper-ability. The communication technology group will define thecommunication requirements between devices in the smartgrid and establish boundaries for generation, transmission, anddistribution in conjunction with the customers [77].Implementing standards is a major issue in transitioningtowards advanced sensing/automation, and also is a crucialstep in creating smart grid communication infrastructure. Ascommunication systems in smart grid are usually from differ-ent vendors with their own legacies, which are proprietaryand have no dual interoperability. The identified standardswhich govern the necessary integration of different functionsare specified by IEC.V. CHALLENGESThe proliferation of wireless/wired sensors and communi-cation devices and the emergence of embedded computingrepresents an opportunity to develop applications for con-nected environments in general, and especially managementsystems that address urgent challenges facing the smart gridcommunication infrastructure. The challenges include the de-ployment of large-scale embedded computing, legacy powergrids, intelligent appliances, and next-generation communi-cations and collaborations that will provide the foundationfor a post-carbon society. In this section, we discuss thecontext that gives these challenges urgency as well as thetechnical challenges that need to be addressed by smart gridcommunication infrastructures.A. ComplexityA smart grid communication infrastructure is a systemof systems and it is extremely complex. As a consequence,modeling, analysis and design a suitable communication in-frastructure meet many new challenges. The models to beused must be capable of accounting for uncertainty as away to simulate emerging behavior. The numerical tools toperform the analysis must be capable of solving very largescale problems. In fact, the power system is tightly coupledand non-linear [78] and does not benefit from the sparsity thattypically characterized this problem. The control system andparticularly communication infrastructure must be designedto manage uncertainty and inconsistencies to be resilient orgracefully degrade when necessary. Finally the performancemetric must be adjusted to the new nature of the powersystem. The challenges in modeling the complexity of asmart grid communication infrastructure are summarized inthe following.1) Need to support multi-physics approach: Systems are sotightly interconnected that is not possible to simply simulatethe electrical subsystem [79]2) Need to support multidisciplinary approach: Differentusers will have to work at the same scenario, each of themfocusing on different aspects (control, power flow, communi-cations) [80], [81].3) Need to support dynamic and reconfigurable model leveldefinition: This is probably the most challenging element.While different users interact with the simulation schematicthey need to focus on different details of the system. Thenext generation simulation system should support this processautomatically [82], [83].This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 114) Need to provide high-level graphic visualization to sup-port system: While engineers may want to focus on thedetails of graphs, system analysis requires different types ofvisualization able to synthesize a \u201csystem-picture\u201d [84].5) Need to provide support for uncertainty propagation:Uncertainty is presented in the power system for differentreasons and from various sources. And therefore it is to beaccounted for in the design and in the operation, as it will bedependent on static and dynamic state estimation [85].B. EfficiencyRealization of the future smart grid requires meeting theever increasing efficiency challenges by harnessing moderncommunication and information technologies to enable acommunication infrastructure that provides grid-wide coor-dinated monitoring and control capabilities. Such commu-nication infrastructure should be capable of providing failproof and nearly instantaneous bidirectional communicationsamong all devices ranging from individual loads to the grid-wide control centers including all important equipment at theelectricity distribution and transmission system. This involvesprocessing vast number of data transactions for analysis andautomation. It requires a high performance communicationinfrastructure capable of providing fast intelligent local sub-second responses coordinated with a higher level global anal-ysis in order to prevent or contain rapidly evolving adverseevents [86]. It needs to meet the challenges in the following.1) Better Telemetry: Phasor Measurement Unit (PMU)technology [87] can offer faster, time-stamped, higher ac-curacy and sub-second scanning to enable timely grid-widesituational awareness [87].2) Faster Controls: Based on power electronics, smart gridcommunication infrastructure enables fast automated controlactions, for voltage and power flow management at electricitygeneration, transmission and distribution systems.3) More Robust Controls: Proactive and adaptive adjust-ment of protection and communication settings for wide areamonitoring and controls support intentional islanding, whichis beyond currently employed ad-hoc schemes in systemprotection.4) Embedded Intelligent Device Communications: To en-able adaptive and intelligent communications for device levelfault diagnosis and bad data identification, operations and theconstraints should be prescribed by system operators or controlcenters, intelligent remedial action scheme (RAS)/system pro-tection schemes (SPS), autonomous restoration of equipmentand autonomous local control actions [88].5) Integrated and Secure Communications: Highly dis-tributed and pervasive communications based on open stan-dards allow flexible network configurability to assure fail-proof monitoring and automation for bidirectional communi-cations between all operators and customers.6) Enhanced Computing Capabilities: Fail-proof and se-cure communication systems for reliable analysis supportoperator decisions and autonomous intelligent agents a geo-graphically and temporally coordinated hierarchy through thegrid-wide communication infrastructure [89].7) Internet Technology: Internet protocols to facilitate dataexchange, process control and cyber security implement adistributed architecture with open interfaces. Plug-and-playhardware and software components in a service oriented archi-tecture is based on communication standards and technologiessuch as message oriented middleware and web services toenable seamless integration of the IT infrastructure rangingfrom lowest equipment level Intelligent Electronic Devices(IEDs) to all higher application levels [90].C. ReliabilityA framework for cohesive integration of reliability tech-nologies facilitate convergence of the needed standards andprotocols, and implementation of necessary analytical capabil-ities. This subsection reviews the impact of a communicationinfrastructure to the reliability of a smart grid. An ideal mixof the current communication and control techniques are ex-pected to lead a flatter net demand that eventually accentuatesmany reliability issues further. A grid-wide communicationarchitectural framework to meet these reliability challengesare discussed in the following [91].1) Renewable Resources: Renewable resources generallyhave adverse challenges on smart grid reliability due to thefollowing factors: variability and low capacity, factors makingthe net demand profile steeper, low correlation with the loadprofile especially in the case of wind resource, relativelyhigh forecast errors especially for longer horizons, congestionissues at transmission level due to large installations andat distribution level due to dispersed resources. Operationalperformance issues such as voltage and regulation.To address the variability of the net demand, as renewableresources growing over the long run, efficient communica-tion infrastructure for information exchange among demandresponse, storage devices and utilization of plug-in electricvehicles (PEVs)/plug-in hybrid electric vehicles (PHEV) willcomplement the remedies [92].2) Demand Response: Demand response allows consumerload reduction in response to emergency and high price con-ditions on the smart grid. Such conditions are more prevalentduring peak load or congested operation as illustrated inFigure 9 [93]. Non-emergency demand response in the rangeof 5% to 15% of system peak load can provide substantialbenefits in reducing the need for additional resources andlowering real-time electricity prices [2]. Demand responsedoes not substantially change the total energy consumptionsince a large fraction of the energy saved during the loadcurtailment period is consumed at a more opportune time -thus a flatter load.3) Load Management: Load rejection as an emergencyresource to protect the smart grid from disruption is wellunderstood and is implemented to operate either by systemoperator command or through under-frequency and/or under-voltage relays. In a smart grid, the load rejection schemes canbe enhanced to act more intelligently and based on customerparticipation.Price based demand response/load management as a systemresource to balance demand and supply has not been widelyadopted yet. Contract based participation has been typicallyThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.12 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONMarket/OperatorUtility/AggregatorConsumer 1 Consumer n...Active NegotiationDemand Reduction SignalBiding messageFig. 9. Communications for Demand Response [93]below 5% of peak load [94]. In a smart grid, real-timeprice information enables wider voluntary participation byconsumers. Demand response can be implemented througheither automatic or manual response to price signals, orthrough a bidding process based on direct communicationsbetween the consumers and the market/system operators orthrough intermediaries such as aggregators or local utilities.4) Storage Devices: Most of the existing storage resourcesare hydro and pumped storage. However, growth potential forthese resources is much smaller than the need for storagenecessary to counter growing net demand variability presentedby new wind and solar resources. Various storage technologiesare emerging to fill the gap. Battery storage appears to bemost promising due to improvements in technology as well aseconomies of scale.Storage resources tend to make the net demand profile flatterand, as such, are expected to improve reliability. In addition,most battery storage devices can respond in time scales ofseconds. Hence they can become valuable enablers of fastcontrols in a smart grid. Storage resources of various sizescan be distributed throughout the grid ranging from end userloads to major substations and central power stations. Thisfeature can help to alleviate congestion at both transmissionand distribution levels [95].5) Electric Transportation: Plug-in electric vehicles (PEV,PHEV, etc.) continue to become more popular as environmen-tal concerns increase. They are a significant means to reducegreen house gases and reliance on fossil fuels. They will be asignificant factor in load growth with a potential to eventuallyconsume 600 TWh/year assuming 30 kwh for a 100-miletrip [96], and 10,000 miles per year for 200 million vehiclesin the U.S. For greater adoption of all-electric vehicles, theissue of recharge time has to be resolved. Long recharge timeslead to generally unacceptable level of vehicle unavailabilityand short recharge times have potential to increase congestion,especially at the distribution levels [97].From reliability viewpoint, electric transportation has fea-tures similar to both demand response resources and storageresources. As PHEVs present a significant factor of loadgrowth, this can also aggravate the demand variability andassociated reliability problems depending on the chargingschemes and consumer behavioral patterns.D. SecurityBased on the evolution of power system communicationinfrastructures and the concern of cyber security, many newissues have arisen in the context of smart grid.Fig. 10. Information Security Domains [99]1) Information Security Domains: Since the SCADA/EMSsystems have become increasingly integrated, it becomes moredifficult to treat the system structure in terms of parts orsubsystems. The physical realization of various functions isless evident from a user perspective. Instead, it becomes morenatural to study a SCADA/EMS system in terms of domains.This concept in application to power systems was introducedin [98].A domain is a specific area, wherein specific activ-ities/business operations are going on and they can begrouped together. The security domains are introduced inFigure 10 [99].When communicating across power utilities, different or-ganizations and companies, using communication networks,the security domains should be recognized. For example, apower utility company could define a security domain andrelated policies and procedures for its telecontrol activity toassure compliance with legislative or regulatory requirements.If similar definitions, procedures, policies, etc. were developedby other power utility companies, it would be easier to discussand define common rules for the information exchange or theusage of common resources in a communication infrastructure.However today, there are no common definitions including theterm security. Also, there are no common control system secu-rity policies or procedures, although groups such as IEC [100],ISA [101], and NIST [102], [103], are working on genericpolicies and procedures.2) Government Coordination on SCADA Security: A gov-ernment coordination action between different authorities andagencies were started in [104], focusing on SCADA secu-rity. The action is based on the participation of the powerutilities, water companies, and railway systems, which haveSCADA systems as the critical part of operations. Also,the security policies are represented. Here, the expertise isgathered and experiences are shared, including both domesticand international knowledge; everything with the purposeof securing the SCADA systems being part of the criticalinformation infrastructures. As a natural step, the SCADA Se-curity Guideline has been developed in [105]. Also, technicalguidelines and administrative recommendations are developedwhich are available for free downloading, that support thesecuring actions of the SCADA systems in the different areasof operations: power, water, and transportation.3) De-Coupling Between Operational SCADA/EMS andAdmin IT: When the existing SCADA/EMS systems are beingThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 13Fig. 11. Vulnerable Access Points to SCADA System [99]refurbished or replaced, the information and IT security issuesmust be taken into account. If a SCADA/EMS system is to berefurbished, the operational SCADA/EMS system part must beshielded from the administrative part, such that the operationalpart is protected from digital threats that are possible overthe Internet connection. If a SCADA/EMS system is to bereplaced, it is then a good occasion to reconsider an overallsystem structure, and then incorporate IT security on allSCADA/EMS levels. A way towards this more secure state isto, if possible, de-couple the operational SCADA/EMS systemand the administrative IT system. Also, an alternative may beto secure the firewall configuration in between operational andadministrative parts.4) Threats: The fact that SCADA/EMS systems are nowbeing interconnected and integrated with external systemscreates new possibilities and threats in cyber security. Someof these new issues have been emphasized in [98] and [106].The various interconnections of a substation were investigatedin [107], as shown in Figure 11. All the numbered accesspoints (1-10) elucidates the possible points where to thesubstation can be accessed. This number creates an operationalenvironment that implies possible digital entrances and hencedigital vulnerabilities at the same time.5) Vulnerability: As presented in [108], using a wirelesssensor network (WSN) in AMI in a smart grid is so vulnerableto be attacked by an intelligent adversary even with anordinary microwave stove. Brodsky et al. [109] documenteda denial-of-service attack on IEEE 802.15.4 wireless sensornetworks used within the smart grid. The equipment neededfor such an attack is inexpensive (about $70).6) Privacy: The privacy of terminal customers and smartmetering networks is important to the eventual acceptance bythe public. Research in this area is going on and smart meterusers will need to be reassured that their data is secure. In[110] the authors describe a method for securely anonymizingfrequent (e.g., every few minutes) electrical metering datasent by a smart meter. Although such frequent metering datamay be required by a utility or electrical energy distributionnetwork for operational reasons, this data may not necessarilyneed to be attributable to a specific smart meter or consumer.However, it needs to be securely attributable to a specificlocation (e.g. a group of houses or apartments) within thesmart grid.VI. CONCLUSIONIn this paper, we presented the background and motivationfor smart grid communication infrastructures. We showed thata smart grid built on the technologies of sensing, communica-tions, and control technologies offer a very promising futurefor utilities and users. We reviewed several industrial trialsand summarized the basic requirements of communicationinfrastructures in smart grid paradigm. Efficiency, reliabilityand security of interconnected devices and systems are criticalto enabling smart grid communication infrastructures. Interop-erability must be achieved while avoiding being isolated intononcompetitive technical solutions and the need for wholesalereplace of existing power communication systems. Alignmentbehind technical standards must be balanced with creating anenvironment that encourages innovation so that the overallcommunication infrastructure may continue to evolve. Basedon the above survey, we can focus on those challenges to smartgrid communication infrastructures in both system design andoperations to make it more efficient and secure.REFERENCES[1] U.S. Department of Energy, [online] Available: www.oe.energy.gov.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.14 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION[2] F. Rahimi and A. Ipakchi, \u201cDemand Response as a Market ResourceUnder the Smart Grid Paradigm,\u201d IEEE Trans. Smart Grid, vol.1, no.1,pp.82-88, June 2010.[3] U.S. Department of Energy, National Energy Technology Laboratory,\u201cA vision for the modern Grid,\u201d March 2007.[4] R. Yu, Y. Zhang, S. Gjessing, C. Yuen, S. Xie, M. Guizani, \u201cCognitiveradio based hierarchical communications infrastructure for smart grid,\u201dIEEE Network, vol.25, no.5, pp.6-14, September-October 2011.[5] S. Massoud Amin and B. F. Wollenberg, \u201cToward a smart grid: powerdelivery for the 21st century,\u201d IEEE Power and Energy Mag., vol. 3,pp. 34-41, 2005.[6] A. Vaccaro and D. Villacci, \u201cPerformance analysis of low earth orbitsatellites for power system communication,\u201d Electric Power SystemsResearch, vol. 73, pp. 287-294, 2005.[7] IEC-TC 57, \u201cCommunication networks and systems in substations- Part1: Introduction and overview,\u201d IEC Standard IEC/TR 61850-1, Edition1.0, 2003.[8] J. G. Cupp and M. E. Beehler, \u201cImplementing Smart Grid Communi-cations\u201d TECHBriefs 2008 No. 4, pp. 5-8.[9] A. Ghassemi, S. Bavarian, and L. Lampe, \u201cCognitive Radio for SmartGrid Communications,\u201d in First IEEE International Conference onSmart Grid Communications (SmartGridComm 2010), pp. 297-302,2010.[10] K. Jeonggil, A. Terzis, S. Dawson-Haggerty, D. E. Culler, J. W.Hui, and P. Levis, \u201cConnecting low-power and lossy networks to theinternet,\u201d IEEE Commun. Mag., vol. 49, pp. 96-101, 2011.[11] V. Madani, A. Vaccaro, D. Villacci and R. L. King, \u201cSatellite BasedCommunication Network for Large Scale Power System,\u201d 2007 iREPSymposium - Bulk Power System Dynamics and Control - VII,Revitalizing Operational Reliability, August 19-24, 2007, Charleston,SC, USA.[12] D. Dzung, I. Berganza, and A. Sendin, \u201cEvolution of powerline com-munications for smart distribution: From ripple control to OFDM,\u201d in2011 IEEE International Symposium on Power Line Communicationsand Its Applications (ISPLC 2011), pp. 474-478.[13] M. Y. Zhai, \u201cTransmission Characteristics of Low-Voltage DistributionNetworks in China Under the Smart Grids Environment,\u201d IEEE Trans.Power Del., vol. 26, pp. 173-180, 2011.[14] N. Ginot, M. A. Mannah, C. Batard, and M. Machmoum, \u201cApplicationof Power Line Communication for Data Transmission Over PWMNetwork,\u201d IEEE Trans. Smart Grid, vol. 1, pp. 178-185, 2010.[15] G. Bumiller, L. Lampe, and H. Hrasnica, \u201cPower line communicationnetworks for large-scale control and automation systems,\u201d IEEE Com-mun. Mag., vol. 48, pp. 106-113, 2010.[16] A. Haidine, B. Adebisi, A. Treytl, H. Pille, B. Honary, and A. Portnoy,\u201cHigh-speed narrowband PLC in Smart Grid landscape - State-of-the-art,\u201d in IEEE International Symposium on Power Line Communicationsand Its Applications (ISPLC 2011), pp. 468-473, 2011.[17] U.S. Department of Energy, Energy Efficiency and Renewable Energy,\u201cAnnual Report on US Wind Power Installation, Cost and PerformanceTrends: 2007,\u201d May 2008.[18] I. Marti, \u201cEvaluation of Advanced Wind Power Forecasting Models,\u201dEuropean Wind Energy Conference, Athens, Feb 27- Mar 2, 2006.[19] The New York State Energy Research and Development Authority,\u201cThe Effects of Integrating Wind Power on Transmission SystemPlanning, Reliability and Operations, Report on Phase 2: SystemPerformance Evaluation,\u201d Albany, NY, March 4, 2005.[20] \u201cWaiting for the sunrise (solar energy forecast) (Science and Technol-ogy),\u201d The Economist , May 19, 1990.[21] U.S. DoE Solar Energy Technologies Program, \u201cSolar Energy IndustryForecast: Perspectives on U.S. Solar Market Trajectory\u201d, May 30, 2008.[22] National Renewable Energy Laboratory, \u201cExecutive Summary: Assess-ment of Parabolic Trough and Power Tower Solar Technology Cost andPerformance Forecasts,\u201d October 2003.[23] T. Van Loon, T. Vu Van, A. Woyte, F. Truyens, B. Bletterie, J. Reekers,B. Blazic, and R. Engelen, \u201cIncreasing photovoltaics grid penetrationin urban areas through active distribution systems: First large scaledemonstration,\u201d in Third International Conference on InfrastructureSystems and Services: Next Generation Infrastructure Systems for Eco-Cities (INFRA 2010), pp. 1-4, 2010.[24] A. B. Pedersen, E. B. Hauksson, P. B. Andersen, B. Poulsen, C.Tr\u00e6holt, and D. Gantenbein, \u201cFacilitating a Generic CommunicationInterface to Distributed Energy Resources: Mapping IEC 61850 toRESTful Services,\u201d First IEEE International Conference onSmart GridCommunications (SmartGridComm 2010), pp. 61-66, 2010.[25] D. Infield and F. Li, \u201cIntegrating micro-generation into distributionsystems: a review of recent research,\u201d in Proc. IEEE Power and EnergySociety General Meeting - Conversion and Delivery of ElectricalEnergy in the 21st Century, July 2008.[26] R. Sauter and J. Watson, \u201cStrategies for the deployment of micro-generation: Implications for social acceptance\u201d, Elsevier, Energy Pol-icy, Vol. 35, Iss.5, pp.2770-2779, May 2007.[27] J. Watson, R. Sauter, B. Bahaj, P. James, L. Myers and R. Wing,\u201cDomestic micro-generation: Economic, regulatory and policy issuesfor the UK,\u201d Energy Policy, Vol. 36, Iss. 8, Pages 3095-3106, August2008.[28] P. Tenti, A. Costabeber, and P. Mattavelli, \u201cImproving power qualityand distribution efficiency in micro-grids by cooperative control ofSwitching Power Interfaces,\u201d International Power Electronics Confer-ence (IPEC 2010), pp. 472-479, 2010.[29] A. Costabeber, P. Tenti, and P. Mattavelli, \u201cSurround control ofdistributed energy resources in micro-grids,\u201d IEEE International Con-ference on Sustainable Energy Technologies (ICSET 2010), pp. 1-6,2010.[30] D. Backer, \u201cPower Quality and Asset Management The Other Two-Thirds of AMI Value,\u201d IEEE Rural Electric Power Conference, pp.6-8, May 2007.[31] F. M. Cleveland, \u201cCyber security issues for Advanced Metering In-frastructure (AMI),\u201d Proceedings of IEEE Power and Energy SocietyGeneral Meeting Conversion and Delivery of Electrical Energy in the21st Century, July 2008.[32] G. A. Taylor, M. R. Irving, P. R. Hobson, C. Huang, P. Kyberd,and R. J. Taylor, \u201cDistributed monitoring and control of future powersystems via grid computing,\u201d IEEE Power Engineering Society GeneralMeeting, 2006.[33] E. Chikuni, M. Dondo, \u201cInvestigating the security of electrical powersystems SCADA,\u201d IEEE AFRICON 2007, pp.1-7, Sep 2007.[34] C. Ten, C. Liu, and M. Govindarasu, \u201cCyber-vulnerability of powergrid monitoring and control systems,\u201d In Proceedings of the 4th AnnualWorkshop on Cyber Security and information intelligence Research(CSIIRW \u201908), Oak Ridge, Tennessee, May 12 - 14, 2008.[35] J. D. Fernandez and A. E. Fernandez, \u201cSCADA systems: vulnera-bilities and remediation,\u201d Journal of Computing Sciences in Collegesarchive,Vol. 20, Iss. 4, pp.160-168, April, 2005.[36] Y. Serizawa, et al., \u201cPresent and future ICT infrastructures for a smartergrid in Japan,\u201d in Innovative Smart Grid Technologies (ISGT2010), pp.1-5, 2010 .[37] O. Samuelsson, S. Repo, R. Jessler, J. Aho, M. Karenlampi, andA. Malmquist, \u201cActive distribution network - Demonstration projectADINE,\u201d in IEEE PES Innovative Smart Grid Technologies ConferenceEurope (ISGT Europe 2010), pp. 1-8, 2010.[38] F. Rahimi and A. Ipakchi, \u201cOverview of Demand Response underthe Smart Grid and Market paradigms,\u201d in Innovative Smart GridTechnologies (ISGT 2010), pp. 1-7, 2010.[39] R. Davies, \u201cHydro one\u2019s smart meter initiative paves way for definingthe smart grid of the future,\u201d in Power & Energy Society GeneralMeeting, 2009. (PES \u201909),pp. 1-2, 2009.[40] E. Santacana, et al., \u201cGetting Smart,\u201d Power and Energy Magazine,IEEE, vol. 8, pp. 41-48, 2010[41] D. Sun, \u201cThe Utilization and Development Strategies of Smart Gridand New Energy,\u201d in Proceedings of Asia-Pacific Power and EnergyEngineering Conference (APPEEC 2010), pp. 1-4, 2010.[42] C. Jaeseok, J. Park, M. Shahidehpour and R. Billinton, \u201cAssessment ofCO2 reduction by renewable energy generators,\u201d in Innovative SmartGrid Technologies (ISGT), pp.1-5, 2010.[43] F. A. Rahimi, \u201cChallenges and opportunities associated with high pen-etration of distributed and renewable energy resources,\u201d in InnovativeSmart Grid Technologies (ISGT), 2010, 2010, pp. 1-1.[44] G. Lorenz, \u201cRegulatory framework to incentivise Smart Grids deploy-ment - EURELECTRIC views,\u201d The 20th International Conference andExhibition on Electricity Distribution - Part 2, 2009. (CIRED 2009),pp. 1-26, 2009.[45] D. Tuan, \u201cThe Energy Web: Concept and challenges to overcome tomake large scale renewable and distributed energy resources a truereality,\u201d in 7th IEEE International Conference on Industrial Informatics,pp.384-389, 2009.[46] http://www.bchydro.com/planning regulatory/projects/smart metering infrastructure program.html.[47] W. Luan, D. Sharp, S. Lancashire, \u201cSmart grid communication networkcapacity planning for power utilities,\u201d 2010 IEEE PES Transmissionand Distribution Conference and Exposition, pp.1-4, 19-22 April 2010.[48] A. Clark, C. J. Pavlovski, and J. Fry, \u201cTransformation of energysystems: The control room of the future,\u201d in Proceedings of IEEEElectrical Power & Energy Conference (EPEC), 2009, pp. 1-6.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 15[49] ZigBee Specification, ZigBee Alliance, ZigBee Document 053474r17,January 2008.[50] M. Fang, J. Wan, X. Xu, and G. Wu, \u201cSystem for TemperatureMonitor in Substation with ZigBee Connectivity,\u201d IEEE InternationalConference on Communication Technology, pp. 25-28, Nov. 2008.[51] B. Chen, M. Wu; S. Yao, B. Ni, \u201cZigBee Technology and itsApplication on Wireless Meter-reading System,\u201d IEEE InternationalConference on Industrial Informatics, Aug. 2006, pp. 1257 - 1260.[52] S. W. Luan, J. H. Teng, S. Y. Chan, L. C. Hwang, \u201cDevelopment of aSmart Power Meter for AMI Based on ZigBee Communication,\u201d IEEE8th International Conference on Power Electronics and Driver Systems,Taiwan, Paper No. 284, 2009.[53] S. W. Luan; J. H. Teng, S. Y. Chan, L. C. Hwang, \u201cDevelopment of anautomatic reliability calculation system for advanced metering infras-tructure,\u201d 8th IEEE International Conference on Industrial Informatics(INDIN 2010), pp.342-347, 13-16 July 2010.[54] P. Zhang, F. Li, N. Bhatt, \u201cNext-Generation Monitoring, Analysis, andControl for the Future Smart Control Center,\u201d IEEE Trans. Smart Grid,vol.1, no.2, pp.186-192, Sept. 2010.[55] A. Aggarwal, S. Kunta, P. K. Verma, \u201cA proposed communications in-frastructure for the smart grid,\u201d in Innovative Smart Grid Technologies(ISGT), 2010, pp. 1-5.[56] C. H. Hauser, D. E. Bakken, I. Dionysiou, K. H. Gjermundrod, V. S.Irava, J. Helkey, A. Bose, \u201cSecurity, trust, and QoS in Next generationcontrol and communication for large power systems,\u201d Int. J. CriticalInfrastructures, Vol. 4, 2008.[57] Smart Grids Interoperability Standards Project, [online] Availablehttp://www.nist.gov/smartgrid/.[58] NIST framework and Roadmamp for Smart Grid interoperabilitystandards release 1.0.[59] IEEE Smart Grid, [online] Available http://smartgrid.ieee.org/nist-smartgrid-framework.[60] A. F. Snyder and M. T. G. Stuber, \u201cThe ANSI C12 protocol suite- updated and now with network capabilities,\u201d in Power SystemsConference: Advanced Metering, Protection, Control, Communication,and Distributed Resources (PSC 2007), pp. 117-122, 2007.[61] F. Lobo, A. Cabello, A. Lopez, D. Mora, and R. Mora, \u201cDistributionNetwork as communication system,\u201d in SmartGrids for Distribution,2008. IET-CIRED. CIRED Seminar, 2008, pp. 1-4.[62] Report to NIST on Smart Grid Interoperability Standards RoadmapEPRI, Jun. 17, 2009.[63] S. Hurd, R. Smith, G. Leischner, \u201cTutorial: Security in ElectricUtility Control Systems,\u201d 61st Annual Conference for Protective RelayEngineers, pp.304-309, 1-3 April 2008.[64] Draft Smart Grid Cyber Security Strategy and Requirements, NIST IR7628, Sep. 2009.[65] GridWise Architecture Council Interoperability Framework,http://www.gridwiseac.org/pdfs/interopframework v1 1.pdf.[66] R. DeBlasio, C. Tom, \u201cStandards for the Smart Grid,\u201d IEEE Energy2030 Conference, pp.1-7, 17-18 Nov. 2008.[67] M. Masera, A. Stefanini and G. Dondossola, \u201cThe Security of Informa-tion and Communication Systems and the E+I Paradigm,\u201d in CriticalInfrastructures at Risk. vol. 9, A. V. Gheorghe, M. Masera, M. Weijnenand D. Vires, Eds., Springer Netherlands, 2006, pp. 85-116.[68] B. Stephens, \u201cSystem-Wide Information Management (SWIM)Demonstration Security Architecture,\u201d IEEE/AIAA 25th Digital Avion-ics Systems Conference, pp.1-12, 15-19 Oct. 2006.[69] P. Lund; \u201cThe Danish Cell Project - Part 1: Background and GeneralApproach,\u201d IEEE Power Engineering Society General Meeting, pp.1-6,24-28 June 2007.[70] IEEE Std 1547.3, \u201cIEEE Guide for Monitoring, Information Exchange,and Control of Distributed Resources Interconnected With ElectricPower Systems,\u201d vol., no., pp.1-158, 2007.[71] G. Deconinck, \u201cMetering, Intelligent Enough for Smart Grids?,\u201d inSecuring Electricity Supply in the Cyber Age. vol. 15, Z. Lukszo, etal., Eds., Springer Netherlands, 2010, pp. 143-157.[72] IEEE Std 802.11i, \u201cIEEE Standard for Information Technology-Telecommunications and Information Exchange Between Systems-Local and Metropolitan Area Networks- Specific Requirements Part11: Wireless LAN Medium Access Control (MAC) and Physical Layer(PHY) Specifications Amendment 6: Medium Access Control (MAC)Security Enhancements,\u201d pp. 1-175, 2004.[73] IEEE Std 802.16e, \u201cIEEE Standard for Local and Metropolitan AreaNetworks Part 16: Air Interface for Fixed and Mobile BroadbandWireless Access Systems Amendment 2: Physical and Medium AccessControl Layers for Combined Fixed and Mobile Operation in LicensedBands and Corrigendum 1,\u201d pp. 1-822, 2006.[74] U.S. Department of Energy, \u201cWireless Procurement Language in Sup-port of Advanced Metering Infrastructure Security\u201d, 2009.[75] IEEE P2030, Draft Guide for Smart Grid Interoperability of EnergyTechnology and Information Technology Operation with the ElectricPower System (EPS), and End-Use Applications and Loads. July 2009.[76] D. Becker, T. L. Saxton, and M. Goodrich, \u201cCIM standard for dynamicmodel exchange,\u201d in IEEE Power and Energy Society General Meeting,pp. 1-3, 2010.[77] IEEE Unifies Power, Communications, and IT with launch of SmartGrid Interoperability Standards Project P2030. IEEE Standards Asso-ciation P2030, June, 2009.[78] S. L. Woodruff, \u201cComplexity in power systems and consequencesfor real-time computing\u201d, IEEE PES Power Systems Conference andExposition, 10-13 Oct. 2004.[79] R. Dougal, T. Lovett, A. Monti and E. Santi, \u201cA MultilanguageEnvironment For Interactive Simulation And Development Of ControlsFor Power Electronics,\u201d IEEE PESC01.[80] R. Dougal, A. Monti and F. Ponci, \u201cThe Incremental Design Processfor Power Electronic Building Blocks,\u201d invited paper for IEEE PESAnnual Meeting 2006.[81] R. Dougal and A. Monti, \u201cThe Virtual Test Bed as a tool for rapidsystem engineering,\u201d IEEE Systems Conference, April 2007.[82] L. Cristaldi, A. Ferrero, M. Lazzaroni, A. Monti and F. Ponci, \u201cMul-tiresolution Modeling: an Experimental Validation,\u201d IEEE-IMCT02,Ankorage (USA), 21-23 May 2002.[83] F. Ponci, A. Monti and E. Santi, \u201cDiscrete-Time Multi- ResolutionModeling of Switching Power Converters Using Wavelets,\u201d SIMU-LATION, Transactions of the Society for Modeling and SimulationInternational, February 2009, vol. 85, no. 2, pages 69-88.[84] A. Monti and R. Dougal, \u201cThe Virtual Test Bed Concept For VirtualPrototyping Of Complex Systems,\u201d in Proc. AED, 2004.[85] R. Rios-Zalapa, X. Wang, J. Wan, K. Cheung, \u201cRobust dispatch tomanage uncertainty in real time electricity markets,\u201d Innovative SmartGrid Technologies (ISGT), pp.1-5, 19-21 Jan. 2010.[86] R. Krebs, B. M. Buchholz, Z. A. Styczynski, K. Rudion, C. Heyde, Y.Sassnick, \u201cVision 2020 \u0142 Security of the network operation today andin the future. German experiences,\u201d IEEE Power and Energy SocietyGeneral Meeting - Conversion and Delivery of Electrical Energy in the21st Century, pp.1-6, 20-24 July 2008.[87] M. Amin, \u201cEnergy Infrastructure Defense Systems,\u201d Proc. IEEE ,vol.93, no.5, pp.861-875, May 2005.[88] J. Wen, P. Arons, W.-H. E. Liu, \u201cThe role of Remedial ActionSchemes in renewable generation integrations,\u201d Innovative Smart GridTechnologies (ISGT), pp.1-6, 19-21 Jan. 2010.[89] M. McGranaghan, D. Von Dollen, P. Myrda, E. Gunther, \u201cUtilityexperience with developing a smart grid roadmap,\u201d IEEE Powerand Energy Society General Meeting - Conversion and Delivery ofElectrical Energy in the 21st Century, pp.1-5, 20-24 July 2008.[90] M. Kezunovic, F. Xu, B. Cuka, P. Myrda, \u201cIntelligent processing ofIED data for protection engineers in the Smart Grid,\u201d MELECON 2010- 2010 15th IEEE Mediterranean Electrotechnical Conference, pp.437-442, 26-28 April 2010.[91] K. Moslehi and R. Kumar, \u201cA Reliability Perspective of the SmartGrid,\u201d IEEE Trans. Smart Grid, vol. 1, pp. 57-64, 2010.[92] K. Mets, T. Verschueren, W. Haerick, C. Develder, F. De Turck,\u201cOptimizing smart energy control strategies for plug-in hybrid electricvehicle charging,\u201d IEEE/IFIP Network Operations and ManagementSymposium Workshops (NOMS Wksps), pp.293-299, 19-23 April2010.[93] K. Moslehi and R. Kumar, \u201cSmart Grid - a reliability perspective,\u201d inInnovative Smart Grid Technologies (ISGT 2010), pp. 1-8, 2010.[94] Markets Committee of the ISO/RTO Council, \u201cHarnessing the Powerof Demand - How ISOs and RTOs Are Integrating Demand Responseinto Wholesale Electricity Markets,\u201d October 16, 2007.[95] R. N. Anderson, \u201cThe Distributed Storage-Generation Smart ElectricGrid of the Future\u201d, white paper, Columbia University.[96] R. Gawel, \u201cTesla\u2019s Tests Confirm Roadster\u2019s 245-Mile Range,\u201d Elec-tronic Design, November 5, 2007.[97] S. Acha, T. C. Green, N. Shah, \u201cEffects of optimised plug-in hybridvehicle charging strategies on electric distribution network losses,\u201dIEEE PES Transmission and Distribution Conference and Exposition,pp.1-6, 19-22 April 2010.[98] G. Ericsson, O. Torkilseng, G. Dondossola, T. Jansen, J. Smith, D.Holstein, A. Vidrascu, and J.Weiss, \u201cSecurity for Information Systemsand Intranets in Electric Power Systems,\u201d Tech Brochure (TB) 317CIGR, 2007.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.16 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION[99] G. Ericsson, \u201cCyber Security and Power System Communica-tion\u0142Essential Parts of a Smart Grid Infrastructure,\u201d IEEE Trans. PowerDelivery, vol.25, no.3, pp.1501-1507, July 2010.[100] IEC, Power System Control & Associated Communications-Data &communication Security 62351 part 1-8, TS.[101] ISA 99 [Online]. Available:http://www.isa.org/MSTemplate.cfm?MicrositeID=988&CommitteeID=6821.[102] NIST, Computer Security Division, Computer Security Resource Cen-tre. [Online]. Available: http://csrc.nist.gov/publications/PubsSPs.html.[103] NIST ICS Security Project [Online].Available:http://csrc.nist.gov/seccert/ics/index.html.[104] Swedish Civil Contingencies Agency, \u201cSCADA Security Coordina-tion\u201d.[105] Swedish Civil Contingencies Agency,\u201cGuide to Increased Security inProcess Control Systems for Critical Societal Functions\u201d.[106] G. Ericsson, O. Torkilseng, G. Dondossola, L. Pitre-Cambacds, S.Duckworth, A. Bartels, M. Tritschler, T. Kropp, J.Weiss, and R.Pellizzonni, \u201cTreatment of Information Security for Electric PowerUtilities (EPUs),\u201d Technical Brochure (TB), CIGRE, to appear 2010.[107] P. Roche; \u201cCyber security considerations in power system operations,\u201dCIGRE Electra No. 218, February 2005.[108] T. Goodspeed, D. R. Highfill and B.A. Singletary, \u201cLow-level DesignVulnerabilities in Wireless Control Systems Hardware,\u201d Proceedingsof the SCADA Security Scientific Symposium 2009 (S4), pp.3-1-3-26,January 21- 22, 2009.[109] J. Brodsy and A. McConnell, \u201cJamming and Interference InducedDenial-of-Service Attacks on IEEE 802.15.4-Based Wireless Net-works,\u201d Proceedings of the SCADA Security Scientific Symposium2009 (S4), pp. 2-1-2 -11, January 21-22, 2009.[110] C. Efthymiou and G. Kalogridis, \u201cSmart Grid Privacy via Anonymiza-tion of Smart Metering Data,\u201d in First IEEE International Conferenceon Smart Grid Communications (SmartGridComm 2010), pp. 238-243,2010.Ye Yan is a Ph.D. student in the Departmentof Computer and Electronics Engineering (CEEN),University of Nebraska-Lincoln (UNL). His cur-rent research articles on wireless network, networksecurity, and smart grid communication has beenpublished in IEEE and other international journalsand conferences. He has been serving as TPC mem-bers on several IEEE conferences and reviewers formany international journals and conferences. He isa student member of IEEE.Yi Qian is an Assistant Professor in the Departmentof Computer and Electronics Engineering, Univer-sity of Nebraska-Lincoln (UNL). His research in-terests include information assurance and networksecurity, network design, network modeling, simu-lation and performance analysis for next generationwireless networks, wireless ad-hoc and sensor net-works, vehicular networks, broadband satellite net-works, optical networks, high-speed networks andthe Internet. Prior to joining UNL, he worked inthe telecommunications industry, academia, and theU.S. government. Some of his previous professional positions include servingas a senior member of scientific staff and a technical advisor at NortelNetworks, a senior systems engineer and a technical advisor at several start-upcompanies, an Assistant Professor at University of Puerto Rico at Mayaguez,and a senior researcher at National Institute of Standards and Technology. Hehas a successful track record to lead research teams and to publish researchresults in leading scientific journals and conferences. Several of his recentjournal articles on wireless network design and wireless network security areamong the most accessed papers in the IEEE Digital Library. Dr. Yi Qian isa member of ACM and a senior member of IEEE. He is currently serving asthe Vice Chair for Conferences - Communications and Information SecurityTechnical Committee (CISTC) for IEEE Communications Society. He is alsoserving as the IEEE Communications Society CISTC Representative to theAd Hoc Committee on Smart-Grid Communications.Hamid Sharif is the Charles J. Vranek Professorof the College of Engineering at the University ofNebraska-Lincoln. He is also the Director of theAdvanced Telecommunications Engineering Labo-ratory (TEL) at University of Nebraska. ProfessorSharif has published a large number of researcharticles in international journals and conferencesand has been the recipient of a number of bestpaper awards. Dr. Sharif has been serving on manyIEEE and other international journal editorial boardsand currently is the co-editor-in-chief for the WileyJournal of Security and Communication Networks. He has contributed to theIEEE in many roles including the elected Chair of the Nebraska Section,elected Chair of the Nebraska Computer Chapter, elected Chair of theNebraska Communications Chapter, and the Chapter Coordinator for the IEEERegion 4 in US.David Tipper is an Associate Professor and Directorof the Graduate Telecommunications and Network-ing Program at the University of Pittsburgh. Heis a graduate of the University of Arizona (Ph.D.EE, M.S.S.I.E.) and Virginia Tech (B.S.E.E.). Hiscurrent research focuses on network design, energyefficiency, information assurance techniques, timevarying network performance analysis and control.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
        "id": 33131981,
        "identifiers": [
          {
            "identifier": "12211338",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:d-scholarship.pitt.edu:12508",
            "type": "OAI_ID"
          },
          {
            "identifier": "10.1109/surv.2012.021312.00034",
            "type": "DOI"
          }
        ],
        "title": "A survey on smart grid communication infrastructures: Motivations, requirements and challenges",
        "magId": null,
        "oaiIds": [
          "oai:d-scholarship.pitt.edu:12508"
        ],
        "publishedDate": "2013-01-01T00:00:00",
        "publisher": "'Institute of Electrical and Electronics Engineers (IEEE)'",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://d-scholarship.pitt.edu/12508/1/Smart_Grid_Infrastructure_Final.pdf"
        ],
        "updatedDate": "2022-05-16T22:46:59",
        "yearPublished": 2013,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "https://core.ac.uk/download/12211338.pdf"
          },
          {
            "type": "reader",
            "url": "https://core.ac.uk/reader/12211338"
          },
          {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/12211338/large"
          },
          {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/12211338/large"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/33131981"
          }
        ]
      },
      "relevance_score": 0.0175,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.175,
          "dimension_weight": 0.1,
          "weighted_score": 0.0175,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2013 (Norm. Score: 0.1)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_primary_0",
      "dynamic_step": 0,
      "core_id": 33131981,
      "doi": "10.1109/surv.2012.021312.00034"
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": "1810.11613",
        "authors": [
          {
            "name": "Barbarossa, Sergio"
          },
          {
            "name": "Chen, Tianyi"
          },
          {
            "name": "Giannakis, Georgios B."
          },
          {
            "name": "Wang, Xin"
          },
          {
            "name": "Zhang, Zhi-Li"
          }
        ],
        "citationCount": 0,
        "contributors": [
          "Barbarossa, Sergio",
          "Wang, Xin",
          "Chen, Tianyi",
          "Giannakis, Georgios B.",
          "Zhang, Zhi-Li"
        ],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/195777516"
        ],
        "createdDate": "2019-02-06T06:45:57",
        "dataProviders": [
          {
            "id": 144,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/144",
            "logo": "https://api.core.ac.uk/data-providers/144/logo"
          },
          {
            "id": 1084,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/1084",
            "logo": "https://api.core.ac.uk/data-providers/1084/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "Internet-of-Things (IoT) envisions an intelligent infrastructure of networked\nsmart devices offering task-specific monitoring and control services. The\nunique features of IoT include extreme heterogeneity, massive number of\ndevices, and unpredictable dynamics partially due to human interaction. These\ncall for foundational innovations in network design and management. Ideally, it\nshould allow efficient adaptation to changing environments, and low-cost\nimplementation scalable to massive number of devices, subject to stringent\nlatency constraints. To this end, the overarching goal of this paper is to\noutline a unified framework for online learning and management policies in IoT\nthrough joint advances in communication, networking, learning, and\noptimization. From the network architecture vantage point, the unified\nframework leverages a promising fog architecture that enables smart devices to\nhave proximity access to cloud functionalities at the network edge, along the\ncloud-to-things continuum. From the algorithmic perspective, key innovations\ntarget online approaches adaptive to different degrees of nonstationarity in\nIoT dynamics, and their scalable model-free implementation under limited\nfeedback that motivates blind or bandit approaches. The proposed framework\naspires to offer a stepping stone that leads to systematic designs and analysis\nof task-specific learning and management schemes for IoT, along with a host of\nnew research directions to build on.Comment: Submitted on June 15 to Proceeding of IEEE Special Issue on Adaptive\n  and Scalable Communication Network",
        "documentType": "research",
        "doi": "10.1109/jproc.2019.2896243",
        "downloadUrl": "https://core.ac.uk/download/195777516.pdf",
        "fieldOfStudy": null,
        "fullText": "1Learning and Management for Internet-of-Things:\nAccounting for Adaptivity and Scalability\nTianyi Chen, Sergio Barbarossa, Xin Wang, Georgios B. Giannakis, and Zhi-Li Zhang\nAbstract\u2014Internet-of-Things (IoT) envisions an intelligent in-\nfrastructure of networked smart devices offering task-specific\nmonitoring and control services. The unique features of IoT\ninclude extreme heterogeneity, massive number of devices, and\nunpredictable dynamics partially due to human interaction. These\ncall for foundational innovations in network design and manage-\nment. Ideally, it should allow efficient adaptation to changing\nenvironments, and low-cost implementation scalable to massive\nnumber of devices, subject to stringent latency constraints. To\nthis end, the overarching goal of this paper is to outline a unified\nframework for online learning and management policies in IoT\nthrough joint advances in communication, networking, learning,\nand optimization. From the network architecture vantage point,\nthe unified framework leverages a promising fog architecture that\nenables smart devices to have proximity access to cloud function-\nalities at the network edge, along the cloud-to-things continuum.\nFrom the algorithmic perspective, key innovations target online\napproaches adaptive to different degrees of nonstationarity in IoT\ndynamics, and their scalable model-free implementation under\nlimited feedback that motivates blind or bandit approaches. The\nproposed framework aspires to offer a stepping stone that leads\nto systematic designs and analysis of task-specific learning and\nmanagement schemes for IoT, along with a host of new research\ndirections to build on.\nIndex Terms\u2014Internet-of-Things, network resource allocation,\nmobile edge computing, stochastic optimization, online learning.\nI. INTRODUCTION\nThe past decade has witnessed a proliferation of connected\ndevices and objects, where the notion of Internet-of-Things\n(IoT) plays a central role in the envisioned technological\nadvances. Conceptually speaking, IoT foresees an intelligent\nnetwork infrastructure with ubiquitous smart devices - home\nautomation, interactive healthcare, and self-driving connected\nvehicles, are typical in IoT [7], [104]; see Fig. 1. Today, a\nnumber of IoT applications have already brought major benefits\nto many aspects of our daily life. The current generation\nof IoT can already afford an increasing amount of real-time\nThe work of T. Chen and G. B. Giannakis was supported by NSF 1509040,\n1508993, and 1711471. The work of S. Barbarossa was supported by the\nH2020 EUJ Project 5G-MiEdge, Nr. 723171. The work of X. Wang was\nsupported by the National Natural Science Foundation of China Grants No.\n61671154, the National Key Research and Development Program of China\nGrant 2017YFB0403402, and the Innovation Program of Shanghai Municipal\nScience and Technology Commission 17510710400. The work of Z.-L. Zhang\nwas supported by US DoD HDTRA1-14-1-0040, NSF 1411636 and 1617729.\nT. Chen and G. B. Giannakis are with the Digital Technology Center,\nUniversity of Minnesota, Minneapolis, MN 55455 USA. Emails: {chen3827,\ngeorgios}@umn.edu. S. Barbarossa is with the Department of Information\nEngineering, Electronics, and Telecommunications, Sapienza University of\nRome, 00184, Rome, Italy. E-mail: sergio.barbarossa@uniroma1.it. X. Wang\nis with the Shanghai Institute for Advanced Communication and Data Science,\nthe Key Laboratory for Information Science of Electromagnetic Waves (MoE),\nDepartment of Communication Science and Engineering, Fudan University,\nShanghai 200433, China. E-mail: xwang11@fudan.edu.cn. Z.-L. Zhang is with\nDepartment of Computer Science, University of Minnesota, Minneapolis, MN\n55455 USA. E-mail: zhang@cs.umn.edu.\nautomation, and thus intelligence toward the vision of real-\ntime IoT. However, despite the popularity of IoT, several\ncritical challenges must be addressed before embracing its\nfull potential [5], [86]. To this end, we highlight three key\nchallenges that are arguably expected to be at the epicenter of\nemerging IoT research fields.\nFig. 1:Internet of Everything[3].\nExtreme heterogeneity.\nThe computational and\ncommunication capacities of\nconnected devices differ due\nto differences in hardware\n(e.g., CPU frequency),\ncommunication protocol\n(e.g., ZigBee, WiFi), and\nenergy availability (e.g.,\nbattery level) [103]. The\ntasks carried out on various\ndevices are often considerably diverse, e.g., motion sensors\nmonitor human behavior in a smart home [60], while cameras\nare responsible for recognizing a suspicious behavior in a\ncrowded environment, or, vehicle plates in a parking garage.\nUnpredictable dynamics. Unlike many existing communica-\ntion, computing and networking platforms, the IoT dynam-\nics can stem from multiple sources, where adaptivity is not\nonly critical but also essential in designing hardware and\nmanagement protocols. Such sources entail human-in-the-loop\ndynamics in addition to physical objects [60], demand response\nin energy systems [40], and intelligent automotive applications\n[59]. In these applications, IoT dynamics are intertwined with\nor even partially determined by human behavior [34], [69],\n[73] - as such, high degree of adaptivity in the algorithm and\nhardware design is needed.\nScalability at the core. IoT entails an intelligent network\ninfrastructure with a massive number of devices. It is estimated\nthat by 2020, there will be more than 50 billion devices con-\nnected through the Internet [39], which highlights scalability as\na key challenge for IoT [7], [86]. Scalability is not only about\ncomputational efficiency, but also about lower communication\noverhead (e.g., how often a device needs to communicate\nwith the remote cloud center), as well as reduced information\nneeded (e.g., what type of information a device needs before\nmaking sensible decisions).\nFaced with these major IoT challenges, innovations in net-\nwork design and management are desired to enable efficient\nonline operations, and seamless co-existence of humans with\nthings [25]. Consequently, it is imperative to develop new tools\nfor IoT management that tap into diverse inference, signal\nprocessing, communications, and networking techniques, by\ndrawing from fields such as machine learning, optimization,\nar\nX\niv\n:1\n81\n0.\n11\n61\n3v\n1 \n [c\ns.S\nY]\n  2\n7 O\nct \n20\n18\n2and applied statistics. The novel expertise gleaned from these\nresearch areas, coupled with the solid analytical approach, are\nthe best credentials for succeeding in IoT research [86].\nFrom a network architecture perspective, to ensure the\ndesired user experience and meet heterogeneous service re-\nquirements, IoT tasks nowadays are no longer only supported\nby the cloud data centers, but also through a promising new\narchitecture termed edge computing, or in a broader sense fog\ncomputing. This architecture distributes computation, commu-\nnication, and storage closer to the end IoT devices and users,\nalong the cloud-to-things continuum [9], [10], [25], [61], [62],\n[94]. This shift of computing paradigms is further promoted\nby the advanced communication techniques emerging with\nstandards such as Narrowband-IoT (NB-IoT) [2], [4].\nGiven the huge volume of data in various IoT setups and the\nproliferation of learning and large-scale optimization advances,\na pertinent direction is prompted by asking the following\nquestion: Can we learn from historical data to improve the\nquality of network management policies in IoT? The rationale\nis that historical data contain statistics of the IoT environments\n[93], and learning from them can mitigate the uncertainty of\nfuture management tasks. Further armed with online adaptation\ncapability to reinforce the current policies, it is envisioned that\nlearn-and-adapt network management schemes can markedly\nimprove IoT user experience in terms of low service delay, high\nsystem resilience, and adaptivity [17], [21]. Toward this goal,\nthe present overview paper will outline an offline-aided online\napproach with markedly improved performance, by leveraging\nstatistical learning from historical samples.\nTaking a step further, online learning, with online con-\nvex optimization (OCO) as a special case, is an emerging\nmethodology for sequential decision making with light-weight\nimplementation and well documented merits, especially when\nthe environment (e.g., a sequence of convex costs) varies in\nan unknown and possibly adversarial manner [15], [109]. Tar-\ngeting a scalable solution in a prohibitively complex IoT envi-\nronment, this paper will also overview a new OCO framework\ndesigned for IoT, which further incorporates various forms of\nfeedback, physical constraints and performance metrics driven\nby IoT applications, relative to the standard settings [15],\n[43], [109]. Novel schemes tailored for this setting can lay\na solid analytical foundation to delineate the tradeoffs among\nalgorithm scalability, performance guarantees, and degree of\n(non-)stationarity present in the IoT environment [16], [19].\nThe rest of the paper is organized as follows. Section II\ndeals with the heterogeneity in IoT demand and QoS, along\nwith a unified formulation for dynamic IoT tasks. Section\nIII introduces methods for optimizing IoT performance under\ndifferent level of non-stationarity in IoT dynamics. Section\nIV summarizes scalable OCO-based schemes with different\nfeedback options. Finally, concluding remarks and possible\nfuture research directions are highlighted in Section V.\nNotation. Bold uppercase (lowercase) letters denote matrices\n(column vectors), while (\u00b7)> stands for transposition, and \u2016x\u2016\ndenotes the `2-norm of a vector x. The projection [a]+ :=\nmax{a,0} are defined entrywise. The indicator function 1(A)\ntakes value 1 when the event A happens, and 0 otherwise. O(x)\ndenotes big order of x, i.e., O(x)/x\u2192 1 as x\u2192 0; O\u02dc neglects\nthe lower-order terms with a polynomial log x rate; and o(x)\ndenotes small order of x, i.e., o(x)/x\u2192 0 as x\u2192 0.\nII. HETEROGENEITY IN IOT DEMAND AND QOS\nHeterogeneity is inherent in IoT, and it manifests itself across\ndifferent aspects, from application requirements and constraints\nto sensing and communication technologies.\nA. Heterogeneous applications\nThe range of IoT applications already spans several fields,\nand it is rapidly increasing. A few examples of applications\nare [4], [5], [104]: (i) lifestyles (wearable gadgets, gam-\ning, augmented/virtual reality, wellness); (ii) smart environ-\nments (homes, offices, cities); (iii) automotive (self-driving,\ntraffic monitoring, intelligent transportation systems, vehicle-\nto-vehicle communications); (iv) industrial (full automation\nand control, structure monitoring, logistic); (v) environmental\nmonitoring (pollution, global warming, waste management);\n(vi) healthcare (patient monitoring, body area networks, smart\nhealth, elderly care); and, (vii) security and surveillance. These\napplications are characterized by highly diverse requirements,\nin terms of data rate, latency, reliability, security, connectivity,\nmobility, etc. To illustrate the extreme variability of require-\nments, we note that virtual reality require latencies in the order\nof a few milliseconds and data rates in the order of 25 Mbps,\nwhile automated driving or certain industrial control applica-\ntions require latencies in the order of milliseconds and high\npacket transmission reliability (in the order of 99.999 percent).\nConversely, for environmental monitoring applications such as\nwaste management, an update frequency of one packet/hour is\nsufficient, with a tolerable delay of 30 minutes.\nA few paradigms are useful to outline the challenges facing\nIoT, and the potential of our approaches to addressing them.\nAutomated driving. The goal in this application is to enhance\nperception of an individual vehicle and thus improve safety.\nA common approach is to set up a cooperative perception\nsystem building on the information sharing between vehicles\nand roadside units (RSUs) [79]. The scope is to widen the\nvisibility of the individual vehicle to prevent that an object\nunseen by a single vehicle might cause an accident [48], [80].\nThe signals to be exchanged go from (low data rate) range mea-\nsurements to (high data rate) high definition maps generated by\nsensors mounted on each vehicle. The communication channels\nbetween vehicles are highly dynamic and hard to predict, while\nthe information available at each time slot can be outdated.\nNevertheless, the communication among vehicles and RSUs\nshould be performed in a reliable and timely manner to ensure\nthat emergency operations can take place in the due time.\nIntelligent transportation. A typical task in this application\nis to navigate a set of electric vehicles to their destination,\nby collecting along the way data about traffic, state of the\nbattery, and availability of parking slots. The objective here is\nto minimize fuel consumption and the time needed to reach\na certain destination, while ensuring that all vehicles find a\nproper refueling station for their batteries along the way. The\n3remaining time to destination is updated online, depending on\nthe time-varying traffic state, which is generally unpredictable.\nB. Heterogeneous technologies\nThe IoT ecosystem is composed of various components,\nwhose functionality falls within the following categories [5]:\nidentification, sensing, communication, computation, and ser-\nvices. Identification is crucial to assign a clear identity to each\nobject in the network. The role of sensing elements is to gather\ndata from the real world. Typically, sensors are integrated\nwith single board computers and TCP/IP functionalities to\ncreate IoT devices, such as Arduino or Raspberry PI, which\nare able to sense and send data to a decision entity. The\nrole of communication is to propagate information from the\nsensing elements to a decision entity, possibly distributed, and\nback to actuators. There is a plethora of very heterogeneous\ncommunication technologies that are in use in IoT. As a\nbroad classification, we can list: (i) short-range technologies to\nsupport machine-to-machine communications, like Bluetooth,\nIEEE 802.15.4 and ZigBee; (ii) long-range networks, like LoRa\nsupporting data rates of around 50 kbps over ranges up to 15\nKm, or SigFox using ultra-narrowband technologies to support\nultra-low power consumption and long ranges (up to 30-50\nKm in rural areas, 3-10 Km in urban areas), at the expenses\nof limited data rates; (iii) Low-power Wi-Fi, also called\nIEEE 802.11ah supporting data rates up to 347 Mbps; and,\n(iv) cellular networks. Current 4G cellular technologies, more\nspecifically the 3rd Generation Partnership Project Long-Term\nEvolution (3GPP LTE), represent the state-of-the art in mobile\ncommunications. However, LTE has been primarily designed\nfor broadband communications, and thus not optimized for the\nmachine-type communications (MTC) envisioned in IoT.\nTo partially overcome this discrepancy, 3GPP has introduced\nsome modifications to the standards to enable the deployment\nof massive smart connected devices and services such as those\nin smart cities or smart grids: eMTC [1] and NB-IoT [2]. But\na truly disruptive framework enabling an effective deployment\nof IoT is 5G communication networks, thanks to increased\ndata rate, reduced end-to-end latency, and improved coverage\nrelative to 4G [74]. The key features of 5G that are particularly\nsuitable for IoT are: (i) the integration of heterogeneous access\ntechnologies; (ii) virtualization of network functionalities; and,\n(iii) bringing cloud functionalities close to the end-user by\nintroducing mobile edge computing (MEC). While earlier\nnetwork generations have been designed as general purpose\nconnectivity platforms, the vision underlying 5G is to create\nan ecosystem for technical and business innovations involving\nvertical markets such as automotive, energy, agriculture, city\nmanagement, healthcare, manufacturing, and transportation.\nSince these services have very different requirements and\nconstraints, the key challenge of 5G is to design a single\nplatform being able to serve different purposes in an efficient\nway. The solution to tackle such a challenging question is\nnetwork slicing. At the basis of network slicing, there is\nnetwork function virtualization, which makes it possible to par-\ntition a single physical network into multiple virtual networks,\neach matched to its specific requirements and constraints.\nThis enables operators to provide networks on an as-a-service\nbasis, while meeting a wide range of use cases in parallel.\nVirtualization is going to play a key role also in IoT to\ncope with high heterogeneity of requirements as well as the\ncapabilities of devices. But being able to meet the stringent\nlatency requirements of IoT applications, virtualization needs\nto be coupled with a new architectural vision, enabled by MEC.\nC. Embedding IoT in the edge cloud\nEven within the sophisticated architecture of 5G networks,\nmeeting the stringent latency constraints required in some IoT\napplications over a wide area network can be still challenging,\nif not impossible. To guarantee low latencies, a popular solution\nis to bring cloud functionalities close to the end users through\nmobile (or multi-access) edge computing [44], [56].\nWith MEC, computation and storage resources are brought\nat the edge of the network, represented by the network access\npoints. In this way, delay-sensitive applications launched by\na mobile device can be offloaded to the nearest mobile edge\nhost (MEH), and the most popular contents can also be cached\nin MEHs to minimize downloading time [26], [27]. Bringing\ncomputation and storage resources at the edge of the network\nmakes it possible to guarantee low and stable delays. In\npractice, the applications launched by the user are executed\nby virtual machines running on nearby edge nodes, either\ncloudlets, exploiting a Wi-Fi connection [29], [49], or MEHs,\nusing cellular communication technologies [10]. The further\nextension of MEC is fog computing, where the edge of the\nnetwork can include devices as well, thus creating a continuum\nof devices able to sense, communicate and compute [12],\n[25]. A critical aspect in this scenario is mobility management\n[89]. To handle mobility while offering a seamless service\ncontinuity, it is necessary to migrate virtual machines quickly\nacross MEH. This is a critical step, because instantiating a\nconventional virtual machine can take times well beyond the\nlatencies required in some IoT applications.\nIn MEC or fog computing settings, communication, com-\nputation and storage resources can be seen as three aspects\nof a single system. From a user-centric perspective, what\nactually matters is the time needed to launch an application\nand receive the result back. The overall delay depends on\ncommunication time, computation time and the distribution of\ncontents across the network. This holistic vision calls for a joint\ndynamic optimization of communication, computation, and\ncaching resources [9]. An application where communication\nand computation resources are closely mingled is computation\noffloading. This is a fundamental mechanism to enable simple\ndevices to run sophisticated applications or to allow battery-\npowered devices to run their applications remotely to save en-\nergy and thus prolong battery lifetime. Computation offloading\nhas gained growing popularity recently. For single-user MEC,\nit has been studied in [50], [57], [61], [64]. The multi-user case\nwas addressed in [24], [82], and later extended to the dynamic\ncase, using stochastic optimization in [65], [81]. See recent\nsurveys [9], [10], [63] and references therein.\nD. Taming heterogeneity via a unified formulation\nWith various applications and technologies in mind, the goal\n4optimize\n{xt,\u2200t}\nT\u2211\nt=1\nf(xt; st) /IoT performance metrics\nsubject to\nT\u2211\nt=1\ng(xt; st) \u2264 0 /IoT long-term requirements\nxt \u2208 X (st), \u2200t /IoT short-term requirements\nPer slot t, IoT state dynamics st+1 = d(st,xt, \u03bet)\nPer slot t, find xt given information oracle Ot\n(1a)\n(1b)\n(1c)\n(1d)\n(1e)\nof this section is to put forth a unified model for IoT tasks that\nwill guide subsequent algorithmic development.\nUnifying models. Consider discrete time t \u2208 N, and a time\nhorizon of T slots. Per slot t, an IoT state variable st \u2208 Rp\nis defined, which characterizes all the critical parameters of\nthe IoT environment. Assuming certain amount of knowledge\nabout the environment, the IoT operator will make a decision\nxt \u2208 Rd, aiming to optimize task-specific performance, subject\nto different types of constraints. The decision xt can in turn\ndrive the next state st+1. To model such decision making pro-\ncesses, we consider a generic problem (1). The model here is\ngeneral. The slot duration can vary from tens of microseconds\nin wireless networks, a few milliseconds in automated driving,\ntens of seconds in intelligent transportation, to minutes or even\nhours in smart power networks; the state st can represent\nthe channel gain in wireless networks, the congestion level\nin data networks as well as transportation networks, and the\nrenewable generation, and energy prices in power networks;\nand the decision xt can include the transmitted power in\ncommunication, the size of data workloads, the number of\nvehicles, or the amount of energy. Regarding the objectives,\nconstraints and state dynamics in (1), we will highlight their\nIoT relevance, especially of interest to communication and\nnetworking communities.\nPerformance metrics. Given the state st and the decision xt,\nwe consider the IoT performance as a generic time-invariant\nfunction f(xt; st) (use ft(xt) interchangeably) depending on\nthe time-varying quantities st and xt. For MEC problem in\nSection II-C, f(xt; st) often represents the power consumption\naggregating over all devices, the aggregated delay, or the sys-\ntem throughput [10], [19], [94]. Another line of recent research\nstudies a new performance metric in MEC \u2014 age of informa-\ntion or age, which measures the timeliness of system status\nusing the elapsed time since the most recently received packet\nwas generated at its source [47]. Age of information is pertinent\nto mission-critical IoT applications [28], [88]. Furthermore, for\ntraffic assignment tasks in intelligent transportation, ft(xt) can\ncapture the overall fuel consumption, and the travel time of\nvehicles on the road [106]; for demand response in smart grids,\nit is related to user utility and power balancing cost depending\non the real-time energy prices [52], [54], [85], [97]; and for\napplications related to wireless communications, throughput or\nachievable rate also plays a critical role in the objective.\nShort-term constraints. The heterogeneous requirements in\nIoT are modeled via short-term and long-term constraints in\n(1). The short-term constraints are imposed to regulate xt in\naccordance to short-term requirements, which can be collected\nin a compact set X (st) \u2014 that is either continuous or discrete,\nand possibly depends on the IoT state st. As an example,\nconsider a MEC system composed of access points (APs),\nMEC servers, and mobile user equipment (UE). To meet the\nstringent latency requirement, the E2E latency of each UE\nshould be less than l\u00af, that is,\nltxt + l\nbk\nt + l\nexe\nt + l\nrx\nt \u2264 l\u00af (2)\nwhere i) ltxt is the time spent to send the program state and\ninput (encoded with bt bits) from UE to AP, e.g., ltxt = bt/rt,\nwith rt being the data rate (in bits/sec); ii) lbkt is the backhaul\nlatency between AP and MEC server, which appears when\nthe computations are performed in a server that is not co-\nlocated with the AP; iii) lexet is the server execution time\ndefined as lexet = ct/ut, where ct is the number of CPU cycles\nto be executed, and ut is the number of CPU cycles/second\nallocated by the MEC server to UE; and, iv) lrxt is the time\nfor the MEC server to send back the result to UE. With\nxt := {ut, rt} and st := {lbkt , lrxt , ct, bt} thus (2) included\nin X (st), selecting xt \u2208 X (st) guarantees the E2E latency\nrequirement in MEC. Short-term constraints also arise due\nto the physical limits of transmission lines and generators in\npower networks [40], transceivers in wireless communication\n[96], as well as vehicles in transportation networks [106].\nLong-term constraints. In some IoT applications, the short-\nterm constraints cannot accurately characterize the demand and\nrequirements. For the latency requirement in MEC, the short-\nterm constraint (2) makes implicit assumptions that i) no new\ntask is generated before the old tasks are completed; and, ii)\neach single task is carried out within an established time frame.\nThese assumptions may be restrictive in some cases. Consider\nalso a vehicle in the intelligent transportation application that\nmust arrive at its destination within a certain interval. To guar-\nantee on-time arrival, its long-term average speed instead of the\ninstantaneous speed needs to be lower bounded. The long-term\nconstraints are thus well-motivated to allow flexible adaptation\nof xt to temporal variations of service requirements. Given\nthe state st and the decision xt, they are modeled as a set of\npenalty functions g(xt; st) := [g1(xt; st), \u00b7 \u00b7 \u00b7 , gN (xt; st)]> in\n(1b). Ideally, we want the accumulated penalty over the entire\nhorizon below a certain threshold. For convenience, we let the\nthreshold to be 0 in (1b), which is without loss of generality\nsubject to a constant shift. Long-term constraints also appear in\nwireless networks where often the average transmit power and\nlink capacity are confined [96]. The challenge in dealing with\nlong-term constraints is that the future states st+1, \u00b7 \u00b7 \u00b7 , sT are\nnot known at slot t, which calls for adaptive optimization.\nState dynamics. One of the key challenges in IoT is its\nunpredictable dynamics. In (1), IoT dynamics are encoded\n5TABLE I: An overview of heterogeneous IoT settings considered.\nSection State dynamics st \u2192 st+1 Information oracle Ot\nSection III-A i.i.d. or Markovian f,g,X and {s1 \u00b7 \u00b7 \u00b7 , st}\nSection III-B Partially controlled Markovian f,g,X and {s1 \u00b7 \u00b7 \u00b7 , st}\nSection III-C Controlled Markovian f1(x1),g1(x1), \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121(xt\u22121) and {s1 \u00b7 \u00b7 \u00b7 , st}\nSection IV-A Generally non-stationary f1,g1, \u00b7 \u00b7 \u00b7 , ft\u22121,gt\u22121,X\nSection IV-B Generally non-stationary f1(x1),g1, \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121,X\nSection IV-C Generally non-stationary f1(x1),g1(x1), \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121(xt\u22121),X\nby a state transition function d which generates the next\nstate st+1 = d(st,xt, \u03bet) given st and xt as well as an\nexogenous variable \u03bet. In most cases, the exogenous variable\n\u03bet can be a random disturbance. For wireless communication\napplications where the state st represents the fading channel\nstate, then st+1 often does not depend on st and xt; that is,\nst+1 = d(\u03bet) := s\u00af + \u03bet, where s\u00af is the mean channel state,\nand \u03be1, \u00b7 \u00b7 \u00b7 , \u03beT are independent, identically distributed (i.i.d.)\nzero-mean random variables; see e.g., [38], [96]. Markovian\ndynamics are also common in modeling energy prices, renew-\nable generation processes [41], in which case st+1 = d(st, \u03bet)\ndepends on the current state st and an i.i.d. noise \u03bet but not\nxt. We refer to both st+1 = d(\u03bet) and st+1 = d(st, \u03bet), as\nnon-interactive dynamics. The decision xt can also play an\nimportant role in state transitions. Taking MEC as an example,\na queueing model is usually incorporated to keep trace of\nthe relevant quantities, such as the amount of remaining tasks\nthat need to be offloaded or processed. With {bt, ct, rt, ut}\ndefined below (2), we consider a transmission queue qtxt that\nquantifies the number of bits to be transmitted at slot t from\nUE, and a computation queue qexet that quantifies the amount of\ncomputation that needs to be completed for UE. If \u2206t denotes\nthe slot duration, the transmission queue evolves as\nqtxt+1 = max\n[\nqtxt \u2212 rt\u2206t, 0\n]\n+ bt (3)\nand the computation queue evolves as follows qexet+1 =\nmax [qexet \u2212 ut\u2206t, 0] + ct. In this case, the IoT state is\nst := {qtxt , qexet }, the decision is xt := {ut, rt}, and the\nexogenous variable is \u03bet := {bt, ct}. It then follows that\nst+1 = d(st,xt, \u03bet) \u2014 what we term interactive dynamics, or\nmore precisely, controlled Markovian dynamics if \u03bet is i.i.d. If\nthe communication and computation resources are sufficient,\nan ideal policy should guarantee the queue stability [71], [92].\nAccording to Little\u2019s law [77], the average execution delay\nexperienced by each UE is proportional to the average queue\nlengths. Hence, a meaningful problem can be minimizing the\naverage power, subject to the average delay constraints, which\nwill be discussed in Section III-B. State variables of this type\nalso include the location of a vehicle in the intelligent trans-\nportation or an unmanned aerial vehicle (UAV) that depends on\ntheir previous location and the current movement [42], [100],\n[101], and the energy level of a battery that depends on their\ninstantaneous (dis)charging amounts. More complex dynamics\nare also possible in IoT due to e.g., strategic human interactions\nand malicious attack [110]. In those cases, \u03bet can be a function\nof all the states s1, \u00b7 \u00b7 \u00b7 , st, or even completely arbitrary.\nAccessible information. While various objectives, constraints\nand state dynamics have been adopted to model heteroge-\nneous problems in IoT, the level of accessible information\ndirectly affects how to solve the resultant problem given\nlimited communication and computation resources \u2014 the\nepicenter of scalability barriers in IoT. Let the information\noracle Ot collect all the information available to the IoT\noperator before making decision xt. For cases where the\nobjectives and the constraints are easy-to-measure formulas\n(e.g., aggregated power, throughput, distance), we consider\nOt := {f,g,X , s1 \u00b7 \u00b7 \u00b7 , st} that includes the explicit form of\nfunctions {f,g}, set X and one-slot-ahead prediction st. In\nsome IoT settings however, i) the objective capturing user-\ncentric quantities, e.g., service latency or reliability, security\nrisk, and customer ratings, is hard to model; ii) the objective\ninvolving fast-varying quantities is hard to predict, e.g., the\nmillimeter wave links in 5G are prone to blocking events,\nthus hard to predict.; and, iii) even if modeling and predicting\nare possible in theory, the low-power smart devices may not\nafford the complexity of running statistical learning tools \u201con-\nthe-fly.\u201d In such cases, we consider a fully causal information\noracle Ot := {f1(x1),g1(x1), \u00b7 \u00b7 \u00b7 , ft\u22121(xt\u22121),gt\u22121(xt\u22121)}\nthat includes only the observed objective function values and\nconstraint penalties at previous slots. IoT scenarios between\nthese two extreme cases will also be discussed.\nIn Table I, we summarize the heterogeneous settings that\none may encounter in IoT. Targeting these settings, a set of\nsuitable solvers will be discussed in the subsequent sections.\nWhile the methodologies presented in this paper mainly focus\non stochastic optimization and online learning, approaches\nbased on other methodologies such as game theory and robust\noptimization can be also applied to solve similar problems.\nIII. ADAPTIVITY TO DYNAMIC IOT ENVIRONMENTS\nThis section introduces methods for optimizing IoT perfor-\nmance under the (asymptotically) stationary assumption on IoT\ndynamics relative to control decisions in the fast timescale.\nCorresponding to different types of state dynamics in Table I,\nwe outline three classes of management schemes; see Fig. 2.\nA. Leveraging statistical learning for IoT management\nAs the generic problem (1), consider the IoT operator makes\na per-slot decision xt, subject to the short-term constraints that\nare collected in a compact set X (st) parameterized by the IoT\nstate st \u2208 S, as well as the long-term constraints that are\nexpressed as a time-varying penalty function g(xt; st) \u2208 RN .\nWith the IoT cost f(xt; st), we wish to find a sequence of\ndecisions {xt} that minimize the expected limiting-average\ncost subject to the long-term and short-term constraints, i.e.,\nf\u2217 := minimize\n{xt\u2208X (st), \u2200t}\nlim\nT\u2192\u221e\n1\nT\nT\u2211\nt=1\nE [f(xt; st)] (4a)\n6!\"#$%&'\n(&\"%)&%'\n!\"#$%&'\n(&\"%)&%'\n!\"#$%&'\n!\"#$#%&#'()*+'&,(\"-$.\"/(''&#0\n!\"/(1&%&#'()*+'&,(\"-$.\"/(''&#0\n!\"#$%&'\n(&\"%)&%'\n!#\"&#'()*+'&,(\"-$.\"/(''&#0\nFig. 2: Three levels of interaction between IoT operator (learner) and\nnature corresponding to the three assumptions in Table I.\nsubject to lim\nT\u2192\u221e\n1\nT\nT\u2211\nt=1\nE [g(xt; st)] \u2264 0 (4b)\nwhere E is taken over the random state st, and possible\nrandomness we may opt to introduce in the decision xt.\nComparing with (1), the infinite time horizon and the limiting\naverage cost are used in (4) and throughout this section\nfor mathematical simplicity. Indeed, assuming st is i.i.d. or\ngenerally stationary, the dynamic problem (4) shares the same\noptimal objective value as the following static problem [71]\nf\u2217 := minimize\n{pi(st)\u2208X (st), st}\nE [f(pi(st); st)]\nsubject to E [g(pi(st); st)] \u2264 0.\n(5a)\n(5b)\nTo this end, our goal is to determine a possibly randomized\npolicy pi that given an IoT state st, generates xt = pi(st)\nso as to minimize the average cost subject to both long- and\nshort-term constraints in (5). The infinite-dimension functional\noptimization problem (5) is more tractable in its dual form,\nwhich entails a finite number of variables [17], [76]. With\n\u03bb \u2208 RN+ denoting the multipliers, the Lagrangian of (5)\nis L(pi,\u03bb) := E[L(pi(st),\u03bb; st)] where the instantaneous\n(per state) Lagrangian is L(pi(st),\u03bb; st) := f(pi(st); st) +\n\u03bb>g(pi(st); st). Correspondingly, the dual problem of (5) is\nmaximize\n\u03bb\u22650\nD(\u03bb) := E [D(\u03bb; st)] (6)\nwhere D(\u03bb; st) := minx\u2208X (st) L(x,\u03bb; st). With the optimal\n\u03bb\u2217 obtained for the dual problem (6), the optimal policy for\nthe problem (5) could be retrieved as\npi\u2217(st) := arg min\nx\u2208X (st)\nL(x,\u03bb\u2217; st). (7)\nThe ensemble problem (6) is difficult to solve since the\nprobability density distribution of st is usually unknown.\nTo find the optimal multipliers \u03bb\u2217 in an efficient manner,\nexisting methods mainly rely on the stochastic subgradient-\nbased (SGD) methods [38], [71], [96]. However, SGD is\nTime\n\u2026 \u2026\nFig. 3: Timescale splitting for offline-aided online SAGA operations.\nIterates {\u03bbt} generate actual IoT decision, while \u03bb1|t, . . . ,\u03bbK|t are\nK virtual iterates updated via (9) at slot t; and \u03bbt+1 := \u03bbK|t.\nknown to suffer from slow convergence, which implies that the\nIoT network needs to implement sufficient many suboptimal\ndecisions generated during the transient stage of SGD.\nFrom a different viewpoint, given the huge volume of histor-\nical data generated by IoT networks, (6) was first formulated in\n[17] as a statistical learning task involving both offline training\nand online operational phases. The rationale is that historical\ndata contain statistics of the IoT states, and learning from\nthem can aid coping with the uncertainty of future management\ntasks, leading to reduced transient time of adaptive algorithms.\nSpecifically, with a training set of N0 historical IoT state\nsamples S\u02c60 := {sn, 1 \u2264 n \u2264 N0} available offline, (6) can be\nrecast in an empirical form via sample averaging as\nmax\n\u03bb\u22650\nD\u02c6S\u02c60(\u03bb), with D\u02c6S\u02c60(\u03bb) :=\n1\nN0\nN0\u2211\nn=1\nD\u02c6n(\u03bb)\u2212 \u000f\n2\n\u2016\u03bb\u20162 (8)\nwhere D\u02c6n(\u03bb) := D(\u03bb; sn), and \u000f > 0 is a regulariza-\ntion constant typically used in statistical learning to boost\ngeneralization capability [93]. Note that while an `2-norm\nregularizer is adopted in (8), other forms of regularization (e.g.,\n`1 and total-variation norm) are also possible depending on a-\npriori knowledge. Note that here t has been replaced by n to\ndifferentiate historical data from data in online phases.\nViewing (8) as a (negated) empirical risk minimization\n(ERM) task, we can resort to the state-of-the-art optimiza-\ntion methods for ERM, e.g., SAGA [33], that enjoys fast\nconvergence and low complexity. Using SAGA, per iteration\nk, we evaluate a single summand of the empirical gradi-\nent, i.e., \u2207D\u02c6\u03bd(k)(\u03bbk) at the iterate \u03bbk, with sample index\n\u03bd(k) \u2208 {1, . . . , N0} selected uniformly at random. Thus,\nthe computational complexity of SAGA is that of a SGD\niteration for (8). Furthermore, SAGA stores a collection of the\noutdated gradients {\u2207oldD\u02c6n} for all samples, where \u2207oldD\u02c6n\nwas evaluated by \u03bbk[n] \u2014 the most recent iteration k[n] that\nsn was drawn; i.e., k[n] := sup{k\u2032 : \u03bd(k\u2032) =n, k\u2032<k}. SAGA\ncombines the fresh gradient with the stored ones as\n\u03bbk+1 =\n[\n\u03bbk+\u03b1\n(\n\u2207D\u02c6\u03bd(k)(\u03bbk)\u2212\u2207oldD\u02c6\u03bd(k) +\u2207oldD\u02c6S\u02c60\n)]+\n(9)\nwhere \u03b1 is the pre-defined stepsize, and the stored gradients\nare \u2207oldD\u02c6S\u02c60 := (1/N)\n\u2211N\nn=1\u2207oldD\u02c6n \u2212 \u000f\u03bbk.\nThe merits of SAGA lie in the fact that its gradient estimator\nin (9) is still unbiased as that with SGD. In addition to the\nunbiasedness however, SAGA\u2019s gradient estimator attains con-\nsiderably lower variance than SGD thanks to the contribution of\nthe stored previous gradients, which is now termed the variance\nreduction technique prevalent in large scale machine learning\ntasks. Needless to mention the encouraging empirical results,\nthe SAGA in (9) is provably convergent to the optimum of (8)\n7with the linear convergence rate [17], [33]\nE\u03bd\n[\nD\u02c6\u2217S\u02c60 \u2212 D\u02c6S\u02c60(\u03bbk)\n]\n= O(\u03c1k) (10)\nwhere D\u02c6\u2217S\u02c60 is the optimal objective of (8), and \u03c1 \u2208 (0, 1) is\nthe linear rate depending on the objective function of (8).\nHence, in the offline phase, we run KN0 SAGA iterations\n(9) on set S\u02c60 - on average K iterations per sample. In the online\nphase, initialized with the offline output, SAGA (we term\nonline SAGA) keeps acquiring data st with a growing training\nset S\u02c6t := S\u02c6t\u22121 \u222a st. At slot t, online SAGA is initialized with\nthe last iterate of slot t \u2212 1, and updates \u03bbt by running K\niterations (9); see Fig. 3. The IoT decision is generated using\nthe current \u03bbt by pit(st) = arg minx\u2208X (st) L(x,\u03bbt; st). This\nis the key idea of offline-aided online IoT operations.\nThe offline-aided online scheme is not simply heuristic. In\nfact, the learning performance can be rigorously quantified via\nseveral concentration results in the learning theory [93], which\nuniformly bound the discrepancy between the empirical loss\n(8) and the loss (6) with high probability (whp), i.e.,\nsup\n\u03bb\u22650\n|D(\u03bb)\u2212 D\u02c6S\u02c6t(\u03bb)| \u2264 Hs(Nt), whp (11)\nwhere Hs(Nt) bounds the statistical error induced by the finite\nsize Nt of the training set S\u02c6t. Under proper (so-termed mixing)\nconditions, the law of large numbers guarantees that Hs(Nt) is\ngenerally in the order of O(\u221a1/Nt) [93, Section 3.4]. On the\nother hand, let Ho(KNt) upper bound the optimization error\nof solving (8) with S\u02c6t due to running on average only finite\n(K) iterations per sample; i.e., D\u02c6\u2217S\u02c6t\u2212D\u02c6S\u02c6t(\u03bbt) \u2264 Ho(KNt).\nOnline SAGA aims at a \u201csweet-spot\u201d between affordable\ncomplexity (controlled by K) and desirable overall learning\nerror, which accounts for both the optimization and statis-\ntical errors Hs(Nt) + Ho(KNt). Specifically, if we select\nN0 \u2265 3\u03ba/4 with \u03ba denoting the condition number of (8), and\nK \u2265 6, the optimization error is bounded by Ho(KNt) \u2264\nHs(Nt) [17]. In fact, even with K = 1, online SAGA can\nstill guarantee that Ho(KNt) = O (Hs(Nt)). With the link\nbetween the optimal policy and the optimal multiplier (7) in\nmind, the key message here is that with sufficient historical\nsamples, online SAGA only requires running a small number\nof iterations per slot to bring the optimization error close\nto the statistical accuracy provided by the current training\nset. Recent works along this line also include [36], [45] that\nfocused on algorithms for piecewise stationary environments.\nLearning more complex policies for non-interactive settings\nhas been also studied by leveraging deep neural networks\n[87]. Possible future research along this line also includes\ndeveloping algorithms under the assumption of stationarity\nin high-order moments, which is also pertinent in practice.\nAlgorithms tailored for fully nonstationary settings will be\npresented in Section IV.\nB. Learn-and-adapt approaches in semi-interactive settings\nThe IoT environment in Section III-A is non-interactive,\nmeaning that the dynamic of st+1 in (5) does not change\naccording to xt. The IoT states can be also driven by decisions,\nwhich include the job queue length in a data center [18], the\nlane length in a transportation network [42], as well as the\nAdapt       to        \nand generate\nAdaptationLearning\nAdd current     , \nand update    \nIoT operationMonitor IoT state     \nand\nFig. 4: A learn-and-adapt diagram for IoT management.\nbattery level in a smart grid [85], [95]. This section considers\nthe case where such IoT states appear in the constraints, but not\nin the objectives, which we call the semi-interactive settings.\nConsider an IoT network represented as a directed graph\nG = (N , E) with nodes N := {1, . . . , N} and edges E :=\n{1, . . . , E}. The node-incidence matrix is formed with (n, e)\nentry A(n,e) = 1(\u22121) if link e enters (leaves) node n, and\nA(n,e) = 0, otherwise. With ct \u2208 RN+ collecting the exogenous\nresources of all nodes per slot t, xt \u2208 RE for the endogenous\nresources across edges, the aggregate resource is Axt + ct.\nConnecting with (5), ct is included in the IoT state st, and the\nconstraint becomes g(xt; st) = Axt + ct. With qt collecting\nall buffered resources at slot t, we wish to solve (4) with the\nadditional state dynamics and the long-term constraints as\nqt+1 = [qt +Axt + ct]\n+\n, \u2200t (12a)\nlim\nT\u2192\u221e\n(1/T )\n\u2211T\nt=1E [\u2016qt\u2016] <\u221e. (12b)\nDue to the extra constraints in (12), the optimal objective of\nthis new problem is at least f\u2217 in (4). Furthermore, the dynamic\nof the interactive state qt (a.k.a. queues) in (12a) also accounts\nfor the transient performance of an adaptive algorithm. To see\nthis, suppose that under pi\u2217, it holds that Api\u2217(st) + ct =\n0, \u2200st; and consider the convergence path of policy pit induced\nby \u03bbt as pi1 \u2192 pi2 \u2192 pi3 = . . . = piT = pi\u2217, along with\nApi1(s1) + c1 = 10 and Api2(s2) + c2 = 5. In this case, if\nq1 = 0, then we have q2 = 10 and q3 = . . . = qT = 15.\nThe simple example entails two variable insights: i) con-\nstraint violations incurred by the sub-optimal decisions during\nthe transient stage (e.g., pi1,pi2) accumulate via qt; and ii) once\naccumulated in the transient stage, qt will not decrease in the\nsteady state (e.g., pit, t \u2265 3). This explains the suboptimal\nperformance tradeoff of SGD for (4) with (12); see also [21].\nTo better control the interactive state qt, it suffices to:\nS1) reduce the transient time of the adaptive algorithm; and,\nS2) diminish qt accumulated during the transient stage.\nFollowing this two guidelines, we adopt a procedure in\nthe online phase that we term online learning-and-adaptation\n(named use LA-SAGA henceforth); see a diagram in Fig. 4.\nRegarding S1), LA-SAGA performs the offline-aided online\nlearning as that in Fig. 3, by growing the training set S\u02c6t\nbased on which it better learns \u03bbt; and for S2), LA-SAGA\nsuperimposes \u03bbt to the instantaneous state (buffered resources)\nqt, and comes up with an effective multiplier as\n\u03b8t\ufe38 \ufe37\ufe37 \ufe38\neffective multiplier\n= \u03bbt\ufe38 \ufe37\ufe37 \ufe38\nstatistical learning\n+ \u00b5qt \u2212 b\ufe38 \ufe37\ufe37 \ufe38\nsystem interaction\n(13)\n8where \u00b5 tunes emphasis to statistical versus interactive state\ninformation, and b is a constant that corrects the possible bias\nin the steady-state - the intuition will become transparent soon.\nBased on \u03b8t, the real-time IoT decision xt is obtained by\nminimizing the Lagrangian over X (st); that is,\npit(st) = xt := arg min\nx\u2208X (st)\nL(x,\u03b8t; st). (14)\nNote that different from stochastic allocation that is solely\nbased on the system feedback \u03b8t = \u00b5qt [71], and statistical\nlearning that only relies on \u03b8t = \u03bbt, LA-SAGA can take\nadvantage of both through the use of effective multiplier \u03b8t.\nTo grasp how the effective multiplier accounts for S2),\nsuppose that after sufficient learning processes, \u03bbt \u2248 \u03bb\u2217, and\nqt is large so that \u00b5qt \u2212 b \u001d 0. In this case, we have the\n\u201cshadow price\u201d \u03b8t \u001d \u03bb\u2217, and thus xt obtained through (14)\nwould ensure that Axt + ct < 0 so that qt+1 < qt via (12a).\nIntuitively speaking, \u03b8t will eventually oscillate around \u03bb\u2217, and\nthus qt will oscillate around b/\u00b5 - this also suggests a positive\nb, otherwise it leads to a biased \u03b8t \u2265 \u03bb\u2217 since qt \u2265 0.\nRigorous analysis demonstrate that through a proper selec-\ntion of the bias b = O\u02dc(\u221a\u00b5), \u03b8t will converge to the O(\u221a\u00b5)-\nneighborhood of \u03bb\u2217 for (6); formally, we have [17]\nlim\nT\u2192\u221e\n(1/T )\n\u2211T\nt=1E [f (xt; st)]\u2212 f\u2217 = O(\u00b5) (15a)\nlim\nT\u2192\u221e\n(1/T )\n\u2211T\nt=1E [\u2016qt\u2016] = O\u02dc (1/\n\u221a\n\u00b5) (15b)\nwhich asserts that LA-SAGA is O(\u00b5)-optimal with an average\nqueue length O\u02dc(1/\u221a\u00b5) - an elegant [O(\u00b5), O\u02dc(1/\u221a\u00b5)] tradeoff.\nComparing with the tradeoff [O(\u00b5),O(1/\u00b5)] under Lyapunov\noptimization in [71], LA-SAGA [17], [21] improves the per-\nformance in terms of constraint violations (queue lengths).\nThe idea of incorporating learning into network optimization\nis pioneered in [46]. However, the developed learning mecha-\nnism therein suffers from the curse of dimensionality. Targeting\nlarge-scale IoT networks, LA-SAGA can tackle settings with\ncontinuous S and X with possibly infinite elements, and still\nbe amenable to efficient and scalable online operations. The\nimportant implication of the learn-and-adapt scheme is that\nit can perform the optimal IoT management, with reduced\nresources and improved QoS, namely, reduced queueing delay\nin data centers [21], faster virtual network function placement\n[23], and lower congestion in transportation networks, or\nsmaller battery capacity in power grids [52].\nAs a closing remark of this subsection, note that while the\nproblem considered in the semi-interactive setting here ex-\nplicitly contains queueing-type constraints, the semi-interactive\nsettings in fact cover a broader class of problems in IoT. For\ninstance, throughput maximization in UAV-enabled wireless\nnetworks under trajectory constraints also belongs to the class\nof semi-interactive IoT settings [100], [105].\nC. Reinforcement learning for interactive IoT environments\nThe IoT environment considered in Section III-B is semi-\ninteractive in the sense that only the dynamic of qt+1 (but\nnot st+1) changes according to xt through (12a). To broaden\nthe scope of the unified framework, this subsection introduces\nmethods tailored for the fully interactive setups, where the\ndynamic of IoT state st that can appear both in the objectives\nand the constraints is driven by the decision xt. This set-\nting captures the trajectory optimization in UAV-aided mobile\ncommunications, e.g., [100], [105], the dynamic caching with\nlimited storage units, e.g., [78], and the route planning in\nintelligent transportation, e.g., [106].\nFor simplicity, consider an IoT environment with a finite\nstate space S, and a finite action space X . The interaction\nbetween the operator and the IoT environment is uniquely\ncaptured by the transition probability of going from the current\nstate s to the subsequent state s\u2032 under action x \u2208 X (s) \u2286 X ,\ngiven by [Px]ss\u2032 := P(st+1 = s|st = s\u2032,xt = x). Similar to\n(5), the goal is to determine a possibly randomized policy pi\nthat given a state st, generates xt = pi(st) so as to minimize\nthe total discounted cost1, that is\nminimize\n{pi(st)\u2208X (st), st}\nlim\nT\u2192\u221e\nE\n[\nT\u2211\nt=1\n\u03b3t\u22121f (pi(st); st)\n]\n(16)\nwhere \u03b3 \u2208 (0, 1) is a discounting factor, and E is taken over\nthe sample path of {st}, as well as the random policy pi.\nFor a fixed policy pi, the state value function is defined as\nVpi(s) := lim\nT\u2192\u221e\nE\n[\nT\u2211\nt=1\n\u03b3t\u22121f (pi(st); st)\n\u2223\u2223\u2223s1 = s] (17)\nand the state-action value function (so-termed Q-function) is\nQpi(s,x) := f (x; s)+\u03b3Es\u2032|s,x [Vpi(s\u2032)], where E is taken over\nthe one-step transition from the current state s to s\u2032 under\naction x. With the optimal policy pi\u2217, we have that2\npi\u2217(s) := arg min\nx\u2208X (s)\nQ\u2217(s,x) (18)\nand V \u2217(s) = Q\u2217(s,pi\u2217(s)). Furthermore, the optimality con-\ndition of (16) that is termed Bellman optimality equation can\nbe written as (e.g., [90])\nQ\u2217(s,x)=f (x; s)+\u03b3Es\u2032|s,x\n[\nmin\nx\u2032\u2208X (s)\nQ\u2217(s\u2032,x\u2032)\n]\n, \u2200x, s (19)\nwhich is a system of nonlinear equations of Q\u2217 \u2208 R|S|\u00d7|X|.\nSwitching the goal from (16) to the fixed point of the Bell-\nman optimality equation (19), a classical yet popular approach\nis the so-termed Q-learning algorithm [98]:\nS1) At slot t, select the decision xt by\npit(st) = xt :=\n{\narg min\nx\u2208X (st)\nQt (st,x) w.p. 1\u2212 \u000ft\nrandom x \u2208 X (st) w.p. \u000ft\n(20)\nwhere \u000ft > 0 is a pre-defined exploration constant, and st+1\nis generated according to P(st+1 = s) = [Pxt ]sts.\nS2) Update the state-action value function as\nQt+1(st,xt) =Qt(st,xt)\n\u2212\u03b1t\n(\nf (xt; st) + \u03b3 min\nx\u2208X (st+1)\nQt(st+1,x)\n)\n(21)\nwhere \u03b1t is a pre-defined stepsize. Note that different from\nSections III-A and III-B, the explicit form of the objective\n1For simplicity, the infinite horizon discounted formulation is considered \u2014\na slight mismatch with the generic one (1). Other formulations with constraints\nor average costs can be also considered with additional assumptions [6].\n2We interchangeably use Q\u2217(s,x) = Qpi\u2217 (s,x) and V \u2217(s) = Vpi\u2217 (s).\n9function f ( \u00b7 ; st) does not need to be known per slot t. Instead,\nonly the functions values {f (x\u03c4 ; s\u03c4 )}t\u03c4=1 along the trajectory\n(s1,x1), \u00b7 \u00b7 \u00b7 , (st,xt) are assumed to be known. With properly\nselected {\u000ft, \u03b1t}, the simple Q-learning algorithm is provably\nconvergent under the finite state and action spaces (a.k.a.\ntabular case) [90]. To date, convergence of Q-learning and\nits variants is mostly asserted for the tabular case.\nTo scale up Q-learning in the large-scale settings, recent\nefforts have been devoted to infer Q by minimizing the residual\nof the Bellman optimality equation (19); that is,\nmin\nQ\n\u2211\nx,s\n(\nQ(s,x)\u2212 f (x; s)\u2212 \u03b3Es\u2032|s,x\n[\nmin\nx\u2032\u2208X (s)\nQ(s\u2032,x\u2032)\n])2\n.\n(22)\nAlbeit its simple expression, several fundamental challenges\narise when solving this fitting problem (22):\nC1) the optimization scale can be prohibitively huge due to the\npossibly large state and action spaces;\nC2) the unknown conditional expectation Es\u2032|s,x inside the\nsquare loss prevents an easy unbiased gradient estimator; and,\nC3) the max operator inside the square loss introduces non-\nsmoothness and non-convexity when performing optimization.\nTo tackle C1), function approximation methods have been\nstudied using linear or nonlinear (random) basis functions\n[13], [84]. Roughly speaking, given a state-action pair (x, s)\nalong with its pre-defined feature vector \u03c6x,s \u2208 Rd, existing\napproaches will approximate the Q-function by Q(s,x) :=\nz>(\u03c6x,s)\u03b8, where z(\u03c6x,s) \u2208 R2D is a lifted feature vector\n(e.g., random features or outputs of deep neural networks)\ngenerated from \u03c6x,s and \u03b8 \u2208 R2D is the wanted parameter\nvector. To this end, the task of finding the |S| \u00d7 |A| function\n(matrix) Q reduces to finding the 2D-dimensional vector\n\u03b8. Along this line, several recent works based on primal-\ndual solvers have made significant progress on simultaneously\nresolving C1) and C2) [30], [99]. Regarding C3), while it is\nstill an active research area, approaches leveraging smoothing\ntechniques for nonsmooth functions in convex optimization\nhave shed light on promising remedies [31], [70].\nIn addition to value iteration-based methods such as Q-\nlearning, approaches based on direct policy search such as\npolicy gradients and actor-critic methods are also prevalent\nnowadays, e.g., [83], [91], [108]. This key idea behind policy\ngradient is to update the \u03b8-parametrized policy pi\u03b8 using the\ngradient of the discounted objective (16) with respect to the\npolicy parameters [91]. Convergence of the policy gradient\nwith deep neural networks or kernel-based function approx-\nimators is now better understood than Q-learning, along with\nthe limitations of policy gradient-based methods that arise from\ntheir high variance.\nWe conclude this section by remarking that approaches in\nlight of the offline-aided-online learning have also been studied\nfor (16) under the name of experience replay, which achieves\ntremendous success in various artificial intelligence tasks [68].\nIV. SCALABILITY IN ONLINE LEARNING FOR IOT\nThe IoT settings considered in Section III involve slow-\nvarying IoT dynamics that are (asymptotically) stationary rel-\native to the timescale of making decisions. In large-scale IoT\nNature:\nLearner:\nConstraint:\nLearner:\nLoss:\nA full-information IoT setting\nA semi-bandit IoT setting\nNature:\nLearner:\nA bandit IoT setting\nFig. 5: Three forms of feedback in IoT environments (termed nature)\ncorrespond to three different types of information oracle in Table I.\nhowever, real-time control and communications entail slow\nand fast time scales that prompt scalable online solvers for\ngenerally nonstationary settings \u2014 the topics of this section.\nIn addition to the general non-stationarity, special attention\nwill be given to approaches designed under limited informa-\ntion about the environment, or equivalently, solvers requiring\nlimited computation and communication resources to sense the\nenvironment. Corresponding to different information that may\nbe available in IoT, we outline three classes of scalable online\nlearning approaches; see also Fig. 5 for a comparison.\nA. Constrained online learning for IoT management\nConsider a finite time horizon T . Per slot t, the IoT operator\nselects an action xt from a known and fixed convex set\nX \u2286 Rd, and the IoT environment (a.k.a. nature in OCO) then\nreveals a loss ft : Rd \u2192 R, along with a time-varying (possibly\nadversarial) penalty function gt : Rd \u2192 RN . The latter leads\nto a time-varying constraint gt(x) \u2264 0, which is driven by the\nunknown IoT dynamics. As in (1), the goal here is to generate\na sequence of decisions that minimize the aggregate loss, and\nensure that the constraints are satisfied in the long term on\naverage. Specifically, we wish to solve\nminimize\n{xt\u2208X ,\u2200t}\nT\u2211\nt=1\nft(xt) subject to\nT\u2211\nt=1\ngt(xt) \u2264 0. (23)\nComparing with the generic problem (1), we keep the time-\nvarying IoT state st implicit in (23), e.g., ft(xt) := f(xt; st)\nand gt(xt) := g(xt; st), since the algorithms introduced in this\nsection may not need to directly sense the state st. For (23), if\n{ft,gt} are known and T is not prohibitively large, the optimal\ndecisions can be found using any off-the-shelf batch solver.\nAlong with the potentially high complexity of batch solvers, a\nkey challenge is that loss and constraint functions in dynamic\nIoT setups are often unknown before allocating resources, due\nto unpredictable channel blocking, in millimeter wave links,\ndue to the unpredictable routing, network congestion, device\nmalfunctions, and nowadays malicious attacks.\n10\nConsider an edge layer with low-power sensors; a fog\nwith N nodes in N ; and, a cloud with multiple computing\ncenters [25]. Per slot t, each node n collects data requests dnt\nfrom nearby sensors, and has to decide among three options:\ni) offloading an amount \u03c7nt (from d\nn\nt ) to the cloud;\nii) offloading xnmt to node m for collaborative computing; and,\niii) processing an amount xnnt using the in-situ fog servers.\nVariable xt consists of all the decisions in i) - iii); see Fig. 6.\nSupposing that each fog node has a local queue to buffer\nunserved workloads, a long-term constraint is imposed to\nensure that the cumulative amount of served workloads is no\nless than the arrived amount over T slots; that is,\nT\u2211\nt=1\ngnt (xt) \u22640, \u2200n\ngnt (xt) := d\nn\nt +\n\u2211\nm\u2208N inn\nxmnt \u2212\n\u2211\nm\u2208N outn\nxnmt \u2212 \u03c7nt \u2212 xnnt (24)\nwhere N inn (N outn ) is the set of fog nodes with in-coming (out-\ngoing) links to (from) node n. Clearly, amounts \u03c7nt , x\nnm\nt , and\nxnnt have caps depending on the communication protocols and\ncomputing cores in use. With x\u00af collecting all these caps, the\nfeasible set is X :={0 \u2264 xt \u2264 x\u00af}.\nAmong candidate figures of merit in optimizing xt, is\nnetwork delay of the online edge processing and offloading\ndecisions [9], [22]. Specifically, the latency associated with \u03c7nt\nis mainly due to the communication delay, which can be mod-\neled as a time-varying convex function lnt (\u03c7\nn\nt ). Likewise, the\ncommunication delay related to xnmt is denoted by l\nnm\nt (x\nnm\nt ).\nIn addition, latency pertaining to xnnt comes from its limited\ncomputation capability, which can be modeled as a function\nhnt (x\nnn\nt ) capturing dynamics during the computing processes.\nThe overall performance in allocating xt is quantified by\naggregate latency metrics. Those include computational (lt)\nand communication delays (ht), namely\nft(xt) :=\n\u2211\nn\u2208N\n(\nlnt (\u03c7\nn\nt ) +\n\u2211\nm\u2208N outn l\nnm\nt (x\nnm\nt ) +h\nn\nt (x\nnn\nt )\n)\n.(25)\nWhile the aggregate delay in some cases cannot directly\nreflect user experience, a viable alternative is the maximum\nof computational and communication delays; see e.g., [22].\nWhile the average-delay objective presumed in (23) may not\nbe the optimal performance metric in some mission critical\napplications, our formulation can also cover the probabilistic\ndelay requirements. The per-slot objective of the latter is an\nindicator function of the delay given by\nft(xt) :=\n\u2211\nn\u2208N\n1\n{(\nlnt (\u03c7\nn\nt ) +\n\u2211\nm\u2208N outn\nlnmt (x\nnm\nt ) + h\nn\nt (x\nnn\nt )\n)\n\u2264 l\u00af\n}\n(26)\nwhere l\u00af is a pre-defined upper bound of user delay. The price\npaid is that the resultant problem is nonconvex, which can be\ntackled by e.g., the approach in Section IV-C.\nWith ft(xt) as in (25) and constraints as in (24), the solution\nof (23) aims to minimize the aggregate delay, while serving\nall IoT demands in the long term. Looking forward, more\nintriguing is to find such an optimal strategy in a fully causal\nsetting, where {ft(xt), dnt } are unknown when deciding xt,\nEdges\nCloud center\nFog clusters\nEdges\nFig. 6: A diagram for mobile computation offloading: IoT devices at\nthe edge layer; fog clusters contain locally connected fog nodes, and\nthe data center in the cloud layer.\nbut are revealed at the end of slot t after deciding xt.\nTo gauge the performance of online decisions, static regret\nis adopted by OCO to measure how far the aggregate loss of\nan OCO algorithm is from the best fixed solution in hindsight\n[109]. Since a static regret relies on a rather coarse benchmark,\nwhich is less useful in dynamic IoT [16], we are motivated to\npursue the so-termed dynamic regret given by\nRegdT :=\nT\u2211\nt=1\nft(xt)\u2212\nT\u2211\nt=1\nft(x\n\u2217\nt ) (27a)\nwith x\u2217t \u2208 arg min\nx\u2208X\nft(x), subject to gt(x)\u22640 (27b)\nwhere the benchmark is now formed using the best sequence\n{x\u2217t } for the instantaneous problem, subject to the instan-\ntaneous constraint. The metric in (5) is more suitable for\nassessing performance of dynamic IoT networks than its static\ncounterpart in [109], because a sub-linear dynamic regret\nimplies a sub-linear static one, but the converse is not true.\nRegarding feasibility of online decisions, the dynamic fit is\nalso useful to quantify the accumulated violations, that is\nFitdT :=\n\u2225\u2225\u2225\u2225\u2225\n[\nT\u2211\nt=1\ngt(xt)\n]+\u2225\u2225\u2225\u2225\u2225. (28)\nThe long-term constraint implicitly assumes that the instanta-\nneous constraint violations can be compensated by subsequent\nstrictly feasible decisions, thus allowing adaptation of fog\ndecisions to the unknown dynamics of IoT user demands.\nUnder the metrics in (27) and (28), an ideal algorithm will\nbe one that achieves both sub-linear dynamic regret and sub-\nlinear dynamic fit. A sub-linear dynamic regret implies \u201cno-\nregret\u201d relative to the clairvoyant dynamic solution on the long-\nterm average; i.e., limT\u2192\u221eRegdT /T = 0, while a sub-linear\ndynamic fit indicates that the online strategy is also feasible\non average; i.e., limT\u2192\u221e FitdT /T = 0.\nWith \u03bb \u2208 RN+ denoting the Lagrange multiplier vector, the\nLagrangian of (23) is\nLt(x,\u03bb) := ft(x) + \u03bb>gt(x). (29)\nBuilding on (29), an online scheme termed modified saddle-\npoint (MOSP) approach has been developed first in [16] and\nlater in [102]. We use the low-complexity variant in [102] for\nthe subsequent illustration. Given xt and \u03bbt, the decision xt+1\nis\nxt+1 = PX (xt \u2212 \u03b1\u2207xLt(xt,\u03bbt)) (30)\n11\nwhere PX (y) := arg minx\u2208X \u2016x \u2212 y\u20162; \u03b1 is a pre-defined\nconstant; and, \u2207xLt(xt,\u03bbt) = \u2207ft(xt) +\u2207>gt(xt)\u03bbt is the\ngradient of Lt(x,\u03bbt) with respect to (w.r.t.) x. In addition, the\ndual update takes the modified online gradient ascent form\n\u03bbt+1 =\n[\n\u03bbt + \u00b5(gt(xt) +\u2207>gt(xt)(xt+1 \u2212 xt))\n]+\n(31)\nwhere \u00b5 is the stepsize, and gt(xt) the gradient of Lt(xt,\u03bb)\nw.r.t. \u03bb. Note that (31) is a modified gradient update since the\ndual variable is updated along the first-order approximation of\ngt(xt+1) at xt rather than the commonly used gt(xt).\nWith properly chosen stepsizes, MOSP enjoys dynamic\nregret and fit bounded by [16]\nRegdT =O\n(\nV(x\u22171:T )T\n1\n2\n)\nand FitdT = O\n(\nT\n1\n2\n)\n(32)\nwhere V(x\u22171:T ) is the accumulated variation of the per-slot\nminimizers x\u2217t in (27) given by V(x\u22171:T ) :=\n\u2211T\nt=1 \u2016x\u2217t\u2212x\u2217t\u22121\u2016.\nIn words, MOSP\u2019s dynamic fit is sub-linear, and its dynamic\nregret is also sub-linear, so long as the variation of the\nminimizers is slow enough; i.e., V(x\u22171:T ) = o(\n\u221a\nT ).\nRelevant approaches developed in similar settings also in-\nclude [11], [32], [55]. Specifically, OCO with switching cost\nhas been studied in [55], and feedback-based tracking algo-\nrithms have been developed in [11], [32].\nRemark 1 (Learning via task-adaptive stepsizes). The primal\nupdate (30) can be refined by adjusting each entry of the\ngradient using a per-entry stepsize in accordance with \u201ceach\nthing\u201d in IoT applications [22]. Such an adaptive stepsize can\nbe regarded as an inexpensive approximation of the Hessian\nused in the online Newton iteration [35]. Using edge computing\nas a paradigm, [22] showed that task-adaptive stepsizes can\nmarkedly reduce the network delay when the underlying IoT\ntasks are heterogeneous, where the resultant gradients could\nhave distinct orders of magnitude over different coordinates.\nB. Constrained convex bandit learning for IoT management\nThe online recursions (30) and (31) remain operational under\nthe premise that the loss functions are known, or, their gradients\nare readily available. Clearly, none of these assumptions is\nalways satisfied in IoT, because i) the loss function capturing\nuser dissatisfaction, e.g., service latency or reliability, can be\nhard to model in dynamic settings; and, ii) even if model-\ning is possible, the low-power devices may not afford the\ncomplexity of running statistical learning tools such as deep\nneural networks online. These considerations motivate online\nbandit saddle-point (BanSP) methods to broaden the scope of\nMOSP to IoT settings where the gradient is unavailable or\ncomputationally costly [19].\nThe key idea behind bandit learning is to construct (prefer-\nably stochastic) gradient estimates using limited function value\ninformation [37], [72]. Consider first a learner only observing\nthe value of ft(x) at a single point x per slot t. The crux is to\nconstruct a (possibly unbiased) estimate of the gradient using\nthis single piece of feedback - what is interestingly possible\nby one random function evaluation [37]. The intuition is easy\nto grasp in the one-dimensional case: For a binary variable u\ntaking values {\u22121, 1} equiprobably, and a small \u03b4 > 0, the\ndifference approximation of the derivative f \u2032t at x yields\nf \u2032t(x) \u2248\nft(x+ \u03b4)\u2212 ft(x\u2212 \u03b4)\n2\u03b4\n= Eu\n[u\n\u03b4\nft(x+ \u03b4u)\n]\n(33)\nwhere the equality follows from the definition of expectation.\nDropping Eu, the scaled single-value evaluation ft(x+\u03b4u)u/\u03b4\nis a nearly unbiased estimator of f \u2032t(x). Generalizing this\napproximation to higher dimensions, with a random vector u\ndrawn from the surface of a unit sphere, the scaled function\nevaluation at a perturbed point x + \u03b4u yields an estimate of\nthe gradient \u2207ft(x), given by [37]\n\u2207ft(x) \u2248 Eu\n[\nd\n\u03b4\nft(x+ \u03b4u)u\n]\n:= Eu\n[\n\u2207\u02c6ft(x)\n]\n(34)\nwhere we define one-point gradient \u2207\u02c6ft(x) := d\u03b4 ft(x+ \u03b4u)u.\nBuilding upon (34), consider the primal update (cf. (30))\nx\u02c6t+1 = P(1\u2212\u03b3)X\n(\nx\u02c6t \u2212 \u03b1\n(\n\u2207\u02c6ft(x\u02c6t) +\u2207>gt(x\u02c6t)\u03bbt\n))\n(35)\nwhere (1 \u2212 \u03b3)X := {(1 \u2212 \u03b3)x : x \u2208 X} is a subset of X ,\nand \u03b3 \u2208 [0, 1) is a pre-selected constant dependent on \u03b4. In\nthe full-information case, xt in (30) is the learner\u2019s action,\nwhereas in the bandit case the learner\u2019s action is xt := x\u02c6t+\u03b4ut,\nwhich is the point for function evaluation instead of x\u02c6t in (35).\nProjection in (35) is on a smaller convex set (1\u2212\u03b3)X in (35),\nwhich ensures feasibility of the perturbed xt \u2208 X . Similar to\n(31), the dual update of BanSP is given by\n\u03bbt+1 =\n[\n\u03bbt + \u00b5(gt(x\u02c6t) +\u2207>gt(x\u02c6t)(x\u02c6t+1 \u2212 x\u02c6t))\n]+\n(36)\nwhere x\u02c6t rather than xt is used in this update. Compared with\n(30)-(31), the updates (35)-(36) with one-point bandit feedback\ndo not increase computation or memory requirements; hence,\nthey provide a light-weight surrogate for MOSP to enable\ngradient-free online bandit IoT network optimization.\nIf the mild conditions in [19] are satisfied, the online\ndecisions generated by BanSP yield\nE\n[\nRegdT\n]\n=O\n(\nV(x\u22171:T )T\n3\n4\n)\nand E\n[\nFitdT\n]\n=O(T 34 ) (37)\nwhere E is taken over the sequence of the random actions xt\nwith randomness induced by {ut} perturbations.\nDepending on the underlying dynamics, BanSP can afford\none or multiple loss function evaluations (bandit feedback) per\nslot. If BanSP is endowed with M > 2 function evaluations,\nthe gradient estimate will be more accurate by querying the\nfunction values over M points in the neighborhood of x\u02c6t.\nIntuitively, the performance of BanSP will improve if multiple\nevaluations are available per slot. Indeed, the dynamic regret\nis provably O(V(x\u22171:T )T 12 ), and the dynamic fit FitdT =\nO(T 12 ) [19], which markedly improve upon their single-\npoint counterparts, and reduce to MOSP bounds in the full-\ninformation case (cf. (32)).\nC. Constrained multi-armed bandit learning\nThe salient assumption so far is that IoT decisions belong\nto a time-invariant convex set X . However, IoT devices usu-\nally exhibit time-varying connectivity to the backbone due to\nmobility and cyber attacks, while network configurations are\noften selected from pre-determined protocols. In this context,\n12\nFull informationSemi-banditBandit\nInformation\nL\no\nss\n i\nn\n (\n2\n3\n) \nF\ne\na\nsi\nb\nle\n s\ne\nt \no\nf \n(2\n3\n)\nN\no\nn\nc\no\nn\nv\ne\nx\n \nD\nis\nc\nre\nte\nC\no\nn\nv\ne\nx\nC\no\nn\nti\nn\nu\no\nu\ns\n \nEXP3SP\nBanSP MOSP\nTAOSP\nApplicability\nFig. 7: A summary of learning approaches corresponding to Fig. 5.\nmulti-armed bandit (MAB) methods can be employed to extend\nBanSP when X is time-varying and discrete [51], [53].\nConsider the discrete feasible set X := {x1, . . . ,xK} with\ntotal K possible actions (a.k.a. arms in MAB). To account for\ndynamics, only the actions in Xt \u2286 X are available per slot t;\ne.g., xt \u2208 Xt. The availability of actions could be stochastic,\nfollowing a certain probability distribution; or even adversarial,\nin which case nature can arbitrarily choose Xt.\nPer slot t, collect the objective values of all actions into\nvector ft := [ft(x1), . . . , ft(xK)]>, and likewise the con-\nstraints into matrix Gt :=[gt(x1), . . . ,gt(xK)]\u2208RN\u00d7K . If the\nlearner\u2019s strategy is to select an action xt = xk with k from a\ndistribution k \u223c pt \u2208 RK , then (23) can be re-formulated as\nan optimization problem over distributions {pt}, namely\nminimize\n{pt\u2208\u2206(Xt),\u2200t}\nT\u2211\nt=1\nf>t pt subject to\nT\u2211\nt=1\nGtpt \u2264 0 (38)\nwhere the Xt-supported \u201cprobability simplex\u201d is defined as\n\u2206(Xt) :=\n{ \u2211\nxk\u2208Xt\np(xk) = 1; p(xk) \u2265 0; p(xk) = 0,xk /\u2208 Xt\n}\n.\n(39)\nIt is worth mentioning that ft(xk) and gt(xk) are well defined\neven when the action xk /\u2208 Xt is not available, and the values\nft(x\nk) and gt(xk) are not revealed.\nIn order to employ an MOSP solver for (38), the gradient of\nthe associated Lagrangian is needed, meaning ft and Gt must\nbe known. The challenge is that such information is hardly\navailable in large-scale IoT settings, where one only knows\nft(xt) and gt(xt) given that xt is implemented. The time-\nvarying action set also prevents a direct implementation of\nBanSP to solve (38). To tackle such a challenging setting, a\nnovel EXP3SP algorithm was developed in our recent work\n[53] that builds on the elegant exponential-weight algorithm\nfor exploration and exploitation (EXP3) [8].\nPer slot t, the learner observes the action set Xt, and selects\nxt according to the current distribution pt given by\npt(x\nk) =\np\u02dct(x\nk)1(xk \u2208 Xt)\u2211\nxk\u2208X p\u02dct(xk)1(xk \u2208 Xt)\n, \u2200xk \u2208 X (40)\nwhere p\u02dct(xk) is the unnormalized weight of xk at slot t, the\nvalue of which will be specified later. Once ft(xt) and gt(xt)\n!\"#$%&'$#(\n)*&+&,#--.\n/01-'$,)\n&..*%\"#$\n0,.\n233-..$4'-\n5\n$,60+%&#$0\n,\n2')0+$#7%5\n.3&'&4$'$#(\n2')0+$#7%5\n&1&\"#$8$#(\nFig. 8: The tradeoff among modeling assumptions, accessible infor-\nmation, algorithm adaptivity, scalability and optimality guarantees.\nbecome available, unbiased estimates of ft and Gt are [53]\nf\u02c6t(x\nk) =\nft(x\nk)1(xt = x\nk)\npt(xk)\n, \u2200xk \u2208 X (41a)\ng\u02c6t(x\nk) =\ngt(x\nk)1(xt = x\nk)\npt(xk)\n, \u2200xk \u2208 X . (41b)\nAdopting the gradient estimators in (41), the primal update\nuses the exponential gradient recursion, namely, \u2200xk \u2208 X\np\u02dct+1(x\nk) = p\u02dct(x\nk) exp\n[\n\u2212\u00b5\n(\nf\u02c6t(x\nk) + \u03bb>t g\u02c6t(x\nk)\n)]\n. (42)\nThe weight p\u02dct+1 is in turn used to generate the action\ndistribution in the next slot (cf. (40)). The dual update is\n\u03bbt+1 =\n[\n\u03bbt + \u00b5\n(\nG\u02c6tpt \u2212 \u03b4\u00b5\u03bbt\n)]+\n(43)\nwhere \u03b4 is a tuned constant to ensure a bounded multiplier.\nIf Xt is stochastic, EXP3SP achieves both sub-linear regret\nand fit [53]. A robust modification of EXP3SP has been also\ndeveloped recently to cope with adversaries blocking access of\nIoT devices to their edge servers [51], while further securing\nedge computing and ensuring sub-linear regret and fit. A\nremark is now in order on a scalable rendition of EXP3SP.\nOur scalable online learning schemes are recapped in Fig. 7.\nV. LESSONS LEARNED AND THE ROAD AHEAD\nWe have presented a unified framework for deriving and\nanalyzing adaptive and scalable network design and resource\nallocation schemes for IoT. Leveraging the contemporary\ncommunication, networking and optimization advances, the\nresultant online learning and management policies not only\nfacilitate low-complexity and scalable implementations with\nlimited feedback, but also enjoy efficient adaptation to chang-\ning environments with analytical performance guarantees.\nThe proposed framework lays a solid analytical foundation to\ndelineate the tradeoffs among performance guarantees, degree\nof (non-)stationarity in modeling IoT dynamics, algorithm\nscalability, and levels of accessible information; see Fig. 8.\nModeling assumptions vs optimality guarantees. While both\ndeal with IoT management with unknown dynamics, the mod-\neling assumptions in Sections III and IV differ considerably.\nSpecifically, those in Section III assume a generally stationary\nIoT environment that corresponds to either the simplest i.i.d.\ncase, or to the Markovian case eventually converging to a\nstationary distribution. In contrast, the approaches in Section\nIV can afford arbitrary dynamics even those manipulated by\nadversaries. However, such minimal assumption does not come\nfor free. As a matter of fact, the performance guarantee in\nterms of the sublinear regret in Section IV is weaker than the\noptimality gap in Section III \u2014 see an analytical comparison in\n13\n[16]. Nevertheless, as the effectiveness of the optimal solution\nin Section III also depends on the discrepancy between the real\nIoT settings and the modeled stationary ones, the actual online\nperformance of these approaches requires further evaluation.\nThe vantage point of this overview opens up a number of\nexciting directions for future research.\nDistributed machine learning. Considering the massive\namount of mobile devices in IoT, centralized learning becomes\ncomputationally intractable, and also rises serious privacy con-\ncerns. To date, the widespread consensus is that besides data\ncenters at the cloud, future machine learning and artificial in-\ntelligence tasks have to be performed starting from the network\nedge, namely mobile devices. This is the overarching goal of\nthe emerging federated learning paradigm [66], [67]. Towards\nthis goal, future challenges and opportunities include reducing\nthe communication overhead during the distributed learning\nprocesses, and enhancing the robustness of learning algorithms\nunder adversarial attacks. Recent advances in the direction of\ncommunication-efficient learning include the adaptive commu-\nnication mechanism in [20] that enjoys the first provably bound\non the reduced number of communication rounds. Challenges\nof distributed learning also lie in asynchrony and delay intro-\nduced by e.g., IoT mobility and heterogeneity. Asynchronous\nparallel learning schemes are thus worth investigating by lever-\naging advances in static optimization settings [14], [75]. From\ndistributed machine learning to distributed control, multi-agent\nreinforcement learning will play a critical role in distributed\ncontrol for IoT [58]. A decentralized actor-critic algorithm has\nbeen recently developed in [108] for multi-agent reinforcement\nlearning over networked agents, and further generalized to\ntasks with large continuous state and action spaces [107].\nCommunication, computation and control co-design. The\npast decade has witnessed the convergence of the commu-\nnication and computing processes [10]. The current brief is\nthat next-generation communication networks should support\nemerging large-scale control applications in IoT with mil-\nlions of diverse devices over a large geographical area. This\ncalls for co-designing communication, computing, and control\nmechanisms. The challenges naturally arise in developing the\ndesired network architecture, the role of different network\nentities, pertinent performance metrics, and the corresponding\npolicies to simultaneously satisfy the timeliness, reliability and\nefficiency of all three intertwined systems.\nOver the decades, the focus of wireless communications has\nbeen anytime, anywhere, anyone connection of the humans,\nwhereas the emerging IoT paradigm largely extends the scope\nof wireless networking to connecting everything, along the\nhumans-to-things and things-to-things continuum. The IoT\nchallenges such as extreme heterogeneity, unpredictable dy-\nnamics and massive scale, call for game-changing innovations\nin network design and management. We hope that the proposed\nunified framework can serve as a stepping stone that leads\nto systematic designs and rigorous analysis of adaptive and\nscalable learning and management schemes for IoT, and a host\nof new research venues to pursue.\nREFERENCES\n[1] Further LTE Physical Layer Enhancements for MTC. Document RP-\n141660, 3GPP TSG RAN Meeting 65, Ericsson, Nokia, 2014.\n[2] Narrowband IoT (NB-IoT). document RP-151621, 3GPP TSG RAN\nMeeting 69, Qualcomm, 2015.\n[3] \u201cWhite paper: A new approach to IoT secu-\nrity,\u201d Jun. 2015. [Online]. Available: www.pubnub.com/blog/\n2015-06-29-white-paper-a-new-approach-to-iot-security/\n[4] G. A. Akpakwu, B. J. Silva, G. P. Hancke, and A. M. Abu-Mahfouz,\n\u201cA survey on 5G networks for the Internet of Things: Communication\ntechnologies and challenges,\u201d IEEE Access, vol. 6, pp. 3619\u20133647,\n2018.\n[5] A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari, and\nM. Ayyash, \u201cInternet of Things: A survey on enabling technologies,\nprotocols, and applications,\u201d IEEE Communications Surveys & Tutori-\nals, vol. 17, no. 4, pp. 2347\u20132376, 2015.\n[6] E. Altman, Constrained Markov decision processes. Boca Raton, FL:\nChapman & Hall, 1999.\n[7] L. Atzori, A. Iera, and G. Morabito, \u201cThe Internet of Things: A survey,\u201d\nComputer Networks, vol. 54, no. 15, pp. 2787\u20132805, Oct. 2010.\n[8] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire, \u201cThe non-\nstochastic multiarmed bandit problem,\u201d SIAM Journal on Computing,\nvol. 32, no. 1, pp. 48\u201377, 2002.\n[9] S. Barbarossa, S. Sardellitti, E. Ceci, and M. Merluzzi, \u201cThe edge\ncloud: A holistic view of communication, computation and caching,\u201d\nin Cooperative and Graph Signal Processing, P. Djuric and C. Richard,\nEds. Springer, 2018. [Online]. Available: arXivpreprint:1802.00700\n[10] S. Barbarossa, S. Sardellitti, and P. Di Lorenzo, \u201cCommunicating while\ncomputing: Distributed mobile cloud computing over 5G heterogeneous\nnetworks,\u201d IEEE Sig. Proc. Mag., vol. 31, no. 6, pp. 45\u201355, 2014.\n[11] A. Bernstein, E. Dall\u2019Anese, and A. Simonetto, \u201cOnline optimization\nwith feedback,\u201d arXiv preprint:1804.05159, Apr. 2018.\n[12] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli, \u201cFog computing and\nits role in the Internet of Things,\u201d in Proc. of the MCC workshop on\nMobile Cloud Comp. ACM, 2012, pp. 13\u201316.\n[13] L. Busoniu, R. Babuska, B. De Schutter, and D. Ernst, Reinforcement\nLearning and Dynamic Programming Using Function Approximators.\nBoca Raton, FL: Taylor & Francis Group, 2010.\n[14] L. Cannelli, F. Facchinei, V. Kungurtsev, and G. Scutari, \u201cAsynchronous\nparallel algorithms for nonconvex big-data optimization: Model and\nconvergence,\u201d arXiv preprint:1607.04818, Jul. 2016.\n[15] N. Cesa-Bianchi and G. Lugosi, Prediction, Learning, and Games.\nCambridge, UK: Cambridge University Press, 2006.\n[16] T. Chen, Q. Ling, and G. B. Giannakis, \u201cAn online convex optimization\napproach to proactive network resource allocation,\u201d IEEE Trans. Signal\nProcessing, vol. 65, no. 24, pp. 6350\u20136364, Dec. 2017.\n[17] T. Chen, A. Mokhtari, X. Wang, A. Ribeiro, and G. B. Giannakis,\n\u201cStochastic averaging for constrained optimization with application to\nonline resource allocation,\u201d IEEE Trans. Signal Processing, vol. 65,\nno. 12, pp. 3078\u20133093, Jun. 2017.\n[18] T. Chen, X. Wang, and G. B. Giannakis, \u201cCooling-aware energy and\nworkload management in data centers via stochastic optimization,\u201d\nIEEE J. Sel. Topics Signal Process., vol. 10, no. 2, pp. 402\u2013415, Mar.\n2016.\n[19] T. Chen and G. B. Giannakis, \u201cBandit convex optimization for scalable\nand dynamic IoT management,\u201d IEEE Internet Things J., May 2018,\nto appear. [Online]. Available: https://arxiv.org/pdf/1707.09060.pdf\n[20] T. Chen, G. B. Giannakis, T. Sun, and W. Yin, \u201cLAG: Lazily\naggregated gradient for communication-efficient distributed learning,\u201d\nin Proc. Advances in Neural Info. Process. Syst., Montreal, Canada,\nDec. 2018. [Online]. Available: arxiv.org/abs/1805.09965\n[21] T. Chen, Q. Ling, and G. B. Giannakis, \u201cLearn-and-adapt stochastic\ndual gradients for network resource allocation,\u201d IEEE Trans. Control of\nNetwork Systems, to appear, 2018.\n[22] T. Chen, Y. Shen, Q. Ling, and G. B. Giannakis, \u201cHeterogeneous online\nlearning for \u2018thing-adaptive\u2019 low-latency fog computing in IoT,\u201d IEEE\nInternet Things J., Oct. 2018, to appear.\n[23] X. Chen, W. Ni, T. Chen, I. B. Collings, X. Wang, R. P. Liu, and G. B.\nGiannakis, \u201cMulti-timescale online optimization of network function\nvirtualization for service chaining,\u201d arXiv preprint:1804.07051, Apr.\n2018.\n[24] X. Chen, L. Jiao, W. Li, and X. Fu, \u201cEfficient multi-user computa-\ntion offloading for mobile-edge cloud computing,\u201d IEEE/ACM Trans.\nNetworking, vol. 24, no. 5, pp. 2795\u20132808, 2016.\n[25] M. Chiang and T. Zhang, \u201cFog and IoT: An overview of research\nopportunities,\u201d IEEE Internet Things J., vol. 3, no. 6, pp. 854\u2013864,\n2016.\n14\n[26] W. Chu, M. Dehghan, J. C. Lui, D. Towsley, and Z.-L. Zhang, \u201cJoint\ncache resource allocation and request routing for in-network caching\nservices,\u201d Computer Networks, vol. 131, pp. 1\u201314, Feb. 2018.\n[27] W. Chu, M. Dehghan, D. Towsley, and Z.-L. Zhang, \u201cOn allocating\ncache resources to content providers,\u201d in Proc. ACM Conf. on Info.-\nCentric Netw., Kyoto, Japan, Sep. 2016, pp. 154\u2013159.\n[28] M. Costa, M. Codreanu, and A. Ephremides, \u201cOn the age of information\nin status update systems with packet management,\u201d IEEE Trans. Info.\nTheory, vol. 62, no. 4, pp. 1897\u20131910, Apr. 2016.\n[29] E. Cuervo, A. Balasubramanian, D.-k. Cho, A. Wolman, S. Saroiu,\nR. Chandra, and P. Bahl, \u201cMaui: making smartphones last longer with\ncode offload,\u201d in Proc. of Intl. Conf. on Mobile Systems, App., and\nServices, San Francisco, CA, Jun. 2010, pp. 49\u201362.\n[30] B. Dai, N. He, Y. Pan, B. Boots, and L. Song, \u201cLearning from\nconditional distributions via dual embeddings,\u201d in Proc. Intl. Conf. on\nArtificial Intelligence and Statistics, Fort Lauderdale, FL, Apr. 2017.\n[31] B. Dai, A. Shaw, L. Li, L. Xiao, N. He, J. Chen, and L. Song,\n\u201cSmoothed dual embedding control,\u201d in Proc. NIPS Symp. Deep Re-\ninforcement Learning, Long Beach, CA, Dec. 2017.\n[32] E. Dall\u2019Anese and A. Simonetto, \u201cOptimal power flow pursuit,\u201d IEEE\nTrans. Smart Grids, vol. 9, no. 2, pp. 942\u2013952, Mar. 2018.\n[33] A. Defazio, F. Bach, and S. Lacoste-Julien, \u201cSAGA: A fast incremental\ngradient method with support for non-strongly convex composite ob-\njectives,\u201d in Proc. Advances in Neural Info. Process. Syst., Montreal,\nCanada, Dec. 2014, pp. 1646\u20131654.\n[34] L. Duan, L. Huang, C. Langbort, A. Pozdnukhov, J. Walrand, and\nL. Zhang, \u201cHuman-in-the-loop mobile networks: a survey of recent\nadvancements,\u201d IEEE J. Sel. Areas Commun., vol. 35, no. 4, pp. 813\u2013\n831, Apr. 2017.\n[35] J. C. Duchi, E. Hazan, and Y. Singer, \u201cAdaptive subgradient methods\nfor online learning and stochastic optimization,\u201d Journal of Machine\nLearning Research, vol. 12, pp. 2121\u20132159, Jul. 2011.\n[36] M. Eisen, K. Gatsis, G. J. Pappas, and A. Ribeiro, \u201cLearning\nin wireless control systems over non-stationary channels,\u201d arXiv\npreprint:1803.01078, Mar. 2018.\n[37] A. D. Flaxman, A. T. Kalai, and H. B. McMahan, \u201cOnline convex\noptimization in the bandit setting: gradient descent without a gradient,\u201d\nin Proc. of ACM SODA, Vancouver, Canada, Jan. 2005, pp. 385\u2013394.\n[38] N. Gatsis, A. Ribeiro, and G. B. Giannakis, \u201cA class of convergent\nalgorithms for resource allocation in wireless fading networks,\u201d IEEE\nTrans. Wireless Commun., vol. 9, no. 5, pp. 1808\u20131823, May 2010.\n[39] B. Gerhardt, K. Griffin, and R. Klemann, \u201cUnlocking value in the frag-\nmented world of big data analytics,\u201d Cisco Internet Business Solutions\nGroup, Jun. 2012.\n[40] G. B. Giannakis, V. Kekatos, N. Gatsis, S.-J. Kim, H. Zhu, and B. F.\nWollenberg, \u201cMonitoring and optimization for power grids: A signal\nprocessing perspective,\u201d IEEE Sig. Proc. Mag., vol. 30, no. 5, pp. 107\u2013\n128, Sep. 2013.\n[41] A. M. Gonz\u00e1lez, A. M. S. Roque, and J. Garc\u00eda-Gonz\u00e1lez, \u201cModeling\nand forecasting electricity prices with input/output hidden Markov\nmodels,\u201d IEEE Trans. Power Syst., vol. 20, no. 1, pp. 13\u201324, Feb. 2005.\n[42] J. Gregoire, X. Qian, E. Frazzoli, A. de La Fortelle, and T. Wongpirom-\nsarn, \u201cCapacity-aware backpressure traffic signal control,\u201d IEEE Trans.\nControl of Network Systems, vol. 2, no. 2, pp. 164\u2013173, June 2015.\n[43] E. Hazan, \u201cIntroduction to online convex optimization,\u201d Found. and\nTrends in Mach. Learn., vol. 2, no. 3-4, pp. 157\u2013325, 2016.\n[44] Y. C. Hu, M. Patel, D. Sabella, N. Sprecher, and V. Young, \u201cMobile\nedge computing: A key technology towards 5G,\u201d ETSI white paper,\nvol. 11, no. 11, pp. 1\u201316, 2015.\n[45] L. Huang, \u201cReceding learning-aided control in stochastic networks,\u201d\nPerformance Evaluation, vol. 91, pp. 150\u2013169, Sep. 2015.\n[46] L. Huang, X. Liu, and X. Hao, \u201cThe power of online learning in\nstochastic network optimization,\u201d in Proc. ACM SIGMETRICS, vol. 42,\nno. 1, New York, NY, Jun. 2014, pp. 153\u2013165.\n[47] S. Kaul, R. Yates, and M. Gruteser, \u201cReal-time status: How often should\none update?\u201d in Proc. INFOCOM, Orlando, FL, Mar. 2012, pp. 2731\u2013\n2735.\n[48] S.-W. Kim, B. Qin, Z. J. Chong, X. Shen, W. Liu, M. H. Ang, E. Fraz-\nzoli, and D. Rus, \u201cMultivehicle cooperative driving using cooperative\nperception: Design and experimental validation,\u201d IEEE Transactions on\nIntelligent Transportation Systems, vol. 16, no. 2, pp. 663\u2013680, 2015.\n[49] S. Kosta, A. Aucinas, P. Hui, R. Mortier, and X. Zhang, \u201cThinkair:\nDynamic resource allocation and parallel execution in the cloud for\nmobile code offloading,\u201d in Infocom, 2012 Proceedings IEEE. IEEE,\n2012, pp. 945\u2013953.\n[50] J. Kwak, Y. Kim, J. Lee, and S. Chong, \u201cDream: Dynamic resource\nand task allocation for energy minimization in mobile cloud systems,\u201d\nIEEE J. Sel. Areas Commun., vol. 33, no. 12, pp. 2510\u20132523, 2015.\n[51] B. Li, T. Chen, X. Wang, and G. B. Giannakis, \u201cSecure edge computing\nin IoT via online learning,\u201d in Proc. Asilomar Conf. on Signals, Systems,\nand Computers, Pacific Grove, CA, Oct. 2018.\n[52] \u2014\u2014, \u201cReal-time energy management in microgrids with reduced bat-\ntery capacity requirements,\u201d IEEE Trans. Smart Grids, 2018, to appear.\n[53] \u2014\u2014, \u201cSleeping multi-armed bandit with constraints,\u201d in Proc. AAAI\nConf. Artificial Intelligence, Honolulu, HI, Jan. 2019 (submitted).\n[54] N. Li, L. Chen, and S. H. Low, \u201cOptimal demand response based on\nutility maximization in power networks,\u201d in Proc. IEEE Power and\nEnergy Society General Meeting, Detroit, MI, Jul. 2011, pp. 1\u20138.\n[55] Y. Li, G. Qu, and N. Li, \u201cOnline optimization with predictions and\nswitching costs: Fast algorithms and the fundamental limit,\u201d arXiv\npreprint:1801.07780, Jan. 2018.\n[56] B. Liang, Mobile Edge Computing. Cambridge, UK: Cambridge\nUniversity Press, 2017.\n[57] J. Liu, Y. Mao, J. Zhang, and K. B. Letaief, \u201cDelay-optimal computation\ntask scheduling for mobile-edge computing systems,\u201d in Proc. Intl.\nSymp. on Info. Theory, Barcelona, Spain, Jul. 2016, pp. 1451\u20131455.\n[58] R. Lowe, Y. Wu, A. Tamar, J. Harb, O. P. Abbeel, and I. Mordatch,\n\u201cMulti-agent actor-critic for mixed cooperative-competitive environ-\nments,\u201d in Proc. Advances in Neural Info. Process. Syst., Long Beach,\nCA, Dec. 2017, pp. 6379\u20136390.\n[59] N. Lu, N. Cheng, N. Zhang, X. Shen, and J. W. Mark, \u201cConnected\nvehicles: Solutions and challenges,\u201d IEEE Internet Things J., vol. 1,\nno. 4, pp. 289\u2013299, Aug. 2014.\n[60] D. Lymberopoulos, A. Bamis, and A. Savvides, \u201cExtracting spatiotem-\nporal human activity patterns in assisted living using a home sensor\nnetwork,\u201d Univ Access Info. Soc, vol. 10, no. 2, pp. 125\u2013138, 2011.\n[61] X. Lyu, W. Ni, H. Tian, R. P. Liu, X. Wang, G. B. Giannakis, and\nA. Paulraj, \u201cOptimal schedule of mobile edge computing for internet of\nthings using partial information,\u201d IEEE J. Sel. Areas Commun., vol. 35,\nno. 11, pp. 2606\u20132615, Nov. 2017.\n[62] P. Mach and Z. Becvar, \u201cMobile edge computing: A survey on archi-\ntecture and computation offloading,\u201d IEEE Comm. Surveys & Tutorials,\n2017, to appear.\n[63] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, \u201cMobile edge\ncomputing: Survey and research outlook,\u201d arXiv preprint:1701.01090,\nJan. 2017.\n[64] Y. Mao, J. Zhang, and K. B. Letaief, \u201cDynamic computation offloading\nfor mobile-edge computing with energy harvesting devices,\u201d IEEE J.\nSel. Areas Commun., vol. 34, no. 12, pp. 3590\u20133605, 2016.\n[65] Y. Mao, J. Zhang, S. Song, and K. B. Letaief, \u201cStochastic joint radio\nand computational resource management for multi-user mobile-edge\ncomputing systems,\u201d IEEE Trans. Wireless Commun., vol. 16, no. 9,\npp. 5994\u20136009, 2017.\n[66] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,\n\u201cCommunication-efficient learning of deep networks from decentralized\ndata,\u201d in Proc. Intl. Conf. Artificial Intell. and Stat., Fort Lauderdale,\nFL, Apr. 2017, pp. 1273\u20131282.\n[67] B. McMahan and D. Ramage, \u201cFederated learning: Collaborative\nmachine learning without centralized training data,\u201d Google Research\nBlog, Apr. 2017. [Online]. Available: https://research.googleblog.com/\n2017/04/federated-learning-collaborative.html\n[68] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.\nBellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski\net al., \u201cHuman-level control through deep reinforcement learning,\u201d\nNature, vol. 518, no. 7540, p. 529, Feb. 2015.\n[69] S. Munir, J. A. Stankovic, C.-J. M. Liang, and S. Lin, \u201cCyber physical\nsystem challenges for human-in-the-loop control.\u201d in Proc. Feedback\nComputing, San Jose, CA, Jun. 2013.\n[70] O. Nachum, M. Norouzi, K. Xu, and D. Schuurmans, \u201cBridging the\ngap between value and policy based reinforcement learning,\u201d in Proc.\nAdvances in Neural Info. Process. Syst., Long Beach, CA, Dec. 2017,\npp. 2772\u20132782.\n[71] M. J. Neely, \u201cStochastic network optimization with application to\ncommunication and queueing systems,\u201d Synthesis Lectures on Commu-\nnication Networks, vol. 3, no. 1, pp. 1\u2013211, 2010.\n[72] Y. Nesterov and V. Spokoiny, \u201cRandom gradient-free minimization of\nconvex functions,\u201d Foundations of Computational Mathematics, vol. 17,\nno. 2, pp. 527\u2013566, Apr. 2017.\n[73] D. S. Nunes, P. Zhang, and J. S. Silva, \u201cA survey on human-in-the-loop\napplications towards an Internet of all,\u201d IEEE Communications Surveys\n& Tutorials, vol. 17, no. 2, pp. 944\u2013965, Second quarter 2015.\n15\n[74] M. R. Palattella, M. Dohler, A. Grieco, G. Rizzo, J. Torsner, T. Engel,\nand L. Ladid, \u201cInternet of Things in the 5G era: Enablers, architecture,\nand business models,\u201d IEEE J. Sel. Areas Commun., vol. 34, no. 3, pp.\n510\u2013527, Mar. 2016.\n[75] Z. Peng, Y. Xu, M. Yan, and W. Yin, \u201cArock: an algorithmic framework\nfor asynchronous parallel coordinate updates,\u201d SIAM J. Sci. Comp.,\nvol. 38, no. 5, pp. 2851\u20132879, Sep. 2016.\n[76] A. Ribeiro, \u201cErgodic stochastic optimization algorithms for wireless\ncommunication and networking,\u201d IEEE Trans. Signal Process., vol. 58,\nno. 12, pp. 6369\u20136386, Dec. 2010.\n[77] S. M. Ross, Introduction to probability models. Academic Press, 2014.\n[78] A. Sadeghi, F. Sheikholeslami, and G. B. Giannakis, \u201cOptimal and\nscalable caching for 5G using reinforcement learning of space-time\npopularities,\u201d IEEE J. Sel. Topics Sig. Proc., vol. 12, no. 1, pp. 180\u2013190,\nFeb. 2018.\n[79] K. Sakaguchi and R. Fukatsu, \u201cCooperative perception realized by\nmillimeter-wave v2v for safe automated driving\u201e\u201d in Proc. Asia-Pacific\nMicrowave Conference, Kyoto, Japan, Nov. 2018.\n[80] K. Sakaguchi, T. Haustein, S. Barbarossa, E. C. Strinati, A. Clemente,\nG. Destino, A. P\u00e4rssinen, I. Kim, H. Chung, J. Kim et al., \u201cWhere,\nwhen, and how mmwave is used in 5g and beyond,\u201d IEICE Transactions\non Electronics, vol. 100, no. 10, pp. 790\u2013808, 2017.\n[81] S. Sardellitti, M. Merluzzi, and S. Barbarossa, \u201cOptimal association of\nmobile users to multi-access edge computing resources,\u201d in IEEE Int.\nConf. on Communications, Kansas City, MO, May 2018.\n[82] S. Sardellitti, G. Scutari, and S. Barbarossa, \u201cJoint optimization of radio\nand computational resources for multicell mobile-edge computing,\u201d\nIEEE Trans. on Signal and Info. Process. over Netw., vol. 1, no. 2,\npp. 89\u2013103, Feb. 2015.\n[83] J. Schulman, S. Levine, P. Abbeel, M. Jordan, and P. Moritz, \u201cTrust\nregion policy optimization,\u201d in Proc. Intl. Conf. on Machine Learning,\nLille, France, Jul. 2015, pp. 1889\u20131897.\n[84] Y. Shen, T. Chen, and G. B. Giannakis, \u201cOnline ensemble multi-kernel\nlearning adaptive to non-stationary and adversarial environments,\u201d in\nProc. of Intl. Conf. on Artificial Intelligence and Statistics, Lanzarote,\nCanary Islands, Apr. 2018.\n[85] W. Shi, N. Li, C.-C. Chu, and R. Gadh, \u201cReal-time energy management\nin microgrids,\u201d IEEE Trans. Smart Grids, vol. 8, no. 1, pp. 228\u2013238,\nJan. 2017.\n[86] J. A. Stankovic, \u201cResearch directions for the Internet of Things,\u201d IEEE\nInternet of Things J., vol. 1, no. 1, pp. 3\u20139, Feb. 2014.\n[87] H. Sun, X. Chen, Q. Shi, M. Hong, X. Fu, and N. D. Sidiropoulos,\n\u201cLearning to optimize: Training deep neural networks for wireless\nresource management,\u201d arXiv preprint:1705.09412, May 2017.\n[88] Y. Sun, E. Uysal-Biyikoglu, R. D. Yates, C. E. Koksal, and N. B.\nShroff, \u201cUpdate or wait: How to keep your data fresh,\u201d IEEE Trans.\nInfo. Theory, vol. 63, no. 11, pp. 7492\u20137508, Nov. 2017.\n[89] Y. Sun, S. Zhou, and J. Xu, \u201cEmm: Energy-aware mobility management\nfor mobile edge computing in ultra dense networks,\u201d IEEE J. Sel. Areas\nCommun., vol. 35, no. 11, pp. 2637\u20132646, 2017.\n[90] R. S. Sutton and A. G. Barto, Reinforcement Learning: An Introduction,\nCambridge, MA, 1998.\n[91] R. S. Sutton, D. A. McAllester, S. P. Singh, and Y. Mansour, \u201cPolicy\ngradient methods for reinforcement learning with function approxima-\ntion,\u201d in Proc. Advances in Neural Info. Process. Syst., Denver, CO,\nDec. 2000, pp. 1057\u20131063.\n[92] L. Tassiulas and A. Ephremides, \u201cStability properties of constrained\nqueueing systems and scheduling policies for maximum throughput in\nmultihop radio networks,\u201d IEEE Trans. Automat. Contr., vol. 37, no. 12,\npp. 1936\u20131948, Dec. 1992.\n[93] V. Vapnik, The Nature of Statistical Learning Theory. New York City,\nNY: Springer Science & Business Media, 2000.\n[94] F. Wang, J. Xu, X. Wang, and S. Cui, \u201cJoint offloading and computing\noptimization in wireless powered mobile-edge computing systems,\u201d\nIEEE Trans. Wireless Commun., vol. 17, no. 3, pp. 1784\u20131797, Mar.\n2018.\n[95] X. Wang, X. Chen, T. Chen, L. Huang, and G. B. Giannakis, \u201cTwo-scale\nstochastic control for integrated multipoint communication systems with\nrenewables,\u201d IEEE Trans. Smart Grids, vol. 9, no. 3, pp. 1822\u20131834,\nMay 2018.\n[96] X. Wang, G. B. Giannakis, and A. G. Marques, \u201cA unified approach\nto QoS-guaranteed scheduling for channel-adaptive wireless networks,\u201d\nProc. IEEE, vol. 95, no. 12, pp. 2410\u20132431, Dec. 2007.\n[97] X. Wang, Y. Zhang, T. Chen, and G. B. Giannakis, \u201cDynamic energy\nmanagement for smart-grid-powered coordinated multipoint systems,\u201d\nIEEE J. Sel. Areas Commun., vol. 34, no. 5, pp. 1348\u20131359, May 2016.\n[98] C. J. Watkins and P. Dayan, \u201cQ-learning,\u201d Machine learning, vol. 8, no.\n3-4, pp. 279\u2013292, May 1992.\n[99] X. Wei, H. Yu, and M. J. Neely, \u201cOnline learning in weakly coupled\nmarkov decision processes: A convergence time study,\u201d in Proc. Sig-\nmetrics, Irvine, CA, Jun. 2018.\n[100] Q. Wu, Y. Zeng, and R. Zhang, \u201cJoint trajectory and communication\ndesign for multi-uav enabled wireless networks,\u201d IEEE Trans. Wireless\nCommun., vol. 17, no. 3, pp. 2109\u20132121, Mar. 2018.\n[101] J. Xu, Y. Zeng, and R. Zhang, \u201cUav-enabled wireless power transfer:\nTrajectory design and energy optimization,\u201d IEEE Trans. Wireless\nCommun., 2018, to appear.\n[102] H. Yu, M. Neely, and X. Wei, \u201cOnline convex optimization with\nstochastic constraints,\u201d in Proc. Advances in Neural Info. Process. Syst.,\nLong Beach, CA, Dec. 2017, pp. 1427\u20131437.\n[103] T. Zachariah, N. Klugman, B. Campbell, J. Adkins, N. Jackson, and\nP. Dutta, \u201cThe Internet of Things has a gateway problem,\u201d in Proc.\nACM HotMobile, Santa Fe, NM, Feb. 2015, pp. 27\u201332.\n[104] A. Zanella, N. Bui, A. Castellani, L. Vangelista, and M. Zorzi, \u201cInternet\nof Things for smart cities,\u201d IEEE Internet of Things Journal, vol. 1,\nno. 1, pp. 22\u201332, 2014.\n[105] Y. Zeng and R. Zhang, \u201cEnergy-efficient uav communication with\ntrajectory optimization,\u201d IEEE Trans. Wireless Commun., vol. 16, no. 6,\npp. 3747\u20133760, 2017.\n[106] J. Zhang, S. Pourazarm, C. G. Cassandras, and I. C. Paschalidis, \u201cThe\nprice of anarchy in transportation networks: Data-driven evaluation and\nreduction strategies,\u201d Proc. IEEE, vol. 106, no. 4, pp. 538\u2013553, Apr.\n2018.\n[107] K. Zhang, Z. Yang, and T. Basar, \u201cNetworked multi-agent reinforcement\nlearning in continuous spaces,\u201d in Proc. IEEE Conf. Decision and\nControl, Miami, FL, Dec. 2018, pp. 5872\u20135881.\n[108] K. Zhang, Z. Yang, H. Liu, T. Zhang, and T. Basar, \u201cFully decentralized\nmulti-agent reinforcement learning with networked agents,\u201d in Proc.\nIntl. Conf. Machine Learn., Stockholm, Sweden, 2018, pp. 5872\u20135881.\n[109] M. Zinkevich, \u201cOnline convex programming and generalized infinites-\nimal gradient ascent,\u201d in Proc. Intl. Conf. on Machine Learning,\nWashington D.C., Aug. 2003.\n[110] Y. Zou, J. Zhu, X. Wang, and L. Hanzo, \u201cA survey on wireless security:\nTechnical challenges, recent advances, and future trends,\u201d Proc. IEEE,\nvol. 104, no. 9, pp. 1727\u20131765, Sep. 2016.\n",
        "id": 54163871,
        "identifiers": [
          {
            "identifier": "1810.11613",
            "type": "ARXIV_ID"
          },
          {
            "identifier": "oai:iris.uniroma1.it:11573/1250684",
            "type": "OAI_ID"
          },
          {
            "identifier": "195777516",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:arxiv.org:1810.11613",
            "type": "OAI_ID"
          },
          {
            "identifier": "10.1109/jproc.2019.2896243",
            "type": "DOI"
          },
          {
            "identifier": "186282996",
            "type": "CORE_ID"
          }
        ],
        "title": "Learning and Management for Internet-of-Things: Accounting for\n  Adaptivity and Scalability",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:arxiv.org:1810.11613",
          "oai:iris.uniroma1.it:11573/1250684"
        ],
        "publishedDate": "2018-10-27T01:00:00",
        "publisher": "",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://arxiv.org/abs/1810.11613",
          "https://iris.uniroma1.it/bitstream/11573/1250684/1/Chen_Learning_post-print_2019.pdf"
        ],
        "updatedDate": "2022-12-13T16:14:04",
        "yearPublished": 2018,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "https://core.ac.uk/download/195777516.pdf"
          },
          {
            "type": "reader",
            "url": "https://core.ac.uk/reader/195777516"
          },
          {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/195777516/large"
          },
          {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/195777516/large"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/54163871"
          }
        ]
      },
      "relevance_score": 0.1345,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.3,
          "dimension_weight": 0.35,
          "weighted_score": 0.105,
          "matched_keywords_detail": {
            "human_oversight_supervision": [
              "monitoring and control"
            ]
          }
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.295,
          "dimension_weight": 0.1,
          "weighted_score": 0.0295,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2018 (Norm. Score: 0.4)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_primary_1",
      "dynamic_step": 0,
      "core_id": 54163871,
      "doi": "10.1109/jproc.2019.2896243"
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": "1909.04492",
        "authors": [
          {
            "name": "Barnhoorn, J. S."
          },
          {
            "name": "Peeters, M. M. M."
          },
          {
            "name": "Schraagen, J. M."
          },
          {
            "name": "Stolk, M. L."
          },
          {
            "name": "van der Vecht, B."
          },
          {
            "name": "van der Waa, J."
          },
          {
            "name": "van Diggelen, J."
          },
          {
            "name": "van Staal, W."
          }
        ],
        "citationCount": 0,
        "contributors": [],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/334857113"
        ],
        "createdDate": "2020-10-12T15:41:51",
        "dataProviders": [
          {
            "id": 144,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/144",
            "logo": "https://api.core.ac.uk/data-providers/144/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "As intelligent systems are increasingly capable of performing their tasks\nwithout the need for continuous human input, direction, or supervision, new\nhuman-machine interaction concepts are needed. A promising approach to this end\nis human-agent teaming, which envisions a novel interaction form where humans\nand machines behave as equal team partners. This paper presents an overview of\nthe current state of the art in human-agent teaming, including the analysis of\nhuman-agent teams on five dimensions; a framework describing important teaming\nfunctionalities; a technical architecture, called SAIL, supporting social\nhuman-agent teaming through the modular implementation of the human-agent\nteaming functionalities; a technical implementation of the architecture; and a\nproof-of-concept prototype created with the framework and architecture. We\nconclude this paper with a reflection on where we stand and a glance into the\nfuture showing the way forward.Comment: presented at NATO HFM symposium on Human Autonomy Teaming,\n  Portsmouth, October 201",
        "doi": null,
        "downloadUrl": "http://arxiv.org/abs/1909.04492",
        "fieldOfStudy": null,
        "fullText": "  \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 1 \n \n \n \nPluggable Social Artificial Intelligence \nfor Enabling Human-Agent Teaming \nJ. van Diggelen (PhD), J. S. Barnhoorn (PhD), M. M. M. Peeters (PhD), W. van Staal (MSc), \nM.L. Stolk (MSc), B. van der Vecht (PhD), J. van der Waa (MSc), J.M. Schraagen (Prof., PhD) \nTNO \nPO Box 23 \n3769 ZG Soesterberg \nTHE NETHERLANDS \n{jurriaan.vandiggelen, jonathan.barnhoorn, marieke.peeters, martin.stolk, bob.vandervecht,  \njasper.vanderwaa, jan_maarten.schraagen}@tno.nl \nABSTRACT  \nAs intelligent systems are increasingly capable of performing their tasks without the need for continuous \nhuman input, direction, or supervision, new human-machine interaction concepts are needed. A promising \napproach to this end is human-agent teaming, which envisions a novel interaction form where humans and \nmachines behave as equal team partners. This paper presents an overview of the current state of the art in \nhuman-agent teaming, including the analysis of human-agent teams on five dimensions; a framework \ndescribing important teaming functionalities; a technical architecture, called SAIL, supporting social \nhuman-agent teaming through the modular implementation of the human-agent teaming functionalities; a \ntechnical implementation of the architecture; and a proof-of-concept prototype created with the framework \nand architecture. We conclude this paper with a reflection on where we stand and a glance into the future \nshowing the way forward. \n1.0 INTRODUCTION \nRecent developments in Artificial Intelligence (AI) technology, computational processing power, and the \navailability of data have given rise to increasingly intelligent systems, i.e. entities capable of engaging in \ndynamic and goal-directed interaction with their environment [48]. Intelligent systems are often described \nin terms of their behaviour and capabilities: intelligent systems can sense their environment, reason about \ntheir observations and goals in order to make decisions, and act upon their environment [62]. Due to their \nprocessing speed and their vast and almost infallible memory, intelligent systems outperform humans in \nhandling large amounts of (heterogeneous) data, dealing with complex problems, and rapid decision-making \n[59]. \nA more recent development is that, for certain tasks, intelligent systems are capable of operating at \nhigh performance levels for extended periods of time without the constant need of human support, guidance, \nor intervention [55][4][36][41]. Concerns about the proliferation of intelligent systems in defence, \nhealthcare, aviation, and other high-risk domains - the military domain being one of the most prominent \ndomains under debate [32][8] - has ignited heated debates around the globe [48], [49], [6], [14].  \nCentral to these debates about intelligent systems is the term \u2018meaningful human control\u2019 \n[19][1][3][32]: How can intelligent systems be developed in such a way that humans remain in control of \nthe behaviour and effects of said systems. Ultimately, such control is necessary to allow for human \nresponsibility and accountability for potential outcomes of the deployment of intelligent systems. \nOne way of approaching the realization of meaningful human control is human-agent teaming (HAT). \nHAT aims to fully benefit from a system\u2019s autonomous capabilities while still maintaining meaningful \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 2 PUB REF NBR (e.g. STO-MP-IST-999) \n \nhuman control. This is accomplished by endowing an intelligent system with a variety of team behaviours, \nmaking the system anticipatory, sensitive, and responsive to the needs, wishes, intentions, control, and/or \ninfluence of other team members. Examples are: pro-actively sharing bits of information to maintain a \nminimally required extent of shared situation awareness; being (re-)directable at a higher level of abstraction \n(e.g. strategic or tactical); anticipating (human) team members\u2019 actions; or foreseeing potential problems, \nsending human teammates timely warnings, and asking them for assistance. Most common architectures for \nautonomous systems (such as 4D/RCS [1]) ignore teaming functionalities and place the focus on task-\noriented Artificial Intelligence (TAI), such as planning and sensing. The purpose of this paper is to describe \na method for pluggable Social Artificial Intelligence (SAI) which allows developers to complement an \nexisting autonomous (TAI) system with the capability to team up with humans. \nThe framework, called SAIL (Social Artificial Intelligence Layer) can be added to an autonomous \nsystem any time during commissioning or, at a later stage, while the system is in use. SAIL provides an \ninfrastructure and a library of common HAT behaviours, promoting reusability, problem decomposition, \nand adaptability. This paper discusses the application of SAIL from functional analysis to functional design, \nto system architecture design to technical implementation. \nWe start our discussion in Section 2 on functional analysis by distinguishing five dimensions that \ncan be used to characterize a Human-Agent Team, such as spatial dispersion of the team members, time \ncriticality, and communication characteristics. Using three illustrative examples from the defence domain \n(mine hunting, aerial surveillance, and robot-assisted house search), we will demonstrate the application of \nthe framework. These scenarios impose different requirements on a HAT and illustrate the scope of the \nproblem space representing military HAT applications. \nWe have extracted a number of common high-level functions needed to enable team collaboration \nbetween humans and autonomous systems. These functions form the main HAT-functions provided by \nSAIL. For example, we identify a proactive communication function that decides whether a particular piece \nof information is relevant for a human given the current task context, user state, and system capabilities. \nAnother common function within HAT is an explainable AI function that allows an autonomous system to \nexplain why it has chosen a certain course of action and select useful explanations to offer to its human user \nto increase its predictability. Seven common HAT functions are described in Section 3. \nThe HAT functions are realized in the SAIL software architecture in a modular way using dedicated \nSAI-components which can be plugged into the autonomous system. Communication between these \ncomponents is facilitated by our newly developed Human-Agent Teaming Communication Language \n(HATCL). This language provides the constructs needed for all components (i.e. TAI, SAI, and human) to \ncoordinate actions among one another, ultimately leading to a coherent team consisting of humans and \nautonomous (TAI) systems glued together by SAI components. Of particular concern is to enable a mapping \nfrom the concepts in the internal control logic in the autonomous system to HATCL and back. This is \nrealized in SAIL by so-called semantic anchors. A description of the SAIL architecture, HATCL and \nsemantic anchors is provided in Section 4. \n Using the SAIL framework, we have implemented a prototype application in which a swarm of \nmilitary surveillance drones running in the Gazebo simulation environment can be controlled in a \nmeaningful way using HAT techniques. The prototype is described in Section 5. \nSection 6 presents a conclusion and future activities.  \n2.0 ANALYSING HAT SCENARIOS IN VARIOUS DIMENSIONS \nTeamwork and collaboration requires interaction and tuning, especially in a HAT. What type of interaction, \ncoordination, and alignment is needed, strongly depends on the type of HAT and the context in which it \noperates. Therefore, we have identified five important dimensions that describe and define a specific HAT, \nand that can be used as a guidance when determining specific requirements for a given HAT. \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 3 \n \n \n2.1 HAT dimensions \nWe describe a set of five dimensions that affect the requirements of a specific HAT: environment, \nmission/task, team organization, team dynamics, and communication (Figure 2-1 provides an overview). \nThe dimensions can be used in multiple ways: to evaluate the generic applicability of HAT solutions for a \nwide variety of tasks, teams, contexts, and situations; to support rapid prototyping and analysis of specific \nHAT cases and identify challenges and requirements; or to compare multiple scenarios or cases to one \nanother in terms of complexity and/or required SAI functionality. \n2.1.1 Environment \nThe environment dimension describes which part of the environment is (a) dynamic, as opposed to static, \nand (b) predictable, and to what extent. This dimension affects, among others, HAT requirements aimed at \nthe establishment of (shared) situation awareness (SA). Situation Awareness is \u201cthe perception of the \nelements in the environment within a volume of time and space, the comprehension of their meaning, and \nthe projection of their status in the near future\u201d [20]. In teams, SA needs to be distributed optimally across \nteam members. Acquiring and maintaining shared SA becomes increasingly difficult as the environment \nbecomes more dynamic and unpredictable [21]. Furthermore, complex environments also make it more \nchallenging to determine when or in which manner the autonomous system may reach the boundaries of its \ncapability envelope [57], posing additional challenges for the human to quickly switch to manual control if \nneeded. \n2.1.2 Mission / task \nThe mission / task dimension describes four factors. First of all, the (a) duration of the work cycles - which \ncan be short, long, repeated, continuous, or team lifespan [54] - affects training and evaluation requirements. \nFor instance, when teams collaborate for brief durations, extensive training and / or preparation may be \nneeded because there is little time for tuning or adjustments during actual task performance. Secondly, the \n(b) interdependency of the team (e.g. [47]) can affect the need for interpredictability (also see Section 3.2)  \nand shared mental models of team members\u2019 capabilities and status as members depend on each other\u2019s \nperformance and actions. The other two factors of the mission / task dimension are (c) time criticality, \naffecting communication requirements, and (d) risk. From a social perspective, increased risk may require \nartificial teammates to be more aware of human team members\u2019 emotional status, which can potentially \naffect task performance. \n2.1.3 Team organization \nThe team organization dimension describes (a) the team's physical proximity, (b) the number of team \nmembers, (c) the team\u2019s adaptability [47], and (d) their skill and authority differentiation (e.g., the extent to \nwhich the team members have different specialisms and ranks, [54]) and (e) network structure. Different \norganizational set-ups require different behaviour from teammates. For instance, we know from the human-\nhuman teaming literature that in distributed teams, team trust is an important mediator of success, and can \nbe increased through effective knowledge sharing and exchange behaviours [24][58]. Proactive \ncommunication in HATs, a requirement we elaborate on later, contributes to this. The team adaptability \nfactor is described as the ability to alter a course of action or team repertoire in response to changing \nconditions and is thus especially important in dynamic and / or unpredictable environments. \n2.1.4 Team dynamics \nThe team dynamics dimension contains (a) the temporal scope - a team may be standing, ad-hoc, to be \nformed in the future or having ceased to exist [54]. The team\u2019s temporal scope may have implications for \nthe extent to which teams are capable of forming longitudinal reciprocal and personalized team \nrelationships. For example, in ad-hoc teams, the artificial teammate may have little or no time to develop a \nuser model, and needs to be able to quickly identify roles, capabilities, and responsibilities. This is related \nto human-awareness, a requirement we elaborate on later in Section 3. The second aspect of the team \ndynamics dimension is (b) the team\u2019s current development phase - which cycles trough commissioning, \npreparation, action, and debriefing / learning. The development phase of the team, and especially the extent \nto which they actively cycle through these phases, may affect the extent to which teams engage in after \naction review and reflection to incrementally improve their processes and procedures. For instance, teams \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 4 PUB REF NBR (e.g. STO-MP-IST-999) \n \nthat cycle through preparation, action and learning phases may benefit from the ability to make work \nagreements among the team members, e.g. about constraints imposed on artificial agents, a functionality \nthat we have implemented a solution for in SAIL (see Sections 3 and 4). \n2.1.5 Communication \nThe communication dimension describes (a) the communication streams, which may vary between many-\nto-many, one-to-many, or one-to-one, (b) the information richness in communication [12], and (c) the \nquality of the infrastructure, which may vary in reliability, bandwidth, and range. During the design phase \nof a HAT, the communication dimension needs to be taken into account in order to optimize how, for \ninstance, (shared) SA will be maintained [50]. For instance, when working in an unreliable network, relevant \ninformation needs to be pushed whenever possible, whereas with a reliable network, the artificial teammate \nmay take other teammates\u2019 workload into account when timing communication. Furthermore, reduced \ncommunication abilities may increase the need to extensive training and clear work agreements so that \nteammates know what to expect from one another during periods of limited communication. \n \n \nFigure 2-1 Overview of the HAT dimensions, and the way each of the scenarios maps onto these factors. \nScenarios are indicated by colour-coding (yellow, green, and purple). \n2.2 Example scenarios illustrating the dimensions \nTo illustrate the five dimensions presented in the above, we will discuss and analyse three typical defence \nscenarios. Figure 2-1 provides a visual overview comparing each of the scenarios with respect to the various \nteam characteristics. \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 5 \n \n \n2.2.1 Surveillance scenario \nIn the Surveillance scenario, a swarm of unmanned aerial vehicles (UAVs) collaborates with a base \ncommander to conduct a surveillance task around a small, temporary military base. The team has a low \nphysical proximity, meaning that it requires the ability to efficiently exchange (shared) situation awareness. \nDifferentiation of skill among the UAVs is low, allowing for quick back-up behaviour within the team. \nFurthermore, as the task concerns mainly surveillance, differentiation of authority between UAVs and the \nbase commander is relatively low. In normal conditions, the UAVs can autonomously select sensors; plan \nand coordinate their flight paths; and choose what information to send to the base commander. However, \nwhen anomalies are detected or when the UAVs are unable to cope with a situation autonomously, the base \ncommander quickly needs to (re)gain SA and decide on subsequent actions. This poses interesting \nrequirements to the HAT: in normal conditions the marine officer has a low workload and SA, but in case \nof potential (often time critical) anomalies or unexpected situations he or she needs to be able to effectively \ntransfer from \u2018out-of-the-loop\u2019 to \u2018in-the-loop\u2019 as quickly as possible (i.e. management by exception). \n2.2.2 House search scenario \nIn the House search scenario, a single soldier teams up with a single unmanned ground vehicle (UGV) to \nperform a house search. Short work cycles are used as multiple houses may be searched subsequently. This \nmeans that there is room for (longitudinal) team development as the team repeatedly cycles from preparation \nto action and evaluation. Furthermore, the team has high internal, but usually low external dependency. The \nhigh internal dependency means that consistent behaviour, potentially enforced trough work agreements, \nand trust calibration are important. For instance, under what circumstances does the UGV perform below \naverage in terms of situation assessment? And when trust is damaged, how can the artificial teammate repair \nit (e.g. [57][46][58])? The risk is high while time pressure is average, this means that it is probably most \neffective to proactively provide updates and request confirmation regularly while still considering the other \nteammate\u2019s current mental state. The house search team often needs to jump right into action and the \nenvironment is highly unpredictable, dynamic, and variable. This means that the team needs to be highly \ntrained so that the team members work together seamlessly, even when they have little time to prepare for \naction while facing unpredictable situations. \n2.2.3 Mine hunting scenario \nIn the Mine hunting scenario, personnel on a naval mine hunter teams up with a swarm of unmanned \nunderwater vehicles (UUVs) to search for and dismantle sea mines. In this scenario, ample time is available \nfor commissioning and preparation as there is usually relatively little time pressure. However, the \navailability of communication infrastructure during action is restricted due to limitations of underwater \ncommunication. This means that common ground is essential and work agreements are required that take \nunexpected situations into account, since agents may need to solve problems without being able to \ncommunicate. The mine hunting case is a typical example of a predictable, static environment with a team \nthat is long-standing. \n2.2.4 Applicability to other cases \nThe dimensions discussed above can also be used to describe and analyse other examples of military HAT. \nFor instance, the goal keeper used to defend navy ships against incoming missiles is characterized by \nrepeated work cycles with extreme time pressure and high risk. The wide range of potential HAT \napplications, situations, and settings makes it clear that HAT functions and solutions that aim to be generic \nneed to be flexible, adaptable, and expandable. Together, SAIL and HATCL provide a platform to facilitate \nthis. For the remainder of the paper, the surveillance scenario will be used as an illustrative running example. \n2.2.5 Added value of HAT analysis \nThe HAT analysis can be used in many ways: to evaluate whether concept HAT solutions are as generic as \nimagined; to analyse specific HAT situations or cases and identify which capabilities are required for the \nartificial teammate; or to compare a set of scenarios or cases. In our experience, analysing cases, scenarios, \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 6 PUB REF NBR (e.g. STO-MP-IST-999) \n \nand HAT solutions in this way can be very helpful in designing better human-agent interaction. Furthermore, \nit helped identifying the most common HAT functions, which we discuss in the next section. \n3.0 COMMON HAT FUNCTIONS \nThis section describes the most common functions of agents participating in Human-Agent Teams. Our \nstarting point are the three basic requirements for effective coordination [22][36]:  \n- Common ground: Team members must have shared beliefs about the world state, the goals, the \nconventions associated with the task at hand, etc. \n- Interpredictability: team members must be capable of predicting each other\u2019s actions with a \nreasonable degree of accuracy. \n- Directability: Team members must be capable of redirecting each other\u2019s behaviour. \nBy creating functionalities and behaviour capabilities for artificial team members that support each of these \nrequirements, artificial agents can contribute to team processes in service of optimizing team performance. \nThe following subsections offer insight in the way this can be achieved. \n3.1 Common ground \nIn order for communication to be accurate and effective, participants in a conversation must establish proper \ncommon ground. Common ground refers to information which is mutually believed by all parties involved \nin a conversation [27]. Conversational efficiency is greatly enhanced through common ground as speakers \nneed not explain all assumptions underlying their statements. Yet conversely, conversational effectiveness \nis greatly limited when speakers assume common ground, where it is lacking. Relying as a speaker on \ncommon ground with the audience is an invitation to cooperate [27] as the speaker appeals to the audience \n\"to base their inferences not on just any knowledge or beliefs they may have, but only on the mutual \nknowledge or beliefs [shared by the conversational participants]\" [10]. \nAccording to Stalnaker (2002), common ground relies on the speaker\u2019s presuppositions about the \naudience\u2019s common beliefs [53]. The common beliefs of the parties to a conversation are the beliefs they \nshare, and that they recognize they share. By presupposing certain beliefs, the speaker takes the audience\u2019s \nunderstanding of such beliefs for granted as background information. By identifying the common ground of \na conversation with the common belief of the participants, the presuppositions of an individual speaker can \nbe identified with what the speaker believes to be common belief. \nFor HATs to establish and maintain common ground and thereby speed up the communication \nprocess, the following functionalities can be introduced in artificial team members. \n3.1.1 Shared situation awareness \nAn important challenge in developing HATs is to endow artificial team members with functionalities \nallowing them to effectively and efficiently share situation awareness (SA) within the team [19]. SA \nprimarily refers to knowledge about the current state of the task environment, as well as team activities, \nteam performance, and overall progression with respect to the team task. Such knowledge facilitates \ncoordination and reallocation of tasks within the team, but can also be used for effective and efficient \ncommunication among the team members. SA can be used to explain dynamic goal selection, attention to \nappropriate critical cues, and future state predictions, but this requires for the parties involved to have access \nto the information needed to assess \u2013and, through that, become aware of\u2013 the situation. Establishing shared \nsituation awareness, then, means for team members to reason about the necessity of sharing certain \ninformation with the other members in the team, to develop a shared team \u201ctheory of the situation\u201d [8]. To \nrealize this, team members should decide to share relevant information, while withholding irrelevant \ninformation, so as to prevent their team members from becoming overloaded with information [46]. \nDeciding on the necessity of information for the other team members, requires an additional type of \nawareness, dubbed \u201cintention awareness\u201d by Howard and Cambria (2013), by which they mean \u201cthe process \nof integrating actors\u2019 intentions into a unified view of the surrounding environment\u201d [31]. Intention \nawareness can also be used to reason about potential adversaries and other actors  \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 7 \n \n \n3.1.2 Explanations \nAt times throughout a conversation, team members may fail to understand one another\u2019s actions or \nutterances. On such occasions, team members may require for additional explanations to gain understanding \nof the other team member\u2019s meaning, motivation, intention, or assumption. When creating artificial team \nmembers, developing functionalities enabling them to explain their behaviour, recommendation, or \nexpression is often referred to as \u201cexplainable artificial intelligence (XAI)\u201d. XAI facilitates the disclosure \nof information by artificial team members to human team members. Compared to the sharing of situation \nawareness, XAI typically concerns more advanced functionalities, as it requires for the intelligent system to \ntrace its internal line of reasoning, inference, classification, or input-output mapping, depending on the type \nof technology used. When done appropriately, XAI helps human team members understand the system\u2019s \nrationale underlying its behaviour and/or decisions. For example, an analyst who receives recommendations \nfrom a smart decision support system needs to understand why the algorithm has recommended a certain \ncourse of action. \nAs of recent, the research area of explainable AI (XAI) has exploded (e.g. [28]). In addition to the \nability to offer a meaningful explanation for a specific human actor when needed, XAI also refers to the \nability to ask for an interpretable explanation from a specific human actor when needed. So far, research \ncentred primarily on the first type of ability. However, more integrative methods are under development, \nincluding bottom-up data-driven (perceptual) processes and top-down model-based (cognitive) processes \n[42]. Such methods could help assess the trustworthiness of the autonomous system\u2019s task performance and, \nsubsequently, explain the foundation and reasons of this performance to establish trust calibration [58]. \n3.2  Interpredictability \nSmooth collaboration can be enhanced by team members anticipating the interdependencies within the team. \nBy predicting team members\u2019 task performance, team members can shorten waiting times, expedite task \nperformance by aiding a team member in need of assistance, provide important just-in-time information to \nthose who need it, and plan for contingencies if a team member may be unavailable or incapable of performing \na task. To enhance interpredictability between team members, endowing an artificial team member with the \nfollowing functionalities can be useful. \n3.2.1 HAT training and longitudinal teaming \nTeam performance requires coordination between activities of each of the team members, under routine \nconditions as well as under novel conditions. Procedures, protocols, and doctrines are all artefacts created \nto foster team performance, as they increase interpredictability and support coordination. Procedural team \ntraining therefore focuses on the internalisation of procedures. However, procedures are often insufficient \nwhen the actual task deviates from the training task. On such occasions, teams have to improvise new ways \nof working together. One way of dealing with this challenge, is through team cross-training: team members \nswitch roles with one another, so as to understand one another\u2019s roles and responsibilities [10]. Nikolaidis \net al. (2015) investigated the use of cross-training in human-robot teams for assembly in the manufacturing \nprocess [43]. By iteratively switching roles between the robot and the human worker, the robot learned a \nmodel of human behaviour, describing the sequence of actions necessary for task completion and matching \nthe preferences of the human worker. \nTeam training (both procedural and cross-training) aims to support the development of shared \nmental models: an overlapping understanding of one another\u2019s objectives, roles, tasks, activities, \nwhereabouts, team structure, and so on [63]. Shared mental models enable team members to reason not only \nabout their own situation, but also about that of their team members in the pursuit of their joint goal. Shared \nmental models, in other words, enable team members to predict a team member\u2019s performance on a \nparticular task, potential need for help or information, risks of failure within the team, etc.  \nHAT training supports the development of shared mental models, by learning about one another\u2019s \ncapabilities and limitations through experience, and optimizing the team processes needed to mitigate risks \nand limitations within the team. By endowing artificial team members with the functionalities required to \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 8 PUB REF NBR (e.g. STO-MP-IST-999) \n \nengage in HAT training, artificial team members can learn to optimize their behaviour with respect to a \nteam, i.e. the constellation of specific team members and their particular dynamics. In other words, team \ntraining facilitates the development of increasingly accurate mental models of team members, with the \nobjective of increasing the team\u2019s ability to flexibly coordinate their activities and increase team \nperformance. This, however, requires for artificial team members to be able to learn from team interactions, \nupdating their models to better interpret the tasks, behaviour, and corresponding needs of their team \nmembers. This is also referred to in the literature as \u201cinteractive shaping\u201d [38][43]. For example, Nikolaidis \net al. (2015) found that cross-training improved mental model similarity, as well as the human worker\u2019s \nperceived robot performance and trust in the robot. \n3.2.2 Proactive communication \nTeamwork often entails the processing, interpretation, and analysis of large amounts of information. Based \non their roles and/or expertise, responsibility for handling certain information sources and types is \ndistributed across the various team members. Oftentimes, the results of the information processed by one of \nthe team members are relevant to the activities of another team member, requiring the team members to \ncommunicate with one another. Communication in teams often aims to contribute to one of the following: \n(1) problem-solving, (2) structuring and coordination, (3) socio-emotional alignment, or (4) proactive \ncommunication [33]. \nAn important challenge in teams is how team members decide to proactively communicate: when \nshould an actor communicate what with whom. Such decisions are often based on shared mental models \n[63]. Interpredictability (facilitated by mental models) enables an agent to infer that its team member is \ncurrently working on a task that requires certain information, or that newly retrieved information affects the \ndecisions and tasks of a team member. Based on such reasoning, the agent may decide to proactively share \nits knowledge with the respective team mate. Proactive communication entails team members providing one \nanother with information on their own accord, i.e. without the need for a team member to explicitly request \nfor that information to be shared. We distinguish between proactive communication to accommodate a team \nmember\u2019s information need based on: (1) that team member\u2019s preferences (e.g. as learned from prior \ninformation requests), (2) knowledge about that team member\u2019s situation (i.e. based on a shared mental \nmodel), and (3) one\u2019s own potential need for assistance in the near future, requiring the envisioned assistant \nto be up to date with the situation at hand. There might be additional reasons and situations where proactive \ncommunication advances team performance, that we currently haven\u2019t thought of yet. \nFor an artificial agent to be able to reason about its human team members, requires for that agent to \nbe human-aware. Human-awareness entails that intelligent actor(s) have access to information about human \nteam members and their characteristics (e.g. preferences, tasks, capabilities and limitations, etc.). In addition \nto this information, the agent(s) also employ various functionalities aiding the maintenance of, reasoning \nabout, and learning from such information. For example, functionalities related to human-aware computing \ninclude location monitoring, attention tracking, and trust calibration. Ultimately, human-awareness enables \nintelligent systems to predict the behaviour of human team members, fostering better shared mental models \nand interpredictability. \n3.3 Directability \nDirectability entails the ability of team members to influence and/or control one another\u2019s behaviour, to \naccommodate adaptations in the team\u2019s activities, coordination, behaviour, and overall performance. \nTraditionally, in human-robot collaboration, directability entailed tasking of a robot by a human operator. \nHowever, as robots (and agents) become more capable of determining their own plans and activities to try \nand accomplish the team goals, human-robot collaboration gradually moves away from traditional tasking, \nand towards e.g. dynamic task allocation, shared initiative, and work agreements. \n3.3.1 HAT communication \nBeing able to influence the behaviour of another actor first requires for the team members to be able to \nexpress themselves about more than simple information sharing, as was the case for common ground and \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 9 \n \n \ninterpredictability. We therefore need to extend communication to include speech acts that express the desire \nfor another agent to perform a certain activity. In most agent communication languages, these speech acts \nare derived from \u201crequest\u201d and \u201cquery\u201d [23]. The request speech act asks another agent to perform a certain \ntask or action, whereas the query speech act asks another agent to provide particular information. We will \ngo deeper into the use of speech acts in the next section. \n3.3.2 Work agreements \nWork agreements are used to impose constraints on the autonomous behaviour of agents [16]. This forms \none of the core building blocks of human-agent teams as they enable external directability on an agent\u2019s \nbehaviour without compromising the agent\u2019s autonomy (also known as internal autonomy requirement \n[18][56]). Furthermore, they contribute to maintaining common ground and interpredictability, by enabling \nan explicit way to specify shared conventions on the agent\u2019s behaviour. \nWork agreements are very similar to policies which have been applied as a teamwork coordination \nmechanism in [8]. We distinguish between two types of work agreements: obligations which describe which \nactions must be performed by an agent in a given context; prohibitions which describe which actions are not \npermitted to be performed by an agent in a given context. Examples of work agreements are \n- UGV 2 has an obligation to notify the human worker when it detects a potentially hostile target \n- UAV 3 has a prohibition to fly above the village \nWork agreements can be applied for various purposes on different time scales. For example, one \nmight specify a work agreement that specifies the current plan that is followed by the human and agent. On \na longer timescale, a work agreement can be used to specify the Rules of Engagement which the system has \nto adhere to, or even military doctrine which lasts for the entire lifecycle of the system. \nWork agreements can also be applied when designing the teamwork process itself by stating which \ncommunicative acts must be performed under which circumstances. For example, to specify the task division \nbetween the human and the agent, or to specify the level of human involvement in the process. \nA more detailed (technical) description of work agreements is provided in the next section. \n3.3.3 Dynamic task allocation and fit-for-purpose collaboration \nAs artificial team mates become more self-sufficient, it is at times unnecessary for a human to control, or \neven monitor, artificial agents at all times. The challenge is, however, that most artificial agents are capable \nof performing their task without the need for assistance or control under specific circumstances, whereas at \nother times, their performance degrades, or they malfunction altogether. As a result, the human-agent \ncollaborative work relationship may vary across situations. To deal with this phenomenon, the team should \nbe able to engage in dynamic task allocation and fit-for-purpose collaboration [25]. For example, the team \nshould be able to shift between the following work relationships depending on the situation at hand: \n\u2022 Parallel task performance: team members perform their tasks in coordination with their team \nmembers. They are capable of identifying, organising, and performing their own tasks and \nresponsibilities without the need for assistance. \n\u2022 Management by exception: team members can perform independently, yet when help or directions \nare required, they either ask for help from their supervisors or colleagues, or their team members \nnotice a break-down and offer help proactively. \n\u2022 Training / educating: team members are still in training and require constant feedback and \nmonitoring so as to strengthen their understanding of the team task or goal, their team members, the \nroles within the team, and their own activities as part of the entire team performance. \n\u2022 Tasking: team members are capable of performing a task once it is provided to them, but are \nincapable of determining their next task, as they are unaware of the encompassing team task or goal, \ntheir surroundings, role within the team, and/or team members. \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 10 PUB REF NBR (e.g. STO-MP-IST-999) \n \n4.0 SYSTEM ARCHITECTURE DESIGN FOR HUMAN-AGENT TEAMING  \nThis section describes a functional architecture, called SAIL, in which the common HAT functions can be \ncombined and configured to turn a set of autonomous agents and humans into a coherently working team. \nThe next subsection describes the SAIL architecture  \n4.1 Social Artificial Intelligence Layer \nSAIL (Social Artificial Intelligence Layer) is an environment in which HAT functionalities can be \nimplemented in a modular way, i.e. using HAT modules. We distinguish between three types of components \nin a SAIL system:  \n- Humans in their ambient environment. For example, these may be professionals working in crisis \nmanagement wearing mobile interaction devices such as smart watches and head-mounted displays \nsupporting augmented reality; or these may be operators working in a control station with large \ninformation displays. \n- TAI (task-oriented AI) components, i.e. technical AI components designed to optimally perform a \ncertain task, but which may not be optimized for human interaction. These may be robots conducting \nsurveillance in a certain area, cyber agents protecting vital ICT infrastructure against cyber threats, \netc. \n- SAI (Social AI) modules which serve as intelligent middleware aiming to transform task-oriented \nAI components and humans into a coherent human-agent team. Such components include machine \nlearning technology that can decide how to exchange the right information at the right moment \namong the right actors [17], or AI message interpretation that can translate a high level command \nsuch as \u201csecure the area\u201d into commands that can be processed by the TAI component. \n \nAn overview of a SAIL configuration is depicted below. \n \n \n \nFigure 4-1 SAIL system architecture, where Task-oriented AI components (TAI) are mediated by Social AI \nComponents (SAI) to allow interaction with humans. \nBecause the different components in SAIL can take on many forms depending on the requirements of the \nsystem, SAIL does not impose any constraints on their internal workings. The focus of SAIL therefore is on \nthe interactions between the different components. These interactions are specified in a dedicated language \ncalled HATCL (Human-Agent Team Communication Language), which provides an abstract specification \nlanguage of the possible information and control flows between the different components of a HAT. HATCL \nis abstract in the sense that it specifies the information in the message and its illocutionary force [50]. \nIllocutionary force refers to the intention of a speaker behind an utterance, e.g. obtaining information, directing, \netc. HATCL messages are neutral with respect to interaction modality or graphical representation. A \nspecification of the language is described in the next subsection. \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 11 \n \n \n4.2 HATCL \nHATCL is inspired by FIPA-ACL, which has been developed as a language for communication between \nintelligent software agents [23]. To function as an effective means of communication between the different \ncomponents in Figure 4-1, HATCL should satisfy a number of additional requirements which makes it suitable \nfor Human-Agent Teaming. \nR1: HATCL should be capable of capturing the different abstraction levels at which machines and \nhumans interpret and process information within a certain problem domain.  \nHATCL should mediate between the different levels of abstraction of the various SAIL components. In the \ninteraction between humans and SAI modules, a HATCL message should be capable of representing the \ninformation that stems from human input or that is outputted to humans. In other words, the language should \n(at least partly) be understandable by humans. This means that the language should align with human mental \nmodels [42]. One way to interpret this is to adopt Daniel Dennett\u2019s intentional stance [12]. This theory states \nthat humans should comprehend the behaviour of artificial agents by attributing goals, beliefs, and intentions \nto them. The communication of such concepts should be facilitated by the HATCL language. In the interaction \nbetween TAI and SAI modules, the language should (at least partly) be understandable for machines. \nTherefore, the conceptualization should be alignable with the internal logic of the system. For example, when \nthe system is based on internal logic that chooses its actions based on maximizing the expected reward, the \nlanguage should be capable of communicating these concepts to be understandable for the system. \nR2: HATCL should allow for sending soft directives.  \nTo implement directability in a team of equal humans and agents, the rule orders are orders does not always \napply. For example, consider the situation where the human commands an autonomous drone to fly back to \nthe command post (CP). Various reasons exist in which the drone\u2019s responsive behaviour might deviate from \nsimply following this command: \n\u2022 Incapability: The drone might know that it is currently incapable of completing the action due to a \nreason unknown to the human (e.g. low battery level). In this case, we might want the drone to point out \nthis problem to the human, rather than trying and failing. \n\u2022 Conflicting with team goal: The drone might possess additional situation awareness that the given \ncommand would lead to an outcome which conflicts with the team goal. For example, that flying back \nto the CP would cause the drone to be subjected to hostile fire, which conflicts with the team goal to \nremain safe. If the drone can think of a better alternative, we might want the drone to propose this \nalternative instead. \n\u2022 Dealing with multiple orders: In practical situations, the drone must deal with multiple orders which \napply to different timescales and may even be in conflict with each other. For example, when the drone \nreceives the order to fly to the CP, the drone may have to decide to finish its previous order first (e.g. to \ntake a picture of an area of interest) or fly back immediately. Most likely, this depends on the time it \ntakes to finish the previous order. In case of uncertainty, we might want the drone to discuss this problem \nwith the human. \nAs the examples above illustrates, a directive used for communication between autonomous agents is \nfundamentally different than a directive used between objects in object-oriented programming language \n(e.g. remote method invocation). Jennings et al. have famously phrased this as: Objects do it for free, agents \ndo it for money [36]. Nevertheless, defining the precise meaning of these soft directives remains a challenge, \nand is one of the major objectives of HATCL specifications. \nR3: HATCL should allow for specifying unambiguous work agreements.  \nAs argued in Section 3.3.1, work agreements form an essential part of HAT technology. Therefore, the \nspecification of these work agreements in an unambiguous way is one of the main purposes of HATCL (also \nsee Section 4.2.2). \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 12 PUB REF NBR (e.g. STO-MP-IST-999) \n \nR4: HATCL should allow symbol grounding in various system architectures.  \nThe symbol grounding problem [15] refers to the problem of relating symbolic messages (such as HATCL \nmessages) to internal structures that are processed by the agent (such as perceptions and plans). We use \nsemantic anchors to formalize this relation. Different system architectures typically require different semantic \nanchors for the same HATCL message. For example, opaque deep learning networks require very different \ntypes of semantic anchors than rule-based systems. \nTo satisfy each of the requirements described above, we define the message structure (syntax) and \nits semantics (in terms of work agreements, ontologies, and semantic anchors). \n4.2.1 The HATCL Message syntax \nA HATCL message has the following structure: <Performative, Sender, Receiver, In-reply-to, Content, \nProtocol, Ontology, Message-ID, Conversation-ID>. Most of these fields, such as Sender, Receiver, Message-\nID, contain meta-information used for routing the message. The fields Performative, Content, and Ontology \nare worthy of further explanation and are discussed below. \n \nThe Performative is used to denote the illocutionary force of a message, which could be:  \n\u2022 Inform: Provide another actor with information \n\u2022 Query: Ask another actor for information \n\u2022 Subscribe: Subscribe to information updates on a specific topic from another actor \n\u2022 Request: Ask another actor to perform a certain task (acts as a single purpose work agreement) \n\u2022 Propose: Propose a work agreement to another actor \n\u2022 Accept: Accept the proposed work agreement \n\u2022 Reject: Reject the proposed work agreement \n\u2022 Understood: Acknowledge reception, and correct interpretation, of an inform message \n\u2022 Not understood: Acknowledge reception, yet misinterpretation, of an inform message \n\u2022 Cancel: Cancel a previously instantiated work agreement \nThis is the set of performatives currently included in HATCL. New performatives may be added as required \nby future applications. Each of these performatives has been defined both syntactically and semantically in our \nHATCL specification document. \n \nThe content of a message specifies what is actually communicated and can be specified in a query language, \nworking agreement language, or assertion language. The content  \n \n{ \u201cPerformative\u201d :   \u201cQuery\u201d ,  \n  \u201cSender\u201d :       \u201cHum1\u201d,  \n  \u201cReceiver\u201d :     \u201cUGV1\u201d,  \n  \u201cIn-reply-to\u201d :   \u201c\u201d,  \n  \u201cContent\u201d :      \u201c$.vehicles.*\u201d \n  \u201cProtocol\u201d :     \u201c\u201d,  \n  \u201cOntology\u201d :     \u201cmilitary_ont\u201d,  \n  \u201cMessage-ID\u201d :    \u201cmsg13\u201d, \n  \u201cConversation-ID :  \u201ccnv-2\u201d } \n \n4.2.2 Work agreements \nAs work agreements between humans and autonomous systems impose well specified constraints on \nautonomous behaviour, they form the core building blocks of HAT technology; many message types in \nHATCL can be interpreted in terms of work agreements. For example, a HATCL message of the type inform \nis translated into the work agreement: <Actor1, Actor2, upon receiving this message, O(send information of \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 13 \n \n \ntype x to Actor1)>, which states that by accepting this work agreement, Actor2 commits to an obligation to \nimmediately send information of type x to Actor1. \nScientific research on the formalization of work agreements (also referred to as \u201csocial \ncommitments\u201d) comes from the field of normative multi-agent systems [40][51]. A work agreement is an \nexplicit agreement between two actors, specifying that one actor, denoted as debtor, owes it to another actor, \ndenoted as creditor, to effectuate some consequent (e.g., refrain from or see to it that some action is \nperformed or some objective is achieved) if the antecedent (e.g., some precondition) is valid [51]. Work \nagreements, in short, aim to specify permissions and obligations on agent behaviours. And so allow for the \nvoluntary restriction of an actor\u2019s autonomy as proposed by another actor. Work agreements hold explicitly \nbetween two actors. Therefore, work agreements are sometimes compared to contracts. An example of a \nwork agreement is: \u201cLawrence is obligated to notify Lisa about his change in intent, if he decides to pause \nhis current task to switch to a more pressing task encountered along the way\u201d. \nA work agreement is first and foremost a voluntary restriction on an actor's autonomy (also see \nFigure 4-2), as the actor receiving the proposed work agreement is also allowed to reject the work agreement. \nThe acceptance of the work agreement, and hence the restriction on its autonomy, is completely voluntary. \nAs soon as the debtor has accepted the work agreement, though, the debtor's autonomy is conditionally \nrestricted: the debtor must satisfy the work agreement once the antecedent becomes valid. If the debtor fails \nto provide the consequent of an activated agreement before the deadline, this implies that the agreement has \nbeen violated. If the debtor succeeds to do so, the work agreement is satisfied. Furthermore, commitments \ncan, in general, be cancelled by the actors involved (although this may be subdue to overarching rules). \n \n \nFigure 4-2: The lifecycle of a work agreement as affected by the dynamics between the actors and events \ntaking place in the environment \nA similar approach to work agreements are policies: \u201cenforceable, well-specified constraints on the \nperformance of a machine-executable action by a subject in a given situation\u201d [16]. Policies come in two \nflavours: authorization policies, stating what is permitted, and obligation policies, stating what is obligatory \nin a given situation [16]. Policies do not hold between two actors, but instead are generally applicable to a \nset of actors. Therefore, policies are sometimes compared to laws. An example of a policy is: \u201cTeam \nmembers are obligated to notify their team leader about a change in intent if they decide to switch tasks after \nencountering a more pressing task\u201d. \nThe foundation of both policies and work agreements are normative rules in the form of deontic logic \n[59]. Deontic logic is used to reason about obligations and permissions. Therefore, deontic logic still forms \nthe core of work agreements and policies, as it enables reasoning and verification. \n4.2.3 Ontologies \nOntologies offer explicit, structured, and semantically rich representations of declarative knowledge. They \nconsist of concepts (`classes'), and relations between them, to describe certain parts of the world [45]. \nHATCL uses a domain-independent \u201ctop ontology\u201d and a domain-specific ontology to enable actors in the \nHAT to parse the messages they receive. Figure 4-3 shows the top ontology, consisting of relatively generic \nconcepts, such as Actor, Plan, Goal, and Action. The domain-specific lower-level ontology would provide \nspecific instances of tasks, actors, and plans particular to that domain. \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 14 PUB REF NBR (e.g. STO-MP-IST-999) \n \n \nFigure 4-3: Top-level domain-independent ontology used to specify work agreements and HATCL messages, \nfacilitating coordination and communication between actors in the HAT \n4.2.4 Semantic Anchors \nSemantic anchors relate concepts and variables in HATCL to concepts and variables in the autonomous \nsystem. This translation operation is implemented inside the autonomous system. To illustrate this important \nprinciple in human machine teaming, we will start with a simple example.  \nExample 1: Suppose we have a human team-member controlling an autonomous system which runs the \nfollowing code: \nRepeat  \nturn_left,  \nturn_right,  \nmove_straight  \nUntil false \nSuppose the human teammember expresses the desire to prohibit left turns via work agreements. \nRight now, the autonomous system code is not suitable for that. Therefore, the developer makes the \nfollowing code-update: \nRepeat  \nIf tl_permitted then turn_left,  \nturn_right,  \nmove_straight  \nUntil false \nFurthermore, a semantic anchor is created that maps the WA (specified in HATCL) to code that can \nbe interpreted by the autonomous system: \nprohibited(turn_left) -> tl_permitted=false \nExample 2: Assume now that the autonomous system\u2019s actions do not have the attribute tl_permitted. \nInstead, the system has a variable map indicating the desirability of each position on the ground, which is \nused to determine where to move. In this case, the anchor would access the variable map and set a low \ndesirability on the coordinates on the system\u2019s left side. \n \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 15 \n \n \nAs this example shows, multiple ways exist in which a semantic anchor can be realized. In general, the \nhuman interfaces work at a higher abstraction level than the internal control logic of the autonomous system. \nThis means that semantic anchors whose information flows from the teaming software towards the system \nperform a translation into a lower abstraction level. Whereas the translation into a higher abstraction level \noccurs when the information flow is reversed. Note that this does not need to be the case nor are semantic \nanchors limited to a one direction flow of information. See the figure below for two examples of the \nfunctionality of semantic anchors. The top anchor simply acts as a gateway between an abstract variable in \nthe teaming software and the system, as the abstract meaning is appropriate in both (see the example 1). \nWhereas the bottom anchor performs an actual translate operation and whose information flow is \nbidirectional (see example 2). Also note the presence of the API as a distinct entity. \n \n \n \nFigure 4-4: Semantic anchors describe how abstract variables in the HATCL ontology are grounded in the \nvariables available in the autonomous system \nNote that semantic anchoring can become very difficult or even impossible depending on the representations \nused. HATCL is based on the symbolic representation paradigm where each element corresponds to one \nentity. Neural Networks, which are widely used in AI applications such as autonomous driving and image \nclassification, are based on distributed representations [29]. In these representations, each entity is \nrepresented by a pattern of activity distributed over many elements. How to map HATCL to distributed \nrepresentations in a neural net remains an open question. \n \n4.2.5 Software implementation of SAIL \nSAIL is implemented using an open source distributed application framework, called Akka, which is used \nas a software wrapper around the various pieces of code, making it a coherent human-agent system. The \nSAIL components can be programmed in any language, and may run on any type of hardware (e.g. robots, \nhead-mounted displays, mobile devices, sensors). \n \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 16 PUB REF NBR (e.g. STO-MP-IST-999) \n \n \nFigure 4-5 SAIL development environment allowing the HAT engineer to add extra SAI modules and configure \nthe system\u2019s set of fixed working agreements and ontologies. \nThe figure above shows the Sail development environment. The different SAIL components can be added \nto the tree on the left-hand side of the window. The configuration of these components is done on the right-\nhand side. Other tabs can be used to specify the policies (working agreements), and ontologies that are \nshared within this system. \n5.0 PROTOTYPE OF A HAT APPLICATION WITHIN SAIL  \nTo demonstrate the application of the techniques discussed in the previous section, we used a case for aerial \nsurveillance of a compound as described in Section 2.2.1. The proof of concept implements an initial subset \nof the proposed common HAT functions and shows that the underlying concepts and SAIL architecture \ntranslate into a viable HAT set-up. The surveillance scenario is recreated as a virtual environment. This \nsimulation (implemented in Gazebo [35]) includes a 3D modelled military compound, a variety of potential \nthreats in the vicinity of this compound as well as a swarm of UAVs that survey the surrounding area. \n \nFigure 5-1 the Gazebo simulation environment, which provides the backbone of the prototype but which is \ntypically not visible as such to the base commander. \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 17 \n \n \nTask-related functionality of the UAVs is implemented in TAI modules that cover capabilities such as \nwaypoint navigation, path planning, object detection, video streaming, and threat identification. Using its \nset of TAI modules, each UAV is capable of autonomously scanning the surroundings of the military \ncompound for suspicious activities. \nTo turn the UAV\u2019s into teammates, we added a Social Artificial Intelligence Layer (SAIL). This \nlayer includes a set of SAI modules, including a multi-modal user interface, and offers the infrastructure to \nprovide the middleware between the task-oriented modules and the human team members. In the proof of \nconcept, we have implemented and combined a number of core HAT functions (as discussed in Section 3), \nnamely those for shared situational awareness, proactive communication (ProCom), human-aware \ncomputing, HAT communication, and the work agreement mechanism. \n \nFigure 5-2 An overview of the main SAI modules within the base protection HAT.  \nThe figure above shows the SAI modules that are related to proactive communication (ProCom). ProCom \naims to establish a balance between the value of sharing information and the costs of imposing cognitive \nworkload on the human team member. The autonomous system (the UAV) performs the task of aerial \nsurveillance. Using a semantic anchor, events are published using HATCL and made available to the SAI \nmodule relevance assessment. This module regards each event as a topic and assesses its relevance to the \nhuman team member. For example, topics about the detection of a potential hostile contact are more relevant \nthan topics about a friendly civilian contact. Also, when the human team member has explicitly asked for a \ncertain topic, this topic has high relevance. The SAI module \u201cuser state assessment\u201d builds up a value that \nindicates the cognitive task load of the human team member (how busy he/she is) and the situational \nawareness (what the human team member currently does and does not know). Based on this information, \nthe SAI module interaction selection decides whether that information should be communicated to the \nhuman team member or not and in which way (e.g. using a textual message or using a voice-message). More \ninformation on content-based modality selection can be found in earlier work [17].  \nThe combined SAI functionality manifests itself to the human team member in the form of an avatar. \nThe avatar is able to maintain a dialogue with the human team member and act as an intuitive interface \nbetween him/her and the SAI components of the autonomous agents (e.g. UAVs). In addition the avatar acts \nas an intelligent information retrieval system, capable of accessing various information resources within the \navailable SAIL modules. The avatar responds to speech, typed chat messages, and touch input from the \nhuman team member. Its actions can vary from information retrieval, engaging conversational dialogues \nwith the UAVs, establishing work agreements with these SAI-plugged agents and displaying (task-related) \ncontent tiles on one of the available computer screens. \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 18 PUB REF NBR (e.g. STO-MP-IST-999) \n \n \nFigure 5-3 The avatar representing the UAV swarm and the dialogue window enabling interaction. \nThe figure above shows the avatar (the round circle on the right), and the dialogue window which interacts in \na similar way as Google Allo (https://allo.google.com/). Natural language input can be inputted via speech or \ncommand buttons, and a history of the conversation is shown using text balloons. Besides replying to the \nhuman team member\u2019s input via text messages, the system can also open up additional windows to visualise \ninformation and provide new ways of interaction, such as maps, camera feeds of the robots, etc. Note that this \ncan only be done if sufficient screen space is available.  \n           \nFigure 5-4 The demonstration environment of the base protection HAT. When the autonomous system is not \nencountering problems, the base commander is not distracted with any information (as on the left hand side). \nWhen problems occur, the base commander can drill down on every piece of relevant task information. \nThe figure above shows the set-up of the demo, consisting of three large information displays, a MS surface \npro touch interaction device, microphone, and speakers. When the UAVs are functioning normally, the \nscreens show as little information as possible, and only the avatar is visible (see the right hand side of the \nFigure). When an important topic arises, such as a suspicious contact, more and more information is \nexchanged between the UAV swarm and the base commander. The right hand side of the figure shows the \nsituation in which the individual camera-feeds of the UAVs are shown to the base commander allowing the \nUAV and base commander to make a joint decision on how to classify the object. After the issue is solved, \nthe topic becomes irrelevant again which implies that all camera-feeds close, and the interface returns to its \ncalm state again. \nThe application described above illustrates a management-by-exception type of HAT. This means \nthat the base commander is not bothered with superfluous information when this is not needed. However, \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 19 \n \n \nupon request, or by system initiative, a rich interaction can be set up which drills down to the details of the \nmatter at hand. \n6.0 CONCLUSION \nHuman agent teaming is a problem with many faces. This paper is an attempt to combine a human factors, \nengineering, and military perspective on the issue. Our solution is based on the idea of a Social Artificial \nIntelligence Layer (SAIL), which is a framework for the development of HMT-concepts. The starting point \nof SAIL is that a HAT can be developed without changing the internal capabilities of the autonomous \nsystem. We have argued that these social capabilities are to some extent generic. Examples are functions for \nsituation awareness, human awareness, explainable AI, working agreements and tasking. Within SAIL, \nHAT-modules are developed that construct these social capabilities. The modules are reusable in multiple \ndomains.  \nWe have demonstrated the use of SAIL by building an application for military compound protection \nusing surveillance drones. The surveillance drones where simulated using the robot simulation environment \nGazebo, and SAIL was used to build a teaming layer on top of it. The approach resulted in a system which \nembraces a management by exception type of HAT: no information reaches the human teammember, unless \na problem arises which requires negotiation.  \n We believe that our approach is promising and an important step towards developing and prototyping \nhuman agent teaming applications in the defence domain. We identify three directions for future work. Firstly, \nwe intend to develop more complex types of semantic anchors, and explore which autonomous system \narchitectures enable which types of anchors. This allows us to discover the boundaries of HAT applications, \nas only those types of information can be communicated which can actually be anchored in the agent. \nSecondly, we intend to explore validation methods for HAT applications, which also take the long term aspects \nof teaming into account. Thirdly, we intend to explore combinations of HAT interaction with more immersive \ninteraction techniques such as tele-presence.  \n7.0 REFERENCES \n[1] Albus, J. S., Huang, H. M., Messina, E. R., Murphy, K., Juberts, M., Lacaze, A., ... & Proctor, F. M. \n(2002). 4D/RCS Version 2.0: A reference model architecture for unmanned vehicle systems (No. \nNIST Interagency/Internal Report (NISTIR)-6910). \n[2] Article36. (2015). Killing by machine - Key issues for understanding meaningful human control. \nRetrieved on July 30, 2018 from: http://www.article36.org/weapons-review/killing-by-machine-key-\nissues-for-understanding-meaningful-human-control/ \n[3] Article36. (2014). Key areas for debate on autonomous weapons systems. Retrieved on July 30, 2018 \nfrom http://www.article36.org/wp-content/uploads/2014/05/A36-CCW-May-2014.pdf \n[4] Beer, J. M., Fisk, A. D., & Rogers, W. A. (2014). Toward a framework for levels of robot autonomy \nin human-robot interaction. Journal of Human-Robot Interaction, 3(2), 74\u201399.  \n[5] Bethel, C. L., Carruth, D., & Garrison, T. (2012, November). Discoveries from integrating robots into \nSWAT team training exercises. In Safety, Security, and Rescue Robotics (SSRR), 2012 IEEE \nInternational Symposium on (pp. 1-8). IEEE. \n[6] Bolman, L. (1979). Aviation accidents and the \"theory of the situation.\" In G. E. Cooper, M. D. White, \nand J. K. Lauber (Eds.), Resource management on the flight deck: Proceedings of a NASA/industry \nworkshop (pp. 31-58). Moffett Field, CA: NASA Ames Research Center. \n[7] Boulanin, V., & Verbruggen, M. (2017). Mapping the development of autonomy in weapon systems. \nStockholm International Peace Research Institute (SIPRI). Retrieved on July 30, 2018 from: \nhttps://www.sipri.org/publications/2017/other-publications/mapping-development-autonomy-\nweapon-systems  \n[8] Bradshaw, J. M., Feltovich, P. J., Johnson, M. J., Bunch, L., Breedy, M. R., Eskridge, T., ... & Uszok, \nA. (2008, May). Coordination in human-agent-robot teamwork. In Collaborative Technologies and \nSystems, 2008. CTS 2008. International Symposium on (pp. 467-476). IEEE. \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 20 PUB REF NBR (e.g. STO-MP-IST-999) \n \n[9] Campaign to Stop Killer Robots, \u201cThe Problem,\u201d retrieved on July 24, 2018 from: \nhttp://www.stopkillerrobots.org/the-problem/  \n[10] Cannon-Bowers JA, Salas E, Blickensderfer E, et al. (1998) The impact of cross-training and \nworkload on team functioning: A replication and extension of initial findings. Human Factors: The \nJournal of the Human Factors and Ergonomics Society 40: 92\u2013101. \n[11] Clark, H.H. (1992). Arenas of language use. Chicago: University of Chicago Press. \nCoradeschi, S., Loutfi, A., & Wrede, B. (2013). A short review of symbol grounding in robotic and \nintelligent systems. KI-K\u00fcnstliche Intelligenz, 27(2), 129-136. \n[12] Daft, R. L., & Lengel, R. H. (1986). Organizational information requirements, media richness and \nstructural design. Management science, 32(5), 554-571. \n[13] Danzig, R. (2018). Technology roulette \u2013 managing loss of control as many militaries pursue \ntechnological superiority. Center for a New American Security. Retrieved on August 7, 2018 from: \nhttps://www.cnas.org/publications/reports/technology-roulette  \n[14] David, R. A., & Nielsen, P. (2016). Defense science board summer study on autonomy. Defense \nScience Board Washington United States. Retrieved on July 30, 2018 from: \nhttps://www.hsdl.org/?view&did=794641  \n[15] Dennett, D. C. (1989). The intentional stance. MIT press. \n[16] van Diggelen, J., Bradshaw, J. M., Johnson, M., Uszok, A., & Feltovich, P. J. (2010). Implementing \ncollective obligations in human-agent teams using KAoS policies. In Coordination, Organizations, \nInstitutions and Norms in Agent Systems V (pp. 36-52). Springer, Berlin, Heidelberg. \n[17] van Diggelen, J., Grootjen, M., Ubink, E. M., van Zomeren, M., & Smets, N. J. (2013). Content-based \ndesign and implementation of ambient intelligence applications. In Ambient Intelligence-Software \nand Applications (pp. 1-8). Springer, Heidelberg. \n[18] Dignum, M. V. (2004). A model for organizational interaction: based on agents, founded in logic. \nSIKS. \n[19] Docherty, B. L., Human Rights Watch (Organization), Harvard Law School, & International Human \nRights Clinic. (2016). Making the case: the dangers of killer robots and the need for a preemptive \nban. Retrieved on July 30, 2018 from: https://www.hrw.org/report/2016/12/09/making-case/dangers-\nkiller-robots-and-need-preemptive-ban \n[20] Endsley, M. R. (1988). Situation awareness global assessment technique (SAGAT). In Aerospace and \nElectronics Conference, 1988. NAECON 1988., Proceedings of the IEEE 1988 National (pp. 789\u2013\n795). IEEE. \n[21] Endsley, M. R. (1995). Toward a theory of situation awareness in dynamic systems. Human Factors: \nThe Journal of the Human Factors and Ergonomics Society, 37(1), 32\u201364. \n[22] de Greef, T., Arciszewski, H., & van Delft, J. (2006, September). Adaptive Automation using an \nobject-orientated task model. In: Proceedings MAST conference (pp. 4-6). \n[23] Fipa, (2002). Fipa acl message structure specification. Foundation for Intelligent Physical Agents, \nhttp://www. fipa. org/specs/fipa00061/SC00061G. html (30.6. 2004). \n[24] Gilson, L. L., Maynard, M. T., Jones Young, N. C., Vartiainen, M., & Hakonen, M. (2015). Virtual \nteams research: 10 years, 10 themes, and 10 opportunities. Journal of Management, 41(5), 1313-1337. \n[25] Goodrich, M. A., McLain, T. W., Anderson, J. D., Sun, J., & Crandall, J. W. (n.d.). Managing \nAutonomy in Robot Teams: Observations from Four Experiments, 8. \n[26] Gray, B. (1989). Collaborating: Finding common ground for multiparty problems. \n[27] Grice, H.P. (1975). Logic and conversation. In E Cole & J. Morgan (Eds.), Syntax and semantics 3: \nSpeech acts. New York: Academic Press. \n[28] Guidotti, R., Monreale, A., Turini, F., Pedreschi, D., & Giannotti, F. (2018). A survey of methods for \nexplaining black box models. arXiv preprint arXiv:1802.01933. \n[29] Hinton, G. E., McClelland, J. L., & Rumelhart, D. E. (1984). Distributed representations (pp. 1-127). \nPittsburgh, PA: Carnegie-Mellon University. \n[30] Horton, W. S., & Keysar, B. (1996). When do speakers take into account common ground?. \nCognition, 59(1), 91-117. \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 21 \n \n \n[31] Howard, N., & Cambria, E. (2013). Intention awareness: improving upon situation awareness in \nhuman-centric environments. Human-Centric Computing and Information Sciences, 3(1), 9. \n[32] Human Rights Watch (2016). Killer Robots and the Concept of Meaningful Human Control. \nMemorandum to Convention on Conventional Weapons (CCW) Delegates. Retrieved on July 30, \n2018 from: https://www.hrw.org/news/2016/04/11/killer-robots-and-concept-meaningful-human-\ncontrol \n[33] Kauffeld, S., & Lehmann-Willenbrock, N. (2012). Meetings matter: Effects of team meetings on team \nand organizational success. Small Group Research, 43(2), 130-158. \n[34] Klein, G., Feltovich, P. J., Bradshaw, J. M., & Woods, D. D. (2005). Common ground and \ncoordination in joint activity. Organizational simulation, 53, 139-184. \n[35] Koenig, N. P., & Howard, A. (2004, September). Design and use paradigms for Gazebo, an open-\nsource multi-robot simulator. In IROS (Vol. 4, pp. 2149-2154). \n[36] Jennings, N.R., Sycara, K., Wooldridge, M.: A roadmap of agent research and development. \nAutonomous Agents and Multi-Agent Systems 1 (1998) 275\u2013306. \n[37] Johnson, M., Bradshaw, J. M., Feltovich, P. J., Hoffman, R. R., Jonker, C., Van Riemsdijk, B., & \nSierhuis, M. (2011). Beyond cooperative robotics: The central role of interdependence in coactive \ndesign. Intelligent Systems, 26(3), 81\u201388. \n[38] Knox WB and Stone P (2013) Learning non-myopically from human-generated reward. In: \nProceedings of the 2013 international conference on intelligent user interfaces, pp. 191\u2013202. \n[39] Mioch, T., Kroon, L., & Neerincx, M. A. (2017). Driver Readiness Model for Regulating the Transfer \nfrom Automation to Human Control (pp. 205\u2013213). ACM Press. \n[40] Mioch, T., Peeters, M. M. M., and Neerincx M. A. (2018) Improving Adaptive Human-Robot \nCooperation through Work Agreements. In: International Conference on Robot and Human \nInteractive Communication (RO-MAN), Nanjing, China. IEEE. \n[41] Murphy, R. & Shields, J. (2012). The Role of Autonomy in DoD Systems (No. 20301\u20133140). \nWashington D.C.: Defense Science Board. Retrieved on July 30, 2018 from: \nhttps://fas.org/irp/agency/dod/dsb/autonomy.pdf \n[42] Neerincx, M. A., van der Waa, J., Kaptein, F., & van Diggelen, J. (2018, July). Using Perceptual and \nCognitive Explanations for Enhanced Human-Agent Team Performance. In International Conference \non Engineering Psychology and Cognitive Ergonomics (pp. 204-214). Springer, Cham. \n[43] Nikolaidis, S., Lasota, P., Ramakrishnan, R., & Shah, J. (2015). Improved human\u2013robot team \nperformance through cross-training, an approach inspired by human team training practices. The \nInternational Journal of Robotics Research, 34(14), 1711-1730. \n[44] Norman, D. A. (2014). Some observations on mental models. In Mental models (pp. 15-22). \nPsychology Press. \n[45] Peeters, M. M. M., van den Bosch, K., Neerincx, M. A., & Meyer, J.-J. C. (2014). An ontology for \nautomated scenario-based training. International Journal of Technology Enhanced Learning, 6(3), \n195\u2013211. \n[46] Salas, E., Prince, C., Baker, D. P., & Shrestha, L. (1995). Situation Awareness in Team Performance: \nImplications for Measurement and Training. Human Factors: The Journal of the Human Factors and \nErgonomics Society, 37(1), 123\u2013136. \n[47] Salas, E., Sims, D. E., & Burke, C. S. (2005). Is there a \u201cbig five\u201d in teamwork? Small group research, \n36(5), 555-599. \n[48] Scharre, P., & Horowitz, M. C. (2018). Artificial Intelligence: What Every Policymaker Needs to \nKnow. Center for a New American Security. Retrieved on July 30, 2018 from: \nhttps://www.cnas.org/publications/reports/artificial-intelligence-what-every-policymaker-needs-to-\nknow \n[49] Schaub, G., & Kristoffersen, J. W. (2017). In On or Out of the Loop - Denmark and Autonomous \nWeapon Systems. Centre for military studies, University of Copenhagen. Retrieved on July 30, 2018 \nfrom: https://cms.polsci.ku.dk/english/publications/in-on-or-out-of-the-\nloop/In_On_or_Out_of_the_Loop.pdf \nPluggable Social Artificial Intelligence for enabling Human-Agent Teaming \n  \nPAPER NBR - 22 PUB REF NBR (e.g. STO-MP-IST-999) \n \n[50] Searle, J. R., (1969). Speech acts: An essay in the philosophy of language (Vol. 626). Cambridge \nuniversity press. \n[51] Singh, M. P. (1999). An Ontology for Commitments in Multiagent Systems: Toward. Artificial \nIntelligence and Law, 7, 97--113.  \n[52] Stanton, N. A., Salmon, P. M., Walker, G. H., Salas, E., & Hancock, P. A. (2017). State-of-science: \nsituation awareness in individuals, teams and systems. Ergonomics, 60(4), 449-466. \n[53] Stalnaker, R. (2002). Common ground. Linguistics and philosophy, 25(5-6), 701-721. \n[54] Sundstrom, E., De Meuse, K. P., & Futrell, D. (1990). Work teams: Applications and effectiveness. \nAmerican psychologist, 45(2), 120. \n[55] Vagia, M., Transeth, A., and Fjerdingen, S. (2016) \u2018A Literature Review on the Levels of Automation \nDuring the Years. What are the Different Taxonomies that have been Proposed?\u2019, Applied \nErgonomics, 53, pp. 190-202.  \n[56] van der Vecht, B., Dignum, F., Meyer, J.-J. C., & Neef, M. (2008). A dynamic coordination \nmechanism using adjustable autonomy. In Coordination, Organizations, Institutions, and Norms in \nAgent Systems III (pp. 83\u201396). Springer. \n[57] de Visser, E. J., Pak, R., & Shaw, T. H. (2018). From \u2018automation\u2019 to \u2018autonomy\u2019: the importance of \ntrust repair in human\u2013machine interaction. Ergonomics, 1-19. \n[58] de Visser, E. J., Peeters, M. M. M., Jung, M. F., Kohn, S., Shaw, T. H., Pak, R., and Neerincx, M. A. \n(under review) Longitudinal Trust Development in Human-Robot Teams: Models, Methods and a \nResearch Agenda. IEEE Transactions on Human-Machine Systems, special issue. \n[59] Wieringa, R. J., & Meyer, J.-J. C. (1993). Applications of deontic logic in computer science: A \nconcise overview. Deontic Logic in Computer Science, 17\u201340. \n[60] Williams, A. P., & Scharre, P. D. (2015) \u2018Autonomous Systems \u2013 Issues for Defence Policymakers\u2019. \nRetrieved on July 30, 2018 from: www.dtic.mil/docs/citations/AD1010077. NATO ACT. \n[61] Woods, D. D., & Cook, R. I. (2002). Nine steps to move forward from error. Cognition, Technology \n& Work, 4(2), 137-144. \n[62] Wooldridge, M. (2008). An introduction to multi agent systems. ISBN: 9780470519462. Wiley. \n[63] Yen, J., Fan, X., Sun, S., Hanratty, T., & Dumer, J. (2006). Agents with shared mental models for \nenhancing team decision makings. Decision Support Systems, 41(3), 634-653. \n \n  \nPluggable Social Artificial Intelligence for Enabling Human-Agent Teaming \nPUB REF NBR (e.g. STO-MP-IST-999) PAPER NBR - 23 \n \n \n   \n \n",
        "id": 89569463,
        "identifiers": [
          {
            "identifier": "1909.04492",
            "type": "ARXIV_ID"
          },
          {
            "identifier": "334857113",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:arxiv.org:1909.04492",
            "type": "OAI_ID"
          }
        ],
        "title": "Pluggable Social Artificial Intelligence for Enabling Human-Agent\n  Teaming",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:arxiv.org:1909.04492"
        ],
        "publishedDate": "2019-09-16T01:00:00",
        "publisher": "",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://arxiv.org/abs/1909.04492"
        ],
        "updatedDate": "2020-12-24T15:00:07",
        "yearPublished": 2019,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "http://arxiv.org/abs/1909.04492"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/89569463"
          }
        ]
      },
      "relevance_score": 0.125,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.25,
          "dimension_weight": 0.35,
          "weighted_score": 0.0875,
          "matched_keywords_detail": {
            "human_agent_teaming_collaboration": [
              "human-agent teaming"
            ]
          }
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.375,
          "dimension_weight": 0.1,
          "weighted_score": 0.0375,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2019 (Norm. Score: 0.6)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_primary_2",
      "dynamic_step": 0,
      "core_id": 89569463,
      "doi": null
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": "1812.08198",
        "authors": [
          {
            "name": "Chao, Han-Chieh"
          },
          {
            "name": "Guizani, Mohsen"
          },
          {
            "name": "Zhang, Wenyu"
          },
          {
            "name": "Zhang, Zhenjiang"
          }
        ],
        "citationCount": 0,
        "contributors": [],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/186305968"
        ],
        "createdDate": "2019-02-06T06:50:57",
        "dataProviders": [
          {
            "id": 144,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/144",
            "logo": "https://api.core.ac.uk/data-providers/144/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "In wireless communication systems (WCSs), the network optimization problems\n(NOPs) play an important role in maximizing system performances by setting\nappropriate network configurations. When dealing with NOPs by using\nconventional optimization methodologies, there exist the following three\nproblems: human intervention, model invalid, and high computation complexity.\nAs such, in this article we propose an auto-learning framework (ALF) to achieve\nintelligent and automatic network optimization by using machine learning (ML)\ntechniques. We review the basic concepts of ML techniques, and propose their\nrudimentary employment models in WCSs, including automatic model construction,\nexperience replay, efficient trial-and-error, RL-driven gaming, complexity\nreduction, and solution recommendation. We hope these proposals can provide new\ninsights and motivations in future researches for dealing with NOPs in WCSs by\nusing ML techniques.Comment: 8 pages, 5 figures, 1 table, magzine articl",
        "documentType": "research",
        "doi": null,
        "downloadUrl": "http://arxiv.org/abs/1812.08198",
        "fieldOfStudy": null,
        "fullText": "ar\nX\niv\n:1\n81\n2.\n08\n19\n8v\n1 \n [c\ns.N\nI] \n 19\n D\nec\n 20\n18\n1\nToward Intelligent Network Optimization in\nWireless Networking: An Auto-learning Framework\nWenyu Zhang, Zhenjiang Zhang, Han-Chieh Chao, Mohsen Guizani\nAbstract\u2014In wireless communication systems (WCSs), the\nnetwork optimization problems (NOPs) play an important role in\nmaximizing system performances by setting appropriate network\nconfigurations. When dealing with NOPs by using conventional\noptimization methodologies, there exist the following three prob-\nlems: human intervention, model invalid, and high computation\ncomplexity. As such, in this article we propose an auto-learning\nframework (ALF) to achieve intelligent and automatic network\noptimization by using machine learning (ML) techniques. We\nreview the basic concepts of ML techniques, and propose their\nrudimentary employment models in WCSs, including automatic\nmodel construction, experience replay, efficient trial-and-error,\nRL-driven gaming, complexity reduction, and solution recom-\nmendation. We hope these proposals can provide new insights\nand motivations in future researches for dealing with NOPs in\nWCSs by using ML techniques.\nI. INTRODUCTION\nIn wireless communication systems (WCSs), network op-\ntimization problems (NOPs) have been extensively studied to\nmaximize system performances by setting appropriate network\nconfigurations settings [1]. NOP contains a broad range of\nresearch aspects in wireless networking, typical applications\ninclude resource allocation and management, system parame-\nter provision, task scheduling, and user QoS optimization. Fig.\n1 shows the basic process of solving a NOP in WCSs, which\nincludes the following four steps:\nData Collection: which collects essential information of\nthe system and the surrounding environment. The collected\ndata can be channel state information (CSI), interference,\nnoise, user location, spectrum and time-slot occupations, etc.\nSome QoS information, such as delay and energy consumption\nrates, mobility state, also can be the input data to support the\nfollowing optimization process.\nModel Construction: in which the expert constructs an\noptimization model that contains an objective function and\nseveral constraints. The objective of the optimization model\ncan be throughput, spectrum utilization, user-perceive delay,\nenergy consumption/gain, and facility deployment cost, etc.\nTypically, model construction is conducted by using a math-\nematical formulation process, and the experts are required to\nThis article is going appear in IEEE Wireless Communications.\nW. Zhang and Z. Zhang are with the School of Electronic and Information\nEngineering, Key Laboratory of Communication and Information Systems,\nBeijing Municipal Commission of Education, Beijing Jiaotong University,\nBeijing, 100044, China.\nS. Zeadally is with the College of Communication and Information,\nUniversity of Kentucky, Lexington, KY 40506 USA\nH.-C. Chao is with the Department of Electrical Engineering, National Dong\nHwa University, Hualien 974, Taiwan.\nM. Guizani is with the College of Engineering, University of Idaho,\nMoscow, ID 83844-1023 USA.\nmaster the domain knowledge and theories involved in the\nmodel.\nOptimization: The most commonly used methodologies for\nsolving optimization problems are mathematical derivation-\nbased methods (DBMs) and heuristic algorithms. The for-\nmer one adopts a mathematical derivation process to find\nthe solution, such as the Lagrangian multiplier, KKT con-\nditions, and gradient descendent methodologies. The latter\none adopts a heuristical neighborhood searching process to\napproach the optimal solution, including genetic algorithm,\nsimulated annealing, particle swarm optimization, and firefly\nalgorithms, etc. In general, DBMs are quite suitable for solving\nproblems with explicit and convex objective functions, while\nheuristic algorithms does not require the derivatives of the\nobjective functions, and are generally able to produce high-\nquality solutions for complex optimization problems if the\noptimization complexity is suitably high enough [2]. Except\nthe above two optimization methods, game theoretical tech-\nniques, including non-cooperative games, cooperative games,\nand Bayesian games, also have been successfully applied to\nsolve the optimization problem by learning automatic config-\nuration strategies from the interactions with other functional\nnodes [3].\nConfiguration: With the optimization results, the system\nthen reconfigures the settings of the system to improve the\nperformance. Possible reconfigurations may include transmis-\nsion power allocation, energy harvesting scheduling, routing\ndecision, spectrum resource allocation, to name a few. After\nconfiguration, the system then repeats the optimization process\nto keep the system in suitable working conditions.\nAlthough NOPs have been extensively studied in WCSs,\nexisting optimization methodologies still face the following\nthree dilemmas:\nHuman intervention. The optimization models in NOPs are\nalways constructed by experts with domain knowledge, and\nthis knowledge-driven process is expensive and inefficient in\npractical implementations. If we can conduct the optimization\noperations automatically, network optimization will be more\neasy to be conducted in real world applications. However,\nhow to reduce human intervention in solving NOPs is still\na unexplored field in WCSs.\nModel invalid. With the development of hardware and soft-\nware techniques, the WCS is becoming an increasingly com-\nplex system with more users, more access ways, more complex\nfunctions and relationships among the network entities. In ad-\ndition to transmitting power and the channel states, the system\nperformances are also deeply influenced by the factors such\nas the software, hardware, interference, noise, and physical\n2Optimization\nConfiguration\nData collection\nModel \nConsturction\nThroughput\nSpectrum Utilization\nEnergy Cost/Gain\nUser-perceive Delay \nDeployment Cost\n...\nObjective and\nConstraints\nChannel State\nInterference/Noise\nSpectrum/Slot\nLatency/Energy\nMobility state\nComputation/Storage\n...\nTransmitting power\nEnergy harvesting\nRouting decision\nSpectrum allocation\nComputing/Caching allocation\nTask offloading\nCoding/Decoding\n...\nHeuristic \nalgorithms\nDBMs\nGenetic algorithm\nSimulated annealing\nFirefly algorithm\n...\nGradient descendent\nLagrangian multiplier\nKKT condition\n\u010a\nNon-cooperative games\nCooperative games\nBayesian games\n...\nGame \nTheory\nFig. 1. Workflow of network management in wireless communication systems.\nenvironment, and these factors are always unpredictable and\nhard to be formulated with explicit formulas. It is hard, or even\nunpractical for us to find the valid mathematical formulations\nfor these factors, especially for the performance indices like\ndelay and energy consumption rate influenced by the above\nunpredictable factors. In some situations, even if we have\nmathematical models to formulate the relationship functions,\nthe actual implementation results are far from satisfactory due\nto the mismatches between theories and realities.\nHigh complexity. Solving complex optimization problems\nmay lead to expensive time cost due to the computation inten-\nsive optimization process, especially for complex NOPs with\nhigh dimensional solutions. In this situation, the efficiency\nof the algorithm may be unacceptable to meet the real-time\nrequirement for delay-sensitive applications, such as gaming\nand vehicle networks. Even if the efficiency is acceptable,\nthe continuous optimization process requires high computation\nenergy cost in practical implementations. Predictably, in the\nfuture the complexity of WCSs will become more higher, and\nthe corresponding NOP problem will also be more complex.\nDeveloping new effective and efficient models to solve these\ncomplex POPs is in urgent need in the research of future\nwireless networks.\nIn recent years, machine learning (ML) techniques have\nshown its powerful magics in dealing networking problems,\nsuch as traffic prediction, point-to-point regression, and signal\ndetection [4][5]. However, yet the application of ML in dealing\nNOPs has not been fully discussed in existing works. In this\narticle, we focus on dealing with the NOPs in WCSs, and\npropose an auto-learning framework (ALF) that employs the\nML techniques to achieve intelligent and automatic network\noptimization in WCSs. Within ALF, we propose several poten-\ntial paradigms, including automatic model construction, expe-\nrience replay, efficient trial-and-error, reinforcement learning-\ndriven gaming, complexity reduction, and solution recommen-\ndation. The basic workflows, applications, and the challenges\nof these models will be discussed.\nII. AUTO-LEARNING FRAMEWORK\nAs shown in Fig. 2, we propose an auto-learning frame-\nwork (ALF) to achieve intelligent and automatic network\noptimization in WCSs. The basic workflow of ALF includes\nthe following three steps:\nData Collection. Collecting the experience data is the\nprerequisite for conducting the ML-based models [6], and must\nbe properly addressed. Except the system and environment\nstate information, in ALF the output solution data of an opti-\nmization process will also be collected as historical experience.\nWhen the training data are not sufficient, the system may need\nto conduct a resampling process to collect more data. A data\nfiltering process needs to be done since the quality of used\ndata has critical influences on the performance of the obtained\nblack-box model. The outliers, incomplete data, and repeating\ndata will be abandoned or refined in data filtering process.\nModel Training. The model training process is conducted\nin a ML engine, in which different ML techniques are pro-\nvided, including supervised learning, reinforcement learning\n(RL), and unsupervised learning. Their detailed application\nmodels will be introduced in the following section. After\ntraining, a cross validation process needs to be conducted to\ntest the performance of the obtained model. More specifically,\nwhen the learning problem is a regression problem, i.e. outputs\nare continuous, the performance metric is the mean square\nerror (MSE) between the predicted results and real outputs.\nWhen the outputs are discrete decisions, the problem can\n3Machine learning Models\nInput\nData \nCollection\n......\n...\n...\n...\n...\n...\n......\n...\n...\nOutput\nTraining\n&\nDeployment\nHistorical \nExperience \nData\nNetwork \nManagement \nOperations\nData filtering\nData filtering\nData Sampling\nMachine Learning Engine\nCreate Task\nTraining Data\nNew data\nSupervised Learning\nUnsupervised Learning\nReinforcement Learning\nConfigurations\nConfigurations\nFig. 2. Auto-learning framework for dealing with NOPs in WCSs.\nregarded as a classification problem, and the performance\nmetric can be classification accuracy.\nModel Application. Once a learning model is properly\ntrained, it can be deployed in real-world WCSs. Given a new\ninput instance, it passes through the mapping model and the\ncorresponding output can be easily obtained in an efficient\nway.\n\u2022 Model Deployment. The deployment of the mapping\nmodel is very easy to be achieved. The calculation process\nmainly includes matrix multiplications and non-linear trans-\nforms with activation functions, and both of them can be easily\ncalculated.\n\u2022 Model Refinement. The black-box auto-learning model\nmay need to be refined due to the change of wireless systems\nand environments, and imperfect training data. The dynamic\nadjusting of a ML-model can be regarded an incremental\nlearning problem, and the key step is the proper updating of\ntraining data instances. Therefore, it is suggested to updating\nthe training data set periodically to guarantee the obtained\nmodel perform well when the system model is changed.\nIII. SUPERVISED LEARNING: AUTOMATIC MODEL\nCONSTRUCTION AND EXPERIENCE REPLAY\nWith sufficient training data, a complex non-linear mapping\nfunction from input data space to the output data space\ncan be obtained by training a supervised learning model.\nBenefit from this learning ability, supervised learning has\nbeen successfully applied in point-to-point learning tasks in\ncommunications systems, such as delay prediction, channel\nestimation and signal detection [7]. According to the amount\nof training samples, supervised learning can be divided into\nthe following two categories: small-sample learning (SSL)\nand deep learning (DL). Possible choices of SSL include\nshallow neural networks, kernel-based methods, and ensemble\nlearning methods. For DL, possible choices include deep\nbelief networks, and deep Boltzmann machines, and deep\nconvolutional neural networks [8].\nA. Automatic Model Construction\nModel: Supervised learning-based black-box regression\nprovides an effective way to solve the expensive human\nintervention and model invalid problems. In situations when\nthe explicit functions between the input and output are not\navailable, but we have sufficient data samples that contain the\ninputs and outputs of the system, the mapping function can\nbe trained by using a supervised regression technique. Given\na new input data, the target performance objective can be\naccurately predicted by using the previously obtained model.\nWe propose to use supervised learning techniques to auto-\nmatically conduct the model constructions process in NOPs.\nAs illustrated in Fig. 3(a), in conventional NOPs, the math-\nematical optimization model is constructed by experts with\ndomain knowledge. In ALF, we propose to use black-box\nmodeling to automatically construct the optimization model,\nas shown in Fig. 3(b). In the automatic model construction\nprocess, we can directly regress the objective function and\nconstraints by using regression models. In the same way,\nthe constraints can also be constructed. With the obtained\nmodel, a following heuristic algorithm can be used to solve the\noptimization model, since it just needs to know the objective\nresponse in each searching iteration.\nWhen the target function contains several independent parts,\nwe can firstly train the independent mapping functions of\nthese parts, and then combine them into a unified one. For\nexample, in mobile edge computing, the user-perceive delay\nmainly includes three parts: data transmission time, queuing\ntime, and task execution time. In this scenario, we can build the\noptimization model by combining the three black-box delay\ntime prediction models.\nChallenges: The successful implementation of a supervised\nlearning method requires a dataset with sufficient and reliable\n4Domain knowledge \nand theory\nMathematical \nOptimization Model\nExperts\n(a)\nHistorical data \nrecords\nBlack-box \nOptimization Model\nInput Output\nModel Training\n......\n...\n...\n...\n...\n...\n(b)\nSupervised Learning Models\nModel Formulation\nFig. 3. Comparison of model construction process, in which (a) conventional mathematical model construction, and (b) automatic model construction using\nsupervised learning-based regression techniques.\ndata samples to train the mapping model. In some tasks like\nnetwork delay and energy consumption rate prediction, the\ndata samples can be easily collected. However, collecting\na large number of data samples in a short time may be\nunpractical for some systems with very high reconfiguration\ncost, such as the reconfiguration of virtualized network func-\ntion resources in software defined WCSs. Therefore, how to\nreduce training data samples is critical in automatic model\nconstruction-based NOPs.\nB. Experience Replay\nModel: For intelligent biological individuals, learning from\ntheir experiences is a common practice to improve the effi-\nciencies of their behaviors. In conventional NOPs, although\nthe system may repeatedly conduct the optimization process,\nthe historical experiences are actually abandoned and can\nnot be fully utilized. By exploiting supervised learning tech-\nniques, one can train a learning model that directly maps\nthe input parameters to the optimization solutions. In this\nway, the repeating optimization process with high complexity\ncan be avoided, the solution can be predicted with very\nlow computation cost. The workflow of experience replay-\nbased optimization is shown in Fig. 4(a), which includes the\nfollowing two phases:\nExperience Accumulation: When the optimization model\nis deployed in the network manager, its historical input data\nand the obtained optimal configurations can be used as the\nexperience (or training data) to train a supervised learning\nmodel. To achieve this goal, firstly we construct the optimiza-\ntion model, then an optimization process is developed to find\nthe optimal solutions. Given an input parameter data, its corre-\nsponding optimal solution that achieves best performance will\nbe regarded as the output. The whole data collection process\ncan be obtained by repeating the sampling or reconfiguration\nprocess, and it is terminated until we have sufficient data\nsamples such that the prediction performance of the model\nis satisfied.\nExperience Learning: A supervised learning-based solu-\ntion prediction model can be properly trained with the obtained\ntraining data. Note that the used training data may need to\nbe normalized before the training process. One can use an\nonline model training process by using the gradient descendent\nprocess, or directly using the whole historical experience\ndataset to train the model offline. The choice of the learning\nmodel plays an important role in determining the model\u2019s\nprediction performance. Note that, although DL may have\nstronger generalization capacity when dealing with big data\ncompared with SSL, it doesn\u2019t mean DL is always a better\nchoice than SSL, because a proper training of DL model is\nmuch more expensive compared with SSL, and SSL always\noutperform DL when the data sample is small.\nApplications: Experience replay can be trained both online\nand offline, and requires much less training data samples\ncompared with reinforcement learning since the training data\nare all optimal results. In this way, many resource management\napplications, such as power allocation for OFDM and massive\nMIMO signals can be speed-up by using experience replay.\nWe test the performance of experience replay for power\nallocation to maximize the throughput of a Massive MIMO\nsystem with 50 antennas, the details of parameter settings\nand the used self-embedding baseline technique can be seen\nin [9]. In this test, the CSI data is used as input data, and\nthe power allocations of antennas are output data. Subfigure\n4(b) shows the probability density distribution of the absolute\nerrors between the predicted results and the real solution, and\nsubfigure 4(c) depicts an example of one channel realization.\nTable I shows the average performance comparison results. In\nthis test, the kernel extreme learning machine (KELM) is used\nas the learning model for its excellent performances on high\nregression precision and low computation efficiency [10].\nWe generate 10000 allocation experience instances by us-\ning the self-embedding technique, in which 9000 instances\nare randomly selected for training, and the remaining 1000\ninstances are used for testing. All data instances, including\ninput data and output data, are normalized between interval\n[0,1]. We can see that the average absolute error between\npredicted results and real solutions is only 0.018, and results\nin subfigures (b) and (c) also show that prediction errors are\n5Supervised Learning Models\nInput Output\nHidden layers\n......\n...\n...\n...\n...\n...\nNew input \ndata\nPredicted \nsolutions\nOptimization\n(DBMs, heuristic algorithms)\nCollect system and \nenvironment data\nOptimal solutions\nExperience Data\n(Training Dataset)\nAs input As output\nReplay\nExperience Accumulation\nExperience Learning\n(a)\n(b)\n0 10 20 30 40 50\nChannel No.\n0.35\n0.4\n0.45\n0.5\n0.55\n0.6\n0.65\n0.7\nPo\nw\ner\n A\nm\npl\nitu\nde\n (n\norm\nali\nze\nd) Predicted solutionReal solution\n(c)\nFig. 4. Illustration of experience replay-based fast optimization, in which (a) shows the workfow, (b) and (c) provide an example of an power allocation in\na massive MIMO system with 50 antennas.\nTABLE I\nPERFORMANCE COMPARISON OF SELF-DUAL EMBEDDING AND EXPERIENCE REPLAY\nTraining time (s) Deployment time (s) Average absolute error\nSelf-dual embedding \u2013 1.21 0\nExperience replay 1.2\u00d7 104 2.38\u00d7 10\u22124 0.018\nvery small. Most importantly, the deployment time of one\noptimization using self-embedding technique is 1.21s, but\nexperience replay only needs 2.38 \u00d7 10\u22124s to predict the\nresults, which is much more fast. Since we need to collect\nsufficient training data instances, the total time cost of training\nprocess is about 1.2\u00d7 104s. However, the training process is\nconducted before the algorithm is embedded in the system,\nthus it has no influences on practical implementation. These\nresults prove that experience replay can significantly improve\nthe efficiency of computation intensive network optimization\noperations, at the same time guarantee high-quality prediction\nperformances.\nChallenges: The successful implementation of experience\nreplay relies on the high-quality experience data and the\ngeneralization capacity of the adopted learning algorithm. For\nNOPs without high-quality solutions, the obtained prediction\nmodel maybe biased due the imperfection of the training data.\nMoreover, when the dimension of the solution is very large,\nthe model may be unable to be properly trained even when\nthe adopted learning model has a strong regression ability. As\na result, the predicted results may suffer from a performance\nloss compared with the results of conventional optimization\nresults.\n6IV. REINFORCEMENT LEARNING: EFFICIENT\nTRIAL-AND-ERROR AND RL-DRIVEN GAMING\nReinforcement learning (RL) can be used to learn the\ndecision policies to automatically take actions to maximize\nthe reward of the agent in a certain environment [6]. It is\nknown that RL can be used to solve optimization problems\nwithout requiring objective functions and environment condi-\ntions [11]. On the other hand, Bayesian optimization method\nis an effective statistical inference learning-based optimization\nmethod for problems without explicit objective functions,\nand it have been proved valuable in providing efficient and\neffective frameworks to train ML models [12].\nA. Efficient Trial-and-Error\nModel: In RL-based decision making, the agent collects\nthe system state and reward from the environment, and trains\na Markov decision process to take actions according to the\ncurrent environment state and reward. The policy map and\nenvironment transition probabilities are updated by using\ndynamical interactions with the environment. The most com-\nmonly used RL model is the Q-learning model, in which the\nmanager intends to maximize the Q-value of the by using an\niterative learning process, as given by\nQ\u2217(s, a)\u2190 Q(s, a)+\u03b1[R(s, a)+\u03b3max\na\u2208A\nQ(s\u2217, a\u2217)\u2212Q(s, a)],\n(1)\nwhere s and a denote the state and the action of the system,\nrespectively, R(s, a) denotes the corresponding reward, A\nis the set contains all possible actions. Parameter \u03b1 is the\nlearning rate adjusting the convergence speed of the learning\nprocess, and parameter \u03b3 controls the decaying speed of\nthe impact of historical experience on the Q-value. In each\niteration, the \u01eb-greedy selection strategy is usually used to\ndecide whether accepting a better result, and \u01eb denotes the\nacceptance probability.\nWhen dealing with decision making problems in wireless\nnetworking, an alternative is training a neural network-based\nRL model to automatically to make decisions without any\nmodel of the target system, and usually this RL-model can\nbe trained by using a policy gradient descent (PGD) method.\nHowever, the training process requires a large number of\nreconfiguration trials, which limits its application in wireless\nnetworking. By integrating Bayesian learning in RL, the\nPGD process can be replaced by an efficient trial-and-error\noptimization process to obtain the parameters of the RL model.\nIn this way, the convergence process RL learning process can\nbe more fast, and the number of reconfiguration trails will be\ngreatly reduced.\nApplications: Mobile edge computing (MEC) and fog com-\nputing provides low-latency computation and caching services\nfor mobile user terminals [13]. In MEC, some NOPs like\ncontent caching, task offloading scheduling, task assignment in\nthe Cloudlet server can be achieved by using the efficient trial-\nand-error RL model. In addition, Bayesian optimization itself\ncan be used to derive optimal system provision parameters in\nWCSs.\nB. RL-driven Gaming\nModel: Game theory has been a powerful tool in guiding\nthe behaviors in interacting with other entities of the wireless\nnetwork. In conventional game theoretical models, all users\nadopts a knowledge-based mathematical model to learn the\noptimal strategies to maximize their own benefits (or utilities)\n[3]. In general, when the users are rational, and know how\nto maximize their own rewards, a Nash equilibrium can be\nachieved by repeating the gaming process with proper strategy\nupdate processes. In a similar way, the game model can be\nsolved by using a multi-task learning (MTL) framework with\nreinforcement learning techniques.\nThe implementation of RL-based MTL is quite similar to\nthe strategy updating process in conventional game theoretical\nmodels. In each repetition, all the agents, or users, select their\nown actions and execute the selected action, then observe the\nnew state of the system and reward obtained. Subsequently,\nthe strategies are updated by using equation (1). By repeating\nthe above process, the Nash equilibrium can be achieved in\nthe whole system. In addition, the above RL-based gaming\napproach can be improved by using a cooperative gaming\nprocess, in which the users is able to know the rewards of\nother users, but not just their own rewards. In this way, the\nrepetition numbers can be reduced.\nApplications: RL-driven gaming can be used in device-to-\ndevice (D2D) networks and cognitive radio (CR) networks. In\nD2D networks, the devices directly communicate with each\nother without the relay of base stations. RL-driven gaming can\nbe used to design the communication choices of the devices to\nmaximize their own performances. In CR, the secondary users\nwant to maximize their own communication capacity, but can\nnot interfere the communications of the primary users. RL-\ndriven gaming can be used to design the spectrum occupying\nbehaviors of both primary users and secondary users.\nChallenges: The convergence of RL-driven gaming may\nrequire a large number reconfiguration trials, which is not effi-\ncient compared with conventional model based game models,\nthus using the efficient trial-and-error is also meaningful in this\nscenario. Reducing the sampling number as many as possible\nis still an open problem needs to be further studied.\nV. UNSUPERVISED LEARNING: COMPLEXITY REDUCTION\nAND SOLUTION RECOMMENDATION\nClustering algorithm is one typical unsupervised learning\nmethod that aims at partitioning the data into several clusters\nwith similar regional distribution properties. The k-means\nalgorithm is an efficient and effective clustering algorithm, and\nit can be used to solve most clustering problems [14]. Also, the\nsimilarity learning process used in k-nearest neighbor (k-NN)\nsearch can be used in finding recommended solutions.\nA. Complexity Reduction\nModel: It is recognized that the increasing of variable di-\nmensions will greatly increase the complexity of optimization\nprocess. We therefore discuss the potentials of using clustering\nalgorithms to reduce the complexity of NOPs with high-\ndimensional variables. As shown in Fig. 5, we can modify the\n7Clusters\nOptimization\n... ... ...\nSolutions Solutions\nOptimization\n... ... ...\nSolutions\nFig. 5. Hierarchical optimization for complexity reduction.\noriginal NOP into a hierarchical NOP problem to reduce the\ncomplexity by dividing the target high-dimensional variables\ninto several clusters. Firstly, cluster-level optimization process\nis conducted, then variable-level optimization is executed\nwithin each clusters. In this way, since the cluster number\nand variable dimension of each cluster is much more smaller\nthan original variable vector, the complexity of optimization\nprocess can be greatly reduced.\nApplications: In applications like resource management\nwith large number of variables, the optimization process can\nbe an expensive task with high dimensional target variables.\nIn this situation, the model complexity can be relaxed by\nusing a clustering process. The variable vector can be divided\ninto several sub-vectors according to factors like throughput\ndemand, channel states, computation demands, and data trans-\nmission amount, etc. Some other factors, such as user priority,\ngeographical position, and residual energy, also can be used\nas the features for clustering. By this way, optimization can\nbe conducted in cluster level and task level separately, and the\ncomplexity can be significantly reduced.\nChallenges: The drawback of clustering-based hierarchical\noptimization is that, the obtained results may suffer from a\nperformance loss since the hierarchical optimization process\nis not the same to the original one, and cluster-optimal results\nare not equivalent to variable-optimal results. Therefore, How\nto reduce the performance loss in hierarchical optimization is\nthe challenge of future\u2019s work.\nB. Solution Recommendation\nModel: One can use a similarity measurement to find\nsimilar historical tasks, then directly combine the solution\nof these similar task as the solution of the new task. To\nrealize similarity-based solution recommendation (SSR) in\nALF, firstly we define the feature vector that is able to\ndistinguish the differences of the tasks, and subsequently a\nk-NN searching process can be used to find the tasks with\nsimilar features. The k-NN algorithm is a well-known lazy\nlearning method that searches the nearest instances according\nto similarity measurements, and it can be efficiently realized\nby using a kd-tree algorithm. We assume that the environment\nkeeps stable in a period of time. Given a new task, when\nthe historical tasks with similar features are known, we can\ncombine the solutions of these similar tasks, and directly use\nthe average result as the solution.\nApplications: Large scale power allocation is usually a\ncomputation intensive task due to the high dimension of the\nsolution. If we have sufficient historical feature data, the SSR\ncan be used to solve the real-time optimization problem.\nThe feature data can be defined as a vector contains user\ngeographic location and user terminal type. When the locations\nare close with each other, the corresponding CSI will be\nsimilar. In addition, when the user terminal type is the same,\ntheir antenna capacities will also be the same. In this way, the\npower assignments will also be similar.\nChallenges: First, collecting user feature data may impose\nprivacy concerns since the manager may want to collect sensi-\ntive information, such as geographic locations, user behaviors,\nand user preferences. Second, since SSR assumes that the\nenvironment keeps static in a period time, it is not able to deal\nwith problems with dynamic, or stochastic conditions. Third,\nthe recommended solution is just an approximated version of\nthe real one, and the corresponding performance will also\nbe not optimal. Forth, the distribution of the collected data\nmay not be evenly distributed. For some new tasks without\nsufficient close neighbor, SSR will be failed to find the reliable\nresults.\nVI. CONCLUSIONS\nThis article recalled the models of network optimization in\nWCSs and proposed an ALF that employs the advantages of\npowerful ML techniques to deal with the human intervention,\nmodel invalid, and high complexity problems in conventional\noptimization models. We reviewed the basic concepts of\nsupervised learning, reinforcement learning, and unsupervised\nlearning, and then proposed their several potential models\nto deal with NOPs, including automatic model construction,\nexperience replay, efficient trial-and-error, RL-driven gaming,\ncomplexity reduction, and solution recommendation. We en-\ncourage the readers to test and modify these proposals, and\nfurther design more new ML-based methods for dealing with\nNOPs in WCSs.\nREFERENCES\n[1] David Tse and Pramod Viswanath. Fundamentals of wireless communi-\ncation. Cambridge University Press, 2005.\n[2] Edwin K. P. Chong and Stanislaw H. Zak. An Introduction to Optimiza-\ntion, Third Edition. 2011.\n[3] Walid Saad, Zhu Han, Merouane Debbah, Are Hjorungnes, and Tamer\nBasar. Coalitional game theory for communication networks: A tutorial.\nIEEE Signal Processing Magazine, 26(5):77\u201397, 2009.\n[4] Mowei Wang, Yong Cui, Xin Wang, Shihan Xiao, and Junchen Jiang.\nMachine learning for networking: Workflow, advances and opportunities.\nIEEE Network, 32(2):1\u20138, 2017.\n[5] Min Chen, Yiming Miao, Xin Jian, Xiaofei Wang, and Iztok Humar.\nCognitive-lpwan: Towards intelligent wireless services in hybrid low\npower wide area networks. IEEE Transactions on Green Communica-\ntions and Networking, 2018.\n[6] Chen Min and Leung Victor. From cloud-based communications to\ncognition-based communications: A computing perspective. Computer\nCommunications, 18:74\u201379, 2018.\n[7] Min Chen, Yixue Hao, Kai Lin, Zhiyong Yuan, and Long Hu. Label-\nless learning for traffic control in an edge network. IEEE Network,\n32(6):8\u201314, 2018.\n[8] Norman M Abramson, David J Braverman, and George S Sebestyen.\nPattern recognition and machine learning. Springer, 2006.\n8[9] E Bjornson, M Kountouris, and M Debbah. Massive mimo and small\ncells: Improving energy efficiency by optimal soft-cell coordination. In\nInternational Conference on Telecommunications, pages 1\u20135, 2013.\n[10] Guang Bin Huang. Extreme learning machines: a survey. International\nJournal of Machine Learning & Cybernetics, 2(2):107\u2013122, 2011.\n[11] Ying He, Zheng Zhang, F. Richard Yu, Nan Zhao, Hongxi Yin, Victor\nC. M. Leung, and Yanhua Zhang. Deep reinforcement learning-\nbased optimization for cache-enabled opportunistic interference align-\nment wireless networks. IEEE Transactions on Vehicular Technology,\n66(11):10433\u201310445, 2018.\n[12] Jasper Snoek, Hugo Larochelle, and Ryan P. Adams. Practical bayesian\noptimization of machine learning algorithms. In International Con-\nference on Neural Information Processing Systems, pages 2951\u20132959,\n2012.\n[13] Wenyu Zhang, Zhenjiang Zhang, and Han Chieh Chao. Cooperative fog\ncomputing for dealing with big data in the internet of vehicles: Archi-\ntecture and hierarchical resource management. IEEE Communications\nMagazine, 55(12):60\u201367, 2017.\n[14] Witten, I. H. Frank, Eibe, and Hall. Data mining. China Machine Press,\n2012.\n",
        "id": 54183086,
        "identifiers": [
          {
            "identifier": "186305968",
            "type": "CORE_ID"
          },
          {
            "identifier": "1812.08198",
            "type": "ARXIV_ID"
          },
          {
            "identifier": "oai:arxiv.org:1812.08198",
            "type": "OAI_ID"
          }
        ],
        "title": "Toward Intelligent Network Optimization in Wireless Networking: An\n  Auto-learning Framework",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:arxiv.org:1812.08198"
        ],
        "publishedDate": "2018-12-19T00:00:00",
        "publisher": "",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://arxiv.org/abs/1812.08198"
        ],
        "updatedDate": "2020-12-24T14:44:07",
        "yearPublished": 2018,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "http://arxiv.org/abs/1812.08198"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/54183086"
          }
        ]
      },
      "relevance_score": 0.0295,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.295,
          "dimension_weight": 0.1,
          "weighted_score": 0.0295,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2018 (Norm. Score: 0.4)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_primary_3",
      "dynamic_step": 0,
      "core_id": 54183086,
      "doi": null
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": null,
        "authors": [
          {
            "name": "Stein, Amy L."
          }
        ],
        "citationCount": 0,
        "contributors": [],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/344966554"
        ],
        "createdDate": "2020-11-24T08:44:31",
        "dataProviders": [
          {
            "id": 2396,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/2396",
            "logo": "https://api.core.ac.uk/data-providers/2396/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "As artificial intelligence (AI) continues to embed itself in our daily lives, many focus on the threats it poses to privacy, security, due process, and democracy itself. But beyond these legitimate concerns, AI promises to optimize activities, increase efficiency, and enhance the accuracy and efficacy of the many aspects of society relying on predictions and likelihoods. In short, its most promising applications may come, not from uses affecting civil liberties and the social fabric of our society, but from those particularly complex technical problems lying beyond our ready human capacity. Climate change is one such complex problem, requiring fundamental changes to our transportation, agricultural, building, and energy sectors. This Article argues for the enhanced use of AI to address climate change, using the energy sector to exemplify its potential promise and pitfalls. The Article then analyzes critical policy tradeoffs that may be associated with an increased use of AI and argues for its disciplined use in a way that minimizes its limitations while harnessing its benefits to reduce greenhouse-gas emissions",
        "doi": null,
        "downloadUrl": "https://core.ac.uk/download/344966554.pdf",
        "fieldOfStudy": null,
        "fullText": "09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020 10:02 AM \n890 \nArtificial Intelligence and Climate Change \nAmy L. Stein\u2020 \nAs artificial intelligence (AI) continues to embed itself in our daily lives, \nmany focus on the threats it poses to privacy, security, due process, and \ndemocracy itself. But beyond these legitimate concerns, AI promises to optimize \nactivities, increase efficiency, and enhance the accuracy and efficacy of the \nmany aspects of society relying on predictions and likelihoods. In short, its \nmost promising applications may come, not from uses affecting civil liberties \nand the social fabric of our society, but from those particularly complex \ntechnical problems lying beyond our ready human capacity. Climate change is \none such complex problem, requiring fundamental changes to our \ntransportation, agricultural, building, and energy sectors. This Article argues \nfor the enhanced use of AI to address climate change, using the energy sector \nto exemplify its potential promise and pitfalls. The Article then analyzes critical \npolicy tradeoffs that may be associated with an increased use of AI and argues \nfor its disciplined use in a way that minimizes its limitations while harnessing \nits benefits to reduce greenhouse-gas emissions. \nIntroduction ..................................................................................................... 891 \nI.  Climate Change and Artificial Intelligence ................................................ 894 \nA. Climate Change .............................................................................. 894 \nB. Artificial Intelligence and Climate .................................................. 895 \n1. Artificial Intelligence ............................................................... 895 \n2. Artificial Intelligence and Climate ........................................... 898 \nII.  Climate Artificial Intelligence and the Electric-Power Sector .................. 900 \nA. Artificial Intelligence for Optimizing Grid Assets ......................... 901 \nB. Artificial Intelligence for Increasing Electric-Grid Efficiency ....... 906 \nC. Artificial Intelligence for Electric-Grid Reliability and\nResiliency ....................................................................................... 909 \nIII.  Key Tradeoffs for Artificial Intelligence and Climate ............................. 916 \nA. Environmental Impacts ................................................................... 917 \nB. Data Privacy .................................................................................... 923 \nC. Investment and Procurement........................................................... 928 \n1. Utility Investing in Artificial Intelligence ................................ 928 \n2. Nonutility Private Investment in Artificial Intelligence ........... 934 \n\u2020 Professor of Law and University Term Professor, University of Florida Levin \nCollege of Law. I am grateful to Dr. Sean Meyn, Dr. David Rolnick, Dr. Prabir Barooah, Priya Donti, \nDanny Sokol, and Ryan Calo for their valuable feedback, and to my tireless research assistants, Shannon \nBoylan, Courtney Meyer, and Tatiana Raevsky for their outstanding assistance. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n891 \n3. Public Investment in Artificial Intelligence ............................. 935 \nD. Accountability, Safety, and Certification ....................................... 936 \nConclusion ...................................................................................................... 938 \n \nIntroduction \nHeadlines claim that robots will take our jobs1 and that drones may use \nmachine learning to teach themselves to launch an independent attack.2 \nScholars have documented more immediate concerns about the bias \nsurrounding the use of algorithms for criminal sentencing3 and facial \nrecognition programs.4 Together, each of these scenarios implicates various \nforms of artificial intelligence (AI). An amorphous term that has moved from \nobscurity to commonplace as of late, AI here refers to \u201ca set of techniques \naimed at approximating some aspect of human or animal cognition using \nmachines.\u201d5 There are many different forms of AI. The most popular form is \nmachine learning, a technology used to make predictions that functions best \nwhen using massive amounts of data and computing capacity.6 AI\u2019s tentacles \nhave pervaded many aspects of society, from more mundane uses in Google \n \n1. Blake Morgan, Robots Will Take Our Jobs and We Need a Plan: 4 Scenarios for the \nFuture, FORBES (Sept. 5, 2018), https://www.forbes.com/sites/blakemorgan/2018/09/05/robots-will-\ntake-our-jobs-and-we-need-a-plan-4-scenarios-for-the-future/#40f0d0206db4 [https://perma.cc/F74F-\nLJLU]; Dan Shewan, Robots Will Destroy Our Jobs \u2013 and We\u2019re Not Ready for It, GUARDIAN (Jan. 11, \n2017), https://www.theguardian.com/technology/2017/jan/11/robots-jobs-employees-artificial-\nintelligence [https://perma.cc/PG9M-U9BG]; Alex Williams, Will Robots Take Our Children\u2019s Jobs?, \nN.Y. TIMES (Dec. 11, 2017), https://www.nytimes.com/2017/12/11/style/robots-jobs-children.html \n[https://perma.cc/HR89-N748]. \n2. David Nield,  This Horrifying \u2018Slaughterbot\u2019 Video Is the Best Warning Against \nAutonomous Weapons, SCI. ALERT (Nov. 22, 2017), https://www.sciencealert.com/chilling-drone-video-\nshows-a-disturbing-vision-of-an-ai-controlled-future [https://perma.cc/HU79-6PHV]; Jacob Ware, \nTerrorist Groups, Artificial Intelligence, and Killer Drones, WAR ON ROCKS (Sept. 24, 2019), \nhttps://warontherocks.com/2019/09/terrorist-groups-artificial-intelligence-and-killer-drones \n[https://perma.cc/6UMC-DAPP]. \n3. Jeff Larson et al., How We Analyzed the COMPAS Recidivism Algorithm, \nPROPUBLICA (May 23, 2016), https://www.propublica.org/article/how-we-analyzed-the-compas-\nrecidivism-algorithm [https://perma.cc/F44D-Z4GD]; see also Anastasia Siapka, The Ethical and Legal \nChallenges of Artificial Intelligence: The EU Response to Biased and Discriminatory AI 6 (Dec. 11, \n2018) (unpublished manuscript), https://ssrn.com/abstract=3408773 [https://perma.cc/FT4J-UDY9] \n(\u201cThe pervasiveness of AI in decision procedures, even in crucial sectors such as policing, employment, \nand border control, means that harms caused to humans by biased data processing necessitate immediate \naction.\u201d).  \n4. Kashmir Hill, The Secretive Company That Might End Privacy as We Know It, N.Y. \nTIMES (Jan. 18, 2020), https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-\nrecognition.html [https://perma.cc/8KW6-A24S]. \n5. Ryan Calo, Artificial Intelligence Policy: A Primer and Roadmap, 51 U.C. DAVIS \nL. REV. 399, 404 (2017). \n6. \u201c[Machine learning] is not needed to predict the sun will rise tomorrow, but if a \ndecision about something very data-rich that occurs repeatedly could lead to appreciably better \nperformance, it is worthy of using AI and [machine learning] to build a predictive model.\u201d Herman K. \nTrabish, How Does AI Improve Grid Performance That No One Fully Understands and That\u2019s Limiting \nIts Use, UTIL. DIVE (Nov. 14, 2019), https://www.utilitydive.com/news/how-does-ai-improve-grid-\nperformance-no-one-fully-understands-and-thats-l/566997 [https://perma.cc/85CY-URUY]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n892 \nsearches to more sophisticated uses in criminal-bail sentencing,7 autonomous \nvehicles,8 e-commerce, digital advertising, and medicine.9 Like most \ntechnological innovations, these techniques have the capacity for both \nbeneficial and detrimental outcomes.10 \nThis Article, prepared in connection with the Yale Journal on \nRegulation\u2019s symposium on Regulating the Technological Frontier, attempts to \nstrike a more optimistic tone for AI. It strives to remind its readers that some of \nthe problems plaguing society today are in need of technological assistance, \nthat there are some applications that are less controversial (predicting weather \npatterns) than others (predicting recidivism), and that AI can be valuable \ndespite its imperfections. \nSpecifically, it explores climate change, a massive problem in and of \nitself, and one area ripe for the use of more AI.11 As one federal circuit court \nhas found, \u201c[a]bsent some action, the destabilizing climate will bury cities, \nspawn life-threatening natural disasters, and jeopardize critical food and water \nsupplies.\u201d12 Despite overwhelming and repeated scientific evidence of the need \nto reduce our global carbon emissions, as a result of higher global energy \nconsumption, carbon emissions \u201crose 1.7% last year [in 2018] and hit a new \nrecord.\u201d13 Only during a global pandemic and economy shutdown did the \nUnited States achieve temporary global carbon reductions on par with the 8% \nexperts predict is needed annually to achieve climate-change targets.14 This \n \n7. Noel L. Hillman, The Use of Artificial Intelligence in Gauging the Risk of \nRecidivism, A.B.A. (Jan. 1, 2019), https://www.americanbar.org/groups/judicial/publications/judges_\njournal/2019/winter/the-use-artificial-intelligence-gauging-risk-recidivism [https://perma.cc/7JWA-\nGAET]. \n8. Monika Hengstler et al., Applied Artificial Intelligence and Trust\u2014The Case of \nAutonomous Vehicles and Medical Assistance Devices, 105 TECHNOLOGICAL FORECASTING & SOC. \nCHANGE 105 (2016). \n9. Denise Grady, A.I. Comes to the Operating Room, N.Y. TIMES (Jan. 6, 2020), \nhttps://www.nytimes.com/2020/01/06/health/artificial-intelligence-brain-cancer.html \n[https://perma.cc/9HS7-DZSP]; \n10. See AJAY AGRAWAL, JOSHUA GANS & AVI GOLDFARB, PREDICTION MACHINES: \nTHE SIMPLE ECONOMICS OF ARTIFICIAL INTELLIGENCE 3-4 (2018); Marco Iansiti & Karim Lakhani, \nCompeting in the Age of AI, HARV. BUS. REV., Jan./Feb. 2020; David Lehr & Paul Ohm, Playing with \nthe Data: What Legal Scholars Should Learn About Machine Learning, 51 U.C. DAVIS L. REV. 653, \n669-702 (2017); Harry Surden, Artificial Intelligence and Law: An Overview, 35 GA. ST. U. L. REV. \n1305, 1321-26 (2019) (discussing the benefits and limitations of AI and machine learning). \n11. For a thorough analysis of AI\u2019s potential application for various climate-change \nissues by experts in machine learning, see David Rolnick et al., Tackling Climate Change with Machine \nLearning (June 10, 2019), https://arxiv.org/pdf/1906.05433.pdf [https://perma.cc/ADQ2-6DR7]. \n12. Juliana v. United States, 947 F.3d 1159, 1166 (9th Cir. 2020). \n13. See INT\u2019L ENERGY AGENCY, GLOBAL ENERGY & CO2 STATUS REPORT: THE \nLATEST TRENDS IN ENERGY AND EMISSIONS IN 2018 (Mar. 26, 2019), \nhttps://www.iea.org/reports/global-energy-and-co2-status-report-2019 [https://perma.cc/S46H-P4MN] \n(noting that global energy-related CO2 emissions rose 1.7% in 2018 to a historic high of 33.1 Gt CO2, \nprimarily driven by increased energy demand); Electricity Explained: Electricity and the Environment, \nU.S. ENERGY INFO. ADMIN., https://www.eia.gov/energyexplained/electricity/electricity-and-the-\nenvironment [https://perma.cc/7L93-4ZHZ]. \n14. See Global Energy Review 2020: Global Energy and CO2 Emissions in 2020, \nINT\u2019L ENERGY AGENCY (Apr. 2020), https://www.iea.org/reports/global-energy-review-2020/global-\nenergy-and-co2-emissions-in-2020#abstracthttps://www.iea.org/reports/global-energy-review-2020 \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n893 \nArticle does not suggest that AI can solve climate change, but it does advocate \nfor its use to whittle away at some of the low-hanging fruit contributing to the \nproblem of pervasive greenhouse-gas (GHG) emissions. \nMost experts agree that focusing on just four areas can have substantial \nimpacts on decarbonizing society: electricity,15 transportation,16 agriculture,17 \nand buildings.18 This Article tackles only one: electricity. It is not intended to \nbe an exhaustive evaluation of AI\u2019s applications in the electric industry. But \nthis Article highlights a few examples of AI\u2019s possible use to reduce carbon \nemissions in the electric-power sector and presents a number of policy \nconsiderations as more AI and climate-related proposals come to light. Part I \nprovides a brief primer on AI and climate, and Part II explores some of the \nways that AI can be used to reduce GHG emissions in the electric power sector. \nPart III then analyzes some of the policy tradeoffs associated with expanded \nuse of AI in the electricity sector, highlighting ways to temper AI\u2019s limitations \n \n[https://perma.cc/A8CB-U4RU]; see also Corinee Le Quere, Temporary Reduction in Emissions During \nConfinement, NATURE (May 2020), https://www.nature.com/articles/s41558-020-0797-x \n[https://perma.cc/CX2U-9XXW] (predicting the reduction in carbon-dioxide emissions due to COVID-\n19 shutdowns). \n15. See Global Greenhouse Gas Emissions Data, U.S. ENVTL. PROTECTION AGENCY, \nhttps://www.epa.gov/ghgemissions/global-greenhouse-gas-emissions-data [https://perma.cc/4CHD-\n2KNF] (stating that AI can assist in decarbonizing the electricity sector as described infra in Part II). \n16. Globally, transportation accounts for roughly fourteen percent of GHG emissions. \nSee id. AI can assist in decarbonizing transportation through improved vehicle engineering, enabling \nintelligent infrastructure, optimizing how freight is routed, and lowering barriers to electric-vehicle \nadoption. Rolnick et al., supra note 11, at 13-15; see also Amy L. Stein & Joshua Fersh\u00e9e, Chapter 14: \nLight-Duty Vehicles, in LEGAL PATHWAYS TO DEEP DECARBONIZATION IN THE UNITED STATES 353, \n375-76 (Michael B. Gerrard & John C. Dernbach eds., 2019) (highlighting the importance of the \ntransportation sector for decarbonization efforts and providing legal recommendations for the light-duty \ntransportation sector to decrease carbon emissions), https://www.eli.org/eli-press-books/legal-pathways-\ndeep-decarbonization-united-states [https://perma.cc/V9VZ-KY2T]. The Chinese Hanghzhou \u201cCity \nBrain\u201d project focused on reducing traffic emissions by optimizing real-time traffic flows. Simon \nGreenman, How Can AI Help Tackle Climate Change, MEDIUM: TOWARDS DATA SCI. (Dec. 6, 2019), \nhttps://towardsdatascience.com/how-can-technology-and-artificial-intelligence-help-tackle-climate-\nchange-b97db0ff4c95 [https://perma.cc/N4X4-27UG]. \n17. Globally, agriculture accounts for approximately twenty-four percent of GHG \nemissions, with methane emissions playing a significant role. See Global Greenhouse Gas Emissions \nData, supra note 15. AI could improve agricultural efficiency by enabling \u201cprecision agriculture\u201d at \nscale, helping farmers predict when and what to plant, allowing for soil regeneration and reducing the \nneed for fertilizers. See WORLD ECON. FORUM, HARNESSING ARTIFICIAL INTELLIGENCE FOR THE EARTH \n13 (Jan. 2018) [hereinafter HARNESSING AI], \nhttp://www3.weforum.org/docs/Harnessing_Artificial_Intelligence_for_the_Earth_report_2018.pdf \n[https://perma.cc/2VM8-HNYJ]. To mitigate increased heat\u2019s impacts on agriculture, AI can improve \ncrop productions by using data from sensors monitoring crop moisture, soil composition and \ntemperature to let farmers know when crops need watering. See Renee Cho, Artificial Intelligence\u2014A \nGame Changer for Climate Change and the Environment, STATE OF THE PLANET, COLUMBIA UNIV.: \nEARTH INST. (June 5, 2018), https://blogs.ei.columbia.edu/2018/06/05/artificial-intelligence-climate-\nenvironment [https://perma.cc/3C4U-XFM3]; see also Sjaak Wolfert et al., Big Data in Smart Farming\u2013\nA Review, 153 AGRIC. SYS. 69, 70 (2017) (discussing how smart devices \u201cextend conventional tools [in \nfarming] (e.g. rain gauge, tractor, notebook) by adding autonomous context-awareness by all kind of \nsensors, built-in intelligence, capable to execute autonomous actions or doing this remotely\u201d). \n18. Globally, buildings account for approximately six percent of GHG emissions, but \ndepending on how the sectors are parsed, they can also encompass part of industry\u2019s global emissions \n(twenty-one percent). See Global Greenhouse Gas Emissions Data, supra note 15. AI can improve \nenergy efficiency and reduce consumption for buildings. HARNESSING AI, supra note 17, at 14. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n894 \nwhile still successfully using AI to help put a \u201ccheck\u201d on the impending havoc \ncaused by climate change. \nI.  Climate Change and Artificial Intelligence \nClimate change is one of the more daunting problems facing society. But \nbecause the worst of its impacts are likely to take place in the future, more \nimmediate and manageable problems that fit within an election cycle often \ndominate the political stage.19 Behavioral experts even remind us that people \nare more inclined to discount the greatest dangers in society as a defense \nmechanism.20 Denial can do wonders for one\u2019s psyche but little for one\u2019s \ngrandchildren. This Part provides a brief primer on climate change. It focuses \non its technical and data challenges and provides examples of AI\u2019s generic \nclimate applications for reducing GHGs. \nA. Climate Change \nClimate change is a global problem, and addressing it involves both \nmitigation of carbon emissions and adaptation to its effects. Researchers from \naround the world have come together to study the basis and impacts of a \nwarming world,21 concluding that human-induced increases of GHG emissions \nsince the industrial revolution have been the \u201cdominant cause\u201d of \nunprecedented increases in global temperature.22 A 2018 Special Report by the \nUnited Nations Intergovernmental Panel on Climate Change (IPCC) found that \nlimiting global warming to 1.5\u00b0C is necessary to reduce challenging impacts on \necosystems and human health and wellbeing.23 \nTo avoid the extreme consequences accompanying a global temperature \nincrease of 2\u00b0C,24 the IPCC declared that greenhouse-gas pollution would have \n \n19.  See Lauren Reiff, Political Myopia & Short-Term Bias in Government, MEDIUM \n(Feb. 22, 2019), https://medium.com/@laurennreiff/political-myopia-short-term-bias-in-government-\nfaed60e68114 [https://perma.cc/3PD7-2554]. \n20.  See Am. Psychological Ass\u2019n\u2019s Task Force on the Interface Between Psychology \n& Global Climate Change, Psychology and Global Climate Change: Addressing a Multi-faceted \nPhenomenon and Set of Challenges, AM. PSYCHOLOGICAL ASS\u2019N 85 (2011), \nhttps://www.apa.org/science/about/publications/climate-change [https://perma.cc/2W5S-3JTV] \n(theorizing that the public\u2019s apparent apathy regarding climate change is actually paralysis at the size of \nthe problem). \n21.  For example, over 800 experts from 80 countries authored the IPCC\u2019s Fifth \nAssessment Report (2014). IPCC, Selection of Authors for IPCC Sixth Assessment Report (Apr. 6, \n2020), https://www.ipcc.ch/2018/04/06/ar6-author-selection [https://perma.cc/YJ33-4WJV]. \n22.  According to the 2018 IPCC report \u201chuman influence has become a principal \nagent of change on the planet\u201d and \u201c[h]uman influence on climate has been the dominant cause of \nobserved warming since the mid-20th century . . . .\u201d INTERGOV\u2019TAL PANEL ON CLIMATE CHANGE \n(IPCC), SPECIAL REPORT: GLOBAL WARMING OF 1.5 \u00baC, at 1, 51 (2018), https://www.ipcc.ch/sr15 \n[https://perma.cc/3T7Z-EVJ5].  \n23.   Id.   \n24.  According to the report, a 2\u00b0C temperature increase would greatly exacerbate \nextreme weather, rising sea levels and diminishing Arctic sea ice, coral bleaching, and loss of \necosystems, among other impacts. Id. at 53, 69-70.  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n895 \nto decrease 45% by 2030, and 100% by 2050.25 To accomplish these lofty \ngoals, the report recognizes that these deep emissions cuts will need to be rapid \nand far-reaching and will require \u201cunprecedented changes in all aspects of \nsociety.\u201d26 Such unprecedented societal changes will need to occur across \nmany dimensions of society, as the largest carbon emissions in the United \nStates come from transportation (29%), followed closely by electricity (28%), \nindustry (22%), commercial and residential buildings (12%), and agriculture \n(9%).27 Researchers, scientists, and policymakers have developed both \nmitigation and adaptation strategies, with varying degrees of political \nacceptance.28 But much more needs to be done. As the Ninth Circuit found, \n\u201c[c]opious expert evidence establishes that this unprecedented rise stems from \nfossil fuel combustion and will wreak havoc on the Earth\u2019s climate if \nunchecked.\u201d29 \nB. Artificial Intelligence and Climate \nAI appears naturally poised to address these transformational challenges \npresented by climate change. This Section provides a brief explanation of AI \nand some examples of its use to mitigate irreversible environmental damage. \n1. Artificial Intelligence \nArtificial intelligence has become ubiquitous in today\u2019s society. What \nbegan in the 1950s with data scientists30 has morphed into a commonplace \nterm.31 But most articles on AI still begin by acknowledging that this term is \n \n25. Id. at 116. \n26. Id. at 77.  \n27. Total U.S. Greenhouse Gas Emissions by Economic Sector in 2017, U.S. ENVTL. \nPROTECTION AGENCY (2017), https://www.epa.gov/ghgemissions/sources-greenhouse-gas-emissions; \nsee also Global Greenhouse Gas Emissions Data, supra note 15 (indicating global emissions for these \nsectors). \n28. Morocco is one of only two countries (the other being The Gambia) that is on \ntrack to reduce its carbon-dioxide emissions to limit warming to 1.5\u00b0C, partly due to its investment in the \nlargest concentrated solar farm in the world. Kieran Mulvaney, Climate Change Report Card: These \nCountries Are Reaching Targets, NAT\u2019L GEOGRAPHIC (Sept. 19, 2019), \nhttps://www.nationalgeographic.com/environment/2019/09/climate-change-report-card-co2-emissions \n[]. As a comparison, the United States has been rated \u201ccritically insufficient\u201d by the Climate Action \nTracker (CAT), the worst rating possible for measuring emission-reduction efforts. Id. CAT even \nestimates that if the Trump administration\u2019s environmental agenda is fully implemented, the United \nStates\u2019 annual GHG emissions by 2030 could increase by an amount equivalent to the California\u2019s total \nannual emissions. Id.  \n29. Juliana v. United States, 947 F.3d 1159, 1166 (9th Cir. 2020). \n30. See John Markoff, John McCarthy, 84, Dies; Computer Design Pioneer, N.Y. \nTIMES (Oct. 25, 2011), https://www.nytimes.com/2011/10/26/science/26mccarthy.html \n[https://perma.cc/B3D6-NZPV] (\u201cWhile teaching mathematics at Dartmouth in 1956, Dr. McCarthy was \nthe principal organizer of the first Dartmouth Conference on Artificial Intelligence. The idea of \nsimulating human intelligence had been discussed for decades, but the term \u2018artificial intelligence\u2019\u2014\noriginally used to help raise funds to support the conference\u2014stuck.\u201d). \n31. See Chris Meserole, What Is Machine Learning?, BROOKINGS INST. (Oct. 4, \n2018), https://www.brookings.edu/research/what-is-machine-learning (\u201cWhen Facebook recognizes \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n896 \namorphous, capable of many and varied definitions.32 As noted earlier, one can \nbegin thinking about AI as \u201ca set of techniques aimed at approximating some \naspect of human or animal cognition using machines.\u201d33 Perhaps part of the \nproblem in grasping this slippery concept is that we humans do not fully \nunderstand how our own cognition works.34 Accepting the limitations of our \nown knowledge may make it easier to accept AI\u2019s gray areas. Our limited \nunderstanding may also explain why AI is often defined using examples that \nillustrate various types of cognitive tasks that computers can accomplish\u2014for \nexample, speech or facial recognition, problem solving, natural language \nprocessing\u2014which are narrow and discrete, especially compared to the vast \ncapacities of the human brain.35 \nAt the outset, therefore, it is critically important to at least establish clear \nconceptual divides, if not clear definitions between three key concepts: data \n \nyour face in a photo, or Amazon Echo understands your question, they\u2019re relying on an insight that is \nover sixty years old.\u201d). \n32. Ben Dickson, What Is Artificial Intelligence (AI)?, PCMAG (May 3, 2019), \nhttps://www.pcmag.com/news/what-is-artificial-intelligence-ai [https://perma.cc/HUJ8-WYGM] (\u201cA \ngreat challenge with artificial intelligence is that it\u2019s a broad term, and there\u2019s no clear agreement on its \ndefinition.\u201d); Nick Heath, What Is AI? Everything You Need to Know About Artificial Intelligence, \nZDNET (Feb. 12, 2018), https://www.zdnet.com/article/what-is-ai-everything-you-need-to-know-about-\nartificial-intelligence [https://perma.cc/HUJ8-WYGM] (\u201cWhat is artificial intelligence (AI)? It depends \nwho you ask.\u201d); Bernard Marr, What is AI?, BERNARD MARR & CO., \nhttps://www.bernardmarr.com/default.asp?contentID=963 [https://perma.cc/KCD5-MCYK] (\u201cThe \nconcept of what defines AI has changed over time . . . .\u201d); Darrell West, What Is Artificial Intelligence?, \nBROOKINGS INST. (Oct. 4, 2018), https://www.brookings.edu/research/what-is-artificial-intelligence \n[https://perma.cc/5ABY-YAT4] (\u201cPart of the problem [of understanding AI] is the lack of a uniformly \nagreed upon definition.\u201d); What Is Artificial Intelligence?, BUILT IN, https://builtin.com/artificial-\nintelligence [https://perma.cc/T5PS-9AYL] (discussing different potential definitions and the difficulties \nof using any single definition.). \n33. Calo, supra note 5, at 405. \n34. A commonly accepted definition of cognition is \u201cthe ability to process information \nthrough perception (stimuli that we receive through our different senses), knowledge acquired through \nexperience, and our personal characteristics that allow us to integrate all of this information to evaluate \nand interpret our world[,] . . . in other words, [] the ability that we have to assimilate and process the \ninformation that we receive from different sources (perception, experience, beliefs, etc.) and convert \nthem into knowledge.\u201d Cognition and Cognitive Science, COGNIFIT, https://www.cognifit.com/cognition \n[https://perma.cc/YW6U-6BNH]. \u201cCognition encompasses the mental functions by which knowledge is \nacquired, retained, and used: perception, learning, memory, and thinking. While some cognitive \nprocesses are carried out consciously and deliberately, others are carried out unconsciously and \nautomatically.\u201d John F. Kihlstrom, Unconscious Cognition, in ENCYCLOPEDIA OF CONSCIOUSNESS 411 \n(2009); see also Understanding Cognition, HUMAN BRAIN PROJECT, \nhttps://www.humanbrainproject.eu/en/understanding-cognition [https://perma.cc/TMY7-3YAC] \n(describing a project that is using models to \u201cuncover the neural mechanisms underlying cognitive \nprocesses\u201d).  \n35. This is often referred to as the divide between narrow (weak) AI and general \n(strong) AI. As just one example, the human brain automatically filters out tons of data as irrelevant. See \nJohn Seabrook, Dressing for the Surveillance Age, NEW YORKER (Mar. 16, 2020), \nhttps://www.newyorker.com/magazine/2020/03/16/dressing-for-the-surveillance-age \n[https://perma.cc/589U-XK2Y]; see also Massive Computing, HUM. BRAIN PROJECT, \nhttps://www.humanbrainproject.eu/en/massive-computing [https://perma.cc/589U-XK2Y] (\u201cThe human \nbrain is so complex that a normal computer is not enough to simulate even a fraction of the human brain. \nOne of the supercomputers is as powerful as about 350,000 standard computers.\u201d). \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n897 \nanalytics, AI, and machine learning.36 While all three require big data to be \neffective, these can be treated as nested, but distinct, concepts.37 Data analytics \nof old involved humans gathering vast quantities of data with the goal of \naggregating and analyzing its \u201ccommonalities\u201d to try to find relationships \nbetween variables.38 Assumptions are made by humans and the data is \u201cqueried \nto test\u201d those relationships.39 In the electricity sector, data analytics assists in \nforecasting, operating, and settling payments.40 Some suggest that data \nanalytics can do \u201cmost of what utilities need without the cost and complexities \nof AI and [machine learning].\u201d41 \nBut the additional cost and complexity of AI and machine learning are \nsometimes justified. Today\u2019s data analytics often involves machine learning, \nallowing the process to go beyond just analyzing data by making assumptions, \ntesting, and learning autonomously.42 Machine learning is a collection of \ntechniques that rely upon massive amounts of data to train an algorithm and \nenable its continuous self-improvement.43 Humans provide the data and specify \nsome key parameters. But at each pass, the algorithm first makes an educated \nguess about what type of information to look for and then updates the next \nguess based on how well the previous one worked.44 \nWith that understanding, one can then better understand why machine \nlearning has become the poster child of today\u2019s AI. AI can refer to a wide \nspectrum of technologies, of which machine learning is but one,45 but it is often \n \n36. See Vance Reavie, Do You Know the Difference Between Data Analytics and AI \nMachine Learning, FORBES (Aug. 1, 2018), https://www.forbes.com/sites/forbesagencycouncil/2018/\n08/01/do-you-know-the-difference-between-data-analytics-and-ai-machine-learning/#4145ef295878 \n[https://perma.cc/2SWM-8FJC].  \n37. These nested concepts can continue, as machine learning can use supervised, \nunsupervised, or reinforcement learning. See Ritu Agarwal & Vasant Dhar, Editorial \u2013 Big Data, Data \nScience, and Analytics: The Opportunity and Challenge for IS Research, 25 INFO. SYS. RES. 443 (2014); \nShweta Bhatt, Reinforcement Learning 101, MEDIUM: TOWARDS DATA SCI. (Mar. 19, 2018), \nhttps://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292 [https://perma.cc/3ZKB-\nAFFV]; Trabish, supra note 6. \n38. See Reavie, supra note 36; see also Sunny Srinidhi, Data Science vs. Artificial \nIntelligence vs. Machine Learning vs. Deep Learning, MEDIUM: TOWARDS DATA SCI. (Nov. 19, 2019), \nhttps://towardsdatascience.com/data-science-vs-artificial-intelligence-vs-machine-learning-vs-deep-\nlearning-9fadd8bda583 [https://perma.cc/34LU-7UEY] (discussing  how \u201c[m]achine learning is used in \ndata science to make predictions and also to discover patterns in the data,\u201d whereas AI is \u201ca collection of \nmathematical algorithms that make computers understand relationships between different types and \npieces of data such that this knowledge of connections\u201d is used to make decisions and draw \nconclusions).  \n39. See Reavie, supra note 36.  \n40. See, e.g., Trabish, supra note 6 (discussing how data analytics allowed a Texas \nutility to defer a $3 million transformer replacement with a repair). See generally DNV GL, DATA \nANALYTICS IN THE ELECTRICITY SECTOR (2018), https://www.dnvgl.com/publications/data-analytics-in-\nthe-electricity-sector-131778 [https://perma.cc/U23U-SLVP] (describing data analytics\u2019 use in the \nelectricity sector).  \n41. Trabish, supra note 6. \n42. Reavie, supra note 36. \n43. Meserole, supra note 31.  \n44. Id. \n45. Reavie, supra note 36. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n898 \nused interchangeably with machine learning because learning-based AI \n\u201cdiagnoses problems by interacting with the problem,\u201d46 by making \nassumptions, reassessing models, and re-evaluating the data all without human \nintervention.47 \u201cThe core insight of machine learning is that much of what we \nrecognize as [human] intelligence hinges on probability rather than reason or \nlogic.\u201d48 \nAlthough many are hoping for development of \u201cbroad AI,\u201d reflected by \nmachines with abilities that meet or surpass human-level cognition,49 today\u2019s \n\u201cnarrow AI\u201d is much more like a Roomba50 than the Terminator.51 AI today is \ngood at clearly-defined tasks but still lacks a broad understanding of the world, \ncommon sense, the ability to learn from limited examples, consciousness, or \ntrue out-of-the-box creativity.52 \n2. Artificial Intelligence and Climate \nAI seems particularly fitting for addressing questions surrounding climate \nchange, an area rife with massive data challenges. Monitoring GHGs and their \nsources has been ongoing for decades, but the data has remained difficult to \nparse, analyze, and use productively.53 Meaningful climate science requires \ncollecting huge amounts of data on many different variables such as \ntemperature and humidity,54 but working with such massive data sets is \nchallenging.55 Nevertheless, some suggest that \u201crapid and incessant increases, \n \n46. Nicholas Farmen, How AI Is Helping Solve Climate Change, SMASH MAG. (Sept. \n19, 2019), https://www.smashingmagazine.com/2019/09/ai-climate-change [https://perma.cc/AE4W-\nT5HC]. \n47. Trabish, supra note 6. \n48. Meserole, supra note 31.   \n49. Some think this comes down to three aspects: \u201c(1) the ability to generalize \nknowledge from one domain to another and take knowledge from one area and apply it somewhere else; \n(2) the ability to make plans for the future based on knowledge and experiences; and (3) the ability to \nadapt to the environment as changes occur.\u201d Kathleen Walsh, Rethinking Weak vs. Strong AI, FORBES \n(Oct. 4, 2019), https://www.forbes.com/sites/cognitiveworld/2019/10/04/rethinking-weak-vs-strong-\nai/#7619f2296da3 [https://perma.cc/5MPM-VP3H].  \n50. Raghav Bharadwaj, Artificial Intelligence Home Robots \u2013 Current and Future \nUse-Cases, EMERJ (Nov. 22, 2019), https://emerj.com/ai-sector-overviews/artificial-intelligence-home-\nrobots-current-future-use-cases [https://perma.cc/S5BU-U2AU]. \n51. The Terminator (Hemdale Film Corp. 1984).  \n52. Meserole, supra note 31.  \n53. See Jackie Snow, How Artificial Intelligence Can Tackle Climate Change, NAT\u2019L \nGEOGRAPHIC (July 18, 2019), https://www.nationalgeographic.com/environment/2019/07/artificial-\nintelligence-climate-change [https://perma.cc/4PJ2-HWPR]. \n54. See Willem Sundblad, Data Is the Foundation for Artificial Intelligence and \nMachine Learning, FORBES (Oct. 18, 2018), \nhttps://www.forbes.com/sites/willemsundbladeurope/2018/10/18/data-is-the-foundation-for-artificial-\nintelligence-and-machine-learning/#7409280051b4 [https://perma.cc/5YVU-8MYB]. \n55. See James H. Faghmous & Vipin Kumar, A Big Data Guide to Understanding \nClimate Change: The Case for Theory-Guided Data Science, 2 BIG DATA 155, 155-163 (Sept. 2014) \n(stating that \u201cshowing that solely relying on traditional big data techniques results in dubious findings\u201d \nand instead proposing \u201ca theory-guided data science paradigm that uses scientific theory to constrain \nboth the big data techniques as well as the results-interpretation process\u201d); Maria Korolov, AI\u2019s Biggest \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n899 \nand improvements in the sophistication, affordability, compactness, and use of \ntechnology are enabling the prompt generation and analysis of copious data \nsets.\u201d56 \nInvesting in ways to conquer these challenges can yield great benefits. AI \nis already being used to analyze images of shallow-water reefs to recognize \ncoral by color to track the effects of climate change57 and to collect \ntemperature, humidity, and carbon-dioxide data to track the health of our \nforests.58 With almost a billion people currently without electricity in the \nworld,59 AI can also play a role in democratizing electricity by providing more \naffordable access to it60 and by facilitating off-grid zero-carbon electrification \nthrough microgrid development.61 AI can also help predict where carbon \nemissions come from, which can help influence policy makers and financiers \non how and where to regulate and invest in energy production.62 \nGiven machine learning\u2019s predictive strengths,63 one can imagine its \napplication to solve numerous other facets of climate change. One of the most \nobvious applications of AI to climate change is its potential to improve climate \n \nRisk Factor: Data Gone Wrong, INSIDER (Feb. 13, 2018), \nhttps://www.idginsiderpro.com/article/3254693/ais-biggest-risk-factor-data-gone-wrong.html \n[https://perma.cc/YT2Q-Q5CY] (discussing how mistakes in training sets caused issues like Google \nImages searches for keywords like \u201cgorilla\u201d showing pictures of African-Americans); see also Douglas \nHeaven, Why Deep-Learning AIs Are So Easy to Fool, NATURE (Oct. 9, 2019), \nhttps://www.nature.com/articles/d41586-019-03013-5 [https://perma.cc/QK3V-L2T2] (\u201c[M]aking \nalterations to inputs \u2014 in the form of tiny changes that are typically imperceptible to humans \u2014 can \nflummox the best neural networks around.\u201d). \n56. VUYO MJIMBA & GAMELIHLE SIBANDA, BIOMIMICRY, BIG DATA AND ARTIFICIAL \nINTELLIGENCE FOR A DYNAMIC CLIMATE CHANGE MANAGEMENT POLICY REGIME 2 (2019). \n57. See Jonathan Jeffrey, 8 Companies Using AI to Tackle Climate Change, \nENTREPRENEUR (Sept. 27, 2019), https://www.entrepreneur.com/article/340002 [https://perma.cc/BX44-\n6NNT] (discussing The Ocean Agency\u2019s 50 Reefs initiative). \n58. See Snow, supra note 53 (describing how forests can act as enormous sponges that \nhelp absorb carbon dioxide). \n59. Hannah Ritchie, Number of People in the World Without Electricity Falls Below \nOne Billion, OUR WORLD DATA (Jan. 18, 2019), https://ourworldindata.org/number-of-people-in-the-\nworld-without-electricity-access-falls-below-one-billion [https://perma.cc/GWY7-N4KD]. \n60. See Trabish, supra note 6  (\u201cThe cloud has democratized access to data, and now it \nis the quality of the data and the quality of the question being asked that are most important.\u201d); see also \nYassine Landa, How Artificial Intelligence Will Incredibly Lower Your Energy Bill, MEDIUM (Apr. 29, \n2019), https://medium.com/datadriveninvestor/how-artificial-intelligence-will-incredibly-lower-your-\nenergy-bill-33914791ea1a [https://perma.cc/5PUL-6QKV] (discussing how AI can reduce individual \nenergy bills by catching energy leaks, detecting energy consumption behaviors and use patterns, and \nfinding the best place for solar energy placement).  \n61. Megan Nichols, How Will AI Improve Microgrid Energy Efficiency?, SCHOOLED \nBY SCI. (Apr. 25, 2019), https://schooledbyscience.com/how-will-ai-improve-microgrid-energy-\nefficiency [https://perma.cc/NAE3-59NG]; PingThings, A National Infrastructure for Artificial \nIntelligence on the Grid, ARPA-E, https://arpa-e.energy.gov/?q=slick-sheet-project/national-\ninfrastructure-artificial-intelligence-grid [https://perma.cc/CMY5-X5SZ].  \n62. See Snow, supra note 53.  \n63. There are many, including Google searches and facial-recognition applications, \nmade possible by advances in machine learning of the past few decades, combined with equally \nremarkable acceleration in computer power and resources.  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n900 \nmodeling and predictions.64 Climate (and weather prediction) models are \nphysical models that use the governing laws of physics to arrive at solutions.65 \nMeteorology and climate science have used statistical techniques for decades \nthat are now considered \u201cAI\u201d or \u201cmachine learning.\u201d66 Recent innovations in \nmachine learning for meteorological purposes are showing increasing accuracy \nand improved predictability from AI-constructed models.67 In addition, AI is \nbeing used more frequently to interpret the model results and square them with \nwhat is actually being observed in the atmosphere.68 \nII.  Climate Artificial Intelligence and the Electric-Power Sector \nBeyond AI\u2019s capabilities for climate science, it can also play a vital role in \nefforts to reduce emissions across one of the largest contributors of GHGs: the \nelectric-power sector. Globally, electricity accounts for roughly twenty-five \npercent of GHG emissions.69 In the United States, the electric-power sector is \nthe second-leading GHG emitter, accounting for nearly twenty-eight percent of \nall GHG emissions.70  Furthermore, the demand for electricity is expected to \ngrow as the transportation sector transitions to electric vehicles.71 Such \nincreased electricity use will result in increased GHG emissions unless steps \nare taken to decarbonize the electric grid. \nComprised of generation, transmission, distribution, and consumption of \nelectricity, the electric-power sector has plenty of opportunities for AI, \nincluding accelerating the development of clean-energy technologies, \nimproving electricity-demand forecasts, strengthening system optimization and \nmanagement, and enhancing system monitoring.72 AI may even enable the \ndiscovery of new substances for use in batteries storing energy or materials \n \n64. For a thorough analysis of AI\u2019s potential application for various climate-change \nissues by experts in machine learning, see Rolnick et al., supra note 11. \n65. See, e.g., Numerical Weather Prediction Models, THEWEATHER.COM, \nhttps://www.theweather.com/models [https://perma.cc/5772-26BH]. \n66. See Amy McGovern et al., Using Artificial Intelligence to Improve Real-Time \nDecision-Making for High-Impact Weather, AM. METEOROLOGICAL SOC\u2019Y (Oct. 2017), \nhttps://journals.ametsoc.org/doi/pdf/10.1175/BAMS-D-16-0123.1 [https://perma.cc/5N2M-CHRC].   \n67. See Shreya Agrawal, Machine Learning for Precipitation Nowcasting from Radar \nImages, 33RD CONF. ON NEURAL INFORMATION PROCESSING SYS., https://arxiv.org/pdf/1912.12132.pdf \n[https://perma.cc/9KD2-5AQ3]. \n68. See Allison Lynn, How\u2019s the Weather? Using Artificial Intelligence for Better \nAnswers, MICROSOFT: AI BLOG (Aug. 10, 2015), https://blogs.microsoft.com/ai/hows-the-weather-\nusing-artificial-intelligence-for-better-answers [https://perma.cc/X28D-7DXY]; Kelsey Tsipis, 3Q: \nMachine Learning and Climate Modeling, MIT NEWS (Feb. 13, 2019), http://news.mit.edu/2019/mit-3q-\npaul-o-gorman-machine-learning-for-climate-modeling-0213 [https://perma.cc/ZC4S-W4BM]; Pail \nVoosen, Science Insurgents Plot a Climate Model Driven by Artificial Intelligence, SCIENCE (July 26, \n2018) https://www.sciencemag.org/news/2018/07/science-insurgents-plot-climate-model-driven-\nartificial-intelligence [https://perma.cc/P5SH-4SXD]. \n69. See Global Greenhouse Gas Emissions Data, supra note 15. \n70. See Total U.S. Greenhouse Gas Emissions by Economic Sector in 2017, supra note \n27.  \n71. See infra Section II.A. \n72. Rolnick et al., supra note 11. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n901 \nabsorbing carbon dioxide from the atmosphere.73 Finally, AI can help make the \ngrid safer, more efficient, and more reliable by integrating data from hazards \nsuch as wildfires and extreme storms and adjusting grid operations \naccordingly.74 Although AI has historically been used in legacy fossil-fuel \noperations,75 it is also being used to help develop more sustainable potential \nfuels of the future such as fusion technology.76 \nThis Part describes both the importance of the electricity sector for \nclimate change, as well as three areas where AI can assist in reducing GHGs \nfrom the electricity sector: (1) optimizing grid assets, (2) increasing energy \nefficiency, and (3) enhancing reliability and resiliency. \nA. Artificial Intelligence for Optimizing Grid Assets \nOne of the most obvious AI applications for the electricity sector involves \noptimizing grid assets: improving the way energy is used in the grid, both for \nconservation and efficiency purposes.77 While the U.S. grid has historically \nbeen comprised of thousands of large, centralized generation sources (for \nexample, power plants), the grid has been undergoing a significant \ntransformation. This transformation includes an increase in renewable \ngeneration sources, many of which are taking the form of smaller, distributed \nresources (for example, rooftop solar and energy storage), a smart grid to help \nfacilitate these resources, and a shift toward more electric vehicles. This section \naddresses AI applications in each of these four areas. \nIntermittent Renewables. A first step to reduce GHG emissions from the \nelectricity sector is to shift the country\u2019s reliance from fossil fuels to \nrenewables. In 2019, the United States relied on fossil fuels for approximately \nsixty-three percent of its electricity needs.78 Renewable penetration, however, \nhas been growing steadily and is projected to comprise seventy-six percent of \nnew planned U.S. generating capacity in 2020.79 But much of renewable energy \n \n73. Id. at 8. \n74. See David G. Victor, How Artificial Intelligence Will Affect the Future of Energy \nand Climate, BROOKINGS INST. (Jan. 10, 2019),  https://www.brookings.edu/research/how-artificial-\nintelligence-will-affect-the-future-of-energy-and-climate [https://perma.cc/AM3J-DTN8]. \n75. AI is being used to unlock new hydrocarbon resources, an application particularly \nsuited to machine learning. Id. \n76. Julian Kates-Harbeck et. al,  Predicting Disruptive Instabilities in Controlled \nFusion Plasmas Through Deep Learning, NATURE (Apr. 17, 2019), \nhttps://www.nature.com/articles/s41586-019-1116-4 [https://perma.cc/W64R-4Y4K] (reporting the \nrecent successful use of neural networks to predict disruptions of advanced fusion technology). \n77. Greg Wassel, Grid Optimization: What Does It Mean?, FRANKLIN ENERGY (June \n20, 2018), https://blog.franklinenergy.com/grid-optimization-what-does-it-mean [https://perma.cc/S4Z8-\nEHC4]. \n78. See Energy Sources: Electricity, U.S. ENERGY INFO. ADMIN. fig., \nhttps://www.eia.gov/kids/energy-sources/electricity [https://perma.cc/NL8C-VNAP] (depicting \n\u201c[s]ources of U.S. electricity generation, 2019\u201d). \n79. Suparna Ray, New Electric Generating Capacity in 2020 Will Come Primarily \nfrom Wind and Solar, U.S. ENERGY INFO. ADMIN. (Jan. 14, 2020), \nhttps://www.eia.gov/todayinenergy/detail.php?id=42495 [https://perma.cc/GN9V-XPZJ]. Nevertheless, \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n902 \nis intermittent, only providing electricity when the sun is shining or the wind is \nblowing.80 Compared to baseload sources like nuclear and natural gas, which \ncan provide electricity on a more continual basis, this intermittency creates \nunique reliability challenges.81 \nAI can be used to enhance the predictability of these intermittent \nrenewables, enhancing their value. For instance, Google and DeepMind applied \nmachine learning to wind power capacity in the United States \u201cto better predict \nwind power output thirty-six hours ahead of actual generation,\u201d assisting in \noptimal hourly day-ahead delivery commitments.82 Google claims that the use \nof machine learning boosted the value of its wind energy by approximately \ntwenty percent.83 \n\u201cAI is increasingly being used to manage the intermittency of renewable \nenergy so that more can be incorporated into the grid; it can handle power \nfluctuations and improve energy storage as well.\u201d84 For example, AI can be \nused to adjust wind-farm propellers to keep up with changing wind directions, \ntherefore decreasing the intermittency issue of wind turbines.85 Similarly, AI \ncan help design the layout of renewable energy sources, such as solar power or \nwind-turbine farms.86 Perhaps most impressively, AI can improve the storage \nof renewable energy during intermittent periods of downtime87 by maximizing \nthe efficiency of large energy batteries to prolong their lifespans with fewer \nissues.88 Such efficiency maximization requires large-scale data analysis, \nmaking it ideal for AI involvement.89 \nDistributed Resources. A second and related result of the move toward \nmore renewables is a shift from large, centralized power sources to smaller, \ndecentralized sources located closer to the place of use.90 In the residential \n \nrenewables still comprise only seventeen percent of the total generation in the United States. Energy \nSources: Electricity, supra note 78, at fig. \n80. See Steven Ferrey, Restructuring a Green Grid: Legal Challenges to \nAccommodate New Renewable Energy Infrastructure, 39 ENVTL. L. 977, 993 (2009). \n81. See, e.g., Amy L. Stein, Distributed Reliability, 87 U. COLO. L. REV. 887, 913 \n(2016). \n82. Sims Witherspoon & Will Fadrhonc, Machine Learning Can Boost the Value of \nWind Energy, GOOGLE: AI (Feb. 26, 2019), https://blog.google/technology/ai/machine-learning-can-\nboost-value-wind-energy [https://perma.cc/3UTY-A7S6]. \n83. Id. \n84. Cho, supra note 17. \n85. Id. \n86. See Nanalyze, How Artificial Intelligence Can Improve Renewable Energy, \nNANALYZE.COM (Nov. 12, 2018), https://www.nanalyze.com/2018/11/artificial-intelligence-renewable-\nenergy [https://perma.cc/XGX5-ZWVR]. \n87. Sustainia, AI Improves Efficiency of Renewable Energy Storage, GLOBAL \nOPPORTUNITY EXPLORER (Mar. 5, 2019), https://goexplorer.org/ai-improves-efficiency-of-renewable-\nenergy-storage [https://perma.cc/87U9-JJLC]. \n88. Id. \n89. Id. \n90. See Distributed Generation of Electricity and Its Environmental Impacts, U.S. \nENVTL. PROT. AGENCY, https://www.epa.gov/energy/distributed-generation-electricity-and-its-\nenvironmental-impacts [https://perma.cc/E4U4-YEHE] (stating that the United States has more than 12 \nmillion distributed generation units, which is about one-sixth of the capacity of the nation\u2019s existing \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n903 \nsector, common distributed energy resources (DERs) include rooftop solar and \nwind, combined heat and power (CHP), fossil fuel generators, fuel cells, energy \nstorage, microgrids, and nanogrids.91 Utilities are struggling to manage these \ndistributed resources, many of which are not owned, managed, or even visible \nto the grid managers.92 As others have explained, \u201cone large spinning coal-fired \nplant is not easily replaced with tens of thousands of smaller/residential \ndistributed energy sources.\u201d93 Distributed resources even can include demand \nresponse (efforts to shift demand to better match supply), which results in \npushing use of electricity into off-peak time periods.94 It is predicted that in the \nnext decade there may be more distributed energy resources coming onto the \nelectrical grid than any utility can manage.95 \nAI is poised to assist in these challenges. An autonomous energy grid \ncould optimize this integration process to benefit the power system and DER \nowners.96 \u201cAI can help [utility companies] manage their generation assets more \nefficiently, reliably, and flexibly in response to supply and demand fluctuations \nfrom distributed generation.\u201d97 Similarly, AI can be used to learn the variables \nimpacting effective demand response and to optimize small-scale systems for \nautomated demand response in a decentralized manner. For example, to help \n \ncentralized power plants). Of course, there are several centralized or utility-scale renewable generation \nsources. For instance, 69% of solar generation in 2018 was utility-scale (1 MW or greater). Cara Marcy, \nToday in Energy, U.S. ENERGY INFO. ADMIN. (Mar. 19, 2019), https://www.eia.gov/todayinenergy/\ndetail.php?id=38752 [https://perma.cc/M7FG-PUH3]. \n91. What the Rise of Local Energy Means for Businesses, Institutions and \nCommunities, MICROGRID KNOWLEDGE (Jan. 2, 2019), https://microgridknowledge.com/distributed-\nenergy-microgrids [https://perma.cc/7A9R-WB8V]. \n92. See, e.g., Stein, supra note 81, at 888-95. \n93. Erik Felt, Empowering Data to Efficiently Build the Connected Grid of the Future, \nPOWER MAG. (Oct. 1, 2019), https://www.powermag.com/empowering-data-to-efficiently-build-the-\nconnected-grid-of-the-future [https://perma.cc/3EF6-SBYH]. \n94. Peter Alstone et al., Integrating Demand Response and Distributed Resources in \nPlanning for Large-Scale Renewable Energy Integration, AM. COUNCIL FOR ENERGY-EFFICIENT ECON. \n(2018), https://aceee.org/files/proceedings/2018/#/paper/event-data/p359 [https://perma.cc/C2XL-\nKRU2]. \n95. Id.  \nBetween 2018 and 2022, U.S. distributed solar installations will grow from today\u2019s roughly \n2.0 million to almost 3.8 million, according to GTM Research. Behind-the-meter battery \nstorage is forecast to grow in that period from around 200 MW to nearly 1,400 MW. And EVs \nwill go from today\u2019s 1% of new car sales to over 50% by 2035 . . . . \nHerman K. Trabish, How Leading Utilities Are Planning for Distributed Energy Resources, UTIL. DIVE \n(Feb. 6, 2018), https://www.utilitydive.com/news/how-leading-utilities-are-planning-for-distributed-\nenergy-resources/516260 [https://perma.cc/VE9C-PJQQ] (discussing the need for dynamic approaches \nto ease the integration of renewable DER into the centralized energy market). \n96. See Trabish, supra note 6.  \n97. James McClelland, How Digital Intelligence Can Be a Difference Maker for \nPower Plants, POWER MAG. (Oct. 31, 2018), https://www.powermag.com/how-digital-intelligence-can-\nbe-a-difference-maker-for-power-plants [https://perma.cc/R94T-J4GD]; see also Darrell Proctor, Battery \nEnergy Storage System Uses Artificial Intelligence to Lower Energy Bills and Provide Utility Grid \nServices, POWER MAG. (Dec. 5, 2018), https://www.powermag.com/press-releases/battery-energy-\nstorage-system-uses-artificial-intelligence-to-lower-energy-bills-and-provide-utility-grid-services \n[https://perma.cc/2Y4R-WH6R] (reporting on AI for an energy storage system that forecasts moments \nof peak demand to optimize the storage system). \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n904 \nshift energy use to off-peak times, an AI system would need to learn the \nthermal properties of a home, the local weather conditions, the way these \nconditions impact heat flows of a home, and user preferences, as well as adapt \nenergy consumption against real-time price signals.98 \nSmart-Grid Infrastructure. A third and critical component to facilitating a \ntransformed electric grid is a smarter grid.99 The United States\u2019 electricity \nindustry is expected to spend \u201capproximately $3.5 billion annually [on the \nsmart grid alone] . . . as part of modernization efforts,\u201d reaching $46 billion for \nthe period from 2018 through 2030 (in nominal dollars).100 The Department of \nEnergy (DOE) describes the smart grid as \u201can intelligent electricity grid\u2014one \nthat uses digital communications technology, information systems, and \nautomation to detect and react to local changes in usage, improve system \noperating efficiency, and, in turn, reduce operating costs while maintaining \nhigh system reliability.\u201d101 \nAs just a few examples, winners of the DOE\u2019s 2019 Innovation Challenge \nproposed the following AI advancements: \n(a) Southern California Edison: Proposed virtualizing components of \nelectric grid substations and operating them using a human-machine \ninterface (HMI). \n(b) Siemens Corporation: Proposed developing a green-technologies \ndigital companion that combines semantic technologies, machine learning, \nand augmented reality to give grid operators better visibility into the \ngrid\u2019s status. The companion could enable predictive capabilities using \ndifferent data sets such as weather and charging infrastructure.102 \nMany of these \u201c[i]nvestments in digital communications technology, \ninformation systems, and automation in an effort to accommodate more \ncomplex power flows and to improve overall reliability, efficiency, and safety, \nwhile also meeting future demand from new uses\u201d can be facilitated using \nAI.103  \nElectric Vehicles. One last area of grid asset optimization lending itself to \nAI is the ongoing shift from internal combustion engines toward electric \n \n98. Sarvapali Ramchurn, Putting the \u2018Smarts\u2019 into Smart Grids: A Grand Challenge \nfor Artificial Intelligence, COMM. ACM (Apr. 2012), https://eprints.soton.ac.uk/272606/3/p86-\nramchurn.pdf [https://perma.cc/2R8F-TASE]. \n99. RICHARD J. CAMPBELL, R45156, CONG. RESEARCH SERV., THE SMART GRID: \nSTATUS AND OUTLOOK (2018). Although the term \u201csmart grid\u201d is broadly defined by statute to include \nother areas of the electricity sector discussed here, such as distributed resources and electric vehicles, the \ndigital technologies and controls used to enable the smart grid suggested a separate section was justified. \nSee Energy Independence and Security Act of 2007, 42 U.S.C. \u00a7 17381 (2018).  \n100. CAMPBELL, supra note 99, at 7. \n101. Id. at 1 (citing DEP\u2019T OF ENERGY, QUADRENNIAL ENERGY REVIEW, \nTRANSFORMING THE NATION\u2019S ELECTRICITY SYSTEM: THE SECOND INSTALLMENT OF THE QER, at S-4 \n(Jan. 2017)). \n102. Office of Elec., Electricity Industry Technology and Practices Innovation \nChallenge, DEP\u2019T ENERGY, https://www.energy.gov/oe/activities/eitpic [https://perma.cc/VX3Q-EFDC]. \n103. McClelland, supra note 97. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n905 \nvehicles (EVs). Although the transportation and electricity sectors have been \nhistorically distinct, this transition is blurring the lines between them.104 This is \nbecause the automotive industry will increasingly rely on the electric grid if \nworldwide sales of EVs continue to grow exponentially.105 EVs are fueled by a \nmuch more diverse mix of electricity sources, including some percentage of \nrenewables, that varies depending on the geographic location of the charger.106 \nIn this way, the larger the grid\u2019s reliance on renewables, the larger the GHG \nreductions that occur from this shift to EVs. \nAI can be useful in this transformation by helping to improve EV charge \nscheduling, congestion management, vehicle-to-grid algorithms, and battery-\nenergy management, as well as by assisting in the research and development of \nEV batteries.107 Moreover, modeling consumer use and charging behavior will \nbe essential for grid operators to predict and manage electric load.108 AI can \nhelp coordinate the movement of EVs, optimize their charge cycles, and predict \naggregate user demand.109 \nAI advancements in autonomous vehicles also may play a critical role in \ndecreasing GHG emissions, particularly if they continue to be dominated by \nelectric vehicles.110 A report by the World Economic Forum concluded that AI \nwill be particularly vital to the shift to autonomous connected EVs.111 \nIncorporating machine learning into autonomous EVs will help optimize \ntransport networks as connected vehicles communicate with one another and \n \n104. See The Future of Electricity: New Technologies Transforming the Grid Edge, \nWORLD ECON. F. (Mar. 2017), http://www3.weforum.org/docs/WEF_Future_of_Electricity_2017.pdf \n[https://perma.cc/9GVY-Y6TY]. \n105. See Global EV Outlook 2019, INT\u2019L ENERGY AGENCY (2019),  \nhttps://www.iea.org/reports/global-ev-outlook-2019 [https://perma.cc/SMP5-W4YZ] (predicting EV \nsales to reach 130 million to over 250 million units by 2030). \n106. Richard McMahon, Edison Elec. Inst., Making Sense of U.S. Energy Markets, \nNAT\u2019L CONF. ST. LEGISLATORS 17 (2017) \nhttps://www.ncsl.org/Portals/1/Documents/energy/ESTF_McMahon_R_present_1_2017.pdf \n[https://perma.cc/PPV2-99SP].  \n107. Rolnick et al., supra note 11, at 17; see also Matthew Vollrath, How We Could \nSupercharge Battery Development for Electric Vehicles, STAN. ENGINEERING (Feb. 28, 2020), \nhttps://engineering.stanford.edu/magazine/article/how-we-could-supercharge-battery-development-\nelectric-vehicles [https://perma.cc/L2WP-LAZS] (describing an algorithm to test new batteries that \nimproved testing time by 98% (from 2 years to 16 days)). \n108. Rolnick et al., supra note 11, at 17. \n109. Ramchurn, supra note 98. \n110. Jennie Hatch & John Helveston, Will Autonomous Vehicles Be Electric?, B.U. \nINST. FOR SUSTAINABLE ENERGY (Aug. 27, 2018), https://www.bu.edu/ise/2018/08/27/will-\nautonomous-vehicles-be-electric [https://perma.cc/GU9S-K8PE]; Stein & Fersh\u00e9e, supra note 16 \n(discussing how one  benefit of increased adoption and use of autonomous vehicles is a reduction in \nGHGs because most autonomous and semiautonomous vehicles are also electric). \n111.  HARNESSING AI, supra note 17, at 12; Rilnig Elezaj, How AI Is Paving the Way \nfor Autonomous Cars, MACHINE DESIGN (Oct. 17, 2019), https://www.machinedesign.com/mechanical-\nmotion-systems/article/21838234/how-ai-is-paving-the-way-for-autonomous-cars \n[https://perma.cc/DTZ6-6NFW]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n906 \nwith transport infrastructure to identify hazards and improve navigation.112 \nFurthermore, \u201c[i]t has been estimated that smart automated driving systems \ncould see a 15% reduction in fuel consumption over human operators.\u201d113 \nSuch a shift to electric vehicles also would provide a unique opportunity \nfor utilities. Although global energy demand has increased in recent years,114 \nU.S. electricity-consumption projections are relatively stagnant.115 However, \nsome researchers project electricity demand could increase by as much as \nthirty-eight percent with the increased demand created by a massive new fleet \nof EVs.116 Together, AI can yield significant grid-optimization benefits for the \nincreased intermittent renewables and distributed resources, as well as for \nsmart-grid and EV deployment. \nB. Artificial Intelligence for Increasing Electric-Grid Efficiency \nIn addition to the shift to electricity resources with a smaller carbon \nfootprint, utilities could also be taking a second, and less obvious, step to \nreduce GHGs: using AI to target inefficiencies. A recent report by the \nLawrence Livermore National Laboratory found that around sixty-eight percent \nof energy produced in the United States is \u201crejected.\u201d117 Rejected energy is part \nof the energy of a fuel\u2014such as gas or oil\u2014that could be used for a purposeful \nactivity, like making electricity or transport, but instead is lost to the \nenvironment.118 Rejected energy most often takes the form of waste heat, such \nas the warm exhaust from automobiles and furnaces.119 The substantial growth \nin energy use over the past fifty years for electricity and transportation, sectors \n \n112. See, e.g., HARNESSING AI, supra note 17; Jeffrey, supra note 57 (discussing how \nDHL is optimizing their fleet by predicting demand, risk, supply-side variations and fifty-six other \nvariables). \n113. Greenman, supra note 16. \n114. See INT\u2019L ENERGY AGENCY, supra note 13, at 21-24 (noting that global energy-\nrelated carbon-dioxide emissions rose 1.7% in 2018 to a historic high of 33.1 Gt CO2, primarily driven \nby increased energy demand). \n115. David Roberts, After Rising for 100 Years, Electricity Demand Is Flat. Utilities \nAre Freaking Out, VOX (Feb. 27, 2018),  https://www.vox.com/energy-and-\nenvironment/2018/2/27/17052488/electricity-demand-utilities [https://perma.cc/5EVG-LTNU] (\u201cThanks \nto a combination of greater energy efficiency, outsourcing of heavy industry, and customers generating \ntheir own power on site, demand for utility power has been flat for 10 years, and most forecasts expect it \nto stay that way.\u201d). \n116. Robert Walton, EVs Could Drive 38% Rise in US Electricity Demand, DOE Lab \nFinds, UTIL. DIVE (July 10, 2018), https://www.utilitydive.com/news/evs-could-drive-38-rise-in-us-\nelectricity-demand-doe-lab-finds/527358 [https://perma.cc/6MEH-NPWG]. \n117. Estimated U.S. Energy Consumption in 2018: 101.2 Quads, LAWRENCE \nLIVERMORE NAT\u2019L LABORATORY,  https://flowcharts.llnl.gov/content/assets/images/energy/us/Energy_\nUS_2018.png [].  \n118. Gerry Carrington, Rejected Energy \u2013 Why Is So Much Energy Unloved?, UNIV. \nOTAGO: ENERGY CULTURES (July 7, 2014), https://energycultures.org/2014/07/rejected-energy-much-\nenergy-unloved [https://perma.cc/YS7J-SGN8]. \n119. U.S. Energy Use Rises to Highest Level Ever (Apr. 11, 2019), LAWRENCE \nLIVERMORE NAT\u2019L LABORATORY,  https://www.llnl.gov/news/us-energy-use-rises-highest-level-ever \n[https://perma.cc/H43C-KQJD]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n907 \nthat are historically poor at turning fuel into work, has caused energy waste to \ngradually prevail over energy productivity.120 Inefficiencies exist in all aspects \nof the electric grid, but electricity generation in particular wastes approximately \ntwo-thirds of its primary energy potential.121 While the second law of \nthermodynamics explains why it is impossible for heat engines to achieve \n100% efficiency, there is still plenty of room for improved efficiency in the \nelectricity sector.122 \nAI is primed to reduce these inefficiencies. On the generation side, AI can \nhelp reduce inefficiencies at existing fossil-fuel operations123 and nuclear \nplants,124 as well as enhance the efficiency of the newer renewable grid \nresources. For instance, AI can assist in the design and operation of wind and \nsolar farms to make these utility-scale renewable-energy systems much more \nefficient at generating electricity.125 For wind farms, the turbine heads can be \nactively oriented to capture a greater fraction of the incoming wind.126 For solar \npower, with more intelligent solar forecasting, AI can make it easier and more \nlucrative for solar generators to participate in electricity markets.127 \nAI can also be instrumental in reducing energy losses in electricity \ntransmission and distribution.128 For example, a distribution-system operator \n \n120.  US Wastes 61-86% of Its Energy, CLEAN TECHNICA (Aug. 26, 2013), \nhttps://cleantechnica.com/2013/08/26/us-wastes-61-86-of-its-energy [https://perma.cc/MN76-39LH]. \n121.  U.S. Energy Use Rises to Highest Level Ever, supra note 119. \n122.  David Roberts, American Energy Use, in One Diagram, VOX (May 12, 2018),  \nhttps://www.vox.com/energy-and-environment/2017/4/13/15268604/american-energy-one-diagram \n[https://perma.cc/MY8Q-V2XG]; Jim Lucas, What is the Second Law of Thermodynamics, LIVE SCI. \n(2015),  https://www.livescience.com/50941-second-law-thermodynamics.html \n[https://perma.cc/YW2M-CTNB] (\u201cOne thing the Second Law explains is that it is impossible to convert \nheat energy to mechanical energy with 100 percent efficiency.\u201d). \n123. See Transforming Exploration and Production with AWS Machine Learning, \nAMAZON WEB SERVS., \nhttps://d1.awsstatic.com/Industries/Oil/AWS_Oil_Gas_Solution_Brief_FINAL.pdf \n[https://perma.cc/KJM8-MHU7] (advertising Amazon\u2019s machine learning AWS program to oil and gas \ncompanies to assist in oil drilling).  \n124. See generally Mario Gomez-Fernandez et. al, Status of Research and \nDevelopment of Learning-Based Approaches in Nuclear Science and Engineering: A Review, 359 \nNUCLEAR ENGINEERING & DESIGN 1 (2020) (\u201cThe International Atomic Energy Agency (IAEA) has \nsuggested that it \u2018is necessary to address obsolescence issues, to introduce new beneficial functionality, \nand to improve overall performance of the plant and staff\u2019 and to \u2018enhance and detect subtle variation \nthat could remain unnoticed,\u2019 including the use of artificial intelligence (AI) to support decisions.\u201d \n(internal citations omitted)).  \n125. Victor, supra note 74.  \n126. Id.; see also Solar and Wind Forecasting, NAT\u2019L RENEWABLE ENERGY \nLABORATORY, https://www.nrel.gov/grid/solar-wind-forecasting.html [https://perma.cc/5XMV-JHCF] \n(describing ways that AI can be used for \u201cforecasting\u201d). Digital twin technologies can also be used to \nenhance efficiencies. See McClelland, supra note 97 (\u201cThe digital twin serves as a platform for \nmodeling existing physical systems in the digital realm, so a company can run different scenarios to \ndetermine certain outcomes, then make appropriate changes to the real-life environment or system.\u201d).  \n127. See Solar and Wind Forecasting, supra note 126. \n128. Jacques Bughin et al., Artificial Intelligence: The Next Digital Frontier, \nMCKINSEY GLOBAL INST. 48 (June 2017), \nhttps://www.mckinsey.com/~/media/McKinsey/Industries/Advanced%20Electronics/Our%20Insights/\nHow%20artificial%20intelligence%20can%20deliver%20real%20value%20to%20companies/MGI-\nArtificial-Intelligence-Discussion-paper.ashx [https://perma.cc/S5T5-G4UB]; see also Celso Cavellucci \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n908 \n(DSO) in Europe used AI to analyze voltage, load, and grid topology data to \nhelp \u201coperators assess available capacity on the system and plan for future \nneeds.\u201d129 AI allowed the DSO to use existing and incoming assets from \ndistributed energy resources more efficiently.130 Similarly, a transmission \nsystem operator in Germany used AI to make better projections about grid \nloss.131 In the United States, AI could be used in current and new Advanced \nDistribution Management Systems (ADMS).132 ADMS is \u201cthe software \nplatform that supports the full suite of distribution management and \noptimization\u201d and performs functions such as \u201cfault location, . . . peak demand \nmanagement[,] . . . and support for microgrids and electric vehicles.\u201d133 \nLastly, AI can make great strides in reducing the demand for electricity \nconsumption by optimizing end uses. In 2015, for instance, Google announced \nthat it had reduced its energy use for cooling Google\u2019s data centers by forty \npercent with the aid of DeepMind\u2019s machine learning.134 Future savings seem \nlikely, as the DeepMind project has been commissioned to help reduce waste in \nthe UK\u2019s National Grid.135 More recently, in 2019, the National Renewable \nEnergy Laboratories partnered with Hewlett Packard to evaluate how AI could \nenhance its data center\u2019s efficiency.136 \n \n& Christiano Lyra, Minimization of Energy Losses in Electric Power Distribution Systems by Intelligent \nSearch Strategies, 4 INT\u2019L TRANSACTIONS OPERATIONAL RES. 23, 32 (demonstrating how AI can \nachieve optimality in network flows to minimize energy losses for distribution systems). \n129. Suzanna Sanborn, Andrew Slaughter, & Jian Wei, Digital Innovation Creating \nthe Utility of the Future, DELOITTE (Apr. 9, 2019), \nhttps://www2.deloitte.com/us/en/insights/industry/power-and-utilities/digital-transformation-utility-of-\nthe-future.html#endnote-sup-11 [https://perma.cc/3J4H-9N2T].  \n130. Id. (\u201cThe DSO gained 50 percent efficiency and saved \u20ac9.44 million over 10 \nyears in capital expenditures.\u201d). \n131. Transmission System Operator Uses AI to Reduce Costs, T&D WORLD (Jan. 6, \n2020), https://www.tdworld.com/test-and-measurement/article/21119870/transmission-system-operator-\nuses-artificial-intelligence-to-reduce-costs [https://perma.cc/GHH3-Q93V]. \n132. See generally U.S. DEPT. OF ENERGY, VOICES OF EXPERIENCE: INSIGHTS INTO \nADVANCED DISTRIBUTION MANAGEMENT SYSTEMS (2015), \nhttps://www.energy.gov/sites/prod/files/2015/02/f19/Voices%20of%20Experience%20-\n%20Advanced%20Distribution%20Management%20Systems%20February%202015.pdf \n[https://perma.cc/XTG4-XTXT].  \n133. Id. at 4.  \n134. Richard Evans & Jim Gao, DeepMind AI Reduces Google Data Centre Cooling \nBill by 40%, DEEPMIND (July 20, 2016), https://deepmind.com/blog/article/deepmind-ai-reduces-\ngoogle-data-centre-cooling-bill-40 [https://perma.cc/5F8N-4HE7]; see also About: DeepMind, \nDEEPMIND, https://deepmind.com/about [https://perma.cc/U4X8-S3C4]; Robert Walton, With Artificial \nIntelligence, It\u2019s a Brave New World for Utilities, UTIL. DIVE (Nov. 24, 2017), \nhttps://www.utilitydive.com/news/with-artificial-intelligence-its-a-brave-new-world-for-utilities/511008 \n[https://perma.cc/P2FA-QZBX]. But see James Rawlings, Bringing New Technologies and Approaches \nto the Operation and Control of Chemical Process Systems, AICHE J. (2019), \nhttps://aiche.onlinelibrary.wiley.com/doi/pdf/10.1002/aic.16615 [https://perma.cc/ZZD8-6QB4]. \n135. Cheryl Kaften, DeepMind and National Grid in Talks to Use AI to Predict and \nBalance Britain\u2019s Energy Supply, ENV\u2019T + ENERGY LEADER (Mar. 15, 2017), \nhttps://www.environmentalleader.com/2017/03/deepmind-national-grid-talks-use-ai-predict-balance-\nbritains-energy-supply [https://perma.cc/AKM4-6S2L]. \n136. NREL, NREL and HCP Team up to Apply AI for Efficient Data Operations, \nNAT\u2019L RENEWABLE ENERGY LABORATORY (Nov. 18, 2019), \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n909 \nAddressing these inefficiencies can have enormous impacts on carbon \nemissions. In fact, energy efficiency is often touted as the unsung hero of \ndecarbonization, touching upon many sectors and producing some of the largest \nimpacts for the lowest costs.137 Enhancing efficiency across multiple sectors \ncan also help reduce electricity consumption.138 The International Energy \nAgency has argued that energy efficiency is key to the transformation of energy \nsystems and will play an important role in cutting the growth of world energy \ndemand to one-third of the current rate by 2040.139 Experts also modeled the \ncombined impact of energy-efficiency opportunities across buildings, industry, \ntransportation, and the electric grid, and found that such efforts can cut GHGs \nin half by 2050.140 \nC. Artificial Intelligence for Electric-Grid Reliability and Resiliency \nA third area where AI can assist the electric grid involves reliability and \nresilience. The North American Electric Reliability Corporation (NERC) has \ndistinguished between reliability and resilience for the bulk power system.141 \nReliability is composed of both adequacy and security, focusing on the ability \nof the electric system to meet customer needs, as well as to \u201cwithstand sudden \ndisturbances or unanticipated loss of system components.\u201d142 Resilience, on the \nother hand, refers to \u201c[t]he ability to withstand and reduce the magnitude and/or \nduration of disruptive events, which includes the capability to anticipate, \n \nhttps://www.nrel.gov/news/program/2019/nrel-and-hpe-team-up-to-apply-ai-for-efficient-data-center-\noperations.html [https://perma.cc/N47R-832G]. \n137. Steve Sorrell, Reducing Energy Demand: A Review of Issues, Challenges and \nApproaches, 47 RENEWABLE & SUSTAINABLE ENERGY REVIEWS 74 (2015) (stating that improving \nenergy efficiency, along with reducing energy demand, are widely considered the most promising, \nfastest, cheapest, and safest means to reducing emissions).   \n138. See Herman K. Trabish, As Utilities Scramble to Manage Explosive DER \nGrowth, Is Power Grid Autonomy a Solution?, UTIL. DIVE (Sept. 11, 2019), \nhttps://www.utilitydive.com/news/as-utilities-scramble-to-manage-explosive-der-growth-is-power-grid-\nautonom/562439 [https://perma.cc/9QFJ-PLGK]. \n139. INT\u2019L ENERGY AGENCY, SPECIAL REPORT ON ENERGY AND CLIMATE CHANGE, \nPART OF THE WORLD ENERGY OUTLOOK (2015). \n140. Steven Nadel & Lowell Ungar, Report U1907, Halfway There: Energy Efficiency \nCan Cut Energy Use and Greenhouse Gas Emissions in Half by 2050, AM. COUNCIL FOR ENERGY-\nEFFICIENT ECON., at iv (2019),  \nhttps://aceee.org/sites/default/files/publications/researchreports/u1907.pdf. The authors identified the \nfollowing areas as the among top energy-saving opportunities: fuel economy standards and less driving \nfor vehicles; industrial, residential, and appliance efficiencies; and freight and aviation efficiency. Id. at \n5. \n141. The bulk power system is defined as \u201cfacilities and control systems necessary for \noperating an interconnected electric energy transmission network (or any portion thereof), and electric \nenergy from generation facilities needed to maintain transmission system reliability.\u201d 16 U.S.C. \u00a7 \n824o(a)(1) (2018); Amy L. Stein, Regulating Reliability, 54 HOUS. L. REV. 1191, 1250 (2017). \n142. N. AM. ELEC. RELIABILITY CORP., REPORT ON RESILIENCY, at  iv (2018), \nhttps://www.nerc.com/comm/RISC/Related%20Files%20DL/RISC%20Resilience%20Report_Approved\n_RISC_Committee_November_8_2018_Board_Accepted.pdf [https://perma.cc/G6AJ-9HQ4]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n910 \nabsorb, adapt to, and/or rapidly recover from such an event.\u201d143 AI can assist in \nboth of these goals, reducing emissions by reducing downtime and avoiding \nback-up generation that emits more GHGs. \nBlackouts result in devastating economic impacts144 but can have severe \nenvironmental impacts too. Downtime creates inefficiencies and waste that \ncascade through our interconnected grid.145 Manufacturing plants and other \nbusinesses often sit idle until the power returns, sometimes causing them to \nhave to start a process over if they were interrupted.146 For example, a short \nblackout in New York resulted in over twenty-nine tons of food waste.147 The \nGHG emission-rich process of creating and transporting that food into the city \nwas necessarily repeated because the grid failed for just a few hours.148 In \naddition, the use of generators and being forced to use alternate forms of \ntransport (if public transportation is unable to operate) can all contribute to \nincreased emissions during blackouts.149 Preventing and swiftly curing \nblackouts are key to reducing catastrophic impacts. \nFurthermore, utilities historically have been reactive entities. In many \nparts of the country, the utility is only notified of a power outage by calls from \nangry customers.150 The smart-grid advancements discussed above are part of \n \n143. Candice Castaneda, NERC Legal, Perspective on Resilience, N. AM. ELEC. \nRELIABILITY CORP. (Oct. 31, 2018), https://www.usea.org/sites/default/files/event-\n/NERC%20perspective%20on%20resilience%20-%20USEA%202018.pdf [https://perma.cc/J5NC-\nLQBP].  \n144. In 2012, weather-related outages cost the U.S. economy between $18 billion and \n$33 billion. PRESIDENT\u2019S COUNCIL OF ECON. ADVISERS ET AL., ECONOMIC BENEFITS OF INCREASING \nELECTRIC GRID RESILIENCE TO WEATHER OUTAGES 3 (Aug. 2013), \nhttps://www.energy.gov/sites/prod/files/2013/08/f2/Grid%20Resiliency%20Report_FINAL.pdf \n[https://perma.cc/RDM8-GPVQ].  \n145. See Charisse Jones, The New York City Blackout Was Actually Bad for the \nEnvironment, U.S.A. TODAY (July 16, 2019), \nhttps://www.usatoday.com/story/money/2019/07/16/blackout-how-climate-affected-new-york-power-\noutage/1734529001 [https://perma.cc/GBK8-5GFL]; see also Leticia Miranda, As California Burns, \nGenerator Companies Make a Power Grab, NBC NEWS (Nov. 6, 2019), \nhttps://www.nbcnews.com/business/business-news/california-burns-generator-companies-make-power-\ngrab-n1076611 [https://perma.cc/HGD7-RLR9] (discussing how overgrown trees and outdated grid \ninfrastructure led to wildfires in California and how electric companies are implementing rolling \nblackouts while they update their infrastructure to ensure the wildfires do not happen again).  \n146. Jones, supra note 145. \n147. Id. \n148. Id.  \n149. Id.; R. Subramanian et al., Air Quality in Puerto Rico in the Aftermath of \nHurricane Maria: A Case Study on the Use of Lower Cost Air Quality Monitors, 2 ACS EARTH SPACE \nCHEM. 1179, 1179 (2018)  (\u201cThe widespread reliance on generators for regular electric supply in the \naftermath of Hurricane Maria appears to have increased air pollution in San Juan.\u201d); Rejane Frederick & \nCristina Novoa, Echoes of Katrina: Post-Hurricane Maria Public Health Threats and Trauma, CTR. \nFOR AM. PROGRESS (Mar. 20, 2018), \nhttps://www.americanprogress.org/issues/green/news/2018/03/20/448215/echoes-katrina-post-hurricane-\nmaria-public-health-threats-trauma [https://perma.cc/683W-CPCM]. \n150. See How the Smart Grid Keeps Your Power On, SMARTGRID CONSUMER \nCOLLABORATIVE, https://cemast.illinoisstate.edu/downloads/smart-grid/SGCC-Outage-Restoration-\nFact-Sheet.pdf [https://perma.cc/5VHH-BRX7]; Sandra Ponce de Leon, The Role of Smart Grids and AI \nin the Race to Zero Emissions, FORBES (Mar. 20, 2019), \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n911 \nthe race to modernize these distribution systems.151 The senility of the grid has \ncontributed to an increased incidence of weather-related power outages, and a \nlack of automated sensors constrain the response time of grid operators.152 \nOlder transmission lines dissipate more energy than new ones and grid \ndeterioration increases the system\u2019s vulnerability to severe weather.153 \nAI can help utilities shift from reactive into proactive entities. In 2018, the \nDepartment of Energy announced a $5.8 million funding opportunity for \nresearch and development of \u201cadvanced tools and controls\u201d to improve the \nresilience and reliability of the nation\u2019s power grid.154 This Section discusses \nhow AI can help with troubleshooting, aiding in preventative maintenance to \nminimize the amount of sudden disturbances, and improve repair times to \nenhance resilience. \nTroubleshooting/Preventative Maintenance. Instead of waiting for grid \nassets to break down, AI is being used to predict problems before they occur. \nGiven the interconnected nature of the electric grid, preventing just one \nequipment failure can eliminate the cascading blackouts that have occurred in \nmany of our most notorious power outages in U.S. history.155 \nTo become more proactive, utilities and generators are using algorithms156 \nthat \u201ctake into account industry-wide early failure rates for equipment, creating \na richer understanding of premature failure risks for enhanced asset \nmaintenance, workflow, and portfolio management\u201d to predict the probability \nof failure.157 For example, the New York Power Authority (NYPA) has \n \nhttps://www.forbes.com/sites/cognitiveworld/2019/03/20/the-role-of-smart-grids-and-ai-in-the-race-to-\nzero-emissions/#17091f661c8e [https://perma.cc/AXL8-AMKC]. \n151. Robert Walton, Aging Grids Drive $51B in Annual Utility Distribution Spending, \nUTIL. DIVE (July 25, 2018), https://www.utilitydive.com/news/aging-grids-drive-51b-in-annual-utility-\ndistribution-spending/528531 [https://perma.cc/KCX9-CV79] (\u201cA 2015 report from the U.S. \nDepartment of Energy concluded 70% of power transformers are 25 years of age or older, 60% of circuit \nbreakers are 30 years or older and 70% of transmission lines are 25 years or older.\u201d). \n152. PRESIDENT\u2019S COUNCIL OF ECON. ADVISERS ET AL., supra note 144, at 7. \n153. Id. \n154. Peter Maloney, DOE Offers Funding Tied to Big Data, AI, Machine Learning, \nAM. PUB. POWER ASS\u2019N (Oct. 1, 2018),  https://www.publicpower.org/periodical/article/doe-offers-\nfunding-tied-big-data-ai-machine-learning [https://perma.cc/JD7Y-XGGX]. \n155. The 2003 Northeast Blackout affected over fifty million people from New York \nto Montreal. This Day in History August 14: Blackout Hits Northeast United States, HISTORY, \nhttps://www.history.com/this-day-in-history/blackout-hits-northeast-united-states \n[https://perma.cc/HC4K-7V5P]. Many Americans feared it was caused by terrorism, and the utility \ncompanies pointed fingers at each other. Id. After a comprehensive investigation, it was discovered the \noutage was caused by a few overgrown trees that touched a powerline in Ohio. Id. \n156. See Peter Maloney, SRP Taps AI to Monitor and Improve Its IT Systems, AM. \nPUB. POWER ASS\u2019N (Sept. 23, 2019), https://www.publicpower.org/pealoneyriodical/article/srp-taps-ai-\nmonitor-and-improve-its-it-systems [https://perma.cc/3RGA-SLNG]. SRP is using AI to monitor and \nvisualize the system and build a dynamic IP map in real-time to \u201cavoid outages and provide a better \ncustomer experience.\u201d Id. \n157. McClelland, supra note 97. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n912 \ninvested in sensors to help determine the life expectancy of key equipment and \nhead off problems before they can affect operations at power plants.158 \nPower companies can use sensor monitoring for similar preventative \nmaintenance.159 Utilities are already using devices known as phasor \nmeasurement units (PMUs) to \u201cmeasure the amplitude and phase of electric \ncurrent and voltage at various points on the electric grid using a common time \nsource for synchronization\u201d to provide a real-time snapshot of the grid\u2019s \noperating status.160 In 2018, New York also announced a PMU program, which \n\u201cdeploys sensors to collect voltage and current data at NYPA\u2019s power \ngenerating facilities and switchyards with high-resolution and precise time \nstamping. The collected data can then be pulled together and used for real-time \ngrid management, asset management and potential problem detection.\u201d161 \nAlthough these PMUs are over a hundred times faster than the previous system \nused by the electric industry, \u201cmore advanced tools are needed to analyze the \ndata for actionable information.\u201d162 \nFor example, utilities could shift away from a fixed schedule for asset \nmaintenance and retirement and toward a more optimal schedule based on the \nactual condition of assets.163 By leveraging data from sensors and other \nhardware that tracks assets remotely, machine learning applications could \n\u201cliberate grid operators from decommissioning assets before their useful lives \nhave ended, while enabling them to perform more frequent inspections and \nmaintenance to keep assets working well.\u201d164 As one example, a European \npower distribution company was able to reduce its costs by thirty percent by \nanalyzing dozens of variables to determine the overall health of transformers \nand diagnose individual components.165 \nSimilarly, AI can be used to better anticipate extreme weather and natural \ndisasters that are perilous to electric grids.166 For example, NASA recently used \n \n158. See Maloney, supra note 154. The NYPA said that at its Robert Moses-Niagara \nPower Plant, it was testing an array of sensors that will help determine the life expectancy of key \nequipment and head off problems before they can affect operations. Id.  \n159. McClelland, supra note 97. \n160. Maloney, supra note 154. The American Recovery and Reinvestment Act of \n2009 supported the installation of over 1,000 PMUs across North America. Id. There are now PMUs \ndeployed at over 2,500 locations across the nation\u2019s bulk power system. Id. \n161. Id. For instance, NYPA said that data from about one hundred sensors are \ncurrently being used in a simulation on a turbine-generator unit at the plant. Id. \n162. Id. The so-called PMUs can gather data at a rate a hundred times faster than the \nSupervisory Control and Data Acquisition (SCADA) systems that are widely used in the power industry. \nId. \n163. Bughin et al., supra note 128, at 49. \n164. Id. \n165. Id. \n166. See, e.g., Naveen Joshi, How AI Can and Will Predict Disasters, FORBES (Mar. \n15, 2019), https://www.forbes.com/sites/cognitiveworld/2019/03/15/how-ai-can-and-will-predict-\ndisasters [https://perma.cc/9ELU-45RH] (describing efforts to predict the location and intensity of \nvolcano eruptions); Victoria Woolaston, The Algorithm That Can Predict When a Tsunami Will Strike, \nWIRED (May 25, 2016) https://www.wired.co.uk/article/the-algorithm-that-can-predict-when-a-tsunami-\n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n913 \nAI to track Hurricane Harvey, allowing it to predict the storm\u2019s movement with \nsix times more accuracy.167 IBM also has an AI tool that helps predict power \noutages from severe storms and enables utilities to improve their emergency \nresponse times.168 In Switzerland, a team of scientists was able to use AI to \ncorrectly predict lightning strikes inside an 18-mile radius about 80% of the \ntime.169 AI and bionic eyes are also helping to contain wildfires with the aid of \nIBM\u2019s Watson AI system which visually evaluates camera feeds to spot new \nfires and predict where they will spread.170 \nFacilitate repairs. As discussed above, a key component of resiliency \nfocuses on the ability of a system to come back online. AI can become a critical \ntool in the effort to enhance the grid\u2019s resiliency. \u201cBy relying on data from \nremote sensors, power producers can pinpoint where to send a crew for a \nrepair, and based on an assessment of the damage, ensure the team arrives with \nthe right tools for the job.\u201d171 \nUtilities have been using drones and AI trained on deep-learning \nalgorithms, combined with sensors, to address malfunctions in remote areas.172 \nDrones collect information about many different remote issues, such as \nmalfunctioning equipment, downed trees, or simply vegetation encroachment \non remote assets.173 Combining AI analysis with images taken by drones \ncreates a powerful tool for use by the energy and utility industries.174 Some \n \nwill-strike [https://perma.cc/XE9S-MJL3] (discussing the development of an algorithm to better predict \ntsunami occurrences and potential damage). \n167. Hurricane Harvey, Forecasting Weather with Machine Learning Artificial \nIntelligence, TRADERS COMMUNITY (Aug. 24, 2017), \nhttps://traderscommunity.com/index.php/technology/171-forecasting-weather-with-machine-learning-\nartificial-intelligence [https://perma.cc/V5WF-VWSV]. \n168. Aili McConnon, AI Helps Cities Predict Natural Disasters, WALL ST. J. (June \n26, 2018), https://www.wsj.com/articles/ai-helps-cities-predict-natural-disasters-1530065100 \n[https://perma.cc/4ZWX-88SF]. \n169. Courtney Linder, Artificial Intelligence Can Now Predict When Lightning Will \nStrike, POPULAR MECHANICS (Nov. 17, 2019), \nhttps://www.popularmechanics.com/science/environment/a29703282/artificial-intelligence-lightning \n[https://perma.cc/Z4GL-4SVG].   \n170. CNN Wire, Artificial Intelligence Helps Spot Wildfires Faster, FOX5 SAN DIEGO \n(Dec. 5, 2019), https://fox5sandiego.com/2019/12/05/artificial-intelligence-helps-spot-wildfires-faster \n[https://perma.cc/UM7D-27YT]; Garrett Hering, Calif. Utilities Tap Artificial Intelligence in War \nAgainst Wildfires, S&P GLOBAL (Mar. 22, 2019), \nhttps://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/50714018 \n[https://perma.cc/H7A9-ZD23]; Brian K. Sullivan, AI and Bionic Eyes Are Helping to Contain Raging \nWildfires, BLOOMBERG NEWS (Aug. 4, 2019),  https://www.bloomberg.com/news/articles/2019-08-\n04/bionic-eyes-and-ai-are-helping-keep-raging-wildfires-contained [https://perma.cc/HUL3-6SXE].  \n171. McClelland, supra note 97. \n172. Isaac Bruns, Drones for Power Line Inspections, UTIL. PRODUCTS (Jan. 1, 2019), \nhttps://www.utilityproducts.com/line-construction-maintenance/article/16003823/drones-for-power-line-\ninspections [https://perma.cc/LK36-V2SP]; In Photos: How Drones And Artificial Intelligence Can Help \nSpeed Hurricane Recovery, ONE BRIEF, https://theonebrief.com/in-photos-how-drones-and-artificial-\nintelligence-can-help-speed-hurricane-recovery [https://perma.cc/6XLV-9F3G]; McClelland, supra note \n97. \n173. See sources cited supra note 172. \n174. See Sam Daley, Fighting Fires and Saving Elephants: How 12 Companies Are \nUsing the AI Drone to Solve Big Problems, BUILT IN (Mar. 10, 2019), https://builtin.com/artificial-\n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n914 \nprofessionals even predict that synthesizing drones and AI will help prevent \nutility issues before they even happen, simply by analyzing predictive data.175 \nNERC Security Requirements. Bulk grid users can use AI as a more cost-\neffective way to satisfy the reliability requirements imposed by the nation\u2019s \nreliability monitor, the North American Electric Reliability Corporation \n(NERC). NERC has issued security regulations to address both physical and \ncybersecurity threats. The regulations are designed to push entities to become \nmore proactive by \u201crequir[ing] a minimum level of organizational, operational, \nand procedural controls to mitigate risk.\u201d176 \nThe NERC physical security regulations, known as CIP-014-1,177 \u201cinclude \nsix basic independent verifications of the risk assessment and an evaluation of \nthe potential threats and vulnerabilities of a physical attack on these critical \nstations or substations.\u201d178 Perhaps the most challenging requirement is to \ndevelop and implement a documented physical-security plan, which must \ninclude measures to detect and respond to physical threats.179 Among the more \ninnovative solutions to comply with these physical-security requirements are \ntower-mounted robots powered by AI.180 \nThe NERC cybersecurity regulations are more extensive than the physical \nsecurity regulations, addressing cybersecurity concerns through ten \nregulations181 ranging from personnel training182 to incident reporting.183 This \nmight be due in part to an increasing number of data breaches in the United \n \nintelligence/drones-ai-companies [https://perma.cc/9VDX-JQ75]; Reena Kamra, AI-Powered Drones: A \nTechnological Benison, MEDIUM (June 26, 2019), https://medium.com/datadriveninvestor/ai-powered-\ndrones-a-technological-benison-c734f6135c2c [https://perma.cc/KT7E-RKG7]. \n175. See Ilkka Hiidenheimo, Implementing Drones to Inspect Electric Utility Wires, \nROBOTICS TOMORROW (Dec. 23, 2019), \nhttps://www.roboticstomorrow.com/article/2019/12/implementing-drones-to-inspect-electric-utility-\nwires/14554 [https://perma.cc/AMS9-2G4H].  \n176. NERC, https://www.nerc.com/AboutNERC/Pages/default.aspx; CIP-011-2 \u2013 \nCyber Security \u2014 Information Protection, N. AM. ELECTRIC RELIABILITY CORP., \nhttps://www.nerc.com/pa/Stand/Reliability%20Standards/CIP-011-2.pdf [https://perma.cc/2992-TAVJ].  \n177. CIP-014-1 \u2014 Physical Security,  \nhttps://www.nerc.com/pa/Stand/Reliability%20Standards/CIP-014-1.pdf [https://perma.cc/RC9R-\nKQMT]. \n178.  Steven Bowen, Using Artificial Intelligence to Protect the Power Grid, POWER \nMAG. (Jan. 31, 2018), https://www.powermag.com/using-artificial-intelligence-to-protect-the-u-s-\npower-grid [https://perma.cc/MP9Q-RJYP]. \n179. Id. \n180. See, e.g., id. A network \u201ccould transform a power grid\u2019s passive security system \ninto an active defense-and-denial physical protection system. Using non-lethal actuators, such as \ncameras and sensors, the system detects, delays, and safely thwarts a potential attacker by overwhelming \nthem with directed, high-intensity sound, lights, and strobes.\u201d Id.  \n181. See Reliability Standards, N. AM. ELECTRIC RELIABILITY CORP., \nhttps://www.nerc.com/pa/Stand/Pages/CIPStandards.aspx [https://perma.cc/SM32-A2GN].   \n182. CIP-004-6 \u2014 Cyber Security \u2014 Personnel & Training, N. AM. ELECTRIC \nRELIABILITY CORP., https://www.nerc.com/pa/Stand/Reliability%20Standards/CIP-004-6.pdf \n[https://perma.cc/9JZX-23MB].  \n183. CIP-008-5 \u2014 Cyber Security \u2014 Incident Reporting and Response Planning, N. \nAM. ELECTRIC RELIABILITY CORP., https://www.nerc.com/pa/Stand/Reliability%20Standards/CIP-008-\n5.pdf [https://perma.cc/2YG2-76NG]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n915 \nStates184 or to an overall heightened concern for data protection.185 Similar to \nCIP-014-1, CIP-010-2 requires entities to implement processes to develop \nbaseline configurations of cyber assets, monitor changes in the baselines, and \n\u201c[a]t least once every 15 calendar months, conduct a paper or active \nvulnerability assessment.\u201d186 Other standards extend to both physical-security \nand cybersecurity threats; for example, CIP-006-6 requires entities to limit \naccess to cyber assets to only those authorized in advance.187 AI could be used \nto combat these cybersecurity threats by predicting and responding to data \nbreaches or automating security operations processes by providing a big-data \nsolution to a big-data problem.188 \nCybersecurity threats in the energy sector are an omnipresent concern for \nregulators and utilities. In May of 2020, President Trump declared a national \nemergency in response to the threat of foreign adversaries \u201cexploiting \nvulnerabilities in the United States bulk-power system.\u201d189 To address these \nthreats, President Trump prohibited any \u201cacquisition, importation, transfer, or \ninstallation of any bulk-power system electric equipment\u201d where the \n \n184. See In re Equifax, Inc., Customer Data Sec. Breach Litig., 362 F. Supp. 3d 1295, \n1308 (N.D. Ga. 2019) (\u201c[H]ackers stole the personal and financial information of nearly 150 million \nAmericans. . . . [I]t affected almost half of the entire American population. . . . The hackers stole at least \n146.6 million names, 146.6 million dates of birth, 145.5 million Social Security numbers, 99 million \naddresses, 17.6 million driver\u2019s license numbers, 209,000 credit card numbers, and 97,500 tax \nidentification numbers.\u201d); see also In re SuperValu, Inc., 870 F.3d 763, 766-67 (8th Cir. 2017) \n(discussing a class-action data-breach suit with defendant SuperValu grocery stores where \u201ccyber \ncriminals accessed the computer network that processes payment card transactions for 1,045 of \ndefendants\u2019 stores\u201d); Lewert v. P.F. Chang\u2019s China Bistro, Inc., 819 F.3d 963, 966 (7th Cir. 2016) \n(discussing a class-action data-breach suit with defendant P.F. Chang\u2019s China Bistro after the \n\u201crestaurant\u2019s computer system had been hacked and debit-and credit-card data had been stolen\u201d); \nRemijas v. Neiman Marcus Grp., LLC, 794 F.3d 688, 690 (7th Cir. 2015) (discussing a class action data \nbreach suit with the defendant Neiman Marcus, a luxury department store, where hackers attacked \ndefendant\u2019s system and stole the credit card numbers of its customers); Charlotte A. Tschider, \nRegulating the Internet of Things: Discrimination, Privacy, and Cybersecurity in the Artificial \nIntelligence Age, 96 DENV. L. REV. 87, 140 (2018) (\u201cThe problematic state of cybersecurity has led to \nmore frequent data breaches across industries and products.\u201d).  \n185. \u201cPrevious Pew Research Center studies of the digital privacy environment have \nfound that many Americans fear they have lost control of their personal information and many worry \nwhether government agencies and major corporations can protect the customer data they collect.\u201d Aaron \nSmith, Americans and Cybersecurity, PEW RES. CTR. (Jan. 26, 2017), \nhttps://www.pewresearch.org/internet/2017/01/26/americans-and-cybersecurity \n[https://perma.cc/NAA2-LXN5].  \n186. CIP-010-2 \u2014 Cyber Security \u2014 Configuration Change Management and \nVulnerability Assessments, N. AM. ELECTRIC RELIABILITY CORP., \nhttps://www.nerc.com/pa/Stand/Reliability%20Standards/CIP-010-2.pdf [https://perma.cc/9HML-\n6XG4]. \n187. CIP-006-6 \u2014 Cyber Security \u2014 Physical Security of BES Cyber Systems, N. AM. \nELECTRIC RELIABILITY CORP., https://www.nerc.com/pa/Stand/Reliability%20Standards/CIP-006-6.pdf \n[https://perma.cc/Z8GV-MA9J]. \n188. Louis Columbus, 10 Predictions How AI Will Improve Cybersecurity in 2020, \nFORBES (Nov. 24, 2019), https://www.forbes.com/sites/louiscolumbus/2019/11/24/10-predictions-how-\nai-will-improve-cybersecurity-in-2020/#35c888d06dd7 [https://perma.cc/PBF8-V9QP]. See generally \nCatherine J.K. Sandoval, Cybersecurity Paradigm Shift: The Risks of Net Neutrality Repeal to Energy \nReliability, Public Safety, and Climate Change Solutions, 10 SAN DIEGO J. CLIMATE & ENERGY L. 91, \n123-26, 150-52 (2019). \n189. Exec. Order. No. 13920, 85 Fed. Reg. 26595, 26595 (May 1, 2020).  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n916 \ntransaction \u201cinvolves any property in which any foreign country or a national \nthereof has any interest.\u201d190 Further, in a recent test by a Boston security firm, \nin just three days, hackers were able to completely overwhelm a fake control \nnetwork modeled after control networks found in North American electric \ncompanies.191 The DOE has already taken steps to combat cybersecurity threats \nby funding programs to research and develop \u201ccybersecurity solutions for \nenergy delivery systems . . . to detect, prevent, and mitigate the consequences \nof a cyber-incident . . . .\u201d192 In the energy sector, AI could be used by energy \nsuppliers to \u201cmanage their distribution systems, including diagnosis of faults\u201d \nto prevent future cybersecurity attacks, \u201cand rerouting of power flows, with \nreal-time awareness and control,\u201d that allows for quick responses if a \ncybersecurity attack were to occur.193 Although grid operators have long used \ndata analytics to address many of the issues discussed here, AI has the potential \nto exceed the limitations of human processing with regard to optimizing grid \nassets, increasing efficiency, and enhancing reliability and resiliency.194 \nIII.  Key Tradeoffs for Artificial Intelligence and Climate \nIf we are to embrace artificial intelligence as part of the climate strategy, it \nwill be important to be aware of the tradeoffs associated with these \ntechnological tools. As with all emerging technologies, AI may face suspicion, \nhigh upfront costs, and close scrutiny by regulators.195 Even established players \n \n190. Id.  \n191. Robert Walton, Utility Ransomware Attacks Becoming More Sophisticated, New \n\u2018Honeypot\u2019 Operation Finds, UTIL. DIVE (June 15, 2020), https://www.utilitydive.com/news/utility-\nransomware-attacks-becoming-more-sophisticated-new-honeypot-oper/579780 [https://perma.cc/H55Z-\nLVML]. \n192. Cybersecurity Research, Development, and Demonstration (RD&D) for Energy \nDelivery Systems, U.S. DEP\u2019T ENERGY, https://www.energy.gov/ceser/activities/cybersecurity-critical-\nenergy-infrastructure/cybersecurity-research-development-and [https://perma.cc/R4VP-7AR5].  \n193. N.Y. PUB. SERV. COMM\u2019N, Case 14-M-0101, Proceeding on Motion of the \nComm\u2019n in Regard to Reforming the Energy Vision., No. 14-M-0101, 2014 WL 1713082, at *10 (Apr. \n25, 2014) (discussing opportunities to use technology to combat cyber-attacks); see also GE Global \nResearch, Cyber-Attack Detection and Accommodation for the Energy Delivery System, U.S. DEP\u2019T \nENERGY (Nov. 6-8, 2018), \nhttps://www.energy.gov/sites/prod/files/2018/12/f58/GE%20Global%20Research%20-%20Cyber-\nAttack%20Detection%20and%20Accommodation.pdf [https://perma.cc/R65P-U7MJ] (discussing a \nproposed technology that detects asset abnormal behavior, locates attack focal points (nodes), forecasts \ntrending to abnormal behavior, and neutralizes attacked nodes). For some examples of technology being \ntested to improve the energy sector, see 2018 Cybersecurity for Energy Delivery Systems Peer Review, \nU.S. DEPT. ENERGY, https://www.energy.gov/ceser/articles/2018-cybersecurity-energy-delivery-\nsystems-peer-review [https://perma.cc/YCM8-FFMK]; and Cybersecurity for Energy Delivery Systems \n2018 Peer Review Presentations, U.S. DEP\u2019T ENERGY, https://www.energy.gov/ceser/cybersecurity-\nenergy-delivery-systems-2018-peer-review-presentations [https://perma.cc/RT7M-XV83]. \n194. \u201cDigital solutions can help power producers gain efficiency across multiple \nfacets of their operations, from preventive plant maintenance to fuel use decisions and beyond.\u201d \nMcClelland, supra note 97. \n195. Of course, there may also be other explanations, including a general apathy \ntoward change, skepticism about the cost effectiveness of AI and its tangible benefits. This short Article \nmerely raises a few of many potential obstacles. See generally Gary E. Marchant  & Yvonne A. \nStevens, Resilience: A New Tool in the Risk Governance Toolbox for Emerging Technologies, 51 U.C. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n917 \nin the energy industry may lack a general understanding of its capabilities and \nits limitations, making it difficult for them to have the same comfort level that \nexists when relying on the status quo.196 This Part analyzes just a few of the \nmajor tradeoffs associated with increased use of AI to address electricity-\nrelated climate issues: (1) environmental impacts, (2) data privacy, (3) \ninvestment and procurement, and (4) accountability.197 Within each tradeoff, it \nalso provides normative recommendations for how to best move forward with \nAI in a way that best balances the competing needs of the industry, the \nconsumers, and the public interest. \nA. Environmental Impacts \nFor all its potential to reduce electricity usage and optimize efficiencies \nassociated with the electric grid, AI can also be a large consumer of electricity. \nData centers consume more than 2% of the world\u2019s electricity,198 and \nresearchers have predicted that by 2025, that number could rise to somewhere \nbetween 8% (best case) and 21% (expected).199 These numbers might grow \n \nDAVIS L. REV. 233 (2017) (discussing the challenges of governing emerging technologies, including \n\u201chighly uncertain benefits, risks, and trajectories associated with the technology, an extremely rapid \npace of development and change, and a broad range of applications that implicate many different \nindustries, regulatory agencies, and stakeholders\u201d); Grant Wilson, Minimizing Global Catastrophic and \nExistential Risks from Emerging Technologies Through International Law, 31 VA. ENVTL. L.J. 307, 309 \n(2013) (noting that while many scientists point to developments in nanotechnology, bioengineering, and \nartificial intelligence as a panacea for disease, pollution, and even mortality, these emerging \ntechnologies also risk massive human death and environmental harm). \n196. In the Cascade Mountains in Washington, Bitcoin miners are flocking to the area \nto take advantage of cheap electricity. Udi Merhav, Are Utilities Ready to Do What It Takes to Survive, \nSMART ENERGY INT\u2019L (Jan. 29, 2019), https://www.smart-energy.com/industry-sectors/smart-grid/are-\nutilities-ready-survive-udi-merhiv-energy-orbit [https://perma.cc/Y6P8-MFRS]. Cryptocurrency mining \nconsumes inordinate amounts of energy, stressing the local grid and utility companies. Id. Instead of \ntaking advantage of the increased demand, the local utility companies treated the miners like a problem \nto be stopped. Id.  Even utilities that have adopted technologies such as smart meters are failing to use \nthe meters to their full potential. See Jeff. St. John, Why Most US Utilities Are Failing to Make the Most \nof Their Smart Meters, GREENTECH MEDIA (Jan. 10, 2020), \nhttps://www.greentechmedia.com/articles/read/why-most-u-s-utilities-arent-making-the-most-of-their-\nsmart-meters [https://perma.cc/WP2K-6H22]. See Table 1 in the Article for a good representation of \nvarious utilities\u2019 adoption of smart meter technologies. Id. tbl.1. \n197. To be sure, there are many more that could be discussed, including whether the \n\u201csocial problems with the culture of \u2018free online\u2019\u201d and the current model of extracting value from a vast \nnumber of people without paying them is a threat not just to a stable economic but also to democracy. \nImanol Arrieta Ibarra et al., Should We Treat Data as Labor? Moving Beyond \u201cFree,\u201d 108 AEA PAPERS \nAND PROCEEDINGS 38, 38 (2018); see also JARON LANIER, WHO OWNS THE FUTURE?, at xxv (2014) \n(arguing that the idea of free information is a fallacy because whomever possesses the best computer \nwill always gain \u201cinformation superiority\u201d and \u201climitless wealth and influence\u201d). \n198. Fred Pierce, Energy Hogs: Can World\u2019s Huge Data Centers Be Made More \nEfficient?, YALEENVIRONMENT360 (Apr. 3, 2018), https://e360.yale.edu/features/energy-hogs-can-\nhuge-data-centers-be-made-more-efficient [https://perma.cc/J2H3-EL75].  \n199. Anders S. G. Andrae & Tomas Edler, On Global Electricity Usage of \nCommunication Technology: Trends to 2030, 6 CHALLENGES 117, 138 (2015); see also Martin Giles, Is \nAI the Next Big Climate-Change Threat? We Haven\u2019t a Clue, MIT TECH. REV. (July 29, 2019), \nhttps://www.technologyreview.com/2019/07/29/663/ai-computing-cloud-computing-microchips \n[https://perma.cc/5GMR-TQ6R] (\u201c[I]n the absence of significant innovation in materials, chip \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n918 \neven bigger, as one study suggested when it found that computational resources \nused by AI are increasing at an alarming rate.200 One study from the University \nof Massachusetts found that training a large AI model to handle human \nlanguage can lead to emissions about five times the lifetime emissions of the \naverage car in the United States.201 \nThis concern may be tempered by the wide variety of processing demands \nacross the many different types of AI.202 As discussed earlier, AI refers to a \nbroad set of techniques, including machine learning. Each of these techniques \nhas vastly different computing needs, depending on the complexity of the task \nand the efficiency of the algorithm deployed. For example, the processing of \nhuman language, the AI technique evaluated in the Massachusetts study,203 is \none of the most energy-intensive uses of AI.204 Fortunately, that technique is \nnot as prevalent in the algorithms used to reduce the carbon intensity of the \nelectric industry.205 By being conscious of the varying energy demands, the \n \nmanufacturing and design, data centers\u2019 AI workloads could account for a tenth of the world\u2019s electricity \nusage by 2025.\u201d). \n200. Dario Amodei & Danny Hernandez, AI and Compute, OPENAI (May 16, 2018), \nhttps://openai.com/blog/ai-and-compute [https://perma.cc/2WMC-CBNT]. In 2018, the power consumed \nby the entire Bitcoin network was estimated to be higher than that of the Republic of Ireland. Alexa \nHern, Bitcoin\u2019s Energy Usage Is Huge \u2013 We Can\u2019t Afford to Ignore It, GUARDIAN (Jan. 17, 2018), \nhttps://www.theguardian.com/technology/2018/jan/17/bitcoin-electricity-usage-huge-climate-\ncryptocurrency [https://perma.cc/2X2H-CF9V]. Some studies give us hope, showing that leaps in \nefficiency might soon outpace the growth of energy consumption. See Data Centres and Data \nTransmission Networks, INT\u2019L ENERGY AGENCY (May 2019), https://www.iea.org/reports/tracking-\nbuildings/data-centres-and-data-transmission-networks [https://perma.cc/5QJA-AB3K] (\u201cBased on \ncurrent trends in the efficiency of hardware and data centre infrastructure, global data centre energy \ndemand is projected to decrease slightly.\u201d). Data centers are not the only part of AI that can have a \nsignificant environmental impact. As AI develops, sensors are going to become increasingly important, \nas most of this data is collected through a series of physical sensors before it is stored in a data center. \nVivienne Sze et al., Hardware for Machine Learning: Challenges and Opportunities, MIT (Oct. 17, \n2017), https://arxiv.org/pdf/1612.07625.pdf [https://perma.cc/Z67Y-Y9XR] (discussing how there were \nan estimated 10 billion sensors in use in 2013 and that number is expected to rise to 1 trillion by 2020).  \n201. See Emma Strubel et al., Energy and Policy Considerations for Deep Learning in \nNLP, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS 1 tbl.1, 4  tbl.4 \n(June 5, 2019), https://arxiv.org/abs/1906.02243 [https://perma.cc/W9UB-LHAP] (discussing that the \naverage lifetime emissions of a car are 126,000 pounds of carbon dioxide and training the NAS \nalgorithm resulted in almost 626,155 pounds of carbon-dioxide emissions). \n202. Dario Amodei & Danny Hernandez, AI and Compute, OPENAI (May 16, 2018), \nhttps://openai.com/blog/ai-and-compute/#fn2 [https://perma.cc/SV99-EYGP]; Chethan Kumar, Artificial \nIntelligence: Definition, Types, Examples, Technologies, MEDIUM (Aug. 31, 2018), \nhttps://medium.com/@chethankumargn/artificial-intelligence-definition-types-examples-technologies-\n962ea75c7b9b [https://perma.cc/4TXQ-DVS8]. \n203. Strubel et al, supra note 201, at 3.  \n204. For a basic overview of how natural-language processing is conducted and the \ndifficulties of natural-language processing, see Dr. Michael K. Garbade, A Simple Introduction to \nNatural Language Processing, MEDIUM: BECOMING HUMAN (Oct. 15, 2018), \nhttps://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32 \n[https://perma.cc/9QCS-J8R9]; see also Melanie Ehrenkranz, How to Train Artificial Intelligence That \nWon\u2019t Destroy the Environment, OUTLINE (Nov. 4, 2019), https://theoutline.com/post/8186/artificial-\nintelligence-destroy-environment [https://perma.cc/37WD-V4WZ] (\u201cTraining these language models in \na valuable way requires a monster amount of computing power and electricity.\u201d).  \n205. The algorithms used in the electricity sector, discussed supra in Part II, use \nprecise numbers, such as error rates and voltages, that do not have the same uncertainties and variation \nthat natural language processing does. Garbade, supra note 204 (\u201cWhile humans can easily master a \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n919 \nelectric-power sector may be able to favor the less energy-intensive algorithms \nto reduce emissions. It will also be important to keep an eye on the oil and gas \nindustry\u2019s use of AI to enhance efficiency.206 Depending on those algorithms\u2019 \nenergy demands, AI\u2019s use in fossil fuels may make their associated emissions \ncheaper to emit and increase their competitive advantage over less carbon-\nintensive resources.207  \nIf AI is to be used to combat climate change, we need to ensure that AI\u2019s \nnegative environmental impacts are outweighed by its positive ones. \nFortunately, there are several ways to do that, three of which are discussed \nbelow: (1) disclosure requirements, (2) certification regulations, and (3) \nincreasing data sharing. \nDisclosure. A first solution, proposed by the Allen Institute for AI, would \nbe having AI researchers include various financial and computational costs in \ntheir published results.208 Other scholars also advocate for greater visibility and \ndisclosure of environmental impacts.209 Researchers recently developed a \ncarbon-emissions tracker for machine learning that allows researchers to train \nthe data on their system and then generate emissions totals.210 In addition to \nemissions disclosures, researchers should report the amount of AI\u2019s other \n \nlanguage, the ambiguity and imprecise characteristics of the natural languages are what make NLP \ndifficult for machines to implement.\u201d); Will Knight, AI Can Do Great Things\u2014If It Doesn\u2019t Burn  Down \nthe Planet, WIRED (Jan. 21, 2020), https://www.wired.com/story/ai-great-things-burn-planet \n[https://perma.cc/TW9M-47KM] (\u201cRecent advances in natural language processing\u2014an AI technique \nthat helps machines parse, interpret, and generate text\u2014have proven especially power-hungry.\u201d).  \n206. See Shahab D. Mohaghegh, Recent Developments in Application of Artificial \nIntelligence in Petroleum Engineering, 57 J. PETROLEUM TECH. 86 (2005), \nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.117.4811&rep=rep1&type=pdf;  Jeff \nWilliams, Does AI Have the Power to Refine Oil and Gas Efficiency?, EY (June 4, 2019), \nhttps://www.ey.com/en_us/oil-gas/does-ai-have-the-power-to-refine-oil-and-gas-efficiency \n[https://perma.cc/CVW9-YF2Z] (\u201cOne of the world\u2019s largest oil companies uses analytics to better \nanticipate fluctuations in demand and supply, maximizing the value generated by each barrel of oil \nproduced.\u201d).  \n207. This \u201crebound effect\u201d is called the Jevon\u2019s Paradox. See Sara C. Bronin, \nBuilding-Related Renewable Energy and the Case of 360 State Street, 65 VAND. L. REV. 1875, 1934 \n(2012) (\u201c[A] term that refers to the phenomenon of increased efficiency leading to a reduction of the \nprice of services, leading in turn to increased consumption of services, which offsets the benefits of the \ninitial improvements in efficiency.\u201d). See generally W. STANLEY JEVONS, THE COAL QUESTION (A.W. \nFlux ed., 3d rev. ed. 1906) (discussing the Jevon\u2019s paradox as applied to Britain\u2019s coal industry). \n208. Karen Hao, AI Research Has an Environmental Climate Toll, MIT TECH. REV. \n(Aug. 2, 2019); https://www.technologyreview.com/f/614056/ai-research-has-an-environment-climate-\ntoll [https://perma.cc/GGW8-VF9D]; see also Roy Schwartz et al., Green AI, ALLEN INST. FOR AI 1-2 \n(July 2019), https://arxiv.org/pdf/1907.10597.pdf.  [https://perma.cc/69KG-Z53A] \n209. Ehrenkranz, supra note 204. \n210. See, e.g., Borning et. al, What Pushes Back from Considering Materiality in IT?, \nLIMITS (2018), https://computingwithinlimits.org/2018/papers/limits18-borning.pdf \n[https://perma.cc/HMA9-93GF] (suggesting visibility is one of the most impactful methods of limiting \nAI\u2019s environmental effects); Ehrenkranz, supra note 204. AI researchers have created resources for AI \nusers to calculate their approximate energy expenditure for each algorithm. See generally Eva Garcia-\nMartin et al., Estimation of Energy Consumption in Machine Learning, 134 J. PARALLEL & \nDISTRIBUTED COMPUTING  75 (2019) (discussing a method of calculating AI energy consumption). AI \nresearcher Sasha Luccioni launched a website to assist other AI researchers in calculating the \napproximate carbon footprint of their algorithms. ML CO2 IMPACT, \nhttps://mlco2.github.io/impact/#home [https://perma.cc/RV6Y-2FM3]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n920 \necological costs, including the heat and electronic waste generated and the raw \nmaterials used.211 \nThe hope is that increasing transparency and accountability would make \nresearchers put more effort into keeping those costs low212 and bring awareness \nto potential impacts of algorithms.213 The Allen Institute of AI specifically \nsuggests researchers disclose carbon emissions, electricity usage, elapsed real \ntime, number of parameters used by the model, and the number of floating-\npoint operations214 to generate a full picture of the potential impacts of the \nalgorithm.215  Researchers can only compare the costs to the benefits of an \nalgorithm if they are aware of the potential costs\u2014a topic that is often absent \nfrom conversations about the training and creation of algorithms.216 \nCertification. A second solution mimics other environmental regimes by \ncontemplating a certification requirement. The Allen Institute proposed a \ncertification for AI practices, labeling carbon-neutral AI as \u201cgreen\u201d and non-\ncarbon-neutral AI as \u201cred.\u201d217 As with other environmental-certification \nregimes, these labels can have important signaling effects that motivate \ncompanies to internalize their electricity use. As with organic-label regulation, \nfederal agencies could be involved in this certification process.218 But as with \nother environmental-certification regimes, these labels also run the risk of \ngreenwashing.219 \nData Sharing. A last approach for minimizing the environmental impacts \nof AI\u2019s computing power would be to enhance the sharing of data used in \nclimate-related algorithms. Data are algorithms\u2019 key input, and one person\u2019s \n \n211. See Borning et al., supra note 210 (assessing the \u201cdark side of IT\u2019s materiality\u201d).  \n212. Hao, supra note 208.  \n213. For example, scientists, when confronted with the issue of heat waste, have \nproposed methods of reusing the waste to heat nearby neighborhoods to make AI more efficient. See, \ne.g., Marcel Antal et al., Reuse of Data Center Waste Heat in Nearby Neighborhoods: A Neural \nNetworks-Based Prediction Model, MDPI (2019), \nhttps://www.researchgate.net/publication/331489955_Reuse_of_Data_Center_Waste_Heat_in_Nearby_\nNeighborhoods_A_Neural_Networks-Based_Prediction_Model [https://perma.cc/9GUR-HP4D]; \nEhrenkranz, supra note 204.  \n214. Floating-point operations provide an estimate of the amount of work performed \nby a computational process. Schwartz et al., supra note 208, at 6.  \n215. Id. at 6.  \n216. Professor Luccioni states, \u201cWe\u2019re not telling people, don\u2019t emit or don\u2019t train or \ndon\u2019t make this great algorithm. We\u2019re just trying to say, compare the costs and the environmental costs \nand the benefit of your algorithm.\u201d Id.; see also Alexandre Lacoste & Alexandra Luccioni et al., \nQuantifying the Carbon Emissions of Machine Learning (2019), https://arxiv.org/pdf/1910.09700.pdf \n[https://perma.cc/SCX5-ALGB] (providing a method for calculating a machine-learning algorithm\u2019s \ncarbon emissions).  \n217. Id. \n218. Governmental agencies controlling energy use, such as the Federal Energy \nRegulatory Commission (FERC) and the National Institute of Standards and Technology (NIST), could \npromote \u201cGreen\u201d certification, and control the requirements for meeting that certification. Compare to \nUSDA Organic label certifications, for example, Organic Certification and Accreditation, U.S. DEP\u2019T \nAGRIC., https://www.ams.usda.gov/services/organic-certification [https://perma.cc/V7NX-LMP5]. \n219. See infra Section III.D. See generally Jacob Vos, Actions Speak Louder Than \nWords: Greenwashing in Corporate America, 23 NOTRE DAME J.L. ETHICS & PUB. POL\u2019Y 673 (2009). \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n921 \nuse of the data does not reduce another\u2019s ability to use it.220 Data\u2019s nonrivalrous \nnature renders it a viable candidate to be treated as a public good, much as we \ntreat scientific knowledge.221 \nJust as the federal government has a role to play in other sorts of public \ngoods, so too it may be a viable partner for climate-related AI. For the electric-\npower sector, for instance, the federal government could minimize the number \nof duplicative tasks related to climate AI by serving as a repository for publicly \navailable, nonidentifying electricity data.222 Back in 2005, Congress took steps \ntoward addressing these complicated issues by allowing interested persons \naccess to nonspecific smart-meter customer information.223 In 2012, the White \nHouse followed by launching the Green Button Initiative in concert with the \nDOE.224 The initiative enables utility customers to securely share their data \nwith authorized third-party service providers.225 According to the DOE, about \n \n220. This reflects one of the components of \u201cpublic goods,\u201d those that are generally \npublicly available. Will Kenton, Public Good, INVESTOPEDIA (Mar. 25, 2019), \nhttps://www.investopedia.com/terms/p/public-good.asp [https://perma.cc/JQ4U-DSRK]. Key \ncharacteristics include nonrivalry (i.e., when one person uses a product, others are not thereby deprived \nof it) and nonexcludability (i.e., everyone can use it). Id.; see also Victoria Stodden, Enabling \nReproducibility in Big Data Research: Balancing Confidentiality and Scientific Transparency, in \nPRIVACY, BIG DATA, AND THE PUBLIC GOOD: FRAMEWORKS FOR ENGAGEMENT 112, 114 (Julia Lane et \nal. eds.), https://web.stanford.edu/~vcs/papers/Chapter5-BigDataPrivacy-STODDEN.pdf \n[https://perma.cc/FRM8-FWY3] (arguing that while data is in theory accessible, ordinary people have a \nhard time understanding the data because the method of analyzing the data is often not included in \nresearch studies); Benjamin K. Sovacool, The Best of Both Worlds: Environmental Federalism and the \nNeed for Federal Action on Renewable Energy and Climate Change, 27 STAN. ENVTL. L.J. 397, 471 \n(2008) (discussing how every state would benefit from scientific studies regarding energy and the \nenvironment and how federal regulation and intervention could make up funding gaps, provide a \nunilateral cooperative approach, and reduce transaction costs).  \n221. Dana Dalrymple, Scientific Knowledge as a Global Public Good: Contributions \nto Innovation and the Economy, in THE ROLE OF SCIENTIFIC AND TECHNICAL DATA AND INFORMATION \nIN THE PUBLIC DOMAIN: PROCEEDINGS OF A SYMPOSIUM (2003), \nhttps://www.ncbi.nlm.nih.gov/books/NBK221876 [https://perma.cc/W9D9-56QF] (\u201cScientific \nknowledge in its pure form is a classic public good. It is a keystone for innovation.\u201d); see also D. Daniel \nSokol & Roisin Comerford, Antitrust and Regulating Big Data, 23 GEO. MASON L. REV. 1129, 1140 \n(2016) (discussing data as a public good). \n222.  Individual states are experimenting with smaller scale shared electricity data \nplatforms. See, e.g., Smart Meter Texas, SMART PREPAID ELECTRIC, \nhttps://www.smartprepaidelectric.com/FAQs/SmartMeterTexas.aspx [https://perma.cc/D4UH-83FN]; \nJeff St. John, Texas Takes a Big Step in Improving Access to Smart Meter Data, GREENTECH MEDIA \n(Feb. 6, 2018), https://www.greentechmedia.com/articles/read/texas-smart-meter-data-access \n[https://perma.cc/G4ZJ-L4LT].  \n223.  See Federal Smart Metering Law of 2005, 16 U.S.C. \u00a7 2621 (2018) (\u201cPurchasers \nshall be able to access their own information at any time through the Internet and on other means of \ncommunication elected by that utility for Smart Grid applications. Other interested persons shall be able \nto access information not specific to any purchaser through the Internet. Information specific to any \npurchaser shall be provided solely to that purchaser.\u201d (emphasis added)).  \n224.  Green Button Initiative Makes Headway with Electric Industry and Consumers, \nWHITE HOUSE: PRESIDENT BARACK OBAMA (July 22, 2015), \nhttps://obamawhitehouse.archives.gov/blog/2015/07/22/green-button-initiative-makes-headway-electric-\nindustry-and-consumers [https://perma.cc/3LCG-67G4]; see also Green Button: Open Energy Data, \nU.S. DEP\u2019T ENERGY, https://www.energy.gov/data/green-button [https://perma.cc/G5AB-L9FZ].   \n225.  Green Button: Powering Access to Energy and Water Usage Data, GREEN \nBUTTON ALLIANCE, https://www.greenbuttonalliance.org/green-button\u2014powering-access \n[https://perma.cc/2CJN-DF8M].  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n922 \nfifty utilities and electricity suppliers have joined the initiative,226 but with over \n3,000 utility and electricity suppliers in the United States,227 it still has a long \nway to go. \nThe federal government may even be able to centralize some of the other \nsteps in the development of quality AI. Collecting, cleaning, and partitioning \nthe data, as well as selecting, training, and deploying the model, are all energy-\nconsuming endeavors.228 Centralizing these steps would allow more efficient \naccess to more data while avoiding exorbitant costs and minimizing the \nenvironmental impacts of training the AI.229 Some of such nonproprietary work \ncan be performed by the federal government and then shared with the broader \nscientific community.230 This could help to alleviate needless duplication while \nresearchers develop useful climate AI. Such collaborations may face familiar \nobstacles associated with trade secrets, intellectual property rights, and \ncustomer privacy rights.231 Private utility data with identifying information may \nnot qualify for such a data-sharing initiative due to the highly personal and \nconfidential nature of the data. The privacy implications of electricity data are \ndiscussed in Section II.B below. \n \n226.  Green Button: Open Energy Data, U.S. DEP\u2019T ENERGY, \nhttps://www.energy.gov/data/green-button [https://perma.cc/4VBM-KL3H] (\u201cTo date, a total over 50 \nutilities and electricity suppliers have signed on to the initiative.\u201d).  \n227.  Investor-Owned Utilities Served 72% of U.S. Electricity Customers in 2017, U.S. \nENERGY INFO. ADMIN. (Aug. 15, 2019), https://www.eia.gov/todayinenergy/detail.php?id=40913 \n[https://perma.cc/YE3L-QMSE] (\u201cAccording to the U.S. Energy Information Administration\u2019s (EIA) \nelectric power sector survey data, almost 3,000 electric distribution companies\u2014or utilities\u2014were \noperating in the United States in 2017.\u201d).  \n228.  Paul Ohm, Broken Promises of Privacy: Responding to the Surprising Failure of \nAnonymization, 57 UCLA L. REV. 1701,1757-58 (2010).  \n229. Ehrenkranz, supra note 204 (\u201c[F]or example, Google might spend millions of \ncompute hours training a model and then they publish it and then a similar company could take that \nmodel and just do a few compute hours transferring the knowledge to the dataset.\u201d). With data sharing, \ncompanies like Uber and Lyft will be able to better manage issues such as congestion and pollution. See \nStephen Edelstein, Ford, Uber, Lyft Join Urban Data-Sharing Project to Reduce Traffic and Pollution, \nDRIVE (Sept. 27, 2018), https://www.thedrive.com/tech/23874/ford-uber-lyft-join-urban-data-sharing-\nproject-to-reduce-traffic-and-pollution [https://perma.cc/TL9Y-SVEL].  \n230. See, e.g., Tyler Cowen, Public Goods, ECONLIB, \nhttps://www.econlib.org/library/Enc/PublicGoods.html [https://perma.cc/T2TC-3DU7]; Jasmin Leveille, \nEmbrace Open-Source Military Research to Win the AI Competition, WAR ON ROCKS (Oct. 16, 2019),  \nhttps://warontherocks.com/2019/10/embrace-open-source-military-research-to-win-the-ai-competition \n[https://perma.cc/E8PH-7QLT]; Tim Worstall, Why Government Should Spend More on Public Goods, \nFORBES (May 5, 2013), https://www.forbes.com/sites/timworstall/2013/05/05/why-government-should-\nspend-more-on-public-goods [https://perma.cc/E8XV-7T4D]. \n231. See, e.g., Heather Payne, Sharing Negawatts: Property Law, Electricity Data, \nand Facilitating the Energy Sharing Economy, 123 PENN ST. L. REV. 355, 379-86 (2019); Britain Eakin, \nUSPTO Wants Input On How AI Impacts Copyrights, TMs, LAW360 (Oct. 30, 2019), \nhttps://www.law360.com/articles/1215158/uspto-wants-input-on-how-ai-impacts-copyrights-tms \n[https://perma.cc/645F-AYRQ]; Tiffany Hu, USPTO Hears Mixed Views on AI Copyright Protections, \nLAW360 (Jan. 16, 2020), https://www.law360.com/articles/1233791/uspto-hears-mixed-views-on-ai-\ncopyright-protections [https://perma.cc/W9SR-3GNM]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n923 \nB. Data Privacy \nOne of the looming questions across all applications of AI concerns the \nprivacy implications of all this data.232 These questions are no less important \nfor utilities.233 Utilities are in a unique position of power in this situation, as \nthey have enduring relationships with many of their customers, many of whom \nare captured ratepayers with no retail choice.234 Utilities have had longstanding \naccess to these customers\u2019 data,235 and increasing access to more granular data \nwith the advent of smart meters.236 \nThese smart meters are particularly vexing for privacy issues. Smart \nmeters are bidirectional meters that can be accessed remotely; communicate \ninformation on voltage, current, and power directly to utilities; and support \nsmart consumption and pricing applications of distributed resources like \nrooftop solar.237 If AI functions better the more data it has, data sharing will be \ncritical to successfully implementing AI technologies.238 There are more than \n \n232. For a general discussion on Big Data and privacy concerns, see Micah Altman et \nal., Practical Approaches to Big Data Privacy over Time, 8 INT\u2019L DATA PRIVACY L. 29, 29-47 (2018); \nDavid Gray & Danielle Citron, The Right to Quantitative Privacy, 98 MINN. L. REV. 62, 80 (2013); \nThomas M. Lenard & Paul H. Rubin, Big Data, Privacy and the Familiar Solutions, 11 J.L. ECON. & \nPOL\u2019Y 1 (2015); and Ira S. Rubinstein & Nathaniel Good, Privacy by Design: A Counterfactual Analysis \nof Google and Facebook Privacy Incidents, 28 BERKELEY TECH. L.J. 1333, 1335 (2013). See also \nUnited States v. Jones, 565 U.S. 400, 405 (2012) (\u201cWe hold that the Government\u2019s installation of a GPS \ndevice on a target\u2019s vehicle, and its use of that device to monitor the vehicle\u2019s movements, constitutes a \n\u2018search.\u2019 . . . The Government physically occupied private property for the purpose of obtaining \ninformation. We have no doubt that such a physical intrusion would have been considered a \u2018search\u2019 \nwithin the meaning of the Fourth Amendment when it was adopted.\u201d (footnote omitted)); Meghanath \nMacha et al., Perils of Location Tracking? Personalized and Interpretable Privacy Preservation in \nConsumer Mobile Trajectories (2019), https://www.law.nyu.edu/sites/default/files/Beibei%20Li.pdf \n[https://perma.cc/Z9W8-V5G5] (discussing the tradeoffs of efficient versus optimal privacy). \n233. Utilities are aware of the risks they face with storing data, but they may not truly \nunderstand what needs to be done to protect against these risks. See Susan Partain, Protecting Customer \nTrust: Ensuring Data Privacy, AM. POWER ASS\u2019N (Sept. 4, 2018), \nhttps://www.publicpower.org/periodical/article/protecting-customer-trust-ensuring-data-privacy \n[https://perma.cc/4K9M-8JPD] (\u201c[U]tilities already recognize the importance of protecting data . . . . \nHowever, . . . the challenge for utility managers is . . . knowing how and where to implement the right \nlevel of protection and controls.\u201d). \n234. See Electricity Residential Retail Choice Participation Has Declined Since 2014 \nPeak, U.S. ENERGY INFO. ADMIN. (Nov. 8, 2018), \nhttps://www.eia.gov/todayinenergy/detail.php?id=37452 [https://perma.cc/GXS4-LBBH] (\u201cThe number \nof customers participating in retail choice programs peaked at 17.2 million customers (13% of total \nresidential customers) in 2014 and has since declined, reaching 16.2 million customers (12% of the \nnational total) in 2016 and 16.7 million customers (13% of the national total) in 2017.\u201d).  \n235. Access to Data: Bringing the Electricity Grid into the Information Age, \nADVANCED ENERGY ECON. (Sept. 2017), https://info.aee.net/hubfs/PDF/Access-to-data.pdf \n[https://perma.cc/7J82-QA43] [hereinafter Access to Data].  \n236. See id. (\u201cHistorically, most electric meters were read monthly, severely limiting \nthe actionable data available. Today, with over 50% of U.S. households having electric meters with \nadvanced metering functionality[,] . . . tens of millions of customers now have meters that can collect \ngranular usage data and transmit that data to the utility.\u201d).   \n237. Ramyar Rashed Mohassel et al., A Survey on Advanced Metering Infrastructure, \n63 INT\u2019L J. ELECTRIC POWER & ENERGY SYS. 473, 478 (2014). \n238. Walton, supra note 134.  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n924 \n86.8 million smart meters installed in the United States,239 accounting for about \n56% of all meters,240 with that number expected to rise to 93% by 2030.241 \n\u201cWith deployment of advanced metering infrastructure (AMI) and smart \nsensor-equipped hardware, system operators are capturing unprecedented levels \nof data.\u201d242 This leads to concerns about the private information that can be \ngleaned about individuals through their behavioral patterns, with fears of \naccidental or malicious surveillance, targeted home invasions, profiling, \nbehavior tracking, or identity theft.243 This places additional responsibilities on \nthe utilities as guardians of this data and raises important questions about this \ndata\u2019s storage, use, transfer, and disposal.244 \nThe ability of the government to access this information has even come \nunder constitutional scrutiny in the context of warrants for this data. In 2018, \nthe Seventh Circuit held that collecting data from smart meters constituted a \n\u201csearch\u201d under the Fourth Amendment.245 The court held that the data \u201ceven \nwhen collected at fifteen-minute intervals, reveals details about the home that \nwould be otherwise unavailable to government officials with a physical search. \n[The utility company] therefore \u2018searches\u2019 its residents\u2019 homes when it collects \nthis data.\u201d246 Nevertheless, the court also held that the search was reasonable \nafter balancing the intrusion against the promotion of the legitimate \ngovernment interest in modernizing the electrical grid.247 Other state courts \nhave disagreed, finding a warrant for such data was not required.248 And at \n \n239. How Many Smart Meters Are Installed in the United States, and Who Has \nThem?, U.S. ENERGY INFO. ADMIN., https://www.eia.gov/tools/faqs/faq.php?id=108&t=3 \n[https://perma.cc/33SD-PPMA].  \n240. U.S. ENERGY INFO. ADMIN., ELECTRIC POWER ANNUAL 2018, at 188, tbl.10.10 \n(2018),  https://www.eia.gov/electricity/annual/pdf/epa.pdf [https://perma.cc/L6U3-THFH] (86,844,157 \ntotal AMI meters in 2018 divided by 154,068,551 total meters in 2018).  \n241. U.S. DEP\u2019T OF ENERGY, SMART GRID SYSTEM REPORT: 2018 REPORT TO \nCONGRESS 30 fig.10 (2018), \nhttps://www.energy.gov/sites/prod/files/2019/02/f59/Smart%20Grid%20System%20Report%20Novemb\ner%202018_1.pdf [https://perma.cc/MP8D-9WM8].  \n242. Trabish, supra note 6. \n243. The Smart Grid and Privacy, ELECTRONIC PRIVACY INFO. CTR., \nhttps://epic.org/privacy/smartgrid/smartgrid.html [https://perma.cc/7NGR-DFHD]. \n244. BRANDON J. MURRILL, EDWARD C. LIU & RICHARD M. THOMPSON II, CONG. \nRES. SERV., R42338, SMART METER DATA; PRIVACY AND CYBERSECURITY, \nhttps://fas.org/sgp/crs/misc/R42338.pdf [https://perma.cc/7TQX-68G7]; Megan McLean, How Smart Is \nToo Smart?: How Privacy Concerns Threaten Modern Energy Infrastructure, 18 VAND. J. ENT. & \nTECH. L. 879, 895\u201399 (2016); Payne, supra note 231, at 359. \n245. Naperville Smart Meter Awareness v. City of Naperville, 900 F.3d 521, 527 (7th \nCir. 2018). \n246. Id.; see also Mohassel et al., supra note 237, at 478 (explaining that, through \nanalyzing these signatures, it is possible to determine information such as \u201chow many people live in the \nhouse, duration of occupancy, type of appliances, security and alarming systems, to inferring special \nconditions such as medical emergencies\u201d). \n247. Naperville Smart Meter Awareness, 900 F.3d at 528 (\u201cThat interest is substantial \nin this case. Indeed, the modernization of the electrical grid is a priority for both Naperville . . . and the \nFederal Government.\u201d).  \n248. See United States v. Colby, No. A-07-CR-072-LY, 2007 WL 9718271, at *7 \n(W.D. Tex. Dec. 13, 2007), aff\u2019d, 369 F. App\u2019x 625 (5th Cir. 2010) (holding that the police did not need \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n925 \nleast one state legislature has taken a firm stance against requiring warrants to \naccess smart-meter data.249 \nSuch privacy concerns run into direct conflict with efforts to minimize \nduplicative training and to facilitate sharing of data, steps discussed supra and \nviewed as critical to enabling a more modern grid.250 To address this tradeoff, \nstakeholders and regulators can take a number of important steps to minimize \nthe negative privacy implications of using all this energy data. At least two \navenues exist to help facilitate such collaborations: (1) rigorous procedures for \nanonymizing energy data; and (2) regulating data ownership, each of which is \ndiscussed below. \nAnonymizing Data. Anonymization of data is a commonly used technique \nfor protecting data privacy. Anonymization is the process of deidentifying data, \nsuch that the information can no longer \u201creasonably identify, relate to, describe, \nreference, be capable of being associated with, or be linked, directly or \nindirectly, to a particular individual.\u201d251 Common data-anonymization \ntechniques include randomization252 and generalization.253 \nIn the United States, data-protection laws provide safe harbors for entities \nthat anonymize their data.254 However, anonymized data is often not entirely \n \na warrant in a drug operation to gather electricity data from a home because it did not \u201creveal intimate \ndetails about activity within the home\u201d); People v. Stanley, 86 Cal. Rptr. 2d 89, 94 (App. 1999) (holding \nthat no warrant was needed to gather data on energy consumption because \u201c[i]t only tells officers how \nmuch electricity is being delivered by the utility and, by comparison to billing records, whether it is \nbeing diverted or stolen\u201d). \n249. See TENN. CODE ANN. \u00a7 39-13-610(e) (2020). \n250. See Access to Data, supra note 235 (\u201cTimely and convenient access to granular \ncustomer and electricity system data is critical to support the development of a modern grid.\u201d); see also \nPayne, supra note 231, at 361 (\u201cOnly with this granular data can [utilities] customers have actionable \ninsights\u2014and participate in the sharing economy. The lack of the ability to have this data, then, hampers \nthe development of the sharing economy and the grid and environmental benefits that could come along \nwith it.\u201d). Although it is not a data sharing organization, sharing technology may be similarly critical. \nSee About Us, INDUS. INTERNET CONSORTIUM, https://www.iiconsortium.org/about-us.htm \n[https://perma.cc/U8W5-RSED] (\u201cThe Industrial Internet Consortium was founded in March 2014 to \nbring together the organizations and technologies necessary to accelerate the growth of the industrial \ninternet by identifying, assembling, testing and promoting best practices.\u201d). \n251. Online Privacy Act of 2019, H.R. 4978, 116th Cong. \u00a7 2(8) (2019); see also Tal \nZ. Zarsky, Governmental Data Mining and Its Alternatives, 116 PENN ST. L. REV. 285, 299 n.47 (2011) \n(\u201cAnonymized data refers to data that went through an anonymization process\u2014the process of removing \nidentifying information and rendering the dataset anonymous.\u201d).  \n252. \u201cRandomization is a family of techniques that alters the veracity of the data in \norder to remove the strong link between the data and the individual.\u201d ARTICLE 29 DATA PROTECTION \nWORKING PARTY, OPINION 05/2014 ON ANONYMISATION TECHNIQUES 12 (Apr. 10, 2014), \nhttps://www.pdpjournals.com/docs/88197.pdf [https://perma.cc/A2LS-6NXE].  \n253. Generalization includes \u201cgeneralizing, or diluting, the attributes of data subjects \nby modifying the respective scale or order of magnitude.\u201d Id. at 16.  \n254. For example, HIPPA states:  \n(1) Uses and disclosures to create de-identified information. A covered entity may use \nprotected health information to create information that is not individually identifiable health \ninformation . . . . (2) Uses and disclosures of de-identified information. Health information \nthat meets the standard and implementation specifications for de-identification under \u00a7 \n164.514(a) and (b) is considered not to be individually identifiable health information, i.e., de-\nidentified.  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n926 \nanonymous. Professor Ohm, a leading data-privacy scholar, analyzed three \ncases where anonymization failed and found: \nEven though administrators had removed any data fields they thought might \nuniquely identify individuals, researchers . . . unlocked identity by discovering \npockets of surprising uniqueness remaining in the data. Just as human \nfingerprints left at a crime scene can uniquely identify a single person and link \nthat person with \u201canonymous\u201d information, so too do data subjects generate \n\u201cdata fingerprints\u201d\u2014combinations of values of data shared by nobody else in \ntheir table.255 \nThe proposed Online Privacy Act of 2019 addresses these re-identification \nconcerns but did not take an aggressive stance on mandatory anonymization.256 \nIt only required anonymization where efforts to do so are \u201creasonable,\u201d257 a \ncondition that may preclude anonymization of massive amounts of smart meter \ndata,258 not just when it is not \u201can unreasonable amount of effort.\u201d259 \nRegulating Data Ownership. A last option would be the regulation of data \nownership, its use, and its distribution.260 Generally, utility-company customers \nhave a right to access the data, but there are varying views on whether third \nparties can access this data,261 as well as who owns the data.262 Congress has \nalready begun to address these complicated issues, including allowing \ninterested persons access to nonspecific utility-customer information.263 \n \n45 C.F.R. \u00a7 164.502 (2019). In the European Union (EU), data anonymization is encouraged and slowly \nbeing adopted to ensure data privacy in response to the General Data Protection Regulation (GDPR). See \nARTICLE 29 DATA PROTECTION WORKING PARTY, OPINION 03/2016 ON THE EVALUATION AND REVIEW \nOF THE EPRIVACY DIRECTIVE (July 19, 2016); see also Elizabeth A. Brasher, Addressing the Failure of \nAnonymization: Guidance from the European Union\u2019s General Data Protection Regulation, 2018 \nCOLUM. BUS. L. REV. 209, 211-14 (comparing anonymization\u2019s role in U.S. privacy laws and the \nGDPR).   \n255. Ohm, supra note 228, at 1723.  \n256. Online Privacy Act of 2019, H.R. 4978, 116th Cong. (2019). \n257. Id. \u00a7 201(d) (\u201cIn cases in which personal information can be replaced \nwith\u2026personal information that has been de-identified, or the random personal information of a one or \nmore individuals without substantially reducing the utility of the data or requiring an unreasonable \namount of effort, such a replacement shall take place.\u201d).  \n258. For a description of a two-stage approach to protecting the privacy of such \ninformation, see Lindah Kotut et. al, Privacy Preserving Smart Meter Data, PROC. ACM CONF. ON \nCOMPUTER & COMM. SECURITY (Aug. 2018), http://urbcomp.ist.psu.edu/2018/papers/privacy.pdf \n[https://perma.cc/9J35-5MJ5]. See also Costas Efthymiou & Georgios Kalogridis, Smart Grid Privacy \nvia Anonymization of Smart Metering Data, 2010 FIRST IEEE INT\u2019L CONF. ON SMART GRID COMM. \n(Nov. 2010) (suggesting a method for anonymizing smart meter data).  \n259. See Lindah Kotut et. al, Privacy Preserving Smart Meter Data, PROC. ACM \nCONF. ON COMPUTER & COMM. SECURITY (Aug. 2018), \nhttp://urbcomp.ist.psu.edu/2018/papers/privacy.pdf [https://perma.cc/7LVC-3L5R]. \n260. See, e.g., Alexandra Klass & Elizabeth Wilson, Remaking Energy: The Critical \nRole of Energy Consumption Data, 104 CALIF. L. REV. 1095 (2016) (arguing that data-privacy concerns \ncan be adequately addressed through aggregating historic data). \n261. For a discussion on utility-data access and ownership rights in different states, \nsee Payne, supra note 231, at 372-79. \n262. Id. at 379-95. \n263. See Federal Smart Metering Law of 2005, 16 U.S.C. \u00a7 2621 (2018) (\u201cPurchasers \nshall be able to access their own information at any time through the Internet and on other means of \ncommunication elected by that utility for Smart Grid applications. Other interested persons shall be able \nto access information not specific to any purchaser through the Internet. Information specific to any \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n927 \nColorado is one of the few states that explicitly regulate the distribution of \nsmart-meter data.264 And in Massachusetts, an order regarding a smart-meter \nproposal even considered distributing ownership rights between the customer \nand the utility based on who collected the data.265 Moreover, the Green Button \ninitiative, mentioned above, also encourages utilities to \u201cprovide utility \ncustomers with easy and secure access to their energy usage information in a \nconsumer-friendly and computer-friendly format for electricity, natural gas, and \nwater usage.\u201d266 The initiative allows utility customers to access their data, \nwith the option to share the data if they choose.267 \nAI algorithms use data to make important public-policy decisions every \nday,268 thus most scholars agree some degree of regulation is warranted.269 \nProfessor Solow-Niederman goes one step past regulation of data in arguing \ninstead that we should be regulating AI algorithms, but she acknowledges that \nadministrative law will have to adapt if we are to effectively regulate them.270 \nAI\u2019s speed, complexity, and uncertainty would make standard prescriptive \nregulations difficult to enforce.271 While public policy might eventually \ndemand regulation of AI algorithms, that will take time; a good start would be \nto explicitly regulate the ownership of the data used in the algorithm to ensure \nAI applications are being developed with the public interest in mind. \n \npurchaser shall be provided solely to that purchaser.\u201d (emphasis added)). Illinois regulators recently \nfinalized a nonbinding Open Data Access Framework which is very similar to the Federal Smart \nMetering Law of 2005, 16 U.S.C. \u00a7 2621. Payne, supra note 231, at 376-77. \n264. 4 COLO. CODE REGS. \u00a7 723-3:3029 (LexisNexis 2016); see also Electric Usage \nData Protection Act, OKLA. STAT. ANN. tit. 17, \u00a7\u00a7 710.1-.8 (primarily regulating customer access to data \nwith a few exceptions for third-party access to data in emergency situations).  \n265. In re Elec. Distribution Cos., No. DTE 01-28, 2001 WL 1149629 (Mass. D.T.E. \nMay 18, 2001); see also Payne, supra note 231, at 376 (\u201cA Massachusetts decision seems to indicate \nthat there may be a difference in ownership rights depending on who collects the data, either the utility \nor the consumer.\u201d). \n266. GREEN BUTTON DATA, http://www.greenbuttondata.org/index.html \n[https://perma.cc/LQ27-X6H2]; see supra notes 224-227 and accompanying text. \n267. Green Button: Powering Access to Energy and Water Usage Data, GREEN \nBUTTON ALLIANCE, https://www.greenbuttonalliance.org/green-button\u2014powering-access \n[https://perma.cc/2CJN-DF8M]. \n268. Alicia Solow-Niederman, Administering Artificial Intelligence, 93 S. CAL. L. \nREV. (forthcoming 2020) (manuscript at 3-11), https://papers.ssrn.com/abstract=3495725 \n[https://perma.cc/FFV5-PYLL].  \n269. See, e.g., Michael Guihot et al., Nudging Robots: Innovative Solutions to \nRegulate Artificial Intelligence, 20 VAND. J. ENT. & TECH. L. 385 (2017); Matthew U. Scherer, \nRegulating Artificial Intelligence Systems: Risks, Challenges, Competencies, and Strategies, 29 HARV. \nJ.L. & TECH. 353 (2016). \n270. Solow-Niederman, supra note 268 (manuscript at 40-50).  \n271. Professor Solow-Niederman suggests utilizing markets and norms to govern AI \ncodes. Id. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n928 \nC. Investment and Procurement \nA key policy tool for facilitating the use of more AI for climate issues is \nfunding. This Section addresses potential funding constraints for three source \ncategories: private regulated utilities, private nonutilities, and public entities. \n1. Utility Investing in Artificial Intelligence \nRegulated utilities, comprising one-third of our country, will experience \nunique challenges associated with implementing AI. Regulated utilities\u2019 \ninvestments are approved by state public utility commissions (PUCs) through \nratemaking requests.272 Such PUCs are often skeptical of emerging new \ntechnologies, often bound to only approve the least-cost alternative, and \nutilities are only provided a rate of return for capital investments, not operating \ncosts.273 This raises problems for utilities seeking to use more AI on three \nfronts: emerging technologies, cost, and accounting classification of AI \ninvestments. \nEmerging Technologies. If AI has the potential to serve as a cost-effective \ndiagnostic tool for the electric industry to reduce GHGs, why aren\u2019t all the \nutilities jumping on board? One answer may lie in the difficulties of obtaining \ncost recovery for emerging technologies.274 Decisions about cost recovery for \nutility investments, including emerging technologies, are made by state PUCs. \nGiven how many utilities need to obtain regulatory approvals of their \nexpenditures to obtain cost recovery, a critical factor in the advancement of AI \nto enhance efficiencies across the electricity sector is the regulatory treatment \nof emerging technologies. \nEmerging technologies are those that have not been readily proven, and \nchange with the times.275 Nuclear plants were once considered emerging \ntechnologies, as were combined-cycle natural-gas plants. The last decade\u2019s \n \n272. U.S. DEP\u2019T OF ENERGY, DOE/OE-0017, UNITED STATES ELECTRICITY \nINDUSTRY PRIMER (2015), https://www.energy.gov/sites/prod/files/2015/12/f28/united-states-electricity-\nindustry-primer.pdf [https://perma.cc/5ZUL-XUKZ]. Two-thirds of the country procures their electricity \nthrough competitive markets while one-third procures it through ratemaking requests to the PUC. \n273. LISA WOOD ET AL., FUTURE ELEC. UTIL. REGULATION ADVISORY GRP., LBNL-\n1005742, REPORT NO. 5, RECOVERY OF UTILITY FIXED COSTS: UTILITY, CONSUMER, ENVIRONMENTAL \nAND ECONOMIST PERSPECTIVES 1 (2016), https://emp.lbl.gov/sites/all/files/lbnl-1005742.pdf \n[https://perma.cc/MV88-ZDE6]. \n274. See, e.g., Jonas J. Monast & Sarah K. Adair, Completing the Energy Innovation \nCycle: The View from the Public Utility Commission, 65 HASTINGS L.J. 1345, 1360 (2014) (\u201cIt is \nchallenging for early applications of innovative technologies to strictly meet the least cost standard, \nespecially in the current era of large capital investment needs, declining sales growth, and the resulting \nupward pressure on electricity rates.\u201d). Of course, there may also be other explanations, including a \ngeneral apathy toward change, skepticism about the cost effectiveness of AI or its tangible benefits, and \nothers. This Article merely raises one of many potential obstacles. \n275. For example, popular emerging technologies in 2018 included drones, \nbiometrics, and augmented reality. Alison DeNisco Rayome, Top 10 Emerging Technologies of 2019, \nTECHREPUBLIC (June 24, 2019), https://www.techrepublic.com/article/top-10-emerging-technologies-\nof-2019 [https://perma.cc/YZG2-LAHC]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n929 \nemerging technologies du jour in the electricity sector have included renewable \nenergy,276 smart meters, and energy storage, with varying successes for cost \nrecovery.277 \nEmerging technologies present many business and financial opportunities, \nbut the lack of information relating to these technologies can lead to feelings of \ntrepidation for both regulators and investors.278 Utilities may have difficulty \njustifying investment in power-grid infrastructure to regulators without proof of \nrecouping those costs.279 Furthermore, many of the value propositions of these \nemerging technologies involve avoided costs or long-term savings that are hard \nto quantify. In addition to PUC hesitancy, investors may similarly view such \nuncertainties as unfavorable in their return-on-investment forecasts. \nEfforts to support such emerging technologies are further hindered by \nexamples of technologies that were approved and failed to meet their potential. \nSuch failures can cost customers millions of dollars, as did Duke Energy\u2019s \nfailed attempts to update and build two nuclear plants, costing ratepayers more \nthan $3 billion.280 Relatedly, an approval of a nuclear repair project in Southern \nCalifornia went awry and cost ratepayers $3.3 billion dollars.281 Even if the \nproject is not an outright failure, a perceived lack of success by ratepayers can \nbe almost as damaging as a complete failure.282 Such failures tend to remain \nfresh on the mind and can be damning for subsequent emerging technologies. \n \n276. See  Office of Energy Efficiency & Renewable Energy, Renewable Energy: \nUtility-Scale Policies and Programs, U.S. DEP\u2019T ENERGY, https://www.energy.gov/eere/slsc/renewable-\nenergy-utility-scale-policies-and-programs [https://perma.cc/85U4-55RB]. Many PUCs rejected early \napplications for renewable energy, focusing on their intermittency, reliability, and cost concerns. Id. \n277. Compare Application of Balt. Gas & Elec. Co. for Adjustments to Its Elec. & \nGas Base Rates, 330 P.U.R.4th 30 (2016) (approving), with Stevens & Lee, Xcel Energy Denied $14.8 \nMillion in Smart Grid City Cost Recovery, SMART GRID LEGAL NEWS (Feb. 16, 2011), \nhttps://www.smartgridlegalnews.com/cost-recovery/xcel-energy-denied-148-million-in-smart-grid-city-\ncost-recovery [https://perma.cc/42NA-2DQG] (denying), and Denied: US Utility\u2019s Request to Charge \nCustomers for AMI Opt-Out, SMART ENERGY INT\u2019L (Feb. 9, 2019), https://www.smart-\nenergy.com/industry-sectors/business-finance-regulation/denied-us-utilitys-request-to-charge-\ncustomers-for-ami-opt-out [https://perma.cc/9PUU-7SCC] (denying  request to charge for smart meter \nopt-out). \n278. Id. \n279. Kendra Chamberlain, Smart Grids Are Essential to Prevent Old Power \nInfrastructure from Holding Back the US Economy (Mar. 23, 2019), \nhttps://thenextweb.com/podium/2019/03/23/us-smart-grids-electricity-economy [https://perma.cc/LG57-\nTE3K] (referring to a recent report commissioned by the National Electrical Manufacturers Association \n(NEMA)). \n280. See Duke Energy Customers Will Pay $108 Million a Year for Canceled Nuclear \nPlants, TAMPA BAY TIMES (Aug. 6, 2013), https://www.tampabay.com/news/business/energy/duke-\nenergy-customers-will-pay-108-million-a-year-for-cancelled-nuclear/2134867 [https://perma.cc/2DYZ-\nA7R8]; Ivan Penn, From Useful to Wasteful: How Utility Ratepayers Have Borne the Brunt of Failed \nProjects, L.A. TIMES (June 5, 2016), https://www.latimes.com/business/la-fi-aliso-canyon-20160605-\nsnap-story.html [https://perma.cc/8GCL-E3ZE]. \n281. Penn, supra note 280 (discussing a steam generator replacement at a nuclear \nplant that led to radiation leakage).  \n282.  A biomass plant approved for cost recovery by the utility in Gainesville, Florida, \nfunctions properly, but is viewed by many as a failed investment. See Mickie Anderson, GRU, Biomass \nPlant Battle Gets Uglier, GAINESVILLE SUN (July 30, 2016), \nhttps://www.gainesville.com/news/20160730/gru-biomass-plant-battle-gets-uglier \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n930 \nAlthough AI technologies will sometimes suffer the same fate as these \nother emerging technologies, there are a few strategies that could help \nimmunize these investments. First, many of the hardware and software cost \ncomponents could be characterized as more mundane capital costs. Rarely \nwould a line-item present itself as \u201cAI\u201d, but rather as the more innocuous \ncomputer-related costs. Second, utilities sometimes insulate themselves from \nthe riskiness of emerging technologies by charging customers in advance.283 \nThird, state legislatures could mandate the use of AI, shielding the PUC from \nbearing the brunt of the investment risk. Some states have taken this approach \nto smart meters by mandating their use,284 contributing to reports that utility \ninvestment in smart meters has more than doubled over the past decade.285 \nCost. Emerging technologies often take a double hit, as they are not only \noften viewed as riskier, but they are also often more expensive than incumbent \ntechnologies that have had years to work on efficiency improvements.286 These \nadditional costs can come in the form of novel research, design, testing, and \nmanufacturing.287 For new companies, economic factors such as economies of \nscale also play a large role in raising costs.288 And these costs can indeed be \n \n[https://perma.cc/AK6C-XAYL] (\u201cBy the time the $500 million plant began operating in late 2013, \nnatural gas prices had crashed, which meant GRU, and by extension, taxpayers, were paying much \nhigher prices to get biomass-produced energy than could be gotten from other sources.\u201d). \n283. See U.S. ENVTL. PROT. AGENCY, PUBLIC UTILITY COMMISSION STUDY (Mar. 31, \n2011), https://www3.epa.gov/airtoxics/utility/puc_study_march2011.pdf [https://perma.cc/4VTU-\nVB2Z]; see also John Downey, Here\u2019s How Much Duke Energy Is Seeking to Raise Utility Rates in \nNorth Carolina, CHARLOTTE BUS. J. (Sept. 30, 2019), \nhttps://www.bizjournals.com/charlotte/news/2019/09/30/heres-how-much-duke-energy-is-seeking-to-\nraise.html [https://perma.cc/VNW5-HCZS].  \n284. See 66 PA. STAT. AND CONS. STAT. ANN. \u00a7 2807(f) (West 2020); see also 220 \nILL. COMP. STAT. ANN. 5/16-124 (2020) (\u201cAn electric utility shall not require a residential or small \ncommercial retail customer to take additional metering . . . unless the Commission finds . . . that \nadditional metering or metering capability is required to meet reliability requirements.\u201d); P.R. LAWS \nANN. tit. 22, \u00a7 817 (stating that Puerto Rico\u2019s utility companies \u201cshall initiate programs to study the \nfeasibility and promote the use of smart meters . . . aimed at achieving the efficient and rational use of \nelectric power\u201d); Daniel Shea & Kate Bell, Smart Meter Opt-Out Policies, NAT\u2019L CONF. ST. \nLEGISLATORS (Aug. 20, 2019), https://www.ncsl.org/research/energy/smart-meter-opt-out-policies.aspx \n[https://perma.cc/69WD-4UTZ]. PUCs also mandate smart meters. See Hawkins v. Commonwealth \nEdison Co., 28 N.E.3d 869, 871 (Ill. App. 2015) (suit against the Illinois utility for failing to implement \nsmart meters in violation of an order from the Illinois Commerce Commission).  \n285. Major Utilities Continue to Increase Spending on U.S. Electric Distribution \nSystems, U.S. ENVTL. INFO. ADMIN. (July 20, 2018), \nhttps://www.eia.gov/todayinenergy/detail.php?id=36675 [https://perma.cc/R2CW-PGEE]. \n286. See GREEN ENERGY: TECHNOLOGY, ECONOMICS AND POLICY 230 (U. \nAswathanarayana, Tulsidas Harikrishnan & Thayyib S. Kadher-Mohien eds., 2010) (noting new energy \ntechnologies are generally more expensive than incumbent technologies). \n287. Amanda Robb, The Costs & Benefits of New Technology, STUDY.COM (Aug. 11, \n2016), https://study.com/academy/lesson/the-costs-benefits-of-new-technology.html \n[https://perma.cc/CR7Y-7SEH]. \n288. See Callum Glennen, Start-Ups Are Growing Like Never Before Thanks to \nEconomies of Scale, WORLD FIN. (Oct. 30, 2017), https://www.worldfinance.com/strategy/start-ups-are-\ngrowing-like-never-before-thanks-to-economies-of-scale [https://perma.cc/M5BC-LMPM].  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n931 \nexorbitant. For example, one study found that new medical technologies raised \nhospital expenses by twenty-five percent within a period of only six years.289 \nRenewable technologies provide yet another example. For years, solar-\nenergy generation was significantly more expensive than conventional energy \nsources like natural gas.290 At least a portion of that cost is caused by the fact \nthat as an emerging technology, solar power lacked the infrastructure needed to \nmake it compete significantly with conventional gas.291 But the high demand \nfor solar energy in recent years has driven down prices to the point where they \nare now on par with conventional energy generation.292 The cost of wind \npower, and especially onshore wind power, also now rivals that of fossil \nfuels.293 \nSimilarly, there may be a steep investment curve associated with the use \nof AI. Using AI may require new hardware and software, cloud costs, energy \nand data center costs, training costs, system and business-process integration \ncosts, and manpower.294 And as researchers work to gather, clean, and use data, \nit may be quite expensive to train electricity-sector models to perform as \ndesired.295 As with other emerging technologies, it may be important to \ndevelop a return-on-investment strategy that takes into account some of the \ndifficult-to-quantify benefits of implementing AI in the electricity sector like \nenhanced efficiency, avoided costs, reduced manpower, and improved accuracy \nin results.296 \nAccounting for Capital versus Operating Costs. A last reason that utilities \nmay not be fully realizing AI\u2019s benefits may be related to its accounting \nclassification. Regulated utilities earn a healthy rate of return on their capital \ninvestments. As has been noted frequently, this can provide them with a \nperverse incentive to invest in new construction (e.g., natural gas plants) as \n \n289. PETER J. NEUMANN & MILTON C. WEINSTEIN, THE CHANGING ECONOMICS OF \nMEDICAL TECHNOLOGY 24 (1991), https://www.ncbi.nlm.nih.gov/books/NBK234309 \n[https://perma.cc/P9WM-S522].  \n290. Barbara Hollingsworth, Study: Despite Subsidies, Solar Power More Expensive, \nCNSNEWS (Oct. 19, 2016), https://www.cnsnews.com/news/article/barbara-hollingsworth/study-solar-\npower-remains-considerably-more-expensive-electricity [https://perma.cc/9QM4-77KY]. \n291. Id. \n292. Dominic Dudley, Renewable Energy Costs Take Another Tumble, Making Fossil \nFuels Look More Expensive Than Ever, FORBES (May 19, 2019), \nhttps://www.forbes.com/sites/dominicdudley/2019/05/29/renewable-energy-costs-\ntumble/#248475e6e8ce [https://perma.cc/6SGM-GWA4] (\u201cThe cost of renewable energy has tumbled \neven further over the past year, to the point where almost every source of green energy can now compete \non cost with oil, coal and gas-fired power plants.\u201d). \n293. Id. \n294. Mary Shacklett, The True Costs and ROI of Implementing AI in the Enterprise, \nZD NET (Apr. 1, 2019), https://www.zdnet.com/article/the-true-costs-and-roi-of-implementing-ai-in-the-\nenterprise [https://perma.cc/2MN5-27KA]. \n295. See Tony Peng, The Staggering Cost of Training SOTA AI Models, MEDIUM \n(June 27, 2019), https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-\ne329e80fa82 [https://perma.cc/2JL3-VR9M]. \n296. Shacklett, supra note 294.  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n932 \nopposed to investments that could reduce our energy consumption (e.g., energy \nefficiency).297 \nA similar counterintuitive result can occur with AI. Most studies have \nshown that using commercial cloud computing can have cost savings for a \nbusiness over internally managing data.298 Yet utilities have historically been \nwary of adopting certain emerging technologies such as cloud computing \nbecause of the lack of financial incentives to adopt these technologies. Cost \nrecovery for capital expenditures encourages utilities to continue investing in \ncapital investments.299 Yet users of commercial cloud computing often pay \nmonthly for such services,300 constituting \u201coperating expenses\u201d in the regulated \nutility world. Unlike capital expenses, operating expenses are not typically \navailable for cost recovery.301 This accounting classification results in some \nutilities instead opting to run their data management onsite internally, a \nsuboptimal result.302 \nIn an effort to eliminate the financial incentive to use the less cost-\neffective internal data management service, in 2016, the National Association \nof Regulatory Utility Commissioners (NARUC) issued a resolution to instead \nreconsider the accounting treatment of external cloud computing: \n\u201cRESOLVED, That NARUC encourages State regulators to consider whether \n \n297. Promoting Cost-Effective Investment in Energy Efficiency, NAT\u2019L CONF. ST. \nLEGISLATURES (2019), https://www.ncsl.org/research/energy/promoting-cost-effective-utility-\ninvestment-in-energy-efficiency.aspx [https://perma.cc/HC3L-GTXF]. \n298. See Zach Lanich, The Benefits of Moving to the Cloud, FORBES (May 19, 2017), \nhttps://www.forbes.com/sites/forbestechcouncil/2017/05/19/the-benefits-of-moving-to-the-\ncloud/#6c4aa2c44733 [https://perma.cc/8ZT5-GUBT] (\u201cCloud services allow you to pay for the \nresource usage you need while taking advantage of scale and reliability, two things that most companies \ncan\u2019t afford internally. And there\u2019s no need to update software internally since this is handled \nautomatically.\u201d). An Illinois Commerce Commissioner has noted that incentivizing investments in cloud \ncomputing \u201chas beneficial environmental impacts, such as reducing a utility\u2019s carbon footprint and \nenergy usage and encouraging dematerialization. By removing carbon emitting on-site computing \nsolutions and migrating to cloud services, which is also increasingly powered by renewable resources, \nwe further our State\u2019s carbon emission reduction goals.\u201d Initiating Proposed Rulemaking Relating to the \nRegulatory Accounting Treatment of Cloud-Based Solutions, No. 170855, at 3 (Ill. Commerce Comm\u2019n \nJuly 16, 2020) (dissenting opinion to final order), https://icc.illinois.gov/docket/P2017-\n0855/documents/301395/files/525481.pdf [https://perma.cc/M3CJ-FE85]. \n299. Jill Feblowitz, Utilities Opt to Use Cloud-Based Analytics, Despite Lack of \nMonetary Incentives, UTIL. ANALYTICS (May 1, 2019), https://utilityanalytics.com/2019/05/utilities-opt-\nto-use-cloud-based-analytics-despite-lack-of-monetary-incentives [https://perma.cc/94LC-X2HX] \n(discussing the slow adoption of cloud services by some investor-owned utilities despite the lack of state \nor PUC action in assisting and encouraging the transition).   \n300. See Regulatory Accounting of Cloud Computing \u2013 Software as a Service in New \nYork and Illinois, ADVANCED ENERGY ECON. INST., \nhttps://info.aee.net/hubfs/IL_NY%20Cloud%20Computing%20Final%20.pdf [https://perma.cc/8JDJ-\nK56K] [hereinafter Regulatory Accounting]. \n301. Id.  \n302. This allows them to label such investments \u201ccapital expenses,\u201d allowing them to \nreceive their healthy rate of return on these costs. See Herman K. Trabish, Tackling the Perverse \nIncentive: Utilities Need New Cost Recovery Mechanisms for New Technologies, UTIL. DIVE (Mar. 6, \n2018), https://www.utilitydive.com/news/tackling-the-perverse-incentive-utilities-need-new-cost-\nrecovery-mechanism/518320 [https://perma.cc/K5MS-RR7U] (\u201cThe perverse incentive rewards utilities \nwith a profit margin for making capital investments, but not for contracted services that might serve \ncustomers better.\u201d).  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n933 \ncloud computing and on-premise solutions should receive similar regulatory \naccounting treatment, in that both would be eligible to earn a rate of return and \nwould be paid for out of a utility\u2019s capital budget.\u201d303 \nTwo states, New York and Illinois, are paving the way to allow cost \nrecovery for service-based emerging technologies.304 In New York, the NY \nPublic Service Commission (PSC) approved utilities capitalizing prepaid \ncontracts for software services.305 In essence, the PSC allowed the utility \ncompanies to prepay the total cost of the service contract and record it as a \nregulatory asset in the rate base.306 Illinois took a different approach. In January \n2019, the Illinois Commerce Commission proposed to allow utility companies \nto prepay for cloud services.307 But the Commission was poised to allow some \nearnings on pay-as-you-go-services, where the utility pays based on its actual \nuse of the service.308 On July 15, 2020, after three years of proceedings, the \nIllinois Commerce Commission issued a final rule declining to adopt the \nproposal \u201cas it lacks necessary consumer protection mechanisms.\u201d309 In a \nspirited dissent, two commissioners expressed disappointment in Illinois\u2019s \ndecision to stand \u201con the sidelines\u201d rather than be a leader on this issue, noting \nthe lost opportunity to provide regulatory certainty of treatment of these \nexternal cloud-computing services as regulatory assets, the lost environmental \nbenefits, and the overblown concerns about consumer protection given these \ncosts would still need to be reviewed for \u201cordinary prudence and \nreasonableness.\u201d310 Aside from these two states, there has not been widespread \nresponse to the NARUC resolution. Nevertheless, FERC has recognized the \npotential benefits of virtualization and cloud computing services in association \nwith bulk electric system operations and has issued a Notice of Inquiry to take \n \n303. Resolution Encouraging State Utility Commissions to Consider Improving the \nRegulatory Treatment of Cloud Commuting Arrangements, NAT\u2019L ASS\u2019N REG. UTIL. COMM\u2019RS, \nhttps://pubs.naruc.org/pub.cfm?id=2E54C6FF-FEE9-5368-21AB-638C00554476 \n[https://perma.cc/6B6X-Q4UR]. \n304. James McClelland, Utilities Moving to the Cloud? No Way . . . I Mean \nAbsolutely!, SMART ENERGY INT\u2019L (Dec. 27, 2017), https://www.smart-energy.com/news/utilities-cloud-\ncomputing [https://perma.cc/8JD4-DQVA] (\u201cPer a recent cloud survey from IDC, 18% of utilities \nindicated a propensity to move to a public cloud in 2018.\u201d).  \n305. Regulatory Accounting, supra note 300. \n306. Coley Girouard, Making Cloud Computing and Other Services Pay for Utilities \nand Customers, UTIL. DIVE (Apr. 11, 2019), https://www.utilitydive.com/news/making-cloud-\ncomputing-and-other-services-pay-for-utilities-and-customers/552471 [https://perma.cc/6UU7-5MA4]. \n307. Id. \n308. Regulatory Accounting, supra note 300. The pay-as-you-go model, unlike \nprepaid contracts, provides flexibility to utilities and lets them avoid paying for unused services. \nGirouard, supra note 306. \n309. Initiating Proposed Rulemaking Relating to the Regulatory Accounting \nTreatment of Cloud-Based Solutions, No. 170855, at 12 (Ill. Commerce Comm\u2019n July 15, 2020) (final \norder), https://icc.illinois.gov/docket/P2017-0855/documents/301398/files/525486.pdf \n[https://perma.cc/CX7M-L7BG]. \n310. Initiating Proposed Rulemaking Relating to the Regulatory Accounting \nTreatment of Cloud-Based Solutions, No. 170855, at 2-5 (Ill. Commerce Comm\u2019n July 16, 2020) \n(dissenting opinion to final order), https://icc.illinois.gov/docket/P2017-\n0855/documents/301395/files/525481.pdf [https://perma.cc/M3CJ-FE85]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n934 \ncomments on their benefits and risks, as well as whether the Critical \nInfrastructure Protection Reliability Standards stand as an obstacle to their \nuse.311 As such, states may want to more seriously consider such external cloud \ncomputing accounting options to truly reap AI\u2019s benefits. \n2. Nonutility Private Investment in Artificial Intelligence \nNonutilities include the rest of the private players in the electricity sector: \nmerchant plants, universities, entrepreneurs, and clean-energy start-up \ncompanies. As just one example, an international group of researchers has \nformed an organization called \u201cClimate Change AI.\u201d312 The goals of Climate \nChange AI include facilitating work at the intersection of climate change and \nmachine learning by encouraging the formation of cross-disciplinary teams and \npromoting discourse about best practices regarding the use of machine learning \nin climate-change domains.313 \nThese private players may be more dependent on public-sector funding \nand grants for AI and climate.314 However, the latest wave of AI technology \nseems to have brought its own wave of funding. Investments in AI are booming \nwith corporate and venture capital support.315 Some may have the backing of \nlarge activist corporate actors.316 According to Forbes magazine \u201cin 2010 the \naverage early-stage round for AI or machine learning startups was about $4.8 \nmillion. However, in 2017, total funding increased to $11.7 million[,] . . . and \nin 2018 AI investment hit an all-time high with over $9.3 billion raised by AI \n \n311.  Virtualization and Cloud Computing Services, 85 Fed. Reg. 11363 (Feb. 27, \n2020) (notice of inquiry). \n312. CLIMATE CHANGE AI, https://www.climatechange.ai [https://perma.cc/KCD6-\n3T5X]. \n313. Id. \n314. Utilities have the opportunity for cost recovery of new technologies without \nrequiring the use of private fund, see supra Section III.C, whereas groups such as the National Science \nFoundation provide grants to \u201csix research institutes in order to advance AI research and create national \nnexus points for universities, federal agencies, industries and nonprofits.\u201d NSF Leads Federal Partners \nin Accelerating the Development of Transformational, AI-Powered Innovation, NAT\u2019L SCI. FOUND. (Oct. \n8, 2019), https://www.nsf.gov/news/news_summ.jsp?cntn_id=299329&org=NSF&from=news \n[https://perma.cc/J6SD-37SV]. \n315. Kathleen Walch, Is Venture Capital Investment in AI Excessive?, FORBES (Jan. 5, \n2020), https://www.forbes.com/sites/cognitiveworld/2020/01/05/is-venture-capital-investment-for-ai-\ncompanies-getting-out-of-control/#2271d5347e05 [https://perma.cc/QM2H-JPQ5].   \n316. Matt Egan, Secretive Energy Startup Backed by Bill Gates Achieves Solar \nBreakthrough, CNN: BUS. (Nov. 19, 2019), https://www.cnn.com/2019/11/19/business/heliogen-solar-\nenergy-bill-gates/index.html [https://perma.cc/62F7-K7HU] (discussing how Heliogen, a clean energy \nstartup backed by Bill Gates, has discovered a way to use artificial intelligence and a field of mirrors to \ncreate concentrated solar energy); Jeff St. John, Billionaire-Backed Breakthrough Energy Ventures \nMakes 7 More Investments, GREENTECH MEDIA (Oct. 1, 2018), \nhttps://www.greentechmedia.com/articles/read/billionaire-backed-breakthrough-energy-ventures-makes-\n7-more-investments [https://perma.cc/3DEN-2XJN]. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n935 \ncompanies.\u201d317 The largest investments in AI in the fourth quarter of 2018 \nranged from $100 million to $400 million.318 \nOne example of largescale private funding of clean-energy AI projects is \nBreakthrough Energy Ventures (BEV).319 BEV is funded by billionaires such \nas Bill Gates, Jeff Bezos, and Michael Bloomberg.320 BEV invests in \ncompanies such as Kobold Metals, which uses AI to accelerate the search for \nethical sources of metals needed for lithium-ion batteries.321 While funding \nmay be an issue, especially for smaller players, a significant advantage of \nnonutility investment in AI is freedom, as these private players do not have to \nendure the same rate- and investment-approval process that utilities do.322 \n3. Public Investment in Artificial Intelligence \nIn addition to private investment in AI for climate, public funding is \nimperative to its success. Governments at all levels can look for opportunities \nto invest in climate-related AI, as well as adjust government-procurement \npolicies that could harness its benefits. For example, over the last few years, the \nEU government has been proactive in generating funding for AI-related \nprojects.323 The U.S. government has also taken steps toward a more active role \nin AI use and development.324 Over the last ten years, the Department of \nEnergy has invested billions of dollars into new energy infrastructure that \ninterfaces with AI technology to improve energy efficiency.325 Public utilities \n \n317. Walch, supra note 315.  \n318. PWC, MONEYTREE REPORT 24 (Q4 2018), \nhttps://www.pwc.com/us/en/moneytree-report/moneytree-report-q4-2018.pdf [https://perma.cc/36MN-\n6KPP]. These investments were in the healthcare, scientific, security-software, and internet-software \nindustries. Id. \n319. St. John, supra note 316; see also Our Investment Portfolio, BREAKTHROUGH \nENERGY, https://www.b-t.energy/our-investment-portfolio [https://perma.cc/3GYA-TMQG] (listing \nBreakthrough Energy Venture\u2019s 27 investments). \n320. St. John, supra note 316. \n321. Akshat Rathi, Bill Gates-Led $1 Billion Fund Expands Its Portfolio of Startups \nFighting Climate Change, QUARTZ (Aug. 26, 2019), https://qz.com/1693546/breakthrough-energy-\nventures-expands-its-portfolio-to-19-startups [https://perma.cc/B449-GG7E]. \n322. See supra Section III.C.  \n323. EU to Boost Public and Private Investment in Artificial Intelligence, GOV\u2019T \nEUROPA (Apr. 25, 2018), https://www.governmenteuropa.eu/public-and-private-investment-in-artificial-\nintelligence/86871 [https://perma.cc/AM24-CLDT]. \n324. Exec. Order No. 13859, 50 Fed. Reg. 3967, 3967 (Feb. 11, 2019) (\u201cIt is the \npolicy of the United States Government to sustain and enhance the scientific, technological, and \neconomic leadership position of the United States in AI R&D and deployment through a coordinated \nFederal Government strategy, the American AI Initiative (Initiative) . . . .\u201d); Tom Krazit, Updated: \nWashington\u2019s Sen. Cantwell Prepping Bill Calling for AI Committee, GEEK WIRE (July 10, 2017), \nhttps://www.geekwire.com/2017/washingtons-sen-cantwell-reportedly-prepping-bill-calling-ai-\ncommittee [https://perma.cc/P32M-LN8V].  \n325. Franklin Wolfe, How Artificial Intelligence Will Revolutionize the Energy \nIndustry, SCI. NEWS (Aug. 28, 2017), http://sitn.hms.harvard.edu/flash/2017/artificial-intelligence-will-\nrevolutionize-energy-industry [https://perma.cc/7UXZ-V9M4].  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n936 \nalso are entering into deals with private companies to use their AI systems.326 \nSuch governmental involvement might have big payoffs in AI\u2019s future.327  \nD. Accountability, Safety, and Certification \nA last area of concern is accountability, safety, and certification. This \ninvolves at least two components. First, it demands caution to prevent entities \nfrom labeling everything as \u201cAI\u201d to qualify for funding, cost recovery, and \ngeneral acceptance. Second, processes need to be in place to ensure that AI is \nperforming as expected, which may demand more explainable AI. At present, it \nis extremely difficult to perform \u201cquality control\u201d on AI before we set it loose \non the power grid as no one can fully predict how it will perform.328 Each of \nthese concerns is addressed below. \nAvoiding AI-Washing. The first concern is that of \u201cAI-washing.\u201d Much \nlike whitewashing329 and greenwashing,330 it is imperative that AI not be used \nas a catchall for all matters involving data processing. AI has been around since \nthe 1950s, and yet it has come through its AI winter331 in full bloom. As AI has \nmoved from relative obscurity to common parlance,332 it now carries a certain \ncache that many can use to their advantage.333 Some suggest that people use the \n \n326. For a good example, see the Salt River Project, a Phoenix-based public power \nutility, that signed a contract to adopt ScienceLogic\u2019s SL1 platform to monitor all of its IT operations \nand applications. Maloney, supra note 156. \n327. Kriti Sharma, Artificial Intelligence Can Make America\u2019s Public Sector Great \nAgain, VOX (July 14, 2017), https://www.vox.com/2017/7/14/15968746/artificial-intelligence-ai-\nfederal-government-public-sector.  [https://perma.cc/CJ4A-YJ97] \n328. One approach may be to collect so much data that there are no \u201cout of sample \nscenarios,\u201d but until that point, it is difficult to know whether AI will not have an unintended result \nwhen it sees a condition for which it was not trained. Benjamin Cheatham et al., Confronting the Risks \nof Artificial Intelligence, MCKINSEY & CO. (Apr. 26, 2019), https://www.mckinsey.com/business-\nfunctions/mckinsey-analytics/our-insights/confronting-the-risks-of-artificial-intelligence \n[https://perma.cc/24S6-C5VL]. \n329. \u201c[W]hitewashing describes the habit of casting white actors to play non-white \ncharacters[,] . . . sometimes out of racial insensitivity, invariably to the detriment of people (and \nespecially actors) of colour.\u201d Steve Rose, \u2018The Idea That It\u2019s Good Business Is a Myth\u2019 \u2013 Why \nHollywood Whitewashing Has Become Toxic, GUARDIAN (Aug. 29, 2017), \nhttps://www.theguardian.com/film/2017/aug/29/the-idea-that-its-good-business-is-a-myth-why-\nhollywood-whitewashing-has-become-toxic [https://perma.cc/HZD7-79QZ]. \n330.  \u201cGreenwashing\u201d is the practice of making one\u2019s products seem more \nenvironmentally friendly than they really are. Koh v. S.C. Johnson & Son, Inc., No. C-09-00927, 2010 \nWL 94265, at *1 (N.D. Cal. Jan. 6, 2010); see Joseph W. Price II, Bradley G. Dowler & F. Clark \nJennings, Even Courts Are Going Green: How to Protect Yourself from Greenwashing Litigation, ARK. \nLAW., Winter 2013, at 22. \n331.  \u201cAn AI winter is a point at which research, investment, and funding for AI goes \ninto a period of decline and it\u2019s hard to get funding for research or other projects . . . .\u201d Kathleen Walch, \nAre We Heading for Another AI Winter Soon?, FORBES (Oct. 20, 2019), \nhttps://www.forbes.com/sites/cognitiveworld/2019/10/20/are-we-heading-for-another-ai-winter-\nsoon/#2e48964156d6 [https://perma.cc/P5TG-V4QZ]. \n332. See id. (discussing the increase in interest in AI in the past decade). \n333. See id. (\u201c[I]nvestment [in AI] is now quite diverse coming from enterprises, \ngovernments, academics, and venture capital . . . . Today, AI is being used all around the world to \naccomplish any number of tasks. We have put AI into cars, phones, advanced bots, and other technology \nthat we use every day.\u201d); What Are the Risks and Benefits of Artificial Intelligence?, FORBES (Aug. 2, \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n937 \nterm too generously, with some using it interchangeably with machine \nlearning.334 Others suggest that data analytics can accomplish much of what \nsome attribute to AI.335 Erroneously categorizing activities as AI could both \nminimize the legitimacy of actual AI applications and deny opportunities for \nactual and progressive AI advancements. Should entities label their activities as \n\u201cAI\u201d to qualify for certain advantages, AI could become a watered-down term. \nAnd should entities try to squeeze their activities into an \u201cAI\u201d box when that \ndesignation is questionable, it could cast doubt on valid AI. \nOne solution to this concern may be to elicit the assistance of the Federal \nTrade Commission (FTC). This federal agency is charged with \u201c[p]rotecting \nconsumers and competition by preventing anticompetitive, deceptive, and \nunfair business practices through law enforcement, advocacy, and education \nwithout unduly burdening legitimate business activity.\u201d336 The FTC could \npursue false or misleading AI claims,337 issue guidance informing companies \non how to avoid misleading labeling,338 and require support from those \nclaiming to use AI. The FTC has already begun to consider regulations \npreventing bias in algorithms339 and has regulated other areas where label \nmisuse is common.340 \nExplainable AI. The second concern affects the actual legitimacy of the \nalgorithm itself. If we are to base important policy decisions on the results of \nclimate AI, it is imperative that there is trust in the system. This quest for \nexplainable AI (XAI) is taking place across many dimensions, particularly \n \n2019), https://www.forbes.com/sites/quora/2019/08/02/what-are-the-risks-and-benefits-of-artificial-\nintelligence/#6e9c172234d8 [https://perma.cc/6L75-PBCZ]. \n334. As discussed earlier, machine learning is a subset of AI, not its equivalent. \nMJIMBA & SIBANDA, supra note 56, at 9 (\u201cOften, there is interchangeable use of these terms in daily \nlanguage. However, the terms differ although refer to related things.\u201d). \n335. Reavie, supra note 36.  \n336. About the FTC, FED. TRADE COMM\u2019N, https://www.ftc.gov/about-ftc \n[https://perma.cc/ML77-M3DY].  \n337. See FTC v. Truly Organic Inc., No. 1:19-cv-23832-RNS (S.D. Fla. Sept. 18, \n2019), https://www.ftc.gov/system/files/documents/cases/truly_organic_stipulated_final_order_0.pdf \n[https://perma.cc/8EXS-RAMA].  \n338. Such guidance could resemble the FTC\u2019s \u201cGreen Guides.\u201d See Green Guides, \nU.S. FED. TRADE COMM\u2019N, https://www.ftc.gov/news-events/media-resources/truth-advertising/green-\nguides [https://perma.cc/F36L-HJPN].  \n339. Andrew Smith, Using Artificial Intelligence and Algorithms, U.S. FED. TRADE \nCOMM\u2019N (Apr. 8, 2020), https://www.ftc.gov/news-events/blogs/business-blog/2020/04/using-artificial-\nintelligence-algorithms [https://perma.cc/P7PP-Y2NV].  \n340. See, e.g., Press Release, FTC, Federal Judge Approves FTC Order for Owners of \nCertain Volkswagen, Audi, and Porsche 3.0 Liter \u201cClean\u201d Diesels to Receive Refunds (May 17, 2017), \nhttps://www.ftc.gov/news-events/press-releases/2017/05/federal-judge-approves-ftc-order-owners-\ncertain-volkswagen-audi [https://perma.cc/PQ6L-DUYM] (\u201cclean diesel\u201d labels); Press Release, FTC, \nFTC Seeks Comments on Proposed Changes to the Energy Labeling Rule (Mar. 27, 2020), \nhttps://www.ftc.gov/news-events/press-releases/2020/03/ftc-seeks-comments-proposed-changes-energy-\nlabeling-rule [https://perma.cc/M9CN-XJR8] (energy-efficiency labeling); Press Release, FTC, Truly \nOrganic? The FTC Says No, Alleges Retailer Misled Consumers About Its Products (Sept. 19, 2019), \nhttps://www.ftc.gov/news-events/press-releases/2019/09/truly-organic-ftc-says-no-alleges-retailer-\nmisled-consumers-about [https://perma.cc/CV36-LG4D] (labeling of \u201corganic\u201d products).  \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nYale Journal on Regulation Vol. 37:890 2020 \n938 \nthose where civil rights and privacy are at issue.341 XAI is often defined as a \nmachine-learning field that aims to address how an AI system makes decisions, \nwanting the system to produce transparent explanations and reasons for \nthem.342 In short, it answers the \u201cwhy?\u201d question most humans ask to better \nunderstand decisions. \nAlthough explainability is imperative where AI is making decisions that \naffect an individual\u2019s freedom, explainability is important for electric-sector AI \nas well. As one national laboratory researcher stated, \u201cwe don\u2019t know exactly \nhow a neural network selects from the inputs and comes to the final decision \nbecause there is so much complicated processing to reach that decision.\u201d343 \nAnother researcher has suggested that \u201c[t]he need for trials to validate \nreliability is a major reason [machine learning] and AI have seen little \ndeployment\u201d in the electric-power sector.344 For AI in energy and other climate \nsectors to gain public and private acceptance, its transparency will need to be \nenhanced, allowing those who rely on it to better understand why the algorithm \nreached the predictions it did, remain open to criticism, disclose unknowns, and \nallow for remediation of troublesome training data. \nThis Part does not suggest these are the only tradeoffs. In fact, given the \nspace constraints of an Article, they barely scratch the surface of the depth of \nthe issues that will need to be addressed to more thoroughly use AI to address \nclimate challenges. But acknowledging and addressing the environmental, \nprivacy, investment, and accountability implications of climate-related AI are a \ngood starting place for further discussion. \nConclusion \nClimate change continues to plague civilization. Despite an increasing \nawareness of the problem, humanity has yet to collectively take the drastic \nsteps needed to curb our carbon emissions. As the world continues to eat away \nat the carbon budget set to keep us on course for a 1.5\u00b0C-degree warming of the \nEarth, we must continue to engage in a multifaceted strategy. AI needs to \nbecome part of that strategy. This Article only addresses one of the many \nsectors that require transformation, but similar analysis of the tradeoffs of AI\u2019s \n \n341. See, e.g., The General Data Protection Regulation 2016/679, art. 22, 2016 O.J. (L \n119) 46; Danielle K. Citron, Technological Due Process, 85 WASH. U. L. REV. 1249, 1278-300 (2008); \nTirthajyoti Sarkar, Google\u2019s New \u201cExplainable AI\u201d (xAI) Service, MEDIUM: TOWARDS DATA SCI. (Nov. \n25, 2019), https://towardsdatascience.com/googles-new-explainable-ai-xai-service-83a7bc823773 \n[https://perma.cc/A953-J8YL]. \n342. See Margot Kaminski, The Right to Explanation, Explained, 34 BERKELEY TECH. \nL. REV. 189, 190-92  (2019); Ron Schmelzer, Understanding Explainable AI, FORBES (July 23, 2019), \nhttps://www.forbes.com/sites/cognitiveworld/2019/07/23/understanding-explainable-ai/#108d12567c9e \n[https://perma.cc/7SG5-MAMX]. \n343. Trabish, supra note 6. \n344. Id. Similarly, users will want to understand the consequences of AI, meaning it is \nimportant to \u201cdefine the adjustable autonomy of such systems; to what extent should the agent \nautomatically decide to shift devices to run at certain times, and when should it ask for confirmation \nfrom the user.\u201d Ramchurn, supra note 98. \n09. STEIN ARTICLE. FINAL (DO NOT DELETE) 7/30/2020  10:02 AM \nArtificial Intelligence and Climate Change \n939 \nbenefits and limitations could be had with respect to the agricultural, \ncommercial, residential, and transportation sectors. It is imperative that the \nlimitations of AI be acknowledged and tempered. Furthermore, recognizing \nAI\u2019s limitations should not result in excluding its application where appropriate \nto help address the complicated data challenges associated with climate change. \nAs a federal judge has noted, \u201c[w]hat sets this harm apart from all others is not \njust its magnitude, but its irreversibility.\u201d345 Climate change is too important \nnot to try. \n \n345. Juliana v. United States, 947 F.3d 1159, 1177 (9th Cir. 2020) (Staton, J., \ndissenting). \n",
        "id": 96041778,
        "identifiers": [
          {
            "identifier": "344966554",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:digitalcommons.law.yale.edu:yjreg-1565",
            "type": "OAI_ID"
          }
        ],
        "title": "Artificial Intelligence and Climate Change",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:digitalcommons.law.yale.edu:yjreg-1565"
        ],
        "publishedDate": "2020-01-01T08:00:00",
        "publisher": "Yale Law School Legal Scholarship Repository",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "https://digitalcommons.law.yale.edu/cgi/viewcontent.cgi?article=1565&amp;context=yjreg"
        ],
        "updatedDate": "2021-08-22T03:20:56",
        "yearPublished": 2020,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "https://core.ac.uk/download/344966554.pdf"
          },
          {
            "type": "reader",
            "url": "https://core.ac.uk/reader/344966554"
          },
          {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/344966554/large"
          },
          {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/344966554/large"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/96041778"
          }
        ]
      },
      "relevance_score": 0.0375,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.375,
          "dimension_weight": 0.1,
          "weighted_score": 0.0375,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2020 (Norm. Score: 0.6)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_primary_4",
      "dynamic_step": 0,
      "core_id": 96041778,
      "doi": null
    },
    {
      "original_data": {
        "acceptedDate": "2014-07-25T00:00:00",
        "arxivId": null,
        "authors": [
          {
            "name": "Bhattacharya, S."
          },
          {
            "name": "McLernon, D.J."
          },
          {
            "name": "Mol, B.W.J."
          },
          {
            "name": "Steyerberg, E.W."
          },
          {
            "name": "te Velde, E.R."
          }
        ],
        "citationCount": 0,
        "contributors": [
          "University of Aberdeen.Clinical Medicine",
          "University of Aberdeen.Institute of Applied Health Sciences",
          "University of Aberdeen.Public Health, Health Services and Primary Care",
          "University of Aberdeen.Data Safe Haven",
          "University of Aberdeen.Other Applied Health Sciences",
          "University of Aberdeen.Medical Statistics"
        ],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/29465852",
          "https://api.core.ac.uk/v3/outputs/566811103",
          "https://api.core.ac.uk/v3/outputs/79083322",
          "https://api.core.ac.uk/v3/outputs/209836415",
          "https://api.core.ac.uk/v3/outputs/567379233",
          "https://api.core.ac.uk/v3/outputs/444043851"
        ],
        "createdDate": "2015-09-14T19:20:23",
        "dataProviders": [
          {
            "id": 1,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/1",
            "logo": "https://api.core.ac.uk/data-providers/1/logo"
          },
          {
            "id": 4786,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/4786",
            "logo": "https://api.core.ac.uk/data-providers/4786/logo"
          },
          {
            "id": 83,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/83",
            "logo": "https://api.core.ac.uk/data-providers/83/logo"
          },
          {
            "id": 500,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/500",
            "logo": "https://api.core.ac.uk/data-providers/500/logo"
          },
          {
            "id": 22326,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/22326",
            "logo": "https://api.core.ac.uk/data-providers/22326/logo"
          }
        ],
        "depositedDate": "2014-07-24T00:00:00",
        "abstract": "Funding This work was supported by a Chief Scientist Office Postdoctoral Training Fellowship in Health Services Research and Health of the Public Research (Ref PDF/12/06). The views expressed in this paper represent the views of the authors and not necessarily the views of the funding body.Peer reviewedPostprin",
        "documentType": "research",
        "doi": "10.1093/humrep/deu173",
        "downloadUrl": "https://core.ac.uk/download/29465852.pdf",
        "fieldOfStudy": null,
        "fullText": "1 \n \nClinical prediction models to inform individualized decision making in subfertile couples: a 1 \nstratified medicine approach 2 \nDJ McLernonP1P, ER te VeldeP2P, EW SteyerbergP2P, BWJ MolP3P, S BhattacharyaP1 3 \nP\n1\nPDivision of Applied Health Sciences, University of Aberdeen, Aberdeen, UK; P2PDepartment of Public 4 \nHealth, Erasmus MC - University Medical Centre Rotterdam, Rotterdam, The Netherlands; 5 \nP\n3\nPDepartment of Obstetrics and Gynaecology, Academic Medical Centre, Amsterdam, The 6 \nNetherlands. 7 \n 8 \nUCorresponding authorU:  9 \nDavid J. McLernon, Medical Statistics Team, Division of Applied Health Sciences, University of 10 \nAberdeen, Polwarth Building, Foresterhill, Aberdeen, UK, AB25 2ZD. 11 \nTel: +441224437152, Fax: +441224437285 12 \nEmail: d.mclernon@abdn.ac.uk 13 \nURunning titleU: Individualized decision making in subfertility 14 \nUWord CountU: 4139 15 \n  16 \n \n \n2 \n \nAbstract 17 \nInfertility is defined as failure to conceive after one year of unprotected intercourse. This 18 \ndichotomisation into fertile versus infertile, based on lack of conception over 12 month period, is 19 \nfundamentally flawed. Time to conception is strongly influenced by factors such as female age and 20 \nwhilst a minority of couples have absolute infertility (sterility), many are able to conceive without 21 \nintervention but may take longer to do so, reflecting the degree of subfertility. This natural 22 \nvariability in time to conception means that subfertility reflects a prognosis rather than a diagnosis. 23 \nCurrent clinical prediction models in fertility only provide individualised estimates of the probability 24 \nof either treatment independent pregnancy or treatment dependent pregnancy, but do not take 25 \naccount of both.  Together, prognostic factors which are able to predict natural pregnancy and 26 \npredictive factors of response to treatment would be required to estimate the absolute increase in 27 \npregnancy chances with treatment. This stratified medicine approach would be appropriate for 28 \nfacilitating personalised decision-making concerning whether or not to treat subfertile patients.  29 \nPublished models are thus far of little value for decisions regarding when to initiate treatment in 30 \npatients who undergo a period of, ultimately unsuccessful, expectant management. We submit that 31 \na dynamic prediction approach, which estimates the change in subfertility prognosis over the course 32 \nof follow-up, would be ideally suited to inform when the commencement of treatment would be 33 \nmost beneficial in those undergoing expectant management. Further research needs to be 34 \nundertaken to identify treatment predictive factors and to identify or create databases to allow 35 \nthese approaches to be explored. In the interim, the most feasible approach is to use a combination 36 \nof previously published clinical prediction models.  37 \n \n \n3 \n \nIntroduction   38 \nInfertility is defined as \u201ca disease of the reproductive system defined by the failure to achieve a 39 \nclinical pregnancy after 12 months or more of regular unprotected sexual intercourse\u201d according to 40 \nthe World Health Organisation (WHO) and International Committee for Monitoring Assisted 41 \nReproductive Technology (ICMART) (Zegers-Hochschild et al., 2009). Absence of pregnancy within 42 \nthis time-period is interpreted as evidence of sterility by many couples, who then request immediate 43 \ntreatment. 44 \nIn fact, the probability of conceiving is highly variable (te Velde et al. 2000) and genuine unresolved 45 \ninfertility or sterility, occurs in a minority (3\u20135%) of all couples (Greenhall and Vessey 1990). 41TAs 46 \ncouples who are more \u201cfertile\u201d41T tend to conceive early, the length of time couples have been 47 \nunsuccessful at conceiving reflects the degree of subfertility. The term \u201cinfertility\u201d is often used 48 \ninterchangeably with \u201csubfertility\u201d ((Gnoth et al. 2005, Gurunath et al. 2011, Habbema et al. 2004)). 49 \nHowever, in this article we define as subfertile those couples in whom routine investigations have 50 \nnot been able to identify any absolute barriers to conception such as blocked Fallopian tubes, 51 \nanovulation or azoospermia. Many of these couples are advised to undergo a period of expectant 52 \nmanagement, meaning that they continue trying to conceive naturally for a specified period of time 53 \nbefore being offered treatment. 54 \nData from non-contracepting populations (Bongaarts 1975) show that increase in the duration of 55 \nunsuccessful unprotected intercourse is associated with decreasing chances of pregnancy. However, 56 \nthe definition of infertility as a failure to conceive within a year represents an oversimplification, as 57 \nmany couples in this group will conceive beyond one year (Bongaarts 1975, Snick et al. 1997). The 58 \nonly certain way of \u2018diagnosing\u2019 absolute infertility in subfertile couples, i.e. establishing with 59 \ncertainty that a couple is sterile, is lack of conception in women at the end of reproductive life. By 60 \nthen of course it is too late to rectify the situation by medical means. Thus, in order to be a clinically 61 \nuseful entity, subfertility needs to reflect the prognosis of a couple in terms of their ability to 62 \n \n \n4 \n \nconceive unaided. Such an approach recognises the fact that apart from duration, a woman\u2019s ability 63 \nto conceive also declines with her age and depends on many other factors that vary the chances of 64 \nconception such as frequency of intercourse, semen quality and pelvic pathology (Evers 2002).  65 \nHaving acknowledged that subfertility represents a prognosis rather than an absolute diagnosis, it is 66 \nworth considering the best way of assessing the chances of pregnancy for the purposes of initiating 67 \ninvestigations and treatment. One option, which allows consideration of time on a continuous scale 68 \n(rather than dichotomously) and a couple\u2019s risk factors for conception, is to use appropriately 69 \ndeveloped and validated clinical prediction models. Many of these already exist in fertility and they 70 \neither predict the chances of pregnancy following treatment or without treatment, but not both 71 \n(Leushuis et al. 2009). However, a method of taking both groups into account to estimate the 72 \nadditional chances of pregnancy following treatment could allow clinicians to identify those who 73 \nwould benefit from it. For example, an absolute increase of 5% in the chance of pregnancy following 74 \nin vitro fertilization (IVF) compared to no treatment, might be important to a woman aged 38 whose 75 \nnatural chances of pregnancy have declined with age, but not to a woman aged 28 whose natural 76 \nchances are still relatively high. 77 \nIn this paper we describe the limitations of current clinical prediction models for subfertility and 78 \nsubsequently aim to explore the advancement of such models to address two key questions in 79 \nfertility care: firstly, how should clinicians discriminate between those who need active fertility 80 \ntreatment versus those who do not? Secondly, given that subfertility prognosis changes over time, 81 \nwhen should those on expectant management be offered active treatment? 82 \n 83 \nExisting clinical prediction models in subfertility 84 \nCritical for the management of a subfertile couple prior to initiation of treatment is knowledge of 85 \ntheir subfertility prognosis i.e. chances of spontaneous conception. As mentioned earlier, a way of 86 \n \n \n5 \n \nestimating subfertility prognosis is through clinical prediction modelling. A time-to-event statistical 87 \nmodel (such as the Cox proportional hazards model) is a good method of predicting the chances of a 88 \nbinary outcome, such as conception (versus no conception), over a period of time. Such models 89 \nadjust for prognostic factors, which are clinical or biological characteristics (such as female age and 90 \nduration of infertility) that are associated with a clinical outcome (such as spontaneous pregnancy) 91 \nin an untreated patient (Italiano 2011). Prognostic factors for subfertility can be obtained from the 92 \nmedical literature, clinical opinion or further research. Table 1 contains a list of known prognostic 93 \nfactors of spontaneous pregnancy from published models (Leushuis et al. 2009). The recently 94 \npublished Prognosis Research Strategy (PROGRESS) articles specify a framework of four interlinked 95 \nthemes for prognostic research. They recommend that large, prospective, registered prognostic 96 \nfactor studies with appropriate sample size and statistical analyses are required in order to find new 97 \nprognostic factors that can predict an outcome (Hemingway et al. 2013, Hingorani et al. 2013, Riley 98 \net al. 2013, Steyerberg et al. 2013). 99 \nA systematic review of clinical prediction models in reproductive medicine identified 29 prediction 100 \nmodels that predicted spontaneous pregnancy (n=9) or successful intrauterine insemination (IUI, 101 \nn=3) or IVF  n=17) (Leushuis et al. 2009). Of these 29 models, only eight were externally validated, 102 \nthree of which showed adequate performance (Custers et al. 2007, Hunault et al. 2004, Smeenk et 103 \nal. 2000, Steures et al. 2006, Steures et al. 2004, Templeton et al. 1996, van der Steeg et al. 2007). 104 \nAssessment of the predictive ability and external validation of a prediction model is essential if it is 105 \nto be used to facilitate clinical practice (Collins 2005, Coppus et al. 2009). Aspects to evaluate include 106 \ndiscrimination (how good a model is distinguishing between patients who do and do not become 107 \npregnant) and calibration (agreement between the probability estimate from the prediction model 108 \nand observed outcome frequencies) (Steyerberg 2009). 109 \nThe Hunault model, synthesised from three previous models based on three prospective databases 110 \nof subfertile women attending a Dutch University hospital, a Dutch general hospital and eleven 111 \n \n \n6 \n \nCanadian University Hospitals, was found to predict spontaneous pregnancy leading to live birth 112 \nreasonably well (Hunault et al. 2004). It had poor discriminatory ability, which is generally the case 113 \nwith prediction modelling in subfertile couples who tend to be rather homogeneous in terms of 114 \nclinical characteristics (Coppus et al. 2009), but calibrated well when applied to external cohorts 115 \n(Hunault et al. 2005, van der Steeg et al. 2007). 116 \nTwo other models, which showed acceptable performance in the Leushuis et al (2009) review, were 117 \nthe Steures et al (2006) model which predicts live birth following IUI, and the Templeton et al (1996) 118 \nmodel which predicts live birth following IVF. Both of these models also had poor discriminatory 119 \nability (Coppus et al. 2009, Smeenk et al. 2007). However, the Templeton model performs 120 \nreasonably well after adjusting for improved IVF success rates over time (te Velde et al. 2014). Since 121 \nthe Leushuis review, a model developed using the Human Fertilisation and Embryological Authority 122 \n(HFEA) database of all IVF treatments in the UK has been published (Nelson and Lawlor 2011) but 123 \nperformed no better than the Templeton model (te Velde et al. 2014). 124 \nA prognostic model could be used to make risk-based decisions in clinical practice. This would 125 \ninvolve calculating the absolute chance of spontaneous pregnancy occurring within a pre-specified 126 \ntime period, e.g. one year, for a given individual (see Figure 1, Model 1a). Decisions regarding 127 \nwhether or not to treat can then be made using some pre-specified clinically agreed chance cut-off. 128 \nFor example, the creators of the Hunault model considered couples with <20% chance of 129 \nspontaneous pregnancy as a poor prognosis group who should undergo immediate treatment 130 \n(Hunault et al. 2004). Those with >40% chance were labelled as having a high chance of spontaneous 131 \npregnancy and the article suggested that these couples should be encouraged to wait for another 132 \nyear. Those in the middle group of 20\u201340% chance should be advised in such a manner as to balance 133 \nthe probability of pregnancy against the risks from fertility treatment. 134 \nHowever, using probabilities from a model that predicts treatment independent pregnancy to make 135 \ntreatment decisions does not take into account the chance that treatment may not be effective in 136 \n \n \n7 \n \nparticular women. For example, being led solely by the above model cut-offs, a woman with a 15% 137 \nchance of pregnancy would undergo immediate treatment. However, depending on the woman\u2019s 138 \nspecific characteristics, her chance of pregnancy following treatment may be no greater, or, it may 139 \nbe substantially greater. Conversely, models that predict pregnancy following treatment do not tell 140 \nus whether the woman\u2019s absolute chance of pregnancy would have been any lower without 141 \ntreatment, and indeed how much lower (Figure 1, Model 1b). The best option would be to use a 142 \ncombined dataset, ideally from randomized controlled trial (RCT) data, including these two groups of 143 \nwomen in order to model the additional benefit of treatment over no treatment. This can be made 144 \npossible using a stratified medicine approach. 145 \n 146 \nAbsolute versus relative risk 147 \nBefore we consider stratified medicine it is important to define absolute and relative risk.  Absolute 148 \nrisk refers to the chance that a patient will have some outcome of interest (for example, a treated 149 \npatient has a 10% risk of mortality and a control patient has a 12.5% risk of mortality). The relative 150 \nrisk refers to the chance of the outcome for one group of patients compared with another (in the 151 \ngiven example the relative risk of mortality decreases by 20% for the treatment group compared to 152 \nthe control group). The word \u2018risk\u2019 is used since the outcome is often unfavourable. However, since 153 \npregnancy is a favourable outcome the term \u2018risk\u2019 is generally replaced with \u2018chance\u2019. If the relative 154 \neffect of treatment is constant for all patients, then the absolute benefit of treatment only increases 155 \nin relation to the baseline pregnancy chances. For example, if statins have a constant relative risk 156 \nreduction for all, then the absolute benefit is highest for those at highest risk of cardiovascular 157 \ndisease (LaRosa et al., 1999). 158 \n 159 \nTo treat or not to treat? - A stratified medicine approach 160 \n \n \n8 \n \nStratified medicine has been defined as \u2018the targeting of treatments (including pharmaceutical and 161 \nnon-pharmaceutical interventions) according to the biological or risk characteristics shared by 162 \nsubgroups of patients\u2019 (Hingorani et al. 2013). A clinician will use such an approach where the 163 \nrelative effect of treatment is believed to be inconsistent across patients. This means one or more 164 \npatient characteristics are associated with changes in the relative effect of treatment. Such 165 \ncharacteristics are called predictive factors of treatment response (Hingorani et al. 2013). The 166 \nstratified medicine approach allows targeting of therapy based on the combination of subfertility 167 \nprognostic factors and such treatment predictive factors, which increase the response to treatment 168 \nin relation to no treatment. This enables decisions to be made regarding who should receive such 169 \ntreatment. For example, in non-small cell lung cancer, the response of the disease to chemotherapy 170 \nis quite poor but there are therapy agents, gefitinib and erlotinib, which optimise therapy by being 171 \neffective only in patients whose tumours harbour specific epidermal growth factor receptor profiles 172 \n(Hall 2013). 173 \nIn the stratified medicine approach the relative effect of treatment is allowed to vary across patients 174 \naccording to their treatment predictive factors. The relative increase in pregnancy chances for 175 \ntreatment in relation to no treatment has limited value since it does not tell us from what baseline 176 \nchance (i.e. chance of pregnancy without treatment) the increase occurs. Stratified medicine 177 \nconsiders the absolute rather than the relative increase in chance of pregnancy with treatment since 178 \nthe former provides the more relevant individualised prediction of successful treatment to guide 179 \ndecision-making. 180 \nSome thought needs to be given to identifying factors that predict differential treatment response. 181 \nIn fertility, the success of treatment, such as IVF, is heavily influenced by factors such as female age 182 \n(van Loendersloot et al. 2010). As age is also a subfertility prognostic factor, increasing age may vary 183 \nthe additional effect of treatment over expectant management on chances of pregnancy. In other 184 \nwords, prognostic factors such as age, which affect the chance of spontaneous pregnancy and 185 \n \n \n9 \n \nsuccess of IVF may also be treatment predictive factors which determine the relative effectiveness of 186 \ntreatment (Hingorani et al. 2013). Of interest is the difference in these two relative effects. 187 \nMoreover, it is likely that an older woman whose chance of pregnancy with treatment is expected to 188 \nbe better than without, will require a more rapid resolution involving assisted reproduction, whilst a 189 \nyounger patient has sufficient time to undergo a series of less invasive (and cheaper) alternatives 190 \nfirst. We know that as female age increases the ability of assisted reproduction technology to make 191 \nup for all births lost by the natural decline of fertility decreases (Leridon 2004). Nevertheless, the 192 \nabsolute (and relative) benefit of treatment may be larger in older women than for younger women.  193 \nThere may also exist factors that are not necessarily prognostic that may predict the treatment 194 \nresponse. For example, in women with different tubal factor subfertility problems those with 195 \nhydrosalpinges had a poorer IVF pregnancy rate, which can be improved by salpingectomy (Johnson 196 \net al. 2011). Within such a cohort of women, subfertility prognosis would not be expected to vary 197 \nbetween different tubal factor diagnoses, but type of tubal factor subfertility is clearly a treatment 198 \npredictive factor. 199 \n 200 \nIssues to consider for a stratified approach 201 \nA stratified model can be developed from: i. one data source that has compared treated versus 202 \nuntreated patient outcomes; or ii. two separate sources \u2013 one to model subfertility prognosis and 203 \none to predict outcome following treatment. We will discuss these in turn. 204 \nOne data source, one model 205 \nThis involves using one dataset, preferably from an RCT, comparing treatment with no treatment. 206 \nOne can then examine the effect of prognostic factors for subfertility (main effects in a statistical 207 \nmodel) (Figure 1, Model 2a) together with treatment predictive factors (interaction terms in a 208 \nstatistical model) (Figure 1, Model 2b). 209 \n \n \n10 \n \nWe could not find any examples of a published stratified medicine analysis for fertility using 210 \ntreatment predictive factors. However, a recent study attempted the secondary analysis of 211 \nindividual patient data from RCTs to determine whether a patient\u2019s prognostic profile, based on a 212 \nscore from the Hunault model, influenced the effectiveness of different fertility treatments (van den 213 \nBoogaard et al. 2013). Investigating how the prognostic score from a model affects the treatment 214 \nresponse, rather than the individual treatment predictive factors which made up the score, is called 215 \na risk-stratified analysis (Kent DM 2007). 216 \nDue to heterogeneity in the treatment protocols of the included trials in the Van den Boogaard study 217 \nit was not possible to combine the individual patient data from each trial to conduct a meta-analysis. 218 \nThe modelling was performed in each trial separately. The study found no effect of prognostic 219 \nprofile on the effectiveness of different clinical strategies, including expectant management. This 220 \nhighlights the need for large RCTs with more heterogeneity in patient characteristics if they are to be 221 \nused for secondary analyses involving modelling (Farooq et al. 2013). However, this is an expensive, 222 \nchallenging and lengthy process. 223 \nAlthough large RCTs are the preference for stratified medicine research, the use of observational 224 \ndata containing treated and non-treated women is an alternative. Such data usually contain a larger 225 \nand more varied sample of patients than an RCT. An observational design requires high quality 226 \nelectronic healthcare data that can be record-linked in order to obtain an accurate history of the 227 \npatient\u2019s journey (Hemingway et al., 2013). However, observational data can suffer from serious 228 \nselection bias issues, and whilst there are methods available that may be able to account for some of 229 \nthese, the results of any analyses should be interpreted with caution. 230 \n 231 \nTwo separate data sources, two models 232 \n \n \n11 \n \nIn the absence of RCTs or observational databases containing both treated and non-treated women, 233 \na third approach is possible. This can use either previously published models \u2013 e.g. a prognostic 234 \nmodel for spontaneous pregnancy, such as Hunault, and a model predicting treatment dependent 235 \npregnancy, such as the Nelson and Lawlor IVF model \u2013 or develop new models for each outcome 236 \nusing two separate data sources. The advantage of the former method is that most of the work has 237 \nalready been done and it is much less expensive than setting up a prospective, or even a 238 \nretrospective, database from scratch. The difference in the absolute probability of success from both 239 \nmodels would give the absolute benefit of treatment (Figure 1, Models 1a and 1b combined). 240 \nHowever, a key problem with this method is the comparability of cohorts. The limitations of 241 \ncombining models developed from two different cohorts were highlighted in the recently updated 242 \nNational Institute of Clinical Excellence (NICE) clinical guideline on assessment and treatment for 243 \npeople with fertility problems (National Collaborating Centre for Women's and Children's Health 244 \n2013). A health economic analysis to compare the cost-effectiveness of different treatment 245 \nstrategies over a woman\u2019s reproductive life used the Hunault and the Nelson and Lawlor models to 246 \ninform the cost-effectiveness model with probabilities of cumulative live birth in women following 247 \nspontaneous pregnancy and IVF dependent pregnancy respectively. However, as the guideline 248 \nacknowledges, there were major limitations associated with this approach. For example, the Hunault 249 \nmodel was developed using a cohort of subfertile women, which excluded those who would not be 250 \nexpected to conceive naturally, meaning the severity of subfertility may not be as high as that in 251 \nwomen referred for IVF (the cohort used for the Nelson and Lawlor models). Further, the maximum 252 \nage of women used to develop the Hunault model was less than the maximum age included in the 253 \nNICE cost-effectiveness model, which may result in an overestimate of the probability of 254 \nspontaneous live birth in older aged women. However, if separate cohorts exist, which contain 255 \npatients with very similar characteristics, who undergo either expectant management or treatment, 256 \nthen previous models can be adapted to fit such data or new models can be developed. If such 257 \n \n \n12 \n \ncohorts are available then this two-model approach would be equivalent to using the one model 258 \napproach with statistical interaction terms between treatment and the treatment predictive factors. 259 \n 260 \nWhen to treat? \u2013 A dynamic prediction approach 261 \nAnother major aspect of clinical decision-making concerns the length of time couples should be 262 \nadvised to continue trying to conceive naturally before treatment should be offered. In order to do 263 \nthis we need a dynamic approach where we constantly assess the change in subfertility prognosis at 264 \ndifferent points in the future. One method is dynamic prediction modelling (van Houwelingen and 265 \nPutter 2012). This involves fitting multiple time to event models from sequential equally spaced time 266 \npoints to predict natural pregnancy over, say, the following year (see Figure 2). This process enables 267 \none to determine the impact of delayed treatment on the predicted probability of pregnancy at 268 \ndifferent points in time. This is not the same as using, for example the Hunault model, to obtain the 269 \nupdated chances of pregnancy as time goes on by iteratively updating the same woman\u2019s prognostic 270 \nfactors for subfertility at baseline (i.e. when the cause of infertility is established). Rather, as time 271 \nprogresses the more fertile couples are excluded from the cohort due to pregnancy.  Therefore 272 \nafter, for example, 6 months the cohort has reduced in size and is less fertile on average than the full 273 \nsized cohort on which the model was originally based.  Furthermore, since the original follow-up 274 \nperiod has been extended by 6 months (i.e. follow-up now ends 18 months from baseline as 275 \nopposed to 12 months) some of the women may have conceived during this period. Thus, different 276 \nmodel estimates will be obtained. 277 \nDynamic prediction could be used to advise those patients who are found to have a high chance of 278 \nconceiving spontaneously at their first visit on when to return for treatment if their attempts are 279 \nunsuccessful e.g. when their absolute chance of pregnancy dips below some pre-specified threshold. 280 \n \n \n13 \n \nIt could also be used to make decisions regarding the immediate treatment for couples who have a 281 \nlow probability of pregnancy at their initial visit, which will decline further with each passing month. 282 \nDynamic prediction should be used with the stratified medicine approach in order to estimate the 283 \nchange in the absolute benefit of treatment over time. In a couple with a good subfertility prognosis 284 \ninitially advised expectant management, this approach could be used to decide when in the future 285 \nthe absolute benefit of treatment is likely to trump their chance of spontaneous pregnancy such that 286 \nthe couple should be advised to return for treatment. 287 \nDynamic prediction requires a cohort of patients with a sufficient length of follow-up to enable 288 \nmodelling at different time points. For this reason, existing observational datasets would be more 289 \nsuitable than an RCT. Finally, as for all clinical prediction modelling, the key steps involved in 290 \ndevelopment and validation should be considered. The latter have been highlighted in the 291 \nPROGRESS series (Steyerberg et al. 2013). 292 \n 293 \nPractical recommendations 294 \nGiven the complexities of the above approach to individualised-decision making in subfertility 295 \ntreatment, it is worth considering some practical guidelines for clinical practice and research. Firstly, 296 \nthe decision whether to treat a subfertile patient requires careful consideration of her background 297 \nchance of spontaneous pregnancy and her predicted response to treatment. The former is 298 \ninfluenced by prognostic factors and the latter by treatment predictive factors. Currently, in the 299 \nNetherlands, an online prediction tool called \u2018Freya\u2019, based on the Hunault model, is used in clinical 300 \npractice to make treatment decisions based on the probability of spontaneous ongoing pregnancy 301 \nwithin the next 12 months (Hunault et al. 2004). However, clinicians should be aware that this model 302 \ndoes not provide an estimate of response to treatment. Currently, the only way to do this is to use a 303 \ncombination of existing models from the literature, such as the Hunault model and the Nelson and 304 \n \n \n14 \n \nLawlor model, which can be used to predict the chance of live birth following IVF. As mentioned 305 \nearlier, this approach was used in a cost-effectiveness analysis of IVF relative to expectant 306 \nmanagement by NICE who acknowledge the shortcomings of this approach (National Collaborating 307 \nCentre for Women's and Children's Health 2013). 308 \n 309 \nSecondly, clinicians looking after couples with unexplained subfertility need to make a conscious 310 \ndecision as to when treatment should be offered. Depending on patient characteristics, such as 311 \nfemale age, the live birth rate following one or more episodes of treatment will vary compared to 312 \nwhat might be expected without treatment. Thus, it may be better to treat some women straight 313 \naway after a diagnosis has been made, whilst in others a period of expectant management may lead 314 \nto comparable or better live birth rates without the expense and invasiveness of active treatment. 315 \nFrom the NICE analysis using the combined models, a 34 year old woman with two years of 316 \nunexplained infertility is predicted to have a treatment independent live birth rate of 20% (National 317 \nCollaborating Centre for Women's and Children's Health 2013) compared to 40% after one cycle of 318 \nIVF. The same model predicts a live birth rate of 55% without treatment versus 70% following three 319 \ncomplete cycles of IVF over the next 11 years, suggesting that it would seem advantageous to offer 320 \nIVF treatment. 321 \nFinally, output from clinical predictive models need to be interpreted in the context of the individual 322 \ncircumstances of each couple. For fertility care to be genuinely patient centred, treatment decisions 323 \nshould involve couples themselves and accommodate their personal values and preferences (Dancet 324 \net al. 2011). 325 \n 326 \nConclusions 327 \n \n \n15 \n \nThe current one-year definition of infertility should be used as a trigger for referral to the fertility 328 \nclinic in order to initiate investigations and estimate prognosis \u2013 but not necessarily to begin 329 \ntreatment in all. 330 \nCurrent prognostic models in reproductive medicine are reasonably good at predicting the chances 331 \nof pregnancy in either women who are treated or those who are not. As none of the existing models 332 \ninclude both groups, predicting the marginal benefit of treatment versus no treatment is less 333 \naccurate. 334 \nWe advise the stratified medicine approach to identify those who actually benefit more from fertility 335 \ntreatment based on their prognostic and treatment predictive factors. Subsequently, the added 336 \nbenefit of treatment needs to be considered in context, for example in relation to the age of the 337 \nwoman. We also advise the dynamic prediction approach to estimate the patient\u2019s changing 338 \nsubfertility prognosis over time which could inform the decision about when to treat. 339 \nFurther research needs to be undertaken to identify treatment predictive factors and to identify or 340 \ncreate databases to allow these approaches to be explored. RCT data are preferred, but are the most 341 \nchallenging and expensive choice. In the interim, the most feasible option is to use output from a 342 \ncombination of previously published clinical prediction models, whilst acknowledging the specific 343 \nclinical circumstances of each couple and their preferences. 344 \n 345 \nAuthor\u2019s roles 346 \nDJM, SB and EWS proposed the concept.  DJM drafted the paper and all named authors contributed 347 \ncontent and commented on the draft.   348 \n 349 \nFunding 350 \n \n \n16 \n \nThis work was supported by a Chief Scientist Office Postdoctoral Training Fellowship in Health 351 \nServices Research and Health of the Public Research (Ref PDF/12/06). 352 \n 353 \nConflict of interest 354 \nNone of the authors declare any conflict of interest. 355 \n 356 \nReferences  357 \nBongaarts J. A Method for the Estimation of Fecundability. Demography 1975;12:645-660.  358 \nCollins JA. Associate editor\u2019s commentary: Mathematical modelling and clinical prediction. Hum 359 \nReprod 2005;20:2932-2934.  360 \nCoppus SFPJ, van der Veen F, Opmeer BC, Mol BWJ and Bossuyt PMM. Evaluating prediction models 361 \nin reproductive medicine. Hum Reprod 2009;24:1774-1778.  362 \nCusters IM, Steures P, van der Steeg JW, van Dessel TJHM, Bernardus RE, Bourdrez P, Koks CAM, 363 \nRiedijk WJ, Burggraaff JM, van der Veen F et al. External validation of a prediction model for an 364 \nongoing pregnancy after intrauterine insemination. Fertil Steril 2007;88:425-431.  365 \nDancet EAF, Van Empel IWH, Rober P, Nelen WLDM, Kremer JAM, D'Hooghe TM. Patient-centred 366 \ninfertility care: a qualitative study to listen to the patient's voice. Hum Reprod 2011;26:827-833. 367 \nEvers J. Female subfertility. The Lancet 2002:360:151-159.  368 \nFarooq V, van Klaveren D, Steyerberg EW, Meliga E, Vergouwe Y, Chieffo A, Kappetein AP, Colombo 369 \nA, Holmes Jr DR, Mack M et al. Anatomical and clinical characteristics to guide decision making 370 \n \n \n17 \n \nbetween coronary artery bypass surgery and percutaneous coronary intervention for individual 371 \npatients: development and validation of SYNTAX score II. The Lancet 2013:381:639-650.  372 \nGnoth C, Godehardt E, Frank-Herrmann P, Friol K, Tigges J and Freundl G. Definition and prevalence 373 \nof subfertility and infertility. Human Reproduction 2005:20:1144-1147.  374 \nGreenhall E and Vessey M. The prevalence of subfertility: a review of the current confusion and a 375 \nreport of two new studies. Fertil Steril 1990:54:978-983.  376 \nGurunath S, Pandian Z, Anderson RA and Bhattacharya S. Defining infertility - a systematic review of 377 \nprevalence studies. Human Reproduction Update 2011:17:575-588.  378 \nHabbema JDF, Collins J, Leridon H, Evers JLH, Lunenfeld B and te Velde ER. Towards less confusing 379 \nterminology in reproductive medicine: a proposal. Human Reproduction 2004:19:1497-1501.  380 \nHall IP. Stratified medicine: drugs meet genetics. Eur Respir Rev 2013:22:53-57.  381 \nHemingway H, Croft P, Perel P, Hayden JA, Abrams K, Timmis A, Briggs A, Udumyan R, Moons KGM, 382 \nSteyerberg EW et al. Prognosis research strategy (PROGRESS) 1: A framework for researching clinical 383 \noutcomes. BMJ 2013:345:e5595.  384 \nHingorani AD, van der Windt DA, Riley RD, Abrams K, Moons KGM, Steyerberg EW, Schroter S, 385 \nSauerbrei W, Altman DG and Hemingway H. Prognosis research strategy (PROGRESS) 4: Stratified 386 \nmedicine research. BMJ 2013:346:e5793.  387 \nHunault CC, Habbema JDF, Eijkemans MJC, Collins JA, Evers JLH and te Velde ER. Two new prediction 388 \nrules for spontaneous pregnancy leading to live birth among subfertile couples, based on the 389 \nsynthesis of three previous models. Human Reproduction 2004:19:2019-2026.  390 \n \n \n18 \n \nHunault CC, Laven JSE, van Rooij IAJ, Eijkemans MJC, te Velde ER and Habbema JDF. Prospective 391 \nvalidation of two models predicting pregnancy leading to live birth among untreated subfertile 392 \ncouples. Human Reproduction 2005:20:1636-1641.  393 \nItaliano A. Prognostic or Predictive? It's Time to Get Back to Definitions!. Journal of Clinical Oncology 394 \n2011:29:4718-4718.  395 \nJohnson N, van Voorst S, Sowter MC, Strandell A and Mol BWJ. Tubal surgery before IVF. Hum 396 \nReprod Update 2011:17:3-3.  397 \nKent DM HR. Limitations of applying summary results of clinical trials to individual patients: The need 398 \nfor risk stratification. JAMA 2007:298:1209-1212.  399 \nLaRosa JC, He J,Vupputuri S. Effect of statins on risk of coronary disease: A meta-analysis of 400 \nrandomized controlled trials. JAMA 1999:282:2340-2346.  401 \nLeridon H. Can assisted reproduction technology compensate for the natural decline in fertility with 402 \nage? A model assessment. Hum Reprod 2004:19:1548-1553.  403 \nLeushuis E, van der Steeg JW, Steures P, Bossuyt PMM, Eijkemans MJC, van der Veen F, Mol BWJ and 404 \nHompes PGA. Prediction models in reproductive medicine: a critical appraisal\u2020. Human Reproduction 405 \nUpdate 2009:15:537-552.  406 \nNational Collaborating Centre for Women's and Children's Health. Fertility: assessment and 407 \ntreatment for people with fertility problems 2013:.  408 \nNelson SM and Lawlor DA. Predicting Live Birth, Preterm Delivery, and Low Birth Weight in Infants 409 \nBorn from In Vitro Fertilisation: A Prospective Study of 144,018 Treatment Cycles. PLoS Med 410 \n2011:8:e1000386.  411 \n \n \n19 \n \nRiley RD, Hayden JA, Steyerberg EW, Moons KGM, Abrams K, Kyzas PA, Malats N, Briggs A, Schroter 412 \nS, Altman DG et al. Prognosis Research Strategy (PROGRESS) 2: Prognostic Factor Research. PLoS 413 \nMed 2013:10:e1001380.  414 \nSmeenk JMJ, Stolwijk AM, Kremer JAM and Braat DDM. External validation of the Templeton model 415 \nfor predicting success after IVF. Human Reproduction 2000:15:1065-1068.  416 \nSmeenk JMJ, Braat DDM, Stolwijk AM and Kremer JAM. Pregnancy is predictable: a large-scale 417 \nprospective external validation of the prediction of spontaneous pregnancy in subfertile couples. 418 \nHuman Reproduction 2007:22:2344-2345.  419 \nSnick HK, Snick TS, Evers JL and Collins JA. The spontaneous pregnancy prognosis in untreated 420 \nsubfertile couples: the Walcheren primary care study. Human Reproduction 1997:12:1582-1588.  421 \nSteures P, van der Steeg J, Hompes P, Habbema J, Eijkemans M, Broekmans F, Verhoeve H, Bossuyt 422 \nP, van der Veen F and Mol B. Intrauterine insemination with controlled ovarian hyperstimulation 423 \nversus expectant management for couples with unexplained subfertility and an intermediate 424 \nprognosis: a randomised clinical trial. The Lancet 2006:368:216-221.  425 \nSteures P, van der Steeg JW, Mol BWJ, Eijkemans MJC, van der Veen F, Habbema JDF, Hompes PGA, 426 \nBossuyt PMM, Verhoeve HR, van Kasteren YM et al. Prediction of an ongoing pregnancy after 427 \nintrauterine insemination. Fertil Steril 2004:82:45-51.  428 \nSteyerberg E. Clinical prediction models: a practical approach to development, validation, and 429 \nupdating. 1st edn, 2009. Springer, New York.  430 \nSteyerberg EW, Moons KGM, van dW, Hayden JA, Perel P, Schroter S, Riley RD, Hemingway H, 431 \nAltman DG and for the PG. Prognosis Research Strategy (PROGRESS) 3: Prognostic Model Research. 432 \nPLoS Med 2013:10:e1001381.  433 \n \n \n20 \n \nte Velde ER, Eijkemans R and Habbema HD. Variation in couple fecundity and time to pregnancy, an 434 \nessential concept in human reproduction. Lancet 2000:355:1928-1929.  435 \nte Velde ER, Nieboer D, Lintsen AM, Braat DDM, Eijkemans MJC, Habbema JDF and Vergouwe Y. 436 \nComparison of two UK models predicting IVF success; the effect of time trends on model 437 \nperformance. Hum Reprod 2014:29:57-64.  438 \nTempleton A, Morris JK and Parslow W. Factors that affect outcome of in-vitro fertilisation 439 \ntreatment. The Lancet 1996:348:1402-1406. 440 \nvan den Boogaard NM, Bensdorp AJ, Oude Rengerink K, Barnhart K, Bhattacharya S, Custers IM, 441 \nCoutifaris C, Goverde AJ, Guzick DS, Hughes EC et al. Prognostic profiles and the effectiveness of 442 \nassisted conception: secondary analyses of individual patient data. Human Reproduction Update 443 \n2013:.  444 \nvan der Steeg JW, Steures P, Eijkemans MJC, Habbema JDF, Hompes PGA, Broekmans FJ, van Dessel 445 \nHJHM, Bossuyt PMM, van der Veen F and Mol BWJ. Pregnancy is predictable: a large-scale 446 \nprospective external validation of the prediction of spontaneous pregnancy in subfertile couples. 447 \nHuman Reproduction 2007:22:536-542.  448 \nvan Houwelingen HC and Putter H. Dynamic prediction in clinical survival analysis. 1st edn, 2012. CRC 449 \nPress, Boca Raton.  450 \nvan Loendersloot LL, van Wely M, Limpens J, Bossuyt PMM, Repping S and van der Veen F. Predictive 451 \nfactors in in vitro fertilization (IVF): a systematic review and meta-analysis. Human Reproduction 452 \nUpdate 2010:16:577-589.  453 \nZegers-Hochschild F, Adamson GD, de Mouzon J, Ishihara O, Mansour R, Nygren K, Sullivan E and van 454 \nder Poel S. The International Committee for Monitoring Assisted Reproductive Technology (ICMART) 455 \n \n \n21 \n \nand the World Health Organization (WHO) Revised Glossary on ART Terminology, 2009. Hum Reprod 456 \n2009:24:2683-2687.  457 \n 458 \n 459 \n 460 \n 461 \n 462 \n 463 \n 464 \n 465 \n 466 \n 467 \n 468 \n 469 \n 470 \n 471 \n 472 \n 473 \n 474 \n \n \n22 \n \nTable 1. Prognostic factors used to predict spontaneous pregnancy (taken from Leushuis et al, 2009). 475 \nCouple factors \n Duration of subfertility (year) \n Secondary subfertility \nFemale factors \n Female age (years) \n Referral status (tertiary care) \n Ovulation disorder \n Pelvic surgery \n Tubal defect \n Endometriosis \n Ovulation or cervical disorder \n Uterine abnormality (UA) \n UA and ovulation or cervical disorder \nMale factors \n Male age (year) \n Sperm motility (%) \n Degree of motility (good) \n Sperm morphology (%) \n Sperm concentration (x 10P6P) \n Abnormal post coital test (PCT) \n World Health Organisation (WHO) semen defect \n Hypo-osmotic test (HOS) test (%) \n Urethritis in history \n Fertility problem in male\u2019s family \n 476 \n \n \n23 \n \nFigure 1 Diagram to explain absolute and relative benefit of treatment (Tx) in the stratified medicine 477 \napproach for individualised predictions of a pregnancy outcome, such as live birth, in a subfertile 478 \npopulation 479 \n 480 \n 481 \n  482 \n 483 \n 484 \n 485 \n 486 \n 487 \n 488 \n 489 \n 490 \n 491 \n 492 \n 493 \n 494 \n 495 \n 496 \n 497 \n 498 \nAbsolute chance    Relative Tx benefit         Absolute Tx benefit \n      (using Models 1a and 1b) \n         \n            X%  \n \n             \n \n             Y%/X%     Y% - X%        \nEquivalent to stratified medicine \napproach described in Model 2b IF the \ntwo cohorts contain similar women.  \n \n \n \nNote: X and Y depend on prognostic factors for a particular woman \nExpectant \nmanagement \nTreatment effect \nIVF Tx \nIVF Tx \nExpectant \nmanagement \nModel 1a \u2013 Prediction of Spontaneous live birth \n \nModel 1b \u2013 Prediction of Tx dependent live birth \nModel 2a \u2013 Prediction of live birth adjusting for Tx \nModel 2b \u2013 Stratified medicine approach \n% chance of \nSpontaneous \nlive birth \nIVF Tx \n% chance of \nTx dependent \nlive birth \nModels Individualised chance of live birth \n \n% chance of live \nbirth by Tx status in \ncombination with \nprognostic factors \nPrognostic factors Treatment predictive factors \nSubfertile \ncouples \nSubfertile \ncouples \nRelative Tx benefit \n \n \n \nRelative increase in \nchance of live birth \nfor Tx versus no Tx is \nconstant for all \nwomen. \n \n \n \n            \n \n \n            \n            \nAbsolute Tx benefit \n \n \n \nThe absolute increase \nin chance of live birth \nfor a particular treated \nwoman depends on \nher baseline chance. \n              \n \n \n            \n \n \n            \n            \nRelative Tx benefit \n \n \nRelative increase in \nchance of live birth \nfor Tx versus no Tx \ndepends on \npredictive factors. \n \n \n            \n \n \n            \n            \nAbsolute Tx benefit \n \n \nThe absolute increase \nin chance of live birth \nfor a particular treated \nwoman depends on her \nbaseline chance and \nthe specific relative \neffectiveness. \n              \n \n \n            \n \n \n            \n            \nKey: \nY% \nExpectant \nmanagement \n% chance of live birth by \nTx status in combination \nwith prognostic and \ntreatment predictive \nfactors \n \n \n \n \n24 \n \nFigure 2 Dynamic prediction for pregnancy prognosis 499 \n 500 \n 501 \n 502 \n 503 \n 504 \n 505 \n 506 \n 507 \n 508 \n 509 \n 510 \n 511 \n 512 \n 513 \n 514 \n 515 \n 516 \n 517 \n 518 \n 519 \n 520 \n 521 \n 522 \n 523 \nModel 1: A time to event model predicts the probability of pregnancy (PR0R) within one year at the point where the type of 524 \ninfertility is established (baseline).   525 \nModel 2: A second time to event model predicts the probability of pregnancy (PR1R) within one year from 1 month after 526 \nbaseline.  All women who were pregnant in the first month (dotted line) are excluded. 527 \nThis is repeated from every month thereafter, until month N. 528 \nModel N+1: An (N+1)th time to event model predicts the probability of pregnancy (PRNR) within one year from N months 529 \nafter baseline.  All women who were pregnant up to month N (dotted line) are excluded. 530 \nModel N+1 \nModel 1 \nPN \nP6 \nP5 P4 P3 \nP2 P1 P0 \nBaseline prognosis \n1 year \nfollow-up \n0 \nTime from baseline (months) \n3 6 9 12 \n3 6 9 12 13 \n1 2 \n1 2 \n1 year \nfollow-up \n1 year \nfollow-up \n6 9 12 18 \nPrognosis at 6 months \nPrognosis at 1 month \nProbability of \npregnancy within one \nyear at month i, (Pi) \n \nP0 \n \n \n \n \n \nP1 \n \n \n \n \n \n \n \n \nP6 \n \n \n \n \n \n \n \n \n \nPN \n1 year \nfollow-up \nN+12 N \nProbability of pregnancy over the next year from each month \nfollowing diagnosis of type of infertility \n0       1     2     3      4      5       6                        N \n1 \n0 \n     \n \n  \nPrognosis at N months \nModel 2 \nModel 7 \nPr\nob\nab\nili\nty\n o\nf p\nre\ngn\nan\ncy\n  \nMonth \n \n \n \n",
        "id": 18018297,
        "identifiers": [
          {
            "identifier": "oai:pure.eur.nl:publications/2ae5eb75-4582-4c6c-8e4c-09f24d4c2ecb",
            "type": "OAI_ID"
          },
          {
            "identifier": "590648858",
            "type": "CORE_ID"
          },
          {
            "identifier": "567379233",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:http://orca.cardiff.ac.uk:114437",
            "type": "OAI_ID"
          },
          {
            "identifier": "info:doi/10.1093%2fhumrep%2fdeu173",
            "type": "OAI_ID"
          },
          {
            "identifier": "oai:pure.eur.nl:openaire_cris_publications/2ae5eb75-4582-4c6c-8e4c-09f24d4c2ecb",
            "type": "OAI_ID"
          },
          {
            "identifier": "79083322",
            "type": "CORE_ID"
          },
          {
            "identifier": "209836415",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:http://orca.cf.ac.uk:114437",
            "type": "OAI_ID"
          },
          {
            "identifier": "2141363958",
            "type": "MAG_ID"
          },
          {
            "identifier": "161103173",
            "type": "CORE_ID"
          },
          {
            "identifier": "10.1093/humrep/deu173",
            "type": "DOI"
          },
          {
            "identifier": "444043851",
            "type": "CORE_ID"
          },
          {
            "identifier": "566811103",
            "type": "CORE_ID"
          },
          {
            "identifier": "29465852",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:https://orca.cardiff.ac.uk:114437",
            "type": "OAI_ID"
          },
          {
            "identifier": "oai:digital.library.adelaide.edu.au:2440/89837",
            "type": "OAI_ID"
          },
          {
            "identifier": "oai:aura.abdn.ac.uk:2164/4701",
            "type": "OAI_ID"
          }
        ],
        "title": "Clinical prediction models to inform individualized decision-making in subfertile couples : a stratified medicine approach",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:http://orca.cardiff.ac.uk:114437",
          "oai:aura.abdn.ac.uk:2164/4701",
          "oai:http://orca.cf.ac.uk:114437",
          "oai:pure.eur.nl:publications/2ae5eb75-4582-4c6c-8e4c-09f24d4c2ecb",
          "oai:digital.library.adelaide.edu.au:2440/89837",
          "oai:pure.eur.nl:openaire_cris_publications/2ae5eb75-4582-4c6c-8e4c-09f24d4c2ecb",
          "info:doi/10.1093%2fhumrep%2fdeu173",
          "oai:https://orca.cardiff.ac.uk:114437"
        ],
        "publishedDate": "2014-01-01T00:00:00",
        "publisher": "'Oxford University Press (OUP)'",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://orca.cf.ac.uk/114437/1/McLernon_et_al_HUMREP_14_SB.pdf",
          "https://aura.abdn.ac.uk/bitstream/2164/4701/1/McLernon_et_al_HUMREP_14_0292.R1_final_version_pre_publication.pdf",
          "https://orca.cardiff.ac.uk/id/eprint/114437/1/McLernon_et_al_HUMREP_14_SB.pdf"
        ],
        "updatedDate": "2024-03-02T06:57:09",
        "yearPublished": 2014,
        "journals": [
          {
            "title": "Human Reproduction",
            "identifiers": [
              "0268-1161",
              "issn:0268-1161"
            ]
          }
        ],
        "links": [
          {
            "type": "download",
            "url": "https://core.ac.uk/download/29465852.pdf"
          },
          {
            "type": "reader",
            "url": "https://core.ac.uk/reader/29465852"
          },
          {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/29465852/large"
          },
          {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/29465852/large"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/18018297"
          }
        ]
      },
      "relevance_score": 0.0175,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.175,
          "dimension_weight": 0.1,
          "weighted_score": 0.0175,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2014 (Norm. Score: 0.1)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_secondary_5",
      "dynamic_step": 0,
      "core_id": 18018297,
      "doi": "10.1093/humrep/deu173"
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": "1708.06414",
        "authors": [
          {
            "name": "Attree, Sandeep"
          },
          {
            "name": "Patel, Sourav"
          },
          {
            "name": "Prakash, Mangal"
          },
          {
            "name": "Salapaka, Murti V."
          },
          {
            "name": "Talukdar, Saurav"
          }
        ],
        "citationCount": 0,
        "contributors": [
          "Sourav"
        ],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/467399917"
        ],
        "createdDate": "2017-10-17T02:36:57",
        "dataProviders": [
          {
            "id": 144,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/144",
            "logo": "https://api.core.ac.uk/data-providers/144/logo"
          },
          {
            "id": 4786,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/4786",
            "logo": "https://api.core.ac.uk/data-providers/4786/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "Greater penetration of Distributed Energy Resources (DERs) in power networks\nrequires coordination strategies that allow for self-adjustment of\ncontributions in a network of DERs, owing to variability in generation and\ndemand. In this article, a distributed scheme is proposed that enables a DER in\na network to arrive at viable power reference commands that satisfies the DERs\nlocal constraints on its generation and loads it has to service, while, the\naggregated behavior of multiple DERs in the network and their respective loads\nmeet the ancillary services demanded by the grid. The Net-load Management\nsystem for a single unit is referred to as the Local Inverter System (LIS) in\nthis article . A distinguishing feature of the proposed consensus based\nsolution is the distributed finite time termination of the algorithm that\nallows each LIS unit in the network to determine power reference commands in\nthe presence of communication delays in a distributed manner. The proposed\nscheme allows prioritization of Renewable Energy Sources (RES) in the network\nand also enables auto-adjustment of contributions from LIS units with lower\npriority resources (non-RES). The methods are validated using\nhardware-in-the-loop simulations with Raspberry PI devices as distributed\ncontrol units, implementing the proposed distributed algorithm and responsible\nfor determining and dispatching realtime power reference commands to simulated\npower electronics interface emulating LIS units for demand response.Comment: 7 pages, 11 Figures, IEEE International Conference on Smart Grid\n  Communication",
        "documentType": "research",
        "doi": "10.1109/smartgridcomm.2017.8340735",
        "downloadUrl": "http://arxiv.org/abs/1708.06414",
        "fieldOfStudy": null,
        "fullText": "Distributed Apportioning in a Power Network for\nproviding Demand Response Services\nSourav Patel, Sandeep Attree, Saurav Talukdar, Mangal Prakash, Murti V. Salapaka\nDepartment of Electrical and Computer Engineering\nUniversity of Minnesota\n{patel292, attree002, taluk005, praka027, murtis}@umn.edu\nAbstract\u2014Greater penetration of Distributed Energy Re-\nsources (DERs) in power networks requires coordination strate-\ngies that allow for self-adjustment of contributions in a network\nof DERs, owing to variability in generation and demand. In this\narticle, a distributed scheme is proposed that enables a DER in\na network to arrive at viable power reference commands that\nsatisfies the DERs local constraints on its generation and loads it\nhas to service, while, the aggregated behavior of multiple DERs in\nthe network and their respective loads meet the ancillary services\ndemanded by the grid. The Net-load Management system for a\nsingle unit is referred to as the Local Inverter System (LIS) in this\narticle . A distinguishing feature of the proposed consensus based\nsolution is the distributed finite time termination of the algorithm\nthat allows each LIS unit in the network to determine power\nreference commands in the presence of communication delays in a\ndistributed manner. The proposed scheme allows prioritization of\nRenewable Energy Sources (RES) in the network and also enables\nauto-adjustment of contributions from LIS units with lower\npriority resources (non-RES). The methods are validated using\nhardware-in-the-loop simulations with Raspberry PI devices as\ndistributed control units, implementing the proposed distributed\nalgorithm and responsible for determining and dispatching real-\ntime power reference commands to simulated power electronics\ninterface emulating LIS units for demand response.\n1. INTRODUCTION\nThe existing power grid network is in the process of tran-\nsitioning from a framework, where conventional large power\nplants generate at one end while loads consume at the other,\ntowards integration of large number of smaller distributed\ngeneration (DG) units scattered throughout the network to\nprovide ancillary services and support the power grid [1], [2],\n[3]. The coordination of multiple distributed generation units\npresents significant challenges. [4] and [5] provide a review of\nworks that have employed a centralized approach to solve the\nproblem of aggregating and coordinating Distributed Energy\nResources (DERs), where a secondary centralized controller\ndispatches commands to DERs and requires information from\nall of the DERs, in many cases is not tenable. A distributed\nmethod for grid ancillary services has a number of advantages\nover centralized architecture as enumerated below:\n1) Distributed co-ordination is achieved using only local\ncomputations (which reduces communication overheads\nand congestion) pertaining only to the neighborhood of\nthe DER.\n2) Distributed coordination facilitates \u2018plug and play\u2019 ca-\npability, where a new DER that needs to connect to\nthe network requires communication only to its nearest\navailable DER.\n3) Distributed architecture is resilient to failures as any\nparticular node failure does not lead to failure of the\nentire network.\nThe objective of this article is to meet the grid ancillary\ndemand (global objective) by using an aggregation of DERs\nforming a network while respecting their local generation and\ndemand constraints in a distributed manner. In this regard, we\npropose a distributed resource apportioning framework that\nis suitable for real-time implementation. We envision the use\nof ultra low-cost computing devices like Raspberry Pi (R-\nPi) acting as control and communication agents in the DER\nnetwork. The wireless communication channel between R-\nPis suffers from time varying (stochastic) delays, which for\npractical purposes can be considered to be bounded (see Figure\n5(b)). The distributed resource apportioning solution proposed\nhere is robust to the presence of bounded communication\ndelays between the DERs\u2019 communication devices.\nRatio consensus algorithm for distributed coordination of\nDERs to meet the ancillary service demand is presented in [6].\nThe ratio consensus algorithm is used to compute the power\nreference commands for the DERs based on their generation\ncapacities. However, the convergence of ratio consensus\nto the power reference command values is asymptotic in\nnature and hence, unsuitable for real time implementation.\nTo circumvent this issue, a distributed finite time termination\nof ratio consensus is presented in [7], which builds on ideas\npresented in [6] and [8] for frequency regulation in a network\nof islanded AC micro grids. However, none of the works\ndiscussed above address the issue of communication delays\nin ratio consensus and the method for distributed termination\nis not present. Distributed finite time termination of ratio\nconsensus in the presence of bounded delays is presented in\n[9] but it does not adhere to distributed resource apportioning\nand coordination of DERs in the presence of communication\ndelays. Figure 1 shows experimental results for implementing\nratio consensus algorithm on a 5 node network for averaging\nof initial values without accounting for any communication\ndelays. Ignoring communication delays results in a converged\nvalue of 225, that is, an error of 43.75% from the true average\nof 400. This motivates the need to address the challenges\nof communication delays for successful implementation of\ndistributed consensus algorithms for real-time applications\nsuch as power networks. Furthermore, the power network\nrelies on a number of measurements and communicating\nthese measurements among control units for purposes of\nar\nX\niv\n:1\n70\n8.\n06\n41\n4v\n1 \n [c\ns.S\nY]\n  2\n1 A\nug\n 20\n17\n0 10 20 30 40\nNumber of iterations\n0\n200\n400\n600\n800\n1000\nAg\nent\n va\nlue\nAgent 1\nAgent 2\nAgent 3\nAgent 4\nAgent 5\nAverage\n(a) (b)\nFig. 1. (a) 5 node network with initial conditions, (b) experimental\nresults for the 5 node network when communication delays are not\nconsidered converge at a value different than the true average.\nFig. 2. Residential scale LIS unit with generation sources and local\nloads\neffective control [10]. Ignoring communication delays could\nresult in a destabilizing effect on the entire system or any\npart thereof; hence, it is important that communication delays\nare taken care of for meeting performance specifications.\nIn this article we present a distributed scheme for apportion-\ning the share of resources that a DER has to provide toward\nmeeting a global demand while satisfying local load demands.\nThe effectiveness of the algorithm is demonstrated by execut-\ning the algorithm on real devices (Raspberry Pis) where the\npower reference commands, obtained from the termination of\nratio consensus, are implemented in a hardware in the loop\nsimulation with Simulink. We use a number of basic notions\nfrom graph theory and linear algebra which are essential for\nthe subsequent developments. Detailed description of these\nnotions are available in [11] and [12].\nIn the next section we provide an overview of the Local\nInverter System (LIS), the associated network topology as well\nas the resource apportioning problem.\n2. LOCAL INVERTER SYSTEMS\nA. System Topology\nA residential level local inverter system (Figure 2) consists\nof an array of distributed generation sources (such as PV, EV,\nbattery) interfaced with DC-DC converters, DC Link Capacitor\nand DC-AC inverters to serve local AC loads. Utility scale\nLIS unit consists of an utility scale inverter with a PV array\nto meet ancillary demand services of the grid and/or a network\nof residential LIS units. The output of an LIS unit is connected\nthrough a point of common coupling (PCC) to other LIS units\nin a peer-to-peer microgrid or to the grid through an aggregator\n(described later) when in grid-connected mode.\nFig. 3. (a) Bidirectional DC-DC Converter realizations for DERs in a\nResidential LIS unit where q(t) is the desired duty ratio input, (b) A single\nLIS unit with N DERs implementing power-voltage droop control and inner-\ncontrol loops for voltage regulation and load sharing.\nFig. 4. Aggregator injecting grid ancillary demand \u03c1d at node LIS 2 in a\n6-node LIS network.\nConsider a single LIS unit with N DERs connected in\nparallel. A power-voltage droop control is implemented for\neach DC-DC converter unit as described in [13] and extended\nto the parallel converter system of Figure 3. The Power output\nof jth DC-DC converter, Pj , is compared against a desired\nreference power output set point, P \u2217j , demanded from the j\nth\nDER. A suitable droop coefficient \u03b7j is chosen that generates\nvoltage reference set point Vrefj according to equation (1) for\nthe inner loop controller. Thus,\nVrefj = V\n\u2217 \u2212 \u03b7j(Pj \u2212 P \u2217j ). (1)\nThe inner-loop controller consists of a voltage controller\nloop that generates a current reference signal irefj and a fast\ncurrent controller loop for voltage regulation of the jth DC-DC\nConverter. An extensive design of such inner-loop controller\nis proposed in [14] that implements a decentralized control ar-\nchitecture for load sharing among multiple parallel converters\nsimilar to the topology proposed here. The converter devices\nare assumed to be lossless in this article. The reactive power\nflow is assumed to be zero in the network and transmission\nlines are considered to be lossless.\nB. Network of LIS units\nAn Aggregator as shown in Figure 4 is an entity that injects\nthe grid ancillary demand into the network of LIS units, which\nthen becomes the global objective of the network. Consider a\nnetwork of I = {1, 2, ..., n} LIS units, where, the jth LIS unit\nhas Ej DERs and Lj loads. The generation capacity of the\njth LIS unit, pijg :=\n\u2211Ej\nm=1 pi\nj\ngm , where, pi\nj\ngm is the generation\ncapacity of the mth DER in the jth LIS unit. The local load\ndemand of the jth LIS unit, pijl :=\n\u2211Lj\nm=1 pi\nj\nlm\n, where, pijlm is\nthe demand of the mth load in the jth LIS unit. At a given\ninstant, the jth LIS unit is said to have a net reserve Rj , where,\nRj =\nEj\u2211\nm=1\npijgm \u2212\nLj\u2211\nm=1\npijlm for all j = 1, 2, ..., n. (2)\nIf the net reserve Rj > 0, LIS unit j behaves as a network\nsource otherwise it is a network load. In this article, we assume\nall LIS units act as sources to meet the grid demand \u03c1d;\nextending the resource apportioning framework to the case\nwhere there is a mix of source and load LIS units is a simple\nextension.\nThe LIS units communicate with each other as dictated by\nthe network topology through wireless channels. This com-\nmunication link is represented as a bidirectional edge in the\nnetwork and results in an undirected graph. Delays are inherent\nbecause of the presence of wireless communication channels\nbetween control units of LIS units, and are assumed to be fixed\nand uniformly bounded for simplicity of presentation and the\nHIL validation is for the stochastic but bounded delay case.\nC. Resource Apportioning Problem\nThe network of LIS units can be viewed as a multi agent\nsystem with the agents interacting with their neighbors over\na communication network. Each LIS unit is considered as\na node and each communication link between LIS units is\nconsidered as an undirected edge in a graph G = (V,E),\nwhere, V denotes the set of nodes and E denotes the set of\nedges. The central aggregator requests that a total resource \u03c1d\nbe supplied, which has to be collectively provided by the n LIS\nunits, while respecting their individual resource constraints.\nLet pi\u2217i be the amount of resource supplied by the i\nth LIS\nunit, where pimini and pi\nmax\ni represent the minimum and the the\nmaximum amount of power ith agent can supply respectively.\nThe objective is to determine {pi\u2217i }i\u2208V such that,\npimini \u2264 pi\u2217i \u2264 pimaxi and\n\u2211\ni\u2208V\npi\u2217i = \u03c1d.\nWe refer to the problem of determining pi\u2217i respecting the\nabove constraints as the resource apportioning problem. We\nassume that\n\u2211n\ni=1 pi\nmin\ni \u2264 \u03c1d \u2264\n\u2211n\ni=1 pi\nmax\ni holds to ensure\nfeasibility of the resource allocation problem. Let \u03c4ij denote\nthe delay in the communication link from node j to node i. The\ncommunication delay in each link is assumed to be constant\nand bounded by \u03c4\u00af . We present below an approach which meets\nthe demand \u03c1d asymptotically while respecting the constraints\nof each agent via a distributed iterative algorithm where each\nnode updates its state based on its current state and the state\nof its neighbors.\n3. RESOURCE APPORTIONING USING DISTRIBUTED\nAVERAGING\nThe resource apportioning problem in the presence of\nbounded communication delays between LIS units can be\nsolved by using average consensus protocols which incor-\nporates delays. We first summarize below the distributed\naveraging protocol in presence of bounded delays as presented\nin [15].\nA. Distributed Averaging Protocol\nA1. Let pij denote the weight on the information coming\nfrom node j to node i. Weight matrix [P ](i, j) = pij\nassociated with the undirected graph is primitive and\ncolumn stochastic.\nA2. The undirected graph G = (V,E) is connected.\nA3. Any node i \u2208 V in the undirected graph G = (V,E)\nhas access to its own value at any instant k without any\ndelay.\nA4. The delay on the edge from node j to i, \u03c4ij is bounded by\nsome constant \u03c4\u00af , for all i, j \u2208 V , that is, \u03c4ij \u2264 \u03c4\u00af <\u221e.\nUnder the assumptions A1-A4 consider the iterations,\nxi(k + 1) = piixi(k) +\n\u2211\nj\u2208Ni\u2212\npijxj(k \u2212 \u03c4ij), (3)\nwi(k + 1) = piiwi(k) +\n\u2211\nj\u2208Ni\u2212\npijwj(k \u2212 \u03c4ij), (4)\nwith the initial conditions be given by x(0) =\n[x1(0) x2(0)...xn(0)]\nT and w(0) = 1n where 1n is a\nn\u00d7 1 column vector of all ones. Then the ratio of xi(k) and\nwi(k) asymptotically converges to lim\nk\u2192\u221e\n\u00b5j(k) =\n\u2211n\ni=1xi(0)\nn\nfor all j = 1, ..., n, where \u00b5j(k) := xj(k)/wj(k) [15].\nRemark 1. The weight matrix being column stochastic en-\nables the weights pij to be chosen in a distributed manner. A\nsimple scheme for choosing the weights are pji = 1D+i +1\nfor\nall j \u2208 {N+i \u222a i}.\nNow we use the distributed averaging based on (3) and (4)\nfor distributed resource allocation. Suppose that the resource\ndemanding authority, which is referred to as the aggregator\ncan communicate to p agents out of n (1 \u2264 p \u2264 n) and\nsend across its demand \u03c1d. The nodes to which the aggregator\nrelays its demand are called demand circulation nodes and the\nset of such nodes is denoted by Nd. Suppose that each node\nhas three states, [ri(k), si(k), ti(k)]T such that,\nri(k + 1) = piiri(k) +\n\u2211\nj\u2208N\u2212i\npijrj(k \u2212 \u03c4ij), (5)\nri(0) =\n\u03c1d\np\n\u2212 pimini if i \u2208 Nd or\nri(0) = \u2212pimini if i 6\u2208 Nd,\nsi(k + 1) = piisi(k) +\n\u2211\nj\u2208N\u2212i\npijsj(k \u2212 \u03c4ij), (6)\nsi(0) = pi\nmax\ni \u2212 pimini , for all i \u2208 V,\nti(k + 1) = piiti(k) +\n\u2211\nj\u2208N\u2212i\npijtj(k \u2212 \u03c4ij), (7)\nti(0) = 1, for all i \u2208 V,\nwhere, pimaxi and pi\nmin\ni denote the maximum and minimum\npower availability from the ith LIS unit. It follows from\nthe above discussion that, lim\nk\u2192\u221e\nri(k)\nti(k)\n=\n\u03c1d \u2212\nn\u2211\nj=1\npiminj\nn\n, and\nlim\nk\u2192\u221e\nsi(k)\nti(k)\n=\nn\u2211\nj=1\n(pimaxj \u2212 piminj )\nn\n, for all i \u2208 V.\nTheorem 3.1. Let the power reference command for the ith\nLIS unit be defined as, pi\u2217i := pi\nmin\ni + lim\nk\u2192\u221e\nri(k)\nsi(k)\n(pimaxi \u2212\npimini ). Then\nn\u2211\ni=1\npi\u2217i = \u03c1d and pi\nmin\ni \u2264 pi\u2217i \u2264 pimaxi for all\ni \u2208 V .\nProof. It follows from the above discussion that,\npi\u2217i = pi\nmin\ni +\n\u03c1d \u2212\nn\u2211\nj=1\npiminj\nn\u2211\nj=1\n(pimaxj \u2212 piminj )\n(pimaxi \u2212 pimini ), for all i \u2208 V.\nIt is clear from the feasibility of demand \u03c1d that, pimini \u2264\npi\u2217i \u2264 pimaxi . Moreover, it follows that,\nn\u2211\ni=1\npi\u2217i = \u03c1d.\nThis completes the proof.\nTheorem 3.1 provides a distributed protocol to allocate\nresources to meet the demand \u03c1d. It is an extension of the ratio\nconsensus approach for resource apportioning presented in [6]\nto incorporate communication delays between the agents. It\nshould be noted that the result in Theorem 3.1 is asymp-\ntotic. Thus, the agents in principle keep updating their states\n(using (5),(6),(7)) forever without termination, which makes\nit untenable from a real time implementation perspective.\nOne needs to terminate the computations at each node in a\ndistributed manner when the sum of the contribution from\neach node is \u2018close\u2019 to \u03c1d. This problem of distributed finite\ntime termination of resource apportioning is dealt in the next\nsection.\n4. DISTRIBUTED FINITE TIME TERMINATION OF\nRESOURCE APPORTIONING\nIn this section, first results based on the update rules (3) and\n(4) are established followed by the definitions and convergence\nof Max-Min consensus algorithms. Subsequently, a finite-time\ntermination criterion for average consensus is developed based\non these results. Let us consider the maximum and minimum\nvalue of the ratio of consensus protocols given by (1) and (4)\nover all nodes within a horizon \u03c4\u00af from any time instant k be\ngiven by,\nM(k) := max\nj\u2208V\nr={0,1,2,...,\u03c4\u00af}\nxj(k \u2212 r)\nwj(k \u2212 r) , wj(k \u2212 r) 6= 0, j \u2208 V (8)\nm(k) := min\nj\u2208V\nr={0,1,2,...,\u03c4\u00af}\nxj(k \u2212 r)\nwj(k \u2212 r) , wj(k \u2212 r) 6= 0, j \u2208 V (9)\nRemark 2. It is shown in [9] that {M(k)}k\u2208N and\n{m(k)}k\u2208N converges to\n\u2211n\nj=1 xj(0)\nn .\nRemark 3. Given that wj(0) = 1 for all j \u2208 V and P is a\nnon-negative matrix, wj(k) 6= 0 for all k \u2208 N.\nNext, we introduce the Maximum Consensus and Minimum\nConsensus protocols.\nA. Maximum and Minimum Consensus Protocols [16]\nMaximum Consensus Protocol (MXP) computes the\nmaximum of the given initial node conditions z(0) =\n[z1(0) z2(0)....zn(0)]\nT in a distributed manner. It takes z(0)\nas an input and generates a sequence of node values based on\nthe following update rule for node i,\nzi(k\u03c4\u00af + q) = zi(k\u03c4\u00af + q \u2212 1), q \u2208 {k + 1, k + 2, \u00b7 \u00b7 \u00b7 , k + \u03c4\u00af},\nzi((k + 1)(\u03c4\u00af + 1)) =\nmax\nj\u2208N\u2212i \u222a{i}\nzj((k + 1)(\u03c4\u00af + 1)\u2212 (\u03c4ij + 1)) for k \u2265 0. (10)\nThe Minimum Consensus Protocol (MNP) computes the\nminimum of the given initial node conditions y(0) =\n[y1(0) y2(0)....yn(0)]\nT in a distributed manner. It takes y(0) as\nan input and generates a sequence of node values y(k) based\non the following update rule:\nyi(k\u03c4\u00af + q) = yi(k\u03c4\u00af + q \u2212 1), q \u2208 {k + 1, k + 2, \u00b7 \u00b7 \u00b7 , k + \u03c4\u00af},\nyi((k + 1)(\u03c4\u00af + 1)) =\nmin\nj\u2208N\u2212i \u222a{i}\nyj((k + 1)(\u03c4\u00af + 1)\u2212 (\u03c4ij + 1)), for k \u2265 0. (11)\nRemark 4. MXP and MNP converge to the maximum and\nminimum of the initial conditions respectively in D(1 + \u03c4\u00af)\niterations, where D is the diameter of the network [16].\nB. Distributed Finite Time Termination of Resource Appor-\ntioning\nIn this section, we propose an algorithm using the MXP-\nMNP for stopping the ratio consensus protocol in finite time\nbased on a user-specified threshold \u03c1. This framework first\nappeared in [7] as an extension of the Max-Min consensus\nbased finite time termination of averaging consensus [8].\nHowever, [7], [8] do not consider any communication de-\nlays in the network and [8] is based on the weight matrix\nP being doubly stochastic thereby restrictive in the sense\nof distributed selection of the edge weights. A MXP-MNP\nframework for finite time termination of ratio consensus ((3)\nand (4)) with uniformly bounded communication delays and\ncolumn stochastic weight matrix is reported in [9]. We apply\nthe results in [9] for distributed finite time termination of the\nnumerator and denominator ratio consensus protocol as shown\nin Algorithm 1. The initial conditions for the MXP and MNP\nprotocols are set as the initial ratio held by the nodes, that\nis, zi(0) = ri(0)/si(0) and yi(0) = ri(0)/si(0). The MXP\nand MNP protocols at each node i \u2208 V are re-initialized at\nk = \u03b8(D(1 + \u03c4\u00af) + \u03c4\u00af), where \u03b8 = 1, 2, ..., with zi(k) =\nri(k)\nsi(k)\nand yi(k) =\nri(k)\nsi(k)\n. Given a threshold \u03c1 > 0, it is proven in\n[9] that Algorithm 1 terminates in finite number of iterations.\nNote that {ti}i\u2208V iterations were used for analysis only and\nis not required to be maintained at the nodes as its effect is\ncancelled.\nAlgorithm 1: Distributed finite-time termination of re-\nsource apportioning in presence of communication delays\n(at each node i \u2208 V )\nRepeat:\nInput:\npimini , pi\nmax\ni , \u03c1d, p\n\u03c1, \u03c4\u00af , D\nInitialize:\nri(0) =\n\u03c1d\np \u2212pimini , if i \u2208 Nd, else ri(0) = \u2212pimini ;\nsi(0) = pi\nmax\ni \u2212 pimini ;\nk := 0;\nzi := ri(0)/si(0);\nyi := ri(0)/si(0);\nl := 1;\n\u03b8 := 1;\nRepeat:\n/* ratio consensus updates of node\ni given by (3) and (4) */\nri(k + 1) := piiri(k) +\n\u2211\nj\u000fN\u2212i\npijrj(k \u2212 \u03c4ij);\nsi(k + 1) := piisi(k) +\n\u2211\nj\u000fN\u2212i\npijsj(k \u2212 \u03c4ij);\nif k + 1 = l(1 + \u03c4\u00af) then\n/* maximum and minimum\nconsensus updates given by\n(10) and (11) for each node\ni \u2208 V */\nzi := max\nj\u2208N\u2212i \u222a{i}\nzj ;\nyi := min\nj\u2208N\u2212i \u222a{i}\nyj ;\nl := l + 1\nend\nemit: ri(k + 1), si(k + 1), yi and zi\nif k + 1 = \u03b8(D(1 + \u03c4\u00af) + \u03c4\u00af) then\nif zi \u2212 yi < \u03c1 then\nr\u2217i = ri(k + 1);\ns\u2217i = si(k + 1);\nbreak ; // stop ri, si, yi and zi\nupdates\nelse\nzi :=\nri(\u03b8(D(1+ \u03c4\u00af)+ \u03c4\u00af))/si(\u03b8(D(1+ \u03c4\u00af)+ \u03c4\u00af));\nyi :=\nri(\u03b8(D(1+ \u03c4\u00af)+ \u03c4\u00af))/si(\u03b8(D(1+ \u03c4\u00af)+ \u03c4\u00af));\n\u03b8 := \u03b8 + 1;\nend\nend\nk = k + 1\npi\u2217i := pi\nmin\ni +\nr\u2217i\ns\u2217i\n(pimaxi \u2212 pimini ) // power\nreference command for node i \u2208 V\nRemark 5. The MXP and MNP iterations can be used to\ncompute \u03b2i(\u03b8) in a distributed manner at each node. Algorithm\n1 presented below uses \u03b2i(\u03b8) < \u03c1 as a stopping criteria\nfor termination of (5) and (6). It computes the approxi-\nmate limiting ratio r\u2217i /s\n\u2217\ni (each node converges \u2018close\u2019 to\nlim\nk\u2192\u221e\nri(k)/si(k)) in a distributed manner. The only global\nparameters needed by each node are upper bounds on both\nthe maximum delay and diameter of the network.\n5. RESULTS\nHardware in the loop (HIL) simulations are performed on a\nnetwork of 6 LIS units as shown in Figure 4 for demonstrating\nthe applicability of the algorithm presented. Each LIS unit\nis equipped with a Raspberry-PI 3 (Model B V1.2) (see\nFigure 5 (a)) [17] module for control and communication\nwith other LIS units. R-PI 3 implements 802.11n Wireless\nstandard that allows for a larger range of communication with\nfaster data transmission speeds [18]. LIS units communicate\nin their respective neighborhoods (Figure 4) wirelessly. Figure\n5 (b) shows pairwise communication delays experienced by\nR-PI units. These delays are due to inherent uncertainties in\nthe communication channel as well as those modeled for the\nexperiment.\nIf an LIS unit has RES, then it has a time dependent gen-\neration profile associated with it because of the variability in\nenvironmental parameters that impact generation, otherwise a\nfixed maximum and minimum generation capacity is assumed.\nFor the considered topology as depicted in Figure 4, D = 3,\n\u03c4\u00af = 3 and the weight matrix P (column stochastic) is chosen\ndistributively as described in Remark 1. Let the grid ancillary\ndemand, \u03c1d be 7000 W. In this simulation, LIS 2 is chosen to\nbe a RES, which is a PV array operating in Maximum Power\nPoint Tracking (MPPT) mode [19] with a suitable profile\nselected to reflect a normal sunny day as defined in Table I.\nAll other LIS units are energy sources with the maximum\nand minimum capacity as listed in Table II. The DC Link\nBus voltage reference command is set to 300 V. Switching\nmodels of DC-DC and DC-AC Converters [20] are developed\nin Simulink, which execute the real time power reference\ncommands received through Serial Communication Interface\n(SCI) from Raspberry PI modules [21]. In this study, LIS 2 is\nthe demand circulation node. The prioritization of RES is done\nby setting the capacities of LIS 2 as, pimin = PMPPT (t)\u2212 \u000f\nand pimax = PMPPT (t), for all time t, where \u000f is a small\npositive number and PMPPT is the output power of PV\nobtained by implementing an MPPT algorithm at all instants.\nThe capacities of all non-RES LIS units are listed in Table II.\nAgents are initialized as discussed in (5), (6), (7) with p = 1.\nTABLE I\nPV profile for experiment\nTime(Hrs) Power-\nOutput(kW)\n0 \u2264 t < 3 ramps up to 1kW\n3 \u2264 t < 5 1kW (Constant)\n5 \u2264 t \u2264 8 ramps down to 0\nAlgorithm 1 is executed in a distributed manner on each R-\nPI unit and a power reference command is generated approx-\nimately at every second. Delays are variable and empirically\ndelays as high as 3000 ms between R-PI units are observed\nTABLE II\nLIS Parameters used for validation\nUnit pimin(W ) pimax(W )\nLIS 1 0 1500\nLIS 2 (PV) Profile Min(t) Profile Max(t)\nLIS 3 0 1000\nLIS 4 0 1200\nLIS 5 0 1500\nLIS 6 0 2000\nLIS 1 LIS 2 LIS 3 LIS 4 LIS 5 LIS 6\n1000\n1500\n2000\n2500\n3000\nD\nel\nay\n(in\n m\ns)\n(a) (b)\nFig. 5. (a) Raspberry PI units communicating wirelessly to their\nrespective neighbors, (b) Pairwise latency in communication channels\nbetween R-PI units and their respective neighbors.\n(see Figure 5(b)). Power reference commands are generated\nupon termination of Algorithm 1 at each R-PI unit based\non the user-specified threshold \u03c1. Figure 6 shows successive\nratio consensus cycles terminated using Algorithm 1 with\neach cycle taking about 30 iterations (Figure 7) for finite\ntime termination within the given threshold. Power reference\ncommands are then dispatched by each R-PI agent through\nSCI at every minute to the power electronics interface of the\nrespective LIS unit in Simulink. The LIS units inject power\ninto the network by following the reference power commands\nas shown in Figure 8. Figure 9 and Figure 10 demonstrate RES\nprioritization of LIS 2 and auto-adjustment of contributions\nfrom non-RES LIS units. It is evident that as more (less)\nenergy from RES LIS 2 becomes available in the network, in\norder to prioritize and consume all available solar energy from\nLIS 2, the non-RES units (LIS 1, 3, 4, 5 and 6) auto-adjust\nto increase (decrease) their power injection into the network\nbased on the ratio of their capacities. A total AC power output\nof the six LIS units is 7000 W \u00b1150 W (not exactly 7000 W\ndue to termination of the algorithm based on the threshold)\nat all instants as shown in Figure 11 which is equal to the\nancillary services demanded by the grid. The DC Link voltages\n0 1 2 3\nNumber of Cycles\n0\n1\n2\n3\n4\n5\nCo\nns\nen\nsu\ns \nra\ntio\n v\nal\nue\nAgent 1 Agent 2 Agent 3 Agent 4 Agent 5 Agent 6\nFig. 6. Successive cycles of R-PI agents showing convergence of\nconsensus ratio in finite time\n30 150 300 450 600 750\nConvergence Cycle\n0.8\n0.85\n0.9\n0.95\n1\nR\nat\nio\n V\nal\nue\nFig. 7. Converged ratio values of Non-RES LIS units demonstrating\nadjustment of contributions allowing RES penetration in the network\nwith higher priority.\n1 2 3 4 5 6 7 8\nTime (Hrs)\n0\n1000\n2000\nAg\nen\nt u\npd\nat\ne \nva\nlu\nes\n (W\n)\nAgent 1 Agent 2 Agent 3 Agent 4 Agent 5 Agent 6\nFig. 8. Updated pi\u2217 values for each R-PI agent after convergence\nof consensus iterations dispatched as Reference Power Commands to\nLIS unit.\nof all LIS units is observed to be within the safe limits at all\ntime.\nIn summary, we applied the algorithm proposed for coordi-\nnation of LIS units on hardware that communicate through\nwireless channels that suffers from uncertainties, such as\ndelays, to meet the grid demand. Thus, we now have a\ncoordination algorithm which is distributed and suitable for\nreal time application.\n6. CONCLUSION\nThis paper extends the results of finite-time termination\nof ratio consensus algorithm to an application of distributed\napportioning of load in the presence of communication delays\nfor providing demand response services requested by the\ngrid. The most notable result of this paper is the completely\nFig. 9. DC Power Output of each LIS unit and RES Prioritization of LIS 2\nby self-adjustment of contributions from non-RES LIS units.\nFig. 10. AC Side Power Composition of LIS Units\nFig. 11. Total power output from LIS units delivered in response to\nancillary services requested by the grid.\ndistributed nature of the resource apportioning algorithm,\nfrom selection of communication weights to the finite time\ntermination criteria. This framework enables unique and si-\nmultaneous, yet local and independent realization of power\nreference commands by the distributed control units and a\nsubsequent coordinated action. The algorithm proposed in this\npaper also enables prioritization of Renewable Energy Sources\navailable in the power network and auto-adjustment of energy\ncontributions from other non-RES units to allow for increased\nrenewable penetration. The proposed algorithm also performs\nefficiently with time-varying ancillary service requests of the\ngrid within the limits of convergence of each consensus cycle.\nThe efficacy of the algorithm is demonstrated by hardware-in-\nthe-loop experiments using a network of Raspberry Pi agents\nas distributed control units, which dispatch the power reference\ncommands generated by the resource apportioning algorithm\nto the local power electronics interface.\nACKNOWLEDGMENT\nThe authors acknowledge Advanced Research Projects\nAgency-Energy (ARPA-E) for supporting this research through\nthe project titled \u2018A Robust Distributed Framework for Flexible\nPower Grids\u2019 via grant no. DE-AR000071 and Xcel Energy\u2019s\nRenewable Development Fund.\nREFERENCES\n[1] R. H. Lasseter and P. Piagi, \u201cMicrogrid: A conceptual solution,\u201d in Proc.\nPower Electronics Specialists Conf, vol. Vol. 6, pp. 4285\u20134290, Aachen,\nGermany, Jun 2004.\n[2] G. Joos, B. T. Ooi, D. McGillis, F. D. Galiana, and R. Marceau, \u201cThe\npotential of distributed generation to provide ancillary services,\u201d Proc.\nIEEE Power Engineering Society Summer Meeting, vol. Vol. 3, pp.\n1762\u20131767, Seattle, 2000.\n[3] G. Pepermans, J. Driesen, D. Haeseldonckx, R. Belmans, and\nW. D\u2019haeseleer, \u201cDistributed generation: definition, benefits and issues,\u201d\nEnergy Policy, vol. 33, pp. 787\u2013798, April 2005.\n[4] E. Unamuno and J. A. Barrena, \u201cHybrid ac/dc microgrids part ii: Review\nand classification of control strategies,\u201d Renewable and Sustainable\nEnergy Reviews, vol. 52, pp. 1123\u20131134, 2015.\n[5] E. Planas, A. Gil-de Muro, J. Andreu, I. Kortabarria, and I. Martinez de\nAlegria, \u201cGeneral aspects, hierarchical controls and droop methods\nin microgrids: A review,\u201d Renewable and Sustainable Energy Review,\nvol. 17, pp. 147\u2013159, 2013.\n[6] A. D. Dominguez-Garcia and C. N. Hadjicostis, \u201cCoordination and con-\ntrol of distributed energy resources for provision of ancillary services,\u201d\nin Smart Grid Communications (SmartGridComm), 2010 First IEEE\nInternational Conference on. IEEE, 2010, pp. 537\u2013542.\n[7] S. T. Cady, A. D. Dom\u00ednguez-Garc\u00eda, and C. N. Hadjicostis, \u201cFinite-\ntime approximate consensus and its application to distributed frequency\nregulation in islanded ac microgrids,\u201d in System Sciences (HICSS), 2015\n48th Hawaii International Conference on. IEEE, 2015, pp. 2664\u20132670.\n[8] V. Yadav and M. V. Salapaka, \u201cDistributed protocol for determining\nwhen averaging consensus is reached,\u201d in 45th Annual Allerton Conf,\n2007, pp. 715\u2013720.\n[9] M. Prakash, S. Talukdar, S. Attree, S. Patel, and M. Salapaka, \u201cDis-\ntributed finite time termination of ratio consensus for averaging in the\npresence of delays,\u201d arXiv preprint arXiv:1704.08297, 2017.\n[10] J. W. Stahlhut, T. J. Browne, G. T. Heydt, and V. Vittal, \u201cLatency viewed\nas a stochastic process and its impact on wide area power system control\nsignals,\u201d IEEE Transactions on Power Systems, vol. 23, pp. 84\u201391, 2008.\n[11] R. Diestel, Graph theory {graduate texts in mathematics; 173}.\nSpringer-Verlag Berlin and Heidelberg GmbH & amp, 2000.\n[12] R. A. Horn and C. R. Johnson, Eds., Matrix Analysis. New York, NY,\nUSA: Cambridge University Press, 1986.\n[13] S. Salapaka, B. Johnson, B. Lundstrom, S. Kim, S. Collyer, and\nM. Salapaka, \u201cViability and analysis of implementing only voltage-\npower droop for parallel inverter systems,\u201d IEEE Conference on Decision\nand Control, vol. 53, no. 3, pp. 3246\u20133251, 2014.\n[14] M. Baranwal, S. Salapaka, and M. Salapaka, \u201cRobust decentralized\nvoltage control of dc-dc converters with applications to power sharing\nand ripple sharing,\u201d American Control Conference, pp. 7444\u20137449,\n2016.\n[15] C. N. Hadjicostis and T. Charalambous, \u201cAverage consensus in the\npresence of delays in directed graph topologies,\u201d IEEE Transactions\non Automatic Control, vol. 59, no. 3, pp. 763\u2013768, 2014.\n[16] M. Prakash, S. Talukdar, S. Attree, V. Yadav, and M. Salapaka, \u201cDis-\ntributed finite time termination of consensus in presence of delays,\u201d\nIEEE Transactions of Automatic Control (in review), (arXiv preprint\narXiv:1701.0002), 2016.\n[17] \u201cRaspberry pi 3 model b , https://www.raspberrypi.org/products/raspberry-\npi-3-model-b/.\u201d\n[18] M. J. Lee, J. Zheng, Y.-B. Ko, and D. M. Shrestha, \u201cEmerging standards\nfor wireless mesh technology,\u201d IEEE Wireless Communications, vol. 13,\nno. 2, pp. 56\u201363, 2006.\n[19] R. Faranda and S. Leva, \u201cEnergy comparison of mppt techniques for\npv systems,\u201d WSEAS transactions on power systems, vol. 3, no. 6, pp.\n446\u2013455, 2008.\n[20] N. Mohan and T. M. Undeland, Power electronics: converters, applica-\ntions, and design. John Wiley & Sons, 2007.\n[21] A. Kurniawan, Getting Started with Matlab Simulink and Raspberry Pi.\nPE Press, 2013.\n",
        "id": 44592086,
        "identifiers": [
          {
            "identifier": "93937478",
            "type": "CORE_ID"
          },
          {
            "identifier": "467399917",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:arxiv.org:1708.06414",
            "type": "OAI_ID"
          },
          {
            "identifier": "10.1109/smartgridcomm.2017.8340735",
            "type": "DOI"
          },
          {
            "identifier": "1708.06414",
            "type": "ARXIV_ID"
          }
        ],
        "title": "Distributed Apportioning in a Power Network for providing Demand\n  Response Services",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:arxiv.org:1708.06414"
        ],
        "publishedDate": "2017-08-21T01:00:00",
        "publisher": "",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://arxiv.org/abs/1708.06414"
        ],
        "updatedDate": "2021-08-10T09:38:22",
        "yearPublished": 2017,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "http://arxiv.org/abs/1708.06414"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/44592086"
          }
        ]
      },
      "relevance_score": 0.0665,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.3,
          "dimension_weight": 0.15,
          "weighted_score": 0.045,
          "matched_keywords_detail": {
            "der_automated_coordination_context": [
              "distributed energy resources"
            ]
          }
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.215,
          "dimension_weight": 0.1,
          "weighted_score": 0.0215,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2017 (Norm. Score: 0.2)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_secondary_6",
      "dynamic_step": 0,
      "core_id": 44592086,
      "doi": "10.1109/smartgridcomm.2017.8340735"
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": "1602.06347",
        "authors": [
          {
            "name": "Fioretto, Ferdinando"
          },
          {
            "name": "Pontelli, Enrico"
          },
          {
            "name": "Yeoh, William"
          }
        ],
        "citationCount": 0,
        "contributors": [],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/42683862"
        ],
        "createdDate": "2016-08-03T02:46:11",
        "dataProviders": [
          {
            "id": 144,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/144",
            "logo": "https://api.core.ac.uk/data-providers/144/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "The field of Multi-Agent System (MAS) is an active area of research within\nArtificial Intelligence, with an increasingly important impact in industrial\nand other real-world applications. Within a MAS, autonomous agents interact to\npursue personal interests and/or to achieve common objectives. Distributed\nConstraint Optimization Problems (DCOPs) have emerged as one of the prominent\nagent architectures to govern the agents' autonomous behavior, where both\nalgorithms and communication models are driven by the structure of the specific\nproblem. During the last decade, several extensions to the DCOP model have\nenabled them to support MAS in complex, real-time, and uncertain environments.\nThis survey aims at providing an overview of the DCOP model, giving a\nclassification of its multiple extensions and addressing both resolution\nmethods and applications that find a natural mapping within each class of\nDCOPs. The proposed classification suggests several future perspectives for\nDCOP extensions, and identifies challenges in the design of efficient\nresolution algorithms, possibly through the adaptation of strategies from\ndifferent areas",
        "documentType": "research",
        "doi": "10.1613/jair.5565",
        "downloadUrl": "http://arxiv.org/abs/1602.06347",
        "fieldOfStudy": "computer science",
        "fullText": "Journal of Artificial Intelligence Research 1 (1993) 1-15 Submitted 6/91; published 9/91\nDistributed Constraint Optimization Problems and Applications:\nA Survey\nFerdinando Fioretto FIORETTO@UMICH.EDU\nDepartment of Industrial and Operations Engineering\nUniversity of Michigan\nAnn Arbor, MI 48109, USA\nEnrico Pontelli EPONTELL@CS.NMSU.EDU\nDepartment of Computer Science\nNew Mexico State University\nLas Cruces, NM 88003, USA\nWilliam Yeoh WYEOH@WUSTL.EDU\nDepartment of Computer Science and Engineering\nWashington University in St. Louis\nSt. Louis, MO 63130, USA\nAbstract\nThe field of multi-agent system (MAS) is an active area of research within artificial intelligence,\nwith an increasingly important impact in industrial and other real-world applications. In a MAS,\nautonomous agents interact to pursue personal interests and/or to achieve common objectives. Dis-\ntributed Constraint Optimization Problems (DCOPs) have emerged as a prominent agent model to\ngovern the agents\u2019 autonomous behavior, where both algorithms and communication models are\ndriven by the structure of the specific problem. During the last decade, several extensions to the\nDCOP model have been proposed to enable support of MAS in complex, real-time, and uncertain\nenvironments.\nThis survey provides an overview of the DCOP model, offering a classification of its multiple\nextensions and addressing both resolution methods and applications that find a natural mapping\nwithin each class of DCOPs. The proposed classification suggests several future perspectives\nfor DCOP extensions, and identifies challenges in the design of efficient resolution algorithms,\npossibly through the adaptation of strategies from different areas.\n1. Introduction\nAn agent can be defined as an entity (or computer program) that behaves autonomously within an\narbitrary system in the pursuit of some goals (Wooldridge, 2009). A multi-agent system (MAS) is\na system where multiple agents interact in the pursuit of such goals. Within a MAS, agents may\ninteract with each other directly, via communication acts, or indirectly, by acting on the shared en-\nvironment. In addition, agents may decide to cooperate, to achieve a common goal, or to compete,\nto serve their own interests at the expense of other agents. In particular, agents may form coopera-\ntive teams, which can in turn compete against other teams of agents. Multi-agent systems play an\nc\u00a91993 AI Access Foundation. All rights reserved.\nar\nX\niv\n:1\n60\n2.\n06\n34\n7v\n4 \n [c\ns.A\nI] \n 11\n Ja\nn 2\n01\n8\nFIORETTO, PONTELLI, & YEOH\nimportant role in distributed artificial intelligence, thanks to their ability to model a wide variety\nof real-world scenarios, where information and control are decentralized and distributed among a\nset of agents.\nFigure 1 illustrates a MAS example. It represents a sensor network where a group of agents,\nequipped with sensors, seeks to determine the position of some targets. Agents may interact with\neach other and move away from the current position. The figure depicts the targets as star-shaped\nobjects. The dotted lines define an interaction graph and the directional arrows illustrate agents\u2019\nmovements. In addition, various events that obstruct the sensors of an agent may dynamically\noccur. For instance, the presence of an obstacle along the agent\u2019s sensing range may be detected\nafter the agent\u2019s movement.\nWithin a MAS, an agent is:\n\u2022 Autonomous, as it operates without the direct intervention of humans or other entities and has\nfull control over its own actions and internal state (e.g., in the example, an agent can decide to\nsense, to move, etc.);\n\u2022 Interactant, in the sense that it interacts with other agents in order to achieve its objectives\n(e.g., in the example, agents may exchange information concerning results of sensing activities);\n\u2022 Reactive, as it responds to changes that occur in the environment and/or to the requests from\nother agents (e.g., in the example, agents may react with a move action to the sudden appearance\nof obstacles).\n\u2022 Proactive, because of its goal-driven behavior, which allows the agent to take initiatives beyond\nthe reactions in response to its environment.\nAgent architectures are the fundamental mechanisms un-\nderlying the autonomous agent components, supporting their\nbehavior in real-world, dynamic, and uncertain environments.\nAgent architectures based on decision theory, game theory,\nand constraint programming have successfully been developed\nand are popular in the Autonomous Agents and Multi-Agent\nSystems (AAMAS) community.\nDecision theory (Raiffa, 1968) assumes that the agent\u2019s ac-\ntions and the environment are inherently uncertain and mod-\nels such uncertainty explicitly. Agents acting in complex\nand dynamic environments are required to deal with various\nsources of uncertainty. The Decentralized Partially Observ-\nable Markov Decision Processes (Dec-POMDPs) framework\n(Bernstein, Givan, Immerman, & Zilberstein, 2002) is one of\nthe most general multi-agent frameworks, focused on team co-\nordination in presence of uncertainty about agents\u2019 actions and\na2\na1\na2\na4\n? ?\nFigure 1: Illustration of a multi-\nagent system: Sensors (agents)\nseek to determine the position of\nthe targets.\nobservations. The ability to capture a wide range of complex scenarios makes Dec-POMDPs of\ncentral interest within MAS research. However, the result of this generality is a high complexity for\ngenerating optimal solutions. Dec-POMDPs are non-deterministic exponential (NEXP) complete\n2\nDCOP: MODEL AND APPLICATIONS SURVEY\n(Bernstein et al., 2002), even for two-agent problems, and scalability remains a critical challenge\n(Amato, Chowdhary, Geramifard, Ure, & Kochenderfer, 2013).\nGame theory (Binmore, 1992) studies interactions between self-interested agents, aiming at\nmaximizing the welfare of the participants. Some of the most compelling applications of game\ntheory to MAS have been in the area of auctions and negotiations (Kraus, 1997; Noriega & Sierra,\n1999; Parsons & Wooldridge, 2002). These approaches model the trading process by which agents\ncan reach agreements on matters of common interest, using market oriented and cooperative mech-\nanisms, such as reaching Nash equilibria. Typical resolution approaches aim at deriving a set of\nequilibrium strategies for each agent, such that, when these strategies are employed, no agent can\nprofit by unilaterally deviating from their strategies. A limitation of game theoretical-based ap-\nproaches is the lack of an agent\u2019s ability to reason upon a global objective, as the underlying model\nrelies on the interactions of self-interested agents.\nConstraint programming (Rossi, Beek, & Walsh, 2006) aims at solving decision-making prob-\nlems formulated as optimization problems of some real-world objective. Constraint programs use\nthe notion of constraints \u2013 i.e., relations among entities of the problems (variables) \u2013 in both prob-\nlem modeling and problem solving. Constraint programming relies on inference techniques that\nprevent the exploration of those parts of the solution search space whose assignments to variables\nare inconsistent with the constraints and/or dominated with respect to the objective function. Dis-\ntributed Constraint Optimization Problems (DCOPs) (Modi, Shen, Tambe, & Yokoo, 2005; Petcu\n& Faltings, 2005b; Gershman, Meisels, & Zivan, 2009; Yeoh & Yokoo, 2012) are problems where\nagents need to coordinate their value assignments, in a decentralized manner, to optimize their\nobjective functions. DCOPs focus on attaining a global optimum given the interaction graph of a\ncollection of agents. This approach can be effectively used to model a wide range of problems.\nProblem solving and communication strategies are directly linked in DCOPs. This feature makes\nthe algorithmic components of a DCOP suitable for exploiting the structure of the interaction graph\nof the agents to generate efficient solutions.\nThe absence of a framework to model dynamic problems and uncertainty makes DCOPs un-\nsuitable at solving certain classes of multi-agent problems, such as those characterized by action\nuncertainty and dynamic environments. However, since its original introduction, the DCOP model\nhas undergone a process of continuous evolution to capture diverse characteristics of agent behav-\nior and the environment in which they operate. Researchers have proposed a number of DCOP\nframeworks that differ from each other in terms of expressiveness and classes of problem they can\ntarget, extending the DCOP model to handle both dynamic and uncertain environments. However,\ncurrent research has not explored how the different DCOP frameworks relate to each other within\nthe general MAS context, which is critical to understand: (i) What resolution methods could be\nborrowed from other MAS paradigms, and (ii) What applications can be most effectively mod-\neled within each framework. While there are important existing surveys for Distributed Constraint\nSatisfaction (Yokoo & Hirayama, 2000) and Distributed Constraint Optimization (Meisels, 2008),\nthis survey aims to comprehensively analyze and categorize the different DCOP frameworks pro-\nposed by the MAS community. We do so by presenting an extensive review of the DCOP model\nand its extensions, the different resolution methods, as well as a number of applications modeled\n3\nFIORETTO, PONTELLI, & YEOH\nList of key symbols\nai Agent pi(\u00b7) Projection operator\nxi Decision variable pi(\u00b7) Probability function\nri Random variable Lai ai\u2019s local variables\nDi Domain of xi Nai ai\u2019s neighbors\n\u2126i Event space of ri Cai ai\u2019s children\nfi Cost function PCi ai\u2019s pseudo-children\nxi Scope of fi Pai ai\u2019s parent\nm Number of agents PPai ai\u2019s pseudo-parents\nn Number of variables \u03b1(fi) Agents whose variables are in xi\nq Number of random variables EC Set of edges of the constraint graph\nk Number of cost functions ET Tree edges of the pseudo-tree\nd Size of the largest domain EF Set of edges of the factor graph\nFg Global objective function w\u2217 Induced width of the pseudo-tree\n~F Vector of objective functions l Size of the largest neighborhood\nFi Objective function in ~F z Size of the largest local variable set\n~F\u25e6 Utopia point s Maximal sample size\n\u22a5 Infeasible value p Size of the Pareto set\n\u03c3 Complete assignment b Size of the largest bin\n\u03c3V Partial assignment for the variables in V \u2286 X ` Number of iterations of the algorithm\n\u03a3 State space\nTable 1: Commonly Used Symbols and Notations\nwithin each particular DCOP extension. This analysis also provides opportunities to identify open\nchallenges and discuss future directions in the general DCOP research area.\nThis survey paper is organized as follows. The next section provides an overview on two rel-\nevant constraint satisfaction models and their generalization to the distributed cases. Section 3\nintroduces DCOPs, overviews the representation and coordination models adopted during the res-\nolution of DCOPs, and it proposes a classification of the different variants of DCOPs based on the\ncharacteristics of the agents and the environment. Section 4 presents the classical DCOP model as\nwell as two notable extensions: One characterized by asymmetric cost functions and another by\nmulti-objective optimization. Section 5 presents a DCOP model where the environment changes\nover time. Section 6 discusses DCOP models in which agents act under uncertainty and may have\npartial knowledge of the environment in which they act. Section 7 discusses DCOP models in\nwhich agents are non-cooperative. For each of these models, the paper introduces their formal\ndefinitions, discusses related concepts, and describes several resolution algorithms. A summary of\nthe various classes of problems discussed in this survey is given in Table 6. Section 8 describes\na number of applications that have been proposed in the DCOP literature. Section 9 provides a\ncritical review on the DCOP variants surveyed and focuses on their applicability in various set-\ntings. Additionally, it describes some potential future directions for research. Finally, Section 10\nprovides concluding remarks. To facilitate the reading of this survey, Table 1 summarizes the most\ncommonly used symbols and notations.\n4\nDCOP: MODEL AND APPLICATIONS SURVEY\n2. Overview of (Distributed) Constraint Satisfaction and Optimization\nThis section provides an overview of several constraint satisfaction models, which form the foun-\ndation of DCOPs. Figure 2 illustrates the relations among these models.\n2.1 Constraint Satisfaction Problems\nConstraint Satisfaction Problems (CSPs) (Golomb & Baumert, 1965; Mackworth & Freuder, 1985;\nApt, 2003; Rossi et al., 2006) are decision problems that involve the assignment of values to vari-\nables, under a set of specified constraints on how variable values should be related to each other. A\nnumber of problems can be formulated as CSPs, including resource allocation, vehicle routing, cir-\ncuit diagnosis, scheduling, and bioinformatics. Over the years, CSPs have become the paradigm of\nchoice to address difficult combinatorial problems, drawing and integrating insights from diverse\ndomains, including artificial intelligence and operations research (Rossi et al., 2006).\nA CSP is a tuple \u3008X,D,C\u3009, where:\n\u2022 X={x1, . . . , xn} is a finite set of variables.\n\u2022 D = {D1, . . . , Dn} is a set of finite domains for the variables in X, with Di being the set of\npossible values for the variable xi.\n\u2022 C is a finite set of constraints over subsets ofX, where a constraint ci, defined on the k variables\nxi1 , . . . , xik , is a relation ci \u2286 \"kj=1Dij , where {i1, . . . , ik} \u2286 {1, . . . , n}. The set of variables\nxi = {xi1 , . . . , xik} is referred to as the scope of ci.1 ci is called a unary constraint if k = 1 and\na binary constraint if k = 2. For all other values of k, the constraint is called a k-ary constraint.2\nA partial assignment is a value assignment for a proper subset of variables from X that is\nconsistent with their respective domains, i.e., it is a partial function \u03c3 : X \u2192 \u22c3ni=1Di such that,\nfor each xj \u2208 X, if \u03c3(xj) is defined, then \u03c3(xj) \u2208 Dj . An assignment is complete if it assigns\na value to each variable in X. The notation \u03c3 is used to denote a complete assignment, and, for a\nset of variables V = {xi1 , . . . , xih} \u2286 X, \u03c3V = \u3008\u03c3(xi1), . . . , \u03c3(xih)\u3009 to denote the projection of\nthe values in \u03c3 associated to the variables in V, where i1 < \u00b7 \u00b7 \u00b7 < ih. The goal in a CSP is to find\na complete assignment \u03c3 such that, for each ci \u2208 C, \u03c3xi \u2208 ci, that is, a complete assignment that\nsatisfies all the problem constraints. Such a complete assignment is called a solution of the CSP.\n2.2 Weighted Constraint Satisfaction Problems\nA solution of a CSP must satisfy all of its constraints. In many practical cases, however, it is\ndesirable to consider complete assignments whose constraints can be violated according to a vio-\nlation degree. The Weighted Constraint Satisfaction Problem (WCSP) (Shapiro & Haralick, 1981;\nLarrosa, 2002) was introduced to capture this property. WCSPs are problems whose constraints\nare considered as preferences that specify the extent of satisfaction (or violation) of the associated\nconstraint.\n1. The presence of a fixed ordering of variables is assumed.\n2. A constraint with k = 3 is also called a ternary constraint and a constraint with k = n is also called a global\nconstraint.\n5\nFIORETTO, PONTELLI, & YEOH\nCSP\nCOP\nDisCSP\nDCOP\nExtends to\nExtends to\n(distributed)\n(distributed)\nGeneralizes to Generalizes to\nFigure 2: DCOP Problems as a Generalization and Extension of Constraint Satisfaction Problems\nA WCSP is a tuple \u3008X,D,F\u3009, where X and D are the set of variables and their domains as\ndefined in a CSP, and F is a set of weighted constraints. A weighted constraint fi \u2208 F is a function\nfi : \"xj\u2208xi Dj \u2192 R+ \u222a {\u22a5}, where xi \u2286 X is the scope of fi and \u22a5 is a special element used\nto denote that a given combination of values for the variables in xi is not allowed, and it has the\nproperty that a+\u22a5 = \u22a5+ a = \u22a5, for all a \u2208 R+. The cost of an assignment \u03c3 is the sum of the\nevaluation of the constraints involving all the variables in \u03c3. A solution is a complete assignment\nwith cost different from \u22a5, and an optimal solution is a solution with minimal cost.\nThus, a WCSP is a generalization of a CSP which, in turn, can be seen as a WCSP whose\nconstraints use exclusively the costs 0 and \u22a5. The terms WCSP and Constraint Optimization\nProblem (COP) have been used interchangeably in the literature and the use of the latter term has\nbeen widely adopted in the recent years.\n2.3 Distributed Constraint Satisfaction Problems\nWhen the elements of a CSP are distributed among a set of autonomous agents, the resulting model\nis referred to as a Distributed Constraint Satisfaction Problem (DisCSP) (Yokoo, Durfee, Ishida, &\nKuwabara, 1998; Yokoo, 2001). A DisCSP is a tuple \u3008A,X,D,C, \u03b1\u3009, where X, D, and C are the\nset of variables, their domains, and the set of constraints, as defined in a CSP; A= {a1, . . . , am}\nis a finite set of autonomous agents; and \u03b1 : X \u2192 A is a surjective function, from variables to\nagents, which assigns the control of each variable x \u2208 X to an agent \u03b1(x). The goal in a DisCSP\nis to find a complete assignment that satisfies all the constraints of the problem.\nDisCSPs can be seen as an extension of CSPs to the multi-agent case, where agents communi-\ncate with each other to assign values to the variables they control so as to satisfy all the problem\nconstraints. For a survey on the topic, the interested reader is referred to (Rossi et al., 2006) (Chap-\nter 20).\n6\nDCOP: MODEL AND APPLICATIONS SURVEY\nELEMENT CHARACTERIZATION\nAGENT(S) BEHAVIOR Deterministic StochasticKNOWLEDGE Total Partial\nTEAMWORK Cooperative Competitive\nENVIRONMENT BEHAVIOR Deterministic StochasticEVOLUTION Static Dynamic\nTable 2: DCOP Classification Elements\n2.4 Distributed Constraint Optimization Problems\nSimilar to the generalization of CSPs to COPs, the Distributed Constraint Optimization Problem\n(DCOP) model (Modi et al., 2005; Petcu & Faltings, 2005b; Gershman et al., 2009; Yeoh &\nYokoo, 2012) emerges as a generalization of the DisCSP model, where constraints specify a degree\nof preference over their violation, rather than a Boolean satisfaction metric. DCOPs can also\nbe viewed as an extension of the COP framework to the multi-agent case, where agents control\nvariables and constraints, and need to coordinate the value assignment for the variables they control\nso as to optimize a global objective function. The DCOP framework is formally introduced in the\nnext section.\n3. DCOP Classification\nThe DCOP model has undergone a process of continuous evolution to capture diverse character-\nistics of the agent behavior and the environment in which agents operate. This section proposes a\nclassification of DCOP models from a multi-agent systems perspective. It accounts for the differ-\nent assumptions made about the behavior of the agents and their interactions with the environment.\nThe classification is based on the following elements (summarized in Table 2):\n\u2022 Agent Behavior: This parameter captures the stochastic nature of the effects of an action being\nexecuted. These effects can be either deterministic or stochastic.\n\u2022 Agent Knowledge: This parameter captures the knowledge of an agent about its own state and\nthe environment. It can be total or partial (i.e., incomplete).\n\u2022 Agent Teamwork: This parameter characterizes the approach undertaken by (teams of) agents\nto solve a distributed problem. It can be either a cooperative or a competitive resolution approach.\nIn the former class, all agents cooperate to achieve a common goal (i.e., they all optimize a global\nobjective function). In the latter class, each agent (or team of agents) seeks to achieve its own\nindividual goal (i.e., each agent optimizes its individual objective functions).\n\u2022 Environment Behavior: This parameter captures the exogenous properties of the environment.\nThe response of the environment to the execution of an action can be either deterministic or\nstochastic.\n\u2022 Environment Evolution: This parameter captures whether the DCOP does not change over time\n(static) or it changes over time (dynamic).\n7\nFIORETTO, PONTELLI, & YEOH\nE\nnv\nir\non\nm\nen\nt\nE\nvo\nlu\ntio\nn\nEnvironment Behavior\nDETERMINISTIC STOCHASTIC\nSTATIC Classical DCOP Probabilistic DCOP\nDYNAMIC Dynamic DCOP \u2014\nTable 3: DCOPs Models\nGame Theory\nDecision \nTheory\nConstraint \nProgramming\nClassical DCOP\nAsymmetric DCOP\nMulti-Objective DCOP\nAuction       Negotiation\nMMDP\nDec-MDP\nDec-POMDP\nDynamic DCOP Probabilistic DCOP\nDynamic\nAsymmetric DCOP\nDynamic\nMulti-Objective DCOP\nFigure 3: DCOPs Within a MAS Perspective\nFigure 3 illustrates a categorization of the DCOP models proposed to date from a MAS perspec-\ntive. This survey focuses on the DCOP models proposed at the junction of constraint programming,\ngame theory, and decision theory. The classical DCOP model is directly inherited from constraint\nprogramming as it extends the WCSP model to a distributed setting. It is characterized by a static\nmodel, a deterministic environment and agent behavior, a total agent knowledge, and a cooperative\nagent teamwork. Game theoretical concepts explored in the context of auctions and negotiations\nhave influenced the DCOP framework leading to the development of the Asymmetric DCOP and\nthe Multi-Objective DCOP. The DCOP framework has also borrowed fundamental decision theo-\nretical concepts related to modeling uncertain and dynamic environments, resulting in models like\nthe Probabilistic DCOP and the Dynamic DCOP. Researchers from the DCOP community have\nalso designed solutions that inherit from all of the three communities.\nThe next sections describe the different DCOP frameworks, starting with classical DCOPs be-\nfore proceeding to its various extensions. The survey focuses on a categorization based on three\ndimensions: Agent knowledge, environment behavior, and environment evolution. It assumes a de-\nterministic agent behavior, a fully cooperative agent teamwork, and a total agent knowledge (unless\notherwise specified), as they are, by far, common assumptions adopted by the DCOP community.\nThe DCOP models associated to this categorization are summarized in Table 3. The bottom-right\nentry of the table is left empty, indicating a promising model with dynamic and uncertain environ-\nments that, to the best of our knowledge, has not been explored yet. There has been only a modest\namount of effort in modeling the different aspects of teamwork within the DCOP community. Sec-\ntion 7 describes a formalism that has been adopted to model DCOPs with mixed cooperative and\ncompetitive agents.\n8\nDCOP: MODEL AND APPLICATIONS SURVEY\n4. Classical DCOP\nWith respect to the proposed categorization, in the classical DCOP model (Modi et al., 2005; Petcu\n& Faltings, 2005b; Gershman et al., 2009; Yeoh & Yokoo, 2012) the agents are fully cooperative\nand have deterministic behavior and total knowledge. Additionally, the environment is static and\ndeterministic. This section reviews the formal definitions of classical DCOPs, presents some rele-\nvant solving algorithms, and provides details of selected variants of classical DCOPs of particular\ninterest.\n4.1 Definition\nA classical DCOP is described by a tuple P = \u3008A,X,D,F, \u03b1\u3009, where:\n\u2022 A={a1, . . . , am} is a finite set of agents.\n\u2022 X={x1, . . . , xn} is a finite set of variables, with n \u2265 m.\n\u2022 D={D1, . . . , Dn} is a set of finite domains for the variables in X, with Di being the domain of\nvariable xi.\n\u2022 F={f1, . . . , fk} is a finite set of cost functions, with fi : \"xj\u2208xi Dj \u2192 R+\u222a{\u22a5}, where similar\nto WCSPs, xi \u2286 X is the set of variables relevant to fi, referred to as the scope of fi. The arity\nof a cost function is the number of variables in its scope. Each cost function fi represents a factor\nin a global objective function Fg(X) =\n\u2211k\ni=1 fi(x\ni). In the DCOP literature, the cost functions\nfi are also called constraints, utility functions, or reward functions.\n\u2022 \u03b1 : X \u2192 A is a total and onto function, from variables to agents, which assigns the control of\neach variable x \u2208 X to an agent \u03b1(x).\nWith a slight abuse of notation, \u03b1(fi) will be used to denote the set of agents whose variables\nare involved in the scope of fi, i.e., \u03b1(fi) = {\u03b1(x) | x \u2208 xi}. A partial assignment is a value\nassignment for a proper subset of variables of X. An assignment is complete if it assigns a value to\neach variable in X. For a given complete assignment \u03c3, we say that a cost function fi is satisfied\nby \u03c3 if fi(\u03c3xi) 6= \u22a5. A complete assignment is a solution of a DCOP if it satisfies all its cost\nfunctions. The goal in a DCOP is to find a solution that minimizes the total problem cost expressed\nby its cost functions:3\n\u03c3\u2217 := argmin\n\u03c3\u2208\u03a3\nFg(\u03c3) = argmin\n\u03c3\u2208\u03a3\n\u2211\nfi\u2208F\nfi(\u03c3xi), (1)\nwhere \u03a3 is the state space, defined as the set of all possible solutions.\nGiven an agent ai, Lai = {xj \u2208 X | \u03b1(xj) = ai} denotes the set of variables controlled by\nagent ai, or its local variables, and Nai = {a\u2032i \u2208 A | ai 6= a\u2032i, \u2203fj \u2208 F, xr, xs \u2208 xj , \u03b1(xr) =\nai \u2227 \u03b1(xs) =a\u2032i} denotes the set of its neighboring agents. A cost function fi is said to be hard if\n\u2200\u03c3 \u2208 \u03a3 we have that fi(\u03c3xi) \u2208 {0,\u22a5}. Otherwise, the cost function is said to be soft.\n3. Alternatively, one can define a maximization problem by substituting the argmin operator in Equation 1 with\nargmax. Typically, if the objective functions are referred to as utility functions or reward functions, then the DCOP\nis a maximization problem. Conversely, if the objective functions are referred to as cost functions, then the DCOP\nis a minimization problem.\n9\nFIORETTO, PONTELLI, & YEOH\nFinding an optimal solution for a classical DCOP is known to be NP-hard (Modi et al., 2005).\n4.2 DCOP: Representation and Coordination\nRepresentation in DCOPs plays a fundamental role, both from an agent coordination perspective\nand from an algorithmic perspective. This section discusses the most predominant representations\nadopted in various DCOP algorithms. It starts by describing some widely adopted assumptions\nregarding agent knowledge and coordination, which will apply throughout this document, unless\notherwise stated:\n(i) A variable and its domain are known exclusively to the agent controlling it and its neighboring\nagents.\n(ii) Each agent knows the values of the cost function involving at least one of its local variables.\nNo other agent has knowledge about such cost function.\n(iii) Each agent knows (and it may communicate with) exclusively its own neighboring agents.\n4.2.1 CONSTRAINT GRAPH\nGiven a DCOP P , GP = (X, EC) is the constraint graph of P , where an undirected edge {x, y} \u2208\nEC exists if and only if there exists fj \u2208 F such that {x, y} \u2286 xj . A constraint graph is a standard\nway to visualize a DCOP instance. It underlines the agents\u2019 locality of interactions and therefore it\nis commonly adopted by DCOP resolution algorithms.\nGiven an ordering o onX, a variable xi is said to have a higher priority with respect to a variable\nxj if xi appears before xj in o. Given a constraint graph GP and an ordering o on its nodes, the\ninduced graph G\u2217P on o is the graph obtained by connecting nodes, processed in increasing order\nof priority, to all their higher-priority neighbors. For a given node, the number of higher-priority\nneighbors is referred to as its width. The induced width w\u2217o of GP is the maximum width over all\nthe nodes of G\u2217P on ordering o.\nFigure 4(a) shows an example constraint graph of a DCOP with four agents a1 through a4, each\ncontrolling one variable with domain {0,1}. There are two cost functions: a k-ary cost function\nf123 with scope x123 = {x1, x2, x3} and represented by a clique among x1, x2, and x3; and a\nbinary cost function f24 with scope x24 = {x2, x4}.\n4.2.2 PSEUDO-TREE\nA number of DCOP algorithms require a partial ordering among the agents. In particular, when\nsuch an order is derived from a depth-first search (DFS) exploration, the resulting structure is\nknown as a (DFS) pseudo-tree. A pseudo-tree arrangement for a DCOP P is a subgraph TP =\n\u3008X, ET \u3009 ofGP such that TP is a spanning tree ofGP \u2013 i.e., a connected subgraph ofGP containing\nall the nodes and being a rooted tree \u2013 with the following additional condition: for each x, y \u2208 X,\nif {x, y} \u2286 xi for some fi \u2208 F, then x, y appear in the same branch of TP (i.e., x is an ancestor\nof y in TP or vice versa). Edges of GP that are in (respectively out of) ET are called tree edges\n(respectively backedges). The tree edges connect parent-child nodes, while backedges connect\n10\nDCOP: MODEL AND APPLICATIONS SURVEY\na4\na2\na1\na3\nx1\nx2 x3\nx4\nx1\nx2\nx3x4\na3\na2\na4\na1\nx1\nx2\nx4f24\nx3f123\na4\na3a2\na1\n(a) Constraint Graph (b) Pseudo-Tree (c) Factor Graph\nFigure 4: DCOP Representations\na node with its pseudo-parents and its pseudo-children. The separator of an agent ai is the set\ncontaining all the ancestors of ai in the pseudo-tree (through tree edges or backedges) that are\nconnected to ai or to one of its descendants. The notation Cai , PCai , Pai , and PPai will be used\nto indicate the set of children, pseudo-children, parent, and pseudo-parents of the agent ai.\nBoth constraint graph and pseudo-tree representations cannot deal explicitly with k-ary cost\nfunctions (with k > 2). A typical artifact to deal with such cost functions in a pseudo-tree repre-\nsentation is to introduce a virtual variable that monitors the value assignments for all the variables\nin the scope of the cost function, and generates the cost values (Bowring, Tambe, & Yokoo, 2006)\n\u2013 the role of the virtual variables can be delegated to one of the variables participating in the cost\nfunction (Pecora, Modi, & Scerri, 2006; Matsui, Matsuo, Silaghi, Hirayama, & Yokoo, 2008).\nFigure 4(b) shows one possible pseudo-tree of the example DCOP in Figure 4(a), where Ca1 =\n{x2}, PCa1 ={x3}, Pa4 ={x2}, and PPa3 ={x1}. The solid lines are tree edges and dotted lines\nare backedges.\n4.2.3 FACTOR GRAPH\nAnother way to represent DCOPs is through a factor graph (Kschischang, Frey, & Loeliger, 2001).\nA factor graph is a bipartite graph used to represent the factorization of a function. In particular,\ngiven the global objective function Fg, the corresponding factor graph FP = \u3008X,F, EF \u3009 is com-\nposed of variable nodes xi \u2208 X, factor nodes fj \u2208 F, and edgesEF such that there is an undirected\nedge between factor node fj and variable node xi if xi \u2208 xj .\nFactor graphs can handle k-ary cost functions explicitly. To do so, they use a similar method\nas the one adopted within pseudo-trees with such cost functions: They delegate the control of a\nfactor node to one of the agents controlling a variable in the scope of the cost function. From an\nalgorithmic perspective, the algorithms designed over factor graphs can directly handle k-ary cost\nfunctions, while algorithms designed over pseudo-trees require changes in the algorithm design so\nto delegate the control of the k-ary cost functions to some particular entity.\n11\nFIORETTO, PONTELLI, & YEOH\nFigure 4(c) shows the factor graph of the example DCOP in Figure 4(a), where each agent ai\ncontrols its variable xi and, in addition, a3 controls the cost function f123 and a4 controls cost\nfunction f24.\n4.3 Algorithms\nThe field of classical DCOPs is mature and a number of different resolution algorithms have been\nproposed. DCOP algorithms can be classified as being either complete or incomplete, based on\nwhether they can guarantee the optimal solution or they trade optimality for shorter execution\ntimes, producing near-optimal solutions. They can also be characterized based on their runtime\ncharacteristics, their memory requirements, and their communication requirements (e.g., the num-\nber and size of messages that they send and whether they communicate with their neighboring\nagents only or also to non-neighboring agents). Table 4 tabulates the properties of a number of key\nDCOP algorithms that will be surveyed in Sections 4.3.4 and 4.3.5. An algorithm is said anytime\nif it can return a valid solution even if the DCOP agents are interrupted at any time before the\nalgorithm terminates. Anytime algorithms are expected to seek for solutions of increasing quality\nas they keep running (Zivan, Okamoto, & Peled, 2014).\nAll these algorithms were originally developed under the assumption that each agent controls\nexactly one variable. The description of their properties will follow the same assumption. These\nproperties may change when generalizing the algorithms to allow for agents to control multiple\nvariables, but they will depend on how the algorithms are generalized. Throughout this document,\nthe following notation will be often adopted when discussing the complexity of the algorithms:\n\u2022 n = |X| refers to the number of variables in the problem; in Table 4, n also refers to the number\nof agents in the problem since each agent has exactly one variable;\n\u2022 d = maxDi\u2208D |Di| refers to the size of the largest domain;\n\u2022 w\u2217 refers to the induced width of the pseudo-tree;\n\u2022 l = maxai\u2208A |Nai | refers to the largest number of neighboring agents; and\n\u2022 ` refers to the number of iterations in incomplete algorithms.\nIn addition, each of these classes can be categorized into several groups, depending on the\ndegree of locality exploited by the algorithms, the way local information is updated, and the type\nof exploration process adopted. These different categories are described next.\n4.3.1 PARTIAL CENTRALIZATION\nIn general, the DCOP solving process is decentralized, driving DCOP algorithms to follow the\nagent knowledge and communication restrictions described in Section 4.2. However, some algo-\nrithms explore methods to centralize the decisions to be taken by a group of agents, by delegating\nthem to one of the agents in the group. These algorithms explore the concept of partial central-\nization (Hirayama & Yokoo, 1997; Mailler & Lesser, 2004; Petcu, Faltings, & Mailler, 2007),\nand thus they are classified as partially centralized algorithms. Typically, partial centralization\nimproves the algorithms\u2019 performance allowing agents to coordinate their local assignments more\n12\nDCOP: MODEL AND APPLICATIONS SURVEY\nAlgorithm\nQuality Characteristics Runtime Characteristics Memory Communication Characteristics\nOptimal? Error Bound? Complexity Anytime? per Agent # Messages Message Size Local Communication?\nSyncBB O(dn) O(n) O(dn) O(n) \u00d7\nAFB O(dn) O(n) O(dn) O(n) \u00d7\nADOPT O(dn) \u00d7 O(n+ld) O(dn) O(n)\nConcFB O(dn) O(n) O(dn) O(n) \u00d7\nDPOP O(dw\n\u2217\n) \u00d7 O(dw\u2217) O(n) O(dw\u2217)\nOptAPO O(dn) \u00d7 O(ld) O(dn) O(d+n) \u00d7\nMax-Sum \u00d7 \u00d7 O(`d l) \u00d7 O(d l) O(`nl) O(d)\nRegion Optimal \u00d7 O(`dw\u2217) O(dw\u2217) O(`n2) O(dw\u2217) \u00d7\nMGM \u00d7 \u00d7 O(`ld) O(l) O(`nl) O(1)\nDSA \u00d7 \u00d7 O(`ld) O(l) O(`nl) O(1)\nDUCT \u00d7 O(`ld) O(dw\u2217) O(`n) O(n)\nD-Gibbs \u00d7 O(`ld) O(l) O(`nl) O(1)\nTable 4: Quality, Runtime, Memory, and Communication Characteristics of DCOP Algorithms\nefficiently. However, such performance enhancement comes with a loss of information privacy, as\nthe centralizing agent needs to be granted access to the local subproblem of other agents in the\ngroup (Greenstadt, Grosz, & Smith, 2007; Mailler & Lesser, 2004). In contrast, fully decentralized\nalgorithms inherently reduce the amount of information privacy at cost of a larger communication\neffort.\n4.3.2 SYNCHRONICITY\nDCOP algorithms can enhance their effectiveness by exploiting distributed and parallel processing.\nBased on the way the agents update their local information, DCOP algorithms are classified as\nsynchronous or asynchronous. Asynchronous algorithms allow agents to update the assignment\nfor their variables based solely on their local view of the problem, and thus independently from\nthe actual decisions of the other agents (Modi et al., 2005; Farinelli, Rogers, Petcu, & Jennings,\n2008; Gershman et al., 2009). In contrast, synchronous algorithms constrain the agents decisions\nto follow a particular order, typically enforced by the representation structure adopted (Mailler &\nLesser, 2004; Petcu & Faltings, 2005b; Pearce & Tambe, 2007).\nSynchronous algorithms tend to delay the actions of some agents guaranteeing that their local\nview of the problem is always consistent with that of the other agents. In contrast, asynchronous\nalgorithms tend to minimize the idle-time of the agents, which in turn can react quickly to each\nmessage being processed; however, they provide no guarantee on the consistency of the state of\nthe local view of each agent. Such effect has been studied by Peri and Meisels (2013), concluding\nthat inconsistent agents\u2019 views may cause a negative impact on network load and algorithm perfor-\nmance, and that introducing some level of synchronization may be beneficial for some algorithms,\nenhancing their performance.\n4.3.3 EXPLORATION PROCESS\nThe resolution process adopted by each algorithm can be classified in three categories (Yeoh, 2010):\n13\nFIORETTO, PONTELLI, & YEOH\nComplete\nDecentralized\nSynchronous Asynchronous\nSearch Inference Search\nSyncBB DPOP and\nvariants\nAFB; ConcFB;\nADOPT and \nvariants \nPartially \nCentralized\nInference\nPC-DPOP\nSynchronous Asynchronous\nSearch\nOptAPO\nIncomplete\nDecentralized\nSynchronous\nSearch\nDSA;  MGM DUCT;\nD-Gibbs\nSamplingInference\nMax-Sum and\nvariants\nRegion Optimal\n(k-OPT, t-OPT)\nPartially \nCentralized\nSynchronous Asynchronous\nSearch\nDALO\nSearch\nFigure 5: Classical DCOP Algorithm Taxonomy\n\u2022 Search-based algorithms are based on the use of search techniques to explore the space of pos-\nsible solutions. These algorithms are often derived from corresponding search techniques devel-\noped for centralized AI search problems, such as best-first search and depth-first search.\n\u2022 Inference-based algorithms are derived from dynamic programming and belief propagation tech-\nniques. These algorithms allow agents to exploit the structure of the constraint graph to aggregate\ncosts from their neighbors, effectively reducing the problem size at each step of the algorithm.\n\u2022 Sampling-based algorithms are incomplete approaches that sample the search space to approxi-\nmate a function (typically, a probability distribution) as a product of statistical inference.\nFigure 5 illustrates a taxonomy of classical DCOP algorithms. The following subsections\nsummarize some representative complete and incomplete algorithms from each of the classes\nintroduced above. A detailed description of the DCOP algorithms is beyond the scope of this\nmanuscript. The interested reader is referred to the original articles that introduce each algorithm.\n14\nDCOP: MODEL AND APPLICATIONS SURVEY\n4.3.4 COMPLETE ALGORITHMS\nSome of the algorithms described below were originally designed to solve the variant of DCOPs\nthat maximizes rewards, while others solve the variant that minimizes costs. However, the algo-\nrithms that maximize rewards can be easily adapted to minimize costs. For consistency, this survey\ndescribes the version of the algorithms that focus on minimization of costs. It also describes their\nquality, runtime, memory, and communication characteristics as summarized in Table 4.\nSyncBB (Hirayama & Yokoo, 1997). Synchronous Branch-and-Bound (SyncBB) is a complete,\nsynchronous, search-based algorithm that can be considered as a distributed version of a branch-\nand-bound algorithm. It uses a complete ordering of the agents to extend a Current Partial As-\nsignment (CPA) via a synchronous communication process. The CPA holds the assignments of\nall the variables controlled by all the visited agents, and, in addition, functions as a mechanism to\npropagate bound information. The algorithm prunes those parts of the search space whose solution\nquality is sub-optimal, by exploiting the bounds that are updated at each step of the algorithm.\nSyncBB agents perform O(dn) number of operations since the lowest priority agent needs to\nenumerate through all possible value combinations for all variables. While, by default, it is not an\nanytime algorithm, it can be easily extended to have an anytime property since it is a branch-and-\nbound algorithm. The memory requirement per SyncBB agent is O(n) since the lowest priority\nagent stores the value assignment of all problem variables. In terms of communication requirement,\nSyncBB agents send O(dn) number of messages: The lowest priority agent enumerates through\nall possible value combinations for all variables and sends a message for each combination. The\nlargest message, which contains the value assignment of all variables, is of size O(n). Finally, the\ncommunication model of SyncBB depends on the given agent\u2019s complete ordering. Thus, agents\nmay communicate with non-neighboring agents.\nAFB (Gershman et al., 2009). Asynchronous Forward Bounding (AFB) is a complete, asyn-\nchronous, search-based algorithm. It can be considered as an asynchronous version of SyncBB.\nIn this algorithm, agents communicate their cost estimates, which in turn are used to compute\nbounds and prune the search space. In AFB, agents extend a CPA sequentially, provided that the\nlower bound on their costs does not exceed the global upper bound, that is, the cost of the best\nsolution found so far. Each agent performing an assignment (the \u201cassigning\u201d agent) triggers asyn-\nchronous checks of bounds, by sending forward messages containing copies of the CPA to agents\nthat have not yet assigned their variables. The unassigned agents that receive a CPA estimate the\nlower bound of the CPA given their local view of the constraint graph and send their estimates\nback to the agent that originated the forward message. This assigning agent will receive these\nestimates asynchronously and aggregate them into an updated lower bound. If the updated lower\nbound exceeds the current upper bound, the agent initiates a backtracking phase.\nThe runtime, memory, and communication characteristics of AFB are identical to those of\nSyncBB for the same reasons. However, while both AFB and SyncBB agents communicate with\nnon-neighboring agents, AFB agents broadcasts some of their messages while SyncBB agents do\nnot.\n15\nFIORETTO, PONTELLI, & YEOH\nADOPT (Modi et al., 2005). Asynchronous Distributed OPTimization (ADOPT) is a complete,\nasynchronous, search-based algorithm. It can be considered as a distributed version of a memory-\nbounded best-first search algorithm. It makes use of a DFS pseudo-tree ordering of the agents. The\nalgorithm relies on maintaining, in each agent, lower and upper bounds on the solution cost for the\nsubtree rooted at its node in the DFS tree. Agents explore partial assignments in best-first order,\nthat is, in increasing lower bound order. They use COST messages (propagated upwards in the\nDFS pseudo-tree) and THRESHOLD and VALUE messages (propagated downwards in the pseudo-\ntree) to iteratively tighten the lower and upper bounds, until the lower bound of the minimum cost\nsolution is equal to its upper bound. ADOPT agents store lower bounds as thresholds, which can\nbe used to prune partial assignments that are provably sub-optimal.\nSimilar to SyncBB and AFB, ADOPT agents perform O(dn) number of operations since the\nlowest priority agent needs to enumerate through all possible value combinations for all variables\nwhen the pseudo-tree degenerates into a pseudo-chain. It is also not an anytime algorithm as it\nis a best-first search algorithm. The memory requirement per ADOPT agent is O(n + ld), where\nO(n) is used to store a context, which is the value assignment of all higher-priority variables, and\nO(ld) is used to store the lower and upper bounds for each domain value and variable belonging to\nthe agent\u2019s child agents. Finally, ADOPT agents communicate exclusively with their neighboring\nagents.\nADOPT has been extended in several ways. In particular, BnB-ADOPT (Yeoh, Felner, &\nKoenig, 2010; Gutierrez & Meseguer, 2012b) uses a branch-and-bound method to reduce the\namount of computation performed during search, and ADOPT(k) combines both ADOPT and BnB-\nADOPT into an integrated algorithm (Gutierrez, Meseguer, & Yeoh, 2011). There are also exten-\nsions that trade solution optimality for smaller runtimes (Yeoh, Sun, & Koenig, 2009a), extensions\nthat use more memory for smaller runtimes (Yeoh, Varakantham, & Koenig, 2009b), and extensions\nthat maintain soft arc-consistency (Bessiere, Gutierrez, & Meseguer, 2012; Bessiere, Brito, Gutier-\nrez, & Meseguer, 2014; Gutierrez & Meseguer, 2012a; Gutierrez, Lee, Lei, Mak, & Meseguer,\n2013).\nFinally, the No-Commitment Branch and Bound (NCBB) algorithm (Chechetka & Sycara,\n2006) can be considered as a variant of ADOPT and SyncBB. Similar to ADOPT, NCBB agents ex-\nploit the structure defined by a pseudo-tree order to decompose the global objective function. This\nallow the agents to search non-intersecting parts of the search space concurrently. Another main\nfeature of NCBB is the eager propagation of lower bounds on solution cost: An NCBB agent prop-\nagates its lower bound every time it learns about its ancestors\u2019 assignments. This feature provides\nan efficient pruning of the search space. The runtime, memory, and communication characteristics\nof NCBB are the same as those of ADOPT except that NCBB is an anytime algorithm.\nConcFB (Netzer, Grubshtein, & Meisels, 2012). Concurrent Forward Bounding (ConcFB) is a\ncomplete, asynchronous, search-based algorithm that runs multiple parallel versions of AFB con-\ncurrently. By running multiple concurrent search procedures, it is able to quickly find a solution,\napply a forward bounding process to detect regions of the search space to prune, and to dynami-\ncally create new search processes when detecting promising sub-spaces. Similar to AFB, it uses a\n16\nDCOP: MODEL AND APPLICATIONS SURVEY\ncomplete ordering of agents and variables instead of pseudo-trees. As such, it is able to simplify the\nmanagement of reordering heuristics, which can provide substantial speed up to the search process\n(Zivan & Meisels, 2006).\nThe algorithm operates as follows: Each agent maintains a global upper bound, which is up-\ndated during the search process. The highest-priority agent begins the process by generating a\nnumber of different search processes (SP), one for each value of its variable. It then sends an\nLB Request message to all unassigned agents. This LB Request message contains the current CPA\nand triggers a calculation of the lower bounds of the receiving agents, which are sent back to the\nsender agent via a LB Report message. If the sum of the aggregated costs and the current CPA\ncost is no smaller than the current upper bound, the agent selects another value for its variable\nand repeats the process. If the agent has exhausted all value assignments for its variable, then it\nbacktracks, sending the CPA to the last assigning agent. If the CPA cost is lower than the current\nupper bound, then it forwards the CPA message to the next non-assigned agent. Upon receiving a\nCPA message, the agent repeats the above process. When the lowest-priority agent finds a solution\nresulting to a new upper bound, it broadcasts the upper bound via a UB message, which is stored\nby each each agent.\nNetzer et al. (2012) described a series of enhancements that can be used to speed up the\nsearch process of ConcFB, including dynamic variable ordering and dynamic splitting. Despite\nthe process within a subproblem is carried out in a synchronous fashion, different subproblems\nare explored independently. Thus, the agents act asynchronously and concurrently. The runtime,\nmemory, and communication characteristics of ConcFB are identical to those of AFB since it runs\nmultiple parallel versions of AFB concurrently.\nDPOP (Petcu & Faltings, 2005b). Distributed Pseudo-tree Optimization Procedure (DPOP) is a\ncomplete, synchronous, inference-based algorithm that makes use of a DFS pseudo-tree ordering\nof the agents. It involves three phases. In the first phase, the agents order themselves into a DFS\npseudo-tree. In the second phase, called the UTIL propagation phase, each agent, starting from the\nleaves of the pseudo-tree, aggregates the costs in its subtree for each value combination of variables\nin its separator. The aggregated costs are encoded in a UTIL message, which is propagated from\nchildren to their parents, up to the root. In the third phase, called the VALUE propagation phase,\neach agent, starting from the root of the pseudo-tree, selects the optimal value for its variable. The\noptimal values are calculated based on the UTIL messages received from the agent\u2019s children and\nthe VALUE message received from its parent. The VALUE messages contain the optimal values of\nthe agents and are propagated from parents to their children, down to the leaves of the pseudo-tree.\nDPOP agents perform O(dw\n\u2217\n) number of operations. When an agent optimizes for each value\ncombination of variables in its separator, it takes O(dw\n\u2217\n) operations since there are w\u2217 variables in\nthe separator set in the worst case. It is not an anytime algorithm as it terminates upon finding its\nfirst solution, which is an optimal solution. The memory requirement per DPOP agent is O(dw\n\u2217\n)\nsince it stores all value combinations of variables in its separator. In terms of communication re-\nquirement, DPOP agents send O(n) messages in total; O(n) UTIL messages are propagated up\nthe pseudo-tree and O(n) VALUE messages are propagated down the pseudo-tree. The largest\n17\nFIORETTO, PONTELLI, & YEOH\nmessage sent by an agent, which contains the aggregated costs in its subtree for each value combi-\nnation of variables in its separator, is O(dw\n\u2217\n). Finally, DPOP agents only communicate with their\nneighboring agents only.\nDPOP has also been extended in several ways to enhance its performance and capabilities. O-\nDPOP and MB-DPOP trade runtimes for smaller memory requirements (Petcu & Faltings, 2006,\n2007a), A-DPOP trades solution optimality for smaller runtimes (Petcu & Faltings, 2005a), SS-\nDPOP trades runtime for increased privacy (Greenstadt et al., 2007), PC-DPOP trades privacy for\nsmaller runtimes (Petcu et al., 2007), H-DPOP propagates hard constraints for smaller runtimes\n(Kumar, Petcu, & Faltings, 2008), BrC-DPOP enforces branch consistency for smaller runtimes\n(Fioretto, Le, Yeoh, Pontelli, & Son, 2014), and ASP-DPOP is a declarative version of DPOP that\nuses Answer Set Programming (Le, Son, Pontelli, & Yeoh, 2015).\nOptAPO (Mailler & Lesser, 2004). Optimal Asynchronous Partial Overlay (OptAPO) is a com-\nplete, asynchronous, search-based algorithm. It trades agent privacy for smaller runtimes through\npartial centralization. It employs a cooperative mediation schema, where agents can act as me-\ndiators and propose value assignments to other agents. In particular, the agents check if there is\na conflicting assignment with some neighboring agent. If a conflict is found, the agent with the\nhighest priority acts as a mediator. During mediation, OptAPO solves subproblems using a cen-\ntralized branch-and-bound-based search, and when solutions of overlapping subproblems still have\nconflicting assignments, the solving agents increase the degree of centralization to resolve them.\nBy sharing their knowledge with centralized entities, agents can improve their local decisions, re-\nducing the communication costs. For instance, the algorithm has been shown to be superior to\nADOPT on simple combinatorial problems (Mailler & Lesser, 2004). However, it is possible that\nseveral mediators solve overlapping problems, duplicating efforts (Petcu et al., 2007), which can\nbe a bottleneck in dense problems.\nOptAPO agents perform O(dn) number of operations, in the worst case, as a mediator agent\nmay solve the entire problem. Like ADOPT and DPOP, OptAPO is not an anytime algorithm. The\nmemory requirement per OptAPO agent is O(nd) since it needs to store all value combinations of\nvariables in its mediation group, which is of size O(n). In terms of communication requirement,\nOptAPO agents send O(dn) messages in the worst case, though the number of messages decreases\nwith increasing partial centralization. The size of the messages is bounded by O(d + n), where\nin the initialization phase of each mediation step, each agent sends its domain to its neighbors\nand the list of variables that it seeks to mediate. Finally, OptAPO agents can communicate with\nnon-neighboring agents during the mediation phase.\nThe original version of OptAPO has been shown to be incomplete due to the asynchronicity of\nthe different mediators\u2019 groups, which can lead to race conditions. Grinshpoun and Meisels (2008)\nproposed a complete variant that remedies this issue.\n4.3.5 INCOMPLETE ALGORITHMS\nMax-Sum (Farinelli et al., 2008). Max-Sum is an incomplete, synchronous, inference-based al-\ngorithm based on belief propagation. It operates on factor graphs by performing a marginalization\n18\nDCOP: MODEL AND APPLICATIONS SURVEY\nprocess of the cost functions, and optimizing the costs for each given variable. This process is per-\nformed by recursively propagating messages between variable nodes and factor nodes. The value\nassignments take into account their impact on the marginalized cost function. Max-Sum is guar-\nanteed to converge to an optimal solution in acyclic graphs, but convergence is not guaranteed on\ncyclic graphs.\nMax-Sum agents performO(dl) number of operations in each iteration, where each agent needs\nto optimize for all value combinations of neighboring variables. It is not an anytime algorithm. The\nmemory requirement per Max-Sum agent is O(dl) since it needs to store all value combinations of\nneighboring variables. In terms of communication requirement, in the worst case, each Max-Sum\nagent sends O(l) messages in each iteration, one to each of its neighbor. Thus, the total number\nof messages sent across all agents is O(`nl). Each message is of size O(d) as it needs to contain\nthe current aggregated costs of all the agent\u2019s variable\u2019s values. Finally, the agents communicate\nexclusively with their neighboring agents.\nMax-Sum has been extended in several ways. Bounded Max-Sum bounds the quality of the\nsolutions found by removing a subset of edges from a cyclic DCOP graph to make it acyclic,\nand running Max-Sum to solve the acyclic problem (Rogers, Farinelli, Stranders, & Jennings,\n2011); Improved Bounded Max-Sum improves on the error bounds (Rollon & Larrosa, 2012); and\nMax-Sum ADVP guarantees convergence in acyclic graphs through a two-phase value propagation\nphase (Zivan & Peled, 2012; Chen, Deng, & Wu, 2017). Max-Sum and its extensions have been\nsuccessfully used to solve a number of large scale, complex MAS applications (see Section 8).\nRegion Optimal (Pearce & Tambe, 2007). Region-optimal algorithms are incomplete, syn-\nchronous, search-based algorithms that allow users to specify regions of the constraint graph and\nsolve the subproblem within each region optimally. Regions may be defined to have a maximum\nsize of k agents (Pearce & Tambe, 2007), t hops from each agent (Kiekintveld, Yin, Kumar, &\nTambe, 2010), or a combination of both size and hops (Vinyals, Shieh, Cerquides, Rodriguez-\nAguilar, Yin, Tambe, & Bowring, 2011). The concept of k-optimality is defined with respect to\nthe number of agents whose assignments conflict, whose set is denoted by c(\u03c3, \u03c3\u2032), for two assign-\nments \u03c3 and \u03c3\u2032. The deviating cost of \u03c3 with respect to \u03c3\u2032, denoted by \u2206(\u03c3, \u03c3\u2032), is defined as the\ndifference of the aggregated cost associated to the assignment \u03c3 (F (\u03c3)) minus the cost associated\nto \u03c3\u2032 (F (\u03c3\u2032)). An assignment \u03c3 is k-optimal if \u2200\u03c3\u2032 \u2208 \u03a3, such that |c(\u03c3, \u03c3\u2032)| \u2264 k, we have that\n\u2206(\u03c3, \u03c3\u2032) \u2265 0. In contrast, the concept of t-distance emphasizes the number of hops from a cen-\ntral agent a of the region \u2126t(a), that is the set of agents which are separated from a by at most t\nhops. An assignment \u03c3 is t-distance optimal if, \u2200\u03c3\u2032 \u2208 \u03a3, F (\u03c3) \u2265 F (\u03c3\u2032) with c(\u03c3, \u03c3\u2032) \u2286 \u2126t(a),\nfor any a \u2208 A. Therefore, the solutions found have theoretical error bounds that are a function\nof k and/or t. Region-optimal algorithms adopt a partially-centralized resolution scheme in which\nthe subproblem within each region is solved optimally by a centralized authority (Tassa, Zivan, &\nGrinshpoun, 2016). However, this scheme can be altered to use a distributed algorithm to solve\neach subproblem.\nRegion-optimal agents perform O(dw\n\u2217\n) number of operations in each iteration, as each agent\nruns DPOP to solve the problem within each region optimally. It is also an anytime algorithm as\n19\nFIORETTO, PONTELLI, & YEOH\nsolutions of improving quality are found until they are region-optimal. The memory requirement\nper region-optimal agent is O(dw\n\u2217\n) since its region may have an induced width of w\u2217 and it uses\nDPOP to solve the problem within its region. In terms of communication requirement, each region-\noptimal agent sends O(n) messages, one to each agent within its region. Thus, the total number\nof messages sent across all agents is O(`n2). Each message is of size O(dw\n\u2217\n) as it uses DPOP.\nFinally, the agents communicate to all agents within their region \u2013 either to a distance of bk2c or t\nhops away. Thus, they may communicate with non-neighboring agents.\nAn asynchronous version of regional-optimal algorithms, called Distributed Asynchronous Lo-\ncal Optimization (DALO), was proposed by Kiekintveld et al. (2010). The DALO simulator pro-\nvides a mechanism to coordinate the decision of local groups of agents based on the concepts of\nk-optimality and t-distance.\nMGM (Maheswaran, Pearce, & Tambe, 2004a). Maximum Gain Message (MGM) is an incom-\nplete, synchronous, search-based algorithm that performs a distributed local search. Each agent\nstarts by assigning a random value to each of its variables. Then, it sends this information to all\nits neighbors. Upon receiving the values of its neighbors, it calculates the maximum gain (i.e., the\nmaximum decrease in cost) if it changes its value and sends this information to all its neighbors.\nUpon receiving the gains of its neighbors, the agent changes its value if its gain is the largest among\nthose of its neighbors. This process repeats until a termination condition is met. MGM provides\nno quality guarantees on the returned solution.\nMGM agents perform O(ld) number of operations in each iteration, as each agent needs to\ncompute the cost for each of its values by taking into account the values of all its neighbors. MGM\nis anytime since agents only change their values when they have a non-negative gain. The memory\nrequirement per MGM agent is O(l). Each agent needs to store the values of all its neighboring\nagents. In terms of communication requirement, each MGM agent sends O(l) messages, one to\neach of its neighboring agents. Thus, the total number of messages sent across all agents isO(`nl).\nEach message is of constant size O(1) as it contains either the agent\u2019s current value or the agent\u2019s\ncurrent gain. Finally, the agents communicate exclusively with their neighboring agents.\nDSA (Zhang, Wang, Xing, & Wittenberg, 2005). Distributed Stochastic Algorithm (DSA) is an\nincomplete, synchronous, search-based algorithm that is similar to MGM, except that each agent\ndoes not send its gains to its neighbors and it does not change its value to the value with the maxi-\nmum gain. Instead, it decides stochastically if it takes on the value with the maximum gain or other\nvalues with smaller gains. This stochasticity allows DSA to escape from local minima. Similar\nto MGM, it repeats the process until a termination condition is met, and it cannot provide quality\nguarantees on the returned solution. The runtime, memory, and communication characteristics of\nDSA are identical to those of MGM since it is essentially a stochastic variant of MGM.\nDUCT (Ottens, Dimitrakakis, & Faltings, 2017). The Distributed Upper Confidence Tree (DUCT)\nalgorithm is an incomplete, synchronous, sampling-based algorithm that is inspired by Monte-\nCarlo Tree Search and employs confidence bounds to solve DCOPs. DUCT emulates a search\nprocess analogous to that of ADOPT, where agents select the values to assign to their variables\naccording to the information encoded in their context messages (i.e., the assignments to all the\n20\nDCOP: MODEL AND APPLICATIONS SURVEY\nvariables in the receiving variable\u2019s separator). However, rather than systematically selecting the\nnext value to assign to their own variables, DUCT agents sample such values. To focus on promis-\ning assignments, DUCT constructs a confidence bound B, such that cost associated to the best\nvalue for any context is at least B, and hence agents sample the choice with the lowest bound. This\nprocess is started by the root agent of the pseudo-tree: After sampling a value for its variable, it\ncommunicates its assignment to its children in a context message. When an agent receives this mes-\nsage, it repeats this process until the leaf agents are reached. When the leaf agents choose a value\nassignment, they calculate the cost within their context and propagate this information up to the\ntree in a cost message. This process continues for a given number of iterations or until convergence\nis achieved, i.e., until the sampled values in two successive iterations do not change. Therefore,\nDUCT is able to provide quality guarantees on the returned solution.\nDUCT agents perform O(ld) number of operations in each iteration, as each agent needs to\ncompute the cost for each of its values by taking into account the values of all its neighbors. It is\nan anytime algorithm; The quality guarantee improves with increasing number of iterations. The\nmemory requirement per DUCT agent isO(dn)4 since it needs to store the best cost for all possible\ncontexts. In terms of communication requirement, in each iteration, each DUCT agent sends one\nmessage to its parent in the pseudo-tree and one message to each of its children in the pseudo-tree.\nThus, the total number of messages sent across all agents is O(`n). Each message is of size O(n);\ncontext messages contain the value assignment for all higher priority agents. Finally, the agents\ncommunicate exclusively with their neighboring agents.\nD-Gibbs (Nguyen, Yeoh, & Lau, 2013). The Distributed Gibbs (D-Gibbs) algorithm is an incom-\nplete, synchronous, sampling-based algorithm that extends the Gibbs sampling process (Geman\n& Geman, 1984) by tailoring it to solve DCOPs in a decentralized manner. The Gibbs sampling\nprocess is a centralized Markov Chain Monte-Carlo algorithm that can be used to approximate\njoint probability distributions. By mapping DCOPs to maximum a-posteriori estimation problems,\nprobabilistic inference algorithms like Gibbs sampling can be used to solve DCOPs.\nLike DUCT, it too operates on a pseudo-tree, and the agents sample sequentially from the\nroot of the pseudo-tree down to the leaves. Like DUCT, each agent also stores a context (i.e., the\ncurrent assignment to all the variables in its separator) and it samples based on this information.\nSpecifically, it computes the probability for each of its values given its context and chooses its\ncurrent value based on this probability distribution. After it chooses its value, it informs its lower\npriority neighbors of its value, and its children agents start to sample. This process continues\nuntil all the leaf agents sample. Cost information is propagated up the pseudo-tree. This process\ncontinues for a fixed number of iterations or until convergence. Like DUCT, D-Gibbs is also able\nto provide quality guarantees on the returned solution.\nThe runtime characteristics of D-Gibbs are identical to that of DUCT and for the same reasons.\nHowever, its memory requirements are smaller: The memory requirement per D-Gibbs agent is\nO(l) since it needs to store the current values of all its neighbors. In terms of communication re-\n4. It is actually O(dt), where t is the depth of the pseudo-tree. However, in the worst case, when the pseudo-tree\ndegenerates into a pseudo-chain, then t = n.\n21\nFIORETTO, PONTELLI, & YEOH\nquirement, in each iteration, each D-Gibbs agent sendsO(l) messages, one to each of its neighbors.\nThus, the total number of messages sent across all agents is O(`nl). Each message is of constant\nsize O(1) since they contain only the current value of the agent or partial cost of its solution.\nFinally, the agents communicate exclusively with their neighboring agents.\nA version of the algorithm that speeds up the agents\u2019 sampling process with Graphical Process-\ning Units (GPUs) is described in (Fioretto, Yeoh, & Pontelli, 2016a).\n4.4 Tradeoffs Between the Various DCOP Algorithms\nThe various DCOP algorithms discussed above provide a good coverage across various character-\nistics that may be important in different applications. As such, how well suited an algorithm is for\nan application depends on how well the algorithm\u2019s characteristics match up to the application\u2019s\ncharacteristics. The next section discusses several suggestions for the types of algorithms that are\nrecommended based on the characteristics of the application at hand.\n4.4.1 COMPLETE ALGORITHMS\nWhen optimality is a requirement of the application, then one is limited to complete algorithms:\n\u2022 If the agents in the application have large amounts of memory and it is faster to send few large\nmessages than many small messages, then inference-based algorithms (e.g., DPOP and its ex-\ntensions) are preferred over search-based algorithms (e.g., SyncBB, AFB, ADOPT, ConcFB,\nOptAPO). This is because, in general, search algorithms perform some amount of redundant\ncommunication. Thus, for a given problem instance, the overall runtime of inference-based al-\ngorithms tend to be smaller than the runtime of search-based ones.\n\u2022 If the agents in the application have limited amounts of memory, then one has to use the search-\nbased algorithms (e.g., SyncBB, AFB, ADOPT, ConcFB, OptAPO), which have small memory\nrequirements. The exception is when the problem has a small induced width (e.g., the constraint\ngraph is acyclic), in which case inference-based algorithms (e.g., DPOP) are also preferred.\n\u2022 If partial centralization is allowed by the application, then OptAPO is preferred as it has been\nshown to outperform many of the other search algorithms (Mailler & Lesser, 2004).\n\u2022 Otherwise, ConcFB is recommended as it has been shown to outperform AFB due to the\nconcurrent search (Netzer et al., 2012), and AFB has been shown to outperform ADOPT and\nSyncBB (Gershman et al., 2009). The exception is if the application does not permit agents\nto communicate directly to non-neighbors, in which case ConcFB, AFB, and SyncBB cannot\nbe used and one is restricted to use ADOPT or one of its variants. Note that many of the\nvariants (e.g., BnB-ADOPT, NCBB) have been shown to significantly outperform ADOPT\nwhile maintaining the same runtime, memory, and communication requirements (Chechetka\n& Sycara, 2006; Yeoh et al., 2010).\n4.4.2 INCOMPLETE ALGORITHMS\nIn terms of incomplete algorithms, the following recommendations are given:\n22\nDCOP: MODEL AND APPLICATIONS SURVEY\n\u2022 If the solution returned must have an accompanying quality guarantee, then, one can choose to\nuse Bounded Max-Sum, region-optimal algorithms, DUCT, or D-Gibbs. Bounded Max-Sum al-\nlows users to choose the error bound as a function of the different subsets of edges that can be\nremoved from the graph to make it acyclic. Region-optimal algorithms allow users to parameter-\nize the error bound according to the size of the region k or the number of hops t that the solution\nshould be optimal for. Finally, DUCT and D-Gibbs allow users to parameterize the error bound\nbased on the number of sampling iterations to conduct. The error bounds for these two algo-\nrithms are also probabilistic bounds (i.e., the likelihood that the quality of the solution is within\nan error bound is a function of the number of iterations). Therefore, the choice of algorithm will\ndepend on the type of error bound one would like to impose on the solutions. One may also\nchoose to use a number of extensions of complete algorithms (e.g., Weighted (BnB-)ADOPT\nand A-DPOP) that allow users to parameterize the error bound and affect the degree of speedup.\n\u2022 If the solution quality guarantee is not required, then one can also use Max-Sum, MGM, or DSA.\nTheir performance depends on a number of factors: If the problem has large domain sizes, MGM\nand DSA often outperform Max-Sum, since the memory and computational complexities of\nMax-Sum grows exponentially with the domain size. However, if the problem has small induced\nwidths (for instance, when its constraint graph is acyclic), then Max-Sum is very efficient. It\nis even guaranteed to find optimal solutions when the induced width is 1. In general, Max-Sum\ntends to find solutions of good quality especially when considering its recent improvements (e.g.,\n(Zivan, Parash, Cohen, Peled, & Okamoto, 2017)).\n\u2022 If the problem has hard constraints (i.e., certain value combinations are prohibited), then the sam-\npling algorithms (i.e., DUCT and D-Gibbs) are not recommended as they are not able to handle\nsuch problems. They require the cost functions to be smooth, and exploit that characteristic to\nexplore the search space. Thus, one is restricted to search- or inference-based algorithms.\n\u2022 In general, MGM and DSA are good robust benchmarks as they tend to find reasonably high\nquality solutions in practice. However, if specific problem characteristics are known, such as the\nones discussed above, then certain algorithms may be able to exploit them to find better solutions.\n4.5 Notable Variant: Asymmetric DCOPs\nAsymmetric DCOPs (Grinshpoun, Grubshtein, Zivan, Netzer, & Meisels, 2013) are used to model\nmulti-agent problems where agents controlling variables in the scope of a cost function can incur\nto different costs, given a fixed join assignment. Such a problem cannot be naturally represented by\nclassical DCOPs, which require that all agents controlling variables participating in a cost function\nincur to the same cost as each other.\n4.5.1 DEFINITION\nAn Asymmetric DCOP is a tuple \u3008A,X,D,F, \u03b1\u3009, where A,X,D, and \u03b1 are as defined in Defi-\nnition 4.1, and each cost function fi \u2208 F is defined as: fi : \"xj\u2208xi Dj \u00d7 \u03b1(fi) \u2192 (R+ \u222a {\u22a5}).\nIn other words, an Asymmetric DCOP is a DCOP where the cost that an agent incurs from a cost\nfunction may differ from the cost that another agent incurs from the same cost function.\n23\nFIORETTO, PONTELLI, & YEOH\nAs costs for participating agents may differ from each other, the goal in Asymmetric DCOPs is\ndifferent from the goal in classical DCOPs. Given a cost function fj \u2208 F and complete assignment\n\u03c3, let fj(\u03c3, ai) denote the cost incurred by agent ai from cost function fj with complete assignment\n\u03c3. Then, the goal in Asymmetric DCOPs is to find the solution \u03c3\u2217:\n\u03c3\u2217 := argmin\n\u03c3\u2208\u03a3\n\u2211\nfj\u2208F\n\u2211\nai\u2208\u03b1(fj)\nfj(\u03c3xj , ai) (2)\nAs in classical DCOPs, solving Asymmetric DCOPs is NP-hard. In particular, it is possible\nto reduce any Asymmetric DCOP to an equivalent classical DCOP by introducing a polynomial\nnumber of variables and constraints, as described in the next section.\n4.5.2 RELATION TO CLASSICAL DCOPS\nOne way to solve MAS problems with asymmetric costs via classical DCOPs is through the Private\nEvent As Variables (PEAV) model (Maheswaran et al., 2004a). It can capture asymmetric costs\nby introducing, for each agent, as many \u201cmirror\u201d variables as the number of variables held by\nneighboring agents. The consistency with the neighbors\u2019 state variables is imposed by a set of\nequality constraints. However, this formalism suffers from scalability problems, as it may result\nin a significant increase in the number of variables in a DCOP. In addition, Grinshpoun et al.\n(2013) showed that most of the existing incomplete classical DCOP algorithms cannot be used to\neffectively solve Asymmetric DCOPs, even when the problems are reformulated through the PEAV\nmodel. They show that such algorithms are unable to distinguish between different solutions that\nsatisfy all hard constraints, resulting in a convergence to one of those solutions and the inability\nto escape that local optimum. Therefore, it is important to design specialized algorithms to solve\nAsymmetric DCOPs.\n4.5.3 ALGORITHMS\nThe current research direction in the design of Asymmetric DCOP algorithms has focused on adapt-\ning existing classical DCOP algorithms to handle the asymmetric costs. Asymmetric DCOPs re-\nquire that each agent, whose variables participate in a cost function, coordinate the aggregation of\ntheir individual costs. To do so, two approaches have been identified (Brito, Meisels, Meseguer, &\nZivan, 2009):\n\u2022 A two-phase strategy, where only one side of the constraint (i.e., the cost induced by one agent)\nis considered in the first phase. The other side(s) (i.e., the cost induced by the other agent(s)) is\nconsidered in the second phase once a complete assignment is produced. As a result, the costs\nof all agents are aggregated.\n\u2022 A single-phase strategy, which requires a systematic check of each side of the constraint before\nreaching a complete assignment. Checking each side of the constraint is often referred to as back\nchecking, a process that can be performed either synchronously or asynchronously.\nCOMPLETE ALGORITHMS\n24\nDCOP: MODEL AND APPLICATIONS SURVEY\nSyncABB-2ph (Grinshpoun et al., 2013). Synchronous Asymmetric Branch and Bound - 2-phase\n(SyncABB-2ph) is a complete, synchronous, search-based algorithm that extends SyncBB with the\ntwo-phase strategy. Phase 1 emulates SyncBB, where each agent considers the values of its cost\nfunctions with higher-priority agents. Phase 2 starts once a complete assignment is found. During\nthis phase, each agent aggregates the sides of the cost functions that were not considered during\nPhase 1 and verifies that the known bound is not exceeded. If the bound is exceeded, Phase 2 ends\nand the agents restart Phase 1 by backtracking and resuming the search from the lower priority\nagent that exceeded the bound. The worst case runtime, memory, and communication requirements\nof this algorithm are the same as those of SyncBB.\nSyncABB-1ph (Grinshpoun et al., 2013; Levit, Grinshpoun, Meisels, & Bazzan, 2013). Syn-\nchronous Asymmetric Branch and Bound - 1-phase (SyncABB-1ph) is a complete, synchronous,\nsearch-based algorithm that extends SyncBB with the one-phase strategy. Each agent, after having\nextended the CPA, updates the bound with its local cost associated to the cost functions involving\nits variables \u2013 as done in SyncBB. In addition, the CPA is sent back to the assigned agents to up-\ndate its bound via a sequence of back checking operations. The worst case runtime, memory, and\ncommunication requirements of this algorithm are the same as those of SyncBB.\nATWB (Grinshpoun et al., 2013). The Asymmetric Two-Way Bounding (ATWB) algorithm is a\ncomplete, asynchronous, search-based algorithm that extends AFB to accommodate both forward\nbounding and backward bounding. The forward bounding is performed analogously to AFB. The\nbackward bounding, instead, is achieved by sending copies of the CPA backward to the agents\nwhose assignments are included in the CPA. Similar to what is done in AFB, agents that receive a\ncopy of the CPA compute their estimates and send them forward to the assigning agent. The worst\ncase runtime, memory, and communication requirements of this algorithm are the same as those of\nAFB.\nINCOMPLETE ALGORITHMS\nACLS (Grinshpoun et al., 2013). Asymmetric Coordinated Local Search (ACLS) is an incomplete,\nsynchronous, search-based algorithm that extends DSA. After a random value initialization, each\nagent exchanges its values with all its neighboring agents. At the end of this step, each agent\nidentifies all possible improving assignments for its own variables, given the current neighbors\nchoices. Each agent then selects one such assignments, according to the distribution of gains\n(i.e., reductions in costs) from each proposal assignment, and exchanges it with its neighbors.\nWhen an agent receives a proposal assignment, it responds with the evaluation of its side of the\ncost functions, resulting from its current assignment and the proposal assignments of the other\nagents participating in the cost function. After receiving the evaluations from each of its neighbors,\neach agent estimates the potential gain or loss derived from its assignment, and commits to a change\nwith a given probability, similar to agents in DSA, to escape from local minima. The worst case\nruntime, memory, and communication requirements of this algorithm are the same as those of DSA.\nMCS-MGM (Grinshpoun et al., 2013). Minimal Constraint Sharing MGM (MCS-MGM) is an\nincomplete, synchronous, search-based algorithm that extends MGM by considering each side of\n25\nFIORETTO, PONTELLI, & YEOH\nthe cost function. Like MGM, the agents operate in an iterative fashion, where they exchange\ntheir current values at the start of each iteration. Afterwards, each agent sends the cost for its side\nof each cost function to its neighboring agents that participate in the same cost function.5 Upon\nreceiving this information, each agent knows the total cost for each cost function \u2013 by adding\ntogether the value of both sides of the cost function. Therefore, like in MGM, the agent can\ncalculate the maximum gain (i.e., maximum reduction in costs) if it changes its values, and will\nsend this information to all its neighbors. Upon receiving the gains of its neighbors, each agent\nchanges its value if its gain is the largest among its neighbors. The worst case runtime, memory,\nand communication requirements of this algorithm are the same as those of MGM.\n4.6 Notable Variant: Multi-Objective DCOPs\nMulti-Objective Optimization (MOO) (Miettinen, 1999; Marler & Arora, 2004) aims at solv-\ning problems involving more than one objective function to be optimized simultaneously. In a\nMOO problem, optimal decisions need to accommodate potentially conflicting objectives. Multi-\nObjective DCOPs extend MOO problems and DCOPs (Delle Fave, Stranders, Rogers, & Jennings,\n2011).\n4.6.1 DEFINITION\nA Multi-Objective DCOP (MO-DCOP) is a tuple \u3008A,X,D, ~F, \u03b1\u3009, where A,X,D, and \u03b1 are as\ndefined in Definition 4.1, and ~F = [F1, . . . , Fh]T is a vector of multi-objective functions, where\neach Fi is a set of cost functions fj as defined in Definition 4.1. For a complete assignment \u03c3 of\na MO-DCOP, let the cost for \u03c3 according to the ith multi-objective optimization function set Fi,\nwhere 1 \u2264 i \u2264 h, be\nFi(\u03c3) :=\n\u2211\nfj\u2208Fi\nfj(\u03c3xj ) (3)\nThe goal of a MO-DCOP is to find a complete assignment \u03c3\u2217 such that:\n\u03c3\u2217 := argmin\n\u03c3\u2208\u03a3\n~F(\u03c3) = argmin\n\u03c3\u2208\u03a3\n[F1(\u03c3), . . . , Fh(\u03c3)]\nT (4)\nwhere ~F(\u03c3) is a cost vector for the MO-DCOP. A solution to a MO-DCOP involves the optimiza-\ntion of a set of partially-ordered assignments. The above definition considers point-wise compar-\nison of vectors\u2014i.e., ~F(\u03c3) \u2264 ~F(\u03c3\u2032) if Fi(\u03c3) \u2264 Fi(\u03c3\u2032) for all 1 \u2264 i \u2264 h. Typically, there is no\nsingle global solution where all the objectives are optimized at the same time. Thus, solutions of\na MO-DCOP are characterized by the concept of Pareto optimality, which can be defined through\nthe concept of dominance:\nDefinition 1 (Dominance) A solution \u03c3 \u2208 \u03a3 is dominated by a solution \u03c3\u2032 \u2208 \u03a3 iff ~F(\u03c3\u2032) \u2264 ~F(\u03c3)\nand Fi(\u03c3\u2032) < Fi(\u03c3) for at least one Fi.\n5. This is a version of the algorithm with a guarantee that it will converge to a local optima. In the original version\nof the algorithm, which does not have such guarantee, each agent sends the cost only if its gain with the neighbor\u2019s\nnew values is larger than the neighbor\u2019s last known gain.\n26\nDCOP: MODEL AND APPLICATIONS SURVEY\nDefinition 2 (Pareto Optimality) A solution \u03c3\u2032 \u2208 \u03a3 is Pareto optimal iff it is not dominated by\nany other solution.\nTherefore, a solution is Pareto optimal iff there is no other solution that improves at least one\nobjective function without deteriorating the cost of another function. Another important concept is\nthe Pareto front:\nDefinition 3 (Pareto Front) The Pareto front is the set of all cost vectors of all Pareto optimal\nsolutions.\nSolving a MO-DCOP is equivalent to finding the Pareto front. However, even for tree-structured\nMO-DCOPs, the size of the Pareto front may be exponential in the number of variables.6 Thus,\nmulti-objective algorithms often provide solutions that may not be Pareto optimal but may satisfy\nother criteria that are significant for practical applications. A widely-adopted criterion is that of\nweak Pareto optimality:\nDefinition 4 (Weak Pareto Optimality) A solution \u03c3\u2032 \u2208 \u03a3 is weakly Pareto optimal iff there is\nno other solution \u03c3 \u2208 \u03a3 such that ~F(\u03c3) < ~F(\u03c3\u2032).\nIn other words, a solution is weakly Pareto optimal if there is no other solution that improves all\nof the objective functions simultaneously. An alternative approach to Pareto optimality is one that\nuses the concept of utopia points:\nDefinition 5 (Utopia Point) A cost vector ~F\u25e6 = [F \u25e61 , . . . , F \u25e6h ]\nT is a utopia point iff F \u25e6i =\nmin\u03c3\u2208\u03a3 Fi(\u03c3) for all 1 \u2264 i \u2264 h.\nIn other words, a utopia point is the vector of costs obtained by independently optimizing hDCOPs,\neach associated to one objective of the multi-objective function vector. In general, ~F\u25e6 is unattain-\nable. Therefore, different approaches focus on finding a compromise solution (Salukvad, 1971),\nwhich is a Pareto optimal solution that is close to the utopia point. The concept of closeness is\ndependent on the approach adopted.\nSimilar to their centralized counterpart, MO-DCOPs have been shown to be NP-hard (their\ndecision versions), and #P-hard (the related counting versions), and to have exponentially many\nnon-dominated points (Gla\u00dfer, Reitwie\u00dfner, Schmitz, & Witek, 2010).\n4.6.2 ALGORITHMS\nThis section categorizes the proposed MO-DCOP algorithms into two classes: complete and in-\ncomplete algorithms, according to their ability to find the complete set of Pareto optimal solutions\nor only a subset of it.\nCOMPLETE ALGORITHMS\n6. In the worst case, every possible solution is a Pareto optimal solution.\n27\nFIORETTO, PONTELLI, & YEOH\nMO-SBB (Medi, Okimoto, & Inoue, 2014). Multi-Objective Synchronous Branch and Bound\n(MO-SBB) is a complete, synchronous, search-based algorithm that extends SyncBB. It uses an\nanalogous search strategy to that of the mono-objective SyncBB: After establishing a complete or-\ndering, MO-SBB agents extend a CPA with their own value assignments and the current associated\ncost vectors. Once a non-dominated solution is found, it is broadcasted to all agents, which add the\nsolution to a list of global bounds. Thus, agents maintains an approximation of the Pareto front,\nwhich is used to bound the exploration, and extend the CPA only if the new partial assignment is\nnot dominated by solutions in the list of global bounds. When the algorithm terminates, it returns\nthe set of Pareto optimal solutions obtained by filtering the list of global bounds by dominance.\nThe worst case runtime and communication requirements of this algorithm are the same as those of\nSyncBB. In terms of memory requirement, each MO-SBB agent needs O(np) amount of memory,\nwhere p is the size of the Pareto set.\nPseudo-tree Based Algorithm (Matsui, Silaghi, Hirayama, Yokoo, & Matsuo, 2012). The pro-\nposed algorithm is a complete, asynchronous, search-based algorithm that extends ADOPT. It intro-\nduces the notion of boundaries on the vectors of multi-objective values, which extends the concept\nof lower and upper bounds to vectors of values. The proposed approach starts with the assumption\nthat |F1| = \u00b7 \u00b7 \u00b7 = |Fh| = k. Furthermore, the cost functions within each Fi are sorted according to\na predefined ordering, and for each 1 \u2264 j \u2264 k, the scope of f ij (i.e., the jth function in Fi) is the\nsame for each i (i.e., all functions in the same position in different Fi have the same scope). Thus,\nwithout loss of generality, the notation xj will be used to refer to the scope of f ij .\nGiven a complete assignment \u03c3, for 1 \u2264 j \u2264 k, let ~\u03c3j = [\u03c31fj , . . . , \u03c3hfj ] =\n[f1j (\u03c3xj ), . . . , f\nh\nj (\u03c3xj )] be the vector of cost values. The notion of non-dominance is applied\nto these vectors, where a vector ~\u03c3j is non-dominated iff there is no other vector ~\u03c3\u2032j such that\nub(\u03c3\u2032j\ns) \u2264 lb(\u03c3sj ) for all 1 \u2264 s \u2264 h and ub(\u03c3\u2032js) < lb(\u03c3sj ) for at least one s. The algorithm uses the\nnotion of non-dominance for bounded vectors to retain exclusively non-dominated vectors.\nThe worst case runtime and communication requirements of this algorithm are the same as\nthose of ADOPT. In terms of memory requirement, each agent needs O(np) amount of memory.\nHowever, notice that the number of combinations of cost vectors grows exponentially with the\nnumber of tuples of cost values, in the worst case. This algorithm has also been extended to\nsolve Asymmetric MO-DCOPs (Matsui, Silaghi, Hirayama, Yokoo, & Matsuo, 2014), which is an\nextension of both Asymmetric DCOPs and MO-DCOPs.\nINCOMPLETE ALGORITHMS\nB-MOMS (Delle Fave et al., 2011). Bounded Multi-Objective Max-Sum (B-MOMS) is an incom-\nplete, asynchronous, inference-based algorithm, and was the first MO-DCOP algorithm introduced.\nIt extends Bounded Max-Sum to compute bound approximations for MO-DCOPs. It consists of\nthree phases. The Bounding Phase generates an acyclic subgraph of the multi-objective factor\ngraph, using a generalization of the maximum spanning tree problem to vector weights. During the\nMax-sum Phase, the agents coordinate to find the Pareto optimal set of solutions to the acyclic fac-\ntor graph generated in the bounding phase. This is achieved by extending the addition and marginal\n28\nDCOP: MODEL AND APPLICATIONS SURVEY\nmaximization operators adopted in Max-Sum to the case of multiple objectives. Finally, the Value\nPropagation Phase allows agents to select a consistent variable assignment, as there may multiple\nPareto optimal solutions. The bounds provided by the algorithm are computed using the notion of\nutopia points.\nThe worst case runtime requirement of this algorithm is the same as those of Max-Sum. In\nterms of communication requirement, the number of messages sent is also like Max-Sum, but the\nsize of each message is nowO(pdn). In terms of memory requirement, each B-MOMS agent needs\nO(pdn) amount of memory to store and process the messages received.\nDP-AOF (Okimoto, Clement, & Inoue, 2013). Dynamic Programming based on Aggregate Ob-\njective Functions (DP-AOF) is an incomplete, synchronous, inference-based algorithm. It adapts\nthe AOF technique (Miettinen, 1999), designed to solve centralized multi-objective optimization\nproblems, to solve MO-DCOPs. Centralized AOF adopts a scalarization to convert a MOO prob-\nlem into a single objective optimization. This is done by assigning weights (\u03b11, . . . , \u03b1h) to each\nof the cost functions in the objective vector [F1, . . . , Fh]T such that\n\u2211h\ni=1 \u03b1i = 1 and \u03b1i > 0 for\nall 1 \u2264 i \u2264 h. The resulting mono-objective function \u2211hi=1 \u03b1i Fi can be solved using any mono-\nobjective optimization technique with guarantee to find a Pareto optimal solution (Miettinen, 1999).\nDP-AOF proceeds in two phases. First, it computes the utopia point ~F\u25e6 by solving as many\nmono-objective DCOPs as the number of objective functions in the MO-DCOP. DP-AOF uses\nDPOP to solve these mono-objective DCOPs. It then constructs a new problem building upon\nthe solutions obtained from the first phase. Such a problem is used to assign weights to each\nobjective function of the MO-DCOP to construct the new mono-objective function in the same\nway as centralized AOF, which then can be solved optimally. The worst case runtime, memory,\nand communication requirements of this algorithm are the same as those of DPOP, except that the\nnumber of operations and the number of messages are larger by a factor of h since it runs DPOP h\ntimes to solve the h mono-objective DCOPs.\nMO-DPOPLp (Okimoto, Schwind, Clement, & Inoue, 2014). Multi-Objective Lp-norm based\nDistributed Pseudo-tree Optimization Procedure (MO-DPOPLp) is an incomplete, synchronous,\ninference-based algorithm. It adapts DPOP using a scalarization measure based on the Lp-norm\nto find a subset of the Pareto front of a MO-DCOP. Similar to DP-AOF, the algorithm proceeds in\ntwo phases. Its first phase is the same as the first phase of DP-AOF: It solves h mono-objective\nDCOPs using DPOP to find the utopia point ~F\u25e6. In the second phase, the agents coordinate to\nfind a solution that minimizes the distance from ~F\u25e6 according to the Lp-norm. The algorithm is\nguaranteed to find a Pareto optimal solution only when the L1-norm (Manhattan norm) is adopted.\nIn this case, MO-DPOPL1 finds a Pareto optimal solution that minimizes the average cost values of\nall objectives. The worst case runtime, memory, and communication requirements of this algorithm\nare the same as those of DP-AOF.\nDIPLS (Wack, Okimoto, Clement, & Inoue, 2014). Distributed Iterated Pareto Local Search\n(DIPLS) is an incomplete, synchronous, search-based algorithm. It extends the Pareto Local Search\n(PLS) algorithm (Paquete, Chiarandini, & Sttzle, 2004), which is a hill climbing algorithm designed\nto solve centralized multi-objective optimization problems, to solve MO-DCOPs. The idea behind\n29\nFIORETTO, PONTELLI, & YEOH\nDIPLS is to evolve an initial solution toward the Pareto front. To do so, it starts from an initial\nset of random assignments, and applies PLS iteratively to generate new non-dominated solutions.\nDIPLS requires a total ordering of agents and elects one agent as the controller. At each iteration,\nthe controller filters the set of solutions by dominance and broadcasts them to the agents in the MO-\nDCOP. Upon receiving a solution, an agent generates a list of neighboring solutions by modifying\nthe assignments of the variables that it controls, and sends them back to the controller. When the\ncontroller receives the messages from all agents, it proceeds to filter (by dominance) the set of\nsolutions received, and if a new non-dominated solution is found, it repeats the process.\nThe worst case runtime of this algorithm is O(`kp) as the controller agent is required to check\nthe dominance of the newly generated solutions at each iteration. In terms of memory requirement,\nDIPLS agents use O(np) space to store the Pareto front. Finally, in terms of communication\nrequirement, the controller agent broadcasts messages that contain the current Pareto front. Thus,\nthe message size is O(np).\n5. Dynamic DCOPs\nWithin a real-world MAS application, agents often act in dynamic environments that evolve over\ntime. For instance, in a disaster management search and rescue scenario, new information (e.g., the\nnumber of victims in particular locations or priorities on the buildings to evacuate) typically be-\ncomes available in an incremental manner. Thus, the information flow modifies the environment\nover time. To cope with such a requirement, researchers have introduced the Dynamic DCOP (D-\nDCOP) model, where cost functions can change during the problem solving process, agents may\nfail, and new agents may be added to the DCOP being solved. With respect to the categoriza-\ntion described in Section 3, in the D-DCOP model, the agents are fully cooperative and they have\ndeterministic behavior and total knowledge. On the other hand, the environment is dynamic and\ndeterministic.\n5.1 Definition\nThe Dynamic DCOP (D-DCOP) model is defined as a sequence of classical DCOPs: D1, . . . ,DT ,\nwhere each Dt = \u3008At,Xt,Dt,Ft, \u03b1t\u3009 is a DCOP representing the problem at time step t, for 1 \u2264\nt \u2264 T . The goal in a D-DCOP is to solve the DCOP at each time step optimally. By assumption,\nthe agents have total knowledge about their current environment (i.e., the current DCOP) but they\nare unaware of changes to the problem in future time steps.\nIn a dynamic system, agents are required to adapt as fast as possible to environmental changes.\nStability (Dijkstra, 1974; Verfaillie & Jussien, 2005) is a core algorithmic concept in which an\nalgorithm seeks to minimize the number of steps that it requires to converge to a solution each time\nthe problem changes. In such a context, these converged solutions are also called stable solutions.\nSelf-stabilization is a related concept derived from the area of fault-tolerance:\nDefinition 6 (Self-stabilization) A system is self-stabilizing iff the following two properties hold:\n30\nDCOP: MODEL AND APPLICATIONS SURVEY\n(i) Convergence: The system reaches a stable solution in a finite number of steps, starting\nfrom any given state. In the DCOP context, this property expresses the ability of the agents\nto coordinate a joint assignment for their variables that optimizes the problem at time step\nt+ 1, starting from an assignment of the problem\u2019s variables at time step t.\n(ii) Closure: The system remains in a stable solution, provided that no changes in the envi-\nronment happens. In the DCOP context, this means that agents do not change the assignment\nfor their variables after converging to a solution.\nSolving D-DCOPs is NP-hard, as it requires to solve each DCOP of the D-DCOP indepen-\ndently.\n5.2 Algorithms\nIn principle, one could use classical DCOP algorithms to solve the DCOP Dt at each time step\n1 \u2264 t \u2264 T . However, the dynamic environment evolution encourages firm requirements on the\nalgorithm design in order for the agents to respond automatically and efficiently to environmental\nchanges over time. In particular, D-DCOP algorithms often follow the self-stabilizing property.\nAs in the previous sections, the algorithms are categorized as being either complete or incomplete,\naccording to their ability to determine the optimal solution at each time step.\n5.2.1 COMPLETE ALGORITHMS\nS-DPOP (Petcu & Faltings, 2005c). Self-stabilizing DPOP (S-DPOP) is a synchronous,\ninference-based algorithm that extends DPOP to handle dynamic environments. It is composed\nof three self-stabilizing phases: (i) A self-stabilizing DFS pseudo-tree generation, whose goal is\nto create and maintain a DFS pseudo-tree structure; (ii) A self-stabilizing algorithm for the UTIL\npropagation phase; and (iii) A self-stabilizing algorithm for the VALUE propagation phase. These\nprocedures work as in DPOP and they are invoked whenever any change in the DCOP problem\nsequence is revealed. Additionally, Petcu and Faltings (2005c) discuss self-stabilizing extensions\nthat can be used to provide guarantees about the way the system transitions from a valid state to\nthe next, after an environment change.\nThe worst case runtime, memory, and communication requirements of this algorithm to solve\nthe DCOP at each time step are the same as those of DPOP. Additionally, upon changes to the\nproblem, S-DPOP stabilizes after at most \u03c4 UTIL messages and k VALUE messages, where \u03c4 is\nthe depth of the pseudo-tree and k is the number of cost functions of the problem.\nI-ADOPT and I-BnB-ADOPT (Yeoh, Varakantham, Sun, & Koenig, 2011). Incremental Any-\nspace ADOPT (I-ADOPT) and Incremental Any-space BnB-ADOPT (I-BnB-ADOPT) are asyn-\nchronous, search-based algorithms that extend ADOPT and BnB-ADOPT, respectively. In the\nincremental any-space versions of the algorithms, each agent maintains bounds for multiple con-\ntexts; in contrast, agents in ADOPT and BnB-ADOPT maintain bounds for one context only. By\ndoing so, when solving the next DCOP in the sequence, agents may reuse the bounds information\ncomputed in the previous DCOP. In particular, the algorithms identify affected agents, which are\n31\nFIORETTO, PONTELLI, & YEOH\nagents that cannot reuse the information computed in the previous iterations, and they recompute\nbounds exclusively for such agents.\nThe worst case runtime and communication requirements of this algorithm to solve the DCOP\nat each time step are the same as those of ADOPT. However, since these algorithms have the any-\nspace property, their minimal memory requirements are the same as those of ADOPT but they can\nuse more memory, if available, to speed up the algorithms.\n5.2.2 INCOMPLETE ALGORITHMS\nSBDO (Billiau, Chang, & Ghose, 2012a). Support Based Distributed Optimization (SBDO) is an\nasynchronous search-based algorithm that extends the Support Based Distributed Search algorithm\n(Harvey, Chang, & Ghose, 2007) to the multi-agent case. It uses two types of messages: is-good\nand no-good. Is-good messages contain an ordered partial assignment and are exchanged among\nneighboring agents upon a change in their value assignments. Each agent, upon receiving a mes-\nsage, decides what value to assign to its own variables, attempting to minimize their local costs,\nand communicates such decisions to its neighboring agents via is-good messages. No-good mes-\nsages are used in response to violations of hard constraints, or in response to obsolete assignments.\nA no-good message is augmented with a justification, that is, the set of hard constraints that are\nviolated, and are saved locally within each agent. This information is used to discard partial assign-\nments that are supersets of one of the known no-goods. The changes of the dynamic environment\nare communicated via messages, which are sent from the environment to the agents. In particular,\nchanges in hard constraints require the update of all the justifications in all no-goods.\nThe worst case runtime, memory, and communication requirements of this algorithm are the\nsame as those of SyncBB each time the problem changes.\nFMS (Ramchurn, Farinelli, Macarthur, & Jennings, 2010). Fast Max-Sum (FMS) is an asyn-\nchronous inference-based algorithm that extends Max-Sum to the Dynamic DCOP model. As in\nMax-Sum, the algorithm operates on a factor graph. Solution stability is maintained by recomput-\ning only those factors that changed between the previous DCOP Dt\u22121 and the current DCOP Dt.\nRamchurn et al. (2010) exploit domain-specific properties in a task allocation problem to reduce\nthe number of states over which each factor has to compute its solution. In addition, FMS is able to\nefficiently manage addition or removal of tasks (e.g., factors), by performing message propagation\nexclusively on the factor graph regions that are affected by such topological changes. The worst\ncase runtime, memory, and communication requirements of this algorithm to solve the DCOP at\neach time step are the same as those of Max-Sum.\nFMS has been extended in several ways. Bounded Fast Max-Sum provides bounds on the solu-\ntion found, as well as it guarantees self-stabilization (Macarthur, Farinelli, Ramchurn, & Jennings,\n2010). Branch-and-Bound Fast Max-Sum (BnB-FMS) extends FMS providing online domain prun-\ning using a branch-and-bound technique (Macarthur, Farinelli, Ramchurn, & Jennings, 2011).\n32\nDCOP: MODEL AND APPLICATIONS SURVEY\n5.3 Notable Variants: D-DCOPs with Commitment Deadlines or Markovian Properties\nWe now describe several notable variants of D-DCOPs and their corresponding algorithms.\nRS-DPOP (Petcu & Faltings, 2007b). In this proposed model, agents have commitment deadlines\nand stability constraints. In other words, some of the variables may be unassigned at a given point\nin time, while others must be assigned within a specific deadline. Commitment deadlines are either\nhard or soft. Hard commitments model irreversible processes. When a hard committed variable is\nassigned, its value cannot be changed. Soft commitments model contracts with penalties. If a soft\ncommitted variable xti has been assigned at time step t, its value can be changed at time step t\n\u2032 > t,\nat the price of a cost penalty. These costs are modeled via stability constraints, which are defined\nas binary relations si : Di \u00d7Di \u2192 R+, representing the cost of changing the value of variable xi\nfrom time step t to time step t+ 1. Given the set of stability constraints S \u2286 F, at each time step t,\nthe goal is to find a solution \u03c3\u2217t :\n\u03c3\u2217t := argmin\n\u03c3\u2208\u03a3\n\uf8eb\uf8edFg(\u03c3) + \u2211\nsj\u2208S\nsj(\u03c3\n\u2217\nt\u22121(xj), \u03c3(xj))\n\uf8f6\uf8f8 .\nThe latter term accounts for the penalties associated to the value assignment updates for the soft\ncommitted variables. RS-DPOP has the same order complexity as S-DPOP.\nTo solve this problem, Petcu and Faltings (2007b) extended S-DPOP to RS-DPOP.7 Like S-\nDPOP, it is a synchronous, inference-based algorithm. Unlike S-DPOP, it\u2019s UTIL and VALUE\npropagation phases now take into account the commitment deadlines. The worst case runtime,\nmemory, and communication requirements of this algorithm to solve the DCOP at each time step\nare the same as those of S-DPOP.\nDistributed Q-learning and R-learning (Nguyen, Yeoh, Lau, Zilberstein, & Zhang, 2014). In\nthis proposed model, called Markovian Dynamic DCOPs (MD-DCOPs), the DCOP in the next time\nstep Dt+1 depends on the solution (i.e., assignment of all variables) adopted by the agents for the\nDCOP in the current time step Dt. However, the transition function between these two DCOPs are\nnot known to the agents and the agents must, thus, learn them. The Distributed Q-learning and R-\nlearning algorithms are synchronous reinforcement-learning-based algorithms that extend the cen-\ntralized Q-learning (Abounadi, Bertsekas, & Borkar, 2001) and centralized R-learning (Schwartz,\n1993; Mahadevan, 1996) algorithms. Each agent maintains Q-values and R-values for each \u03c3t\u22121, dti\npair, where \u03c3t\u22121 is the solution for the DCOP Dt\u22121 and dti is the value of its variables in the cost\nfunction f ti \u2208 Ft. These Q- and R-values represent the predicted cost the agent will incur if it as-\nsigns its variables values according to dti when \u03c3t\u22121 is the previous solution. The agents repeatedly\nrefine these values at every time step and choose the values with the minimum Q- or R-value at\neach time step.\nThe worst case runtime, communication, and memory requirements of these two algorithms to\nsolve the DCOP at each time step are the same as those of DPOP, as they use DPOP as a subroutine\n7. The full name of the algorithm was not provided by Petcu and Faltings (2007b).\n33\nFIORETTO, PONTELLI, & YEOH\nto update the Q- and R-values. The exception is that agents in the Distributed Q-learning algorithm\nalso broadcast their value assignments at each time step to all other agents. Thus, they send O(m2)\nmessages in each time step instead of the O(m) complexity of DPOP.8\nA related model is the Proactive Dynamic DCOPs (PD-DCOPs) (Hoang, Fioretto, Hou, Yokoo,\nYeoh, & Zivan, 2016; Hoang, Hou, Fioretto, Yeoh, Zivan, & Yokoo, 2017), where the transition\nfunctions between two subsequent DCOPs are known and can be exploited by the resolution pro-\ncess. Additionally, another key difference between these two models is that the DCOP in the next\ntime step Dt+1 does not depend on the solution in the current time step, but instead depends on the\nvalues of the random variables at the current time step. Researchers have introduced a number of\noffline proactive and online reactive algorithms to solve this problem (Hoang et al., 2016, 2017).\n6. Probabilistic DCOPs\nThe DCOP models discussed so far can model MAS problems in deterministic environments. How-\never, many real-world applications are characterized by environments with a stochastic behavior.\nIn other words, there are exogenous events that can influence the outcome of an agent\u2019s action. For\nexample, the weather conditions or the state of a malfunctioning device can affect the cost of an\nagent\u2019s action. To cope with such scenarios, researchers have introduced Probabilistic DCOP (P-\nDCOP) models, where the uncertainty in the state of the environment is modeled through stochas-\nticity in the cost functions. With respect to the DCOP categorization described in Section 3, in the\nP-DCOP model, the agents are fully cooperative and have a deterministic behavior. Additionally,\nthe environment is static and stochastic. While a large body of research has focused on problems\nwhere agents have total knowledge, this section includes a discussion of a subclass of P-DCOPs\nwhere the agents\u2019 knowledge of the environment is limited, and the agents must balance the explo-\nration of the unknown environment and the exploitation of the known costs.\n6.1 Definition\nA common strategy to model uncertainty is to augment the outcome of the cost functions with\na stochastic character (Atlas & Decker, 2010; Stranders, Delle Fave, Rogers, & Jennings, 2011;\nNguyen, Yeoh, & Lau, 2012). Another method is to introduce additional random variables as input\nto the cost functions, which simulate exogenous uncontrollable traits of the environment (Le\u00b4aute\u00b4\n& Faltings, 2009, 2011; Wang, Sycara, & Scerri, 2011). To cope with such a variety, this section\nintroduces the Probabilistic DCOP (P-DCOP) model, which generalizes the proposed models of\nuncertainty. A P-DCOP is defined by a tuple \u3008A,X,D,F, \u03b1, I,\u2126,P, E ,U\u3009, where A and D are\nas defined in Definition 4.1. In addition,\n\u2022 X is a mixed set of decision variables and random variables.\n\u2022 I = {r1, . . . , rq} \u2286 X is a set of random variables modeling uncontrollable stochastic events,\nsuch as weather or a malfunctioning device.\n8. A single broadcast message is counted asm peer-to-peer messages, wherem is the number of agents in the problem.\n34\nDCOP: MODEL AND APPLICATIONS SURVEY\n\u2022 F = {f1, . . . , fk} is the set of cost functions, each defined over a mixed set of decision variables\nand random variables, and such that each value combination of the decision variables on the cost\nfunction results in a probability distribution. As a result, fi is itself a random variable, given the\nlocal value assignment \u03c3xi\\I and a realization for the random variables involved in fi.\n\u2022 \u03b1 : X \\I \u2192 A is a mapping from decision variables to agents. Notice that random variables are\nnot controlled by any agent, as their outcomes do not depend on the agents\u2019 actions.\n\u2022 \u2126 = {\u21261, . . . ,\u2126q} is the (possibly discrete) set of events for the random variables (e.g., the\ndifferent weather conditions or stress levels a device is subjected to) such that each random\nvariable ri \u2208 I takes values in \u2126i. In other words, \u2126i is the domain of random variable ri.\n\u2022 P = {p1, . . . , pq} is a set of probability distributions for the random variables, such that pi :\n\u2126i \u2192 [0, 1] \u2286 R assigns a probability value to an event for ri and\n\u222b\n\u03c9\u2208\u2126i pi(\u03c9) d\u03c9 = 1 for each\nrandom variable ri \u2208 I.\n\u2022 E is an evaluator function from random variables to real values, that, given an assignment of\nvalues to the decision variables, summarizes the distribution of the aggregated cost functions.\n\u2022 U is a utility function that given a random variable returns an ordered set of different outcomes,\nand it is based on the decision maker preferences. This function is needed when the cost functions\nhave uncertain outcomes and, thus, these distributions are not readily comparable.\nThe goal in a P-DCOP is to find a solution \u03c3\u2217, that is, an assignment of values to all the decision\nvariables, such that:\n\u03c3\u2217 := arg min/max\n\u03c3\u2208\u03a3\nE\n\uf8ee\uf8f0\u2211\nfi\u2208F\nU(fi(\u03c3xi\\I))\n\uf8f9\uf8fb (5)\nwhere argmin or argmax are selected depending on the algorithm adopted,\n\u2211\nis the operator that is\nused to aggregate the values from the functions fi \u2208 F. Typically such an operator is a summation,\nhowever, to handle continuous distributions, other operators have been proposed.\nThe probability distribution over the domain of random variables ri \u2208 I is called a belief. An\nassignments of all random variables in I describes a (possible) scenario governed by the environ-\nment. As the random variables are not under the control of the agents, they act independently of\nthe decision variables. Specifically, their beliefs are drawn from probability distributions. Further-\nmore, they are assumed to be independent of each other and, thus, they model independent sources\nof exogenous uncertainty.\nThe utility function U enables us to compare the uncertain cost outcomes of the cost functions.\nIn general, the utility function is non-decreasing, that is, the lower the cost, the higher the utility.\nHowever, the utility function should be defined for the specific application of interest. For example,\nin farming, the utility increases with the amount of produce harvested. However, farmers may\nprefer a smaller but highly certain amount of produce harvested over a larger but highly uncertain\nand, thus, risky outcome.\nThe evaluation function E is used to summarize in one criterion the costs of a given assignment\nthat depends on the random variables. A possible evaluation function is the expectation function:\nE [\u00b7] = E[\u00b7].\n35\nFIORETTO, PONTELLI, & YEOH\nLet us now introduce some concepts that are commonly adopted in the study of P-DCOPs.\nDefinition 7 (Convolution) The convolution of the probability density function (PDF) f(x) and\ng(x) of two independent random variables X and Y is the integral of the product of the two\nfunctions after one is reversed and shifted:\nh(z) = (f \u2217 g)(z) :=\n\u222b \u221e\n\u2212\u221e\nf(\u03c4) g(z \u2212 \u03c4) d\u03c4 =\n\u222b \u221e\n\u2212\u221e\nf(z \u2212 \u03c4) g(\u03c4) d\u03c4 (6)\nIt produces a new PDF h(z) that defines the overlapping area between f(x) and g(y) as a function\nof the quantity that one of the original functions is translated by. In other words, the convolution is\na method of determination of the sum of two random variables. The counterpart for the distribution\nof the sum Z = X + Y of two independent discrete variables is:\nP (Z = z) =\n\u221e\u2211\nk=\u2212\u221e\nP (X = k)P (Y = z \u2212 k). (7)\nIn a P-DCOP, the value returned by a function fi, for an assignment on its scope xi, is a\nrandom variable Vi (Vi \u223c fi(xi)). Thus, the global value\n\u2211\nfi\u2208F Vi is also a random variable,\nwhose probability density function is the convolution of the PDFs of the individual Vi\u2019s. Thus, the\nconcept of convolution of two PDFs in a P-DCOP is related to the summation of the utilities of two\ncost functions in classical DCOPs.\nA common concept in optimization with uncertainty is that of ranking a set of random vari-\nables {r1, r2, . . . } with Cumulative PDFs (CDFs) {F1(x), F2(x), . . . }. These distributions are\nalso commonly called lotteries, a concept related to that of stochastic dominance, which is a form\nof stochastic ordering based on preference regarding outcomes. It refers to situations where a\nprobability distribution over possible outcomes can be ranked as superior to another.\nThe first-order stochastic dominance refers to the situation when one lottery is unambiguously\nbetter than another:\nDefinition 8 (First-Order Stochastic Dominance) Given two random variables ri and rj with\nCDFs Fi(x) and Fj(x), respectively, Fi first-order stochastically dominates Fj iff:\nFi(x) \u2264 Fj(x), (8)\nfor all x with a strict inequality over some interval.\nIf Fi first-order stochastically dominates Fj , then Fi necessarily has a strictly smaller expected\nvalue: E[Fi(x)] < E[Fj(x)]. In other words, if Fi dominates Fj , then the decision maker prefers\nFi over Fj regardless of his utility function U is, as long as it is weakly increasing.\nIt is not always the case that one CDF will first-order stochastically dominate another. In such\na case, one can use the second-order stochastic dominance to compare them. The latter refers to\nthe situation when one lottery is unambiguously less risky than another:\n36\nDCOP: MODEL AND APPLICATIONS SURVEY\nDefinition 9 (Second-Order Stochastic Dominance) Given two random variables ri and rj with\nCDFs Fi(x) and Fj(x), respectively, Fi second-order stochastically dominates Fj iff:\u222b c\n\u2212\u221e\nFi(x) dx \u2264\n\u222b c\n\u2212\u221e\nFj(x) dx, (9)\nfor all c with a strict inequality for some values of c.\nIf Fi second-order stochastically dominates Fj , then E[Fi(x)] \u2264 E[Fj(x)]. If Equation 9 holds for\nall c \u2265 c\u2032, for some sufficiently large c\u2032, then E[Fi(x)] = E[Fj(x)]. In this case, as both lotteries\nare equal in expectation, the decision maker prefers the lottery Fi, which has less variance and is,\nthus, less risky.\nAnother common concept in P-DCOPs is that of regret. In decision theory, regret expresses the\nnegative emotion arising from learning that a different solution than the one adopted, would have\nhad a more favorable outcome. In P-DCOPs the regret of a given solution is typically defined as\nthe difference between its associated cost and that of the theoretical optimal solution. The notion of\nregret is especially useful in allowing agents to make robust decisions in settings where they have\nlimited information about the cost functions.\nAn important type of regret is the minimax regret. Minimax regret is a decision rule used to\nminimize the possible loss for a worst case (i.e, maximum) regret. As opposed to the (expected)\nregret, minimax regret is independent of the probabilities of the various outcomes. Thus, minimax\nregret could be used when the probabilities of the outcomes are unknown or difficult to estimate.\nSolving P-DCOPs is PSPACE-hard, as in general, the process is required to remember a solu-\ntion for each possible state associated to the uncertain random variables. The study of complexity\nclasses for P-DCOPs is largely unexplored. Thus, we foresee this as a potential direction for future\nresearch, in which particular focus could be given in determining fragments of P-DCOPs charac-\nterized by lower complexity than the one above.\n6.2 Algorithms\nUnlike for Classical DCOPs and Dynamic DCOPs, where the algorithms solve the same problem,\nP-DCOP algorithms approach the problem uncertainty in different ways and, thus, solve different\nvariants of the problem. This is due to the greater modeling flexibility offered by the P-DCOP\nframework. As such, the proposed algorithms are often not directly comparable to one another. We\ncategorize P-DCOP algorithms into complete and incomplete algorithms, according to their ability\nto guarantee to find the optimal solutions or not, for a given evaluator and utility functions. Unless\notherwise specified the ordering operator in Equation 5 refers to the argmax operator.\n6.2.1 COMPLETE ALGORITHMS\nE[DPOP] (Le\u00b4aute\u00b4 & Faltings, 2011). E[DPOP] is a synchronous, sampling-based and inference-\nbased algorithm. It can be either complete or incomplete based on the E[DPOP] variant used, and\ndescribed below. E[DPOP] uses a collaborative sampling strategy, where all agents concerned with\n37\nFIORETTO, PONTELLI, & YEOH\na given random variable agree on a common sample set that will be used to estimate the PDF of that\nrandom variable. Agents performing collaborative sampling independently propose sample sets for\nthe random variables influencing the variables they control, and elect one agent among themselves\nas responsible for combining the proposed sample sets into one. The algorithm is defined over\nP-DCOPs with I 6= \u2205 and deterministic cost function outcomes, that is, for each combination of\nvalues for the variables in xi, fi(\u03c3xi\\I) is a degenerate distribution (i.e., a distribution that results\nin a single value) and the utility function U is the identity function. E is an arbitrary evaluator\nfunction summing over all functions in F.\nE[DPOP] builds on top of DPOP and proceeds in four phases: In Phase 1, the agents order\nthemselves into a pseudo-tree ignoring the random variables. In Phase 2, the agents bind random\nvariables to some decision variable. In Phases 3 and 4, the agents run the UTIL and VALUE propa-\ngation phases like in DPOP except that random variables are sampled. Based on different strategies\nadopted in binding the random variables in Phase 2, the algorithm has two variants (Le\u00b4aute\u00b4 & Falt-\nings, 2009). In Local-E[DPOP], a random variable ri \u2208 I is assigned to each decision variable\nresponsible for enforcing a constraint involving ri. In this approach, the agents do not collab-\norate by exchanging information about how their utilities depend on the random variables. In\ncontrast, Global-E[DPOP] assigns ri to the lowest common ancestor agent,9 which is responsible\nfor combining the proposed samples. While this additional information can produce higher-quality\nsolutions, both algorithms are generally incomplete. One exception is when the evaluation func-\ntion E adopted is linear, as in the case of the expectation function, in which case the algorithms are\ncomplete.\nThe worst case runtime, memory, and communication requirements of this algorithm are\nthe same as those of DPOP. The exception is the message size of Global-E[DPOP], which is\nO(dw\n\u2217\nsq), where s is the largest sample set size; the UTIL messages have this size when the root\nas well as all leaves of the pseudo-tree are constrained with all q random variables.\nSD-DPOP (Nguyen et al., 2012). Stochastic Dominance DPOP (SD-DPOP) operates on a P-\nDCOP model where I = \u2205, E is the second order stochastic dominance criteria, U is the identity\nfunction, and \u03a3 denotes the convolution of the distributions fi(\u03c3xi\\I). It is a complete synchronous\ninference-based algorithm that extends DPOP to solve P-DCOPs. Similar to DPOP, it has three\nphases. In Phase 1, like DPOP, it constructs a pseudo-tree. In Phase 2, instead of summing up\ncosts, the agents convolve cost functions, and instead of propagating costs up the pseudo-tree, they\npropagate convolved cost functions. In Phase 3, like DPOP, the agents choose values for their\nvariables. However, instead of choosing values that minimize the cost of their subtrees, the agents\nchoose their values according to the second-order stochastic dominance criteria.\nLike DPOP, SD-DPOP requires a linear number of messages. In addition, in SD-DPOP,\nVALUE messages contain each Pareto optimal value of the sending agent, and UTIL messages\ncontain a representation of the cost function for each Pareto optimal solution and each combination\nof values of the parent and pseudo-parents of the sending agents. Thus, for continuous PDFs that\n9. The agent that is separated by the smallest number of tree edges from all variables constrained with the given random\nvariable.\n38\nDCOP: MODEL AND APPLICATIONS SURVEY\ncould be represented by mean and variance, the message size is O(pdw\n\u2217\n), where p is the size of\nthe Pareto set. If the cost functions are represented by discretized bins, then the message size is\nO(bpdw\n\u2217\n), where b is the maximum number of bins used to represent a cost function. The memory\nrequirement of each SD-DPOP agent is O(pdw\n\u2217\n) or O(bpdw\n\u2217\n), similarly as above, as they need to\nstore and process the messages received. The worst case runtime requirement and the number of\nmessages sent by SD-DPOP are the same as those of DPOP.\n6.2.2 INCOMPLETE ALGORITHMS\nDNEA (Atlas & Decker, 2010). The P-DCOP model proposed by Atlas and Decker (2010) is\ncharacterized by uncertainty exclusively at the level of the outcome of the cost functions, and not\ndue to random variables. Thus, I = \u2205. In addition, the utility function U is the identity function,\nwhile E is a given evaluator function (e.g., the expectation) for the functions fi \u2208 F. In this\nsettings, by employing the evaluation function, Atlas and Decker show that one can reduce the\nuncertainty associated to each cost function to the deterministic case. Thus, one can solve the\nproposed P-DCOP problems using classical DCOP approaches.\nIn particular, they propose the Distributed Neighbor Exchange Algorithm (DNEA), which is\nan incomplete, synchronous, search-based algorithm that is similar to DSA. Each agent starts by\nassigning a random value to each of its variables and sends this information to all its neighbors.\nUpon receiving the values of its neighbors, it computes a cost vector containing the costs for each\npossible combination of values for all its variables, under the assumption that its neighbors\u2019 values\nare those in the messages received. It then sends this cost vector to all its neighbors. Upon receiving\nthe cost vector of its neighbors, it computes the best value for each of its variables, assigns those\nvalues to its variables probabilistically, and sends the assigned values to all its neighbors. This\nprocess repeats until a termination condition is satisfied.\nThe runtime requirement of this algorithm is O(`(ld + d2)). In terms of communication re-\nquirement, the number of messages sent is O(`nl), and the size of each message is O(d). In terms\nof memory requirement, each DNEA agent needs O(ld) amount of memory to store and process\nthe messages received.\nU-GDL (Stranders et al., 2011). The P-DCOP model proposed by Stranders et al. (2011) also\nassumes that the cost functions are not dependent on random variables. Thus, I = \u2205. Additionally,\nthey assume that E is the expectation of the convolution (\u03a3) of the distributions fi(\u03c3xi\\I), and U is a\ngiven risk function. Stranders et al. propose the Uncertain Generalized Distributive Law (U-GDL)\nalgorithm, which is an incomplete asynchronous inference-based algorithm similar to Max-Sum,\nand operates on acyclic graphs. A cyclic constraint graphG is converted into an acyclic graph G\u02c6 by\nmerging variables until the new resulting graph contains no cycles. Merging two variables creates a\nnew variable whose domain is the Cartesian product of the domain of the merged variables. U-DGL\nextends the Generalized Distributive Law (GDL) algorithm (Aji & McEliece, 2000) by redefining\n39\nFIORETTO, PONTELLI, & YEOH\nthe (min,+)10 algebra to the setting where costs are random variables rather than scalars. The +\noperator is extended to perform convolution of two random variables. To cope with the potential\nissue that not all PDFs are closed under convolution, Stranders et al. (2011) suggest to resort to\nsampling methods to approximate such operations. The min operator is defined to distribute over\nconvolution and to select the minimal elements from a set of random variables based on their\nexpected cost. In order to filter partial potential solutions that can never achieve global optimality,\nthe authors introduce a first-order stochastic dominance condition, which is employed in the context\nof the min operator. They also discuss necessary and sufficient conditions for dominance, where\nthe former discards all dominated solutions, but it might also discard some non-dominated solution\n\u2013 this is equivalent to using a classical DCOP algorithms to solve the P-DCOP model adopted in\ntheir work. The latter preserves optimal solutions, but retains, in general, sub-optimal ones as well.\nThe runtime requirement of this algorithm is O(pd\u02c6l), where d\u02c6 is the size of the largest domain\nof the merged variables in G\u02c6. In terms of memory requirement, each U-GDL agent needs O(pd\u02c6l)\nspace to store all value combinations of neighboring variables for each solution in its current Pareto\nfrontier. In terms of communication requirement, the number of messages sent is O(\u03b4(G\u02c6)), where\n\u03b4(G\u02c6) is the diameter of the resulting acyclic graph, and the size of each message isO(pd\u02c6) as agents\nneed to send the current aggregated costs of all the agent\u2019s variable\u2019s values for each solution in its\ncurrent Pareto frontier.\n6.3 Notable Variant: P-DCOPs with Partial Agent Knowledge\nThis section describes a class of Probabilistic DCOPs where agents have partial knowledge about\nthe environment. In other words, the cost functions are only partially known and, therefore,\nagents may discover the unknown costs via exploration (Taylor, Jain, Tandon, Yokoo, & Tambe,\n2011). The new model aims at capturing those domains where agents have an \u201cexplorative nature,\u201d\ni.e., one of the agents\u2019 goals is to acquire knowledge about the environment in which they act.\nAgents are concerned with a total, online, cost achievable in a limited time frame. In this context,\nagents must balance the coordinated exploration of the unknown environment and the exploitation\nof the known portion of the costs, in order to minimize the global utility. This model was originally\ncalled Distributed Coordination of Exploration and Exploitation (DCEE) (Taylor, Jain, Jin, Yokoo,\n& Tambe, 2010).\n6.3.1 DEFINITION\nThe P-DCOP model for agents with partial knowledge is described by extending the P-DCOP\nmodel introduced in Section 6.1, as follows: \u3008A,X,D,F, \u03b1, I,\u2126,P, E ,U , T \u3009, where T > 0 is a\nfinite time horizon characterizing the time within which the agents can exploit the unknown cost\nfunctions and explore the search space. The goal in such a P-DCOP problem is to find a set of\ncomplete assignments ~\u03c3\u2217 = [\u03c3\u22171, . . . , \u03c3\u2217T ] that minimizes the utility of the cumulative cost within\n10. U-GDL was originally defined for maximization problems. Its presentation is adapted to minimization problems for\nconsistency of the DCOP models objective presented in this survey.\n40\nDCOP: MODEL AND APPLICATIONS SURVEY\nthe finite time horizon T :\n~\u03c3\u2217 := arg min/max\n\u03c31,...,\u03c3T\nE\n\uf8ee\uf8f0 T\u2211\nt=0\n\u2211\nfi\u2208F\nU(fi(\u03c3txi\\I))\n\uf8f9\uf8fb (10)\nwhere \u03c3t \u2208 \u03a3 denotes a solution at time step t. In other words, agents have at most T time steps\nto modify the value of their decision variables, and solve T P-DCOP problems by acquiring more\nand more knowledge on the environment as the time unrolls.\n6.3.2 ALGORITHMS\nIn a stochastic and unknown environment, the cost functions need to be learned online through\ninteractions between the agents and their environment. Thus, the algorithms presented in this\nsection are targeted to coordinate agents to solve a sequence of optimization problems in order\nto simultaneously reduce uncertainty about the local cost functions (exploration) and optimize the\nglobal objective (exploitation). In addition, the following algorithms are incomplete.\nBE-Rebid (Taylor et al., 2010). The Balanced Exploration Rebid (BE-Rebid) is a synchronous,\nsearch-based algorithm that solves P-DCOPs with I = \u2205, and U and E are the identity functions. It\nextends MGM as it calculates and communicates its expected gain. The algorithm is introduced in\nthe context of a wireless sensor network problem, where agents can perform small movements in\norder to enhance their communication capabilities, which are characterized by the distance between\npairs of agents. Each agent can perform three actions: stay in the current position, explore another\nposition, or backtrack to a previously explored position and halt movement. In each time step, BE-\nRebid computes the expected cost of executing the explore or backtrack actions, assuming complete\nknowledge of the underlying distribution of the cost functions. Exploring is evaluated by using\norder statistics and is based on the cost of the best value found during exploration. Backtracking to\na known position results in a cost associated to the backtracked state for the remainder of the time\nsteps (i.e., it stays in that state).\nFollowing the region-optimal approaches presented in the context of classical DCOPs, Taylor\net al. (2011) propose a version of the algorithm, called BE-Rebid-2, that allows pairs of agents to\nexplore in a coordinated fashion. Interestingly, in such settings, the authors find that increasing\ncoordination (measured by the number of agents that can execute a joint action) can decrease\nsolution quality. This phenomenon is referred to as team uncertainty penalty. The worst case\nruntime and communication requirements of this algorithm are the same as those of MGM.\nHeist (Stranders, Tran-Thanh, Fave, Rogers, & Jennings, 2012). Heist is a synchronous,\ninference-based algorithm that solves P-DCOPs with I = \u2205, E is the expectation function, and\nU is the identity function. It aims at minimizing the expected utility of the cumulative cost func-\ntion Fg, within the finite time horizon T . It does so by modifying a Multi-Armed Bandit (MAB)\napproach (Vermorel & Mohri, 2005) to a distributed scenario. A MAB is a slot machine with\nmultiple arms, each of which yields a cost drawn from an unknown but fixed probability distribu-\ntion. It trades exploration and exploitation by pulling the arms in order to minimize the cumulative\n41\nFIORETTO, PONTELLI, & YEOH\ncost over a finite horizon. To cope with the uncertain and stochastic nature of the cost functions,\nHeist models each cost function as a MAB, such that the joined assignment of the variables in the\nscope of the given cost function becomes an arm of that bandit. It seeks to minimize the expected\ncumulative optimization cost received over a finite time horizon by repeatedly pulling the MAB\narms to select the joint action with the highest estimated Upper Confidence Bound (UCB) (Auer,\nCesa-Bianchi, & Fischer, 2002) on the sum of the local gains received in a single time step. To\ndo so, it employs a belief propagation algorithm, known as Generalized Distributive Law (GDL)\n(Aji & McEliece, 2000), in order to minimize the UCB in a decentralized fashion. Stranders et al.\n(2012) show that Heist enables agents to balance between exploration and exploitation, and derive\noptimal asymptotic bounds on the regret of the global cumulative cost attained.\nThe worst case runtime requirement of this algorithm is O(`Tdl) as each agent computes the\nmaximum marginal UCB for its variable assignment for each time step before the horizon. In\nterms of memory requirement, each Heist agent needs O(dl) space to store all value combinations\nof neighboring variables. In terms of communication requirement, the number of messages sent\nis O(`T l), one to each neighbor and time step in each iteration, and the size of each message is\nO(Td) as it contains the aggregated costs of all the agent\u2019s variable\u2019s values for each time step.\nICG-Max-Sum (Wu & Jennings, 2014). The Iterative Constraint Generation Max-Sum (ICG-\nMax-Sum) algorithm is a synchronous, inference-based algorithm that solves P-DCOPs with I 6= \u2205,\nE is the identity function, and U(fi(\u00b7)) is the maximal regret function. The algorithm aims at\nminimizing the sum of maximal regrets for all the functions in F. Furthermore, the horizon is\nT = 1. Thus, unlike the previous algorithms, IGC-Max-Sum does not attempt to learn the outcome\nof the cost functions. Its objective is to find robust solutions to the uncertain problem distributions;\nit does so by finding the solution that minimizes the maximum regret. The algorithm extends the\nIterative Constraint Generation (ICG) method (Benders, 1962; Regan & Boutilier, 2010) to the\ndecentralized case by decomposing the overall problem into a master problem and a subproblem\nthat are iteratively solved until convergence. At each iteration, the resolutions of these problems\nare attained by using Max-Sum. The master problem solves a relaxation of the minimax regret\ngoal, where only a subset of all possible joint beliefs is considered, attempting to minimize the\nloss for the worst case derived from the considered joint belief. Once it generates a solution, the\nsubproblem finds the maximally violated constraint associated to such a solution. This is referred to\nas the witness point, indicating that the current solution is not the best one in terms of the minimax\nregret. This point is added to the set of joint beliefs considered by the master problem, and the\nprocess is repeated until no new witness points can be found.\nThe worst case runtime requirement of this algorithm is O(`|I|dl), which is dominated by the\nmaster problem, whose computation is exponential in the number of variables in the scope of the\nassociated cost function for each belief and iteration of the algorithm. In terms of memory require-\nment, each ICG-Max-Sum agent needsO(|I|dl) space (dominated by the master problem again) to\nstore all value combinations of neighboring variables for each belief. In terms of communication\nrequirement, the number of messages sent is the same as that of Max-Sum since two parallel itera-\n42\nDCOP: MODEL AND APPLICATIONS SURVEY\ntions of Max-Sum is executed in each ICG-Max-Sum iteration. However, the size of each message\nis O(|I|d) as it contains the aggregated cost of all the agent\u2019s variable\u2019s value for each belief.\nA variation of this algorithm that aims at minimizing the expected regret, rather than minimiz-\ning the maximum regret, was introduced by Le, Fioretto, Yeoh, Son, and Pontelli (2016).\n7. Quantified DCOPs\nThe various extensions of the DCOP model discussed so far differ from each other in terms of agent\nbehavior (deterministic vs. stochastic), agent knowledge (total vs. partial), environmental behavior\n(deterministic vs. stochastic), and environment evolution (static vs. dynamic). However, in terms of\nthe agent teamwork, all of these models assume the agents are fully cooperative. Researchers have\nintroduced the Quantified DCOP (QDCOP) model (Matsui, Matsuo, Silaghi, Hirayama, Yokoo, &\nBaba, 2010), which assumes a subset of agents to be adversarial, that is, the agents are partially\ncooperative or competitive.\n7.1 Definition\nThe Quantified DCOP (QDCOP) model (Matsui et al., 2010) adapts the Quantified Constraint\nSatisfaction Problem (QCSP) (Benedetti, Lallouet, & Vautard, 2008) and Quantified Distributed\nCSP (QDCSP) (Baba, Iwasaki, Yokoo, Silaghi, Hirayama, & Matsui, 2010; Baba, Joe, Iwasaki, &\nYokoo, 2011) models to DCOPs. In QCSPs and QDCSPs, all variables are associated to quantifiers\nand the constraints should be satisfied independently of the value taken by universally quantified\nvariables. Analogously, in QDCOPs, existential (\u2203) and universal (\u2200) quantifiers are introduced to\ndifferentiate the cooperative agents from the adversarial ones.\nA QDCOP has the form Q(F) := q0x0 . . . qnxn.11 Q is a sequence of quantified variables,\nwhere each qi \u2208 {\u2203,\u2200} quantifies the variable xi. The goal of a QDCOP is to find a global optimal\nsolution of the corresponding DCOP. However, a universally quantified variable is not coordinated\nnor assigned, as the result has to hold when it takes any value from its domain. In contrast, an ex-\nistentially quantified variable takes exactly one value from its domain, as in (cooperative) DCOPs.\nThus, the optimal solution of a QDCOP may be different from that of the corresponding DCOP.\nWhile a DCOP solution defines a single value, associated to its cost, a QDCOP defines upper\nand lower bounds to the optimal solution. In particular, the best choice in a QDCOP defines the\nsmallest lower bound. In the worst case, the universally quantified variables can worsen the overall\nobjective as much as possible. Therefore, the worst case defines the smallest upper bound. While\nfinding an optimal solution for a DCOP is NP-hard, solving a QDCOP is, in general, P-SPACE-hard\n(Benedetti et al., 2008; Lallouet, Lee, Mak, & Yip, 2015).\n11. In the original proposal, the set F is separated in a set of constraints C, representing relationships among variables,\nand a set of functions F , assigning values to each valid assignment.\n43\nFIORETTO, PONTELLI, & YEOH\n7.2 Algorithms\nQDCOPs impose a rigid order on the variables, which reflects the correct order of evaluation of the\nquantifiers. Therefore, classical DCOP algorithms cannot be directly applied to solve QDCOPs.\nMatsui et al. (2010) proposed several variations of ADOPT to solve QDCOPs, which are all based\non a DFS pseudo-tree ordering. To keep the ordering of the quantifiers unchanged, the pseudo-tree\ncan be reshaped by applying extra null edges for each pair of nodes, if necessary.\nAll the algorithms presented here are complete, and are based on the intuition that universally\nquantified variables can be seen as adversarial virtual agents, whose goal is to minimize the overall\nobjective. Following this intuition and the pseudo-tree modifications discussed above, pseudo-tree-\nbased DCOP algorithms can be extended to solve QDCOP.\nMin-max ADOPT (Matsui et al., 2010). Min-max ADOPT is an asynchronous, search-based\nalgorithm that extends ADOPT to solve QDCOPs. It uses VALUE messages to communicate\nvalues of the variables, and COST messages to announce their costs, similar to ADOPT. Each agent,\nstarting from the root of the pseudo-tree, assigns values to its variables and propagates them to its\nneighboring agents with lower priority. Upon receiving VALUE messages from all higher-priority\nneighbors, the agent updates its context and repeats the same process by choosing an assignment\nthat minimizes its local cost. In Min-max ADOPT, the existentially quantified variables are used to\ncompute the lower bound, while the universally quantified variables are used to compute the upper\nbound. This process is executed until the root agent detects that the upper bound is equal to the\nlower bound. This algorithm has a relatively simple structure and does not adopt any major pruning\nstrategy.\nAlpha-beta ADOPT (Matsui et al., 2010). Alpha-beta ADOPT is an asynchronous, search-based\nalgorithm that extends Min-max ADOPT by adapting the alpha-beta search strategy, a common\npruning strategy adopted in game-tree search. This strategy employs two boundary parameters,\nalpha and beta, representing the lower bound and the upper bound for each possible cost of an\nassignment, respectively. Alpha represents the lower bound, controlled by the universally quan-\ntified variables, while beta represents the upper bound, controlled by the existentially quantified\nvariables. Lower bound and upper bound can be modified exclusively by universally quantified\nand existentially quantified variables, respectively. In Alpha-beta ADOPT, when an agent reports\nthe cost value of the current partial assignment, its parent reduces the alpha/beta threshold accord-\ningly. Thus, the new alpha/beta values are used to prune the search when an agent detects that\nthe current assignment cannot be better than any other solution already evaluated. Alpha and beta\nvalues are obtained using a backtracking technique similar to how thresholds are obtained through\nbacktracking in the original ADOPT.\nBi-threshold ADOPT (Matsui et al., 2010). Bi-threshold ADOPT extends ADOPT by employing\ntwo backtracking thresholds instead of one as in ADOPT. In ADOPT, each agent ai maintains the\nthreshold invariant lb\u2217i \u2264 ti \u2264 ub\u2217i , where lb\u2217i and ub\u2217i are the smallest lower and upper bounds,\nrespectively, of the agent over all of its values, and ti is the threshold of the agent. In contrast, in\nBi-threshold ADOPT, each agent maintains the threshold invariant lb\u2217i \u2264 t\u03b1i \u2264 t\u03b2i \u2264 ub\u2217i , where t\u03b1i\n44\nDCOP: MODEL AND APPLICATIONS SURVEY\nGroup Problem Model\nAK EB EE\nDISASTER MANAGEMENT Disaster Evacuation T D S/D\n& COORDINATION Coalition Formation P D D\nRADIO FREQUENCY ALLOCATION Cooperative Channel Assignment T D S/D\nRECOMMENDATION SYSTEMS Group Recommendation T D S\nSCHEDULING\nDistributed Meeting Scheduling T D S\nWater Allocation Scheduling T D S\nVessel Rotation Planning T D S\nPatient Scheduling T D S/D\nSENSOR NETWORK\nTarget Tracking T D/S D\nRobotic Network Optimization P D D\nMobile Sensor Team P S D\nSensor Sleep Scheduling T D S\nSERVICE-ORIENTED COMPUTING\nApplication Component Placement T D S\nServer Allocation T D D\nSMART GRID AND SMART BUILDINGS\nEconomic Dispatch T D/S S/D\nPower Supply Restoration T D S\nMicrogrid Islanding T D S\nProsumer Energy Trading T D/S S\nSmart Building Devices Scheduling T D/S S/D\nSUPPLY CHAIN MANAGEMENT Supply Chain Formation T D S/D\nTRAFFIC CONTROL Traffic Light Synchronization T/P S D\nTable 5: DCOP Applications. AK = Agent Knowledge, it can be [T]otal or [P]artial; EB = Envi-\nronment Behavior, it can be [D]eterministic or [S]tochastic; EE = Environment Evolution, it can be\n[S]tatic or [D]ynamic\nis a lower bound on the threshold, similar to alpha in Alpha-beta ADOPT, and t\u03b2i is an upper bound\non the threshold, similar to beta in Alpha-beta ADOPT.\n8. DCOP Applications\nDCOP models have been adopted to represent a wide range of MAS applications, thanks to their\nability to capture essential and fundamental MAS aspects as well as the support for the development\nof general domain-independent algorithms. This section describes some of the most compelling\napplications as well as a general overview of their corresponding DCOP models. A comprehensive\nlist of DCOP applications, categorized according to the DCOP classification of Table 2, is given in\nTable 5.\n8.1 Disaster Management and Coordination Problems\nDisaster management and coordination problems refer to how to efficiently and effectively respond\nto an emergency. In these scenarios, low-powered mobile devices that require limited bandwidth\n45\nFIORETTO, PONTELLI, & YEOH\nare often deployed and utilized to assist the disaster management process. Due to their decen-\ntralized nature, the DCOP approach fits naturally with this application. A description of several\nproblems within this application domain is presented next.\nDisaster Evacuation Problems. In a disaster scenario, moving evacuees to the closest refuge\nshelter can quickly overwhelm shelter capacities. A number of researchers have proposed a DCOP\nmodel for disaster evacuation, in which several groups of evacuees have to be led to available\nshelters (Carpenter, Dugan, Kopena, Lass, Naik, Nguyen, Sultanik, Modi, & Regli, 2007; Kopena,\nSultanik, Lass, Nguyen, Dugan, Modi, & Regli, 2008; Lass, Kopena, Sultanik, Nguyen, Dugan,\nModi, & Regli, 2008a; Lass, Regli, Kaplan, Mitkus, & Sim, 2008b; Kinoshita, Iizuka, & Iizuka,\n2013). Group leaders can communicate via mobile devices to monitor and coordinate actions.\nEach group is represented by a DCOP agent managing variables that represent shelter allocations.\nThus, the domain of each variable corresponds to the available shelters. Group sizes and shelter\ncapacity, as well as additional group requirements (e.g., medical needs) and the distance of a group\nto shelters, are encoded as cost functions. Solving the DCOP ensures an assignment of all groups\nto shelters that minimizes overflow, such that groups receive the services they need and their travel\ndistances are minimal.\nCoalition Formation with Spatial and Temporal Constraints Problems. In a Coalition For-\nmation with Spatial and Temporal Constraints (CFST) problem (Ramchurn et al., 2010; Steinbauer\n& Kleiner, 2012; Pujol-Gonzalez, Cerquides, Farinelli, Meseguer, & Rodriguez-Aguilar, 2015),\nambulance and fire brigade agents cooperate in order to react efficiently to an emergency scenario\nso as to rescue victims and extinguish fires located in different locations. Agents can travel from\none location to another in a given time. Each task (i.e., rescuing a victim, extinguishing a fire)\nhas a deadline, representing the time until which the victim will survive, and a workload, denoting\nthe amount of time necessary to rescue the victim or put out the fire. The locations of the victims\nand the fires may be unknown to the agents, and need to be discovered at runtime, which requires\nagents to dynamically update the sequence of the tasks they will attempt, taking account of two\nmain constraints: (1) Spatial constraints, which model where an agent can travel and at what time;\nand (2) Temporal constraints, which model task deadlines and completion times. Agents may also\nform coalitions to execute a given task faster or if the requirements of a given task cannot be met\nby a single agent. Hence, the agents\u2019 arrival times at each task need to be coordinated in order to\nform the desired coalition. The objective is to maximize the number of tasks to be completed.\nA DCOP formalization for the CFST is described by Ramchurn et al. (2010), where ambu-\nlances and fire brigades are modeled as DCOP agents. Each agent controls a variable that encodes\nthe current task that the agent will attempt, and whose domain represents task locations. Unary\nconstraints restrict the set of reachable locations, according to distance from a destination and the\nvictim\u2019s deadline. Agents\u2019 coalitions are defined as groups of agents traveling to the same location.\nEach task is associated to a utility, which encodes the success for a coalition to complete such task.\nThe goal is to find an assignment of agents to tasks that maximizes the overall utility.\nA variant of the CFST problem, called the Law Enforcement Problem (LEP), was introduced\nby Amador, Okamoto, and Zivan (2014). Similar to the CFST problem, in a LEP, police officers\n46\nDCOP: MODEL AND APPLICATIONS SURVEY\nneed to execute a number of tasks, and may form coalitions to improve their response quality.\nAdditionally, and differently from the CFST, new tasks can be revealed to the agents dynamically\nover time. Agents can choose to interrupt their current task to perform a new revealed task at the\ncost of a penalty that is proportional to the importance of the task being interrupted.\n8.2 Radio Frequency Allocation Problems\nThe performance of a wireless local area network (WLAN) depends on the channel assignments\namong neighboring access points (APs). Neighboring transmissions occurring in APs on the same\nchannel or adjacent channels degrade network performance due to transmission interference. In\ndense urban areas, different APs may belong to different administrative domains, whose control is\ndelegated to different entities. Thus, a distributed approach to the channel assignment is necessary.\nCooperative Channel Assignment Problems. In a cooperative channel assignment problem\n(Hollos, Karl, & Wolisz, 2004; Monteiro, Pellenz, Penna, Enembreck, Souza, & Pujolle, 2012a;\nMonteiro, Pujolle, Pellenz, Penna, Enembreck, & Demo Souza, 2012b), APs need to be config-\nured in order to reduce the overall interference between simultaneous transmissions on neighbor-\ning channels. Monteiro et al. (2012a, 2012b) proposed a DCOP-based approach for cooperative\nchannel assignment in WLANs where APs may belong to different administration entities. In the\nproposed model, each AP is represented by a DCOP agent, which controls a decision variable\nmodeling a choice for the AP\u2019s channels. The signal-to-interference-and-noise ratio perceived by\nan AP or a client is modeled as a cost function, as the overall concurrent transmissions occurring in\nthe same channel and in partially overlapped adjacent channels. The goal is to find an assignment\nof channels to APs that minimizes the total interference experienced in the WLAN.\nXie, Howitt, and Raja (2007) and Mir, Merghem-Boulahia, and Ga\u0131\u00a8ti (2010) study dynamic\nsolutions to the problem of allocating and utilizing the wireless network\u2019s available spectrum. In\nsuch a problem, the agents operate in a dynamic radio frequency environment that is composed of\ntime-varying interference sources, which are periodically sampled and measured.\n8.3 Recommendation Systems\nRecommendation systems are tools that provide user-tailored information about items to users.\nThese systems provide information that is tailored to the characteristics and preferences of the\nusers.\nGroup Recommendation Problems. Like individual recommendations, group recommendations\nneed to take into account the preferences of all group members and formulate a recommendation\nthat suits the whole group. Lorenzi, dos Santos, Ferreira Jr, and Bazzan (2008) propose a DCOP-\nbased travel package recommendation system for groups of users. The users in the group share\na common goal (the travel package recommendation), and have individual preferences for each\ntravel service (hotel, flight companies, tour operators, etc). In such a problem, the objective is to\nfind a group recommendation that optimizes the users\u2019 preferences. The proposed DCOP solution\nis composed of two types of agents: user agents and recommender agents. Each user agent controls\n47\nFIORETTO, PONTELLI, & YEOH\na decision variable that models that user\u2019s travel choices, while each recommender agent controls\na decision variable that models a travel service supplier\u2019s recommendations. User travel prefer-\nences are modeled via unary constraints on the user agents\u2019 decision variables. Binary constraints\nbetween user agents in a group and their associated recommender agent ensure that each user\u2019s\nchoice in the group is compatible to the recommendation of the recommender agent. The goal is to\nfind the best recommendation for the entire group.\n8.4 Scheduling Problems\nScheduling problems are an important class of problems that have been long studied in the area\nof constraint programming and operations research (Giffler & Thompson, 1960; Solomon, 1987;\nMinton, Johnston, Philips, & Laird, 1992; Van Hentenryck & Michel, 2009). In such problems,\ntime schedules are to be associated to resource usage. The problem is made particularly difficult\nwhen the scheduling process needs to be coordinated in a distributed manner across several entities.\nIn such a context, many scheduling problems can be naturally mapped to DCOPs.\nDistributed Meeting Scheduling Problems. The distributed meeting scheduling problem cap-\ntures generic scheduling problems where one wishes to schedule a set of events within a time range\n(Jennings & Jackson, 1995; Garrido & Sycara, 1996). Each event is defined by: (i) the resources\nrequired for it to be completed, (ii) the time required for it to be completed, within which it holds\nthe required resources, and (iii) the cost of using such resources at a given time. A scheduling\nconflict occurs if two events with at least one common resource are scheduled in overlapping time\nslots. The goal is to maximize the utilities over all the resources, defined as the net gain between\nthe opportunity benefit and opportunity cost of scheduling various events.\nMaheswaran, Tambe, Bowring, Pearce, and Varakantham (2004b) discuss three possible DCOP\nformulations for this problem: Time slots as variables (TSAV), events as variables (EAV), and\nprivate events as variables (PEAV). We describe the EAV formulation and refer the reader to the\noriginal article for the other two formulations and additional details. In the EAV formulation, events\nare considered as decision variables. Each variable can take on a value from the time slot range\nthat is sufficiently early to schedule the required resources for the required amount of time, or zero\nto denote that an event is not scheduled. If a variable takes on a non-zero value, then all its required\nresources cannot be assigned to any other overlapping event.\nWater Allocation Scheduling Problems. The management of water resources in large-scale\nsystems is often associated with multiple institutionally-independent decision makers, which may\nrepresent different and conflicting interests, such as flood prevention, hydropower production, and\nwater supply (Giuliani, Castelletti, Amigoni, & Cai, 2014). The aim of such problems is to find an\nefficient use of water allocation and distribution according to the different users\u2019 interests.\nGiuliani et al. (2014) formalize a regulatory mechanism in water management as a DCOP.\nThe model involves several active human agents and passive ecological agents. Each agent is\nassociated with an objective function that it seeks to maximize. Active agents make decisions about\nthe amount of water to divert from the river or to be released from a dam in order to maximize\ntheir corresponding objective functions. Passive agents, on the other hand, represent ecological\n48\nDCOP: MODEL AND APPLICATIONS SURVEY\ninterests through their associated objective functions and do not make decisions. The agents model\ndifferent water supplies for cities and agricultural districts, hydropower productions, and ecological\npreservation. The goal is to optimize the agents\u2019 objective functions, satisfying hard (physical)\nconstraints and maximizing the soft (normative) constraints, which aim at protecting the interests\nof the passive agents. A solution to such problem, which makes use of a multi-objective DCOP\nformalization, is presented in (Amigoni, Castelletti, & Giuliani, 2015).\nVessel Rotation Planning Problem. In a large port, vessels are scheduled to visit different\nterminals for loading and unloading operations. The sequence of terminals visited by a vessel is\ncalled the vessel rotation. Due to the different nature of the terminal visits (e.g., loading, unload-\ning containers, different inland shipping activities) there are often dependencies between activities\nperformed at the terminals. Additionally, vessel operators have their own preferences on when\nto visit a particular terminal. The vessel rotation planning problem (VRPP) (Li, Negenborn, &\nLodewijks, 2016) describes the problem of assigning rotations to vessels, consisting of sequences\nof visits to terminals and arrival and departure times of vessels to terminals in a port area, while\nsatisfying the terminals\u2019 visits dependencies and taking into account operators\u2019 preferences. Due\nto the geographically distributed nature of the resources (vessels, terminals, loading facilities) and\nthe distributed coordination process undertaken by vessels operators, this problem fits naturally in\nthe DCOP framework.\nLi et al. (2016) proposed a DCOP model for the VRPP, where vessels and terminals are modeled\nas DCOP agents. The problem\u2019s variables are the time slot for which a vessel i is at terminal j (xij),\nthe arrival and departure times of vessel i at terminal j (aij and dij , respectively), and the number\nof time steps a vessel i waits at terminal j (wij). A vessel agent i governs variables xij , aij , dij ,\nand wij , for each terminal j that it can visit, while a terminal agent controls auxiliary variables yij\nfor each vessel i that can visit j, which has the same value of xij and is used by terminal agents to\nrepresent the terminal capacities. The problem constraints represent the preferences of vessels of\nbeing at a given terminal in a given time, the penalty occurring for a waiting vessel, and the time\nwindows during which a vessel can visit a terminal.\nPatient Scheduling Problems. Medical appointments scheduling problems are related to meet-\ning scheduling problems, as they need to associate patients to resources (e.g., doctors, medical\nmachinery) and times, but they require different types of constraints. Patients may require several\nservices from different departments within the same hospital or in multiple hospitals. In general,\nthe objective is to minimize the patient treatment waiting time under limited resource conditions,\nas well as to ensure efficient resource usage, taking into account patient preferences.\nHannebauer and Mu\u00a8ller (2001) formulate the problem of scheduling patients to diagnostic units\nin an hospital as a DCOP, where appointments are modeled as variables, whose domains describe\ntimes, durations, and locations. The constraints of the problem model the schedule feasibility, the\npatient preferences over hospitalization times, the workplace constraints, which restricts the types\nof appointment for a given workplace, and diagnostic unit constraints, which model resource usage.\nBilliau, Chang, Ghose, and Miller (2012b, 2012c) propose a Dynamic DCOP model for a\nradiotherapy patients scheduling problem. In this problem, each agent represents a patient, and it\n49\nFIORETTO, PONTELLI, & YEOH\ncontrols variables that represent private information (e.g., type of tumor, number of radiation doses\nper day, the use of chemotherapy) and public information (e.g., current schedule of the radiotherapy\nmachine). The constraints of the problem model the duration of each daily treatment, as well as\ntumor-specific treatment restrictions. The problem objective considers patient waiting times to\nreceive their treatment, patient priorities (based on tumor aggressiveness), and patient preferences.\n8.5 Sensor Network Problems\nSensor networks typically consist of a large number of inexpensive and autonomous sensor nodes,\nconstrained by a limited communication range and battery life. These networks have been de-\nployed for environmental sensing (temperature, humidity, etc.), military applications (e.g., bat-\ntlefield surveillance), and target tracking (Akyildiz, Su, Sankarasubramaniam, & Cayirci, 2002).\nWhen deploying sensor networks, it may not be possible to pre-determine the position of each sen-\nsor node. The distributed nature of the problem and the presence of several communication and\nsensing constraints create a natural fit for DCOPs to solve a wide range of related applications.\nTarget Tracking Problems. In a target tracking application (Zhang et al., 2005; Matsui & Mat-\nsuo, 2008; Jain, Taylor, Tambe, & Yokoo, 2009; Ota, Matsui, & Matsuo, 2009; Stranders, Farinelli,\nRogers, & Jennings, 2009; Semnani & Basir, 2013), a collection of small Doppler sensors are scat-\ntered in an area to detect possible moving targets in the region. Each sensor is battery-powered, can\ncommunicate with one another through radio communication, and can scan and detect an object\nwithin a fixed range. Communication incurs an energy cost. Thus, to save energy, a sensor may\nturn itself off. Multiple sensors may be necessary to detect a single target with high accuracy. The\noverall objective is to maximize the number of targets detected, as quickly as possible and, at the\nsame time, preserve energy so as to prolong the system\u2019s lifetime\nZhang et al. (2005) models a simplified version of the above problem as a weighted graph\ncoloring problem, where the total weight of violated constraints needs to be minimized. A node\ncorresponds to a sensor, an edge between two nodes represents the constraint of a shared region\nbetween agents, and the weight captures the importance of the common region. The size of the\ncommon region reflects the amount of energy loss when two sensors scan the shared region at\nthe same time. Each color corresponds to a time slot in which a sector is scanned. A node must\nhave at least one color so that the corresponding sector is scanned at least once. This graph coloring\nproblem is mapped to a DCOP, where agents represent nodes, agent\u2019s variables represent the agents\ndecision on their color, and cost functions represent the graph edges.\nSemnani and Basir (2013) use a hierarchical DCOP approach to scale to larger problems. The\nauthors partition the original problem into n local regions, and use n DCOPs to solve the smaller\nsubproblems. Their solutions are then combined in a hierarchical approach, solved by a DCOP that\nencompasses variables and constraints shared among the connected regions of the lower hierarchy\nDCOPs.\nRobotic Network Optimization Problems. The robotic network optimization problem describes\na sensor network problem where sensors are placed on top of robots that have limited movement\n50\nDCOP: MODEL AND APPLICATIONS SURVEY\ncapability. In such a problem, robots can make small movements to optimize the wireless con-\nnectivity with their neighbors, without affecting the network topology (Choxi & Modi, 2007; Jain\net al., 2009).\nJain et al. (2009) proposed a DCOP formulation where each robot is represented by an agent.\nEach agent controls one variable describing the decision on the robots\u2019 possible movements. Thus,\nthe variables\u2019 domains consist of the valid positions the agent can move to. The cost functions of\nthe problem model the power loss (or gain, depending on the optimization criteria) of the wireless\nlink from a transmitter and a receiver robot, and depend on their positions. Radio communica-\ntion in wireless sensor networks have a predictable signal strength loss that is roughly inversely\nproportional to the square of the distance between transmitter and receiver. However, radio wave\ninterference is very difficult to predict (Molisch, 2012). Thus, Jain et al. (2009) use a P-DCOP-\nbased approach with partial agent knowledge to capture the robot\u2019s partial knowledge on its cost\nfunctions, and to balance exploration of the unknown costs and exploitation of the known portion\nof the costs.\nMobile Sensor Team Problem. The Mobile Sensor Team (MST) problem is similar to the target\ntracking problem with the difference that agents are capable of moving autonomously within the\nenvironment and that time is modeled explicitly as a discrete sequence of time steps. In an MST,\nagents are placed on a grid. For an agent ai, cur pos i denotes the agent\u2019s current position; SRi\ndenotes the agent\u2019s perception sensing range, which determines the coverage range within which\nan agent can detect targets; MRi denotes the agent\u2019s mobility range, which defines the maximum\ndistance that the agent can move within a single time step; and cred i denotes the agent\u2019s credibility,\nwhich reflects the likelihood of the correctness of the detected targets. The targets are defined\nimplicitly through an environmental requirement (ER) function, which defines, for each point in\nthe space, the minimum joint credibility value (the sum of the credibility variables) required for\nthat point to be sensed. In such a representation, targets are points p with ER(p) > 0. Given a set\nof agents SRp whose sensing range covers a target p, the remaining coverage requirement of p is\nthe environmental requirement diminished by the joint credibility of the agents currently covering\np: Cur REQ(p) = max{0, ER(p) \t\u2211ai\u2208SRp cred i}, where \t : R \u00d7 R \u2192 R is an operator\nthat defines how the environmental requirement decreases by the joint credibility. The goal of the\nagents is to find positions that minimize the values of Cur REQ for all targets.\nMST problems are modeled through a subclass of Dynamic DCOPs, named DCOP MST (Zi-\nvan, Glinton, & Sycara, 2009; Yedidsion, Zivan, & Farinelli, 2014; Yedidsion & Zivan, 2014).\nEach agent ai controls one variable xi representing its position, and whose domain contains all lo-\ncations within MRi of cur pos i. Thus, the domains are updated each time the agent moves.\n12 The\nconstraint Cp of a target p involves exclusively those agents ai whose variable\u2019s domain includes a\nlocation within SRi of p. Thus, at each time step, both domains and constraints may change. As a\nconsequence, the constraint graph changes as well \u2013 the neighbors of each agent have to be updated\nat each time step. Finally, in a DCOP MST two agents are neighbors if their sensing areas overlap.\n12. An alternative representation is that of modeling the domain of each variable as the entire grid, and to constrain the\nagent variable, at each agent move, in order to hide those points lying outsideMRi.\n51\nFIORETTO, PONTELLI, & YEOH\nSensor Sleep Scheduling Problem. Wireless sensor nodes are equipped with a radio, which\ncan be used to communicate with neighboring nodes, and a limited power source. These sensor\nnodes are often deployed in inaccessible terrains, thus, replacing their power sources may not be\npossible. The wireless sensor sleeping scheduling problem aims at switching on/off a particular\nsensor node component (such as the sensor or the radio) for a certain period of time, so to ensure\npower conservation, maximizing the lifetime of the sensor network.\nChachra and Marefat (2006) proposed a DCOP model for this problem, where each sensor is an\nagent whose variables denote its status (on or off) for each time step. Hard constraints are employed\nto enforced that if a sensor is on, then all its neighbors should be off, and that sensors cannot stay\non for two consecutive time steps. The overall objective is to minimize the delay induced in the\nnetwork.\nA similar problem is solved by Stranders et al. (2009), where sensors are also able to harvest\nenergy from the environment (e.g. using a photo-voltaic cell or vibration-harvesting microgenera-\ntors). In such a context, the goal is to find a schedule that maximizes the probability of detecting\nevents while maintaining energy-neutral operations (that is, exhibit an indefinite lifetime for each\nof the agents).\n8.6 Service-Oriented Computing Problems\nThe service-oriented computing paradigm is one that relies on sharing resources over a network,\nfocusing on maximizing the effectiveness of the shared resources, which are used by multiple\napplications. Efficient solutions with optimal use of resources are crucial in this paradigm and\nhave a wide industrial impact (Moreno-Vozmediano, Montero, & Llorente, 2013). The distributed\nnature of the resources and the privacy concerns arising when different clouds are involved in the\ndeployment, makes DCOP appealing to solve a range of problems in this paradigm (Mejias & Roy,\n2010).\nApplication Component Placement Problems. An Application Component Placement (ACP)\nproblem is defined over a network of servers offering storage devices with various capabilities, and\ncomponent-based application with requirements for processing, communication, and storage (Jin,\nCao, & Li, 2011; Li, Wang, Ding, & Li, 2014). The ACP problem is a problem of deciding which\nserver to assign to each application component. The component-based application is described by\na set of characteristics that establish their requirements in terms of hardware (e.g., CPU speed, stor-\nage capacity) as well as constraints between components of the same application (e.g., minimum\nbandwidth, secure communication channel requirement). When the APC involves deployment on\nmultiple clouds data privacy must be preserved. Additionally, in cloud environments computing\nresources are shared by many applications and the infrastructure is dynamically changing, making\ncentralized solutions unfeasible.\nJin et al. (2011) proposed a DCOP model for the ACP problem where servers bid for a compo-\nnent to host, with an emphasis that is proportional to the affinity of the server characteristics and\nthe component hardware and software requirements. Each server is modeled by an agent, which\ncontrols a decision variable representing the server bids. Thus, the domain of each variable is the\n52\nDCOP: MODEL AND APPLICATIONS SURVEY\nset of possible components that may be deployed on the server. Unary functions express utility\nfor each component. Hard constraints are employed to ensure that each component is deployed\nexactly on a single server, and that two components are placed between servers satisfying the re-\nquired communication bandwidth. The objective is to find a feasible assignment of component to\nservers that maximizes the utilities.\nServer Allocation Problems. Services-oriented middleware networks are composed of entities\nconnected within a physical network. These entities can both provide and require multiple ser-\nvices. In turn, each service can be provided by multiple servers and can serve multiple clients. A\nservice request from a given client, takes into account various Quality of Service (QoS) parameters\n(e.g., service response time, service completion time). When a client generates a service request,\nit can be satisfied by any of the servers offering such requests. The server allocation problem is a\nproblem of selecting servers to allocate services, ensuring maximum social welfare, while meeting\nthe QoS requirements of all clients.\nChoudhury, Dey, Dutta, and Choudhury (2014) presented a DCOP model for this problem\nwhere agents correspond to network entities, variables correspond to services, and their values are\neither 1, if the associated agent is willing to provide/forward the service, or 0, otherwise. Clients\u2019\nservice requests are mapped to servers\u2019 service offers, accounting for the delays that occur when\ntraversing between intermediate nodes using a routing multicast protocol (Yan, Lee, Shen, & Qiao,\n2013). Moreover, in order to provide a service, all requested QoS requirements need to be satis-\nfied. The utility associated to each variable is the combination of the utility for such a node when\nacting as a service consumer, a service provider, and a service forwarder, and depends on several\nparameters, such as available GPU cycles, battery power, memory, and bandwidth. The problem\nmay change dynamically when a new request is made, or when a new service is offered or released,\nand as such can be modeled as a Dynamic DCOP.\n8.7 Smart Grid and Smart Homes Problems\nThe smart grid is a vision of the future electricity grid (also called power network) that uses data\nanalytics and decision making to improve the efficiency and reliability of energy production and\ndistribution. The development of smart grids poses several challenges: (i) How to deal with the\nincreasing power network utilization due to growth of loads, such as electric vehicles (EVs) and\nheat pumps; (ii) How to efficiently integrate a diverse range of energy sources, including renewable\ngenerators, into the power network; and (iii) How to deal with the uncertainty in the equipment as\nwell as in the participation of consumers through demand-side technologies. Due to the distributed\nand dynamic nature of loads and generators participating in the power network, agent-based de-\ncentralized autonomous control of smaller distributed microgrids is a very compelling solution\n(Davidson, Dolan, McArthur, & Ault, 2009; Ramchurn, Vytelingum, Rogers, & Jennings, 2012).\nIn particular, several agent-based decentralized optimization solutions have been explored to de-\nliver this vision (Kumar, Faltings, & Petcu, 2009; Matsui & Matsuo, 2011; Miller, Ramchurn, &\nRogers, 2012; Jain, Ranade, Gupta, & Pontelli, 2012). The following is a list of the most prominent\nDCOP approaches for smart grid and smart homes applications.\n53\nFIORETTO, PONTELLI, & YEOH\nEconomic Dispatch Problems. Economic Dispatch (ED) is the problem of coordinating the vari-\nous settings of the power generators in order to meet the power loads with the lowest cost possible,\nwhile satisfying the physical power network constraints (Wood & Wollenberg, 2012). Researchers\nhave cast this problem as a DCOP (Miller et al., 2012; Jain et al., 2012; Gupta, Jain, Yeoh, Ranade,\n& Pontelli, 2013a; Athanasiadis, Kockar, & McArthur, 2013), considering a network of nodes\n(agents), each of which relays power to other nodes, but can also contain a combination of gen-\nerators and loads. Generators are distributed across nodes, and are represented through variables\nwhose domain describe a certain set of discrete power outputs. The power lines connecting nodes\nof the networks are also associated to DCOP variables, each of which has a thermal capacity de-\nscribing the maximum power that it can safely carry. The DCOP objective function describes a\nparticular optimization criteria, such as minimizing the carbon emissions of generators within the\nnetwork, as well as the imposed load and network constraints. In particular, the constraints ensure\nthat the overall demand and supply are in balance and that the thermal capacity constraints of the\npower lines are satisfied.\nA version of the ED problem with a planning horizon has been proposed by Fioretto, Yeoh,\nPontelli, Ma, and Ranade (2017b). This formalization extends the ED model described above\nby capturing the physical restrictions of transmission lines, power loads, and power generators\narising when deploying a sequence of solutions (set-points for generators and loads) over time. In\nparticular, it models the maximum incremental power that can be supplied or reduced in one time\nstep to each power generator, which depends on the mechanical characteristics of the generators.\nThis problem has been cast as a Dynamic DCOP, where, in addition to the variables and constraints\nof the classic ED problem, a set of constraints is introduced between each two consecutive time\nsteps to limit the maximum variation of the generators\u2019 output.\nPower Supply Restoration Problems. After (multiple) line failures, a power network must be\nreconfigured to ensure restoration of power supply. A power network distribution is a network\nof power lines connected by switching devices (SDs) and fed by circuit breakers (CBs). SDs are\nanalogous to sinks (transformer stations), while CBs are analogous to power sources. Both of these\ndevices can operate in two states: open or closed. Closed SDs consume some power and forward\nthe rest of it on other lines. Open SDs stop power flow. CBs feed the network when they are closed.\nThe configuration of the devices\u2019 state is such that energy flow traversing CBs takes the form of a\n(feeder) tree, and that no SD is powered by more than a single power line. Flow conservation and\ntransmission line capacity constraints must be enforced. The power supply restoration problem is\nthe problem of finding a configuration that ensures power restoration for the maximum number of\nsinks affected by the line failures.\nResearchers have proposed a DCOP formulation for this problem (Kumar et al., 2009; Agrawal,\nKumar, & Varakantham, 2015). In such a framework, each node of the distribution network is\ncontrolled by an agent that owns all variables and constraints corresponding to that node. Two\nDCOP variables are associated to each network node: A load variable and a direction variable.\nLoad variables model the amount of incoming flow for sink nodes, and the number of sinks fed for\npower source nodes. Direction variables model all the possibilities of feeding a node, as the set\n54\nDCOP: MODEL AND APPLICATIONS SURVEY\nof possible configurations in which its neighboring nodes can forward power to it. The acyclicity\nof the power flow and the flow conservation are modeled as constraints. The former restricts the\npower path to be a tree as well as defines the optimization criterion. The latter enforces Kirchhoff\u2019s\nlaw, that the amount of incoming power flow to the node i must equal the sum of power consumed\nat i and the amount of power forwarded to other nodes.\nMicrogrid Islanding Problems. A microgrid islanding problem is the problem of creating is-\nlands (i.e., clusters of generator units and loads able to operate without external energy supply) in\nresponse to major power outages and blackouts. Gupta, Yeoh, Pontelli, Jain, and Ranade (2013b)\nformalized this problem as a DCOP where agents represent nodes in the network and each agent\nhas its own power generation and power consumption capabilities. The variables of the DCOP\nrepresent the amount of power that an agent generates and consumes, as well as transmission line\nflows and the switch status between network nodes. The flow variables are constrained by their\nmaximum transmission line capacities, while switches are modeled as binary variables that can be\nturned on or off. Flow conservation are modeled as constraints to enforce Kirchhoff\u2019s law. The\ngoal is to find a switching configuration that minimizes the unserved load of the system.\nProsumer Energy Trading Problems. In its more general form, a smart grid is populated by\nprosumers capable of both generating and consuming resources. The prosumer energy trading\nproblem aims at setting market-based prices for prosumers to directly trade energy over the smart\ngrid, while taking account of the power network constraints. This problem has been cast as an\noptimization problem, called the energy allocation problem, where, given a graph with nodes rep-\nresenting prosumers and edges describing transmission lines connecting adjacent prosumers, the\ngoal is to find an allocation that maximizes the benefits of all the prosumers while satisfying the\ncapacity constraints of the power network.\nCerquides, Picard, and Rodr\u0131\u00b4guez-Aguilar (2015) proposed a DCOP formalization for this\nproblem, where each prosumer is modeled as an agent. Variables are associated with edges of\nthe energy trading network (i, j) and describe the number of units of energy that prosumer i sells\nto/buys from prosumer j. Thus, two variables (i, j) and (j, i) are associated to each edge of the\nnetwork. For each prosumer, an energy balance constraint models the utility of a given instantiation\nof its offers as the sum of the offers associated to the energy traded with each of its neighbor. Line\ncapacity and flow conservation constraints ensure that the energy traded along the transmission\nlines is within their maximum capacity and is consistent with Kirchhoff\u2019s law.\nSmart Building Devices Scheduling Problems. A smart building is a residential or commercial\nbuilding that is partially automated through the introduction of smart devices (e.g., smart ther-\nmostats, circulator heating, washing machines). Additionally, a range of smart plugs allow users to\ncontrol remotely the activity of the devices connected to them. Therefore, smart device scheduling\ncan be executed by householders without the control of a centralized authority. The distributed\nnature of smart devices within a smart building, and of smart buildings within a neighborhood, as\nwell as data privacy concerns, make this domain suitable to DCOP solutions.\nWithin a smart building, the Smart Environment Configuration Problem (SECP) proposed by\nRust, Picard, and Ramparany (2016) is the problem of coordinating several smart devices (light\n55\nFIORETTO, PONTELLI, & YEOH\nbulbs, roller shutters, luminosity sensors, etc.) whose actions affect the building environment,\nwith the goal of reaching a desired goal state (e.g., a given luminosity level for a room). This\nresource allocation problem is cast to a DCOP in which devices are described via DCOP agents,\neach of which controls a single variable describing the devices\u2019 action. The domain of the variables\nmodel the possible device\u2019s actions. Finally, the impact of the device\u2019s action onto the building\nenvironment is captured by a set of soft constraints. The goal is that of finding an assignment of\nactions for the building\u2019s devices that satisfies the given goals while minimizing some cost function\n(e.g., the energy consumption of each device).\nWithin a smart city, the Smart Home Device Scheduling Problem (SHDS) proposed by Fioretto,\nYeoh, and Pontelli (2017a) is the problem of coordinating the schedule of several smart homes\u2019 de-\nvices so to minimize the aggregated energy peaks as well as to minimize the users\u2019 energy bill cost,\nwhen adopting a real-time energy price schema. In the SHDS problem, each smart home controls\na set of smart sensors and smart devices. Within each smart home, users establish scheduling rules\ndefining goal states upon certain home\u2019s properties (e.g., reaching a certain room temperature by a\ngiven time of the day, or charging the battery of an electric vehicle of at least some amount during\nthe night). Each device\u2019s action has an associated energy consumption and a cost (which depends\non the time of the day in which the action is executed and on its required power). Each user in\na smart home attempts to find a schedule for its smart devices that satisfies its scheduling rules\nwhile minimizing the energy cost. Additionally, multiple smart homes coordinate their devices\u2019\nschedules so to minimize the daily energy peak consumption. Fioretto et. al map the SHDS prob-\nlem as a DCOP where each agent models a smart home. Agents control multiple variables, each\nrepresenting a smart device (a sensor or an actuator). Similar to the SECP problem, variables\u2019\ndomains model the possible actions of a device, and constraints capture the actions\u2019 costs, energy\nconsumption, and user preferences. Additionally, a set of hard constraints is used to model the\nuser\u2019s temporal goals. A dataset for the SHDS problem has been recently released (Kluegel, Iqbal,\nFioretto, Yeoh, & Pontelli, 2017). Finally, Tabakhi, Le, Fioretto, and Yeoh (2017) investigate how\nto elicit preferences associated to the users\u2019 temporal goals in an extension of the SHDS problem.\n8.8 Supply Chain Management Problems\nThe management of large businesses involves the management of the flow of goods from suppliers\nto customers. This flow of goods is called a supply chain. Supply chains have to be carefully man-\naged to ensure that a sufficient quantity of raw material is available at factories for production and\na sufficient quantity of processed goods is available at stores for consumers to buy. Additionally,\nsince goods can be purchased from different producers and sold to different consumers, there is\nalso the need to consider how much to buy/sell the goods and who to buy/sell the goods to. In such\nan environment, information, decision making and control are inherently decentralized.\nSupply Chain Formation Problems. A supply chain formation problem is the process of de-\ntermining the participants in a supply chain, who will exchange what, with whom, and the terms\nof the exchange. Several DCOP-based approaches for this problem have been proposed in the\nliterature (Gaudreault, Frayret, & Pesant, 2009; Penya-Alba, Cerquides, Rodriguez-Aguilar, &\n56\nDCOP: MODEL AND APPLICATIONS SURVEY\nVinyals, 2012; Penya-Alba, Vinyals, Cerquides, & Rodriguez-Aguilar, 2012; Winsper & Chli,\n2013; Penya-Alba, Vinyals, Cerquides, & Rodriguez-Aguilar, 2014). They rely on the notion of\na Task Dependency Network (TDN), a graph-based representation to capture dependencies among\nproduction processes, introduced by Walsh and Wellman (2000). A TDN is a bipartite directed\nacyclic graph representing exchanges, where nodes in the graph correspond to producers and con-\nsumers and edges in the graph correspond to feasible exchanges of goods between the producers\nand consumers. A path from potential producers and consumers defines a feasible supply chain\nconfiguration and the goal is to find the feasible configuration that optimizes a particular cost func-\ntion. A DCOP encoding for this problem models producers and consumers as agents, each of which\ncontrols a variable describing the agent\u2019s decision regarding whom to buy from/sell to as well as its\nassociated quantities and costs. Cost functions are associated with each edge of the TDN encoding\nthe willingness of the producer and consumer to trade with each other.\nA dynamic version of the above formalization has been investigated by Chli and Winsper\n(2015). This model allows for the entry and departure of producers and consumers as well as\nchanges in properties of the problem (e.g., prices of goods, production capacity of producers, and\nconsumption requirements of consumers).\n8.9 Traffic Flow Control Problems\nA challenge for the increase of transportation demand is to enforce traffic flow control using the\nexisting infrastructure, such as traffic lights, loop detectors, and cameras. Coordinating the actions\nof these individual devices aims at smoothing the traffic flow at the network level. Such coordi-\nnated actions often generates coherent traffic control plans faster and more accurately compared to\nthose of a human traffic operator (Van Katwijk, De Schutter, & Hellendoorn, 2009). Due to the\ndistributed nature of such devices, multi-agent solutions are particularly suitable for this class of\nproblems.\nTraffic Light Synchronization Problem. This problem is the problem of finding a synchroniza-\ntion schema for the traffic lights in adjacent intersections that creates green waves, which are waves\nof vehicles that are traveling at a given speed and are able to cross multiple intersections without\nstopping at red lights.\nde Oliveira, Bazzan, and Lesser (2005) and Junges and Bazzan (2008) model this problem as a\nDCOP, where agents represent traffic lights, each controlling one variable that models the coordi-\nnation direction for the associated traffic signal. Thus, the domain of the variables is given by two\npossible directions of coordination (north-south/south-north, east-west/west-east). Conflicts that\narise when two neighboring traffic signals choose different directions are modeled as constraints.\nCost functions are defined to model the number of incoming vehicles in a junction, and the costs\nare influenced by whether two adjacent agents agree on a direction of coordination or not. The goal\nis to minimize the global cost. Due to the dynamic nature of the problem, the proposed algorithms\nfall under the umbrella of Dynamic DCOP algorithms.\nPham, Tawfik, and Taylor (2013) and Brys, Pham, and Taylor (2014) proposed a Probabilistic\nDCOP-based approach with partial agent knowledge to solve the traffic light synchronization prob-\n57\nFIORETTO, PONTELLI, & YEOH\nlem in the context where agents have partial information about their cost functions. In particular,\nthe authors argue that traffic patterns may vary during time and, thus, the agents should learn them\nto update their cost functions. In this context, agents are given a limited amount of time to explore\ndifferent signal duration intervals, whose associated costs are learned by evaluating the average\ntravel time of the first 100 cars traveling across the agent\u2019s traffic light.\n9. Analyses and Perspectives on DCOPs\nDCOPs have emerged as a popular formalism for distributed reasoning and coordination in multi-\nagent systems. It provides an elegant modeling framework, which offers flexibility in both the\nagents\u2019 reasoning and coordination strategies. Its ability to support the notions of preferences and\nconstraints makes it suitable to model a variety of multi-agent optimization problems. Preferences\nare a central concept of decision making and arise in a multitude of contexts in multi-agent systems.\nThey are fundamental for the analysis of human choice behavior, and allow agents to express\ntheir inclinations through specific actions and behaviors. Constraints have been long studied in\ncentralized systems (Rossi et al., 2006) and have been proved especially practical and efficient for\nmodeling and solving resource allocation and scheduling problems. They are naturally handled\nwithin DCOPs and offer a flexible and effective mean to model a variety of complex problems.\nIn addition, DCOPs support several aspects that are crucial in multi-agent systems, such as agent\nprivacy, autonomy in reasoning, and cooperation.\nThe classical DCOP notion is unable to capture important aspects of the problem related with\nthe environment characteristics, such as partial observability, environment evolution, and uncer-\ntainty. Therefore, several DCOP model extensions have been recently presented. Each DCOP\nmodel imposes distinctive algorithmic requirements, which concern both the agent\u2019s reasoning and\ncooperation aspects. These requirements, in turn, are strictly related to the characteristics of the\nproblem domain. Due to the performance variability imposed by such requirements, an appropri-\nate selection of the DCOP model and algorithm is essential to obtain desirable performances in\nrealistic application domains.\n9.1 Comparative Overview of DCOP Models\nClassical DCOPs can be used to represent a wide range of MAS applications where agents in\na team need to work cooperatively to achieve a single goal in a static, deterministic, and fully\nobservable environment. Exploring the domain structural properties, as well as understanding the\nrequirements of the problem designer, is crucial to design and apply effective DCOP algorithms. A\ndiscussion on how to choose an appropriate algorithm based on the characteristic of the application\nat hand is provided in Section 4.4.\nAsymmetric DCOPs are suitable when constrained agents incur different costs for a joint action,\nwhich arise especially in scenarios where privacy is a particular concern, where agents cannot re-\nveal to the other agents the costs associated to their putative actions. Examples of problems that can\nbe suitably modeled as Asymmetric DCOPs are resource allocation problems where agents incur in\n58\nDCOP: MODEL AND APPLICATIONS SURVEY\ndistinct costs from using the same resource, and where their preferences and constraints regarding\nusage time slots and durations are expected to be different. Asymmetric DCOPs are particularly\nattractive to model those domains that can be represented as graphical games (Kearns, Littman, &\nSingh, 2001), and where constraint reasoning could be actively used to exploit the problem struc-\nture. In a graphical game, the costs of each agent are affected exclusively by its neighboring agents.\nIt is important to note that, even though the Asymmetric DCOP model bears similarities with many\ngame-theoretic approaches, these two models are fundamentally different. While game-theoretic\nagents are self-interested, and their non-cooperative actions lead to a desirable global target, Asym-\nmetric DCOP agents are cooperative and seek to minimize the global cost even at the expense of\nlarger local costs.\nMulti-Objective DCOPs are tailored to represent those classes of distributed problems that can-\nnot be modeled with a single optimization function. The observations above on classical DCOPs\nalso hold for Multi-Objective DCOPs and, in addition, agents cooperate to optimize multiple ob-\njectives. Numerous MAS applications fall in the category of multi-objective optimization. One\nexample is that of disaster management and coordination problems, where agents coordinate to ef-\nfectively respond to an emergency scenario (see Section 8.1). Due to memory requirements, which\nare proportional to the number of objectives and the size of the Pareto set, incomplete strategies\nseem particularly promising for this research area.\nDynamic DCOPs capture the dynamic behavior of the evolving environment in which agents\nact. Dynamic environments play a fundamental role in real-wold MAS applications. Virtually all\ncomplex MAS applications involve dynamic situations, which may restructure the network topol-\nogy due to agent movements, or bring additional information to the problem being solved. For\nexample, in a search and rescue operation during disaster management, as the environment evolves\nover time, new information becomes available about civilians to be rescued and new agencies may\narrive at any time to help conduct rescue operations (see Section 8.1). In a smart grid domain,\nreal-time pricing is commonly enforced. Thus, agent preferences need to be adapted over time,\nwhile energy costs are updated (see Section 8.7). Dynamic DCOPs are therefore a modern area\nthat presents an exciting field for groundbreaking research.\nProbabilistic DCOPs extend the classical DCOP model to include the capability of handling\nuncertain events, allowing DCOP agents to handle a wider range of applications. In particular,\nProbabilistic DCOPs are suitable to capture those applications characterized by a static environ-\nment evolution with exogenous uncertain events (e.g., when the actions of agents on the environ-\nment can have different outcomes, based on external, uncertain factors) and, yet, agents have total\nknowledge of their own actions and of the observable environment and act in a fully cooperative\ncontext. The domain of multi-agent task planning and scheduling encompasses diverse problems\nthat require complex models and robust solutions under uncertainty (see Section 8.4). The Prob-\nabilistic DCOP model for agents with partial knowledge is suitable to model those applications\nwhere agents have no prior knowledge of how the environment reacts to some of the actions. In\nsuch a model, the agents are aware of their own actions, which are performed deterministically.\nHowever, there is uncertainty in the cost associated to such actions, which is influenced by uncer-\ntain events that can be discovered over time. Thus, a common approach in such cases is to resort\n59\nFIORETTO, PONTELLI, & YEOH\nDCOP MODEL COMPLEXITY\nClassical NP-hard\nAsymmetric NP-hard\nMulti-objective NP-hard\nDynamic NP-hard\nProbabilistic PSPACE-hard\nQuantified PSPACE-hard\nTable 6: Complexity of the DCOP Models\nto sampling strategies, in order to obtain simple approximations of the probability distributions \u2013\nin the form of sample realizations of the probabilistic costs. Due to the uncertainty arising in such\nproblems, it is especially appealing to recur to solutions that adopt approaches to decision making\nunder uncertainty, such as minimax, maximin, and regret-based methods.\nAs outlined in Table 3, more research effort is needed to solve DCOP models in which agents\nact in a combined uncertain and dynamic environment. This is by far the most realistic setting for\nteams of agents acting within a MAS. More generally, a coordination strategy that can adapt to\nthe situation where the environment or network problem is evolving dynamically and rapidly and\nwhere several scenarios require different approaches to coordination, has not yet been studied.\nFinally, Quantified DCOPs model adversarial agents, which are common in many MAS appli-\ncations. In a Quantified DCOP, universally quantified variables can be considered as the choice of\nthe nature of an adversary. Quantified DCOPs can thus formalize problems where a team of agents\nseeks to limit the effect of the adversarial agents, as well as problems associated to planning under\nuncertainty. Examples of relevant applications include distributed surveillance planning problems,\nwhere sensors in a network need to coordinate their surveillance areas to detect intruders, whose\npositions are unknown and who are trying to avoid detection. Thus, the sensors try to find a robust\nplan that can handle different intruding scenarios (see Section 8.5).\nIn terms of complexity, solving classical, Asymmetric, Multi-Objective, and Dynamic DCOPs\noptimally is NP-hard. In contrast, the Probabilistic DCOP extension to include the capability of\nhandling uncertain events and the Quantified DCOP extension to model adversarial agents comes\nat a cost of increasing complexity. Both Probabilistic DCOPs and Quantified DCOPs are PSPACE-\nhard. Table 6 summarizes the complexity of the DCOP models discussed in this survey.\n9.2 Algorithms and Theoretical Analysis\nDespite the fact that classical DCOPs have reached a sufficient level of maturity from the algorith-\nmic perspective, most of the other proposed formalisms fall short on both algorithmic and theoreti-\ncal foundations. The proposed algorithms mostly extend classical DCOP algorithms and, therefore,\nthey result in similar performance. Investigating strategies that are based on different backgrounds\ncould help propel the evolution of this area.\n60\nDCOP: MODEL AND APPLICATIONS SURVEY\nInter-disciplinary Research: In particular, further investigations on relating DCOPs to the areas\nof game theory and decision theory are necessary. Similar to the work of Chapman, Rogers, and\nJennings (2008), where the authors study relationship between DCOPs and potential games, an-\nalyzing the relationship of DCOPs to auction mechanisms could shed light on how to effectively\naddress coordination and reasoning strategies in DCOP with partially cooperative agents. Another\ndirection is to relate DCOP with machine learning techniques. For instance, as outlined by Kumar\nand Zilberstein (2011) and Ghosh, Kumar, and Varakantham (2015), one can use inference-based\nalgorithms, such as expectation-maximization, and convex optimization machinery to develop ef-\nficient message-passing algorithms for solving large DCOPs. Additionally, merging insights from\ndecision theory, such as handling partial observability, with the inherent DCOP ability of naturally\nexploiting problem structure could result in improved performance and/or refined models (Nair,\nVarakantham, Tambe, & Yokoo, 2005; Hoang et al., 2016, 2017).\nAnytime Mechanisms: Due to the complexity of the DCOP models, the study of incomplete ap-\nproaches to solve large DCOPs whose agents may act in a dynamic and/or uncertain environment\nseems particularly suitable. Within the current incomplete methods proposed, a considerable ef-\nfort has been employed in developing anytime algorithms (Zilberstein, 1996). In addition to the\nanytime mechanism, which constrains the problem resolution within a particular time requirement,\nany-space algorithms have been proposed to limit the amount of space needed to an agent during\nproblem resolution (Petcu & Faltings, 2007a; Yeoh et al., 2009b, 2011; Gutierrez et al., 2011). Sim-\nilar to these mechanisms, we see an urge for investigating algorithms that allow problem resolution\nwithin any particular network load restriction. For instance, in a congested network agents might\nneed to exchange smaller messages, or to communicate less frequently and/or with a restricted\nset of neighbors. Situations like these may arise in problems where a multitude of interconnected\nsystems share the same medium, and thus limited bandwidth and interference may cause unsuit-\nable delays. This context may be exacerbated with the advent of concepts such as the Internet of\nthe Things, which expects to see million of connected devices, possibly sharing several mediums\n(Atzori, Iera, & Morabito, 2010; Chen, 2012; Miorandi, Sicari, De Pellegrini, & Chlamtac, 2012).\nThus, orthogonal to the direction pursed by anytime and any-space algorithms, we envision the\ndevelopment of any-communication procedures.\nCoordination and Cooperation Study: Another open question is related to agent coordination. It\nhas been observed that simple coordination strategies give good results in extremes (high or low)\nagent workload environments. However, at intermediate workload levels, such strategies lose their\neffectiveness, and more complex coordination strategies are necessary (Lesser, Decker, Wagner,\nCarver, Garvey, Horling, Neiman, Podorozhny, Prasad, Raja, et al., 2004; Zhang & Lesser, 2013).\nFor example, Zhang and Lesser (2013) study agent learning, where coordination is driven by a\ndynamic decomposition of a DCOP, each solving smaller independent subproblems. Their pro-\nposal effectively produced near-optimal agent policies for learning and significantly reduced the\namount of communication. These empirical observations suggest the existence of phase transition\nbehaviors occurring at the level of agent coordination. A formal understanding of these phenom-\nena, which looks at the environment, agents\u2019 local reasoning strategies, their assumptions on other\n61\nFIORETTO, PONTELLI, & YEOH\nagents states, as well as team coordination, could help researchers to understand the inherent com-\nplexity of coordination problems. Such a formal framework could be useful to build new and more\nefficient coordination strategies for a wide variety of multi-agent applications, perhaps resembling\nthe way studies of phase transitions of NP-hard problems (Monasson, Zecchina, Kirkpatrick, Sel-\nman, & Troyansky, 1999) led to the understanding of problem complexity and creation of effective\nheuristics and search strategies.\n9.3 Evaluation Metrics and Benchmarks\nDCOP Resolution Assumptions: Modeling many real-world problems as DCOPs often require\neach agent to solve large complex subproblems, each requiring many variables and constraints. A\nlimitation of most DCOP algorithms is the assumption that each agent controls exactly one vari-\nable, and that all constraints are binary. Such assumptions simplify the algorithm organization and\npresentation. To operate under this assumption, reformulation techniques are commonly adopted\nto transform a general DCOP into one where each agent controls exclusively one variable. There\nare two commonly used reformulation techniques (Burke & Brown, 2006; Yokoo, 2001): (i) Com-\npilation (or complex variables) where each agent creates a new pseudo-variable whose domain\nis the Cartesian product of the domains of all variables of the agent; and (ii) Decomposition (or\nvirtual agents) where each agent creates a pseudo-agent for each of its variables. While both tech-\nniques are relatively simple, they can be inefficient. In compilation, the memory requirement for\neach agent grows exponentially with the number of variables that it controls. In decomposition,\nthe DCOP algorithms will treat two pseudo-agents as independent entities, resulting in unneces-\nsary computation and communication costs. A more realistic view is to allow each agent to solve\nits local subproblem (in a centralized fashion) since it is independent of the subproblems of other\nagents. The agent\u2019s subproblem resolution can then explore techniques from centralized reasoning,\nsuch as constraint optimization problems, linear programming, and graphical models. One can\neven exploit novel hardware platforms, such as Graphical Processing Units (GPUs) to parallelize\nsuch solvers (Fioretto, Pontelli, Yeoh, & Dechter, 2017; Fioretto et al., 2016a; Bistaffa, Farinelli,\n& Bombieri, 2014).\nResearchers have proposed re-designed versions of existing algorithms to be able to handle\nmulti-variables agents problems (Davin & Modi, 2006; Khanna, Sattar, Hansen, & Stantic, 2009;\nPortway & Durfee, 2010). Additionally, recently, Grinshpoun (2015) and Fioretto, Yeoh, and\nPontelli (2016b) have proposed general DCOP problem decompositions which are able to solve\nproblems where agents control multiple variables.\nDCOP Modeling Language: Despite the wide applicability of the DCOP model, unfortunately,\nthere is no general language being used to formally specify a DCOP. While there are several DCOP\nsimulators that include implementations of various DCOP algorithms using a common language\nspecification (Sultanik, Modi, & Regli, 2007; Le\u00b4aute\u00b4, Ottens, & Szymanek, 2009; Wahbi, Ezza-\nhir, Bessiere, & Bouyakhf, 2011), by and large, most stand-alone algorithms specify DCOPs in\nan ad-hoc manner. As a result, it is often inconvenient to experimentally compare different algo-\nrithms. More importantly, the great majority of such languages requires constraints values to be\n62\nDCOP: MODEL AND APPLICATIONS SURVEY\nspecified explicitly. Such requirement makes unpractical to convert problems which are naturally\ndefined as mathematical optimization problems (such as Mixed Integer Programs) into an explicit\nform which specifies the utilities for each value combination of the variables in the scope of the\nproblem constraints. The adoption of a common distributed constraint modeling language, which\nallows one to express constraints as standard algebraic or logic expressions, may be beneficial for\ndeveloping standard benchmarks. Additionally, it would provide a tool for researchers outside the\nAI communities to model and test the applicability of new problems, extending the applicability of\nDCOPs to new areas. For instance, within the constraint programming community, the adoption\nof the MiniZinc language (Nethercote, Stuckey, Becket, Brand, Duck, & Tack, 2007) to model\nCSPs and COPs has gained wide traction, and it is becoming a modeling choice even outside the\nconstraint programming community.\nDCOP Simulators: DCOP simulators are multi-agent software tools that simulate the execution\nof DCOP algorithms. They are a useful resource for DCOP researchers and practitioners for evalu-\nating different models and algorithms. There are several MAS simulators which have been adopted\nby researchers to develop and compare DCOP algorithms:\n\u2022 DisChoco (Wahbi et al., 2011) is a Java open-source framework for simulating DCOP algorithms\nwhere agents are executed asynchronously (each in a separate execution thread) and communi-\ncation is implemented via messages passing. The simulator includes some problem generators\nand the possibility to take into account message loss, message corruption, and message delay. It\nsupports models in which agents control multiple variables and problems with n-ary constraints.\nAdditionally, it has the ability to be executed in a distributed environment.\n\u2022 Frodo (Le\u00b4aute\u00b4 et al., 2009) is a Java open-source framework for DCOP which implements several\ncomplete and incomplete classic DCOP algorithms, including DPOP and some of it variants,\nMax-Sum, MGM, and DSA. It can be executed either in a synchronous or in an asynchronous\nmode. It provides a Graphical User Interface to visualize the problem structure and algorithm\nexecution, and it includes some problem generators for benchmarking. It supports problems with\nn-ary constraints and models in which agents need to control the assignment of several variables.\nFinally, in addition to simulating DCOP algorithms in a centralized environment, it provides\nsupport for executing agents in a distributed environment.\n\u2022 AgentZero (Lutati, Gontmakher, Lando, Netzer, Meisels, & Grubshtein, 2014) is a Java open-\nsource framework for various MAS applications. It provides distributed runtime environment,\nwhich can be used to simulate both synchronous and asynchronous algorithms. AgentZero of-\nfers several high-level APIs which allow to easily handle complex tasks, such as the construction\nof a pseudo-tree and the evaluation of assignments. Additionally, it provides some built-in per-\nformance measures and visualization tools that can be especially useful to debug distributed\nprograms. It supports the notion of message delays, message corruptions, and message losses.\nWhile it does not support models in which agents control multiple variables, it can deal with\nn-ary constraints.\nIn addition to using DCOP simulators, researchers have developed and deployed DCOP al-\ngorithms using general MAS platforms. In particular, the Java Agent DEvelopment Framework\n63\nFIORETTO, PONTELLI, & YEOH\nPROPERTY DISCHOCO FRODO AGENTZERO JADE\nExecution modes Async Sync/Async Sync/Async Synch/Async\nVisualization No Yes Yes Yes\nMessage support Pointers Pointers Deep copy FIPA messages\nMessage delays/corruptions/losses Yes No Yes Yes\nMultiple variables per agent support Yes Yes No N/A\nN-ary constraints support Yes Yes Yes N/A\nDebugging Tools No No Yes No\nProgramming Language Java Java Java Java\nDocumentation No Yes Yes Yes\nDeployable No No No Yes\nTable 7: Comparison of DCOP Simulators\n(JADE) (Bellifemine, Caire, & Greenwood, 2007) is a multi-agent platform that is compliant with\nthe FIPA specifications.13 It includes a runtime environment in which the agents act, a set of\nAPIs to define the agents\u2019 behaviors, and a suite of graphical tools that can be used to monitor the\nagents\u2019 activity. JADE agents\u2019 messages are specified by the ACL language, defined by the FIPA\ninternational standard for agent interoperability. JADE allows the deployment of agents on several\nenvironments, including mobile and wireless environments and fault-tolerant platforms.\nTable 7 provides a summary of the simulators\u2019 features and describes whether the simulator\nexecution mode supports synchronous or asynchronous algorithms; whether it provides visualiza-\ntion tools; the type of implementation of messages passing simulation (i.e., using pointers, deep\ncopying the message structure into the receiving agent\u2019s message queue, etc.); if the framework\nprovides support to simulate/handle message delays, message corruptions, and message losses; if\nit supports DCOP models in which agents control multiple variables and n-ary constraints; if the\nframework provides tools for debugging the algorithms; the programming language in which the\nsimulator is implemented; whether it provides documentation; and whether it provides support for\ndeployment. For a comprehensive review of multi-agent platforms, the interested reader is referred\nto the survey by Kravari and Bassiliades (2015).\nThe development of DCOP simulators have provided researchers with useful tools to develop\nnew DCOP algorithms and to facilitate comparison of existing DCOP algorithms. However, all\nthe DCOP simulators described above focus on the classical DCOP model, while Dynamic and\nProbabilistic DCOP simulators have received little attention. Thus, there is a need of develop-\ning high-fidelity simulators for Dynamic DCOPs, which simulate how the environment can vary\nover time, as well as for Probabilistic DCOPs, which simulate the stochastic nature of exogenous\nevents.\nEvaluation and Metrics: Another open question in this research area concerns the definition of\na systematic process to evaluate and compare the DCOP algorithms. There are multiple metrics\n13. http://www.fipa.org/\n64\nDCOP: MODEL AND APPLICATIONS SURVEY\nthat can be used to measure the runtime of an algorithm, such as the number of Non-Concurrent\nConstraint Checks (NCCCs) (Meisels, Kaplansky, Razgon, & Zivan, 2002), the simulated runtime\n(Sultanik, Lass, & Regli, 2008), and the number of cycles (Lynch, 1996). However, there is no\nconsensus on a standard metric. Such issues, combined with absence of a general DCOP language,\nmake it inconvenient to experimentally compare different algorithms. In addition, new proposed\nalgorithms are, in general, evaluated on arbitrary benchmarks, some inherited from the CSP litera-\nture, some other from approximations of real-world problems. To cope with these issues, it would\nbe useful to develop a benchmark repository, perhaps by taking inspiration from the efforts made\nby the constraint programming community with CSPLib,14 a library of test problems for constraint\nsolvers, or by the planning community with their international planning competitions.15\n10. Conclusions\nDCOPs have emerged as a popular formalism for distributed reasoning and coordination in multi-\nagent systems. Due to its limitation to support complex, real-time, and uncertain environment,\nresearchers have introduced several model extensions to handle dynamic and uncertain environ-\nments, as well as different levels of cooperation among the agents.\nWhile DCOPs\u2019 theoretical foundation and algorithmic frameworks have matured significantly\nover the past decade, their applicability to realistic domains is lagging behind. This survey aims at\nlinking the DCOP theoretical framework and solving strategies with a set of potential applications\nwhere its applicability is having or may have a significant impact.\nThis survey provided an analysis of the recent advances made by the AAMAS community\nwithin the DCOP framework and propose a categorization based on agent characteristics, environ-\nment properties, and type of teamwork adopted. Within the proposed classification, it (i) presented\na review of the characteristics of the different algorithmic solutions; (ii) discussed a number of ap-\nplication domains that can be naturally modeled within each DCOP framework; and (iii) identified\nsome potential directions for future work with regards to agent coordination, algorithm scalability,\nmodeling languages, and evaluation criteria of DCOP models and algorithms.\nAcknowledgments\nThe authors would like to thank the anonymous reviewers for their valuable comments and sugges-\ntions to improve the quality of the paper. They are also thankful to Tiep Le for early discussions\non Probabilistic DCOPs. The research in this paper has been partially supported by NSF grants\n0947465, 1345232, 1401639, 1458595, and 1550662. The views and conclusions contained in this\ndocument are those of the authors and should not be interpreted as representing the official policies,\neither expressed or implied, of the sponsoring organizations, agencies, or the U.S. government.\n14. http://www.csplib.org/\n15. http://icaps-conference.org/index.php/Main/Competitions\n65\nFIORETTO, PONTELLI, & YEOH\nReferences\nAbounadi, J., Bertsekas, D., & Borkar, V. (2001). Learning algorithms for Markov decision processes with\naverage cost. SIAM Journal on Control and Optimization, 40(3), 681\u2013698.\nAgrawal, P., Kumar, A., & Varakantham, P. (2015). Near-optimal decentralized power supply restoration in\nsmart grids. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 1275\u20131283.\nAji, S. M., & McEliece, R. J. (2000). The generalized distributive law. IEEE Transactions on Information\nTheory, 46(2), 325\u2013343.\nAkyildiz, I. F., Su, W., Sankarasubramaniam, Y., & Cayirci, E. (2002). Wireless sensor networks: a survey.\nComputer Networks, 38(4), 393\u2013422.\nAmador, S., Okamoto, S., & Zivan, R. (2014). Dynamic multi-agent task allocation with spatial and temporal\nconstraints. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 1384\u20131390.\nAmato, C., Chowdhary, G., Geramifard, A., Ure, N. K., & Kochenderfer, M. J. (2013). Decentralized control\nof partially observable Markov decision processes. In Proceedings of the Annual Conference on\nDecision and Control (CDC), pp. 2398\u20132405.\nAmigoni, F., Castelletti, A., & Giuliani, M. (2015). Modeling the management of water resources sys-\ntems using Multi-Objective DCOPs. In Proceedings of the International Conference on Autonomous\nAgents and Multiagent Systems (AAMAS), pp. 821\u2013829.\nApt, K. (2003). Principles of Constraint Programming. Cambridge University Press.\nAthanasiadis, D., Kockar, I., & McArthur, S. (2013). Distributed constraint optimisation for flexible net-\nwork management. In Proceedings of the IEEE International Conference on Innovative Smart Grid\nTechnologies Europe (ISGT EUROPE), pp. 1\u20135.\nAtlas, J., & Decker, K. (2010). Coordination for uncertain outcomes using distributed neighbor exchange.\nIn Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AA-\nMAS), pp. 1047\u20131054.\nAtzori, L., Iera, A., & Morabito, G. (2010). The internet of things: A survey. Computer Networks, 54(15),\n2787\u20132805.\nAuer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis of the multiarmed bandit problem.\nMachine learning, 47(2-3), 235\u2013256.\nBaba, S., Iwasaki, A., Yokoo, M., Silaghi, M. C., Hirayama, K., & Matsui, T. (2010). Cooperative problem\nsolving against adversary: Quantified distributed constraint satisfaction problem. In Proceedings of\nthe International Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 781\u2013788.\nBaba, S., Joe, Y., Iwasaki, A., & Yokoo, M. (2011). Real-time solving of quantified CSPs based on monte-\ncarlo game tree search. In Proceedings of the International Joint Conference on Artificial Intelligence\n(IJCAI), pp. 655\u2013661.\nBellifemine, F. L., Caire, G., & Greenwood, D. (2007). Developing Multi-Agent Systems with JADE, Vol. 7.\nJohn Wiley & Sons.\nBenders, J. F. (1962). Partitioning procedures for solving mixed-variables programming problems. Nu-\nmerische Mathematik, 4(1), 238\u2013252.\nBenedetti, M., Lallouet, A., & Vautard, J. (2008). Quantified constraint optimization. In Proceedings of the\nInternational Conference on Principles and Practice of Constraint Programming (CP), pp. 463\u2013477.\n66\nDCOP: MODEL AND APPLICATIONS SURVEY\nBernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). The complexity of decentralized control\nof Markov decision processes. Mathematics of Operations Research, 27(4), 819\u2013840.\nBessiere, C., Brito, I., Gutierrez, P., & Meseguer, P. (2014). Global constraints in distributed constraint\nsatisfaction and optimization. Computer Journal, 57(6), 906\u2013923.\nBessiere, C., Gutierrez, P., & Meseguer, P. (2012). Including soft global constraints in DCOPs. In Proceed-\nings of the International Conference on Principles and Practice of Constraint Programming (CP),\npp. 175\u2013190.\nBilliau, G., Chang, C. F., & Ghose, A. (2012a). SBDO: A new robust approach to dynamic distributed con-\nstraint optimisation. In Proceedings of the Principles and Practice of Multi-Agent Systems (PRIMA),\npp. 11\u201326.\nBilliau, G., Chang, C. F., Ghose, A., & Miller, A. A. (2012b). Using distributed agents for patient scheduling.\nIn Proceedings of the Principles and Practice of Multi-Agent Systems (PRIMA), pp. 551\u2013560.\nBilliau, G., Chang, C. F., Ghose, A., & Miller, A. (2012c). Support-based distributed optimisation: An\napproach to radiotherapy scheduling. In Electronic Healthcare, pp. 327\u2013334.\nBinmore, K. (1992). Fun and Games, a Text on Game Theory. DC Heath and Company.\nBistaffa, F., Farinelli, A., & Bombieri, N. (2014). Optimising memory management for belief propagation\nin junction trees using GPGPUs. In Proceeding of the International Conference on Parallel and\nDistributed Systems (ICPADS), pp. 526\u2013533.\nBowring, E., Tambe, M., & Yokoo, M. (2006). Multiply-constrained distributed constraint optimization. In\nProceedings of the International Conference on Autonomous Agents and Multiagent Systems (AA-\nMAS), pp. 1413\u20131420.\nBrito, I., Meisels, A., Meseguer, P., & Zivan, R. (2009). Distributed constraint satisfaction with partially\nknown constraints. Constraints, 14(2), 199\u2013234.\nBrys, T., Pham, T. T., & Taylor, M. E. (2014). Distributed learning and multi-objectivity in traffic light\ncontrol. Connection Science, 26(1), 65\u201383.\nBurke, D., & Brown, K. (2006). Efficiently handling complex local problems in distributed constraint opti-\nmisation. In Proceedings of the European Conference on Artificial Intelligence (ECAI), pp. 701\u2013702.\nCarpenter, C. J., Dugan, C. J., Kopena, J. B., Lass, R. N., Naik, G., Nguyen, D. N., Sultanik, E., Modi, P. J., &\nRegli, W. C. (2007). Intelligent systems demonstration: disaster evacuation support. In Proceedings\nof the AAAI Conference on Artificial Intelligence (AAAI), pp. 1964\u20131965.\nCerquides, J., Picard, G., & Rodr\u0131\u00b4guez-Aguilar, J. A. (2015). Designing a marketplace for the trading and dis-\ntribution of energy in the smart grid. In Proceedings of the International Conference on Autonomous\nAgents and Multiagent Systems (AAMAS), pp. 1285\u20131293.\nChachra, S., & Marefat, M. (2006). Distributed algorithms for sleep scheduling in wireless sensor networks.\nIn Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 3101\u2013\n3107.\nChapman, A., Rogers, A., & Jennings, N. (2008). A parameterisation of algorithms for distributed constraint\noptimisation via potential games. In International Workshop on Distributed Constraint Reasoning\n(DCR), pp. 99\u2013113.\nChechetka, A., & Sycara, K. (2006). No-commitment branch and bound search for distributed constraint\noptimization. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 1427\u20131429.\n67\nFIORETTO, PONTELLI, & YEOH\nChen, Y.-K. (2012). Challenges and opportunities of internet of things. In Proceedings of the Asia and South\nPacific Design Automation Conference (ASP-DAC), pp. 383\u2013388.\nChen, Z., Deng, Y., & Wu, T. (2017). An iterative refined max-sum ad algorithm via single-side value\npropagation and local search. In Proceedings of the International Conference on Autonomous Agents\nand Multiagent Systems (AAMAS), pp. 195\u2013202.\nChli, M., & Winsper, M. (2015). Using the Max-Sum algorithm for supply chain emergence in dynamic\nmultiunit environments. IEEE Transactions of Systems, Man, and Cybernetics: Systems, 45(3), 422\u2013\n435.\nChoudhury, B., Dey, P., Dutta, A., & Choudhury, S. (2014). A multi-agent based optimised server selection\nscheme for SOC in pervasive environment. In Advances in Practical Applications of Heterogeneous\nMulti-Agent Systems. The PAAMS Collection, pp. 50\u201361.\nChoxi, H., & Modi, P. (2007). A distributed constraint optimization approach to wireless network optimiza-\ntion. In Proceedings of the AAAI-07 Workshop on Configuration, pp. 1\u20138.\nDavidson, E., Dolan, M., McArthur, S., & Ault, G. (2009). The use of constraint programming for the au-\ntonomous management of power flows. In Proceedings of the International Conference on Intelligent\nSystem Applications to Power Systems (ISAP), pp. 1\u20137.\nDavin, J., & Modi, P. (2006). Hierarchical variable ordering for multiagent agreement problems. In Pro-\nceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS),\npp. 1433\u20131435.\nde Oliveira, D., Bazzan, A. L., & Lesser, V. (2005). Using cooperative mediation to coordinate traffic lights:\na case study. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 463\u2013470.\nDelle Fave, F. M., Stranders, R., Rogers, A., & Jennings, N. R. (2011). Bounded decentralised coordination\nover multiple objectives. In Proceedings of the International Conference on Autonomous Agents and\nMultiagent Systems (AAMAS), pp. 371\u2013378.\nDijkstra, E. W. (1974). Self-stabilization in spite of distributed control. Communication of the ACM, 17(11),\n643\u2013644.\nFarinelli, A., Rogers, A., Petcu, A., & Jennings, N. (2008). Decentralised coordination of low-power em-\nbedded devices using the Max-Sum algorithm. In Proceedings of the International Conference on\nAutonomous Agents and Multiagent Systems (AAMAS), pp. 639\u2013646.\nFioretto, F., Le, T., Yeoh, W., Pontelli, E., & Son, T. C. (2014). Improving DPOP with branch consistency for\nsolving distributed constraint optimization problems. In Proceedings of the International Conference\non Principles and Practice of Constraint Programming (CP), pp. 307\u2013323.\nFioretto, F., Pontelli, E., Yeoh, W., & Dechter, R. (2017). Accelerating exact and approximate inference for\n(distributed) discrete optimization with GPUs. Constraints.\nFioretto, F., Yeoh, W., & Pontelli, E. (2016a). A dynamic programming-based MCMC framework for solving\nDCOPs with GPUs. In Proceedings of Principles and Practice of Constraint Programming (CP), pp.\n813\u2013831.\nFioretto, F., Yeoh, W., & Pontelli, E. (2016b). Multi-variable agents decomposition for DCOPs. In Proceed-\nings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 2480\u20132486.\nFioretto, F., Yeoh, W., & Pontelli, E. (2017a). A multiagent system approach to scheduling devices in\nsmart homes. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 981\u2013989.\n68\nDCOP: MODEL AND APPLICATIONS SURVEY\nFioretto, F., Yeoh, W., Pontelli, E., Ma, Y., & Ranade, S. (2017b). A DCOP approach to the economic\ndispatch with demand response. In Proceedings of the International Conference on Autonomous\nAgents and Multiagent Systems (AAMAS), pp. 999\u20131007.\nGarrido, L., & Sycara, K. (1996). Multi-agent meeting scheduling: Preliminary experimental results. In\nProceedings of the International Conference on Multiagent Systems, pp. 95\u2013102.\nGaudreault, J., Frayret, J.-M., & Pesant, G. (2009). Distributed search for supply chain coordination. Com-\nputers in Industry, 60(6), 441\u2013451.\nGeman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of\nimages. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6(6), 721\u2013741.\nGershman, A., Meisels, A., & Zivan, R. (2009). Asynchronous Forward-Bounding for distributed COPs.\nJournal of Artificial Intelligence Research, 34, 61\u201388.\nGhosh, S., Kumar, A., & Varakantham, P. (2015). Probabilistic inference based message-passing for resource\nconstrained DCOPs. In Proceedings of the International Joint Conference on Artificial Intelligence\n(IJCAI), pp. 411\u2013417.\nGiffler, B., & Thompson, G. L. (1960). Algorithms for solving production-scheduling problems. Operations\nresearch, 8(4), 487\u2013503.\nGiuliani, M., Castelletti, A., Amigoni, F., & Cai, X. (2014). Multiagent systems and distributed constraint\nreasoning for regulatory mechanism design in water management. Journal of Water Resources Plan-\nning and Management, 41(4).\nGla\u00dfer, C., Reitwie\u00dfner, C., Schmitz, H., & Witek, M. (2010). Approximability and hardness in multi-\nobjective optimization. In Proceedings of the Conference on Computability in Europe (CiE), pp.\n180\u2013189.\nGolomb, S. W., & Baumert, L. D. (1965). Backtrack programming. Journal of the ACM, 12(4), 516\u2013524.\nGreenstadt, R., Grosz, B., & Smith, M. (2007). SSDPOP: Improving the privacy of DCOP with secret shar-\ning. In Proceedings of the International Conference on Autonomous Agents and Multiagent Systems\n(AAMAS), pp. 1098\u20131100.\nGrinshpoun, T. (2015). Clustering variables by their agents. In Proceedings of the International Joint\nConferences on Web Intelligence and Intelligent Agent Technologies (WI-IAT), Vol. 2, pp. 250\u2013256.\nGrinshpoun, T., Grubshtein, A., Zivan, R., Netzer, A., & Meisels, A. (2013). Asymmetric distributed con-\nstraint optimization problems. Journal of Artificial Intelligence Research, 47, 613\u2013647.\nGrinshpoun, T., & Meisels, A. (2008). Completeness and performance of the APO algorithm. Journal of\nArtificial Intelligence Research, 33, 223\u2013258.\nGupta, S., Jain, P., Yeoh, W., Ranade, S., & Pontelli, E. (2013a). Solving customer-driven microgrid op-\ntimization problems as DCOPs. In International Workshop on Distributed Constraint Reasoning\n(DCR), pp. 45\u201359.\nGupta, S., Yeoh, W., Pontelli, E., Jain, P., & Ranade, S. (2013b). Modeling microgrid islanding problems as\nDCOPs. In Proceedings of the North American Power Symposium (NAPS), pp. 1\u20136.\nGutierrez, P., Lee, J., Lei, K. M., Mak, T., & Meseguer, P. (2013). Maintaining soft arc consistencies in BnB-\nADOPT+ during search. In Proceedings of the International Conference on Principles and Practice\nof Constraint Programming (CP), pp. 365\u2013380.\nGutierrez, P., & Meseguer, P. (2012a). Improving BnB-ADOPT+-AC. In Proceedings of the International\nConference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 273\u2013280.\n69\nFIORETTO, PONTELLI, & YEOH\nGutierrez, P., & Meseguer, P. (2012b). Removing redundant messages in n-ary BnB-ADOPT. Journal of\nArtificial Intelligence Research, 45, 287\u2013304.\nGutierrez, P., Meseguer, P., & Yeoh, W. (2011). Generalizing ADOPT and BnB-ADOPT. In Proceedings of\nthe International Joint Conference on Artificial Intelligence (IJCAI), pp. 554\u2013559.\nHannebauer, M., & Mu\u00a8ller, S. (2001). Distributed constraint optimization for medical appointment schedul-\ning. In Proceedings of the International Conference on Autonomous Agents and Multiagent Systems\n(AAMAS), pp. 139\u2013140.\nHarvey, P., Chang, C. F., & Ghose, A. (2007). Support-based distributed search: a new approach for multi-\nagent constraint processing. In Argumentation in Multi-Agent Systems, pp. 91\u2013106. Springer Berlin\nHeidelberg.\nHirayama, K., & Yokoo, M. (1997). Distributed partial constraint satisfaction problem. In Proceedings of the\nInternational Conference on Principles and Practice of Constraint Programming (CP), pp. 222\u2013236.\nHoang, K. D., Fioretto, F., Hou, P., Yokoo, M., Yeoh, W., & Zivan, R. (2016). Proactive dynamic distributed\nconstraint optimization. In Proceedings of the International Joint Conference on Autonomous Agents\nand Multiagent Systems (AAMAS), pp. 597\u2013605.\nHoang, K. D., Hou, P., Fioretto, F., Yeoh, W., Zivan, R., & Yokoo, M. (2017). Infinite-horizon proactive\ndynamic DCOPs. In Proceedings of the International Joint Conference on Autonomous Agents and\nMultiagent Systems (AAMAS), pp. 212\u2013220.\nHollos, D., Karl, H., & Wolisz, A. (2004). Regionalizing global optimization algorithms to improve the\noperation of large ad hoc networks. In Proceedings of the Wireless Communications and Networking\nConference (WCNC), pp. 819\u2013824.\nJain, M., Taylor, M. E., Tambe, M., & Yokoo, M. (2009). DCOPs meet the real world: Exploring unknown\nreward matrices with applications to mobile sensor networks. In Proceedings of the International\nJoint Conference on Artificial Intelligence (IJCAI), pp. 181\u2013186.\nJain, P., Ranade, S. J., Gupta, S., & Pontelli, E. (2012). Optimum operation of a customer-driven micro-\ngrid: A comprehensive approach. In Proceedings of the IEEE International Conference on Power\nElectronics, Drives and Energy Systems (PEDES), pp. 1\u20136.\nJennings, N. R., & Jackson, A. (1995). Agent-based meeting scheduling: A design and implementation.\nElectronics letters, 31(5), 350\u2013352.\nJin, Z., Cao, J., & Li, M. (2011). A distributed application component placement approach for cloud com-\nputing environment. In Proceedings of the International Conference on Dependable, Autonomic and\nSecure Computing (DASC), pp. 488\u2013495.\nJunges, R., & Bazzan, A. L. (2008). Evaluating the performance of DCOP algorithms in a real world,\ndynamic problem. In Proceedings of the International Conference on Autonomous Agents and Mul-\ntiagent Systems (AAMAS), pp. 599\u2013606.\nKearns, M., Littman, M. L., & Singh, S. (2001). Graphical models for game theory. In Proceedings of the\nConference on Uncertainty in Artificial Intelligence (UAI), pp. 253\u2013260.\nKhanna, S., Sattar, A., Hansen, D., & Stantic, B. (2009). An efficient algorithm for solving dynamic complex\nDCOP problems. In Proceedings of the International Joint Conferences on Web Intelligence and\nIntelligent Agent Technologies (WI-IAT), pp. 339\u2013346.\nKiekintveld, C., Yin, Z., Kumar, A., & Tambe, M. (2010). Asynchronous algorithms for approximate dis-\ntributed constraint optimization with quality bounds. In Proceedings of the International Conference\non Autonomous Agents and Multiagent Systems (AAMAS), pp. 133\u2013140.\n70\nDCOP: MODEL AND APPLICATIONS SURVEY\nKinoshita, K., Iizuka, K., & Iizuka, Y. (2013). Effective disaster evacuation by solving the distributed con-\nstraint optimization problem. In Proceedings of the International Conference on Advanced Applied\nInformatics (IIAIAAI), pp. 399\u2013400.\nKluegel, W., Iqbal, M. A., Fioretto, F., Yeoh, W., & Pontelli, E. (2017). A realistic dataset for the smart\nhome device scheduling problem for DCOPs. In Sukthankar, G., & Rodriguez-Aguilar, J. A. (Eds.),\nAutonomous Agents and Multiagent Systems: AAMAS 2017 Workshops, Visionary Papers, Sa\u02dco Paulo,\nBrazil, May 8-12, 2017, Revised Selected Papers, pp. 125\u2013142. Springer International Publishing.\nKopena, J. B., Sultanik, E. A., Lass, R. N., Nguyen, D. N., Dugan, C. J., Modi, P. J., & Regli, W. C. (2008).\nDistributed coordination of first responders. Internet Computing, 12(1), 45\u201347.\nKraus, S. (1997). Negotiation and cooperation in multi-agent environments. Artificial Intelligence, 94(1),\n79\u201397.\nKravari, K., & Bassiliades, N. (2015). A survey of agent platforms. Journal of Artificial Societies and Social\nSimulation, 18(1), 11.\nKschischang, F. R., Frey, B. J., & Loeliger, H.-A. (2001). Factor graphs and the sum-product algorithm.\nIEEE Transactions on Information Theory, 47(2), 498\u2013519.\nKumar, A., Faltings, B., & Petcu, A. (2009). Distributed constraint optimization with structured resource\nconstraints. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 923\u2013930.\nKumar, A., Petcu, A., & Faltings, B. (2008). H-DPOP: Using hard constraints for search space pruning in\nDCOP. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 325\u2013330.\nKumar, A., & Zilberstein, S. (2011). Message-passing algorithms for quadratic programming formulations\nof map estimation. In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI),\npp. 428\u2013435.\nLallouet, A., Lee, J. H. M., Mak, T. W. K., & Yip, J. (2015). Ultra-weak solutions and consistency enforce-\nment in minimax weighted constraint satisfaction. Constraints, 20(2), 109\u2013154.\nLarrosa, J. (2002). Node and arc consistency in weighted CSP. In Proceedings of the AAAI Conference on\nArtificial Intelligence (AAAI), pp. 48\u201353.\nLass, R. N., Kopena, J. B., Sultanik, E. A., Nguyen, D. N., Dugan, C. P., Modi, P. J., & Regli, W. C. (2008a).\nCoordination of first responders under communication and resource constraints. In Proceedings of the\nInternational Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 1409\u20131412.\nLass, R. N., Regli, W. C., Kaplan, A., Mitkus, M., & Sim, J. J. (2008b). Facilitating communication for first\nresponders using dynamic distributed constraint optimization. In Proceedings of the Symposium on\nTechnologies for Homeland Security (IEEE HST), pp. 316\u2013320.\nLe, T., Fioretto, F., Yeoh, W., Son, T. C., & Pontelli, E. (2016). ER-DCOPs: A framework for distributed\nconstraint optimization with uncertainty in constraint utilities. In Proceedings of the International\nConference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 606\u2013614.\nLe, T., Son, T. C., Pontelli, E., & Yeoh, W. (2015). Solving distributed constraint optimization problems\nwith logic programming. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),\npp. 1174\u20131181.\nLe\u00b4aute\u00b4, T., & Faltings, B. (2009). E [DPOP]: Distributed constraint optimization under stochastic uncertainty\nusing collaborative sampling. In International Workshop on Distributed Constraint Reasoning (DCR),\npp. 87\u2013101.\n71\nFIORETTO, PONTELLI, & YEOH\nLe\u00b4aute\u00b4, T., & Faltings, B. (2011). Distributed constraint optimization under stochastic uncertainty. In Pro-\nceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 68\u201373.\nLe\u00b4aute\u00b4, T., Ottens, B., & Szymanek, R. (2009). FRODO 2.0: An open-source framework for distributed\nconstraint optimization. In International Workshop on Distributed Constraint Reasoning (DCR), pp.\n160\u2013164.\nLesser, V., Decker, K., Wagner, T., Carver, N., Garvey, A., Horling, B., Neiman, D., Podorozhny, R., Prasad,\nM. N., Raja, A., et al. (2004). Evolution of the GPGP/TAEMS domain-independent coordination\nframework. Journal of Autonomous Agents and Multi-Agent Systems, 9(1-2), 87\u2013143.\nLevit, V., Grinshpoun, T., Meisels, A., & Bazzan, A. L. (2013). Taxation search in boolean games. In Pro-\nceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS),\npp. 183\u2013190.\nLi, S., Negenborn, R. R., & Lodewijks, G. (2016). Distributed constraint optimization for addressing vessel\nrotation planning problems. Engineering Applications of Artificial Intelligence, 48, 159\u2013172.\nLi, X., Wang, H., Ding, B., & Li, X. (2014). MABP: an optimal resource allocation approach in data center\nnetworks. Science China Information Sciences, 57(10), 1\u201316.\nLorenzi, F., dos Santos, F., Ferreira Jr, P. R., & Bazzan, A. L. (2008). Optimizing preferences within groups:\nA case study on travel recommendation. In Proceedings of the Brazilian Symposium on Artificial\nIntelligence (SBIA), pp. 103\u2013112.\nLutati, B., Gontmakher, I., Lando, M., Netzer, A., Meisels, A., & Grubshtein, A. (2014). AgentZero: A\nframework for simulating and evaluating multi-agent algorithms. In Agent-Oriented Software Engi-\nneering, pp. 309\u2013327. Springer Berlin Heidelberg.\nLynch, N. A. (1996). Distributed Algorithms. Morgan Kaufmann.\nMacarthur, K., Farinelli, A., Ramchurn, S., & Jennings, N. (2010). Efficient, superstabilizing decentralised\noptimisation for dynamic task allocation environments. In International Workshop on Optimization\nIn Multi-Agent Systems (OPTMAS), pp. 25\u201332.\nMacarthur, K., Farinelli, A., Ramchurn, S., & Jennings, N. (2011). A distributed anytime algorithm for\ndynamic task allocation in multi-agent systems. In Proceedings of the AAAI Conference on Artificial\nIntelligence (AAAI), pp. 701\u2013706.\nMackworth, A. K., & Freuder, E. C. (1985). The complexity of some polynomial network consistency\nalgorithms for constraint satisfaction problems. Artificial intelligence, 25(1), 65\u201374.\nMahadevan, S. (1996). Average reward reinforcement learning: Foundations, algorithms, and empirical\nresults. Machine Learning, 22(1\u20133), 159\u2013195.\nMaheswaran, R., Pearce, J., & Tambe, M. (2004a). Distributed algorithms for DCOP: A graphical game-\nbased approach. In Proceedings of the International Conference on Parallel and Distributed Com-\nputing Systems (PDCS), pp. 432\u2013439.\nMaheswaran, R. T., Tambe, M., Bowring, E., Pearce, J. P., & Varakantham, P. (2004b). Taking DCOP to the\nreal world: Efficient complete solutions for distributed multi-event scheduling. In Proceedings of the\nInternational Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 310\u2013317.\nMailler, R., & Lesser, V. (2004). Solving distributed constraint optimization problems using cooperative\nmediation. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 438\u2013445.\nMarler, R. T., & Arora, J. S. (2004). Survey of multi-objective optimization methods for engineering. Struc-\ntural and Multidisciplinary Optimization, 26(6), 369\u2013395.\n72\nDCOP: MODEL AND APPLICATIONS SURVEY\nMatsui, T., Matsuo, H., Silaghi, M. C., Hirayama, K., Yokoo, M., & Baba, S. (2010). A quantified distributed\nconstraint optimization problem. In Proceedings of the International Conference on Autonomous\nAgents and Multiagent Systems (AAMAS), pp. 1023\u20131030.\nMatsui, T., & Matsuo, H. (2008). A formalization for distributed cooperative sensor resource allocation. In\nAgent and Multi-Agent Systems: Technologies and Applications, pp. 292\u2013301.\nMatsui, T., & Matsuo, H. (2011). A distributed cooperative model for resource supply networks. In Pro-\nceedings of the International MultiConference of Engineers and Computer Scientists, pp. 7\u201314.\nMatsui, T., Matsuo, H., Silaghi, M., Hirayama, K., & Yokoo, M. (2008). Resource constrained distributed\nconstraint optimization with virtual variables. In Proceedings of the AAAI Conference on Artificial\nIntelligence (AAAI), pp. 120\u2013125.\nMatsui, T., Silaghi, M., Hirayama, K., Yokoo, M., & Matsuo, H. (2012). Distributed search method with\nbounded cost vectors on multiple objective DCOPs. In Proceedings of the Principles and Practice of\nMulti-Agent Systems (PRIMA), pp. 137\u2013152.\nMatsui, T., Silaghi, M., Hirayama, K., Yokoo, M., & Matsuo, H. (2014). Leximin multiple objective op-\ntimization for preferences of agents. In Proceedings of the Principles and Practice of Multi-Agent\nSystems (PRIMA), pp. 423\u2013438.\nMedi, A., Okimoto, T., & Inoue, K. (2014). A two-phase complete algorithm for multi-objective distributed\nconstraint optimization. Journal of Advanced Computational Intelligence and Intelligent Informatics,\n18(4), 573\u2013580.\nMeisels, A. (2008). Distributed Search by Constrained Agents: Algorithms, Performance, Communication.\nSpringer Science & Business Media.\nMeisels, A., Kaplansky, E., Razgon, I., & Zivan, R. (2002). Comparing performance of distributed con-\nstraints processing algorithms. In International Workshop on Distributed Constraint Reasoning\n(DCR), pp. 86\u201393.\nMejias, B., & Roy, P. V. (2010). From mini-clouds to cloud computing. In International Conference on\nSelf-Adaptive and Self-Organizing Systems Workshop (SASOW), pp. 234\u2013238.\nMiettinen, K. (1999). Nonlinear Multiobjective Optimization, Vol. 12. Springer Berlin Heidelberg.\nMiller, S., Ramchurn, S. D., & Rogers, A. (2012). Optimal decentralised dispatch of embedded generation in\nthe smart grid. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 281\u2013288.\nMinton, S., Johnston, M. D., Philips, A. B., & Laird, P. (1992). Minimizing conflicts: a heuristic repair\nmethod for constraint satisfaction and scheduling problems. Artificial Intelligence, 58(1), 161\u2013205.\nMiorandi, D., Sicari, S., De Pellegrini, F., & Chlamtac, I. (2012). Internet of things: Vision, applications and\nresearch challenges. Ad Hoc Networks, 10(7), 1497\u20131516.\nMir, U., Merghem-Boulahia, L., & Ga\u0131\u00a8ti, D. (2010). A cooperative multiagent based spectrum sharing. In\nAdvanced International Conference on Telecommunications (AICT), pp. 124\u2013130.\nModi, P., Shen, W.-M., Tambe, M., & Yokoo, M. (2005). ADOPT: Asynchronous distributed constraint\noptimization with quality guarantees. Artificial Intelligence, 161(1\u20132), 149\u2013180.\nMolisch, A. F. (2012). Wireless Communications, Vol. 34. John Wiley & Sons.\nMonasson, R., Zecchina, R., Kirkpatrick, S., Selman, B., & Troyansky, L. (1999). Determining computa-\ntional complexity from characteristic phase transitions. Nature, 400(6740), 133\u2013137.\n73\nFIORETTO, PONTELLI, & YEOH\nMonteiro, T. L., Pellenz, M. E., Penna, M. C., Enembreck, F., Souza, R. D., & Pujolle, G. (2012a). Chan-\nnel allocation algorithms for WLANs using distributed optimization. AEU-International Journal of\nElectronics and Communications, 66(6), 480\u2013490.\nMonteiro, T. L., Pujolle, G., Pellenz, M. E., Penna, M. C., Enembreck, F., & Demo Souza, R. (2012b).\nA multi-agent approach to optimal channel assignment in WLANs. In Proceedings of the Wireless\nCommunications and Networking Conference (WCNC), pp. 2637\u20132642.\nMoreno-Vozmediano, R., Montero, R. S., & Llorente, I. M. (2013). Key challenges in cloud computing:\nEnabling the future internet of services. Internet Computing, 17(4), 18\u201325.\nNair, R., Varakantham, P., Tambe, M., & Yokoo, M. (2005). Networked distributed POMDPs: A synergy of\ndistributed constraint optimization and POMDPs. In Proceedings of the International Joint Confer-\nence on Artificial Intelligence (IJCAI), pp. 1758\u20131760.\nNethercote, N., Stuckey, P. J., Becket, R., Brand, S., Duck, G. J., & Tack, G. (2007). Minizinc: Towards a\nstandard CP modelling language. In Proceedings of the International Conference on Principles and\nPractice of Constraint Programming (CP), pp. 529\u2013543.\nNetzer, A., Grubshtein, A., & Meisels, A. (2012). Concurrent forward bounding for distributed constraint\noptimization problems. Artificial Intelligence, 193, 186\u2013216.\nNguyen, D. T., Yeoh, W., & Lau, H. C. (2012). Stochastic dominance in stochastic DCOPs for risk-sensitive\napplications. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 257\u2013264.\nNguyen, D. T., Yeoh, W., & Lau, H. C. (2013). Distributed Gibbs: A memory-bounded sampling-based\nDCOP algorithm. In Proceedings of the International Conference on Autonomous Agents and Multi-\nagent Systems (AAMAS), pp. 167\u2013174.\nNguyen, D. T., Yeoh, W., Lau, H. C., Zilberstein, S., & Zhang, C. (2014). Decentralized multi-agent rein-\nforcement learning in average-reward dynamic DCOPs. In Proceedings of the International Confer-\nence on Autonomous Agents and Multiagent Systems (AAMAS), pp. 1341\u20131342.\nNoriega, P., & Sierra, C. (1999). Auctions and multi-agent systems. In Intelligent Information Agents, pp.\n153\u2013175. Springer.\nOkimoto, T., Clement, M., & Inoue, K. (2013). AOF-based algorithm for dynamic Multi-Objective dis-\ntributed constraint optimization. In Multi-disciplinary Trends in Artificial Intelligence (MIWAI), pp.\n175\u2013186.\nOkimoto, T., Schwind, N., Clement, M., & Inoue, K. (2014). Lp-Norm based algorithm for multi-objective\ndistributed constraint optimization (Extended Abstract). In Proceedings of the International Confer-\nence on Autonomous Agents and Multiagent Systems (AAMAS), pp. 1427\u20131428.\nOta, K., Matsui, T., & Matsuo, H. (2009). Layered distributed constraint optimization problem for resource\nallocation problem in distributed sensor networks. In Proceedings of the Principles and Practice of\nMulti-Agent Systems (PRIMA), pp. 245\u2013260.\nOttens, B., Dimitrakakis, C., & Faltings, B. (2017). DUCT: an upper confidence bound approach to dis-\ntributed constraint optimization problems. ACM Transactions on Intelligent Systems and Technology,\n8(5), 69:1\u201369:27.\nPaquete, L., Chiarandini, M., & Sttzle, T. (2004). Pareto local optimum sets in the biobjective traveling\nsalesman problem: An experimental study. In Metaheuristics for Multiobjective Optimisation, Vol.\n535, pp. 177\u2013199.\n74\nDCOP: MODEL AND APPLICATIONS SURVEY\nParsons, S., & Wooldridge, M. (2002). Game theory and decision theory in multi-agent systems. Autonomous\nAgents and Multi-Agent Systems, 5(3), 243\u2013254.\nPearce, J., & Tambe, M. (2007). Quality guarantees on k-optimal solutions for distributed constraint opti-\nmization problems. In Proceedings of the International Joint Conference on Artificial Intelligence\n(IJCAI), pp. 1446\u20131451.\nPecora, F., Modi, P., & Scerri, P. (2006). Reasoning about and dynamically posting n-ary constraints in\nadopt. In International Workshop on Distributed Constraint Reasoning (DCR).\nPenya-Alba, T., Cerquides, J., Rodriguez-Aguilar, J. A., & Vinyals, M. (2012). Scalable decentralized supply\nchain formation through binarized belief propagation. In Proceedings of the International Conference\non Autonomous Agents and Multiagent Systems (AAMAS), pp. 1275\u20131276.\nPenya-Alba, T., Vinyals, M., Cerquides, J., & Rodriguez-Aguilar, J. A. (2014). Exploiting Max-Sum for the\ndecentralized assembly of high-valued supply chains. In Proceedings of the International Conference\non Autonomous Agents and Multiagent Systems (AAMAS), pp. 373\u2013380.\nPenya-Alba, T., Vinyals, M., Cerquides, J., & Rodriguez-Aguilar, J. A. (2012). A scalable message-passing\nalgorithm for supply chain formation. In Proceedings of the AAAI Conference on Artificial Intelli-\ngence (AAAI), pp. 1436\u20131442.\nPeri, O., & Meisels, A. (2013). Synchronizing for performance-DCOP algorithms. In Proceedings of the\nInternational Conference on Agents and Artificial Intelligence (ICAART), pp. 5\u201314.\nPetcu, A., & Faltings, B. (2005a). Approximations in distributed optimization. In Proceedings of the Inter-\nnational Conference on Principles and Practice of Constraint Programming (CP), pp. 802\u2013806.\nPetcu, A., & Faltings, B. (2005b). A scalable method for multiagent constraint optimization. In Proceedings\nof the International Joint Conference on Artificial Intelligence (IJCAI), pp. 1413\u20131420.\nPetcu, A., & Faltings, B. (2005c). Superstabilizing, fault-containing distributed combinatorial optimization.\nIn Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 449\u2013454.\nPetcu, A., & Faltings, B. (2006). ODPOP: An algorithm for open/distributed constraint optimization. In\nProceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 703\u2013708.\nPetcu, A., & Faltings, B. (2007a). MB-DPOP: A new memory-bounded algorithm for distributed opti-\nmization. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pp.\n1452\u20131457.\nPetcu, A., & Faltings, B. (2007b). Optimal solution stability in dynamic, distributed constraint optimization.\nIn Proceedings of the International Conference on Intelligent Agent Technology (IAT), pp. 321\u2013327.\nPetcu, A., Faltings, B., & Mailler, R. (2007). PC-DPOP: A new partial centralization algorithm for dis-\ntributed optimization. In Proceedings of the International Joint Conference on Artificial Intelligence\n(IJCAI), pp. 167\u2013172.\nPham, T., Tawfik, A., & Taylor, M. (2013). A simple, naive agent-based model for the optimization of a\nsystem of traffic lights: Insights from an exploratory experiment. In Proceedings of the Conference\non Agent-based Modeling in Transportation Planning and Operations, pp. 1\u201321.\nPortway, C., & Durfee, E. H. (2010). The multi variable multi constrained distributed constraint optimization\nframework. In Proceedings of the International Conference on Autonomous Agents and Multiagent\nSystems (AAMAS), pp. 1385\u20131386.\nPujol-Gonzalez, M., Cerquides, J., Farinelli, A., Meseguer, P., & Rodriguez-Aguilar, J. A. (2015). Efficient\ninter-team task allocation in RoboCup rescue. In Proceedings of the International Conference on\nAutonomous Agents and Multiagent Systems (AAMAS), pp. 413\u2013421.\n75\nFIORETTO, PONTELLI, & YEOH\nRaiffa, H. (1968). Decision Analysis: Introductory Lectures on Choices under Uncertainty. Addison-Wesley.\nRamchurn, S. D., Farinelli, A., Macarthur, K. S., & Jennings, N. R. (2010). Decentralized coordination in\nRoboCup rescue. Computer Journal, 53(9), 1447\u20131461.\nRamchurn, S. D., Vytelingum, P., Rogers, A., & Jennings, N. R. (2012). Putting the \u2018smarts\u2019 into the smart\ngrid: A grand challenge for artificial intelligence. Communications of the ACM, 55(4), 86\u201397.\nRegan, K., & Boutilier, C. (2010). Robust policy computation in reward-uncertain MDPs using nondomi-\nnated policies. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 1127\u2013\n1133.\nRogers, A., Farinelli, A., Stranders, R., & Jennings, N. (2011). Bounded approximate decentralised coordi-\nnation via the Max-Sum algorithm. Artificial Intelligence, 175(2), 730\u2013759.\nRollon, E., & Larrosa, J. (2012). Improved Bounded Max-Sum for distributed constraint optimization. In\nProceedings of the International Conference on Principles and Practice of Constraint Programming\n(CP), pp. 624\u2013632.\nRossi, F., Beek, P. v., & Walsh, T. (2006). Handbook of Constraint Programming (Foundations of Artificial\nIntelligence). Elsevier Science Inc.\nRust, P., Picard, G., & Ramparany, F. (2016). Using message-passing DCOP algorithms to solve energy-\nefficient smart environment configuration problems. In Proceedings of the International Joint Con-\nference on Artificial Intelligence (IJCAI), pp. 468\u2013474.\nSalukvad, M. E. (1971). Optimization of vector functionals. I. programming of optimal trajectories. Au-\ntomation and remote Control, 32(8), 5\u201315.\nSchwartz, A. (1993). A reinforcement learning method for maximizing undiscounted rewards. In Proceed-\nings of the International Conference on Machine Learning (ICML), pp. 298\u2013305.\nSemnani, S. H., & Basir, O. A. (2013). Target to sensor allocation: A hierarchical dynamic distributed\nconstraint optimization approach. Computer Communications, 36(9), 1024\u20131038.\nShapiro, L. G., & Haralick, R. M. (1981). Structural descriptions and inexact matching. IEEE Transactions\non Pattern Analysis and Machine Intelligence, 3(5), 504\u2013519.\nSolomon, M. M. (1987). Algorithms for the vehicle routing and scheduling problems with time window\nconstraints. Operations Research, 35(2), 254\u2013265.\nSteinbauer, G., & Kleiner, A. (2012). Towards CSP-based mission dispatching in C2/C4I systems. In IEEE\nInternational Symposium on Safety, Security, and Rescue Robotics (SSRR), pp. 1\u20136.\nStranders, R., Delle Fave, F. M., Rogers, A., & Jennings, N. (2011). U-GDL: A decentralised algorithm\nfor DCOPs with uncertainty. Tech. rep., University of Southampton, Department of Electronics and\nComputer Science.\nStranders, R., Farinelli, A., Rogers, A., & Jennings, N. R. (2009). Decentralised coordination of continu-\nously valued control parameters using the Max-Sum algorithm. In Proceedings of the International\nConference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 601\u2013608.\nStranders, R., Tran-Thanh, L., Fave, F. M. D., Rogers, A., & Jennings, N. R. (2012). DCOPs and ban-\ndits: Exploration and exploitation in decentralised coordination. In Proceedings of the International\nConference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 289\u2013296.\nSultanik, E., Modi, P. J., & Regli, W. C. (2007). On modeling multiagent task scheduling as a distributed\nconstraint optimization problem. In Proceedings of the International Joint Conference on Artificial\nIntelligence (IJCAI), pp. 1531\u20131536.\n76\nDCOP: MODEL AND APPLICATIONS SURVEY\nSultanik, E. A., Lass, R. N., & Regli, W. C. (2008). DCOPolis: A framework for simulating and deploy-\ning distributed constraint reasoning algorithms. In Proceedings of the International Conference on\nAutonomous Agents and Multiagent Systems (AAMAS), pp. 1667\u20131668. International Foundation for\nAutonomous Agents and Multiagent Systems.\nTabakhi, A. M., Le, T., Fioretto, F., & Yeoh, W. (2017). Preference elicitation for DCOPs. In Proceedings\nof Principles and Practice of Constraint Programming (CP), pp. 278\u2013296.\nTassa, T., Zivan, R., & Grinshpoun, T. (2016). Preserving privacy in region optimal DCOP algorithms. In\nIJCAI, pp. 496\u2013502.\nTaylor, M. E., Jain, M., Jin, Y., Yokoo, M., & Tambe, M. (2010). When should there be a me in team?: Dis-\ntributed multi-agent optimization under uncertainty. In Proceedings of the International Conference\non Autonomous Agents and Multiagent Systems (AAMAS), pp. 109\u2013116.\nTaylor, M. E., Jain, M., Tandon, P., Yokoo, M., & Tambe, M. (2011). Distributed on-line multi-agent opti-\nmization under uncertainty: Balancing exploration and exploitation. Advances in Complex Systems,\n14(03), 471\u2013528.\nVan Hentenryck, P., & Michel, L. (2009). Constraint-based local search. The MIT Press.\nVan Katwijk, R., De Schutter, B., & Hellendoorn, J. (2009). Multi-agent control of traffic networks: Algo-\nrithm and case study. In IEEE International Conference on Intelligent Transportation Systems (ITSC),\npp. 1\u20136.\nVerfaillie, G., & Jussien, N. (2005). Constraint solving in uncertain and dynamic environments: A survey.\nConstraints, 10(3), 253\u2013281.\nVermorel, J., & Mohri, M. (2005). Multi-armed bandit algorithms and empirical evaluation. In Proceedings\nof the European Conference on Machine Learning (ECML), pp. 437\u2013448. Springer.\nVinyals, M., Shieh, E., Cerquides, J., Rodriguez-Aguilar, J., Yin, Z., Tambe, M., & Bowring, E. (2011).\nQuality guarantees for region optimal DCOP algorithms. In Proceedings of the International Confer-\nence on Autonomous Agents and Multiagent Systems (AAMAS), pp. 133\u2013140.\nWack, M., Okimoto, T., Clement, M., & Inoue, K. (2014). Local search based approximate algorithm\nfor Multi-Objective DCOPs. In Proceedings of the Principles and Practice of Multi-Agent Systems\n(PRIMA), pp. 390\u2013406.\nWahbi, M., Ezzahir, R., Bessiere, C., & Bouyakhf, E.-H. (2011). Dischoco 2: A platform for distributed\nconstraint reasoning. International Workshop on Distributed Constraint Reasoning (DCR), 11, 112\u2013\n121.\nWalsh, W. E., & Wellman, M. P. (2000). Modeling supply chain formation in multiagent systems. In Agent\nMediated Electronic Commerce II, pp. 94\u2013101. Springer.\nWang, Y., Sycara, K., & Scerri, P. (2011). Towards an understanding of the value of cooperation in uncertain\nworld. In Proceedings of the International Joint Conferences on Web Intelligence and Intelligent\nAgent Technologies (WI-IAT), Vol. 2, pp. 212\u2013215.\nWinsper, M., & Chli, M. (2013). Decentralized supply chain formation using Max-Sum loopy belief propa-\ngation. Computational Intelligence, 29(2), 281\u2013309.\nWood, A. J., & Wollenberg, B. F. (2012). Power Generation, Operation, and Control. John Wiley & Sons.\nWooldridge, M. (2009). An introduction to multiagent systems. John Wiley & Sons.\nWu, F., & Jennings, N. R. (2014). Regret-based multi-agent coordination with uncertain task rewards. In\nProceedings of the AAAI Conference on Artificial Intelligence (AAAI), pp. 1492\u20131499.\n77\nFIORETTO, PONTELLI, & YEOH\nXie, J., Howitt, I., & Raja, A. (2007). Cognitive radio resource management using multi-agent systems. In\nProceedings of the Consumer Communications and Networking Conference (CCNC), pp. 1123\u20131127.\nYan, Z., Lee, J.-H., Shen, S., & Qiao, C. (2013). Novel branching-router-based multicast routing protocol\nwith mobility support. IEEE Transactions on Parallel and Distributed Systems, 24(10), 2060\u20132068.\nYedidsion, H., & Zivan, R. (2014). Applying DCOP MST to a team of mobile robots with directional sensing\nabilities. In International Joint Workshop on Optimization In Multi-Agent Systems and Distributed\nConstraint Reasoning (OPTMAS-DCR).\nYedidsion, H., Zivan, R., & Farinelli, A. (2014). Explorative Max-Sum for teams of mobile sensing agents.\nIn Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AA-\nMAS), pp. 549\u2013556.\nYeoh, W. (2010). Speeding Up Distributed Constraint Optimization Search Algorithms. Ph.D. thesis, Uni-\nversity of Southern California, Los Angeles (United States).\nYeoh, W., Felner, A., & Koenig, S. (2010). BnB-ADOPT: An asynchronous branch-and-bound DCOP\nalgorithm. Journal of Artificial Intelligence Research, 38, 85\u2013133.\nYeoh, W., Sun, X., & Koenig, S. (2009a). Trading off solution quality for faster computation in DCOP search\nalgorithms. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),\npp. 354\u2013360.\nYeoh, W., Varakantham, P., & Koenig, S. (2009b). Caching schemes for DCOP search algorithms. In Pro-\nceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS),\npp. 609\u2013616.\nYeoh, W., Varakantham, P., Sun, X., & Koenig, S. (2011). Incremental DCOP search algorithms for solv-\ning dynamic DCOPs (Extended Abstract). In Proceedings of the International Conference on Au-\ntonomous Agents and Multiagent Systems (AAMAS), pp. 1069\u20131070.\nYeoh, W., & Yokoo, M. (2012). Distributed problem solving. AI Magazine, 33(3), 53\u201365.\nYokoo, M. (Ed.). (2001). Distributed constraint satisfaction: Foundation of cooperation in Multi-agent\nSystems. Springer Berlin Heidelberg.\nYokoo, M., Durfee, E. H., Ishida, T., & Kuwabara, K. (1998). The distributed constraint satisfaction problem:\nFormalization and algorithms. Knowledge and Data Engineering, IEEE Transactions on, 10(5), 673\u2013\n685.\nYokoo, M., & Hirayama, K. (2000). Algorithms for distributed constraint satisfaction: A review. Autonomous\nAgents and Multi-Agent Systems, 3(2), 185\u2013207.\nZhang, C., & Lesser, V. (2013). Coordinating multi-agent reinforcement learning with limited communica-\ntion. In Proceedings of the International Conference on Autonomous Agents and Multiagent Systems\n(AAMAS), pp. 1101\u20131108.\nZhang, W., Wang, G., Xing, Z., & Wittenberg, L. (2005). Distributed stochastic search and distributed break-\nout: Properties, comparison and applications to constraint optimization problems in sensor networks.\nArtificial Intelligence, 161(1\u20132), 55\u201387.\nZilberstein, S. (1996). Using anytime algorithms in intelligent systems. AI Magazine, 17(3), 73.\nZivan, R., Glinton, R., & Sycara, K. (2009). Distributed constraint optimization for large teams of mo-\nbile sensing agents. In Proceedings of the International Joint Conferences on Web Intelligence and\nIntelligent Agent Technologies (WI-IAT), pp. 347\u2013354.\n78\nDCOP: MODEL AND APPLICATIONS SURVEY\nZivan, R., & Meisels, A. (2006). Dynamic ordering for asynchronous backtracking on DisCSPs. Constraints,\n11(2-3), 179\u2013197.\nZivan, R., Okamoto, S., & Peled, H. (2014). Explorative anytime local search for distributed constraint\noptimization. Artificial Intelligence, 212, 1\u201326.\nZivan, R., Parash, T., Cohen, L., Peled, H., & Okamoto, S. (2017). Balancing exploration and exploitation in\nincomplete Min/Max-Sum inference for distributed constraint optimization. Journal of Autonomous\nAgents and Multi-Agent Systems, 1\u201343.\nZivan, R., & Peled, H. (2012). Max/Min-Sum distributed constraint optimization through value propagation\non an alternating DAG. In Proceedings of the International Conference on Autonomous Agents and\nMultiagent Systems (AAMAS), pp. 265\u2013272.\n79\n",
        "id": 24765903,
        "identifiers": [
          {
            "identifier": "42683862",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:arxiv.org:1602.06347",
            "type": "OAI_ID"
          },
          {
            "identifier": "10.1613/jair.5565",
            "type": "DOI"
          },
          {
            "identifier": "1602.06347",
            "type": "ARXIV_ID"
          }
        ],
        "title": "Distributed Constraint Optimization Problems and Applications: A Survey",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:arxiv.org:1602.06347"
        ],
        "publishedDate": "2018-01-10T00:00:00",
        "publisher": "'AI Access Foundation'",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://arxiv.org/abs/1602.06347"
        ],
        "updatedDate": "2020-12-24T13:54:15",
        "yearPublished": 2018,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "http://arxiv.org/abs/1602.06347"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/24765903"
          }
        ]
      },
      "relevance_score": 0.0295,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.295,
          "dimension_weight": 0.1,
          "weighted_score": 0.0295,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2018 (Norm. Score: 0.4)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_secondary_7",
      "dynamic_step": 0,
      "core_id": 24765903,
      "doi": "10.1613/jair.5565"
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": "1502.00663",
        "authors": [
          {
            "name": "Lazar, Martin"
          }
        ],
        "citationCount": 0,
        "contributors": [],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/29507560"
        ],
        "createdDate": "2015-09-24T00:03:29",
        "dataProviders": [
          {
            "id": 144,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/144",
            "logo": "https://api.core.ac.uk/data-providers/144/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "We analyse stability of observability estimates for solutions to wave and\nScr\\\" odinger equations subjected to additive perturbations. The paper\ngeneralises the recent averaged observability/control result by allowing for\nsystems consisting of operators of different types. The method also applies to\nthe simultaneous observability problem by which one tries to estimate the\nenergy of each component of a system under consideration. The analysis relies\non microlocal defect tools; in particular on standard H-measures, when the main\ndynamic of the system is governed by the wave operator, while parabolic\nH-measures are explored in the case of the Schr\\\" odinger operator",
        "documentType": "research",
        "doi": null,
        "downloadUrl": "http://arxiv.org/abs/1502.00663",
        "fieldOfStudy": null,
        "fullText": "ar\nX\niv\n:1\n50\n2.\n00\n66\n3v\n1 \n [m\nath\n.A\nP]\n  3\n0 J\nan\n 20\n15\nSTABILITY OF OBSERVATIONS OF PARTIAL DIFFERENTIAL EQUATIONS\nUNDER UNCERTAIN PERTURBATIONS\nMARTIN LAZAR\nAbstract. We analyse stability of observability estimates for solutions to wave and Scro\u00a8dinger equations\nsubjected to additive perturbations. The paper generalises the recent averaged observability/control result\nby allowing for systems consisting of operators of different types. The method also applies to the simultaneous\nobservability problem by which one tries to estimate the energy of each component of a system under\nconsideration. The analysis relies on microlocal defect tools; in particular on standard H-measures, when\nthe main dynamic of the system is governed by the wave operator, while parabolic H-measures are explored\nin the case of the Schro\u00a8dinger operator.\n1. Introduction\nA notion of averaged control has been recently introduced in [15, 10], both for parameter dependent\nODEs, as well as for systems of PDEs with variable coefficients. Its goal is to control the average (or more\ngenerally a suitable linear combination) of system components by a single control. The problem is relevant\nin practice where the control has to be chosen independently of the coefficient value.\nThe notion is equivalent to the averaged observability, by which the energy of the system is recorded by\nobserving the average of solutions on a suitable subdomain.\nIn the paper we investigate a more general problem based on a system whose first component represents\nits main dynamic, while the other ones correspond to perturbations. Assuming that the main component is\nobservable, we explore conditions by which that property remains stable under additive perturbations.\nIn general, the operators entering the system are not assumed to be of the same type. In a special case\nof a system consisting of a same type operators, the result corresponds to the averaged control of the system,\nthus incorporating results obtained in [10].\nThe methods are applied to the simultaneous observability problem as well, by which one tries to estimate\nenergy of all system components by observing their average. The corresponds dual problem consists of\ncontrolling each individual component of the adjoint system by means of a same control.\nThe study of the problem explores microlocal analysis tools, in particular H-measures and their variants.\nH-measures, introduced independently in [7, 14], are kind of defect tools, measuring deflection of the weak\nfrom strong convergence of L2 sequences. Since their introduction, they have been successfully applied\nin many mathematical fields - let us just mention generalisation of compensated compactness results to\nequations with variable coefficients [7, 14] and applications in the control theory [4, 5, 10]. Most of these\napplications apply the so called localisation principle providing constraints on the support of H-measures\n(e.g. [14]), and the proofs of this paper rely on it as well.\nThe paper is organised as follows. In the next section we provide an averaged observability result for a\nsystem whose main dynamic is governed by the wave operator. The finite system is analysed first, followed\nby generalisations to an infinite discrete setting. Application of the approach to simultaneous observability\nis provided in the subsection 2.3. The third section is devoted to observation of the Schro\u00a8dinger equation\nunder perturbations determined either by a hyperbolic or by a parabolic type operator. In the latter case,\nparabolic H-measures (generalisation of original ones to a parabolic setting) have to be explored. The paper\nis closed with concluding remarks, and by pointing toward some open and related problems.\n1991 Mathematics Subject Classification. 93B05, 93B07, 93C20, 93D09 .\nKey words and phrases. averaged control, robust observability, parabolic H-measures.\n1\n2 MARTIN LAZAR\n2. Observation of the wave equation under uncertain perturbations\n2.1. Averaged observability. We analyse the problem of recovering the energy of the wave equation by\nobserving an additive perturbation of the solution. The perturbation is determined by a differential operator\nP2, in general different from the wave one.\nMore precisely, we consider the following system of equations:\nP1u1 = \u2202ttu1 \u2212 div (A1(t,x)\u2207u1) = 0, (t,x) \u2208 R+ \u00d7 \u2126\nP2u2 = 0, (t,x) \u2208 R+ \u00d7 \u2126\nu1 = 0, (t,x) \u2208 R+ \u00d7 \u2202\u2126\nu1(0, \u00b7) = \u03b20 \u2208 L2(\u2126)\n\u2202tu1(0, \u00b7) = \u03b21 \u2208 H\u22121(\u2126) ,\n(2.1)\nwhere \u2126 is an open, bounded set in Rd, A1 is a bounded, positive definite matrix field, while P2 is some,\nalmost arbitrary, differential operator (precise conditions on it will be given below). In the sequel we shall\nalso use the notation A1 = \u2212div (A1\u2207) for the elliptic part of P1.\nFor the moment, we specify neither initial nor boundary conditions for the second equation, we just\nassume that corresponding problem is well posed and that it admits an L2 solution. For the coefficients of\nboth the operators we assume that are merely bounded and continuous.\nProposition 2.1. Suppose that there is a constant C\u02dc, time T and an open subdomain \u03c9 such that for any\nchoice of initial conditions \u03b20, \u03b21 the solution u1 of (2.1) satisfies\nE1(0) := \u2016\u03b20\u20162L2 + \u2016\u03b21\u20162H\u22121 \u2264 C\u02dc\n\u222b T\n0\n\u222b\n\u03c9\n|u1|2dxdt . (2.2)\nIn addition, we assume that characteristic sets {pi(t,x, \u03c4, \u03be) = 0}, i = 1, 2 have no intersection for (t,x) \u2208\n\u30080, T \u3009 \u00d7 \u03c9, (\u03c4, \u03be) \u2208 Sd, where pi stands for the principal symbol of the operator Pi.\nThen for any \u03b81, \u03b82 \u2208 R, \u03b81 6= 0 there exists a constant C\u02dc\u03b81 such that the observability inequality\nE1(0) \u2264 C\u02dc\u03b81\n(\u222b T\n0\n\u222b\n\u03c9\n|\u03b81u1 + \u03b82u2|2dxdt+ \u2016\u03b20\u20162H\u22121 + \u2016\u03b21\u20162H\u22122\n)\n(2.3)\nholds for any pair of solutions (u1, u2) to (2.1).\nProof: Of course, the case \u03b82 = 0 holds trivially, and for simplicity is excluded from the further analysis.\nWe argue by contradiction. Assuming the contrary, there exists a sequence of solutions un1 , u\nn\n2 such that\nEn1 (0) > n\n(\u222b T\n0\n\u222b\n\u03c9\n|\u03b81un1 + \u03b82un2 |2dxdt + \u2016\u03b2n0 \u20162H\u22121 + \u2016\u03b2n1 \u20162H\u22122\n)\n. (2.4)\nAs the considered problem is linear, without loosing generality we can assume that En(0) = 1. Thus (2.4)\nimplies that \u2016\u03b2n0 \u20162H\u22121 + \u2016\u03b2n1 \u20162H\u22122 \u2192 0, resulting in the weak convergence (\u03b2n0 , \u03b2n1 ) \u2212\u21c0 (0, 0) in L2(\u2126) \u00d7\nH\u22121(\u2126). Therefore the solutions (un1 ) converge weakly to zero in L\n2(\u2126\u00d7 \u30080, T \u3009) as well. In order to obtain\na contradiction, we have to show that the last convergence is strong, at least on the observability region.\nFrom the contradictory assumption (2.4) we have that the H-measure \u03bd associated to a subsequence of\n(\u03b81u\nn\n1 + \u03b82u\nn\n2 ) vanishes on \u30080, T \u3009 \u00d7 \u03c9. Furthermore, it is of the form\n\u03bd = \u03b821\u00b51 + \u03b8\n2\n2\u00b52 + \u03b81\u03b822\u211c\u00b512,\nwhere on the right hand side the elements of the matrix measure associated to the vector subsequence of\n(un1 , u\nn\n2 ) are listed, with \u00b512 denoting the off-diagonal element. Note that (u\nn\n2 ) is bounded in L\n2(\u30080, T \u3009 \u00d7 \u03c9),\nsince that is the case for (un1 ) (by boundedness of initial data), and for the linear combination (\u03b81u\nn\n1 + \u03b82u\nn\n2 )\n(by contradictory assumption (2.4)), which enables one to associate an H-measure to it.\nAccording to the localisation property for H-measures, each \u00b5j is supported within the corresponding\ncharacteristic set {pi(t,x, \u03c4, \u03be) = 0}, i = 1, 2, which, by assumption, are disjoint on the observability region.\nOn the other hand, from the very definition of matrix H-measures it follows that off-diagonal entries are\nSTABILITY OF OBSERVATIONS OF PDE-S UNDER UNCERTAIN PERTURBATIONS 3\ndominated by the corresponding diagonal elements. More precisely, it holds that supp\u00b512 \u2286 supp\u00b51 \u2229\nsupp\u00b52, implying that \u00b512 = 0 on the observability region.\nThus we get that\n\u03bd = \u03b821\u00b51 + \u03b8\n2\n2\u00b52 = 0 on \u30080, T \u3009 \u00d7 \u03c9 .\nAs \u00b51 and \u00b52 are positive measures and \u03b81 > 0, it follows that \u00b51 vanishes on \u30080, T \u3009 \u00d7 \u03c9 as well. Thus\nwe get strong convergence of (un1 ) in L\n2(\u30080, T \u3009 \u00d7 \u03c9), which together with the assumption of the constant,\nnon-zero initial energy contradicts the observability estimate (2.2). \u0003\nRemark 1. The last result provides surprising stability of the observability estimate (2.2) under uncertain\nperturbations, up to compact reminders. Essentially, the only requirement for the perturbation is separation of\nthe characteristic sets. This implies that the wave component can be observed robustly when adding unknown\nperturbations, up to a finite number of low frequencies.\nIn the next step we would like to obtain the strong observability inequality for initial energy E1(0) by\nremoving compact terms in (2.3). To this effect, we have to specify some additional constraints on the\nproblem for the perturbation u2.\nWe take P2 to be an evolution operator of the form\nP2 = (\u2202t)\nk + c2(x)A1, k \u2208 N, (2.5)\nwhere A1 is an elliptic part of the wave operator P1, while c2 is a bounded and continuous function.\nTheorem 2.2. As above, we assume that the coefficients of the operator P1 are bounded and continuous,\nand that the corresponding solution u1 satisfies the observability inequality (2.2).\nIn addition we assume that the perturbation operator P2 is of the form (2.5). In the case k = 2 (i.e. P2\nbeing a wave operator) the separation of coefficients c2(x) \u2212 1 6= 0 is supposed on \u03c9.\nFor the initial values of solutions ui, i = 1, 2 we supposed these are related by a linear operator such that\nwhenever ((\u03b81u1(0) + \u03b82u2(0))|\u03c9 = 0) then\n(\nu1(0)|\u03c9 = u2(0)||\u03c9 = 0\n)\n, and the analogous implication holds for\nthe initial first order time derivatives.\nThen there is a positive constant C\u03b81 such that the strong observability inequality holds:\nE1(0) \u2264 C\u03b81\n\u222b T\n0\n\u222b\n\u03c9\n|\u03b81u1 + \u03b82u2|2dxdt . (2.6)\nRemark 2. Note that the above assumptions directly imply that characteristic sets of P1 and P2 are disjoint.\nIndeed, for P2 being an evolution operator of order k 6= 2, its principal symbol equals 0 only in poles \u03be = 0\n(case k = 1), or on the equator \u03c4 = 0 (case k > 2) of the unit sphere in the dual space, where p1 =\n\u03c42 \u2212A1(x)\u03be2 differs from zero.\nIn the case k = 2 separation of the characteristic sets is provided by the assumption c2(x) 6= 1 on \u03c9.\nProof: As in the proof of Proposition 2.1, let us suppose the contrary. Then there exists a sequence of\nsolutions un1 , u\nn\n2 to (2.1) such that E\nn\n1 (0) = 1 and\u222b T\n0\n\u222b\n\u03c9\n|\u03b81un1 + \u03b82un2 |2dxdt \u2212\u2192 0 . (2.7)\nThus the corresponding weak limits satisfy both the equation Piui = 0, as well as the relation\n\u03b81u1 + \u03b82u2 = 0 (2.8)\non the observability region. As functions ui, \u2202tui are continuous with respect to time, the bounds on initial\ndata imply \u03b20 = \u03b21 = 0 on \u03c9.\nAssumptions on the operators Pi, i = 1, 2 ensure that corresponding characteristic sets do not intersect.\nBy applying localisation property of H-measures as in the proof of Proposition 2.1 we get that un1 converges\nto u1 strongly on \u30080, T \u3009 \u00d7 \u03c9.\nIt remains to show that the limit u1 vanishes on the observability region, which, together with the\nassumption of the constant non-zero initial energy, will contradict the observability assumption (2.2).\nWe split the rest of the proof into several cases.\n4 MARTIN LAZAR\na) (k = 2) Due to the relation (2.8) it follows that\n(c2 \u2212 1)\u2202ttu1 = 0, (t,x) \u2208 \u30080, T \u3009 \u00d7 \u03c9 .\nAs |c2 \u2212 1| > 0, and the initial data are 0 on \u03c9, it implies u1 = 0 on the observability region.\nb) (k = 1) Relation (2.8) implies\n\u2202tu1 = c2(x)\u2202ttu1,\nwhich together with u1(0, \u00b7) = \u2202tu1(0, \u00b7) = 0 on \u03c9 provides the claim.\nc) (k > 2) Similar as above we obtain\n\u2202k\u22122t (\u2202ttu1) = c2(x)\u2202ttu1 .\nAs \u2202ttu1(0, \u00b7) = \u2212A1u1(0, \u00b7) = 0 on \u03c9, and similarly for the higher order derivatives, the claim\nfollows.\n\u0003\nRemark 3. Several remarks are in order.\n\u2022 The observability assumption (2.2) on a solution of the wave equation is equivalent to the Geometric\nControl Condition (GCC, [3]), stating that projection of each bicharacteristic ray on a physical space\nhas to enter the observability region in a finite time.\n\u2022 The last theorem also holds if, instead of initial data of two components being linked by an operator,\nwe assume a cone condition \u2016u2(0)\u2016L2(\u03c9) \u2264 c\u2016u1(0)\u2016L2(\u03c9)\n(\n\u2016u2(0)\u2016L2(\u03c9) \u2265 c\u2016u1(0)\u2016L2(\u03c9)\n)\n, with a\nconstant c < \u03b81/\u03b82 (c > \u03b81/\u03b82). The latter condition is stable under passing to a limit, and also\nensures the implication ((\u03b81u1(0) + \u03b82u2(0))|\u03c9 = 0) =\u21d2\n(\nu1(0)|\u03c9 = u2(0)||\u03c9 = 0\n)\n, which suffices for\nthe proof.\n\u2022 The result (2.6) can be generalise to a more general perturbation operator P2 by assuming that\ncoefficients of both the operators are analytic. In that case the separation of characteristic sets\nimplies the separation of corresponding analytic wave front sets ([9, Theorem 9.5.1]). Together with\n(2.8) it provides that u1 is analytic on the observability region. Constraints on initial data and finite\nvelocity of propagation imply u1 = 0 on an open set near t = 0, and as the solution is analytic it\nvanishes on the whole observability region which contradicts the observability assumption (2.2).\n\u2022 If P2 is a wave operator the strong observability inequality (2.6) is equivalent to the controllability of\na suitable linear combination (determined by the operator linking the initial data) of solutions to the\nadjoint system under a single control (cf. [10]).\nMeanwhile, the weak observability result (2.3) in that case corresponds to the average controllability\nof the adjoint system up to a finite number of low frequencies.\n\u2022 The last theorem generalises the results of [10] by allowing for a general evolution operator P2 which\ndoes not have to be the wave one.\nIn addition, it allows for an arbitrary linear combination of system components, while in [10]\njust their (weighted) average is explored. Specially, if the difference u1 \u2212 u2 is considered, the result\ncorresponds to the synchronisation problem (e.g. [12]) in which all the components are driven to the\nsame state by applying the null controllability of their differences.\nFurthermore, unlike in [10], the proof of the relaxed observability inequality (2.3) does not rely on\nthe propagation property of H-measures, which allows for system\u2019s coefficients to be merely continu-\nous. On the other hand, such approach avoid technical issues related to the reflection of H-measures\non the domain boundary.\n\u2022 The theorem to some extent also generalises the results of [16] in which a similar result is provided\nfor the system (2.1) consisting of a wave and a heat operator with constant coefficients (or more\ngenerally with a common elliptic part).\nHowever, although allowing for a more general perturbation operator, it requires initial data of\ntwo components of the system (2.1) to be related, while in [16] no assumptions on initial data for the\nsecond component is assumed.\n\u2022 The constant C\u03b81 can be taken to be uniform for \u03b81 \u2265 \u03b8\u2217 and \u03b8\u2217 > 0.\nSTABILITY OF OBSERVATIONS OF PDE-S UNDER UNCERTAIN PERTURBATIONS 5\n\u2022 The weak observability result (2.3) is easily generalised to a system with a finite number of compo-\nnents, under assumption that the characteristic set of the leading operator P1 is separated from the\ncharacteristic sets of all the other operators, while the latter ones can be arbitrary related.\nHowever, the generalisation of the result to an infinite dimensional setting is not straightforward.\nIt requires study of the localisation property for H-measures determined by a sequence of function\nseries, and is the subject of the next subsection.\nOn the other side, the generalisation of the strong estimate result (2.6) to a system consisting of\nmore than two components has still not been obtained, and is a subject of the current investigations.\n\u2022 The result (2.3) also holds if the observability region is not of a cylindrical type, but a more general\nset satisfying the GCC for the first component of the system. Such generalisation corresponds to a\nmoving control (cf. [11]). However, possible derivation of the corresponding stronger observability\nresult remains open, due to the last part of the proof of Theorem 2.2, in which the special (cylindrical)\nshape of the observability region is used.\n\u2022 Note that the observability result (2.6) is weaker than the one required in the simultaneous control,\nwhere one has to estimate initial energy of all components entering the system. Of course, the\nassumptions in the latter case are stronger, as one has to assume that the observability set satisfies\nthe GCC for the second component as well.\n2.2. Infinite discrete setting. In this subsection we want to analyse the stability of the observability esti-\nmates for the wave equation when the perturbation is given as a superposition of infinitely many components,\neach determined by a differential operator Pi, which, in general, does not have to be the wave one. Thus the\nsystem of interest reads as:\nP1u1 = \u2202ttu1 \u2212 div (A1(t,x)\u2207u1) = 0, (t,x) \u2208 R+ \u00d7 \u2126\nPiui = 0, (t,x) \u2208 R+ \u00d7 \u2126, i \u2265 2\nu1 = 0, (t,x) \u2208 R+ \u00d7 \u2202\u2126\nu1(0, \u00b7) = \u03b20 \u2208 L2(\u2126)\n\u2202tu1(0, \u00b7) = \u03b21 \u2208 H\u22121(\u2126) ,\n(2.9)\nwith the same assumptions on the domain \u2126 and the operator P1 being assumed for the system (2.1). For\nthe other equations, neither initial nor boundary conditions are specified. For the moment, we just assume\nthe corresponding coefficients are bounded and continuous, and the problems are well defined with solutions\nin L2(\u2126).\nIn this setting, the same microlocal analysis tool as in the finite case, in particular the localisation\nproperty of H-measures, is applied in the study of the stability of the observability estimates. However, as\nperturbations are determined by a superposition of infinitely many solutions, this requires analysis of the\nmentioned property for a sequence of function series.\nNamely, it is well known that an H-measure associated to a linear combination of two sequences is\nsupported within the union of supports of measures determined by each component, and the same property\nholds for any finite linear combination. However, in general it fails when considering superposition of infinite\nmany sequences, as shown by the next example.\nExample 1. Let (un) and (fn) be L2(Rd) sequences, whose corresponding H-measures \u00b5u and \u00b5f have\ndisjoint supports, and let (\u03b8i) be a sequence of nonnegative numbers summing in 1.\nDefine the following sequences\nvni =\n{\n\u03b8iu\nn i 6= n\nf i i = n .\nThus for each i an H-measure \u03bdi associated to v\nn\ni equals \u03b8\n2\ni \u00b5u.\nOn the other side we have that\n\u2211\ni v\nn\ni = (1\u2212 \u03b8n)un+ fn, and the corresponding measure equals \u00b5u+\u00b5f .\nThus in order to constrain support of an H-measure by supports of corresponding components we have\nto impose additional assumptions on constituting sequences. More precisely, the following result holds.\n6 MARTIN LAZAR\nLemma 2.3. Let (\u03b8i) be an averaging sequence of positive numbers summing to 1, and let (u\nn\ni )n, i \u2208 N be\na family of uniformly bounded L2 sequences, i.e. we assume there exists a constant Cu such that \u2016uni \u2016L2 \u2264\nCu, i, n \u2208 N.\nDefine the linear combination vn =\n\u2211\ni \u03b8iu\nn\ni , and denote by \u00b5i and \u03bd H-measures associated to (sub)se-\nquences (of) (uni )n and (vn), respectively. Then\nsupp \u03bd \u2286 Cl\n(\n\u222ai supp\u00b5i\n)\n. (2.10)\nProof: Take an arbitrary pseudodifferential operator of order zero, P \u2208 \u03a80c , with a symbol p(x, \u03be) being\ncompactly supported within the complement of the closure of \u222aisupp\u00b5i.\nBy the definition of H-measures we have\n\u3008\u03bd, p\u3009 = lim\nn\n\u222b\nRd\nP\n( \u221e\u2211\n1\n\u03b8iu\nn\ni\n)\n(x)\n( \u221e\u2211\n1\n\u03b8ju\nn\nj\n)\n(x)dx . (2.11)\nAs P is a continuous operator on L2(Rd) it follows that\nlim\nn\n\u2223\u2223\u2223\u2223\u2223\n\u222b\nRd\nP\n( \u221e\u2211\nk\n\u03b8iu\nn\ni\n)\n(x)\n( \u221e\u2211\n1\n\u03b8ju\nn\nj\n)\n(x)dx\n\u2223\u2223\u2223\u2223\u2223 \u2264 lim supn CP\n\u2225\u2225\u2225 \u221e\u2211\nk\n\u03b8iu\nn\ni\n\u2225\u2225\u2225\nL2\n\u2225\u2225\u2225 \u221e\u2211\n1\n\u03b8iu\nn\ni\n\u2225\u2225\u2225\nL2\n\u2264 lim sup\nn\nCP C\n2\nu\n(\n\u221e\u2211\nk\n\u03b8i\n)\nk\u2212\u2192 0 ,\n(2.12)\nwhere CP is the L\n2 bound of the operator P . The last sum is a remainder of a convergent series, and the\nabove limit converges to zero uniformly with respect to n.\nSimilarly, one shows the same property holds for limn\n\u2223\u2223\u2223\u222b\nRd\nP\n(\u2211\u221e\n1 \u03b8\nn\ni u\nn\ni\n)\n(x)\n(\u2211\u221e\nl \u03b8\nn\nj u\nn\nj\n)\n(x)dx\n\u2223\u2223\u2223. Thus\nwe can exchange limits in (2.11), getting\n\u3008\u03bd, p\u3009 =\n\u221e\u2211\ni=1\n\u221e\u2211\nj=1\nlim\nn\n\u222b\nRd\nP (\u03b8iu\nn\ni ) (x) \u03b8ju\nn\nj (x)dx\n=\n\u221e\u2211\ni=1\n\u221e\u2211\nj=1\n\u03b8i\u03b8j\u3008\u00b5ij , p\u3009 = 0,\n(2.13)\nwhere \u00b5ij are H-measures determined by sequences (u\nn\ni ) and (u\nn\nj ), supported within the closure given in\n(2.10), outside which p is supported. \u0003\nAs a consequence of the last lemma, in order to apply the localisation property within the analysis of\nobservability estimates for solutions to (2.9), some kind of uniform boundedness on the solutions has to be\nassumed.\nProposition 2.4. Suppose the observability inequality (2.2) holds for a solution u1 to (2.9).\nAs for the system (2.9), suppose that L2 norm of all the solutions ui is dominated (up to a multi-\nplicative constant, independent of a choice of initial data) by the energy norm of u1. In addition as-\nsume that characteristic set {p1(t,x, \u03c4, \u03be) = 0} has no intersection with Cl\n(\n\u222ai\u22652 {pi(t,x, \u03c4, \u03be) = 0}\n)\nfor\n(t,x) \u2208 \u30080, T \u3009 \u00d7 \u03c9, (\u03c4, \u03be) \u2208 Sd, where pi stands for the principal symbol of the operator Pi.\nThen for any averaging sequence (\u03b8i) of positive numbers summing to 1, with \u03b81 > 0, there exists a\nconstant C\u02dc\u03b8 such that the observability inequality\nE1(0) \u2264 C\u02dc\u03b8\n(\u222b T\n0\n\u222b\n\u03c9\n|\n\u2211\n\u03b8iui|2dxdt + \u2016\u03b20\u20162H\u22121 + \u2016\u03b21\u20162H\u22122\n)\n(2.14)\nholds for any family of solutions (ui) to (2.9).\nSTABILITY OF OBSERVATIONS OF PDE-S UNDER UNCERTAIN PERTURBATIONS 7\nProof: Assume the contrary. Then there exist sequences of initial conditions (\u03b2n0 ), (\u03b2\nn\n1 ), and of associ-\nated solutions (uni ), such that\n1 = En1 (0) := \u2016\u03b2n0 \u20162L2 + \u2016\u03b2n1 \u20162H\u22121 > n\n(\u222b T\n0\n\u222b\n\u03c9\n|\n\u221e\u2211\ni=1\n\u03b8iu\nn\ni |2dxdt + \u2016\u03b2n0 \u20162H\u22121 + \u2016\u03b2n1 \u20162H\u22122\n)\n. (2.15)\nLet \u03bd be an H-measure associated to a (sub)sequence of\n\u2211\u221e\ni=1 \u03b8\nn\ni u\nn\ni . Due to the inequality (2.15), it equals\nzero on \u30080, T \u3009 \u00d7 \u03c9.\nWe split the last sum into two parts \u03b81u\nn\n1 +\n\u2211\u221e\ni=2 \u03b8iu\nn\ni , and we rewrite \u03bd in the form\n\u03bd = \u03bd1 + \u03bd2 + 2\u211c\u03bd12,\nwhere \u03bd1 and \u03bd2 are H-measures associated to (sub)sequences (of) (\u03b8\nn\n1 u\nn\n1 ) and (\n\u2211\u221e\n2 \u03b8\nn\ni u\nn\ni ), respectively, while\n\u03bd12 is a measure corresponding to their product. In addition, \u03bd1 = \u03b8\n2\n1\u00b51, where by \u00b5i we denote a measure\nassociated to a (sub)sequence (of) the i\u2212th component uni .\nFrom here the statement of the theorem is obtained easily (following the lines of the proof in finite\ndiscrete case, Proposition 2.1), once we show that \u03bd1 and \u03bd2 have disjoint supports.\nBy the localisation property for H-measures, each measure \u00b5i is supported within the set {pi(t,x, \u03c4, \u03be) =\n0}.\nThe assumption on the domination of solutions to (2.9) by an energy norm of u1, together with the\nconstant initial energy En1 (0) implies uniform bound on solutions u\nn\ni , both with respect to i and n. Thus we\ncan apply Lemma 2.3 to conclude that \u03bd2 is supported within the set\nCl\n(\n\u222ai\u22652 {pi(t,x, \u03c4, \u03be) = 0}\n)\n,\nwhich, due to the assumption on separation of the characteristics set, does not intersect the support of\n\u03bd1 = \u03b8\n2\n1\u00b51. As \u03b81 is strictly positive, we get that u\nn\n1 converges to 0 strongly in L\n2(\u30080, T \u3009 \u00d7 \u03c9), which\ncontradicts the observability estimate (2.2). \u0003\nRemark 4.\n\u2022 The assumption of the last proposition requiring solutions ui of (2.9) to be dominated by the energy\nnorm of u1 occurs, for example, in a case of a system consisting of the operators of the same form,\nPi = \u03c4\n2 \u2212Ai(t,x)\u03be \u00b7 \u03be, with uniformly bounded (both from below and above) coefficients and initial\nenergies.\nThe assumption on separation of characteristics sets in that case can be stated as\nA1(t,x)\u03be \u00b7 \u03be > (<) sup\ni\u22652\n(inf\ni\u22652\n) Ai(t,x)\u03be \u00b7 \u03be, (t,x) \u2208 \u30080, T \u3009 \u00d7 \u03c9, \u03be 6= 0 ,\ni.e. the fastest (or the slowest) velocity is strictly separated from all the others.\nIn that case the weak observability (2.14) result is equivalent to the averaged controllability of the\nadjoint system up to a finite number of low frequencies.\nOf course, one can construct more general systems, including operators of different types as well,\nthat satisfy the required boundedness assumption.\n\u2022 As already mentioned in previous subsection, obtaining corresponding strong observability result in\nthis setting remains an open problem.\n\u2022 The constant C\u03b8 appearing in (2.14) can be taken uniformly for a family of averaging sequences, each\nsatisfying\n(i) \u03b81 \u2265 \u03b8\u2217,\n(ii)\n\u2211\u221e\nk \u03b8i \u2264 \u01ebk,\nwhere \u03b8\u2217 \u2208 \u30080, 1] and (\u03b5k) is a null sequence, both independent of a choice of a particular sequence\n(\u03b8i).\n2.3. Simultaneous observability. The subsection deals with a problem of recovering energy of a system\nby observing an average of solutions on a suitable subdomain. For this purpose one has to estimate initial\nenergies of all system components, unlike the case of the average observability where this was required just\nfor the first one. A two component system is analysed firstly, while generalisations to a more dimensional\ncase is discussed at the end.\n8 MARTIN LAZAR\nWe reconsider the system (2.1) assuming that P2 is an evolution operator of the form\nP2 = (\u2202t)\nk +A2, k \u2208 N, (2.16)\nwhere A2 is an (uniformly) elliptic operator (in general different from A1), and the problem for the pertur-\nbation u2 is accompanied by a series of initial conditions(\n(\u2202t)\nju2\n)\n(0) = \u03b3j \u2208 H\u2212j(\u2126), j = 0, . . . , k \u2212 1.\nIts initial energy is denoted by\nE2(0) =\nk\u22121\u2211\n0\n\u2016\u03b3j\u2016H\u2212j(\u2126) .\nAs in the previous subsection, we start with a weak observability result.\nProposition 2.5. Suppose that there is a constant C\u02dc, time T and an open subdomain \u03c9 such that for any\nchoice of initial conditions the solutions to (2.1) satisfy\nEi(0) \u2264 C\u02dc\n\u222b T\n0\n\u222b\n\u03c9\n|ui|2dxdt, i = 1, 2 . (2.17)\nIn addition assume that characteristic sets {pi(t,x, \u03c4, \u03be) = 0}, i = 1, 2 have no intersection for (t,x) \u2208\n\u30080, T \u3009 \u00d7 \u03c9, (\u03c4, \u03be) \u2208 Sd, where pi stands for the principal symbol of the operator Pi.\nThen for any \u03b81, \u03b82 \u2208 R \\ {0} there exists a constant C\u02dc\u03b8 such that the observability inequality\nE1(0)+E2(0) \u2264 C\u02dc\u03b8\n(\u222b T\n0\n\u222b\n\u03c9\n|\u03b81u1 + \u03b82u2|2dxdt+ \u2016\u03b20\u20162H\u22121 + \u2016\u03b21\u20162H\u22122 + \u2016\u03b30\u20162H\u22121 + . . .+ \u2016\u03b3k\u22121\u20162H\u2212k\n)\n(2.18)\nholds for any pair of solutions (u1, u2) to (2.1).\nThe result is obtained easily by following the steps of the proof presented above in the averaged ob-\nservability setting. Assuming the contrary and implying microlocal analysis tools, one shows that both\ncomponents uni converge to 0 strongly on the observability region, thus obtaining the contradiction.\nHowever, a different approach is required in order to obtain the strong observability inequality for initial\nenergy by removing compact terms in (2.18). It is based on a standard compactness-uniqueness procedure\nof reducing the observability for low frequencies to an elliptic unique continuation result [3, 5].\nWe introduce a subspace N(T ) of H = L2(\u2126) \u00d7 H\u22121(\u2126) \u00d7 L2(\u2126) \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 H1\u2212k(\u2126), consisting of initial\ndata for which the average of solutions to (2.1) vanishes on the observability region\nN(T ) := {(\u03b20, \u03b21, \u03b30, . . . , \u03b31\u2212k) \u2208 H | \u03b81u1 + \u03b82u2 = 0 on \u30080, T \u3009 \u00d7 \u03c9}.\nBased on the relaxed observability inequality (2.18) it follows that N(T ) is a finite dimensional space.\nFurthermore, the following characterisation holds.\nLemma 2.6. We assume one of the following statements holds:\na) The order k of time derivative in (2.16) is odd. Coefficients of both the operators P1 and P2 are time\nindependent and of class C1,1,\nb) The time derivative order k is even, and Ak/21 \u2212 A2 (or \u2212(Ak/21 \u2212 A2)) is an uniformly elliptic\noperator. Coefficients of both the operators P1 and P2 are analytic.\nThen N(T ) = {0}.\nProof: One first shows that N(T ) is an A-invariant, where A is an unbounded operator on H :\nA =\n\uf8eb\n\uf8ec\uf8ec\uf8ed\n0 \u22121\nA1 0 0\n0\n0 \u2212Ik\u22121\nA2 0\n\uf8f6\n\uf8f7\uf8f7\uf8f8 , (2.19)\nwith the domain D(A) = H10(\u2126)\u00d7 L2(\u2126)\u00d7 H10(\u2126)\u00d7 \u00b7 \u00b7 \u00b7 \u00d7H2\u2212k(\u2126).\nSTABILITY OF OBSERVATIONS OF PDE-S UNDER UNCERTAIN PERTURBATIONS 9\nBeing A-invariant and finite-dimensional, it contains an eigenfunction of A. Thus there is a \u03bb \u2208 C and\n(\u03b20, \u03b21, \u03b30, . . . , \u03b31\u2212k) \u2208 N(T ) such that\nA1\u03b20 = \u2212\u03bb2\u03b20\nA2\u03b30 = (\u22121)k\u22121\u03bbk\u03b30\n\u03b21 = \u2212\u03bb\u03b20\n\u03b3j = (\u22121)j\u03bbj\u03b30, j = 1, . . . , k \u2212 1 .\n(2.20)\nBy the definition of N(T ) it follows \u03b81u1 + \u03b82u2 = 0 on \u30080, T \u3009 \u00d7 \u03c9, and specially\n\u03b81\u03b20 + \u03b82\u03b30 = 0 on \u03c9 . (2.21)\nAt this level, we want to show that each assumption of the lemma implies \u03b20 = \u03b30 = 0.\na) As Ai, i = 1, 2 are positive operators and k is odd, from (2.20) it follows that one of functions \u03b20, \u03b30 is\ntrivial. By relation (2.21) it follows that the other one also equals zero on \u03c9. Being an eigenfunction\nof an elliptic operator, the unique continuation argument (e.g. [8, Theorem 3]) implies it is zero\neverywhere.\nb) Analyticity of coefficients implies analyticity of eigenfunctions. Specially it follows \u03b81\u03b20 + \u03b82\u03b30 = 0\neverywhere, and relations (2.20) imply\n(Ak/21 \u2212A2)\u03b20 = 0.\nAssumptions on the operator Ak/21 \u2212A2 imply \u03b20 = 0 on \u2126.\n\u0003\nRemark 5. In a special case A2 = \u2212div (c2(x)\u2207) one easily proves that the last Lemma holds with analytic\ncoefficients c1, c2 being separated just on an arbitrary non-empty open set, and not on the entire \u2126.\nTheorem 2.7. Under the assumptions of Proposition 2.1 and Lemma 2.6 there is a positive constant C\u03b8\nsuch that the strong observability inequality holds:\nE1(0) + E2(0) \u2264 C\u03b8\n\u222b T\n0\n\u222b\n\u03c9\n|\u03b81u1 + \u03b82u2|2dxdt . (2.22)\nProof: As in the proof of Proposition 2.1, let us suppose the contrary. Then there exists a sequence of\nsolutions un1 , u\nn\n2 to (2.1) such that E\nn\n1 (0) = 1 and\u222b T\n0\n\u222b\n\u03c9\n|\u03b81un1 + \u03b82un2 |2dxdt \u2212\u2192 0 .\nThus for weak limits (u1, u2) of solutions on the observability region we have \u03b81u1 + \u03b82u2 = 0, implying(\nu1(0), \u2202tu1(0), u2(0), . . . ,\n(\n(\u2202t)\nk\u22121u2\n)\n(0)\n) \u2208 N(T ). By means of the above lemma and taking into account\nthe relaxed observability inequality, it follows\n1 \u2264 C\u02dc\u03b8\n(\u222b T\n0\n\u222b\n\u03c9\n|\u03b81un1 + \u03b82un2 |2dxdt + \u2016\u03b2n0 \u20162H\u22121 + \u2016\u03b2n1 \u20162H\u22122 + \u2016\u03b3n0 \u20162H\u22121 + . . .+ \u2016\u03b3nk\u22121\u20162H\u2212k\n)\n\u2212\u2192 0,\nthus obtaining a contradiction. \u0003\nWe close this subsection by the following remarks.\nRemark 6.\n\u2022 If P2 is a second order evolution operator the strong observability inequality (2.22) is equivalent to\nthe simultaneous controllability of the adjoint system, also studied in [10], by which one controls each\ncomponent individually (and not just their average).\n\u2022 The notion of simultaneous observability is stronger than the average one, as it estimates energy of\nall system components, whose initial data, in this case, are not related. Consequently, it requires\nstronger assumption of GCC being satisfied by each component.\n10 MARTIN LAZAR\n\u2022 The application of the compactness-uniqueness procedure in the passage from the weak to the strong\nobservability estimate allows the perturbation P2 to be an evolution operator with an arbitrary elliptic\npart. However, such approach is not possible in the averaged observability setting. Namely, in order\nfor subspace N(T ) to be finite dimensional one has to relate the initial data of two components by a\nbounded linear operator. But such constrain would not be preserved under action of the operator A\ngiven by (2.19), and as a consequence N(T ) would not be A-invariant.\n\u2022 The weak observability result (2.18) is easily generalised to a system with a finite number of compo-\nnents, under assumption that the characteristic sets of all operators are mutually disjoint.\n\u2022 As in the averaged observability case, the generalisation of strong estimate result (2.22) to a system\nconsisting of more than two components has still not been obtained, and is a subject of the current\ninvestigations.\n3. Observation of the Schro\u00a8dinger equation under uncertain perturbations\nIn this section we consider a system in which the first component, the one whose energy is observed,\nsatisfies the Schro\u00a8dinger equation, while the second one, corresponding to a perturbation, is governed by an\nevolution operator P2:\nP1u1 = i\u2202tu1 + div (A1(x)\u2207u1) = 0, (t,x) \u2208 R+ \u00d7 \u2126\nP2u2 = 0, (t,x) \u2208 R+ \u00d7 \u2126\nu1 = 0, (t,x) \u2208 R+ \u00d7 \u2202\u2126\nu1(0, \u00b7) = \u03b20 \u2208 L2(\u2126) .\n(3.1)\nAs in the study of perturbations of the wave dynamics in Section 2, we specify no initial or boundary\nconditions for the second operators, we just assume that corresponding problem is well posed and that it\nadmits an L2 solution. As for the system coefficients, as before we impose merely boundedness and continuous\nassumptions, and suppose that A1 is a positive definite matrix field.\n3.1. Averaged observability under non-parabolic perturbations. For the reasons explained below,\nin this subsection we restrict the analysis to evolution operators P2 of order strictly larger than one. In that\ncase the stability of the Schro\u00a8dinger observability estimate is given by the next theorem.\nTheorem 3.1. Suppose that there is a constant C\u02dc, time T and an open subdomain \u03c9 such that for any\nchoice of initial datum \u03b20 the solution u1 of (2.1) satisfies\nE1(0) := \u2016\u03b20\u20162L2 \u2264 C\u02dc\n\u222b T\n0\n\u222b\n\u03c9\n|u1|2dxdt . (3.2)\nIn addition, for the system (3.1) we assume the following:\na) The perturbation operator is an evolution operator of the form (2.5) and of the order k > 1.\nb) The initial values of solutions ui, i = 1, 2 are related by a linear operator such that whenever\n((\u03b81u1(0) + \u03b82u2(0))|\u03c9 = 0) then\n(\nu1(0)|\u03c9 = u2(0)||\u03c9 = 0\n)\n.\nThen, for any \u03b81 \u2208 \u30080, 1] there exists a constant C\u03b8 such that the observability inequality\nE1(0) \u2264 C\u03b8\n\u222b T\n0\n\u222b\n\u03c9\n|\u03b81u1 + \u03b82u2|2dxdt (3.3)\nholds for any pair of solutions (u1, u2) to (2.1).\nThe proof goes similarly as for the observations of the wave equation. Required conditions a), b) are\nnecessary for obtaining the strong observability inequality, without a compact term.\nOn the other hand, in order to obtain a relaxed inequality with a compact term, no assumption is\nrequired at all. Namely, the assumption on separation of characteristic sets {pi(t,x, \u03c4, \u03be) = 0} required\nin Proposition 2.1 becomes superfluous in this setting, as being directly satisfied by an arbitrary evolution\noperator P2 of order k strictly larger than 1. Namely, its characteristic set does not contain the poles \u03be = 0\nof the unit sphere in the dual space, which constitute the characteristic set of the Schro\u00a8dinger operator P1.\nSTABILITY OF OBSERVATIONS OF PDE-S UNDER UNCERTAIN PERTURBATIONS 11\nHowever, every Schro\u00a8dinger or the heat operator P2 fails to satisfy the assumption. Namely, no matter\nthe coefficients entering the equation, both have characteristic set within the poles \u03be = 0, same as P1, and\nlocalisation principle fail to distinguish corresponding H-measures. To analyse such a system one needs\na microlocal tool better adopted to a study of parabolic problems. Namely, original H-measures were\nconstructed with the aim of analysing hyperbolic problems and are not capable to distinguish differences\nbetween the time and space variables that are intrinsic to parabolic equations. Their variant, parabolic\nH-measures, was recently introduced with the purpose of overcoming the mentioned constraint.\n3.2. Parabolic H-measures. Parabolic H-measures were first introduced in [1], while more exhausted\nintroduction can be found in [2], elaborating in particular their basic properties: localisation and propagation\none. The former will be used in the next subsection for proving the stability of the observability estimate\nfor the Schro\u00a8dinger operator under parabolic perturbation.\nHere we expose the basic result on parabolic H-measures used in the note.\nThe main idea in their construction is to replace the projection along the straight rays in the dual space,\ndetermined by the term \u03be/|\u03be| in the definition of the original H-measures, by the one going along meridians\nof paraboloids \u03c4 = a\u03be2. The hypersurface on which the dual space (except the origin) is projected is a\nrotational ellipsoid\nP : . . . \u03c42 +\n\u03be2\n2\n= 1 .\nAlthough the ellipsoid might seem as an unnatural choice of the surface on which one want to construct\nthe parabolic H-measures, crucial in its choice was that the curves along which the projections are taken\nintersect it in the normal direction, as it was in the classical case, where the rays radiating from origin are\nperpendicular to the unit sphere. The mentioned normality property enables study of propagation properties\nof the measures.\nConcerning the applications, the most important is that the new tool is also a kind of defect measure,\nin the sense that null parabolic H-measure is equivalent to strong convergence of (vn) in L\n2\nloc(R\n1+d).\nIn order to formulate the localisation principle, we first introduce some special anisotropic (Sobolev)\nfunction spaces\nH\ns\n2\n, s(R1+d) :=\n{\nu \u2208 S \u2032 : kspu\u02c6 \u2208 L2(R1+d)\n}\n, s \u2208 R,\nwhere kp(\u03c4, \u03be) :=\n4\n\u221a\n1 + (2\u03c0\u03c4)2 + (2\u03c0|\u03be|)4 is the weight function. These are Hilbert spaces and they are\nparticular examples of more general Ho\u00a8rmander spaces Bp,k described in [9, \u00a710.1].\nWe also define the fractional derivative:\n\u221a\n\u2202t as a pseudodifferential operator with a polyhomogeneous\nsymbol\n\u221a\n2\u03c0i\u03c4 , i.e. \u221a\n\u2202tu = F\n(\u221a\n2\u03c0i\u03c4 u\u02c6(\u03c4)\n)\n.\nTheorem 3.2. (localisation principle for parabolic H-measures, [2]) Let (vn) be a sequence of func-\ntions uniformly compactly supported in t and converging weakly to zero in L2(R1+d;Cr), and let for s \u2208 N\u221a\n\u2202t\ns\n(A0vn) +\n\u2211\n|\u03b1|=s\n\u2202\u03b1x (A\n\u03b1\nvn) \u2212\u2192 0 strongly in H\u2212\ns\n2\n,\u2212s\nloc (R\n1+d) ,\nwhere A0,A\u03b1 are continuous and bounded matrix coefficients, while \u03b1 \u2208 Nd0.\nThen for the associated parabolic H-measure \u00b5 we have(\n(\n\u221a\n2\u03c0i\u03c4)sA0 +\n\u2211\n|\u03b1|=s\n(2\u03c0i\u03be)\u03b1A\u03b1\n)\n\u00b5\u22a4 = 0.\nIn particular, the principle implies that the measure \u00b5 is supported within the parabolic characteristic\nset:\ndet\n(\n(\n\u221a\n2\u03c0i\u03c4)sA0 +\n\u2211\n|\u03b1|=s\n(2\u03c0i\u03be)\u03b1A\u03b1\n)\n= 0, (\u03c4, \u03be) \u2208 P\n12 MARTIN LAZAR\nExample 2. (Application of the localisation principle to various equations)\nIn all the examples we assume that the equation coefficients satisfy the assumptions of the preceding\ntheorem, i.e are continuous and bounded.\n\u2022 The Schro\u00a8dinger equation\nLet (un) be a sequence of solutions to the Schro\u00a8dinger equation\ni\u2202tun + div (A(t,x)\u2207un) = 0.\nIf (un) is bounded in L\n2(R+ \u00d7Rd) then the associated parabolic H-measure \u00b5 satisfies\n(2\u03c0\u03c4 + 4\u03c02A(t,x)\u03be \u00b7 \u03be)\u00b5 = 0,\nimplying \u00b5 is supported in points of the form 2\u03c0\u03c4 = \u22124\u03c02A(t,x)\u03be \u00b7 \u03be.\n\u2022 The heat equation\nLet (un) be a sequence of solutions to the heat equation\n\u2202tun \u2212 div (A(t,x)\u2207un) = 0\nwhere A is a bounded, positive definite matrix field. If (un) is bounded in L\n2(R+ \u00d7Rd) then the\nassociated parabolic H-measure \u00b5 satisfies\n(2\u03c0i\u03c4 + 4\u03c02A(t,x)\u03be \u00b7 \u03be)\u00b5 = 0.\nAs (parabolic) H-measures live on a hypersurface in the dual space excluding the origin, and A is\npositive definite, the term in the braces above never equals zero, implying \u00b5 is a trivial (null) measure.\n\u2022 The wave equation\nLet (un) be a sequence of solutions to the wave equation\n\u2202ttun \u2212 div (A(t,x)\u2207un) = 0.\nIf (un) is bounded in L\n2(R+ \u00d7Rd) then the associated parabolic H-measure \u00b5 satisfies\n4\u03c02\u03c42\u00b5 = 0,\nimplying \u00b5 is supported in the equator \u03c4 = 0 of the hypersurface P.\nFrom the given examples it is clear that by taking two Schro\u00a8dinger operators with separated coefficients\nwe shall be able to distinguish corresponding parabolic H-measures. Of course, the distinction is also possible\nif the considered operators are of different type (e.g. the Schro\u00a8dinger and the wave one), as it was the case with\nthe original H-measures. This enables the generalisation of Theorem 3.1 represented in the next subsection.\n3.3. Averaged observability under parabolic perturbations. We reconsider the system (3.1) with the\naim of obtaining the stability of the observability estimate for the Schro\u00a8dinger operator under perturbation\ndetermined by the operator P2 under minimal conditions on the latter. In particular, we want allow it to be\nthe Schro\u00a8dinger, or some other parabolic type operator, like P1.\nThe results of previous subsection, in particular the localisation property (Theorem 3.2) provide the\nfollowing result.\nTheorem 3.3. In addition to assumptions of Theorem 3.1 we allow P2 to be an evolution operator of order\none, and assume the separation of coefficients c2(x) 6= \u2212i holds on \u03c9 in the case k = 1.\nThen for any \u03b81 \u2208 \u30080, 1] there exists a constant C\u03b8 such that the strong observability inequality\nE1(0) \u2264 C\u03b8\n\u222b T\n0\n\u222b\n\u03c9\n|\u03b81u1 + \u03b82u2|2dxdt (3.4)\nholds for any pair of solutions (u1, u2) to (3.1).\nThe proof goes along the same lines as the one of the Theorem 2.2, using that the parabolic H-measures\nshare the basic properties (positive definiteness, diagonal domination) with their original (hyperbolic) coun-\nterparts. Crucial in the proof is separation of corresponding parabolic characteristic sets. For an evolu-\ntion operator P2 of order k \u2265 2 that set is restricted to the equator \u03c4 = 0 of the hypersurface P, where\np1 = 2\u03c0\u03c4 + 4\u03c0\n2A(t,x)\u03be \u00b7 \u03be differs from zero (cf. Example 2). For k = 1 the separation follows by the\nassumption c2(x) 6= \u2212i.\nSTABILITY OF OBSERVATIONS OF PDE-S UNDER UNCERTAIN PERTURBATIONS 13\nThe novelty obtained by the application of parabolic measures is that both the operators entering the\nsystem (3.1) are allowed to be of the same type (e.g. two Schro\u00a8dinger operators with coefficients being\nseparated on the observability region \u30080, T \u3009 \u00d7 \u03c9). In that case the observability estimate (3.4) is equivalent\nto the averaged control of the adjoint system.\nOf course, operators of different types are admissible as well, thus the last theorem incorporates the\nresults of Subsection 3.1 as well.\nFinally, let us mention that as in Section 2 one can obtain analogous result for the robust observability\nof the Schro\u00a8dinger equation in the simultaneous and infinite discrete setting.\n4. Conclusion\nOne of the most interesting aspects of the above results refers to a system determined by two operators\nof a same type - either the Schro\u00a8dinger or the wave one. The weak observability estimates in that case\ncorrespond to the average control of solutions to adjoint system up to a finite number of low frequencies. The\nrequired assumptions are optimised: the coefficients are merely continuous and separated on the observability\nregion. The strong averaged observability result, corresponding to the exact averaged controllability, assumes\nin addition initial data of two components to be related in an appropriate manner. Its proof, unlike in\n[10], employs neither propagation property of H-measures nor unique continuation procedure, therefore not\nrequiring additional smoothness assumptions.\nThe paper restricts to decoupled systems, but one could analyse more general ones with coupling in\nlower order terms (e.g. [12]). Such terms do not effect microlocal properties of solutions, thus enabling a\ngeneralisation of the obtained estimates.\nSurely of interest would be a generalisation of the results to a parameter dependent system with a para-\nmeter ranging over a continuous set. A problem has been analysed in [13], exploring the heat and Schro\u00a8dinger\nequations with a randomly distributed parameter. The constant coefficients operators are considered, with\neigenfunctions of corresponding elliptic parts being independent of the parameter value. Thus the explored\naverages are presented as a solution (or a superposition of two solutions) to a similar evolution problem(s),\nwhich is crucial in the proof.\nAs the next step in that direction, one would consider a system of equations determined by evolution\noperators whose elliptic parts coincide up to a scalar function:\nP (\u03bd) = \u2202kt + c(x, \u03bd)A ,\nwith \u03bd being a parameter, and A the elliptic part of P . The variable dependence of the coefficient c would\nrequire another techniques from those applied in [13]. In this paper we have obtained a corresponding result\nfor a parameter ranging over an infinite discrete set, but only at the level of a weak observability estimate\nwith compact terms.\nBy using transmutation techniques developed in [6], the simultaneous observability result of subsection\n2.3 can be employed in order to obtain controllability and observability properties for a system of heat\nequations (cf. [10]). Similar transmutation procedure can be constructed, transferring Schro\u00a8dinger into wave\ntype problems, and vice versa. Its application will result in observability estimates for a system of Schro\u00a8dinger\nequations, derived from the corresponding results for the wave ones. It would be interesting to compare such\nobtained results with those obtained directly in Section 3 by means of parabolic H-measures, and to compare\nthe efficiency of methods applied by each approach.\nAcknowledgements\nThe paper is supported in part by Croatian Science Foundation under the project 9780. The author\nacknowledges E. Zuazua for inspiring and fruitful discussions on the subject.\nReferences\n[1] N.Antonic\u00b4 and M.Lazar: H-measures and variants applied to parabolic equations. J. Math. Anal. Appl. 343(1) (2008)\n207\u2013225.\n[2] N.Antonic\u00b4 and M.Lazar: Parabolic H-measures. J. Funct. Anal. 265(7) (2013) 1190\u20131239.\n14 MARTIN LAZAR\n[3] C.Bardos, G. Lebeau and J.Rauch, Sharp sufficient conditions for the observation, control, and stabilization of waves\nfrom the boundary. SIAM J. Control Optim. 30(5) (1992) 1024\u20131065.\n[4] N.Burq and P.Ge\u00b4rard, Condition ne\u00b4cessaire et suffisante pour la contro\u02c6labilite\u00b4 exacte des ondes. C. R. Acad. Sci. Paris\nSe\u00b4r. I Math. 325(7) (1997) 749\u2013752.\n[5] B.Dehman, M.Le\u00b4autaud and J. Le Rousseau, Controllability of two coupled wave equations on a compact manifold.\nArch. Rational Mech. Anal. 211(1) (2014) 113\u2013187.\n[6] S.Ervedoza and E. Zuazua, Sharp observability estimates for heat equations. Arch. Rational Mech. Anal. 202(3) (2011)\n975\u20131017.\n[7] P.Ge\u00b4rard, Microlocal Defect Measures. Comm. Partial Differential Equations 16(11) (1991) 1761\u20131794.\n[8] L.Ho\u00a8rmander, On the uniqueness of the Cauchy problem. II. Math. Scand. 7 (1959) 177\u2013190.\n[9] L.Ho\u00a8rmander, The Analysis of Linear Partial Differential Operators I-IV, Springer, 1990\n[10] M.Lazar and E. Zuazua, Averaged control and observation of parameter-depending wave equations. C. R. Acad. Sci.\nParis, Ser. I 352(6) (2014) 497\u2013502.\n[11] G.Lebeau, J. Le Rousseau, P.Terpolilli and E.Tre\u00b4lat, Some new results for the controllability of waves equations,\npresented on Workshop New trends in modeling, control and inverse problems, Institut de Mathmatiques de Toulouse,\nJune 16 - 19, 2014. http://www.math.univ-toulouse.fr/\u223cervedoza/WebpageCIMI-Enrique/Slides/slides-lebeau.pdf\n[12] T. Li, B. Rao and L.Hu, Exact boundary synchronization for a coupled system of 1-D wave equations. ESAIM: COCV\n20 (2014) 339\u2013361.\n[13] Q. Lu\u00a8 and E. Zuazua, Averaged controllability for random evolution partial differential equations, submitted.\n[14] L.Tartar, H-measures, a new approach for studying homogenisation, oscillation and concentration effects in PDEs. Proc.\nRoy. Soc. Edinburgh. Sect. A 115(3-4) (1990) 193\u2013230.\n[15] E. Zuazua, Averaged Control. Automatica 50(12) (2014) 3077\u20133087.\n[16] E. Zuazua, Robust observation of Partial Differential Equations, preprint (2014).\nMartin Lazar, University of Dubrovnik, Department of Electrical Engineering and Computing, C\u00b4ira Caric\u00b4a\n4, 20 000 Dubrovnik, Croatia, phone: ++385 20 445842, fax: ++385 20 435590\nE-mail address: martin.lazar@unidu.hr\nURL: http://www.martin-lazar.from.hr\n",
        "id": 18043054,
        "identifiers": [
          {
            "identifier": "oai:arxiv.org:1502.00663",
            "type": "OAI_ID"
          },
          {
            "identifier": "1502.00663",
            "type": "ARXIV_ID"
          },
          {
            "identifier": "29507560",
            "type": "CORE_ID"
          }
        ],
        "title": "Stability of Observations of Partial Differential Equations under\n  Uncertain Perturbations",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:arxiv.org:1502.00663"
        ],
        "publishedDate": "2015-01-30T00:00:00",
        "publisher": "",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://arxiv.org/abs/1502.00663"
        ],
        "updatedDate": "2020-12-24T13:40:23",
        "yearPublished": 2015,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "http://arxiv.org/abs/1502.00663"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/18043054"
          }
        ]
      },
      "relevance_score": 0.0215,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.215,
          "dimension_weight": 0.1,
          "weighted_score": 0.0215,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2015 (Norm. Score: 0.2)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_tertiary_8",
      "dynamic_step": 0,
      "core_id": 18043054,
      "doi": null
    },
    {
      "original_data": {
        "acceptedDate": "",
        "arxivId": null,
        "authors": [
          {
            "name": "Antonczyk D."
          },
          {
            "name": "Autor D. H."
          },
          {
            "name": "Lancaster T."
          },
          {
            "name": "Tiemann M."
          }
        ],
        "citationCount": 0,
        "contributors": [
          "Ronald"
        ],
        "outputs": [
          "https://api.core.ac.uk/v3/outputs/158816810",
          "https://api.core.ac.uk/v3/outputs/322823609",
          "https://api.core.ac.uk/v3/outputs/158817285",
          "https://api.core.ac.uk/v3/outputs/478676804",
          "https://api.core.ac.uk/v3/outputs/160465088",
          "https://api.core.ac.uk/v3/outputs/411976594",
          "https://api.core.ac.uk/v3/outputs/187250091"
        ],
        "createdDate": "2018-06-18T21:22:26",
        "dataProviders": [
          {
            "id": 4786,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/4786",
            "logo": "https://api.core.ac.uk/data-providers/4786/logo"
          },
          {
            "id": 213,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/213",
            "logo": "https://api.core.ac.uk/data-providers/213/logo"
          },
          {
            "id": 984,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/984",
            "logo": "https://api.core.ac.uk/data-providers/984/logo"
          },
          {
            "id": 715,
            "name": "",
            "url": "https://api.core.ac.uk/v3/data-providers/715",
            "logo": "https://api.core.ac.uk/data-providers/715/logo"
          }
        ],
        "depositedDate": "",
        "abstract": "The past four decades have witnessed dramatic changes in the structure of employment. In particular, the rapid increase in computational power has led to large-scale reductions in employment in jobs that can be described as intensive in routine tasks. These jobs have been shown to be concentrated in middle skill occupations. A large literature on labour market polarisation characterises and measures these processes at an aggregate level. How- ever to date there is little information regarding the individual worker adjustment processes related to routine- biased technological change. Using an administrative panel data set for Germany, we follow workers over an ex- tended period of time and provide evidence of both the short-term adjustment process and medium-run effects of routine task intensive job loss at an individual level. We initially demonstrate a marked, and steady, shift in em- ployment away from routine, middle-skill, occupations. In subsequent analysis, we demonstrate how exposure to jobs with higher routine task content is associated with a reduced likelihood of being in employment in both the short term (after one year) and medium term (five years). This employment penalty to routineness of work has increased over the past four decades. More generally, we demonstrate that routine task work is associated with reduced job stability and more likelihood of experiencing periods of unemployment. However, these negative ef- fects of routine work appear to be concentrated in increased employment to employment, and employment to unemployment transitions rather than longer periods of unemployment",
        "documentType": "research",
        "doi": "10.1111/bjir.12419",
        "downloadUrl": "https://core.ac.uk/download/322823609.pdf",
        "fieldOfStudy": null,
        "fullText": "  Long-run Patterns of Labour  Market Polarisation  Evidence from German Micro Data  RWI \u2013 Leibniz-Institut f\u00fcr Wirtschaftsforschung     Long-run Patterns of Labour  Market Polarisation  Evidence from German Micro Data  RWI \u2013 Leibniz-Institut f\u00fcr Wirtschaftsforschung      Contact  Dr. Daniel Schraad-Tischler Senior Expert Program Shaping Sustainable Economies Bertelsmann Stiftung Phone  +49 5241 81-81240 Mobile  +49 172 2631499 Fax  +49 5241 81-681240 daniel.schraad-tischler@bertelsmann-stiftung.de www.bertelsmann-stiftung.de    Cover Picture: Shutterstock/zhu difeng Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 3  Authors Ronald Bachmann (RWI \u2013 Leibniz-Institut f\u00fcr Wirtschaftsforschung, DICE / Heinrich-Heine-Universit\u00e4t D\u00fcsseldorf und IZA)  RWI, Hohenzollernstr. 1-3, 45128 Essen, Germany. E-mail: bachmann@rwi-essen.de. Merve Cim (RWI and RGS)   RWI, Hohenzollernstr. 1-3, 45128 Essen, Germany. E-mail: cim@rwi-essen.de. Colin Green (Norwegian University of Science and Technology)  Department of Economics, Norwegian University of Science and Technology, Dragvoll, N-7491 Trondheim, Norway, e-mail: Colin.Green@ntnu.no.  We thank Peggy Bechara, Britta Matthes, Joscha Schwarzw\u00e4lder (Bertelsmann Foundation) and participants at the 2018 AEA meetings, the 2016 IWAEE conference, and the 2016 Scottish Economic Society meetings as well as seminars at IAB, RWI, and the University of Dusseldorf  for helpful comments and suggestions, and Anja R\u00f6s-ner and Jan Wergula for excellent research assistance. We also gratefully acknowledge financial support from the Bertelsmann Foundation.   Page 4 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Contents 1 Abstract ............................................................................................................ 5 2 Introduction ...................................................................................................... 6 3 Data ................................................................................................................... 8 3.1 Worker-level data ........................................................................................................................ 8 3.2 Measuring routine intensity and related worker flows ................................................................. 9 4 Methodology .................................................................................................. 11 4.1 Descriptive Evidence .................................................................................................................11 4.2 Econometric Analysis ................................................................................................................11 5 Results ............................................................................................................ 14 5.1 The Evolution of Task Shares and Intensities 1979 to 2013 .....................................................14 5.2 Descriptive Evidence on the Links between Tasks and Employment Transitions. ...................18 5.3 Labour market histories over the short and medium run ...........................................................23 5.4 Task-specific job stability and unemployment exit rates ...........................................................25 5.5 RTI Wage Penalties ...................................................................................................................27 6 Conclusion ..................................................................................................... 29 7 References ..................................................................................................... 30 8 APPENDIX ...................................................................................................... 32    Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 5  1 Abstract The past four decades have witnessed dramatic changes in the structure of employment. In particular, the rapid increase in computational power has led to large-scale reductions in employment in jobs that can be described as intensive in routine tasks. These jobs have been shown to be concentrated in middle skill occupations. A large literature on labour market polarisation characterises and measures these processes at an aggregate level. How-ever to date there is little information regarding the individual worker adjustment processes related to routine-biased technological change. Using an administrative panel data set for Germany, we follow workers over an ex-tended period of time and provide evidence of both the short-term adjustment process and medium-run effects of routine task intensive job loss at an individual level. We initially demonstrate a marked, and steady, shift in em-ployment away from routine, middle-skill, occupations. In subsequent analysis, we demonstrate how exposure to jobs with higher routine task content is associated with a reduced likelihood of being in employment in both the short term (after one year) and medium term (five years). This employment penalty to routineness of work has increased over the past four decades. More generally, we demonstrate that routine task work is associated with reduced job stability and more likelihood of experiencing periods of unemployment. However, these negative ef-fects of routine work appear to be concentrated in increased employment to employment, and employment to unemployment transitions rather than longer periods of unemployment.  JEL codes: J23, J24, J62, E24  Keywords: polarization, occupational mobility, worker flows, tasks.  Page 6 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  2 Introduction The past four decades have seen dramatic changes in the structure of employment. As documented by Autor et al. (1998), the US witnessed a large reduction in the employment of middle skill workers. At the same time, there have been increases in the employment of high skill, and to some extent, low skill workers. This pattern of em-ployment polarisation has also been demonstrated for the UK by Goos/Manning (2007) and across Europe by Goos et al. (2009), and is likely to continue in the future (Autor 2015). These changes have been ascribed to the fact that these middle skill jobs involved tasks that were intensively routine in nature. As a result, they were most readily substituted with capital as computer technology became cheaper (Autor et al. 2003). This same technology is factor augmenting to high skilled workers which in turn leads to a growth of complementary, high skill, non-routine intensive jobs. Along these lines, Autor et al. (1998) demon-strate that increased employment of high-skill labour largely occurred within computer intensive industries. The growth in low-skill employment that has occurred has also been concentrated in jobs that are not routine intensive (e.g. personal services). One argument is that this reflects a compositional change in consumption due to the in-crease in high skill workers (Mazzolari, Ragusa 2013). This literature provides a compelling view of the impact of structural change on the labour market over the past four decades. With this said, the existing empirical evidence largely takes the form of comparisons of decade upon decade employment numbers and shares at aggregated levels of occupational detail. Until relatively re-cently, the dynamics of employment transitions implicit in the process of polarisation have been inferred from comparisons of these cross-sectional changes. An almost wholly US literature has developed that uses micro data to examine the contribution of different flows to the evolution of employment polarisation. For instance, both Jaimovich/Siu (2012) and Smith (2013) highlight the decline in inflows to routine work particularly from unemploy-ment. The latter paper in addition provides some evidence of increases in inflows into high and low skilled employment, and more generally that overall job finding rates into non-routine jobs have been rising. Along simi-lar lines, Cortes et al. (2014) examine which specific labour market flows can account for rising job market polarization. They find that the disappearance of routine jobs is mainly due to falling worker flows from both un-employment and non-participation to routine employment, and to rising worker flows from routine employment to non-participation. For Germany, Bechara (2017) finds that the employment contraction in routine occupations is largely attributable to young workers and women who increasingly leave routine-intensive jobs and subsequently enter other occupations or into non-participation.1 In practice, little is known regarding the actual process of job-loss and reemployment at the individual worker level, particularly the nature of individual worker transitions that result from the reduction in demand for routine intensive work. This seems an important gap in our knowledge as any potential losses due to this pattern of struc-tural change is likely to be most concentrated among routine workers. An exception is the recent paper by Cortes (2016) who uses the Panel Studies of Income Dynamics (PSID) to look at long-run effects of labour-market polari-zation in the US. He finds evidence of selection on ability for workers switching out of routine jobs. In particular, while low-ability routine workers are more likely to switch to non-routine manual jobs, high-ability routine workers are more likely to switch to non-routine cognitive jobs. With respect to wages, his results suggest that workers staying in routine jobs experience less wage growth than workers staying in any other type of occupation. This is characterised by a reduction in the wage premium for routine occupations of 17% between 1972 and the mid-2000s. Furthermore, Cortes et al. (2014) use CPS data to analyse what role labour market flows play for the dis-appearance of routine jobs in the US since the 1980s. This paper uses administrative data for Germany to characterise the individual level patterns underlying the pro-cess of labour market polarization. Our data is particularly well suited to addressing these issues as it allows us to                                                      1 In contrast to our paper, Bechara (2017) focuses on occupational inflow and outflow rates at the 2-digit level as well as differences between men and women in this context. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 7  follow individuals across a long span of time. Specifically we can examine individual level transitions but also how these have changed over the past four decades. In doing so we provide evidence on the secular pattern of polari-sation over a long time period at a high frequency of observation. As a result, we can characterise the evolution of polarisation over time. In addition, we provide evidence on a range of individual level job transitions. Initially, we provide a range of descriptive evidence on the relative job stability, unemployment experiences and job-to-job transitions for routine task intensive workers. We then move to multivariate analysis in an attempt to assess the role of compositional effects. Finally, we provide suggestive evidence on welfare losses, in terms of unemploy-ment duration and job instability related to employment polarisation. The contribution of our paper to the existing literature on routinisation is therefore twofold. First, we are, to the best of our knowledge, the first to provide encompassing micro evidence on the long-run effects of labour-market polarization for a European country, thus complementing the evidence provided by Cortes (2016) and Cortes et al. (2014) for the US. Second, our analysis goes beyond the existing literature by providing detailed evidence on the nature of the labour market experiences of routine workers, also taking into account occupation-specific measures of task intensity that vary over time. This type of analysis is only possible with the type of panel data at our disposal, which we complement with survey information on occupational task content, i.e. routine intensity. The paper is structured as follows. In the next section, we provide information on the data used including the ad-ministrative data set as well as the data on the task intensity of different occupations. The third section presents the empirical methodology, while the fourth section reports and discusses the results, and the final section sum-marizes and concludes the discussion. Page 8 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  3 Data 3.1 Worker-level data Our main data source is the Sample of Integrated Labour Market Biographies (SIAB) for 1975-2014, which is pro-vided by the Institute for Employment Research (IAB). The SIAB is a representative 2% random sample of the Integrated Employment Biographies (IEB) which contains the labour market history of all individuals in Germany that are employed subject to social security contributions, those in part-time employment not earning enough to make social security contributions, those receiving unemployment or social benefits, and those officially regis-tered as job-seeking at the German Federal Employment Agency or participating in programs of active labour market policies. Civil servants and self-employed workers are not included in the data.2 The information on labour market states is exact to the day. A detailed description of the Sample of Integrated Labour Market Biographies is provided in vom Berge et al. (2013). The SIAB provides information on workers\u2019 employment status, age, gender, occupation and education as well as limited information on establishment characteristics (economic sector, establishment size). This data set is repre-sentative for all dependent-status workers, and contains information on all employment and unemployment spells of the workers covered. From this sample, we further exclude, apprentices, trainees, homeworkers, and individu-als older than 65.3 In line with previous research we focus on male full-time workers aged 18-65. As our period (1975-2014) covers the pre-unification period, we focus on West Germany only. The data allows us to characterise individuals as being in one of three labour market states at any point in time: employment covered by social security (E), unemployment with benefit receipt (U), and non-participation (N). Non-participants are those individuals not recorded in the data sets. Therefore, this state includes those workers out of the labour market, as well as workers not covered by social security legislation, e.g. civil servants and self-employed workers. Because of the way the data are collected, both establishments\u2019 reports of a new employee and individuals\u2019 notifi-cations of moving into or out of unemployment may not be exactly consistent with the actual change of labour market state. For example, workers might report to the unemployment office only a few days after they are laid off. We take this potential measurement error into account in the following way: If the time lag between two em-ployment spells at different establishments does not exceed 30 days, this is defined as a direct transition between the two states recorded. We count it as an intervening spell of non-employment if the time interval between the two records is larger than 30 days. Since the data set used contains daily information on the employment and unemployment history of every individ-ual in the sample, it is possible to calculate worker flows taking into account every change of labour market state that occurs to an individual within a given time period. We are thus able to compute the flows between employ-ment and non-employment, as well as direct job-to-job transitions (EE flows) using the establishment identification number.                                                      2 Caliendo/Uhlendorff (2008) find that only 3% of all non-employed workers and only 1% of all wage-employed workers  in Germany enter the state of self-employment annually, implying that transitions into and out of this state only play a minor role for our analyses. 3 Excluding part-time workers from our sample and treating them as non-participants artificially increases our transitions into and out of non-participation. However, as the SIAB data only distinguish between two categories of part-time employment and the number of working hours can be relatively low, we decided to focus on core full-time workers. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 9  3.2 Measuring routine intensity and related worker flows The analysis of the employment consequences of routinisation requires the classification of employment into oc-cupations according to task types. In the literature there exist two broad approaches to this. The first is a parsimonious approach as per Goos/Manning (2007), Goos et al. (2009) and Cortes (2016) whereby workers are assigned to routine, non-routine manual and non-routine cognitive categories based on groups of standardised occupational codes. A chief virtue of this approach is that it does not require the measurement of task content at an occupational level, while using relatively aggregated occupational information makes this approach more ro-bust to periodic reclassifications of disaggregated occupational classifications. This comes at the potential cost of the introduction of measurement error due both to within-occupational variation in task intensity, and changes in occupational task intensity over time. The second approach, as in Autor et al. (2003), relies on occupational task analysis from additional sources to classify jobs in terms of task intensity. In the US context this comes from the Dictionary of Occupation Titles (DOT) (and later O*NET) information on the task composition of occupations. This information is generated from periodic expert evaluations of job task content. This approach more clearly mitigates some of the issues of meas-urement error inherent in the first approach. However, the relative infrequency of DOT still leads to likely variation between the defined task content of an occupation and what tasks any given worker\u2019s job is likely to actually con-sist of as one moves further away from the DOT date. One of the aims of the O*NET replacement was to limit this information lag by providing more frequent job task information. In the German context, the main approaches used in the literature to date can be viewed as alternatives of this DOT approach where, instead of expert evaluations, survey-based information on task content is used. This re-flects the availability of data from BIBB/IAB and BIBB/BAuA Employment Surveys (herein BIBB data) that provide a representative sample of workers and include questions regarding the task content of jobs.4 In previous work, three different task intensity measures have been generated using this data. Spitz-Oener (2006) and Antonczyk et al (2009) generate different measures of relative task intensity at occupation levels using worker self-reports on the task content of their work. While Baumgarten (2015) computes an alternative measure of routinisation focus-ing on the use of tools on the job.  We follow the approach of Antonczyk et al (2009) and categorize the activities employees perform at the work-place into routine (R), non-routine cognitive (NRC) and non-routine manual tasks (NRM). This is computed for 54 occupational categories following Tiemann et al. (2008), and for each occupation-time period combination pro-vides a R, NRC and NRM share that sums to 100%. This measure can be expressed as:  TIijt= \ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f \ud835\udc5c\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc52\ud835\udc60 \ud835\udc56\ud835\udc5b \ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc54\ud835\udc5c\ud835\udc5f\ud835\udc66 \ud835\udc57 \ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc53\ud835\udc5c\ud835\udc5f\ud835\udc5a\ud835\udc52\ud835\udc51 \ud835\udc4f\ud835\udc66 \ud835\udc56 \ud835\udc56\ud835\udc5b \ud835\udc50\ud835\udc5f\ud835\udc5c\ud835\udc60\ud835\udc60 \ud835\udc60\ud835\udc52\ud835\udc50\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b \ud835\udc61\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59 \ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f \ud835\udc5c\ud835\udc53 \ud835\udc4e\ud835\udc50\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc56\ud835\udc61\ud835\udc56\ud835\udc52\ud835\udc60 \ud835\udc5d\ud835\udc52\ud835\udc5f\ud835\udc53\ud835\udc5c\ud835\udc5f\ud835\udc5a\ud835\udc52\ud835\udc51 \ud835\udc4f\ud835\udc66 \ud835\udc56 \ud835\udc5c\ud835\udc63\ud835\udc52\ud835\udc5f \ud835\udc4e\ud835\udc59\ud835\udc59 \ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc52\ud835\udc54\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc52\ud835\udc60 \ud835\udc4e\ud835\udc61 \ud835\udc61\ud835\udc56\ud835\udc5a\ud835\udc52 \ud835\udc61  (1) As an example, for routine tasks, this implies taking the number of routine tasks performed by a person at a spe-cific point in time, and relating this to the total number of activities performed in all task categories (routine, non-routine manual and non-routine cognitive). Taking the averages of individual task intensities provides a continu-ous measure of Routine Task Intensity (RTI) over time for a given occupational group.5 A key advantage of this data is that the survey is conducted at regular six to seven year intervals throughout our period of analysis (1979, 1985/86, 1991/92, 1998/99, 2006 and 2012). This allows us to have time-varying task intensity by occupational groups. As mentioned above, earlier literature has tried to explain the long-term relative decline of different task intensities, while other research has focused on quite short periods. In both cases this leads naturally to an approach where occupation task intensity is fixed at an initial or pre-sample period. A focus                                                      4 Details about how we deal with the different waves of the task data set are spelt out in the appendix. 5 In unreported estimates we use the alternative approach set out by Spitz-Oener (2006). The nature of our re-sults are largely unaffected by this. Page 10 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  of our paper is how worker outcomes at a particular time period are influenced by exposure to different task mixes. Hence, it seems inappropriate to, for instance, examine outcomes of workers in the 1990s based on the task intensity of their occupation fixed at 1979 values. Our main approach is to use the BIBB data to update occu-pation task intensities over time. This has the advantage that worker outcomes are evaluated more closely to their actual task composition at the time of observation. A cost of this approach is that, when compared to using initial task values only, there is the potential of marked discontinuities in the task intensity shares at BIBB survey dates. These are not large in practice in terms of contin-uous measures of task intensity. However, any analysis that, like previous work, is based on categorising workers into different, discrete task intensity groups (e.g. R, NRM and NRC) faces a naturally greater probability of discon-tinuities at BIBB survey dates in the proportion of occupations (and hence workers) belonging to any given task group. We use a number of approaches to dealing with this issue, but stress that none of these choices \u2018drive\u2019 our results. Initially we provide descriptive evidence that aims at being comparable with longer, but \u2018snapshot\u2019 based, evidence for the US, UK and elsewhere. In doing so, we adopt a similar approach to this particular strand of the literature and fix occupations into three categories at the start of the data. These categories are: i. Routine (R): Administrative support, operatives, maintenance and repair occupations, production and transportation occupations (among others). ii. Non-Routine Cognitive (NRC):  Professional, technical, management, business and financial occupa-tions. iii. Non-Routine Manual (NRM): Service workers. Our next step is to try to examine the evolution of worker outcomes over the periods, focusing on two sets of complementary outcomes. First, we seek to provide results on the effect of RTI on the employment probabilities of workers over the short run (one year) and long run (five years). Note that this means that our analyses using the RTI measure start in 1979, whereas the analyses using the three task groups start in 1975; furthermore, the analyses following individual workers for 5 years stop in 2008 in order to avoid the problem of right-censoring. We then subsequently extend this to duration modelling of the effect of RTI on labour market transitions more broadly. In both of these cases, we use RTI as a continuous measure. We deal with the issue of revisions of oc-cupational task shares across BIBB waves by splitting our data into a number of BIBB-Survey data specific periods (e.g. 1979-1984; 1985-1991; 1992-1998; 1999-2005; 2006-2011 and 2012 to present). This allows us to provide evidence on how the effect of task intensity on worker outcomes has changed over the past 3 decades. We again stress, however, that the main thrust of our findings are not materially affected by alternative ap-proaches such as pooling our data across the whole survey period.  Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 11  4 Methodology 4.1 Descriptive Evidence We first provide descriptive evidence that aims to paint a picture of the labour market situation of workers accord-ing to the task content of their work. Specifically, we provide univariate descriptive statistics on the evolution of task-specific employment shares and unemployment rates, and transition rates between different labour market states and task categories. We exploit a particular strength of our data and examine how these patterns have changed over a long period. In the first step of our descriptive analysis, we provide evidence on employment stocks for the three task catego-ries. To aid comparability over time we adopt a variant of the classification approach used by Cortes (2015) and group occupations into task categories that are fixed across time (see Appendix tables A1 to A3). This has the additional benefit of allowing us to more readily compare changes in occupational/task structure in Germany to existing evidence for the US and elsewhere. We then turn to the BIBB data to provide evidence where, as de-scribed above, we allow the task shares of given occupations to vary reflecting underlying changes in job content over time. The distribution of each task type for each wave is provided using the occupation-level employment shares from the BIBB survey data. Finally, we take the occupational level task measures generated from the BIBB data to the SIAB data. This allows the task shares of employment to vary in between BIBB waves according to annual changes in occupational employment. This, in theory, allows for any cyclical variations in task shares to be apparent. In practice, all three approaches provide an estimate of the share of tasks in the labour market at a point in time. As we discuss in the results, these are not always entirely congruent, but provide similar views on the change in task shares over the entire period.  We then proceed from this to examine worker transitions between labour market states, again paying particular attention to the three task groups. In order to do so, we first display a transition matrix between workers employed in the different task groups and unemployed workers who were previously employed in these three task groups. This provides evidence on the probability of a switch between task groups, both directly (job-to-job) and indirectly (through unemployment). Next, we compute the probability of job exit by task group over time. This yields a measure of job stability for routine, non-routine manual and non-routine cognitive workers. We then examine where workers who have separated from their previous job, and who make a direct job-to-job transition, end up in terms of task category. In a similar vein, we provide evidence on unemployed workers according to the task affili-ation in their previous job. We thus show the evolution of the unemployment exit rates by task type over time, as well as the destination task groups where workers end up. 4.2 Econometric Analysis  With this as initial information, we then examine how the employment probabilities of workers with a given RTI evolve over the short (one year) and medium (five years) term. In order to investigate the determinants of these employment probabilities, we estimate logit models of the form  \ud835\udc43\ud835\udc5f[\ud835\udc66\ud835\udc56\ud835\udc61 = 1|\ud835\udc65\ud835\udc56\ud835\udc61 , \ud835\udefd, \ud835\udefc, \ud835\udefe] = \u039b(\ud835\udefc\ud835\udc56 + \ud835\udc45\ud835\udc47\ud835\udc3c\ud835\udc56\ud835\udc61\ud835\udefd + \ud835\udc65\ud835\udc56\ud835\udc61\ud835\udefe)  (2) where \u039b(.) is the logistic cdf with \u03bb(z) = ez/(1 + ez). Xit is a vector of individual- and job-specific variables including age, skill level, economic sector, firm size, region (Bundesland) fixed effects, month dummies, as well as the re-gional unemployment rate. To avoid issues regarding discontinuous changes in RTI due to changes in BIBB based classifications we stack observations from each BIBB year (1979, 1985, 1992, 1999, 2006, 2012). As a Page 12 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  result, RTI is the routine task intensity of ith individuals job at time t described in equation (1) above. \u03b2 is the coef-ficient of interest and provides the conditional (average) effect of RTI on an individual\u2019s future employment probability. We include BIBB wave dummies in all models. In the empirical results we extend (2) in a number of ways. One main extension relates to time variation and non-linearities in task effects. Estimates of \u03b2 provide the average effect of RTI on employment outcomes of workers across our period of observation. A main interest is in how this has changed over time. To examine this we first interact RTI with a time trend. This provides an estimate of changes in the employment effect of RTI over time. We subsequently include industrial sector \u2013 time interactions to isolate this RTI-time effect separately from sector \u2013 year specific shocks to employment.  Any differential patterns in employment by task group that are revealed reflect a range of underlying types of la-bour market transitions, including those related to job loss and re-employment patterns. To examine this we again provide descriptive evidence related to job loss rates and re-employment rates by task group. This is provided overall and by decade, and with a focus on the extent to which re-employment occurs within the same task type or via transitions to alternative types. This is important as it provides evidence of where routine job workers go after job loss. Do they experience lower re-employment probabilities (and hence are more likely to experience longer unemployment durations)? Examining this again leads directly into multivariate analysis. The most appropriate approach is to estimate mod-els that recognise the underlying duration nature of the data. This leads to the estimation of hazard rate models. As our dataset contains daily information on individual workers\u2019 employment histories, we use a semi-parametric specification in continuous time, i.e. a piecewise-constant exponential (PCE) model. As the PCE model is a pro-portional hazard model, the conditional hazard rate of leaving employment \u03bb(t|X,RTI) satisfies the separability condition:  \ud835\udf06(\ud835\udc61|\ud835\udc65\ud835\udc56\ud835\udc61 , \ud835\udc45\ud835\udc47\ud835\udc3c\ud835\udc56\ud835\udc61) = \ud835\udf060(\ud835\udc61)exp (\ud835\udefe\ud835\udc65\ud835\udc56\ud835\udc61 + \ud835\udefd\ud835\udc45\ud835\udc47\ud835\udc3c\ud835\udc56\ud835\udc61) (3) where X is a vector of individual, potentially time-varying, characteristics, and \u03bb0 denotes the baseline hazard. Again, RTI measures the task intensity of the ith worker\u2019s job and \u03b2 is the parameter of interest. The PCE model assumes that the baseline hazard is constant within a specified time interval, and thus follows a step function with k segments.  \u03bb0(t) = \u03bbj, aj\u22121 \u2264 t < aj, j = 1, ..., k. (4) We specify six such segments: 0 to 30 days of employment duration, 31 to 182 days, 183 to 365 days, 366 to 1095 days, 1096 to 2920 days, and more than 2920 days. We estimate (3) separately for job to job, job to unem-ployment transitions, and unemployment to job transitions. The first set of estimates provides an estimate of the impact of RTI on overall job stability. The second relates to the potentially most negative outcome, job loss coinci-dent with unemployment. While the last provides estimates of the effect of RTI on ongoing difficulties in re-entering employment. An issue with this last set of estimates is how to define an unemployed individual\u2019s RTI. Our approach is to use the RTI of their last employment spell. This has the added effect that we can only estimate these models for unemployed individuals who we observe in our data in a job prior to this.  Even though we control for a wide array of observable characteristics, the hazard rates of observationally equiva-lent individuals may still differ from each other. Ignoring such unobserved heterogeneity in duration models produces incorrect results (cf. Lancaster 1990). To account for unobserved heterogeneity, the proportional hazard model is extended to allow for a multiplicative unobserved heterogeneity term u, which yields a mixed propor-tional hazard model.6 The hazard function then becomes:                                                      6 See van den Berg (2001) for a survey of this model class. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 13   \ud835\udf06(\ud835\udc61|\ud835\udc65\ud835\udc56\ud835\udc61 , \ud835\udc45\ud835\udc47\ud835\udc3c\ud835\udc56\ud835\udc61 , \ud835\udc62) = \ud835\udf060(\ud835\udc61)exp (\ud835\udefe \ud835\udc65\ud835\udc56\ud835\udc61 + \ud835\udefd\ud835\udc45\ud835\udc47\ud835\udc3c\ud835\udc56\ud835\udc61) (5) where \u03c5 follows a Gamma distribution (Abbring and van den Berg, 2007) and is assumed to be independent of regressors and censoring time. The heterogeneity term is shared across different spells of a given individual, causing observations within groups to be correlated. In all duration models our control vector, X, largely follows that for (2). We include industry, region, year fixed ef-fects and regional unemployment rates to capture differences in economic conditions over time and across regions. Again, we explore time variation and non-linearities in the effect of exposure to different levels of RTI on labour market outcomes.  Page 14 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  5 Results 5.1 The Evolution of Task Shares and Intensities 1979 to 2013 Figure 1 displays the annual employment shares by task type for the period 1975 to 2014 based on the initial, Cortes style, classification approach. It is clear that the employment share of routine jobs has strongly declined over the time period under observation, from 69% in 1975 to 48% in 2014 for men (Figure 1a). This represents a dramatic reduction in the employment share for these types of jobs. By contrast, the employment shares of non-routine manual have increased from 12% to 20% and from 19% to 32% for non-routine cognitive jobs during the same time period. Again, this fits broadly with the existing evidence for other countries.7 For comparison, we also provide the corresponding figure for female workers (Figure 1b). While the levels of the task types differ, the pat-terns of change over the period are essentially the same. The notable difference is that non-routine cognitive tasks become the predominant job type for women after 2009.  Figure 1a: Employment shares of task categories, 1975-2014, men  Source: SIAB 1975-2014, own calculation. The relatively smooth nature of this process over the period is also noticeable. Our data suggest that polarization has been an on-going, gradual, process in Germany. Moreover, there is little evidence of substantive cyclical vari-ations, or at the least these variations are dominated by the secular patterns. This is important as, based on decennial comparisons, the existing literature has sometimes suggested that polarisation has been concentrated in specific decades or                                                       7 For instance, Goos et al. (2014) find for 16 European countries that while the employment shares of the highest-paying occupations (mainly characterized by non-routine cognitive tasks) have increased over the time period 1993-2010, the employment shares of the middle-paying occupations (mainly routine jobs) have declined. 00.10.20.30.40.50.60.70.819751977197919811983198519871989199119931995199719992001200320052007200920112013Routine NRC NRMLong-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 15  Figure 1b: Employment shares of task categories, 1975-2014, women  Source: SIAB 1975-2014, own calculation. episodes. At the same time previous research that focuses on relatively short periods has suggested that busi-ness cycle dynamics may speed up the polarisation process. To our knowledge, this is the first time that evidence has been provided allowing for a long-period, and relatively high frequency, view of the polarisation process. As an alternative view of the same process, Figure 2 provides the average share of workers\u2019 job task intensities across the 6 BIBB waves. These numbers result, in effect, from computing the intensities of R, NRC and NRM tasks from the BIBB survey data. This differs from Figure 1 insofar as (a) it provides a measure of overall \u2018routine-ness\u2019 of work across time (and of the overall intensity in NRC and NRM) and (b) by using the BIBB information we allow the task intensities of any given occupation to change over time. Nonetheless, the general view is the same. There has been a marked reduction in routine task intensity over the past 35 years. The drop is steady from 54% of all tasks in 1979 to about 30% in 2006. After this point there is essentially no change in the routine task share.8 Despite the high frequency of the BIBB surveys, the task intensities sometimes change markedly at the beginning of each BIBB period. The reason behind is twofold. First, holding the task intensities constant within the BIBB pe-riods ignores within-occupation changes and causes a dramatic change at the period beginnings. Second, the questions in the BIBB surveys vary to some extent over time. We therefore focus on the survey questions that are repeated across waves, and furthermore merge specific questions with similar content to adjust the number of questions in order to obtain a similar number of questions in each wave and task category.                                                      8 In addition to our baseline approach, we applied further specifications to estimate the task intensities. The de-creasing pattern of routine task intensity is visible in all approaches. See Figure A1 for more detail on the different approaches applied. 00.10.20.30.40.50.619751977197919811983198519871989199119931995199719992001200320052007200920112013Routine NRC NRMPage 16 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Figure 2: Average Task Intensities of Employment from the BIBB data  Source: BIBB/BAuA/IAB surveys, own calculation. Figure 3: Average Task Intensities of Employment from the IAB data, 1979 to 2012  Source: SIAB 1975-2014, BIBB/BAuA/IAB surveys, own calculation. \u2013 RTI: Routine task intensity; NRCI: Non-routine cognitive task intensity; NRMI: non-routine manual task intensity. Finally, Figure 3 reports the routine task share where we weight the BIBB occupation task share by the SIAB em-ployment data. As both represent samples of the same underlying population, the overall patterns of the evolution of task shares are quite similar. However, this approach allows for within BIBB period variation in task shares and hence variation from more short-term employment changes. Taken together this provides a body of evidence that there has been a quite dramatic reduction in routine-intensive tasks in Germany since the 1970s. 00.10.20.30.40.50.61975 1980 1985 1990 1995 2000 2005 2010 2015NRCI RTI NRMI00.10.20.30.40.50.61975 1980 1985 1990 1995 2000 2005 2010 2015RTI NRCI NRMILong-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 17  Are these changes in task shares associated with differing worker compensation over the period? Table 1 pre-sents unconditional mean differences of wages according to task group. A number of points are worth emphasising. The pattern for wages shows a clear ordering of non-routine cognitive workers, routine workers then non-routine manual workers. This fits with the distribution of these skills predominantly over higher, medium and lower skills occupations, respectively. More importantly, for our purposes these wage gaps appear to be in-creasing over time. This, when combined with the earlier evidence is suggestive of a process of quantity adjustments (employment) to labour demand for routine tasks workers. Table 1: Average wages by task group, 1975-2014  Routine NRC NRM Overall 1970s 81.65 101.29 75.76 85.06 1980s 89.65 115.41 81.93 94.83 1990s 100.40 130.40 89.99 107.24 2000s 101.65 137.31 85.98 110.33 2010s 99.16 137.24 85.29 110.61 Total 94.87 127.30 84.90  Source: SIAB 1975-2014, own computation. Note: Wages refer to daily wages in Euro for the time periods 1975-79, 1980-89, 1990-99, 2000-09, 2010-14, and 1975-2014 (total). Figure 4: Task-specific unemployment rates, 1979-2014  Source: SIAB 1975-2014, own calculation. Given these reductions in employment, an obvious question to ask is whether this has led to changes in the un-employment levels associated with previously being in a given job-task category. Figure 4 reports task-specific unemployment rates over time. Non-routine cognitive workers and non-routine manual workers feature the lowest and highest unemployment rates, respectively, while the unemployment rate of routine workers is between these two across the period. 0%2%4%6%8%10%12%19751977197919811983198519871989199119931995199719992001200320052007200920112013Routine NRM NRCPage 18 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  5.2 Descriptive Evidence on the Links between Tasks and Employment Transi-tions. We next provide descriptive evidence on labour market transitions according to job tasks performed by workers. These are most readily reported using discrete categorisation of workers into Routine, Non-Routine Manual and Non-Routine Cognitive groups. The most straightforward means of doing this is, again, in the spirit of Cortes et al (2014). Table 2 provides evidence regarding the transition probabilities from one year to the next between employment in different task types, unemployment, and non-participation. Employment probabilities are highest for non-routine cognitive workers, followed by routine workers and non-routine manual workers. The latter workers also fare worst in terms of job-finding probabilities. Somewhat surprisingly, routine workers have the highest job-finding probabilities, which seems to be an indication of a high level of churning for this type of worker.  Table 2: Transition matrix between different labour market states and task categories   year t+1   Routine E NRC E NRM E U N year t Routine E 90.08 1.28 1.33 2.95 4.37 NRC E 2.02 92.23 0.57 1.91 3.27 NRM E 5.69 1.39 83.04 4.06 5.82 Routine U 21.64 3.38 5.48 56.91 12.59 NRC U 8.07 17.83 3.13 60.01 10.97 NRM U 12.53 2.90 12.56 56.53 15.48 Source: SIAB 1975-2014, own computation. It also becomes apparent that direct changes between different task categories for employed workers are uncom-mon, the corresponding annual transition rates are generally below 2%. An exception to this are transition rates from non-routine manual to routine employment, which amount to nearly 6%. Switching task categories is more common for unemployed individuals, although still relatively low. For example, the probability that a (previously) routine worker who is unemployed finds a job as a non-routine cognitive worker is 3.38%. Again, the transition rate from (previously) non-routine manual workers to a routine job is the exception. Non-routine manual workers who are unemployed display an equal probability of being in non-routine manual work and of being in routine work one year later. Figure 5 provides additional information regarding transitions over time by task type. Specifically, it provides the probability of a job episode ending according to a worker\u2019s task type. The main driving force behind these job exit probabilities seem to be cyclical during most of the observation period, e.g. with an increase during the bursting of the dot-com bubble of the early 2000s. In a similar vein to Figure 1, non-routine manual workers have the highest probability of job exit across the period of 1980-2010. Routine workers have lower job exit probabilities than non-routine manual workers, but higher exit rates than non-routine cognitive workers. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 19  Figure 5: Probability of job exit, by task categories, 1980-2014  Source: SIAB 1975-2014, own calculation. Note: Job exit defined as making a transition to a different establishment, a different task category, or to unemployment. Figure 6 provides information on transitions conditional on a worker making a job-to-job transition and according to their initial task type. For each task type there are high levels of state dependence. A worker who makes a transition is substantially more likely to move to another job in the same task category. More importantly, there is evidence that this level of state dependence has increased over time for two task types. Both non-routine cogni-tive and non-routine manual workers are more likely to transit between jobs in the same task type at the end of our observation period than at the start. This appears to follow a steady path over time, and is most marked for non-routine manual workers. At the same time as this, routine workers witnessed a marked reduction in this state dependence. Moreover, this change appears to have been driven at least in part by what could be considered movements up the occupational ladder into non-routine cognitive work. This provides initial evidence that part of the patterns seen earlier in Figures 1, 2 and 3 reflect differences in transitions across tasks. Turning to workers who have become unemployed, Figure 7 features the unemployment exit rate of workers in the three task categories. First, it becomes apparent that unemployment exit rates showed a marked decline in the 1980s and early 1990s, reflecting the structural worsening of labour market conditions in Germany. Since the mid-1990s, and particularly since the mid-2000s, this trend has been reversed with unemployment exit rates con-stantly increasing, which is in line with the strengthening performance of the German labour market highlighted by (Dustmann et al. 2014). Somewhat surprisingly, previously routine workers are the most likely group to exit unem-ployment over the entire observation period. As Figure 8 shows, these unemployed workers mainly return to a routine job. Non-routine manual workers also largely    - 0.05 0.10 0.15 0.20 0.25 0.30 0.351980 1990 2000 2010Routine NRM NRCPage 20 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Figure 6: Transition shares from employment, conditional on making a transition, by task categories, 1975-2014    Source: SIAB 1975-2014, own calculation. return to the same task category after a spell of unemployment, however with a much lower probability. Many of them actually switch to routine jobs. However, this transition from non-routine manual unemployment to routine employment has become less frequent over the observation period. For non-routine cognitive workers, there is also strong state dependence, with no obvious time trends. 0%10%20%30%40%50%60%70%80%90%100%Transition from Routine task0%10%20%30%40%50%60%70%80%90%100%Transition from NRC task0%10%20%30%40%50%60%70%80%90%100%1980 1990 2000 2010Transition from NRM taskRoutine NRM NRCLong-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 21  Figure 7: Unemployment exit rate, by task category, 1979-2014  Source: SIAB 1975-2014, own calculation. 0%2%4%6%8%10%12%198019821984198619881990199219941996199820002002200420062008201020122014Routine NRM NRCPage 22 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Figure 8: Transition shares from unemployment, conditional on exiting unemployment, by task category, 1975-2010    Source: SIAB 1975-2010, own calculation. 0%10%20%30%40%50%60%70%80%90%100%Transition from previous Routine task0%10%20%30%40%50%60%70%80%90%100%Transition from previous NRM task0%10%20%30%40%50%60%70%80%90%100%1980 1990 2000 2010Transition from previous NRC taskRoutine NRM NRCLong-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 23  5.3 Labour market histories over the short and medium run We now turn to multivariate estimation of the effect of RTI exposure on employment. Employed workers are stacked in 6-7 year intervals (i.e. according to the BIBB wave years described above: 1979, 1985, 1992 etc.) in order to estimate the probability of remaining in employment after one year and five years, respectively, using the logit model described in equation (2). We include a range of controls along with our variable of interest, the RTI of the job. The resultant estimates are presented in Table 3. The first column provides the average conditional effect of RTI exposure on employment probability at t+1. This demonstrates that higher RTI is associated with a lower probability of still being in employment one year in the future. The corresponding marginal effect amounts to -0.026. Since RTI is measured on a 0-1 continuum, this marginal effect can be interpreted as a 2.6 percentage point reduction in the likelihood of being employed one year later if a worker moved from a job with zero routine task intensity to a job that is entirely routine. As such a change in RTI is unrealistic, we compute the change in employment probability if the RTI of a job increases by one standard deviation. The standard deviation of RTI across our time period is 0.202, hence a one standard deviation increase in RTI is associated with a decrease in the likelihood of being employed one year later of 0.53 percentage points (2.6 * 0.202). Given that the mean rate of employment loss over one year amounts to 13 percent, this can be viewed as a small, but substantial, reduc-tion in employment probability due to a worker being exposed to RTI tasks.  Column 2 displays results that extend this to ask whether this RTI penalty has changed over the sample period. It reports coefficients on RTI and RTI interacted with a time trend. Whilst caution must be taken with adding interac-tion and main effects in a non-linear model, the signs and relative magnitude of these terms are informative. The initial RTI effect, which can be interpreted as the effect of RTI on employment stability at the start of our period, is essentially zero. RTI exposure was unrelated to employment stability in the late 1970s. The interaction term sug-gests that this changed over the past decades. Interpreting interaction terms in non-linear models is difficult. To provide a rough guide, we re-estimated this model using a linear probability model. The estimates suggest that a worker who was in an entirely routine job (i.e. RTI intensity = 100 per cent) would face an annual decrease in one year employment stability of 1.5 percentage points when compared to a worker who performed no routine tasks. Again, recognizing that this is an unrealistic comparison we rescale this effect by the standard deviation of RTI across our period of analysis. Doing so suggests that a one standard deviation increase in RTI was associated with a reduction in one-year employment stability of just over 10 percentage points over the past 35 years. This, we believe, is a quite dramatic reduction in employment stability. Column 3 includes industrial sector and year interaction terms. This is motivated by a concern that occupations are not distributed evenly across industrial sec-tors. Hence, conditional associations between RTI and employment could, at least in part, reflect sector-specific temporal shocks. In practice, this introduction does not markedly affect our estimates. The initial RTI effect moves closer to zero, but the rate of change over the period is essentially unaltered.  Columns 4 to 6 report analogous estimates for employment probability after five years, where again we include sector and year interaction terms. As column 4 shows, the probability of employment probability after 5 years is negatively affected by exposure to RTI. This average effect across the period is of a similar magnitude to that re-ported for employment after one year. Computing the marginal effect shows that workers in completely routine jobs (i.e. RTI=1) have a 6 percentage points lower likelihood of being in employment after five years than workers with completely non-routine jobs. Again we standardize the size of this effect. A one standard deviation increase in the RTI of a job is associated with a 1.2 percentage point reduction in being in employment after five years. Column 5 and 6 report estimates where again we include an interaction between RTI and time. In the case of em-ployment probability after five years, the introduction of industrial sector and time interactions is more consequential than for the employment probability in t+1, i.e. the coefficients of interest change more when com-paring specification 5 and 6 than when comparing specification 2 and 3. This is an indication that controlling for sectoral shocks matters more in the longer run (t+5) than in the short run (t+1). The estimates reported in column 6 suggest that exposure to RTI was, in the late 1970s, associated with greater employment stability over a five year period. However, this changed dramatically over the following 35 years, as evidenced by the interaction term Page 24 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  between RTI and time. It is furthermore noticeable that the employment penalties associated with RTI exposure are larger for employment probability in t+5 (compare columns 3 and 6).  Again, to aid interpretation, we re-estimated the model from column 6 as a linear probability model. These results suggest that RTI exposure was associated with a reduction of five year employment stability of 1.3 percentage points every year across the period. This, when again scaled by a one standard deviation increase in RTI, means that five year employment stability falls by approximately 9 percenage points across the 35 year period. Taken together, this suggests short term negative effects of RTI exposure on individual\u2019s employment stability that are exacerbated over the longer-term.  Table 3: Routine Task Intensity of Current Job and Probability of Employment after 1 year and 5 years, 1979-2013, Logit Odds ratios   After 1 year  After 5 years   (1) (2) (3) (4) (5) (6) RTI 0.732*** 1.055 0.993 0.706*** 0.800*** 1.326*** Time 0.990*** 1.055*** 0.940*** 0.384*** 0.716*** 0.720*** RTI x Time   0.852*** 0.845***   0.939*** 0.731*** Year Dummies X X X X X X Sector x Year Dummies     X     X Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Control variables included in all regressions, age groups, skill groups, economic sectors, establishment size, region (Bundesland), year, regional unemployment rate, constant. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively. The estimates reported in Table 3 reflect conditional effects averaged across all workers. One question that natu-rally arises is the extent to which these effects are likely to be heterogeneous over different worker types. Two main dimensions likely to be particularly important are the age and skill levels of workers. Table 4 reports esti-mates that correspond to the specifications in columns (1) and (2) from Table 3. Hence the first column reports the average effect (across the period) of RTI exposure on employment stability, while the 2nd and 3rd column pro-vide the starting (1979) effect on employment stability such that they provide the effect of RTI at the start of the period and trend effect of RTI on employment stability across the whole period. In terms of average effects, the negative effects on employment stability are concentrated among prime-age workers (26-35), with some indica-tion that the negative effects are greater for medium skill workers. For all age groups RTI exposure decreases employment stability over our period of observation. There is variation in the initial effect of RTI on employment stability by skill levels. Low skill workers, even in 1979, faced lower employment stability if in jobs with high RTI. This RTI effect remains constant for these workers, while for both medium and high skill workers RTI is increas-ingly associated with employment instability over time. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 25  Table 4: Routine Task Intensity of Current Job and Probability of Employment after 1 year, 1979-2013, Logit Odds Ratios   Specification 1 Specification 2   RTI RTI RTI x Time Age    18-25 0.91** 1.1 0.90*** 26-35 0.65*** 1.04 0.82*** 36-45 0.62*** 0.9 0.85*** 46-55 0.54*** 0.72*** 0.89*** 56-65 0.90** 1.34*** 0.85*** Skill    Low 0.78*** 0.78*** 0.99 Medium 0.73*** 1 0.87*** High 0.82* 1.60*** 0.76*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Models correspond to columns 1 and 3 in Table 3. Control variables included in all regressions, age groups, skill groups, economic sectors, establishment size, region (Bundesland), year fixed effects and regional unemployment rate, constant. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively. 5.4 Task-specific job stability and unemployment exit rates These differences in employment probabilities by task intensity could reflect a mixture of two different factors. Specifically, task intensity could influence job stability, and/or exit rates out of unemployment. We try to disentan-gle these channels.  Table 5 provides estimates of the probability of exiting from employment to any other employment state (em-ployed or un-employed). In this way, it provides estimates of the effect of RTI exposure on job stability. All estimates are reported as hazard ratios. We follow a similar strategy to the earlier models of employment stability by reporting models with increasingly complex specifications. The first column reports the average effect of RTI on the probability of making an employment transition. This effect is sizeable, again scaling this effect shows that a one percentage point increase in RTI leads to an approximate 0.4% increase (exp(0.34)-1) in the likelihood of exiting your current job. Recalling that the standard deviation of RTI is 0.202, this again is a large effect. Interact-ing this effect with time (column 2 and 3) reveals that this risk of exit is increasing at approximately 0.04 percentage points every year, this represents a non-negligible increase in job instability over our period of analy-sis.  Page 26 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Table  5: Routine Task Intensity and the Risk of Job Exit (to employment/unemployment), hazard ratios   (1) (2) (3) RTI 0.340*** 0.340*** -0.190*** time  0.002*** -0.012*** RTI x time   0.035*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Control variables included in all regressions: Duration dummies:  0 \"0 - 3 months\", 1 \"4 - 12 months\", 2 \"1 - 2 years\", 3 \"2 - 5 years\", 4 \"5 - 10 years\", 5 \"> 10 years\"; Age groups, skill groups, economic sectors, establishment size, region (Bundesland), regional unemployment rate, year dummies. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively. These overall exit rates may hide a mixture of job-to-job transitions and job-to-unemployment transitions. Welfare losses attached to technological change are most likely to be concentrated in the latter transitions. This leads us to re-estimate our duration models where instead the hazard state is exit from employment to unemployment.  These results are reported in Table 6 and reveal more dramatic patterns of the effect of RTI exposure on job sta-bility. RTI exposure is associated with markedly higher risk of subsequent exit to unemployment. A one percentage point higher RTI leads to an increase in the likelihood of entering unemployment of approximately 0.65%. This risk has trended up rapidly across the last 4 decades. This provides evidence that a feature of job polarization has been an increasing risk of experiencing a period of unemployment for workers performing routine tasks. Table 6: Routine Task Intensity and the Risk of Exit to Unemployment, hazard rates   (1) (2) (3) RTI 0.498*** 0.498*** -0.244*** time  0.005*** -0.017*** RTI x time   0.050*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Control variables included in all regressions: Duration dummies:  0 \"0 - 3 months\", 1 \"4 - 12 months\", 2 \"1 - 2 years\", 3 \"2 - 5 years\", 4 \"5 - 10 years\", 5 \"> 10 years\"; Age groups, skill groups, economic sectors, establishment size, region (Bundesland), regional unemployment rate, year dummies. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively. This leads to an obvious question regarding the ability of these workers to subsequently exit unemployment and how this has changed over time. We estimate hazard models of the likelihood of exiting unemployment to em-ployment where we use the RTI of the last employment spell as the main variable of interest. Insofar as this has any effect on re-employment probabilities this is informative of potential labour market scarring effects of RTI ex-posure. In practice, we find no evidence of this (Table 7). Previously holding an RTI-intensive job is associated, if anything, with a higher likelihood of re-entering employment, and this is trending upwards over time. This sug-gests that the increasing job instability of RTI-intensive work over the period has been coincident with countervailing effects on re-employment probabilities. This has the potential to have mitigated some of the wel-fare losses associated with this job instability and the changes in occupational structure, more generally.  Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 27  Table 7: Routine Task Intensity and the Risk of Exiting Unemployment to Employment, hazard rates   (1) (2) (3) RTI 0.124*** 0.124*** -0.443*** time  0.452*** 0.438*** RTI x time   0.032*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Control variables included in all regressions: Duration dummies:  0 \"0 - 3 months\", 1 \"4 - 12 months\", 2 \"1 - 2 years\", 3 \"2 - 5 years\", 4 \"5 - 10 years\", 5 \"> 10 years\"; Age groups, skill groups, economic sectors, establishment size, region (Bundesland), regional unemployment rate, year dummies. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively. The effects reported in Tables 5 to 7 are averaged across all workers. Again we seek to explore heterogeneity of effect across age groups and skill level. These results are reported in Table 8 grouped by the effect on risk of job exit, risk of job exit to unemployment, and subsequent likelihood (risk) of finding a job for the unemployed. For risk of job exit, and job exit to unemployment there is little evidence of variation by age, although workers in jobs with high RTI aged 26 to 35 appear to face a higher likelihood of job exit to unemployment. The effects on subse-quent job finding are more pronounced, RTI exposure for workers aged 36 and above is associated with an increased subsequent job finding rate. There is no effect for younger workers. Furthermore, we find evidence for strong heterogeneous effects with respect to skills, i.e. routine intensity strongly increases the unemployment exit probability of high-skilled workers. This is not apparent for low-skilled workers. Table 8: Routine Task Intensity and the Risk of Job Exit (to employment/unemployment) by age and skill group, hazard ratios   (1) (2) (3) RTI: RTI: RTI: Risk of job exit Risk of job exit to unemployment Job-finding rate of unem-ployed Age    18-25 0.272*** 0.327*** 0.001 26-35 0.454*** 0.791*** 0.042 36-45 0.267*** 0.383*** 0.143*** 46-55 0.371*** 0.419*** 0.216*** 56-65 0.336*** 0.375*** 0.320*** Skill    Low 0.336*** 0.314*** -0.145*** Medium 0.298*** 0.433*** 0.166*** High 0.694*** 1.474*** 0.537*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Models correspond to column 2 in Tables 5, 6 and 7. Con-trol variables included in all regressions, age groups, skill groups, economic sectors (not for column 3), establishment size, region (Bundesland), year fixed effects and regional unemployment rate, constant. ***, ** and * indicate statistical signifi-cance at the 1%, 5% and 10% level respectively. 5.5 RTI Wage Penalties As a final step, we provide some evidence on wage premia attached to RTI exposure, and in particular, how this has changed over our period of analysis. As a first step, we estimate a number of models where the dependent variable is log real wages and our main right hand side variable of interest is the RTI of the job. These are re-ported in Table A.8. The controls are listed in the table notes, but the coefficients are omitted for the sake of brevity. We pool our sample period and the first two columns report the relationship between current job RTI and wages. The first column provides the average wage effect of RTI across the 1975 to 2014 period, which is 0.378 log points lower. A one standard deviation increase in RTI exposure is associated with an approximate 7.6% wage penalty. The second column includes an interaction between RTI and time, such that the RTI coefficient Page 28 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  now provides the initial wage penalty. This is -0.259, while the interaction term indicates that the RTI wage pen-alty increased, and quite substantially, over the period. The following 4 columns provide similar results but where instead the relationship under examination is RTI of the current job and wages in the next year, or five years later, respectively.  The estimates for these are very similar to those for the contemporaneous relationship between RTI and wages. Our reading of this is that there are substantial wage penalties that have increased markedly over the past four decades associated with RTI. However, there is no evidence of additional scarring effects on individual\u2019s wages due to past exposure to RTI.  Table A.9. reports RTI exposure effects on wages by age and skill level of workers, respectively. Again, we report contemporaneous effects along with those for one year and five years on, respectively.  There is a clear age gra-dient to the wage penalties. All age groups suffer wage penalties through RTI exposure, however the magnitude of these effects are over 3 times larger for 46 to 65 year old workers when compared to those aged 18-25. Again these effects do not change markedly over one and five year windows. A skill gradient is also apparent. High-skill workers in jobs suffer a very large wage penalty through RTI exposure. There are substantial penalties for me-dium-skill workers, and smaller effects for low-skill workers. The high-skill RTI penalty diminishes by approximately one third over a five-year period, perhaps reflecting the greater ease with which high-skill workers can change job. These penalties are, in contrast, quite stable for low- and medium-skill workers.  Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 29  6 Conclusion  The past four decades have seen dramatic changes in the structure of the labour market. Rapid decreases in computing costs have led to a sharp reduction in the demand for jobs that are intensive in routine tasks. The ex-isting literature highlights the aggregate patterns of labour market polarisation associated with this. We revisit this issue using German administrative data that allows us to address a range of questions currently unanswered in the literature. We present, to our knowledge, the first evidence on changes in task intensity of jobs over a long period and at an annual level. This allows us to examine the trend in polarisation over time which is important as the previous literature has suggested both periods of heightened polarisation and/or accentuated cyclical pat-terns. Our first main finding is to show that neither are the case in Germany. In this context, polarisation represents a steady secular change over the period of 1975 to 2014. Any cyclical patterns are dominated by this process. This is important as it suggests ongoing structural change without episodes of heightened changes in employment task shares. With this as a starting point we seek to understand the worker transitions contributing to these patterns. Again, this is an analysis for which our data is particular well suited and where there is little existing evidence. Our re-sults suggest that exposure to jobs with higher routine-task content is associated with higher risk of being out of employment in both the short term (after one year) and medium term (five years). Subsequent results show that this employment penalty to routineness of work has increased over the past four decades.  The reasons for the employment penalty to routineness of work were then traced back to routine task work being associated with reduced job stability and an associated higher likelihood of making a transition to unemployment and thus experiencing periods of unemployment. By contrast, we find that previous work with high RTI for unem-ployed persons is associated with higher job-finding rates out of unemployment which thus at least partly compensates for the negative effects of RTI on employment stability. Further research is required to understand the extent to which these patterns of labour market transitions for routine workers are associated with individual welfare losses.Page 30 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  7 References Abbring, J.H. and G.J. van den Berg (2007), The unobserved heterogeneity distribution in duration analysis. Bio-metrika, 94 (1): 87-99. Antonczyk, D., B. Fitzenberger and U. Leuschner (2009), Can a task-based approach explain the recent changes in the German wage structure? Jahrb\u00fccher f\u00fcr National\u00f6konomie und Statistik 229 (2-3): 214-238. Autor, D. (2015), Why Are There Still So Many Jobs? The History and Future of Workplace Automation. Journal of Economic Perspectives 29 (3): 3-30. Autor, D.H., L. Katz and A. Krueger (1998). \u2018Computing Inequality: Have Computers Changed the Labor Market?\u2019 Quarterly Journal of Economics 113 (4): 1169-1213. Autor, D.H., F. Levy and R.J. Murnane (2003), The Skill Content of Recent Technological Change: An Empirical Exploration. Industrial and Labor Relations Review 118 (4): 1279-1333. Baumgarten, D. (2015), Offshoring, the nature of tasks, and occupational stability: empirical evidence for Ger-many. The World Economy 38 (3): 479-508. Bechara, P. (2017), Employment polarization and occupational dynamics, mimeo, RWI. Caliendo, M. and A. Uhlendorff (2008), Self-Employment Dynamics, State Dependence and Cross-Mobility Pat-terns. IZA Discussion Papers 3900, Institute for the Study of Labor (IZA). Cortes, G.M. (2016), Where Have the Middle-Wage Workers Gone? A Study of Polarization Using Panel Data. Journal of Labor Economics 34 (1): 63-105. Cortes, G.M., N. Jaimovic, C.J. Nekarda and H.E. Siu (2014), The micro and macro of disappearing routine jobs: A flows approach. NBER Working Paper 20307, National Bureau of Economic Research. Dustmann, C., B. Fitzenberger, U. Sch\u00f6nberg and A. Spitz-Oener (2014), From sick man of Europe to economic superstar: Germany\u2019s resurgent economy. The Journal of Economic Perspectives 28 (1): 167-188. Goos, M. and A. Manning, A. (2007), Lousy and Lovely Jobs: The Rising Polarization of Work in Britain. Review of Economics and Statistics 89 (1): 118-133. Goos, M., A. Manning and A. Salomons (2009), Job Polarization in Europe\u2019. American Economic Review 99 (2): 58-63. Goos, M., A. Manning and A. Salomons (2014), Explaining Job Polarization: Routine-Biased Technological Change and Offshoring. American Economic Review 104 (8): 2509-2526. Jaimovich, N. and H.E. Siu (2012), The trend is the cycle: Job polarization and jobless recoveries. NBER Working Paper 18334, National Bureau of Economic Research. Lancaster, T. (1990), The Econometric Analysis of Transition Data. Cambridge: University Press. Mazzolari, F. and G. Ragusa (2013), Spillovers from high-skill consumption to low-skill labor markets. Review of Economics and Statistics 95 (1): 74-86. Smith, C.L. (2013), The dynamics of labor market polarization. Finance and Economics Discussion Series, Divi-sion of Research & Statistics and Monetary Affairs 57. Federal Reserve Board, Washington, D.C. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 31  Spitz-Oener, A. (2006), Technical Change, Job Tasks and Rising Educational Demands: Looking Outside the Wage Structure. Journal of Labor Economics 24 (2): 235-270. Tiemann, M., H.J. Schade, R. Helmrich, A. Hall, U. Braun and P. Bott (2008). Berufsfeld-Definitionen des BIBB. Bonn: Bundesinstitut f\u00fcr Berufsbildung. van den Berg, G.J. (2001), Duration models: specification, identification and multiple durations. In: Heckman, J. and E. Leamer (eds.), Handbook of Econometrics. Amsterdam: Elsevier, 3381-3460. vom Berge, P., M. K\u00f6nig and S. Setz (2013), Sample of Integrated Labour Market Biographies (SIAB) 1975-2010\u2019. FDZ-Datenreport 01/2013. N\u00fcrnberg: IAB.Page 32 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  8 APPENDIX The BIBB data and Computation of Task Intensity Measures The first four waves of the task data were conducted under the name \u201cQualification and Career Survey\u201d in a col-laboration of German Federal Institute for Vocational Education and Training (Bundesinstitut f\u00fcr Berufsbildung: BIBB) and the Institute for Employment Research (Institut f\u00fcr Arbeitsmarkt- und Berufsforschung: IAB). The 2006 and 2012 waves were conducted as \u201cBIBB/BAuA Labour Force Survey\u201d, which were jointly carried out by BIBB and the Federal Institute for Occupational Safety and Health (Bundesanstalt f\u00fcr Arbeitsschutz und Ar-beitsmedizin: BAuA). In the cross-section BIBB surveys, workers state which activities they perform at their workplace from a given list. Although the surveys include a rich set of workplace activities, the number and the definition of the surveyed ac-tivities differ across waves. While the 1979 wave covers approximately 90 activities, the number of activities decreased to 19 in the 2012 wave. In order to create a task intensity measure that is consistent over time, we ex-cluded the activities that appeared only in one wave. We merged some of the activities into one variable in order to deal with the changing definitions of the variables and to maintain a total number of activities which is similar in each survey. For example, the activity \u201cbuying, selling, advertising\u201d in the 1985 wave was split into two separate variables as \u201cbuying and selling\u201d and \u201cadvertising\u201d in 1999; we thus merged these two variables to make the com-parison to the previous wave easier.  The answer categories in the surveys were also different across waves. While in some waves the answer cate-gory was binary, in other waves workers were asked whether they performed an activity \u201coften\u201d, \u201csometimes\u201d, or \u201cnever\u201d. In case of three-category answers, we classified the answer categories \u201csometimes\u201d and \u201cnever\u201d together to have a consistent binary variable. We tested the robustness of our results by applying four alternative definitions of task intensity measures to deal with the inconsistencies across waves mentioned above. In the \u201crestricted\u201d approach, we merge even more sur-vey questions compared to the baseline approach in order to keep the number of questions in all three task categories as close to each other as possible. The \u201clenient\u201d definition assumes that an activity is applied when the answer to survey questions is \u201calways\u201d or \u201csometimes\u201d whereas the baseline category uses only the answer cate-gory \u201calways\u201d. \u201cLenient-Restricted\u201d approach applies the lenient definition to the restricted set of merged variables. Finally the \u201cexcluded variables\u201d definition ignores the survey questions which were not repeated in all the waves. The results of these robustness analyses are available from the authors upon request.Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 33  Table A1: List of routine tasks Occupation No. Description 71  Miners     72  Mining shot firers and blasters                                                                                                       81  Stone crushers     82  Earth, gravel and sand quarry workers     83  Gas and crude oil quarry workers     91  Mineral and stone processing plant operators                                                                                                       102  Precious-stone workers, jewel preparers    111  Brickmaker and other stoneware makers    112  Cement and concrete block makers    121  Ceramics plant operators    141  Chemical products plant and machine operators                                                                                                    142  Chemical laboratory workers                                                                                                                                        143  Rubber products machine operators                                                                                                                                        144  Tyre vulcanisers                                                                                                                                           151  Plastic products machine operators                                                                                                                                    161  Pulp and cellulose plant operators                                                                                                                                           162  Packaging makers                                                                                                                                       171  Type setters, pre-press workers    172  Stereotypers and electrotypers                                                                                                                                              173  Book printers, letterpress                                                                                                                                      174  Flat screen, gravure and intaglio printers                                                                                                                                       175  Special, silk-screen printers                                                                                                       176  Hecto- and mimeo-graphers                                                                                                       182  Woodworking machine setters and setter-operators, and appropriate occupations                                                                                                                                       191  Ore and metal furnace operators, metal melters                                                                                                       192  Rolling-mill operators                                                                                                       193  Metal drawers and extruders                                                                                                       201  Moulders and coremakers                                                                                                       202  Casters                                                                                                       203  Casters of semi-finished products and other mould casters                                                                                                       211  Sheet metal pressers, drawer and puncher        212  Wire moulder, cable splicers    221  Metal lathe operators    222  Metal milling cutters    223  Metal planers    224  Metal borers    225  Metal grinders    231  Metal polishers    232  Engravers, chasers    233  Metal finishers    234  Galvanisers, metal colourers    235  Enamellers, zinc platers and other metal surface finishers    241  Welder, oxy-acetylene cutters    242  Solderers    243  Riveters    244  Metal bonders and other metal connectors    251  Steel-, black-, hammersmiths and forging press workers    Page 34 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  252  Tank and container builders, coppersmiths and related occupations    261  Thinsmiths    262  Plumbers    263  Pipe and tube fitters    270  Locksmiths and fitters, not further specified    271  Building fitters    272  Sheet metal worker, plastics fitters    273  Engine fitters    274  Plant and maintenance fitters    275  Steel construction fitters, steel ship builders    281  Motor vehicle repairers                                                                                                       282  Agricultural machinery repairers                                                                                                       286  Watch-, clockmakers    291  Toolmakers, instrument mechanics    301  Precious fitters otherwise undisclosed    302  Precious metal smiths    306  Doll, model makers, taxidermists    311  Electrical fitters, mechanics     312  Telecommunications mechanics, craftsmen     313  Electric motor, transformer fitters                                                                                                       315  Radio, sound equipment mechanics                                                                                                       321  Electrical appliance and equipment assemblers                                                                                                       331  Spinner, fibre-preparer                                                                                                       332  Spoolers, twisters, ropemakers                                                                                                       341  Weaving- and knitting-machine preparers                                                                                                       342  Weavers and weaving-machine operators                                                                                                       343  Tufted textile-, fur- and leather-products makers                                                                                                       351  Tailors and dressmakers    441  Bricklayers ans masons     442  Steel fixers, concreters     451  Carpenters     452  Roofers     453  Scaffolders    492  Upholsterers, mattresses makers    501  Cabinetmakers, carpenters and joiners    502  Pattern and mold carpenters    504  Other wood-products makers, Boat-, glider- and wooden sports-equipment-building experts    512  Goods painters and varnishers    513  Wood surface finishers, veneers    514  Glass, ceramics and related decorative painters, glass engravers and etchers    521  Products testers, sorters otherwise undisclosed                                                                                                       522  Product packagers, balers, wrappers, qualifiers and other loading agents                                                                                                       541  Power production plant operators                                                                                                       542  Winding-, conveyor- and ropeway-machine operators                                                                                                       543  Pump-, compressor-, assemly line-, boring and other machines operators                                                                                                       544 Crane and hoist plant operators                                                                                                                                     545  Earth-moving and related plant operators                                                                                                                                   546  Construction plant operators  547  Machine maintenance operators, machinists' assistants                                                                                                       Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 35  Table A 1 (ctd.2) Occupation No. Description 548  Boilerpersons, incinerators and related plant operators                                                                                                       629  Forepersons and other operations managers                                                                                                       634  Photo laboratory technicians    713  Other brake, signal and switch operators, transport guides and conductors, fleet managers                                                                                                                                                 714  Car, taxi, bus, (heavy) truck and other motor vehicle drivers                                                                                                                                     723  Seagoing ships' deck crews                                                                                                                                       724  Inland boatmans and related ships' decks crews                                                                                                                                               725  Ferrymans, lockmasters, coastguards and other water traffic occupations                                                                                                                                               741  Stocks administrators and clerks                                                                                                                                       742  Lift, lifting-trucks and other materials handling equipment operators                                                                                                                                         834  Decorators, sign painters    836  Interior architects, visual merchandiser    837  Photographers, camera and retouching operateurs       Source: Klassifizierung der Berufe (Kldb) 1988. \u2013 Classification of occupations 1988. Own compilation following Cortes (2016).  Table A2: List non-routine cognitive tasks Occupation No. Description 283  Aircraft mechanics                               284  Precision mechanics                   285  Other mechanics                   303  Dental technicans                   304  Opthalmic opticans                   305  Musical instrument makers                   314  Electrical appliance fitters                   411  Cooks                   601  Mechanical and automotive engineers                   602  Electrical and electronics engineers                   603  Architects, civil and structural engineers                   604  Cartographers and survey engineers                   605  Mining, metallurgy, foundry enineers                   606  Other production engineers                   607  Industrial and other operating engineers                   611  Chemists, chemical engineers                   612  Physicists, physics engineers, mathematicans                   621  Mechanical engineering technicians                   622  Electrical, electronics and telecommunications engineering technicians                   623  Civil engineering technicians                   624  Survey engineering technicans                   625  Mining, metallurgy, foundry engineering technicans                   626  Chemical and physical engineering technicians                   627  Other production technicans                   628  Industrial and other operating technicans                   631  Agronomy, forestry and life science technicians                   632  Physical and mathematical science technicians                   633  Chemical science technicians                   Page 36 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  635  Draftspersons                   681  Wholesaler, retail salespersons and bying agents                   683  Publishers, management assistants in publishing and booksellers                   691  Banking experts including tellers, finance clerks as well as finance dealers and brokers          694  Life, property insurance experts including representative as well as clerks                   703  Advertising and public relations experts                   704  Finance, stock, trade, ship, real estate, insurance brokers                   705  Landlords, hirers, agents, bookers, auctioneers                   711  Locomotive engine, tram and subway drivers                   721  Navigators, nautical ships' officers and pilots                   722  Technical ship's officers, engineers, technicians and machinists                   726  Aircraft pilots, flight engineers and other air traffic occupations                   751  Entrepreneurs, managing directors and division managers                   752  Management, ersonnel and other business consultants                   753  Financial, tax accountants and accounting clerks                   761  Legislators, ministers and elected officials                   762  Senior and administrative state officials                   763  Senior and adminstrative officials of humanitarian and other special-interest organisations                   774  Computer scientists, equipment operators, computing and data processing professionals                   804  Chimney sweepers                   811  Judges and prosecutors                   812  Law officers                   813  Lawyers, notaries, legal representatives, advisors and other legal professionals                   821  Authors, journalists, editors and announcers                   822  Interpreters, translators                   823  Librarians, archivists, documentalists, curators, library and filing clerks                   831  Composers, music directors and musicians                   832  Film, stage and related directors, actors, singers and dancers                   833  Sculptors, painters, graphic and related artists                   835  Set designer, light board, image and sound recording engineers, technicians and operators                   838  Clowns, magicians, acrobats, professional sportspersons, moutain guides and models                   841  Medical doctors                   842  Dentists                   843  Veterinaries       844  Pharmacists                   851  Non-medical practitioners, psychotherapists                   853  Nurses, midwifes, nursing and midwifery associate professionals                   855  Dieticians, nutritionists and pharmacy technicians                   857  Medical technical, laboratory, radiological assistants  861  Social work, welfare, health care professionals and workers; geriatric nurses                   862  Housemasters, social pedagogue, deacons                   863  Housemasters, social pedagogue, deacons                   871  University, college professors and related teaching professionals                   872  Grammar school teacher and related teaching professionals                   873  Primary, secondary school, special education teachers and related teaching professionals                   874  Vocational, professional college teachers and related teaching professionals                   875  Art, music and voice teachers and related teaching professionals, otherwise undisclosed                   876  PE teachers, related teaching professioanls, skiing and other sports instructors                   877  Driving, flying, hygienic and other instructors, otherwise undisclosed                    Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 37  Table A 2 (ctd.2) Occupation No. Description 881  Economists, psychologists, sociologists, political scientists, statisticians                   882  Philologists, historians, philosophers and other humanities scientists, otherwise undisclosed                   883  Biologists, geographers, meteorologists and other natural scientists, otherwise undisclosed                   891  Bishops, pastors, chaplains and other religious professionals                   892  Nuns, friars and other religious associate professionals                   893  Sextons, cantors and other religious assistants                   911  Hoteliers, innkeepers, restaurateurs and management assistants in hotels and restaurants                   921  Housekeepers and related workers  Source: Klassifizierung der Berufe (Kldb) 1988. \u2013 Classification of occupations 1988. Own compilation following Cortes (2016). Page 38 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Table A3: Non-routine manual tasks  Occupation No. Description 164  Other paper products machine operators                   177  Printer's hands                   213  Other metal moulders non cutting deformation                   226  Other metal-cutting occupations                   322  Metal-, rubber-, plastic-, paperboard-, textile and related products assemblers                   323  Metal plant operators no further specification                   471  Earth-moving labourers                   472  Building construction labourers and other construction and maintenance labourers  otherwise undisclosed                   531  Labourers no further specified                   549  Machine-tool setters and setter-operators no further specified                   682  Shop, stall and market salespersons and demonstrators                   684  Chemists in drugstores                   685  Chemist's assistants in pharmacies                   686  Filling station attendants                   688  Street or travelling vendors  701  Logistics managers and transport clerks                   702  Travel agency clerks, attendants, stewards, consultants, organisers and guides                   712  Railway brake, signal and switch operators, shunters and railway guards and conductors                   715  Cabby                   732  Mail carriers, sorting clerks, porters and deliverers                   734  Telephone switchboard operators                   743  Longshoremans, furniture removers                   744  Stock, loading and other transport workers                   773  Cashiers and ticket clerks                   791  Factories security offices, store, hotel and other detectives                   792  Watchpersons, custodians, attendants and related workers                   793  Door-, gatekeepers and caretakers                   794  Menials, bellmans, ushers and groundkeepers                   801  Soldiers, border guards, police officers                   802  Firefighters                   803  Safety inspectors, trade controllers, gauging,and environmental protection officers                   805  Disinfectors, morticians, meat and and other health inspectors                   852  Masseurs, physiotherapists and health care professionals                   854  Paramedics and nursing auxiliary workers                   856  Doctor's receptionists and assistants                   864  Kindergarden teachers, child care workers and paediatric nurses                   901  Hairdressers, barbers, wigmakers and related workers                   902  Beauticians, manicurists, pedicurists and related workers                   912  Waiters, waitresses, stewards, stewardesses and buspersons                   913  Porters, bartenders and other hotel and restaurant attendants                   923  Valets, chambermaids and other housekeeping attendants                                    934  Windows, frontages and buildings cleaners                   935  Sweepers, streets and sewerages cleaners, dustmans and other waste disposal workers                   937  Maschinery, plant, tube and container cleaners                   Source: Klassifizierung der Berufe (Kldb) 1988. \u2013 Classification of occupations 1988. Own compilation following Cortes (2016).  Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 39  Table A4: List of routine tasks according to BIBB data, 1979 wave Task category Occupational Field Non-routine cognitive Sales occupations (retail)   Occupations in wholesale and retail sales   Other commercial occupations (not including wholesale, retail, banking)   Managing directors, auditors, management consultants   Social occupations   Legal occupations   Engineers   Surveying and mapping   Chemists, physicists, scientists   Designers, photographers, advertising creators   Advertising specialists   Teachers   Technical draughtsmen/draughtswomen, related occupations Routine Security Workers   Occupations in aircraft and ship operation   Vehicle and aircraft construction, maintenance occupations   Building caretakers    Personal protection, guards   Packers, warehouse operatives, transport processors   Technicians   Administrative occupations in the public sector   Specialist skilled technicians   Miners and mineral extraction workers   Journalists, librarians, translators, related academic research occupations   Textile processing, leather manufacture   Occupations in insurance and financial services   Auxiliary office occupations, telephone operators   Commercial office occupations   Metal, plant, and sheet metal construction, installation, fitters   Goods examiners, Packagers, despatchers   Production of beverages, food and tobacco   Artists and musicians   Unskilled workers   Precision engineering and related occupations   Paper manufacture, paper processing, printing   Occupations in finance and accounting   Mechanics and tool makers   Butchers   Occupations in production and the processing of glass- and ceramic   Cooks   Agriculture, animal husbandry, forestry, horticulture   IT professions   Occupations in plastic and chemistry -making and \u2013processing   Bakers, pastry cooks, production of confectionary goods   Metal production and processing   Occupations in spinning and rope-making Non-routine manual Occupations in mechatronics, energy electronics and electrical engineering   Transport occupations Page 40 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data    Medical and health care occupations   Construction, wood and plastics manufacture and processing occupations   Hotel and restaurant occupations, housekeeping   Medical and health care occupations without medical medical licence   Body care occupations   Cleaning and disposal occupations Source: Klassifizierung der Berufe (Kldb) 1988. \u2013 Classification of occupations 1988. Own calculation using BIBB/BAuA/IAB surveys.  Table A5: List of routine tasks according to BIBB data, 2012 wave Task category Occupational Field Non-routine cogni-tive Cooks  Occupations in aircraft and ship operation  Medical and health care occupations without medical medical licence  Textile processing, leather manufacture  Hotel and restaurant occupations, housekeeping  Technicians  Occupations in security  Designers, photographers, advertising creators  Artists and musicians  Medical and health care occupations with medical licence  Social occupations  Occupations in finance and accounting  Sales occupations (retail)  IT professions  Surveying and mapping  Chemists, physicists, scientists  Technical draughtsmen/draughtswomen, related occupations  Other commercial occupations (not including wholesale, retail, bank-ing)  Engineers  Commercial office occupations  Body care occupations  Body care occupations  Occupations in wholesale and retail  Teachers  Managing directors, auditors, management consultants  Auxiliary office occupations, telephone operators  Administrative occupations in the public sector  Legal occupations  Journalists, librarians, translators, related academic research occupa-tions  Occupations in insurance and financial services  Advertising specialists Routine Occupations in mechatronics, energy electronics and electrical engi-neering  Construction occupations, wood and plastics manufacture and pro-cessing occupations  Specialist skilled technicians  Goods examiners, Packagers, despatchers  Butchers  Occupations in mechanics and tool making  Production of beverages, foods and tobacco, other nutrition occupa-tions Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 41   Metal, plant, and sheet metal construction, installation, fitters  Bakers, pastry cooks, production of confectionary goods  Occupations in spinning and rope-making  Miners and mineral extraction workers  Occupations in production and processing of glass- and ceramic  Paper manufacture, paper processing, printing  Precision engineering and related occupations  Occupations in plastic and chemistry -making and \u2013processing  Unskilled workers  Metal productions and processing Non-routine manual Vehicle and aircraft construction, maintenance occupations  Agriculture, husbandry, forestry, horticulture  Building caretakers  Cleaning and disposal occupations  Personal protection, guards  Transport occupations Source: Klassifizierung der Berufe (Kldb) 1988. \u2013 Classification of occupations 1988. Own calculation using BIBB/BAuA/IAB surveys.  Table A.6: List of the 10 occupational fields with the lowest RTI in 1979 and 2012 1979 2012 RTI Occupational Field RTI Occupational Field 0.0939 Technical draughtsmen/draughtswomen, re-lated occupations 0.0565  Social occupations 0.0983 Body care occupations 0.0795 Auxiliary office occupations, telephone op-erators 0.2190 Medical and health care occupations 0.0819 Legal occupations 0.2196 Medical and health care occupations without medical medical licence 0.0894  Advertising specialists 0.2561 Teachers 0.1165 Occupations in insurance and financial ser-vices 0.2615 Social occupations 0.1216 Administrative occupations in the public sector 0.2691 Advertising specialists 0.1288 Other commercial occupations (not includ-ing wholesale, retail, banking) 0.2718 Designers, photographers, advertising crea-tors 0.1316 Occupations in wholes le and retail 0.2724 Hotel and restaurant occupations, house-keeping 0.1470 Teachers 0.2739 Cl aning and disposal occupations 0.1539 Occupations in security  Table A.7: List of the 10 occupational fields with the highest RTI in 1979 and 2012 1979 2012 RTI Occupational Field RTI Occupational Field 0.7407 Mechanics and tool makers 0.4956 Metal, plant, and sheet metal construction, installation, fitters 0.7463 Butchers 0.5175 Bakers, pastry cooks, production of confec-tionary goods 0.7489 Occupations in production and the processing of glass- and ceramic 0.5388 Occupati ns in spinning and rope-making 0.7661 Cook  0.5552 Miners and mineral extraction workers 0.7782 Agriculture, animal husbandry, forestry, horti-culture 0.5562 Occupations in production and processing of glass- and ceramic 0.7844 IT professions 0.5696 Paper manufacture, paper processing, printing 0.7893 Occupations in plastic and chemistry -making and \u2013processing 0.6170 P ecision engineering and related occupa-tions 0.8540 Bakers, pastry cooks, production of confec-tionary goods 0.6275 Occupations in plastic and chemistry -mak-ing and \u2013processing 0.8808 Met l production and processing 0.6558 Unskilled w rkers 0.8838 Occupations in spinning and rope-making 0.6564 Metal productions and processing  Page 42 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Table A.8: Wages at different time horizons and RTI, coefficients from OLS regression  t=0 t=1 t=5   (1) (2) (3) (4) (5) (6) RTI -0.378*** -0.259*** -0.382*** -0.267*** -0.368*** -0.287*** time 0.012*** 0.032*** 0.008*** 0.027*** -0.006*** 0.010*** RTI x time  -0.052***  -0.050***  -0.041*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Dependent variable: log wages. RTI refers to time 0 in all regressions. Control variables included in all regressions: Duration dummies:  0 \"0 - 3 months\", 1 \"4 - 12 months\", 2 \"1 - 2 years\", 3 \"2 - 5 years\", 4 \"5 - 10 years\", 5 \"> 10 years\"; Age groups, skill groups, economic sectors, establishment size, region (Bundesland), regional unemployment rate, year dummies. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively.  Table A.9: Wages at different time horizons and RTI by age and skill group, coefficients from OLS regression   (1) t=0  (2) t=1 (3) t=5 Age    18-25 -0.141*** -0.123*** -0.134*** 26-35 -0.304*** -0.303*** -0.308*** 36-45 -0.455*** -0.441*** -0.398*** 46-55 -0.523*** -0.514*** -0.446*** 56-65 -0.535*** -0.535*** -0.501*** Skill    Low -0.114*** -0.097*** -0.116*** Medium -0.440*** -0.433*** -0.383*** High -0.600*** -0.577*** -0.401*** Source: SIAB 1975-2014, BIBB/BAuA/IAB survey, own computation. Dependent variable: log wages. RTI refers to time 0 in all regressions. Control variables included in all regressions: Duration dummies:  0 \"0 - 3 months\", 1 \"4 - 12 months\", 2 \"1 - 2 years\", 3 \"2 - 5 years\", 4 \"5 - 10 years\", 5 \"> 10 years\"; Age groups, skill groups, economic sectors, establishment size, region (Bundesland), regional unemployment rate, year dummies. ***, ** and * indicate statistical significance at the 1%, 5% and 10% level respectively. Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  | Page 43  Figure A1: Average Task Intensities of Employment from the BIBB data, different measures     00.10.20.30.40.50.61979 1985 1992 1999 2006 2012RestrictedROUTINE NRC NRM00.10.20.30.40.50.61979 1985 1992 1999 2006 2012LenientROUTINE NRC NRMPage 44 | Long-run Patterns of Labour Market Polarisation: Evidence from German Micro Data  Figure A 1 (ctd.2)   Source: BIBB/BAuA/IAB surveys, own calculation.  00.10.20.30.40.50.61979 1985 1992 1999 2006 2012Lenient-RestrictedROUTINE NRC NRM00.10.20.30.40.50.61979 1985 1992 1999 2006 2012Excluded Vars.ROUTINE NRC NRM   www.bertelsmann-stiftung.de Address | Contact  Bertelsmann Stiftung Carl-Bertelsmann-Stra\u00dfe 256 33311 G\u00fctersloh Phone +49 5241 81-0  Dr. Daniel Schraad-Tischler Senior Expert Phone  +49 5241 81-81240 Fax   +49 5241 81-681240 daniel.schraad-tischler@bertelsmann-stiftung.de  ",
        "id": 18930523,
        "identifiers": [
          {
            "identifier": "160465088",
            "type": "CORE_ID"
          },
          {
            "identifier": "322823609",
            "type": "CORE_ID"
          },
          {
            "identifier": "10.1111/bjir.12419",
            "type": "DOI"
          },
          {
            "identifier": "oai:ntnuopen.ntnu.no:11250/2590857",
            "type": "OAI_ID"
          },
          {
            "identifier": "10.4419/86788868",
            "type": "DOI"
          },
          {
            "identifier": "oai:econstor.eu:10419/179510",
            "type": "OAI_ID"
          },
          {
            "identifier": "oai:econstor.eu:10419/179037",
            "type": "OAI_ID"
          },
          {
            "identifier": "oai:econstor.eu:10419/181541",
            "type": "OAI_ID"
          },
          {
            "identifier": "158817285",
            "type": "CORE_ID"
          },
          {
            "identifier": "411976594",
            "type": "CORE_ID"
          },
          {
            "identifier": "478676804",
            "type": "CORE_ID"
          },
          {
            "identifier": "158816810",
            "type": "CORE_ID"
          },
          {
            "identifier": "oai:econstor.eu:10419/180588",
            "type": "OAI_ID"
          },
          {
            "identifier": "oai:aei.pitt.edu:102723",
            "type": "OAI_ID"
          },
          {
            "identifier": "187250091",
            "type": "CORE_ID"
          }
        ],
        "title": "Long-run Patterns of Labour\nMarket Polarisation: Evidence from German Micro Data",
        "language": {
          "code": "en",
          "name": "English"
        },
        "magId": null,
        "oaiIds": [
          "oai:aei.pitt.edu:102723",
          "oai:econstor.eu:10419/180588",
          "oai:ntnuopen.ntnu.no:11250/2590857",
          "oai:econstor.eu:10419/181541",
          "oai:econstor.eu:10419/179510",
          "oai:econstor.eu:10419/179037"
        ],
        "publishedDate": "2018-01-01T00:00:00",
        "publisher": "",
        "pubmedId": null,
        "references": [],
        "sourceFulltextUrls": [
          "http://aei.pitt.edu/102723/1/Studie_AND_LabourMarketPolarisation_2018.pdf"
        ],
        "updatedDate": "2025-02-26T04:00:27",
        "yearPublished": 2018,
        "journals": [],
        "links": [
          {
            "type": "download",
            "url": "https://core.ac.uk/download/322823609.pdf"
          },
          {
            "type": "reader",
            "url": "https://core.ac.uk/reader/322823609"
          },
          {
            "type": "thumbnail_m",
            "url": "https://core.ac.uk/image/322823609/large"
          },
          {
            "type": "thumbnail_l",
            "url": "https://core.ac.uk/image/322823609/large"
          },
          {
            "type": "display",
            "url": "https://core.ac.uk/works/18930523"
          }
        ]
      },
      "relevance_score": 0.0295,
      "dimension_scores": {
        "1_human_agent_interaction_oversight": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.35,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "2_agent_protocols_communication_for_HMI": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.3,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "3_der_lifecycle_human_involvement": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.15,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "4_system_properties_safety": {
          "score_sum_sub_weighted": 0.0,
          "dimension_weight": 0.1,
          "weighted_score": 0.0,
          "matched_keywords_detail": {}
        },
        "5_general_relevance_quality": {
          "score_sum_sub_weighted": 0.295,
          "dimension_weight": 0.1,
          "weighted_score": 0.0295,
          "matched_keywords_detail": {
            "publication_year": [
              "Year: 2018 (Norm. Score: 0.4)"
            ],
            "citation_count": [
              "Citations: 0 (Norm. Score: 0.2)"
            ],
            "venue_quality": [
              "Assumed Venue Quality (Norm. Score: 0.5)"
            ]
          }
        }
      },
      "source_query_id": "initial_tertiary_9",
      "dynamic_step": 0,
      "core_id": 18930523,
      "doi": "10.1111/bjir.12419"
    }
  ]
}