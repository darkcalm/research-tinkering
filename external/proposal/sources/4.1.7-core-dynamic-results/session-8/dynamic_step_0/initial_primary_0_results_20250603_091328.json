{
  "totalHits": 20416,
  "limit": 10,
  "offset": 0,
  "results": [
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Qian, Y"
        },
        {
          "name": "Sharif, H"
        },
        {
          "name": "Tipper, D"
        },
        {
          "name": "Yan, Y"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/12211338"
      ],
      "createdDate": "2013-07-19T16:53:52",
      "dataProviders": [
        {
          "id": 457,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/457",
          "logo": "https://api.core.ac.uk/data-providers/457/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "A communication infrastructure is an essential part to the success of the emerging smart grid. A scalable and pervasive communication infrastructure is crucial in both construction and operation of a smart grid. In this paper, we present the background and motivation of communication infrastructures in smart grid systems. We also summarize major requirements that smart grid communications must meet. From the experience of several industrial trials on smart grid with communication infrastructures, we expect that the traditional carbon fuel based power plants can cooperate with emerging distributed renewable energy such as wind, solar, etc, to reduce the carbon fuel consumption and consequent green house gas such as carbon dioxide emission. The consumers can minimize their expense on energy by adjusting their intelligent home appliance operations to avoid the peak hours and utilize the renewable energy instead. We further explore the challenges for a communication infrastructure as the part of a complex smart grid system. Since a smart grid system might have over millions of consumers and devices, the demand of its reliability and security is extremely critical. Through a communication infrastructure, a smart grid can improve power reliability and quality to eliminate electricity blackout. Security is a challenging issue since the on-going smart grid systems facing increasing vulnerabilities as more and more automation, remote monitoring/controlling and supervision entities are interconnected. \u00a9 1998-2012 IEEE",
      "documentType": "research",
      "doi": "10.1109/surv.2012.021312.00034",
      "downloadUrl": "https://core.ac.uk/download/12211338.pdf",
      "fieldOfStudy": "computer science",
      "fullText": "IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION 1A Survey on Smart Grid CommunicationInfrastructures: Motivations, Requirements andChallengesYe Yan, Yi Qian, Hamid Sharif, and David TipperAbstract\u2014A communication infrastructure is an essentialpart to the success of the emerging smart grid. A scalableand pervasive communication infrastructure is crucial in bothconstruction and operation of a smart grid. In this paper,we present the background and motivation of communicationinfrastructures in smart grid systems. We also summarize majorrequirements that smart grid communications must meet. Fromthe experience of several industrial trials on smart grid withcommunication infrastructures, we expect that the traditionalcarbon fuel based power plants can cooperate with emergingdistributed renewable energy such as wind, solar, etc, to reducethe carbon fuel consumption and consequent green house gassuch as carbon dioxide emission. The consumers can minimizetheir expense on energy by adjusting their intelligent homeappliance operations to avoid the peak hours and utilize therenewable energy instead. We further explore the challenges for acommunication infrastructure as the part of a complex smart gridsystem. Since a smart grid system might have over millions ofconsumers and devices, the demand of its reliability and securityis extremely critical. Through a communication infrastructure, asmart grid can improve power reliability and quality to eliminateelectricity blackout. Security is a challenging issue since theon-going smart grid systems facing increasing vulnerabilities asmore and more automation, remote monitoring/controlling andsupervision entities are interconnected.Index Terms\u2014Smart grid, communication infrastructure, in-telligent network, interconnected power system, monitoring,sensing, cyber securityI. BACKGROUNDSMART grid is a term referring to the next generationpower grid in which the electricity distribution and man-agement is upgraded by incorporating advanced two-waycommunications and pervasive computing capabilities for im-proved control, efficiency, reliability and safety. A smart griddelivers electricity between suppliers and consumers usingtwo-way digital technologies. It controls intelligent appliancesat consumers\u2019 home or building to save energy, reduce costand increase reliability, efficiency and transparency [1]. Asmart grid is expected to be a modernization of the legacyelectricity network. It provides monitoring, protecting andoptimizing automatically to operation of the interconnectedelements. It covers from traditional central generator and/orManuscript received 25 April 2011; revised 23 January 2012.Y. Yan, Y. Qian, and H. Sharif are with the Department of Com-puter and Electronics Engineering, University of Nebraska-Lincoln (e-mail:yqian@ieee.org).D. Tipper is with the Graduate Telecommunications and NetworkingProgram, University of Pittsburgh.Digital Object Identifier 10.1109/SURV.2012.021312.00034emerging renewal distributed generator through transmissionnetwork and distribution system to industrial consumer and/orhome users with their thermostats, electric vehicles, intelligentappliances [2]. A smart grid is characterized by the bi-directional connection of electricity and information flowsto create an automated, widely distributed delivery network.It incorporates the legacy electricity grid the benefits ofmodern communications to deliver real-time information andenable the near-instantaneous balance of supply and demandmanagement [3].Many technologies to be adopted by smart grid havealready been used in other industrial applications, such assensor networks in manufacturing and wireless networks intelecommunications, and are being adapted for use in newintelligent and interconnected paradigm. In general, smart gridcommunication technologies can be grouped into five keyareas: advanced components, sensing and measurement, im-proved interfaces and decision support, standards and groups,and integrated communications.Figure 1 illustrates a general architecture for smart gridcommunication infrastructures, which includes home areanetworks (HANs), business area networks (BANs), neigh-borhood area networks (NANs), data centers, and substationautomation integration systems [4]. Smart grids distribute elec-tricity between generators (both traditional power generationand distributed generation sources) and end users (industrial,commercial, residential consumers) using bi-directional infor-mation flow to control intelligent appliances at consumers\u2019side saving energy consumption and reducing the consequentexpense, meanwhile increasing system reliability and opera-tion transparency. With a communication infrastructure, thesmart metering/monitoring techniques can provide the real-time energy consumption as a feedback and correspond tothe demand to/from utilities. Network operation center canretrieve those customer power usage data and the on-linemarket pricing from data centers to optimize the electricitygeneration, distribution according to the energy consumption.In a complex smart grid system, through wide deploymentof new smart grid components and the convergence of existinginformation and control technologies applied in the legacypower grid, it can offer sustainable operations to both utilitiesand customers [5]. It can also enhance the efficiency of legacypower generation, transmission and distribution systems andpenetrate the usage of clean renewable energy by introducingmodern communication systems into smart grids.1553-877X/12/$25.00 c\u00a9 2012 IEEEThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.2 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONFig. 1. Smart Grid Communication Infrastructures [4]The cornerstone of a smart grid is the ability for multipleentities (e.g. intelligent devices, dedicated software, processes,control center, etc) to interact via a communication infrastruc-ture. It follows that the development of a reliable and per-vasive communication infrastructure represents crucial issuesin both structure and operation of smart grid communicationsystems [6], [7]. In this connection, a strategic requirementin supporting this process is the development of a reliablecommunication infrastructure for establishing robust real-timedata transportation through Wide Area Networks (WANs) tothe distribution feeder and customer level [8].Existing electrical utility WANs are based on a hybridof communication technologies including wired technologiessuch as fiber optics, power line communication (PLC) sys-tems, copper-wire line, and a variety of wireless technolo-gies (i.e. data communications in cellular networks suchas GSM/GPRS/WiMax/WLAN and Cognitive Radio [9]).They are designed to support some monitoring/controllingapplications as Supervisory Control and Data Acquisition(SCADA)/Energy Management Systems (EMS), DistributionManagement Systems (DMS), Enterprise Resource Plan-ning (ERP) systems, generation plant automation, distributionfeeder automation and physical security for facilities in widerange areas with very limited bandwidth and capacity in closednetworks.Many applications such as energy metering on the smartgrid, have emerged from a decade of research in wirelesssensor networks. However, the lack of an IP-based networkarchitecture precluded sensor networks from interoperatingwith the Internet, limiting their real-world impact. The IETFchartered the 6LoWPAN and RoLL working groups to specifystandards at various layers of the protocol stack with thegoal of connecting low-power devices to the Internet. In [10]the authors present the standards proposed by these workinggroups, and describe how the research community activelyparticipates in this process by influencing their design andproviding open source implementations.The new communication infrastructures should evolve to-ward nearly ubiquitous data transport networks able to han-dle power delivery applications along with vast amount ofnew data coming from the smart grid applications. Thesenetworks should be scalable, in order to support the presentand the future set of functions characterizing the emergingsmart grid communication technological platform, and highlypervasive in order to support the deployment of last-milecommunications (i.e. from a backbone to the terminal cus-tomers locations) [11]. In the rest of this section, we discussseveral key factors for smart grid systems including power linecommunications, distributed energy resources, smart metering,and monitoring and controlling.A. Power Line CommunicationsPower line communications (PLCs) uses the power feederline as communication media. First generation ripple controlsystems provide one-way communications, in which central-ized load control and peak shaving have been performedfor many years. The European standards body CENELECrestricted the use of frequencies between 3 kHz and 95 kHzfor two-way communications for electricity distributor use.A number of second generation PLC systems with low datarates were proposed in the 1990\u2019s, and Automatic MeterReading systems have been deployed based on this technology.Third generation systems based on OFDM with much higherdata rates are currently being developed and deployed forSmart Grids, Distribution Automation and Advanced MeteringManagement [12].With the development of smart grids, the PLC on thepower transmission and distribution networks have becomeone of the potential technologies to exchange the informationbetween the end users and the utilities. In order to providecommunication services with different priorities under thesmart grid environment, it is a must to design a PLC systemwith variable data rates supported, which means understandingof the PLC physical channel characteristics become vital. Thetesting results in [13] show that the main reason influencingthe reliable communication of high-speed data on power lineis the attenuation of the high-frequency signal, which exhibitsmore obviously in the branch of power line. It is almostimpossible to use the frequency range from 10 to 20 MHzfor the reliable communications from distribution transformerto end user, so it must be solved with the aid of means suchas the repeater and the modulation schemes.Beside the fact that feeder cables are not designed fordata transmission, they are also prone to be interfered bythe inverter\u2019s outcome. Therefore, PLC modems developedfor domestic applications may not be suitable. Limitationsand difficulties that obstruct transmission are revealed in [14].Also, it underlines the possibility of communicating in suchan environment and discusses the possible solutions such asthe use of a pulsewidth modulation filter to overcome thoselimitations.The majority of recent contributions have discussed PLC forhigh-data-rate applications like Internet access or multimediacommunication serving a relatively small number of users.However, it lacks the consideration with PLC as an enabler forsensing, control, and automation in large systems comprisingtens or even hundreds of components spread over relativelywide areas. In [15], the authors discussed communicationnetwork requirements common to such systems and presentedtransmission concepts for PLC to make use of the existingThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 3power transmission and/or distribution infrastructure resources(i.e., power lines) to meet these requirements. In [16] theauthors give an overview of DLC+VIT4IP (Distribution LineCarrier: Verification, Integration and Test of PLC Technologiesand IP Communication for Utilities), a EU funded projectunder the 7th Framework Programme (FP7) that aims toextend the existing PLC technologies by developing efficienttransport of IPv6 protocol, automatic measurement, configu-ration and management, and security. In addition, the projectDLC+VIT4IP also exploits frequency ranges up to 500 kHz,to support systems serving larger smart grid applications.B. Distributed Energy ResourcesThe legacy power generation and transmission concept isconverting to a massively distributed energy generation land-scape integrating an extensive number of variable and smallrenewable energy resources (DERs) such as wind [17]\u2013[19],solar [20]\u2013[22] installations with all their challenging effectson the smart grid.MetaPV [23] is a project demonstrated theprovision of electrical benefits from photovoltaics (PV) on alarge scale, showing the way toward cities powered by renew-able energy sources. The project also demonstrates enhancedcontrol capacities implemented into PV inverters, includingactive voltage control, low-voltage ride-through capability,autonomous grid operation, and interaction of distributionsystem control with PV systems. Smart control should enablean increase of the PV penetration in existing power grids andpromote the use of more renewable energy sources in citiesand industries at minimum additional investment costs. TheMetaPV project is funded by the European Commission inthe 7th Framework Programme, which consists of six partnersfrom four EU countries.New stakeholders (e.g. energy resource aggregators), moreflexibility for the consumers (energy market place), and totallynew concepts (loading of Electric Vehicles (EVs), usage ofEVs as flexible power storage) have to be respected. Innovativemonitoring and control concepts are required to operate thesedistributed energy resources in a reliable and safe way, so thecommunication technologies must support it. A key require-ment for facilitating the distributed production of future gridsis that communication and information are standardized toensure interoperability. For example, the IEC 61850 standard,which was originally aimed at substation automation, has beenexpanded to cover the monitoring and control of DERs. Byhaving a consistent and well-defined data model the standardenables a DER aggregator, such as a Virtual Power Plant(VPP), in communicating with a broad array of DERs. Ifthe data model of IEC 61850 is combined with a set ofcontemporary web protocols, it can result in a major shiftin how DERs can be accessed and coordinated. [24] describeshow IEC 61850 can benefit from the REpresentational StateTransfer (REST) service concept and how a server using thesetechnologies can be used to interface with DERs as diverse asEVs and micro Combined Heat and Power (\u00b5CHP) units.There are some works (e.g., [25]\u2013[27]) in integrating DERgeneration into the traditional centralized carbon fuel basedgeneration power grid. These energy sources include biomassetc. A key observation made in [25] is that existing powergrids were designed in a one-direction radial mode withoutconsidering the communication with the emerging distributedrenewable resource generation. In [26] it discussed the broaderimplications of the social acceptance of these new energy gen-eration technologies, as they represent a significant departurefrom incumbent approach of traditional monolithic large scaleenergy generation. In addition, the implications of regulatoryand economic factors also contribute to potential take-up andvarious deployment models to increase the adoption of thesedistributed renewable resource generators [27].Every DER includes an Electronic Power Processor (EPP)to govern the power exchange with the smart grid andSwitching Power Interface (SPI) to control the currents drawnfrom the smart grid. Such distributed EPPs and SPIs shouldperform cooperatively to take full advantage of smart gridpotentiality (exploitation of renewable energy sources, powerquality and transmission efficiency). To achieve this goal dif-ferent approaches can be adopted, depending on the availablecommunication capability. In [28] it discussed various controlsolutions applicable in absence of supervisory control, e.g.,in residential micro-grids, where communication is possiblebetween neighbor units only (surround control) or is notavailable at all (plug & play control). In micro-grids, wherenumber and type of DERs and loads is unpredictable and mayvary during time, cooperative operation can be achieved bysimple cross-communication among neighbor EPPs, withoutcentralized supervisor. In [29], it describes principles of co-operative operations with existing information and communi-cation architectures, which allows exploitation of micro-gridcapabilities without additional infrastructure investments.C. Smart MeteringThe Advanced Metering Infrastructure (AMI) is a key factorin the smart grid which is the architecture for automated,two-way communications between a smart utility meter and autility company. A smart meter is an advanced meter whichidentifies power consumption in much more detail than a con-ventional meter and communicates the collected informationback to the utility for load monitoring and billing purposes.Consumers can be informed of how much power they areusing so that they could control their power consumptionand the consequent carbon dioxide emission. By managingthe peak load through consumer participation, the utility willlikely provide electricity at lower and even rates for all.AMI has already gained great attraction within the industry,with the advantages in accuracy and process improvement ofon-line meter reading and control. In [30], additional benefitsare suggested to be gained in managing power quality andasset management with AMI. This paper also discussed howreliability, operational efficiency, and customer satisfaction canbe addressed with an AMI deployment. However, the benefitsof AMI are countered by increasing cyber security issues [31].The technologies require a communication infrastructure toprovide interconnectivity. Hence, the vulnerabilities that ex-pose other internetworking systems will ultimately lead tosecurity threats to AMI systems.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.4 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIOND. Monitoring and ControllingSCADA systems have been implemented to monitor andcontrol electrical power grids for decades. The industrialexperience shows that practical deployment of SCADA basedsystems may restrict it to the high voltage transmission net-works only. In [32] the authors made the observation thatexisting monitoring and control systems are restricted to the(high-voltage) transmission network and not suitable for largerscale monitoring and control of the entire electrical grid. Adistributed monitoring control system is proposed to managethe power grid. A grid computing solution is proposed toaddress these monitoring control needs and the results of theresearch for an off-line test environment is discussed. Thekey motivations also include the need to support sustainableand renewable energy source at the micro-generation level. AsSCADA systems evolve, there is much interest in exploringthe security vulnerabilities posed to these systems over com-munication network and/or internet technologies [33]\u2013[35].In [36], the solution applies existing Information andCommunication Technology (ICT) systems in a hierarchi-cal decomposition of the power grid into logical zones formonitoring and control. It outlines the impact to the controlcenter responsible for management and control of the electricalnetwork. It also proposes a framework for future control centerin order to monitor and manage the smart grid. The EUFP6 project ADINE [37] is based on the Active NetworkManagement (ANM) concept, where automation, ICT andpower electronics are used to integrate more distributed gener-ators by exploiting active resources instead of just reinforcingthe network. The resources are mobilized through ancillaryservices or requirements. Five enabling solutions within ANMare pushed forward in the project: Protection relay and faultlocation applications, coordinated protection planning, voltagecontrol with microturbine, centralized voltage control withSCADA/DMS.The rest of this paper is organized as follows: the keymotivations of smart grid communication infrastructures arediscussed in section II. Several industrial trials are shown insection III. The detailed requirements are presented in sectionIV. The challenges are discussed in section V. Conclusions aredrawn in section VI.II. MOTIVATIONSIn this section, we briefly highlight the key motivationsof communication infrastructures in smart grid systems. Asillustrated in Figure 2, the motivations are related to system,operation and environment aspects in emerging smart gridparadigm through communication infrastructures [38].A. Enhanced Customer ExperienceA key objective for communication infrastructures in smartgrid systems is to improve service reliability and quality tocustomers which includes reduced outage times when a powersystem is interrupted, improved notification of electricity net-work problems and providing customers with proper optionsand tools to understand and optimize their energy usage tocurtail the peak-hour usage to avoid power quality degradationor blackout [39].EnvironmentSystemOperationEnhanced Customer ExperienceIncreased ProductivityImproved UtilizationLower Carbon Fuel Consumption/Greenhouse Gas EmissionFacilitated Renewable Resource GenerationAdherence to Regulatory ConstraintsCommunication InfrastructureFig. 2. Motivations of Smart Grid Communication Infrastructures [38]B. Increased ProductivityIntelligent performance information and tools will allowutilities to undertake their current duties in a more efficientmanner, with longer term benefits coming from automatingthe smart grid. These gains in productivity will help to reducedeployment costs and operational costs in managing the smartgrid system [40].C. Improved UtilizationThe communication infrastructure in smart grid will pro-vide detailed real-time data on distributed energy generation,electricity transmission, power consumption and market price.This information allows the utility operators to improve theirdecision making processes by identifying which componentsare likely to fail and the replacement strategy online [41].D. Lower Carbon Fuel Consumption/Greenhouse Gas Emis-sionA smart grid has the potential to reduce electricity lossesin the network and limit growth in demand, due to embeddedmonitoring of the high, medium and low voltage networksthrough communication infrastructures, therefore, lower car-bon fuel consumption and greenhouse gas emission [42].E. Facilitated Renewable Resource GenerationA smart grid will enable options for renewable generationand provide customers with the awareness and capabilities toreduce their energy consumption on carbon fuel based power[43].F. Adherence to Regulatory ConstraintsNew regulatory demands include provisions for increasedlevels of asset data tracking (cost justification), and greaterreliability targeting the implementation of communicationinfrastructure in smart grid [44].This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 5Fig. 3. Energy Web Infrastructure [45]III. CASE STUDIESThe industry has recently undergone a significant trans-formation of their ICT systems to support both current andfuture business models of smart grid operations. Moreover,the power industry is transforming from the traditional modelsof business to embrace a number of new and enhancedtechnologies that support future smart grid operations. Thissection summaries several smart grid industry projects whichinclude energy web infrastructure for power generation andelectricity market information exchange, smart metering in-frastructure which support monitoring and retrieving bothreal-time and historical data, smart community for real-timepower consumption monitoring and managing, ZigBee-basedrecording system with capability for consumers to view andmanage their power consumption online, and future controlcenter for power generation and distribution managing anddeciding between utilities through public networks such asinternet.A. Energy WebThe increasing electricity demand and sustainable devel-opment of renewable energy resources offer opportunitiesfor both utilities, brokers, customers to participate into thedevelopment of the emerging energy web. The basic idea ofenergy web is to use the Internet to gain bandwidth, reliabilityand interconnection for the smart grid. It realizes the on-demand and demand response in local area by establishingthe balance of power generation and consumption.In Figure 3, each power generator is interconnected withan adapted power supplier which has the proper capability ofinterpreting the real-time price signal received from the energyweb infrastructure [45]. In order to match the consumption andgeneration, the participant strategy is adapted. In the powermarket model, each electricity user has option to become apower generator. The electricity price is generated real-timeand sent to every participants by utility operators using thesmart grid communication infrastructure from the electricitymarket. The electricity flows generated by the participantsare monitored in real-time mode by utility operators whoalso operate the real-time metering infrastructures such asautomatic meter reading (AMR) or AMI for establishingthe energy demand and supply balance. While the historicalrecords of both the power consumption and generation withtheir corresponding price are periodically sent to the relatedoffices of the participants for financial settlement.B. Smart Metering and InfrastructureBC Hydro [46] is launching a smart metering and infras-tructure (SMI) program. A multi-level common and integratedcommunication infrastructure to enable grid modernizationis planned as illustrated in Figure 4. That means the com-munication infrastructure will not only support automatedmeter readings, customer home appliance connections, butalso future distribution automation, substation automation andpossibly mobile workforce management and other advancedapplications which utilities could envision in the life span (20years) of AMI infrastructure. This conforms to the industryvision of integrating communication and IT networks with thepower delivery system, in order to provide system sensing andcontrol capability [47].This long term vision raises several key questions: Howmuch data traffic will flow in the network and how muchbandwidth should be planned for the communication network,especially for the wide area communication network? Howmuch of the legacy communication network for system controlpurposes (e.g., SCADA system) can be leveraged to deliver acost effective solution? These questions are addressed basedThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.6 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONFig. 4. High Level Common Communication Infrastructure Architecture [47]on the expected new applications and with communicationand control technology development and system life cycle costminimization in mind.C. Smart CommunityA smart community trial deploys automated metering de-vices into customer\u2019s household. It may include gas, waterand electricity automated metering. The smart communitytrial provides customers new tools to manage their energyconsumption hence reduce the related carbon footprint.Figure 5 provides an overview of the components. Thetrial involves the deployment to the scale of 1,000 housesthat communicate using WiMax to several IT systems whichmanage the reading of water, gas, and electricity. Customerscan access to an information portal via Home Area Networks(HAN). This may be accessed by an in-house display panelor the software based interfaces via the PDA, smart phone orhome personal computer.The home energy consumption is monitored by those ap-pliances enabled with intelligent chips which may support theremote control of appliances operation from Internet. Supportfor electrical vehicles will also be provided for home. The datagathered from this trial can be made available further to thepublic, universities, and researchers for the energy efficiencyand environmental protection.The detailed data on measurements, events, and faults canbe viewed in an example in [48]. In order to retrieve thehistorical measurement data, the solution will be able todisplay the topology of network at selected historical timepoints. While the high voltage transmission network is usuallyFig. 5. Smart Community: Automated Metering Infrastructure [48]static in terms of its network configuration, the medium andlow voltage networks are considerably more volatile. Hence,such a historical network view will provide further input tothe central control to assist in diagnosing network faults, andwill also assist operators and engineers in the design of thesmart grid communication infrastructure.D. A ZigBee-Based Recording SystemZigBee has been designed as a low-cost and low-power-consumption wireless communication standard by ZigBeeThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 7Fig. 6. System Architecture of a ZigBee-based Smart Meter RecordingSystem [53]Alliance [49]. The ZigBee application profile includes homeautomation, industrial plant monitoring, commercial build-ing automation, automatic meter reading, telecom servicese-commerce, wireless sensor networks, personal and home areanetworks [50]\u2013[52].A smart power-meter and a back-end processing systemare proposed in [53] to be equipped with ZigBee devicesand ZigBee coordinators respectively. With the automaticnetworking characteristic of ZigBee, smart power meter serv-ing as a node apparatus will communicate with the ZigBeecoordinator of rear-end processing system and ZigBee networkcan then be constructed to accomplish the meter-readingfunction. After the ZigBee network was constructed, the rear-end processing system can send the request commands to theZigBee coordinators and receive the power consumption dataand outage event data from the power meters. Therefore, theautomatic meter reading can be accomplished. The conceptof the proposed outage recording system is illustrated inFigure 6 while an example of real-time data acquisition isshown in [53].E. Future Control CenterIn [54], the authors proposed a vision to design and developthe next-generation monitoring, analysis, and control technolo-gies to move the industry towards a smarter transmission grid.As shown in Figure 7, the vision for future control centers,also referred to as smart control centers, can be a critical partof the overall framework of the future smart grid. This visionhas five key characteristics as discussed in the following.1) Human-Centered Online Monitoring: Human-centeredis the key characteristic of the next-generation monitoringfunctions in the future smart control centers. In this context,human-centered has two meanings: information-directed andcustomized. The next generation monitoring functions shallprovide operators useful information rather than raw data.With more and more deployment of monitoring devices (e.g.,equipment health sensors), it now has more data available tohelp system operators monitor the power system conditionin real time. However, more data does not necessarily meanmore information. We need to transform the huge volume ofdata into useful information. It is the operators responsibilityto define what information is needed. Since the informationis presented to system operators who are human beings,the monitoring functions shall employ advanced visualizationtechniques with the goal of helping each operator to digestinformation quickly.2) Comprehensive Online Analysis: The next-generationonline analysis functions shall help system operators deter-mine comprehensive operating boundaries in real time. Com-prehensive operating boundaries include both thermal limitsand stability (voltage stability and transient stability) limits.The next-generation online analysis functions shall ap-ply a comprehensive approach to help system operators de-termine the operating boundaries. Comprehensive approachmeans combination of a simulation-based approach and ameasurement-based approach.3) From Reactive Analysis to Proactive Analysis: Thepresent online analysis is based on the current operatingcondition. This does not consider future system conditions.In the future, online analysis shall take a proactive approachto perform look-ahead simulation on the future system condi-tions.The integration of renewable energy sources will introducemore uncertainties into the power system. With the abilityto foresee potential problems, the next-generation proactiveonline analysis will optimize resources (such as demandresponse and energy storage) in order to improve reliabilityand achieve economic operation.By enabling sufficient foresight, the next-generation anal-ysis functions allow system operators to take a proactiveapproach to develop optimal control strategies and mitigationplans.4) From Isolated Protection and Control Strategy to Coor-dinated Protection and Control Strategy: Traditionally, eachcontrol scheme is designed to solve a particular problem.The parameters were developed based on offline simulationsand largely remain fixed. There is a lack of coordinationamong protection and control systems. As modern powersystems have become more interconnected with increasingstress levels, each disturbance may cause multiple protectionand control schemes to respond. There may exist negativeinteractions that can worsen system conditions, which presentchallenges and risks in system operations.When a power system experiences a disturbance, the nextgeneration coordinated protection and control systems willperform according to the optimal control strategies developedby online security assessment and shall quickly bring thesystem to a stable operating condition with minimum controlefforts.5) Self-Healing System Control: The current restorationplans are developed through offline studies based on as-sumptions regarding likely scenarios. However, the restorationstrategy developed from such studies may not work wellThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.8 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONFig. 7. Scopes of Future Control Center [54]following a blackout because the real operational situation mayvary from the assumed scenarios.When part or all of the power system is blacked out, thenext generation self-healing control scheme shall effectivelyrestore the system and bring it back to a normal operatingcondition.IV. REQUIREMENTSMonitoring/sensing, communication and control are thethree fundamental building blocks that will convert a powerdistribution system into a smart grid. Monitoring/sensing willhave the ability to detect malfunctions or deviations fromnormal operational ranges that would warrant actions. Further,since in a smart grid, a point of electricity consumption canalso become a point of generation, the sensing process willbe closely linked with the metering process. Communicationswill allow inputs from sensors to be conveyed to the control el-ements in the smart grid which will generate control messagesfor transmission to various points in the smart grid resultingin appropriate actions. The communication infrastructure hasto be robust enough to accept inputs from a user and make itan integral part of the process. By the same token, the usermust be capable of getting the appropriate level of informationfrom the smart grid. The major requirements for smart gridcommunication infrastructures are discussed in the rest of thissection.A. QoSIn order to realize a practical smart grid communicationinfrastructure, it is necessary to have guaranteed Quality ofService (QoS) for the communication and networking tech-nology used in the smart grid, ranging from power generation,transmission, distribution, to the customer applications.1) Latency: The real-time operational data communicationsin smart grid include online sensor/meter reading and powersystem control signals. The communication is characterizedby the fact that most of interactions must take place in realtime, with hard time bound. The communication require-ments define the design of the technical solutions. For real-time sensing/metering purposes, reading messages should betransmitted within a very short time frame. For instance, themaximum allowed time is in the range of 12-20 ms, dependingon the type of protection scheme which origins from thefact that the disconnection of fault current should withinapproximately 100 ms. Power System Control signals mainlyinclude supervisory control of the power process on secondaryor higher levels. These systems are of the kind SCADA/EMS.Measured values must not be older than 15 seconds, whenarriving at the control center. Breaking information shallarrive no later than 2 seconds after the emergency event hasoccurred [55].2) Bandwidth: As more and more interconnected intelli-gent elements are added to the electricity network with theevolution of the smart grid, the communication infrastruc-ture should be able to transport more and more messagessimultaneously without severe effect on latency. The networkbandwidth must increase faster than the demand of theseinterconnected intelligent elements in the network.C. H. Hauser et al. concluded in [56] that a 10 millisecondaverage latency for a 400 bit message using a T1 line willresult in a utilization of only 6% of the T1 bandwidth. In [55]the authors modeled the communication bandwidth require-ments for a moderate size electricity distribution system. Inthis model, a distribution substation is connected to 10,000feeders and each feeder connects to 10 customers. Assumingthat every electric meter generates a message every secondto the distribution substation, the total is 100,000 messagesper second. The feeders themselves will generate messagesto each other and to the distribution substation. The authorsin [55] modeled the messages in the smart grid arriving atservers located at the control center as M/M/1 traffic. Then,the transmission line bandwidth is evaluated over 100 Mbpsthrough the M/M/1 queuing model. It can be observed that thissituation results in a very poor bandwidth utilization of thetransmission facilities as well. Unfortunately, a higher levelof utilization will not permit meeting the assumed latencyconstraint.B. InteroperabilityInteroperability of a smart grid is the ability of diversesystems to work together, use the compatible parts, exchangeinformation or equipment from each other, and work coop-eratively to perform tasks. It enables integration, effectivecooperation, and two-way communications among the manyinterconnected elements of the smart grid. The National Insti-tute for Standards and Technology (NIST) works as the firstInternational Coordinator for smart grid interoperability [57].NIST developed a framework that includes protocols andstandards for information management to achieve interoper-ability of smart grid devices and systems [58]. NIST hasdeveloped a three phase approach to identify smart grid stan-dards. Phase 1 addresses the engagement of stakeholders ina participatory public process to identify applicable standardsand gaps in currently available standards and priorities for newstandardization activities, ending with the final publication ofthe framework report after public comments have been incor-porated. Phase 2 will establish a private-public partnership andform a smart grid interoperability panel to drive longer-termprogress. Phase 3 will develop and implement a frameworkfor testing and certification of how standards are implementedin smart grid devices, systems, and processes.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 9Fig. 8. NIST Conceptual Model [59]As illustrated in Figure 8, the NIST conceptual referencemodel identifies seven domains as bulk generation, trans-mission, distribution, markets, operations, service providers,and customers and major actors and applications within each.The reference model also identifies interfaces among domainsand actors and applications over which information mustbe exchanged and for which interoperability standards areneeded.For years, the utility industry has been using optical portcommunications, defined by ANSI C12.18, and telephonemodem communications, defined by ANSI C12.21, to getmetering data, defined by ANSI C12.19, from the field tothe back office. While the two communication standards havebeen employed to great success, the missing was a standardmethod for using true network communications for exchangingthe data. Recent work has completed by ANSI C12.22, astandard for interfacing the data communication networks, aswell as updating the optical port and modem communicationstandards. This set of standards offers the industry an open andcomprehensive protocol suite to transport the newly reviseddata standard, ANSI C12.19 [60].C. ScalabilityA smart grid communication infrastructure needs the scala-bility of accommodating more and more devices and servicesinto it and more end-user interaction real-time monitoringof energy meters. As discussed by Lobo et al. [61], anIP-based network will provide an effective solution for thecommunication needs of the smart grid. An IP-based networkas the backbone makes use of new technologies independent ofthe service implemented by the distributed network operator.The cost of deployment and maintenance can be reducedsignificantly using IP-based technologies.D. SecurityAccording to the Electric Power Research Institute (EPRI),one of the emergent requirements facing the smart grid devel-opment is related to cyber security of systems. As indicatedin the EPRI report [62], cyber security is a critical issuedue to the increasing potential of cyber attacks and incidentsagainst this critical sector as it becomes more and moreinterconnected. Cyber security must address not only delib-erate attacks, such as from disgruntled employees, industrialespionage, and terrorists, but also inadvertent compromises ofthe information infrastructure due to user errors, equipmentfailures, and natural disasters. Vulnerabilities might allowan attacker to penetrate a network, gain access to controlsoftware, and alter load conditions to destabilize the grid inunpredictable ways.There are many organizations working on the developmentof smart grid security requirements including North Amer-ican Electrical Reliability Corporation-Critical InfrastructureProtection (NERC-CIP), ISA, IEEE (1402), the National In-frastructure Protection Plan (NIPP), and NIST [63].One prominent source of requirements is the Smart GridInteroperability Panel (SGiP) Cyber Security Working Group,previously NIST Cyber Security Coordination Task Group(CSCTG). NIST CSCTG was established to ensure the con-sistency in the cyber security requirements across all thesmart grid domains and components. The draft document fromthe CSWG, NIST interagency Report (NIST IR) 7628 [64],continues to evolve. NIST and DoE Gridwise ArchitectureCouncil (GWAC) [65] has established Domain Expert WorkingGroups (DEWGs) [66]: Home-to-Grid (H2G), Building-to-Grid (B2G), Industrial-to-Grid (I2G), Transmission and Dis-tribution (T&D) and Business and Policy (B&P). Furthermore,many other standards may apply, including ISO 17799 [67],FIPS 201 [68], other NIST SPs, and DISA Security TechnicalImplementation Guides (STIGs) [69]. Working with standardsbodies, such as NIST and others, will be extremely importantto ensure a highly secure, scalable, consistently deployedsmart grid communication system, as these standards bodieswill drive the security requirements of the smart grid commu-nication systems [70].One thing is consistent among the various standards bodies:the security of the smart grid communications will stronglydepend on authentication, authorization, and privacy technolo-gies. Privacy technologies are well matured. Federal Infor-mation Processing Standard (FIPS) has approved AdvancedEncryption Standard (AES) and Triple Data Encryption Algo-rithm (3DES) solutions, offering strong security and high per-formance, are readily available. The specific privacy solutionsrequired will depend on the type of communication resourcebeing protected. As a specific example, NIST has determinedthat 3DES solution will likely become insecure by the year2030. Considering that utility components are expected to havelong lifetimes, AES would be the preferred solution for newcomponents. However, it is expected the legacy functionalitysuch as 3DES must be supported for system compatibility,therefore there is a risk of compromising the system [71].Wireless links will be secured with technologies from wellknown standards such as 802.11i [72] and 802.16e [73].Different wireless protocols have varying degrees of securitymechanisms. Wired links will be secured with the technologiessuch as firewalls, virtual private networks (VPN) and IPSec.Higher layer security mechanism such as Secure Shell (SSH)and Security Socket Layer (SSL)/Transport Layer Security(TLS) should also be used. System architects and designersoften identify the need for and specify the use of secureprotocols, such as SSH and IPSec, but then skip the detailsassociated with establishing security associations between endpoints of communications. Such an approach is likely to resultin a system where the necessary procedures for secure keymanagement can quickly become an operational nightmare. ItThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.10 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONis due to the fact that, when system architects do not developan integrated and comprehensive key management scheme,customers may be provided with few key management options,and often resort to manually pre-configuring symmetric keys.This approach is simple for the system designers, but it canbe very expensive for the system owner/operator.What has been learned from years of deploying and oper-ating large secure network communication systems is that theefforts required to provision symmetric keys into thousandsof devices can be too expensive or insecure. The developmentof key and trust management schemes for large networkdeployments is required; these systems can be leveraged fromother industries, such as mobile radio systems and Associa-tion of Public-Safety Communications Officials (APCO) radiosystems. Several APCO-deployed systems provide statewidewireless coverage, with tens of thousands of secure de-vices [74]. Trust management systems, based on public-keyinfrastructure (PKI) technology, could be customized specifi-cally for smart grid operators, easing the burden of providingsecurity which adheres to the standards and guidelines that areknown to be secure.All of the above technologies rely on some sort of keymanagement. Considering that the smart grid will containmillions of devices, spread across hundreds of organizations,the key management systems used must be scalable to ex-traordinary levels. Further, key management must offer strongsecurity (authentication and authorization), inter-organizationinteroperability, and the highest possible levels of efficiencyto ensure that unnecessary cost due to overhead, provisioning,and maintenance are minimized. It is likely that new keymanagement systems (specialized to meet the requirementsof smart grid) will be needed.E. StandardizationThe smart grid involves various standards in many fieldssuch as power generation, delivery and control besides com-munications. IEEE has recently taken the initiative to definethese standards and write guidelines on how the smart gridshould operate using the latest technology in power engi-neering, control, communications, and information technology.The standards group that was created is known as the IEEEP2030 group [75]. Three task forces were formed to tackle dis-tribution systems including the integration of different energysources, transmission substations, load side requirements, andcyber security. These task forces will focus on power engineer-ing technology, information technology, and communicationtechnology. The power engineering technology group willwork on the functional requirements of interoperability, draw-ing on various existing and ongoing efforts by groups such asInternational Society of Automation (ISA) and InternationalElectrotechnical Commission (IEC). IEC TC57 WG13 [76]is currently drafting the new international standards for usein improving overall transmission grid reliability and security.This work directly supports the NIST smart grid interoperabil-ity.The information technology group will look at the issuesof privacy, security, data integrity, interfaces, and interoper-ability. The communication technology group will define thecommunication requirements between devices in the smartgrid and establish boundaries for generation, transmission, anddistribution in conjunction with the customers [77].Implementing standards is a major issue in transitioningtowards advanced sensing/automation, and also is a crucialstep in creating smart grid communication infrastructure. Ascommunication systems in smart grid are usually from differ-ent vendors with their own legacies, which are proprietaryand have no dual interoperability. The identified standardswhich govern the necessary integration of different functionsare specified by IEC.V. CHALLENGESThe proliferation of wireless/wired sensors and communi-cation devices and the emergence of embedded computingrepresents an opportunity to develop applications for con-nected environments in general, and especially managementsystems that address urgent challenges facing the smart gridcommunication infrastructure. The challenges include the de-ployment of large-scale embedded computing, legacy powergrids, intelligent appliances, and next-generation communi-cations and collaborations that will provide the foundationfor a post-carbon society. In this section, we discuss thecontext that gives these challenges urgency as well as thetechnical challenges that need to be addressed by smart gridcommunication infrastructures.A. ComplexityA smart grid communication infrastructure is a systemof systems and it is extremely complex. As a consequence,modeling, analysis and design a suitable communication in-frastructure meet many new challenges. The models to beused must be capable of accounting for uncertainty as away to simulate emerging behavior. The numerical tools toperform the analysis must be capable of solving very largescale problems. In fact, the power system is tightly coupledand non-linear [78] and does not benefit from the sparsity thattypically characterized this problem. The control system andparticularly communication infrastructure must be designedto manage uncertainty and inconsistencies to be resilient orgracefully degrade when necessary. Finally the performancemetric must be adjusted to the new nature of the powersystem. The challenges in modeling the complexity of asmart grid communication infrastructure are summarized inthe following.1) Need to support multi-physics approach: Systems are sotightly interconnected that is not possible to simply simulatethe electrical subsystem [79]2) Need to support multidisciplinary approach: Differentusers will have to work at the same scenario, each of themfocusing on different aspects (control, power flow, communi-cations) [80], [81].3) Need to support dynamic and reconfigurable model leveldefinition: This is probably the most challenging element.While different users interact with the simulation schematicthey need to focus on different details of the system. Thenext generation simulation system should support this processautomatically [82], [83].This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 114) Need to provide high-level graphic visualization to sup-port system: While engineers may want to focus on thedetails of graphs, system analysis requires different types ofvisualization able to synthesize a \u201csystem-picture\u201d [84].5) Need to provide support for uncertainty propagation:Uncertainty is presented in the power system for differentreasons and from various sources. And therefore it is to beaccounted for in the design and in the operation, as it will bedependent on static and dynamic state estimation [85].B. EfficiencyRealization of the future smart grid requires meeting theever increasing efficiency challenges by harnessing moderncommunication and information technologies to enable acommunication infrastructure that provides grid-wide coor-dinated monitoring and control capabilities. Such commu-nication infrastructure should be capable of providing failproof and nearly instantaneous bidirectional communicationsamong all devices ranging from individual loads to the grid-wide control centers including all important equipment at theelectricity distribution and transmission system. This involvesprocessing vast number of data transactions for analysis andautomation. It requires a high performance communicationinfrastructure capable of providing fast intelligent local sub-second responses coordinated with a higher level global anal-ysis in order to prevent or contain rapidly evolving adverseevents [86]. It needs to meet the challenges in the following.1) Better Telemetry: Phasor Measurement Unit (PMU)technology [87] can offer faster, time-stamped, higher ac-curacy and sub-second scanning to enable timely grid-widesituational awareness [87].2) Faster Controls: Based on power electronics, smart gridcommunication infrastructure enables fast automated controlactions, for voltage and power flow management at electricitygeneration, transmission and distribution systems.3) More Robust Controls: Proactive and adaptive adjust-ment of protection and communication settings for wide areamonitoring and controls support intentional islanding, whichis beyond currently employed ad-hoc schemes in systemprotection.4) Embedded Intelligent Device Communications: To en-able adaptive and intelligent communications for device levelfault diagnosis and bad data identification, operations and theconstraints should be prescribed by system operators or controlcenters, intelligent remedial action scheme (RAS)/system pro-tection schemes (SPS), autonomous restoration of equipmentand autonomous local control actions [88].5) Integrated and Secure Communications: Highly dis-tributed and pervasive communications based on open stan-dards allow flexible network configurability to assure fail-proof monitoring and automation for bidirectional communi-cations between all operators and customers.6) Enhanced Computing Capabilities: Fail-proof and se-cure communication systems for reliable analysis supportoperator decisions and autonomous intelligent agents a geo-graphically and temporally coordinated hierarchy through thegrid-wide communication infrastructure [89].7) Internet Technology: Internet protocols to facilitate dataexchange, process control and cyber security implement adistributed architecture with open interfaces. Plug-and-playhardware and software components in a service oriented archi-tecture is based on communication standards and technologiessuch as message oriented middleware and web services toenable seamless integration of the IT infrastructure rangingfrom lowest equipment level Intelligent Electronic Devices(IEDs) to all higher application levels [90].C. ReliabilityA framework for cohesive integration of reliability tech-nologies facilitate convergence of the needed standards andprotocols, and implementation of necessary analytical capabil-ities. This subsection reviews the impact of a communicationinfrastructure to the reliability of a smart grid. An ideal mixof the current communication and control techniques are ex-pected to lead a flatter net demand that eventually accentuatesmany reliability issues further. A grid-wide communicationarchitectural framework to meet these reliability challengesare discussed in the following [91].1) Renewable Resources: Renewable resources generallyhave adverse challenges on smart grid reliability due to thefollowing factors: variability and low capacity, factors makingthe net demand profile steeper, low correlation with the loadprofile especially in the case of wind resource, relativelyhigh forecast errors especially for longer horizons, congestionissues at transmission level due to large installations andat distribution level due to dispersed resources. Operationalperformance issues such as voltage and regulation.To address the variability of the net demand, as renewableresources growing over the long run, efficient communica-tion infrastructure for information exchange among demandresponse, storage devices and utilization of plug-in electricvehicles (PEVs)/plug-in hybrid electric vehicles (PHEV) willcomplement the remedies [92].2) Demand Response: Demand response allows consumerload reduction in response to emergency and high price con-ditions on the smart grid. Such conditions are more prevalentduring peak load or congested operation as illustrated inFigure 9 [93]. Non-emergency demand response in the rangeof 5% to 15% of system peak load can provide substantialbenefits in reducing the need for additional resources andlowering real-time electricity prices [2]. Demand responsedoes not substantially change the total energy consumptionsince a large fraction of the energy saved during the loadcurtailment period is consumed at a more opportune time -thus a flatter load.3) Load Management: Load rejection as an emergencyresource to protect the smart grid from disruption is wellunderstood and is implemented to operate either by systemoperator command or through under-frequency and/or under-voltage relays. In a smart grid, the load rejection schemes canbe enhanced to act more intelligently and based on customerparticipation.Price based demand response/load management as a systemresource to balance demand and supply has not been widelyadopted yet. Contract based participation has been typicallyThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.12 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATIONMarket/OperatorUtility/AggregatorConsumer 1 Consumer n...Active NegotiationDemand Reduction SignalBiding messageFig. 9. Communications for Demand Response [93]below 5% of peak load [94]. In a smart grid, real-timeprice information enables wider voluntary participation byconsumers. Demand response can be implemented througheither automatic or manual response to price signals, orthrough a bidding process based on direct communicationsbetween the consumers and the market/system operators orthrough intermediaries such as aggregators or local utilities.4) Storage Devices: Most of the existing storage resourcesare hydro and pumped storage. However, growth potential forthese resources is much smaller than the need for storagenecessary to counter growing net demand variability presentedby new wind and solar resources. Various storage technologiesare emerging to fill the gap. Battery storage appears to bemost promising due to improvements in technology as well aseconomies of scale.Storage resources tend to make the net demand profile flatterand, as such, are expected to improve reliability. In addition,most battery storage devices can respond in time scales ofseconds. Hence they can become valuable enablers of fastcontrols in a smart grid. Storage resources of various sizescan be distributed throughout the grid ranging from end userloads to major substations and central power stations. Thisfeature can help to alleviate congestion at both transmissionand distribution levels [95].5) Electric Transportation: Plug-in electric vehicles (PEV,PHEV, etc.) continue to become more popular as environmen-tal concerns increase. They are a significant means to reducegreen house gases and reliance on fossil fuels. They will be asignificant factor in load growth with a potential to eventuallyconsume 600 TWh/year assuming 30 kwh for a 100-miletrip [96], and 10,000 miles per year for 200 million vehiclesin the U.S. For greater adoption of all-electric vehicles, theissue of recharge time has to be resolved. Long recharge timeslead to generally unacceptable level of vehicle unavailabilityand short recharge times have potential to increase congestion,especially at the distribution levels [97].From reliability viewpoint, electric transportation has fea-tures similar to both demand response resources and storageresources. As PHEVs present a significant factor of loadgrowth, this can also aggravate the demand variability andassociated reliability problems depending on the chargingschemes and consumer behavioral patterns.D. SecurityBased on the evolution of power system communicationinfrastructures and the concern of cyber security, many newissues have arisen in the context of smart grid.Fig. 10. Information Security Domains [99]1) Information Security Domains: Since the SCADA/EMSsystems have become increasingly integrated, it becomes moredifficult to treat the system structure in terms of parts orsubsystems. The physical realization of various functions isless evident from a user perspective. Instead, it becomes morenatural to study a SCADA/EMS system in terms of domains.This concept in application to power systems was introducedin [98].A domain is a specific area, wherein specific activ-ities/business operations are going on and they can begrouped together. The security domains are introduced inFigure 10 [99].When communicating across power utilities, different or-ganizations and companies, using communication networks,the security domains should be recognized. For example, apower utility company could define a security domain andrelated policies and procedures for its telecontrol activity toassure compliance with legislative or regulatory requirements.If similar definitions, procedures, policies, etc. were developedby other power utility companies, it would be easier to discussand define common rules for the information exchange or theusage of common resources in a communication infrastructure.However today, there are no common definitions including theterm security. Also, there are no common control system secu-rity policies or procedures, although groups such as IEC [100],ISA [101], and NIST [102], [103], are working on genericpolicies and procedures.2) Government Coordination on SCADA Security: A gov-ernment coordination action between different authorities andagencies were started in [104], focusing on SCADA secu-rity. The action is based on the participation of the powerutilities, water companies, and railway systems, which haveSCADA systems as the critical part of operations. Also,the security policies are represented. Here, the expertise isgathered and experiences are shared, including both domesticand international knowledge; everything with the purposeof securing the SCADA systems being part of the criticalinformation infrastructures. As a natural step, the SCADA Se-curity Guideline has been developed in [105]. Also, technicalguidelines and administrative recommendations are developedwhich are available for free downloading, that support thesecuring actions of the SCADA systems in the different areasof operations: power, water, and transportation.3) De-Coupling Between Operational SCADA/EMS andAdmin IT: When the existing SCADA/EMS systems are beingThis article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 13Fig. 11. Vulnerable Access Points to SCADA System [99]refurbished or replaced, the information and IT security issuesmust be taken into account. If a SCADA/EMS system is to berefurbished, the operational SCADA/EMS system part must beshielded from the administrative part, such that the operationalpart is protected from digital threats that are possible overthe Internet connection. If a SCADA/EMS system is to bereplaced, it is then a good occasion to reconsider an overallsystem structure, and then incorporate IT security on allSCADA/EMS levels. A way towards this more secure state isto, if possible, de-couple the operational SCADA/EMS systemand the administrative IT system. Also, an alternative may beto secure the firewall configuration in between operational andadministrative parts.4) Threats: The fact that SCADA/EMS systems are nowbeing interconnected and integrated with external systemscreates new possibilities and threats in cyber security. Someof these new issues have been emphasized in [98] and [106].The various interconnections of a substation were investigatedin [107], as shown in Figure 11. All the numbered accesspoints (1-10) elucidates the possible points where to thesubstation can be accessed. This number creates an operationalenvironment that implies possible digital entrances and hencedigital vulnerabilities at the same time.5) Vulnerability: As presented in [108], using a wirelesssensor network (WSN) in AMI in a smart grid is so vulnerableto be attacked by an intelligent adversary even with anordinary microwave stove. Brodsky et al. [109] documenteda denial-of-service attack on IEEE 802.15.4 wireless sensornetworks used within the smart grid. The equipment neededfor such an attack is inexpensive (about $70).6) Privacy: The privacy of terminal customers and smartmetering networks is important to the eventual acceptance bythe public. Research in this area is going on and smart meterusers will need to be reassured that their data is secure. In[110] the authors describe a method for securely anonymizingfrequent (e.g., every few minutes) electrical metering datasent by a smart meter. Although such frequent metering datamay be required by a utility or electrical energy distributionnetwork for operational reasons, this data may not necessarilyneed to be attributable to a specific smart meter or consumer.However, it needs to be securely attributable to a specificlocation (e.g. a group of houses or apartments) within thesmart grid.VI. CONCLUSIONIn this paper, we presented the background and motivationfor smart grid communication infrastructures. We showed thata smart grid built on the technologies of sensing, communica-tions, and control technologies offer a very promising futurefor utilities and users. We reviewed several industrial trialsand summarized the basic requirements of communicationinfrastructures in smart grid paradigm. Efficiency, reliabilityand security of interconnected devices and systems are criticalto enabling smart grid communication infrastructures. Interop-erability must be achieved while avoiding being isolated intononcompetitive technical solutions and the need for wholesalereplace of existing power communication systems. Alignmentbehind technical standards must be balanced with creating anenvironment that encourages innovation so that the overallcommunication infrastructure may continue to evolve. Basedon the above survey, we can focus on those challenges to smartgrid communication infrastructures in both system design andoperations to make it more efficient and secure.REFERENCES[1] U.S. Department of Energy, [online] Available: www.oe.energy.gov.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.14 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION[2] F. Rahimi and A. Ipakchi, \u201cDemand Response as a Market ResourceUnder the Smart Grid Paradigm,\u201d IEEE Trans. Smart Grid, vol.1, no.1,pp.82-88, June 2010.[3] U.S. Department of Energy, National Energy Technology Laboratory,\u201cA vision for the modern Grid,\u201d March 2007.[4] R. Yu, Y. Zhang, S. Gjessing, C. Yuen, S. Xie, M. Guizani, \u201cCognitiveradio based hierarchical communications infrastructure for smart grid,\u201dIEEE Network, vol.25, no.5, pp.6-14, September-October 2011.[5] S. Massoud Amin and B. F. Wollenberg, \u201cToward a smart grid: powerdelivery for the 21st century,\u201d IEEE Power and Energy Mag., vol. 3,pp. 34-41, 2005.[6] A. Vaccaro and D. Villacci, \u201cPerformance analysis of low earth orbitsatellites for power system communication,\u201d Electric Power SystemsResearch, vol. 73, pp. 287-294, 2005.[7] IEC-TC 57, \u201cCommunication networks and systems in substations- Part1: Introduction and overview,\u201d IEC Standard IEC/TR 61850-1, Edition1.0, 2003.[8] J. G. Cupp and M. E. Beehler, \u201cImplementing Smart Grid Communi-cations\u201d TECHBriefs 2008 No. 4, pp. 5-8.[9] A. Ghassemi, S. Bavarian, and L. Lampe, \u201cCognitive Radio for SmartGrid Communications,\u201d in First IEEE International Conference onSmart Grid Communications (SmartGridComm 2010), pp. 297-302,2010.[10] K. Jeonggil, A. Terzis, S. Dawson-Haggerty, D. E. Culler, J. W.Hui, and P. Levis, \u201cConnecting low-power and lossy networks to theinternet,\u201d IEEE Commun. Mag., vol. 49, pp. 96-101, 2011.[11] V. Madani, A. Vaccaro, D. Villacci and R. L. King, \u201cSatellite BasedCommunication Network for Large Scale Power System,\u201d 2007 iREPSymposium - Bulk Power System Dynamics and Control - VII,Revitalizing Operational Reliability, August 19-24, 2007, Charleston,SC, USA.[12] D. Dzung, I. Berganza, and A. Sendin, \u201cEvolution of powerline com-munications for smart distribution: From ripple control to OFDM,\u201d in2011 IEEE International Symposium on Power Line Communicationsand Its Applications (ISPLC 2011), pp. 474-478.[13] M. Y. Zhai, \u201cTransmission Characteristics of Low-Voltage DistributionNetworks in China Under the Smart Grids Environment,\u201d IEEE Trans.Power Del., vol. 26, pp. 173-180, 2011.[14] N. Ginot, M. A. Mannah, C. Batard, and M. Machmoum, \u201cApplicationof Power Line Communication for Data Transmission Over PWMNetwork,\u201d IEEE Trans. Smart Grid, vol. 1, pp. 178-185, 2010.[15] G. Bumiller, L. Lampe, and H. Hrasnica, \u201cPower line communicationnetworks for large-scale control and automation systems,\u201d IEEE Com-mun. Mag., vol. 48, pp. 106-113, 2010.[16] A. Haidine, B. Adebisi, A. Treytl, H. Pille, B. Honary, and A. Portnoy,\u201cHigh-speed narrowband PLC in Smart Grid landscape - State-of-the-art,\u201d in IEEE International Symposium on Power Line Communicationsand Its Applications (ISPLC 2011), pp. 468-473, 2011.[17] U.S. Department of Energy, Energy Efficiency and Renewable Energy,\u201cAnnual Report on US Wind Power Installation, Cost and PerformanceTrends: 2007,\u201d May 2008.[18] I. Marti, \u201cEvaluation of Advanced Wind Power Forecasting Models,\u201dEuropean Wind Energy Conference, Athens, Feb 27- Mar 2, 2006.[19] The New York State Energy Research and Development Authority,\u201cThe Effects of Integrating Wind Power on Transmission SystemPlanning, Reliability and Operations, Report on Phase 2: SystemPerformance Evaluation,\u201d Albany, NY, March 4, 2005.[20] \u201cWaiting for the sunrise (solar energy forecast) (Science and Technol-ogy),\u201d The Economist , May 19, 1990.[21] U.S. DoE Solar Energy Technologies Program, \u201cSolar Energy IndustryForecast: Perspectives on U.S. Solar Market Trajectory\u201d, May 30, 2008.[22] National Renewable Energy Laboratory, \u201cExecutive Summary: Assess-ment of Parabolic Trough and Power Tower Solar Technology Cost andPerformance Forecasts,\u201d October 2003.[23] T. Van Loon, T. Vu Van, A. Woyte, F. Truyens, B. Bletterie, J. Reekers,B. Blazic, and R. Engelen, \u201cIncreasing photovoltaics grid penetrationin urban areas through active distribution systems: First large scaledemonstration,\u201d in Third International Conference on InfrastructureSystems and Services: Next Generation Infrastructure Systems for Eco-Cities (INFRA 2010), pp. 1-4, 2010.[24] A. B. Pedersen, E. B. Hauksson, P. B. Andersen, B. Poulsen, C.Tr\u00e6holt, and D. Gantenbein, \u201cFacilitating a Generic CommunicationInterface to Distributed Energy Resources: Mapping IEC 61850 toRESTful Services,\u201d First IEEE International Conference onSmart GridCommunications (SmartGridComm 2010), pp. 61-66, 2010.[25] D. Infield and F. Li, \u201cIntegrating micro-generation into distributionsystems: a review of recent research,\u201d in Proc. IEEE Power and EnergySociety General Meeting - Conversion and Delivery of ElectricalEnergy in the 21st Century, July 2008.[26] R. Sauter and J. Watson, \u201cStrategies for the deployment of micro-generation: Implications for social acceptance\u201d, Elsevier, Energy Pol-icy, Vol. 35, Iss.5, pp.2770-2779, May 2007.[27] J. Watson, R. Sauter, B. Bahaj, P. James, L. Myers and R. Wing,\u201cDomestic micro-generation: Economic, regulatory and policy issuesfor the UK,\u201d Energy Policy, Vol. 36, Iss. 8, Pages 3095-3106, August2008.[28] P. Tenti, A. Costabeber, and P. Mattavelli, \u201cImproving power qualityand distribution efficiency in micro-grids by cooperative control ofSwitching Power Interfaces,\u201d International Power Electronics Confer-ence (IPEC 2010), pp. 472-479, 2010.[29] A. Costabeber, P. Tenti, and P. Mattavelli, \u201cSurround control ofdistributed energy resources in micro-grids,\u201d IEEE International Con-ference on Sustainable Energy Technologies (ICSET 2010), pp. 1-6,2010.[30] D. Backer, \u201cPower Quality and Asset Management The Other Two-Thirds of AMI Value,\u201d IEEE Rural Electric Power Conference, pp.6-8, May 2007.[31] F. M. Cleveland, \u201cCyber security issues for Advanced Metering In-frastructure (AMI),\u201d Proceedings of IEEE Power and Energy SocietyGeneral Meeting Conversion and Delivery of Electrical Energy in the21st Century, July 2008.[32] G. A. Taylor, M. R. Irving, P. R. Hobson, C. Huang, P. Kyberd,and R. J. Taylor, \u201cDistributed monitoring and control of future powersystems via grid computing,\u201d IEEE Power Engineering Society GeneralMeeting, 2006.[33] E. Chikuni, M. Dondo, \u201cInvestigating the security of electrical powersystems SCADA,\u201d IEEE AFRICON 2007, pp.1-7, Sep 2007.[34] C. Ten, C. Liu, and M. Govindarasu, \u201cCyber-vulnerability of powergrid monitoring and control systems,\u201d In Proceedings of the 4th AnnualWorkshop on Cyber Security and information intelligence Research(CSIIRW \u201908), Oak Ridge, Tennessee, May 12 - 14, 2008.[35] J. D. Fernandez and A. E. Fernandez, \u201cSCADA systems: vulnera-bilities and remediation,\u201d Journal of Computing Sciences in Collegesarchive,Vol. 20, Iss. 4, pp.160-168, April, 2005.[36] Y. Serizawa, et al., \u201cPresent and future ICT infrastructures for a smartergrid in Japan,\u201d in Innovative Smart Grid Technologies (ISGT2010), pp.1-5, 2010 .[37] O. Samuelsson, S. Repo, R. Jessler, J. Aho, M. Karenlampi, andA. Malmquist, \u201cActive distribution network - Demonstration projectADINE,\u201d in IEEE PES Innovative Smart Grid Technologies ConferenceEurope (ISGT Europe 2010), pp. 1-8, 2010.[38] F. Rahimi and A. Ipakchi, \u201cOverview of Demand Response underthe Smart Grid and Market paradigms,\u201d in Innovative Smart GridTechnologies (ISGT 2010), pp. 1-7, 2010.[39] R. Davies, \u201cHydro one\u2019s smart meter initiative paves way for definingthe smart grid of the future,\u201d in Power & Energy Society GeneralMeeting, 2009. (PES \u201909),pp. 1-2, 2009.[40] E. Santacana, et al., \u201cGetting Smart,\u201d Power and Energy Magazine,IEEE, vol. 8, pp. 41-48, 2010[41] D. Sun, \u201cThe Utilization and Development Strategies of Smart Gridand New Energy,\u201d in Proceedings of Asia-Pacific Power and EnergyEngineering Conference (APPEEC 2010), pp. 1-4, 2010.[42] C. Jaeseok, J. Park, M. Shahidehpour and R. Billinton, \u201cAssessment ofCO2 reduction by renewable energy generators,\u201d in Innovative SmartGrid Technologies (ISGT), pp.1-5, 2010.[43] F. A. Rahimi, \u201cChallenges and opportunities associated with high pen-etration of distributed and renewable energy resources,\u201d in InnovativeSmart Grid Technologies (ISGT), 2010, 2010, pp. 1-1.[44] G. Lorenz, \u201cRegulatory framework to incentivise Smart Grids deploy-ment - EURELECTRIC views,\u201d The 20th International Conference andExhibition on Electricity Distribution - Part 2, 2009. (CIRED 2009),pp. 1-26, 2009.[45] D. Tuan, \u201cThe Energy Web: Concept and challenges to overcome tomake large scale renewable and distributed energy resources a truereality,\u201d in 7th IEEE International Conference on Industrial Informatics,pp.384-389, 2009.[46] http://www.bchydro.com/planning regulatory/projects/smart metering infrastructure program.html.[47] W. Luan, D. Sharp, S. Lancashire, \u201cSmart grid communication networkcapacity planning for power utilities,\u201d 2010 IEEE PES Transmissionand Distribution Conference and Exposition, pp.1-4, 19-22 April 2010.[48] A. Clark, C. J. Pavlovski, and J. Fry, \u201cTransformation of energysystems: The control room of the future,\u201d in Proceedings of IEEEElectrical Power & Energy Conference (EPEC), 2009, pp. 1-6.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.YAN et al.: A SURVEY ON SMART GRID COMMUNICATION INFRASTRUCTURES: MOTIVATIONS, REQUIREMENTS AND CHALLENGES 15[49] ZigBee Specification, ZigBee Alliance, ZigBee Document 053474r17,January 2008.[50] M. Fang, J. Wan, X. Xu, and G. Wu, \u201cSystem for TemperatureMonitor in Substation with ZigBee Connectivity,\u201d IEEE InternationalConference on Communication Technology, pp. 25-28, Nov. 2008.[51] B. Chen, M. Wu; S. Yao, B. Ni, \u201cZigBee Technology and itsApplication on Wireless Meter-reading System,\u201d IEEE InternationalConference on Industrial Informatics, Aug. 2006, pp. 1257 - 1260.[52] S. W. Luan, J. H. Teng, S. Y. Chan, L. C. Hwang, \u201cDevelopment of aSmart Power Meter for AMI Based on ZigBee Communication,\u201d IEEE8th International Conference on Power Electronics and Driver Systems,Taiwan, Paper No. 284, 2009.[53] S. W. Luan; J. H. Teng, S. Y. Chan, L. C. Hwang, \u201cDevelopment of anautomatic reliability calculation system for advanced metering infras-tructure,\u201d 8th IEEE International Conference on Industrial Informatics(INDIN 2010), pp.342-347, 13-16 July 2010.[54] P. Zhang, F. Li, N. Bhatt, \u201cNext-Generation Monitoring, Analysis, andControl for the Future Smart Control Center,\u201d IEEE Trans. Smart Grid,vol.1, no.2, pp.186-192, Sept. 2010.[55] A. Aggarwal, S. Kunta, P. K. Verma, \u201cA proposed communications in-frastructure for the smart grid,\u201d in Innovative Smart Grid Technologies(ISGT), 2010, pp. 1-5.[56] C. H. Hauser, D. E. Bakken, I. Dionysiou, K. H. Gjermundrod, V. S.Irava, J. Helkey, A. Bose, \u201cSecurity, trust, and QoS in Next generationcontrol and communication for large power systems,\u201d Int. J. CriticalInfrastructures, Vol. 4, 2008.[57] Smart Grids Interoperability Standards Project, [online] Availablehttp://www.nist.gov/smartgrid/.[58] NIST framework and Roadmamp for Smart Grid interoperabilitystandards release 1.0.[59] IEEE Smart Grid, [online] Available http://smartgrid.ieee.org/nist-smartgrid-framework.[60] A. F. Snyder and M. T. G. Stuber, \u201cThe ANSI C12 protocol suite- updated and now with network capabilities,\u201d in Power SystemsConference: Advanced Metering, Protection, Control, Communication,and Distributed Resources (PSC 2007), pp. 117-122, 2007.[61] F. Lobo, A. Cabello, A. Lopez, D. Mora, and R. Mora, \u201cDistributionNetwork as communication system,\u201d in SmartGrids for Distribution,2008. IET-CIRED. CIRED Seminar, 2008, pp. 1-4.[62] Report to NIST on Smart Grid Interoperability Standards RoadmapEPRI, Jun. 17, 2009.[63] S. Hurd, R. Smith, G. Leischner, \u201cTutorial: Security in ElectricUtility Control Systems,\u201d 61st Annual Conference for Protective RelayEngineers, pp.304-309, 1-3 April 2008.[64] Draft Smart Grid Cyber Security Strategy and Requirements, NIST IR7628, Sep. 2009.[65] GridWise Architecture Council Interoperability Framework,http://www.gridwiseac.org/pdfs/interopframework v1 1.pdf.[66] R. DeBlasio, C. Tom, \u201cStandards for the Smart Grid,\u201d IEEE Energy2030 Conference, pp.1-7, 17-18 Nov. 2008.[67] M. Masera, A. Stefanini and G. Dondossola, \u201cThe Security of Informa-tion and Communication Systems and the E+I Paradigm,\u201d in CriticalInfrastructures at Risk. vol. 9, A. V. Gheorghe, M. Masera, M. Weijnenand D. Vires, Eds., Springer Netherlands, 2006, pp. 85-116.[68] B. Stephens, \u201cSystem-Wide Information Management (SWIM)Demonstration Security Architecture,\u201d IEEE/AIAA 25th Digital Avion-ics Systems Conference, pp.1-12, 15-19 Oct. 2006.[69] P. Lund; \u201cThe Danish Cell Project - Part 1: Background and GeneralApproach,\u201d IEEE Power Engineering Society General Meeting, pp.1-6,24-28 June 2007.[70] IEEE Std 1547.3, \u201cIEEE Guide for Monitoring, Information Exchange,and Control of Distributed Resources Interconnected With ElectricPower Systems,\u201d vol., no., pp.1-158, 2007.[71] G. Deconinck, \u201cMetering, Intelligent Enough for Smart Grids?,\u201d inSecuring Electricity Supply in the Cyber Age. vol. 15, Z. Lukszo, etal., Eds., Springer Netherlands, 2010, pp. 143-157.[72] IEEE Std 802.11i, \u201cIEEE Standard for Information Technology-Telecommunications and Information Exchange Between Systems-Local and Metropolitan Area Networks- Specific Requirements Part11: Wireless LAN Medium Access Control (MAC) and Physical Layer(PHY) Specifications Amendment 6: Medium Access Control (MAC)Security Enhancements,\u201d pp. 1-175, 2004.[73] IEEE Std 802.16e, \u201cIEEE Standard for Local and Metropolitan AreaNetworks Part 16: Air Interface for Fixed and Mobile BroadbandWireless Access Systems Amendment 2: Physical and Medium AccessControl Layers for Combined Fixed and Mobile Operation in LicensedBands and Corrigendum 1,\u201d pp. 1-822, 2006.[74] U.S. Department of Energy, \u201cWireless Procurement Language in Sup-port of Advanced Metering Infrastructure Security\u201d, 2009.[75] IEEE P2030, Draft Guide for Smart Grid Interoperability of EnergyTechnology and Information Technology Operation with the ElectricPower System (EPS), and End-Use Applications and Loads. July 2009.[76] D. Becker, T. L. Saxton, and M. Goodrich, \u201cCIM standard for dynamicmodel exchange,\u201d in IEEE Power and Energy Society General Meeting,pp. 1-3, 2010.[77] IEEE Unifies Power, Communications, and IT with launch of SmartGrid Interoperability Standards Project P2030. IEEE Standards Asso-ciation P2030, June, 2009.[78] S. L. Woodruff, \u201cComplexity in power systems and consequencesfor real-time computing\u201d, IEEE PES Power Systems Conference andExposition, 10-13 Oct. 2004.[79] R. Dougal, T. Lovett, A. Monti and E. Santi, \u201cA MultilanguageEnvironment For Interactive Simulation And Development Of ControlsFor Power Electronics,\u201d IEEE PESC01.[80] R. Dougal, A. Monti and F. Ponci, \u201cThe Incremental Design Processfor Power Electronic Building Blocks,\u201d invited paper for IEEE PESAnnual Meeting 2006.[81] R. Dougal and A. Monti, \u201cThe Virtual Test Bed as a tool for rapidsystem engineering,\u201d IEEE Systems Conference, April 2007.[82] L. Cristaldi, A. Ferrero, M. Lazzaroni, A. Monti and F. Ponci, \u201cMul-tiresolution Modeling: an Experimental Validation,\u201d IEEE-IMCT02,Ankorage (USA), 21-23 May 2002.[83] F. Ponci, A. Monti and E. Santi, \u201cDiscrete-Time Multi- ResolutionModeling of Switching Power Converters Using Wavelets,\u201d SIMU-LATION, Transactions of the Society for Modeling and SimulationInternational, February 2009, vol. 85, no. 2, pages 69-88.[84] A. Monti and R. Dougal, \u201cThe Virtual Test Bed Concept For VirtualPrototyping Of Complex Systems,\u201d in Proc. AED, 2004.[85] R. Rios-Zalapa, X. Wang, J. Wan, K. Cheung, \u201cRobust dispatch tomanage uncertainty in real time electricity markets,\u201d Innovative SmartGrid Technologies (ISGT), pp.1-5, 19-21 Jan. 2010.[86] R. Krebs, B. M. Buchholz, Z. A. Styczynski, K. Rudion, C. Heyde, Y.Sassnick, \u201cVision 2020 \u0142 Security of the network operation today andin the future. German experiences,\u201d IEEE Power and Energy SocietyGeneral Meeting - Conversion and Delivery of Electrical Energy in the21st Century, pp.1-6, 20-24 July 2008.[87] M. Amin, \u201cEnergy Infrastructure Defense Systems,\u201d Proc. IEEE ,vol.93, no.5, pp.861-875, May 2005.[88] J. Wen, P. Arons, W.-H. E. Liu, \u201cThe role of Remedial ActionSchemes in renewable generation integrations,\u201d Innovative Smart GridTechnologies (ISGT), pp.1-6, 19-21 Jan. 2010.[89] M. McGranaghan, D. Von Dollen, P. Myrda, E. Gunther, \u201cUtilityexperience with developing a smart grid roadmap,\u201d IEEE Powerand Energy Society General Meeting - Conversion and Delivery ofElectrical Energy in the 21st Century, pp.1-5, 20-24 July 2008.[90] M. Kezunovic, F. Xu, B. Cuka, P. Myrda, \u201cIntelligent processing ofIED data for protection engineers in the Smart Grid,\u201d MELECON 2010- 2010 15th IEEE Mediterranean Electrotechnical Conference, pp.437-442, 26-28 April 2010.[91] K. Moslehi and R. Kumar, \u201cA Reliability Perspective of the SmartGrid,\u201d IEEE Trans. Smart Grid, vol. 1, pp. 57-64, 2010.[92] K. Mets, T. Verschueren, W. Haerick, C. Develder, F. De Turck,\u201cOptimizing smart energy control strategies for plug-in hybrid electricvehicle charging,\u201d IEEE/IFIP Network Operations and ManagementSymposium Workshops (NOMS Wksps), pp.293-299, 19-23 April2010.[93] K. Moslehi and R. Kumar, \u201cSmart Grid - a reliability perspective,\u201d inInnovative Smart Grid Technologies (ISGT 2010), pp. 1-8, 2010.[94] Markets Committee of the ISO/RTO Council, \u201cHarnessing the Powerof Demand - How ISOs and RTOs Are Integrating Demand Responseinto Wholesale Electricity Markets,\u201d October 16, 2007.[95] R. N. Anderson, \u201cThe Distributed Storage-Generation Smart ElectricGrid of the Future\u201d, white paper, Columbia University.[96] R. Gawel, \u201cTesla\u2019s Tests Confirm Roadster\u2019s 245-Mile Range,\u201d Elec-tronic Design, November 5, 2007.[97] S. Acha, T. C. Green, N. Shah, \u201cEffects of optimised plug-in hybridvehicle charging strategies on electric distribution network losses,\u201dIEEE PES Transmission and Distribution Conference and Exposition,pp.1-6, 19-22 April 2010.[98] G. Ericsson, O. Torkilseng, G. Dondossola, T. Jansen, J. Smith, D.Holstein, A. Vidrascu, and J.Weiss, \u201cSecurity for Information Systemsand Intranets in Electric Power Systems,\u201d Tech Brochure (TB) 317CIGR, 2007.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.16 IEEE COMMUNICATIONS SURVEYS & TUTORIALS, ACCEPTED FOR PUBLICATION[99] G. Ericsson, \u201cCyber Security and Power System Communica-tion\u0142Essential Parts of a Smart Grid Infrastructure,\u201d IEEE Trans. PowerDelivery, vol.25, no.3, pp.1501-1507, July 2010.[100] IEC, Power System Control & Associated Communications-Data &communication Security 62351 part 1-8, TS.[101] ISA 99 [Online]. Available:http://www.isa.org/MSTemplate.cfm?MicrositeID=988&CommitteeID=6821.[102] NIST, Computer Security Division, Computer Security Resource Cen-tre. [Online]. Available: http://csrc.nist.gov/publications/PubsSPs.html.[103] NIST ICS Security Project [Online].Available:http://csrc.nist.gov/seccert/ics/index.html.[104] Swedish Civil Contingencies Agency, \u201cSCADA Security Coordina-tion\u201d.[105] Swedish Civil Contingencies Agency,\u201cGuide to Increased Security inProcess Control Systems for Critical Societal Functions\u201d.[106] G. Ericsson, O. Torkilseng, G. Dondossola, L. Pitre-Cambacds, S.Duckworth, A. Bartels, M. Tritschler, T. Kropp, J.Weiss, and R.Pellizzonni, \u201cTreatment of Information Security for Electric PowerUtilities (EPUs),\u201d Technical Brochure (TB), CIGRE, to appear 2010.[107] P. Roche; \u201cCyber security considerations in power system operations,\u201dCIGRE Electra No. 218, February 2005.[108] T. Goodspeed, D. R. Highfill and B.A. Singletary, \u201cLow-level DesignVulnerabilities in Wireless Control Systems Hardware,\u201d Proceedingsof the SCADA Security Scientific Symposium 2009 (S4), pp.3-1-3-26,January 21- 22, 2009.[109] J. Brodsy and A. McConnell, \u201cJamming and Interference InducedDenial-of-Service Attacks on IEEE 802.15.4-Based Wireless Net-works,\u201d Proceedings of the SCADA Security Scientific Symposium2009 (S4), pp. 2-1-2 -11, January 21-22, 2009.[110] C. Efthymiou and G. Kalogridis, \u201cSmart Grid Privacy via Anonymiza-tion of Smart Metering Data,\u201d in First IEEE International Conferenceon Smart Grid Communications (SmartGridComm 2010), pp. 238-243,2010.Ye Yan is a Ph.D. student in the Departmentof Computer and Electronics Engineering (CEEN),University of Nebraska-Lincoln (UNL). His cur-rent research articles on wireless network, networksecurity, and smart grid communication has beenpublished in IEEE and other international journalsand conferences. He has been serving as TPC mem-bers on several IEEE conferences and reviewers formany international journals and conferences. He isa student member of IEEE.Yi Qian is an Assistant Professor in the Departmentof Computer and Electronics Engineering, Univer-sity of Nebraska-Lincoln (UNL). His research in-terests include information assurance and networksecurity, network design, network modeling, simu-lation and performance analysis for next generationwireless networks, wireless ad-hoc and sensor net-works, vehicular networks, broadband satellite net-works, optical networks, high-speed networks andthe Internet. Prior to joining UNL, he worked inthe telecommunications industry, academia, and theU.S. government. Some of his previous professional positions include servingas a senior member of scientific staff and a technical advisor at NortelNetworks, a senior systems engineer and a technical advisor at several start-upcompanies, an Assistant Professor at University of Puerto Rico at Mayaguez,and a senior researcher at National Institute of Standards and Technology. Hehas a successful track record to lead research teams and to publish researchresults in leading scientific journals and conferences. Several of his recentjournal articles on wireless network design and wireless network security areamong the most accessed papers in the IEEE Digital Library. Dr. Yi Qian isa member of ACM and a senior member of IEEE. He is currently serving asthe Vice Chair for Conferences - Communications and Information SecurityTechnical Committee (CISTC) for IEEE Communications Society. He is alsoserving as the IEEE Communications Society CISTC Representative to theAd Hoc Committee on Smart-Grid Communications.Hamid Sharif is the Charles J. Vranek Professorof the College of Engineering at the University ofNebraska-Lincoln. He is also the Director of theAdvanced Telecommunications Engineering Labo-ratory (TEL) at University of Nebraska. ProfessorSharif has published a large number of researcharticles in international journals and conferencesand has been the recipient of a number of bestpaper awards. Dr. Sharif has been serving on manyIEEE and other international journal editorial boardsand currently is the co-editor-in-chief for the WileyJournal of Security and Communication Networks. He has contributed to theIEEE in many roles including the elected Chair of the Nebraska Section,elected Chair of the Nebraska Computer Chapter, elected Chair of theNebraska Communications Chapter, and the Chapter Coordinator for the IEEERegion 4 in US.David Tipper is an Associate Professor and Directorof the Graduate Telecommunications and Network-ing Program at the University of Pittsburgh. Heis a graduate of the University of Arizona (Ph.D.EE, M.S.S.I.E.) and Virginia Tech (B.S.E.E.). Hiscurrent research focuses on network design, energyefficiency, information assurance techniques, timevarying network performance analysis and control.This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.",
      "id": 33131981,
      "identifiers": [
        {
          "identifier": "12211338",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:d-scholarship.pitt.edu:12508",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1109/surv.2012.021312.00034",
          "type": "DOI"
        }
      ],
      "title": "A survey on smart grid communication infrastructures: Motivations, requirements and challenges",
      "magId": null,
      "oaiIds": [
        "oai:d-scholarship.pitt.edu:12508"
      ],
      "publishedDate": "2013-01-01T00:00:00",
      "publisher": "'Institute of Electrical and Electronics Engineers (IEEE)'",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "http://d-scholarship.pitt.edu/12508/1/Smart_Grid_Infrastructure_Final.pdf"
      ],
      "updatedDate": "2022-05-16T22:46:59",
      "yearPublished": 2013,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/12211338.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/12211338"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/12211338/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/12211338/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/33131981"
        }
      ]
    },
    {
      "acceptedDate": "2015-07-06T00:00:00",
      "arxivId": null,
      "authors": [
        {
          "name": "Barshan, Maryam"
        },
        {
          "name": "De Turck, Filip"
        },
        {
          "name": "Famaey, Jeroen"
        },
        {
          "name": "Moens, Hendrik"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Maryam"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/223075192",
        "https://api.core.ac.uk/v3/outputs/55825883",
        "https://api.core.ac.uk/v3/outputs/209155073"
      ],
      "createdDate": "2016-11-12T12:39:58",
      "dataProviders": [
        {
          "id": 4786,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/4786",
          "logo": "https://api.core.ac.uk/data-providers/4786/logo"
        },
        {
          "id": 1493,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/1493",
          "logo": "https://api.core.ac.uk/data-providers/1493/logo"
        },
        {
          "id": 1624,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/1624",
          "logo": "https://api.core.ac.uk/data-providers/1624/logo"
        }
      ],
      "depositedDate": "2015-05-01T00:00:00",
      "abstract": "Media production generally requires many geographically distributed actors (e.g., production houses, broadcasters, advertisers) to exchange huge amounts of raw video and audio data. Traditional distribution techniques, such as dedicated point-to-point optical links, are highly inefficient in terms of installation time and cost. To improve efficiency, shared media production networks that connect all involved actors over a large geographical area, are currently being deployed. The traffic in such networks is often predictable, as the timing and bandwidth requirements of data transfers are generally known hours or even days in advance. As such, the use of advance bandwidth reservation (AR) can greatly increase resource utilization and cost efficiency. In this paper, we propose an Integer Linear Programming formulation of the bandwidth scheduling problem, which takes into account the specific characteristics of media production networks, is presented. Two novel optimization algorithms based on this model are thoroughly evaluated and compared by means of in-depth simulation results",
      "documentType": "research",
      "doi": "10.1109/inm.2015.7140291",
      "downloadUrl": "https://core.ac.uk/download/55825883.pdf",
      "fieldOfStudy": null,
      "fullText": "IEEE COMMUNICATIONS SURVEYS & TUTORIALS 1\nNetwork Function Virtualization: State-of-the-art\nand Research Challenges\nRashid Mijumbi, Joan Serrat, Juan-Luis Gorricho, Niels Bouten, Filip De Turck, Raouf Boutaba\nAbstract\u2014Network Function Virtualization (NFV) has drawn\nsignificant attention from both industry and academia as an\nimportant shift in telecommunication service provisioning. By\ndecoupling Network Functions (NFs) from the physical devices\non which they run, NFV has the potential to lead to significant\nreductions in Operating Expenses (OPEX) and Capital Expenses\n(CAPEX) and facilitate the deployment of new services with\nincreased agility and faster time-to-value. The NFV paradigm is\nstill in its infancy and there is a large spectrum of opportunities\nfor the research community to develop new architectures, systems\nand applications, and to evaluate alternatives and trade-offs in\ndeveloping technologies for its successful deployment. In this\npaper, after discussing NFV and its relationship with comple-\nmentary fields of Software Defined Networking (SDN) and cloud\ncomputing, we survey the state-of-the-art in NFV, and identify\npromising research directions in this area. We also overview key\nNFV projects, standardization efforts, early implementations, use\ncases and commercial products.\nIndex Terms\u2014Network function virtualization, virtual network\nfunctions, future Internet, software defined networking, cloud\ncomputing.\nI. INTRODUCTION\nService provision within the telecommunications industry\nhas traditionally been based on network operators deploying\nphysical proprietary devices and equipment for each function\nthat is part of a given service. In addition, service components\nhave strict chaining and/or ordering that must be reflected\nin the network topology and in the localization of service\nelements. These, coupled with requirements for high quality,\nstability and stringent protocol adherence, have led to long\nproduct cycles, very low service agility and heavy dependence\non specialized hardware.\nHowever, the requirements by users for more diverse and\nnew (short-lived) services with high data rates continue to\nincrease. Therefore, Telecommunication Service Providers\n(TSPs) must correspondingly and continuously purchase, store\nand operate new physical equipment. This does not only\nrequire high and rapidly changing skills for technicians op-\nerating and managing this equipment, but also requires dense\ndeployments of network equipment such as base stations. All\nthese lead to high CAPEX and OPEX for TSPs [1], [2].\nMoreover, even with these high customer demands, the\nresulting increase in capital and operational costs cannot be\ntranslated in higher subscription fees, since TSPs have learned\nR. Mijumbi, J. Serrat and J.L. Gorricho are with the Network Engineering\nDepartment, Universitat Polite`cnica de Catalunya, 08034 Barcelona, Spain.\nN. Bouten and F. De Turck are with Department of Information Technology,\nGhent University - iMinds, B-9050 Ghent, Belgium.\nR. Boutaba is with the D.R. Cheriton School of Computer Science,\nUniversity of Waterloo, Waterloo, Ontario, N2L 3G1, Canada.\nthat due to the high competition, both among themselves\nand from services being provided over-the-top on their data\nchannels, increasing prices only leads to customer churn.\nTherefore, TSPs have been forced to find ways of building\nmore dynamic and service-aware networks with the objective\nof reducing product cycles, operating & capital expenses and\nimproving service agility.\nNFV [3], [4] has been proposed as a way to address these\nchallenges by leveraging virtualization technology to offer a\nnew way to design, deploy and manage networking services.\nThe main idea of NFV is the decoupling of physical network\nequipment from the functions that run on them. This means\nthat a network function - such as a firewall - can be dispatched\nto a TSP as an instance of plain software. This allows for\nthe consolidation of many network equipment types onto high\nvolume servers, switches and storage, which could be located\nin data centers, distributed network nodes and at end user\npremises. This way, a given service can be decomposed into\na set of Virtual Network Functions (VNFs), which could\nthen be implemented in software running on one or more\nindustry standard physical servers. The VNFs may then be\nrelocated and instantiated at different network locations (e.g.,\naimed at introduction of a service targeting customers in a\ngiven geographical location) without necessarily requiring the\npurchase and installation of new hardware.\nNFV promises TSPs with more flexibility to further open\nup their network capabilities and services to users and other\nservices, and the ability to deploy or support new network\nservices faster and cheaper so as to realize better service\nagility. To achieve these benefits, NFV paves the way to a\nnumber of differences in the way network service provisioning\nis realized in comparison to current practice. In summary, these\ndifferences are as follows [5]:\nDecoupling software from hardware. As the network ele-\nment is no longer a composition of integrated hardware and\nsoftware entities, the evolution of both are independent of\neach other. This allows separate development timelines and\nmaintenance for software and hardware.\nFlexible network function deployment. The detachment of\nsoftware from hardware helps reassign and share the in-\nfrastructure resources, thus together, hardware and software,\ncan perform different functions at various times. This helps\nnetwork operators deploy new network services faster over\nthe same physical platform. Therefore, components can be\ninstantiated at any NFV-enabled device in the network and\ntheir connections can be set up in a flexible way.\nDynamic scaling. The decoupling of the functionality of the\nnetwork function into instantiable software components pro-\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 2\nCustomer Sites\nCPE 1\nUPnP\nUPnP\nModem\nSwitch\nRadio\nFirewall\nRouting\nNAT\nService Provider\nPublic IP \nServices\nPrivate IP \nServices\nCPE 2\nUPnP\nUPnP\nModem\nSwitch\nRadio\nFirewall\nRouting\nNAT\nCore Router\nCustomer Sites\nCPE 1\nUPnP\nvUPnP\nModem\nSwitch\nRadio\nvFirewal\nl\nvRouting\nvNAT\nService Provider\nPublic IP \nServices\nPrivate IP \nServices\nvCore Router\nModem\nSwitch\nRadio\nModem\nSwitch\nRadio\nModem\nSwitch\nRadio\n. . .\nCPE 2 CPE 3 CPE N\nVirtual Functions\nFig. 1. Traditional CPE Implementations\nCustomer Sites\nCPE 1\nUPnP\nUPnP\nModem\nSwitch\nRadio\nFirewall\nRouting\nNAT\nService Provider\nPublic IP \nServices\nPrivate IP \nServices\nCPE 2\nUPnP\nUPnP\nModem\nSwitch\nRadio\nFirewall\nRouting\nNAT\nCore Router\nCustomer Sites\nCPE 1\nUPnP\nvUPnP\nModem\nSwitch\nRadio\nvFirewall\nvRouting\nvNAT\nService Provider\nPublic IP\nServices\nPrivate IP \nServices\nvCore Router\nModem\nSwitch\nRadio\nModem\nSwitch\nRadio\nModem\nSwitch\nRadio\n. . .\nCPE 2 CPE 3 CPE N\nVirtual Functions\nFig. 2. Possible CPE Implementation with NFV\nvides greater flexibility to scale the actual VNF performance\nin a more dynamic way and with finer granularity, for instance,\naccording to the actual traffic for which the network operator\nneeds to provision capacity.\nIt is worth remarking that the general concept of decoupling\nNFs from dedicated hardware does not necessarily require\nvirtualization of resources. This means that TSPs could still\npurchase or develop software (NFs) and run it on physical\nmachines. The difference is that these NFs would have to be\nable to run on commodity servers. However, the gains (such\nas flexibility, dynamic resource scaling, energy efficiency) an-\nticipated from running these functions on virtualized resources\nare very strong selling points of NFV. Needless to mention,\nit is also possible to have hybrid scenarios where functions\nrunning on virtualized resources co-exist with those running\non physical resources. Such hybrid scenarios may be important\nin the transition towards NFV.\nA. History of Network Function Virtualization\nThe concept and collaborative work on NFV was born in\nOctober 2012 when a number of the world\u2019s leading TSPs\njointly authored a white paper [4] calling for industrial and\nresearch action. In November 2012 seven of these operators\n(AT&T, BT, Deutsche Telekom, Orange, Telecom Italia, Tele-\nfonica and Verizon) selected the European Telecommunica-\ntions Standards Institute (ETSI)[6] to be the home of the\nIndustry Specification Group for NFV (ETSI ISG NFV)1.\n1In the rest of this paper, the acronyms ETSI and ETSI ISG NFV are used\nsynonymously.\nNow, more than two years later, a large community of experts\nare working intensely to develop the required standards for\nNFV as well as sharing their experiences of its development\nand early implementation. The membership of ETSI has\ngrown to over 245 individual companies including 37 of the\nworld\u2019s major service providers as well as representatives\nfrom both telecoms and IT vendors [6]. ETSI has successfully\ncompleted Phase 1 of its work with the publication of 11 ETSI\nGroup Specifications [7]. These specifications build on the\nfirst release of ETSI documents published in October 2013\nand include an infrastructure overview, updated architectural\nframework, and descriptions of the compute, hypervisor and\nnetwork domains of the infrastructure. They also cover\nManagement and Orchestration (MANO), security and trust,\nresilience and service quality metrics.\nSince ETSI is not a standards body, its aim is to produce\nrequirements and potential specifications that TSPs and equip-\nment vendors can adapt for their individual environments,\nand which may be developed by an appropriate standards\ndevelopment organization (SDO). However, since standards\nbodies such as the 3GPP [8] are in liaison with the ETSI,\nwe can expect these proposals will be generally accepted and\nenforced as standards. 3GPP\u2019s Telecom Management working\ngroup (SA5) is also studying the management of virtualized\n3GPP network functions.\nB. NFV Examples\nThe ETSI has proposed a number of use cases for NFV [9].\nIn this subsection, we will explain how NFV may be applied\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 3\nto Customer Premises Equipment (CPE), and to an Evolved\nPacket Core (EPC) network.\n1) Customer Premises Equipment (CPE): In Figures 1 and\n2, we use an example of a CPE to illustrate the economies of\nscale that may be achieved by NFV. Fig. 1 shows a typical\n(current) implementation of a CPE which is made up of the\nfunctions: Dynamic Host Configuration Protocol (DHCP),\nNetwork Address Translation (NAT), routing, Universal Plug\nand Play (UPnP), Firewall, Modem, radio and switching. In\nthis example, a single service (the CPE) is made up of eight\nfunctions. These functions may have precedence requirements.\nFor example, if the functions are part of a service chain2, it\nmay be required to perform firewall functions before NAT.\nCurrently, it is necessary to have these functions in a physical\ndevice located at the premises of each of the customers 1 and\n2. With such an implementation, if there is a need to make\nchanges to the CPE, say, by adding, removing or updating a\nfunction, it may be necessary for a technician from the ISP to\nindividually talk to or go to each of the customers. It may even\nrequire a complete change of the device in case of additions.\nThis is not only expensive (operationally) for the ISPs, but\nalso for the customers.\nIn Figure 2, we show a possible implementation based on\nNFV in which some of the functions of the CPE are transferred\nto a shared infrastructure at the ISP, which could also be a data\ncenter. This makes the changes described above easier since,\nfor example, updating the DHCP for all customers would\nonly involve changes at the ISP. In the same way, adding\nanother function such as parental controls for all or a subset\nof customers can be done at once. In addition to saving on\noperational costs for the ISP, this potentially leads to cheaper\nCPEs if considered on a large scale.\n2) Evolved Packet Core: Virtualizing the EPC is another\nexample of NFV that has attracted a lot of attention from\nindustry. The EPC is the core network for Long Term Evolu-\ntion (LTE) as specified by 3GPP [8]. On the left side of Fig.\n3, we show a basic architecture of LTE without NFV. The\nUser Equipment (UE) is connected to the EPC over the LTE\naccess network (E-UTRAN). The evolved NodeB (eNodeB)\nis the base station for LTE radio. The EPC performs essential\nfunctions including subscriber tracking, mobility management\nand session management. It is made up of four NFs: Serving\nGateway (S-GW), Packet Data Network (PDN) Gateway (P-\nGW), Mobility Management Entity (MME), and Policy and\nCharging Rules Function (PCRF). It is also connected to\nexternal networks, which may include the IP Multimedia\nCore Network Subsystem (IMS). In the current EPC, all its\nfunctions are based on proprietary equipment. Therefore, even\nminor changes to a given function may require a replacement\nof the equipment. The same applies to cases when the capacity\nof the equipment has to be changed.\nOn the right side of Fig. 3, we show the same architecture in\nwhich the EPC is virtualized. In this case, either all functions\n2The chain of functions that make up a service for which the connectivity\norder is important is know as VNF Forwarding Graph (VNFFG) [9]. In\naddition to sequencing requirements, the links in a VNFFG may split (i.e.\nfrom one function, packets could take one of many paths which lead to similar\nfunctionality), or may join.\nFig. 3. Virtualization of the EPC\nin the EPC, or only a few of them are transferred to a shared\n(cloud) infrastructure. Virtualizing the EPC could potentially\nlead to better flexibility and dynamic scaling, and hence allow\nTSPs to respond easily and cheaply to changes in market\nconditions. For example, as represented by the number of\nservers allocated to each function in Fig. 3, there might be\na need to increase user plane resources without affecting the\ncontrol plane. In this case, VNFs such as a virtual MME\nmay scale independently according to their specific resource\nrequirements. In the same way, VNFs dealing with the data\nplane might require a different number of resources than those\ndealing with signaling only. This flexibility would lead to more\nefficient utilization of resources. Finally, it also allows for\neasier software upgrades on the EPC network functions, which\nwould hence allow for faster launch of innovative services.\nC. Related Work and Open Questions\nWhile both industry and academia embrace NFV at unprece-\ndented speeds, the development is still at an early stage, with\nmany open questions. As TSPs and vendors look at the details\nof implementing NFV and accomplishing its foreseen goals,\nthere are concerns about the realization of some of these goals\nand whether implementation translates to the benefits initially\nexpected. There are important unexplored research challenges\nsuch as testing and validation [10], resource management,\ninter-operability, instantiation, performance of VNFs, etc, that\nshould be addressed. Even areas being explored such as\nMANO still have open questions especially with regard to\nsupport for heterogeneity.\nThere have been recent efforts to introduce NFV, explain its\nperformance requirements, architecture, uses cases and poten-\ntial approaches to challenges [3]. A discussion of challenges\nto introducing NFV in mobile networks, with a focus on\nvirtualized evolved packet core is presented in [11], while\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 4\nthe reliability challenges of NFV infrastructures are examined\nin [12]. However, all efforts in current literature are narrow\nin at least one of the following main ways: (1) with regard\nto scope, they do not consider important aspects of NFV,\nsuch as its relationship with SDN and cloud computing, (2)\nlimited review and analysis of standardization activities, and\n(3) incomplete descriptions of ongoing research and state-of-\nthe-art efforts and research challenges.\nThis paper examines the state-of-the-art in NFV and iden-\ntifies key research areas for future exploration. In addition,\nwe explore the relationship between NFV and two closely\nrelated fields, SDN [13] and cloud computing [14]. We also\ndescribe the different research and industrial initiatives and\nprojects on NFV, as well as early implementation, proof of\nconcepts and product cases. To the best of our knowledge, this\npaper presents the most comprehensive state-of-the-art survey\non NFV to date.\nD. Organization\nThe rest of this paper is organized as follows: Section II\npresents the NFV architecture that has been proposed by ETSI,\nand discusses its limitations. We propose a reference business\nmodel and identify important design considerations in section\nIII. In section IV, we introduce SDN and cloud computing,\ndescribing the relationship between them and NFV, as well\nas current efforts to implement environments involving all of\nthem. In section V, we survey the major projects on NFV\nas well as early implementations, use cases and commercial\nproducts. Based on a qualitative analysis of the state-of-the-art,\nsection VI identifies key research areas for further exploration,\nand section VII concludes this paper.\nII. NFV ARCHITECTURE\nAccording to ETSI, the NFV Architecture is composed of\nthree key elements: Network Function Virtualization Infras-\ntructure (NFVI), VNFs and NFV MANO [15]. We represent\nthem graphically in Fig. 4. In this section these elements are\ndefined [5], [15], [16].\nA. NFV Infrastructure (NFVI)\nThe NFVI is the combination of both hardware and software\nresources which make up the environment in which VNFs\nare deployed. The physical resources include commercial-off-\nthe-shelf (COTS) computing hardware, storage and network\n(made up of nodes and links) that provide processing, storage\nand connectivity to VNFs. Virtual resources are abstractions\nof the computing, storage and network resources. The ab-\nstraction is achieved using a virtualization layer (based on a\nhypervisor), which decouples the virtual resources from the\nunderlying physical resources. In a data center environment,\nthe computing and storage resources may be represented in\nterms of one or more Virtual Machines (VMs), while virtual\nnetworks are made up of virtual links and nodes. A virtual\nnode is a software component with either hosting or routing\nfunctionality, for example an operating system encapsulated\nin a VM. A virtual link is a logical interconnection of two\nvirtual nodes, appearing to them as a direct physical link with\ndynamically changing properties [17].\nPhysical Resources\nVirtual Resources\nServices\nNetwork Function Virtualization Infrastructure\nM\na\nn\na\ng\ne\nm\ne\nn\nt \na\nn\nd\n O\nrc\nh\ne\nst\nra\nti\no\nn\nComputing, Storage, Network Resources\nVirtual Network Functions\nComputing, Storage, Network Resources\nM\na\nn\na\ng\ne\nm\ne\nn\nt \na\nn\nd\n O\nrc\nh\ne\nst\nra\nti\no\nn\nVNF 1 VNF 2 VNF 3 VNF n. . .\nFig. 4. Network Function Virtualization Architecture\nB. Virtual Network Functions and Services\nA NF is a functional block within a network infrastructure\nthat has well defined external interfaces and well-defined\nfunctional behaviour [15]. Examples of NFs are elements\nin a home network, e.g. Residential Gateway (RGW); and\nconventional network functions, e.g. DHCP servers, firewalls,\netc. Therefore, a VNF is an implementation of an NF that is\ndeployed on virtual resources such as a VM. A single VNF\nmay be composed of multiple internal components, and hence\nit could be deployed over multiple VMs, in which case each\nVM hosts a single component of the VNF [5]. A service\nis an offering provided by a TSP that is composed of one\nor more NFs. In the case of NFV, the NFs that make up\nthe service are virtualized and deployed on virtual resources\nsuch as a VM. However, in the perspective of the users,\nthe services\u2212whether based on functions running dedicated\nequipment or on VMs\u2212should have the same performance.\nThe number, type and ordering of VNFs that make it up are\ndetermined by the service\u2019s functional and behavioral speci-\nfication. Therefore, the behaviour of the service is dependent\non that of the constituent VNFs.\nC. NFV Management and Orchestration (NFV MANO)\nAccording to the ETSI\u2019s MANO framework [18],\nNFV MANO provides the functionality required for the\nprovisioning of VNFs, and the related operations, such as\nthe configuration of the VNFs and the infrastructure these\nfunctions run on. It includes the orchestration and lifecycle\nmanagement of physical and/or software resources that\nsupport the infrastructure virtualization, and the lifecycle\nmanagement of VNFs. It also includes databases that\nare used to store the information and data models which\ndefine both deployment as well as lifecycle properties of\nfunctions, services, and resources. NFV MANO focuses on\nall virtualization-specific management tasks necessary in the\nNFV framework. In addition the framework defines interfaces\nthat can be used for communications between the different\ncomponents of the NFV MANO, as well as coordination with\ntraditional network management systems such as Operations\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 5\nSupport System (OSS) and Business Support Systems (BSS)\nso as to allow for management of both VNFs as well as\nfunctions running on legacy equipment.\nDiscussion: The ETSI-proposed NFV reference architecture\nspecifies initial functional requirements and outlines the re-\nquired interfaces. However, the ETSI\u2019s scope of work is rather\nlimited, excluding aspects such as control and management of\nlegacy equipment [5]. This could make it difficult to specify\nthe operation and MANO of an end-to-end service involving\nboth legacy functions and VNFs. In addition, standards and/or\nde-facto best practices and reference implementations of the\nVNFs, infrastructure, MANO and detailed definitions of re-\nquired interfaces are not yet available.\nIn particular, it can be seen from current NFV solutions\nthat vendors have differing ideas on what constitutes an NFVI\nand VNFs, and how both of them can be modeled. There\nremains a number of open questions such as: (1) which NFs\nshould be deployed in data center nodes, and which ones\nin operator nodes; (2) which functions should be deployed\non dedicated VMs and which ones in containers3; (3) what\nquantity and types of NFVI resources will be required to\nrun specific functions; and (4) operational requirements of\nenvironments that involve both VNFs and those running on\nlegacy equipment. While many of these questions such as\ninter-operability and interface definition will be addressed in\nthe second Phase of ETSI\u2019s work, time is of the essence. Since\nboth vendors and TSPs are already investing significantly in\nNFV, we could reach a point where it is impossible to reverse\nthe vendor-specific solutions.\nIII. BUSINESS MODEL AND DESIGN CONSIDERATIONS\nUsing the architecture represented in Fig. 4, and based on\nbusiness models for network virtualization [20] and cloud\ncomputing [14], we identify five main players in a NFV\nenvironment and propose a reference business model that\nillustrates the possible business relationships between them\nas shown in Fig. 5. We also discuss important NFV system\ndesign considerations.\nA. Business Model\n1) Infrastructure Provider (InP): InPs deploy and manage\nphysical resources in form of data centers and physical net-\nworks. It is on top of these resources that virtual resources may\nbe provisioned and leased through programming interfaces to\none or more TSPs. The InPs may also determine how the pool\nof the available resources are allocated to the TSPs. In NFV,\nexamples of InPs could be public data centers such as those\nby Amazon, or private servers owned by TSPs. If a given InP\nis not able to provide resources fully or in part to a given\nTSPs, negotiations and hence coalitions can be formed with\nother InPs so as to provision multi-domain VNFs [21].\n3In fact, even the fact whether containers may be used to host VNFs and\nthe corresponding ecosystem still needs research [19].\nBrokers\nInfrastructure Provider (InP) \nComputing, Storage, Network Resources\nUserTelecommunications Service \nProvider (TSP)\n2\n3\n4\nVNF \nProvider \n(VNFP)\nServer \nProvider\n(SP)\n1\n2\nFig. 5. Proposed NFV Business Model\n2) Telecommunications Service Provider (TSP): TSPs4\nlease resources from one or more InPs, which they use for\nrunning VNFs. They also determine the chaining of these\nfunctions to create services for end users. In a more general\ncase, TSPs may sub-lease their virtual resources to other TSPs.\nIn such a case, the reselling TSP would take up the role of a\nInP. In cases where the InP is private or in-house, e.g. provided\nby TSP network nodes or servers, then the InP and TSP may\nbe one entity.\n3) VNF Providers (VNFPs) and Server Providers (SPs):\nNFV splits the role of traditional network equipment vendors\n(such as Cisco, Huawei, HP and Alcatel-Lucent) into two:\nVNFPs and SPs. VNFPs provide software implementations\nfor NFs. These functions may either be provided directly to\nTSPs (via interface 1), or VNFPs could provide them to InPs\n(via interface 2), who would then provide both infrastructure\nas well as VNFs to TSPs. It is also possible that TSPs develop\n(some of) their own NFs (software). In this case, VNFPs and\nTSPs would be one entity.\nIn the same way, SPs provide industry standard servers on\nwhich VNFs can be deployed. These servers may be provided\nto InPs (in case the functions will be run in a cloud), or to\nTSPs (in case the functions will be run in the network nodes of\nTSPs). It is worth noting that these entities (VNFPs and SPs)\nmay in fact be one company. The main difference is that the\nfunctions they provide are not tied to running on equipment\nwith specialized functionality or made by a specific vendor.\nIn other words, a TSP could purchase VNFs from one entity,\nand servers from a different one.\n4) Brokers: In some cases, a TSP may need to purchase\nfunctions which make up a single service from multiple\nVNFPs, and/or to deploy and manage the resulting end-to-\nend services running on resources from multiple InPs. In this\ncase, it may be necessary to have a brokerage role. The brokers\nwould receive resource and/or functions requirements from\nTSPs and then discover, negotiate and aggregate resources and\nfunctions from multiple InPs, VNFPs and SPs to offer them as\n4In this paper, we use the term TSP to generally mean all service providers.\nThis includes service providers such as Netflix that deploy services with\ncaches in different locations, as well as the traditional TSPs such as Telefonica\nand Deutsche Telecom.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 6\na service to the TSP. This role is only included in the model\nfor completeness as it may not be required in all cases of the\nNFV ecosystem.\n5) End User: End users are the final consumers of the\nservices provided by TSPs. They are similar to the end users\nin the existing Internet, except that the existence of multiple\nservices from competing TSPs enables them to choose from\na wide range of services. End users may connect to multiple\nTSPs for different services.\nFinally, the arrows in Fig. 5 indicate business relationships\nor interfaces between the the different entities. For example,\nVNFPs and/or SPs use interfaces 1 and 2 to negotiate and/or\nprovide VNFs and commodity servers respectively, to TSPs\nand InPs, while TSPs use interfaces 3 and 4 for their interac-\ntions with brokers and users respectively.\nB. NFV Design Considerations\nAs NFV matures, it is important to note that it is not\nonly sufficient to deploy NFs over virtualized infrastructures.\nNetwork users are generally not concerned with the complexity\n(or otherwise) of the underlying network. All users require is\nfor the network to allow them access to the applications they\nneed, when they need them. Therefore, NFV will only be an\nacceptable solution for TSPs if it meets key considerations\nidentified below.\n1) Network Architecture and Performance: To be accept-\nable, NFV architectures should be able to achieve performance\nsimilar to that obtained from functions running on dedicated\nhardware. This requires that all potential bottlenecks at all\nlayers of the stack are evaluated and mitigated. As an example,\nif VNFs belonging to the same service are placed in different\nVMs, then there must be a connection between these two VMs,\nand this connection must provide sustained, aggregated high\nbandwidth network traffic to the VNFs. To this end, it may\nbe important for the network to be able to take advantage of\nconnections to the network interfaces that are high-bandwidth\nand low latency due to processor offload techniques such\nas direct memory access (DMA)[22] for data movement and\nhardware assist for CRC computation [23], [24].\nIn addition, some VNFs such as Deep Packet Inspection\n(DPI) are network and compute intensive, and may require\nsome form of hardware acceleration [25] to be provided by\nthe NFVI to still meet their performance goals [26]. Some\nrecent efforts [27] have studied the implications of utilizing\nData Plane Development Kits (DPDKs) for running VNFs and\nshown that near-native (i.e., similar to non-virtualized) perfor-\nmance for small and large packet processing can be achieved.\nIn addition, Field-Programmable Gate Arrays (FPGAs) have\nalso been shown to enhance performance of VNFs [28], [29].\nFinally, VNFs should only be allocated the storage and com-\nputation resources they need. Otherwise, NFV deployments\nmay end up requiring more resources, and hence there would\nbe no justification for transiting to NFV.\n2) Security and Resilience: The dynamic nature of NFV\ndemands that security technologies, policies, processes and\npractices are embedded in its genetic fabric [30]. In particular,\nthere are two important security risks that should be considered\nin NFVI designs: (1) functions or services from different\nsubscribers should be protected/isolated from each other. This\nhelps to ensure that functions are resilient to faults and attacks\nsince a failure or security breach in one function/service\nwould not affect another. (2) the NFVI (physical and virtual\nresources) should be protected from the delivered subscriber\nservices. One way to secure the NFVI is to deploy internal\nfirewalls within the virtual environment [24]. These would\nallow for the NFV MANO to access to the VNFs without\nletting malicious traffic from the customer networks into the\nNFVI. Finally, to make service deployment resilient, it may\nbe necessary for functions that make up the same service not\nbe hosted by physical resources in the same fault or security\ndomain during deployment.\n3) Reliability and Availability: Whereas in the IT domain\noutages lasting seconds are tolerable and a user typically\ninitiates retries, in telecommunications there is an underlying\nservice expectation that outages will be below the recognizable\nlevel (i.e. in the order of milliseconds), and service recovery\nis performed automatically. Furthermore, service impacting\noutages need to be limited to a certain amount of users\n(e.g. a certain geography) and network wide outages are not\nacceptable [31]. These high reliability and availability needs\nare not only a customer expectation, but often a regulatory\nrequirement, as TSPs are considered to be part of critical\nnational infrastructure, and respective legal obligations for ser-\nvice assurance/business continuity are in place. However, not\nevery function has the same requirements for resiliency: For\nexample, whereas telephony usually has the highest require-\nments for availability, other services, e.g. Short Messaging Ser-\nvice (SMS), may have lower availability requirements. Thus,\nmultiple availability classes may be defined which should be\nsupported by a NFV framework [31]. Again, functions may\nbe deployed with redundancy to recover from software or\nhardware failures.\n4) Support for Heterogeneity: The main selling point of\nNFV is based on breaking the barriers that result from propri-\netary hardware-based service provision. It is therefore needless\nto mention that openness and heterogeneity will be at the\ncore of NFV\u2019s success. Vendor-specific NFV solutions with\nvendor-specific hardware and platform capabilities defeat the\noriginal NFV concept and purpose. Therefore, any acceptable\nNFV platform must be an open, shared environment capable\nof running applications from different vendors. InPs must be\nfree to make their own hardware selection decisions, change\nhardware vendors, and deal with heterogeneous hardware.\nIn addition, such platforms should be able to shield VNFs\nfrom the specifics of the underlying networking technolo-\ngies (e.g., optical, wireless, sensor etc.) [32]. Finally, and\nequally important, platforms should allow for possibilities of\nan end-to-end service to be created on top of more than\none infrastructural domain without restrictions, and without\nneed for technology specific solutions. While virtualization\nwithin a single InP reduces cost, inter-provider NFV enables\nthe \u201cproductization\u201d of the same internal software functions\nand results in opportunities for revenue growth [33]. As an\nexample, if a mobile user subscribing to given TSP roams into\nthe coverage of another TSP, the user should not be restricted\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 7\nto voice, data and simple messaging services. The real power\nof NFV would be realized if such a user is able to choose\na firewall or security service from the current TSP, or use a\ncombination of functions from the host TSP and others from\nthe one for which he has coverage.\n5) Legacy Support: Backward compatibility will always be\nan issue of high concern for any new technology. NFV is\nnot an exception. It is even more important for the telecom-\nmunications industry, given that even for a given operator\nthat decides to make the transition to NFV, it may take\ntime for this to be complete, let alone the fact that some\noperators will do this faster than others. Therefore, support\nfor both physical and virtual NFs is important for operators\nmaking the transition to NFV as they may need to manage\nlegacy physical assets alongside virtualized functions for some\ntime. This may necessitate having an orchestration strategy\nthat closes the gap between legacy services and NFV. It is\nimportant to maintain a migration path toward NFV, while\nkeeping operators\u2019 current network investments in place [34].\nInPs must be able to function in an environment whereby\nboth virtualized and physical network functions operate on\nthe network simultaneously.\n6) Network Scalability and Automation: In order to achieve\nthe full benefits of NFV, a scalable and responsive networking\nsolution is necessary. Therefore, while meeting the above\ndesign considerations, NFV needs to be acceptably scalable to\nbe able to support millions of subscribers. To give an example,\nmost current NFV proof-of-concepts are based on deploying a\nVM to host a VNF. Just like a single VM may not be able to\nmeet the requirements of a given function, it is not economical\nto deploy a VM per NFV, as the resulting VM footprint\nwould be too large, and would lead to scalability problems\nat the virtualization layer. However, NFV will only scale if all\nof the functions can be automated. Therefore, automation of\nprocesses is of paramount importance to the success of NFV\n[4]. In addition, the need for dynamic environments requires\nthat VNFs can be deployed and removed on demand and scaled\nto match changing traffic.\nIV. RELATED CONCEPTS\nThe need for innovativeness, agility and resource sharing is\nnot new. In the past, the communications industry has invented\nand deployed new technologies to help them offer new and\nmultiple services in a more agile, cost and resource effective\nway. In this section, we introduce two such concepts that are\nclosely related to NFV; cloud computing and SDN. We also\ndiscuss the relationship between NFV and each of them, as\nwell as current attempts to enable all three to work together.\nA. Cloud Computing\nAccording to NIST [35] cloud computing is \u201ca model for\nenabling ubiquitous, convenient, on-demand network access\nto a shared pool of configurable computing resources (e.g.,\nnetworks, servers, storage, applications, and services) that can\nbe rapidly provisioned and released with minimal management\neffort or service provider interaction\u201d. In a cloud computing\nenvironment, the traditional role of service provider is divided\ninto two: the infrastructure providers who manage cloud plat-\nforms and lease resources according to a usage-based pricing\nmodel, and service providers, who rent resources from one or\nmany infrastructure providers to serve the end users [14]. The\ncloud model is composed of five essential characteristics and\nthree service models [35]. We briefly introduce these in the\nfollowing subsections.\n1) Essential Characteristics of Cloud Computing: On-\ndemand self-service. A consumer can unilaterally provision\ncomputing capabilities, such as server time and network\nstorage, as needed automatically without requiring human\ninteraction with each service provider.\nBroad network access. Capabilities (e.g. compute resources,\nstorage capacity) are available over the network and accessed\nthrough standard mechanisms that promote use by hetero-\ngeneous thin or thick client platforms (e.g., mobile phones,\ntablets, laptops, and workstations).\nResource pooling. The provider\u2019s computing resources are\npooled to serve multiple consumers using a multi-tenant\nmodel, with different physical and virtual resources dynami-\ncally assigned and reassigned according to consumer demand.\nRapid elasticity. Capabilities can be elastically provisioned\nand released, in some cases automatically, to scale rapidly\noutward and inward commensurate with demand.\nMeasured service. Cloud systems automatically control and\noptimize resource use by leveraging a metering capability\nat some level of abstraction appropriate to the type of ser-\nvice (e.g., storage, processing, bandwidth, and active user\naccounts).\n2) Cloud Computing Service Models: The three service\nmodels of cloud computing are shown in Fig. 6, and defined\nbelow [35].\nSoftware as a Service (SaaS). The user is able to use the\nproviders applications running on a cloud infrastructure. The\napplications are accessible from various client devices through\neither a thin client interface, such as a web browser (e.g., web-\nbased email), or a program interface.\nPlatform as a Service (PaaS). The user is able to deploy\nonto the cloud infrastructure consumer-created or acquired\napplications created using programming languages, libraries,\nservices, and tools supported by the provider.\nInfrastructure as a Service (IaaS). The user is able to pro-\nvision processing, storage, networks, and other fundamental\ncomputing resources where the consumer is able to deploy and\nrun arbitrary software, which can include operating systems\nand applications.\n3) Relationship between Cloud Computing and NFV: In\ngeneral, NFV is not restricted to functions for services in\ntelecommunications. In fact, many IT applications already\nrun on commodity servers in the cloud [40]. However, since\nmost of the promising use cases for NFV originate from the\ntelecommunications industry, and because the performance\nand reliability requirements of carrier-grade functions are\nhigher than those of IT applications, the discussions in this\npaper consider that acceptable NFV performance should be\ncarrier-class. In Fig. 6, we have mapped the cloud service\nmodels to part of the NFV architecture. It can be observed that\nIaaS corresponds to both the physical and virtual resources in\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 8\nHardware\nInfrastructure\nPlatform\nSoftware\nIaaS\nData Centres\nPaaS\nSaaS\nFacebook, Google Apps, Twitter, \nZenDesk, Saleforce.com, Zoho Office\nCPU, Storage, Bandwidth\nBusiness Applications, \nWeb Services\nVirtual Machines\nSoftware Framework\nLayered Resources Model Example Mapping to NFV \nArchitecture\nNFVI\nPhysical and \nVirtual Resources\nVNF 1 VNF n\nVNFs / Services\nHeroku, Azure, Google AppEngine, \nRedHat OpenShift, force.com\nOpenStack, Azure, Amazon Web Services \n(EC2, S3, DynamoDB), GoGrid, Rackspace\nFig. 6. Cloud Computing Service Models and their Mapping to Part of the NFV Reference Architecture\nTABLE I\nCOMPARISON OF NFV IN TELECOMMUNICATION NETWORKS AND CLOUD COMPUTING\nIssue NFV (Telecom Networks) Cloud Computing\nApproach Service/Function Abstraction Computing Abstraction\nFormalization ETSI NFV Industry Standard Group DMTF Cloud Management Working Group [36]\nLatency Expectations for low latency Some latency is acceptable\nInfrastructure Heterogeneous transport (Optical, Ethernet, Wireless) Homogeneous transport (Ethernet)\nProtocol Multiple Control Protocols (e.g OpenFlow [37], SNMP [38]) OpenFlow\nReliability Strict 5 NINES availability requirements [39] Less strict reliability requirements [40]\nRegulation Strict Requirements e.g NEBS [41] Still diverse and changing\nthe NFVI, while the services and VNFs in NFV are similar to\nthe SaaS service model in cloud computing.\nBeing the cheapest choice for testing and implementation,\nmost NFV proof of concepts and early implementations have\nbeen based on deploying functions on dedicated VMs in the\ncloud. The flexibility of cloud computing, including rapid\ndeployment of new services, ease of scalability, and reduced\nduplication, make it the best candidate that offers a chance\nof achieving the efficiency and expense reduction that are\nmotivating TSPs towards NFV.\nHowever, deploying NFs in the cloud will likely change\nevery aspect of how services and applications are developed\nand delivered. While work continues to be done with respect\nto networked clouds and inter-cloud networking [42], [43],\ntelecommunication networks differ from the cloud computing\nenvironment in at least three ways: (1) data plane workloads\nin telecom networks imply high pressure on performance,\n(2) telecom network topologies place tough demands on the\nnetwork and the need for global network view for management\n[44], (3) the telecom industry requires scalability, five-nines\navailability and reliability. In traditional telecom networks,\nthese features are provided by the site infrastructure. If NFV\nshould be based on cloud computing, these features need to be\nreplicated by the cloud infrastructure in such a way that they\ncan be orchestrated, as orchestrated features can be exposed\nthrough appropriate abstractions, as well as being coupled with\nadvanced support for discoverability and traceability [45]. It is\ntherefore worth stressing that NFV will require more consider-\nations than just transferring carrier class network functions to\nthe cloud. There is need to adapt cloud environments so as to\nobtain carrier-class behaviour [44]. In Table I, we summarize\nthe relationship between NFV for telecom networks and cloud\ncomputing.\n4) Research on Cloud-based NFV: In order for NFV to\nperform acceptably in cloud computing environments, the\nunderlying infrastructure needs to provide a certain number of\nfunctionalities which range from scheduling to networking and\nfrom orchestration to monitoring capacities. While OpenStack\nhas been identified as one of the main components of a\ncloud-based NFV architectural framework, it currently does\nnot meet some NFV requirements. For example, through a\ngap analysis in [46], it was noted that, among other gaps,\nOpenStack neither provides detailed description of network\nresources including Quality-of-Service (QoS) requirements,\nnor supports a resource reservation service and consequently\nit does not provide any interface for resource reservation.\nIn addition, through measurements some performance\ndegradation has been reported [47]. Some efforts have already\nbeen dedicated to study the requirements needed to make\nthe performance of cloud carrier-grade [48], [49], [50]. In\nparticular, OpenANFV [28] proposes an OpenStack-based\nframework which uses hardware acceleration to enhance the\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 9\nSDN \nController\nNetwork \nApplications Load Balancer\n. . .   Routing MAC Learning\nTraditional Network: Distributed Control and \nMiddleboxes (e.g. Firewall, Intrusion Detection, etc.)\nSoftware Defined Network: Control Logic decoupled \nfrom Forwarding HardwareFig. 7. Distributed Control and Middleboxes (e.g. Firewall,\nIntrusion Detection, etc.) in Traditional Networks\nSDN Controller\nNetwork/Business Applications\nLoad Balancing .    .     .   Routing MAC Learning\nInterface e.g. \nOpenflow\nInfrastructure Layer\nControl Layer\nApplication Layer\nAPIs\nForwarding \nSwitches\nNetwork Services\nFig. 8. Logical Layers in a Software Defined Network\nperformance of VNFs. The author\u2019s efforts are motivated by\nthe observation that for some functions (e.g., DPI, network\ndeduplication (Dedup) and NAT), industry standard servers\nmay not achieve the required levels of performance. Therefore,\nOpenANFV aims at providing elastic, automated provisioning\nfor hardware acceleration to VNFs in OpenStack. To this\nend, the tested VNFs (DPI, Dedup and NAT) were allowed\naccess to a predefined set of accelerated behavior and to com-\nmunicate through a hardware-independent interface with the\nhypervisor to configure the accelerator. The authors reported\nperformances 20, 8 and 10 times better for DPI, Dedup and\nNAT respectively.\nB. Software Defined Networking (SDN)\nSDN [51] is currently attracting significant attention from\nboth academia and industry as an important architecture for\nthe management of large scale complex networks, which may\nrequire re-policing or re-configurations from time to time.\nAs shown in Figures 7 and 8, SDN decouples the network\ncontrol and forwarding functions. This allows network control\nto become directly programmable via an open interface (e.g.,\nForCES [52], OpenFlow [53], etc) and the underlying infras-\ntructure to become simple packet forwarding devices (the data\nplane) that can be programmed.\nWhile the SDN control plane can be implemented as pure\nsoftware which runs on industry-standard hardware, the for-\nwarding plane requires an SDN agent [54], and may therefore\nrequire to be implemented in specialized hardware. However,\ndepending on the performance and capacity needs of the SDN\nnetworking element, and depending on whether specialized\nhardware transport interfaces are required, the forwarding\nplane may also be implemented on commodity servers [55].\nFor example, VMware\u2019s NSX platform [56] includes a virtual\nswitch (vSwitch) and controller both of which implement SDN\nprotocols without requiring specialized hardware.\nSDN has the potential to dramatically simplify network\nmanagement and enable innovation and evolution [57]. Ac-\ncording to the Open Network Foundation (ONF) [58], SDN\naddresses the fact that the static architecture of conventional\nnetworks is ill-suited for the dynamic computing and storage\nneeds of today\u2019s data centers, campuses, and carrier environ-\nments. The SDN architecture is [59]:\nProgrammable. SDN makes network control directly pro-\ngrammable since control is decoupled from forwarding func-\ntions. This programmability can be used to automate network\nconfiguration in such a way that network administrators can\nrun \u2018SDN apps\u2019 that help to optimize particular services such\nas VoIP so as to ensure a high Quality-of-Experience (QoE)\nfor phone calls.\nAgile. Abstracting control from forwarding lets adminis-\ntrators dynamically adjust network-wide traffic flow to meet\nchanging needs. This makes the network more agile since logic\nis now implemented in a software running on commodity hard-\nware, which has shorter release cycles than device firmware.\nCentrally managed. Network intelligence is (logically) cen-\ntralized in software-based SDN controllers that maintain a\nglobal view of the network, which appears to applications and\npolicy engines as a single, logical switch.\nOpen standards-based and vendor-neutral. When imple-\nmented through open standards, SDN simplifies network de-\nsign and operation because instructions are provided by SDN\ncontrollers instead of multiple, vendor-specific devices and\nprotocols.\n1) Relationship between SDN and NFV: NFV and SDN\nhave a lot in common since they both advocate for a pas-\nsage towards open software and standard network hardware.\nSpecifically, in the same way that NFV aims at running NFs\non industry standard hardware, the SDN control plane can be\nimplemented as pure software running on industry standard\nhardware. In addition, both NFV and SDN seek to leverage\nautomation and virtualization to achieve their respective goals.\nIn fact, NFV and SDN may be highly complimentary, and\nhence combining them in one networking solution may lead\nto greater value. For example, if it is able to run on a VM,\nan SDN controller may be implemented as part of a service\nchain. This means that the centralized control and management\napplications (such as load balancing, monitoring and traffic\nanalysis) used in SDN can be realized, in part, as VNFs, and\nhence benefit from NFV\u2019s reliability and elasticity features.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 10\nTABLE II\nCOMPARISON OF SOFTWARE DEFINED NETWORKING AND NETWORK FUNCTION VIRTUALIZATION CONCEPTS\nIssue NFV (Telecom Networks) Software Defined Networking\nApproach Service/Function Abstraction Networking Abstraction\nFormalization ETSI ONF\nAdvantage Promises to bring flexibility and cost reduction Promises to bring unified programmable control andopen interfaces\nProtocol Multiple control protocols (e.g SNMP, NETCONF) OpenFlow is de-facto standard\nApplications run Commodity servers and switches Commodity servers for control plane and possibilityfor specialized hardware for data plane\nLeaders Mainly Telecom service providers Mainly networking software and hardware vendors\nBusiness Initiator Telecom service providers Born on the campus, matured in the data center\nIn the same way, SDN can accelerate NFV deployment by\noffering a flexible and automated way of chaining functions,\nprovisioning and configuration of network connectivity and\nbandwidth, automation of operations, security and policy\ncontrol [60]. It is however worth stressing that most of the\nadvantages expected from both NFV and SDN are promises\nthat have not been proven yet.\nHowever, SDN and NFV are different concepts, aimed at\naddressing different aspects of a software-driven networking\nsolution. NFV aims at decoupling NFs from specialized hard-\nware elements while SDN focuses on separating the handling\nof packets and connections from overall network control. As\nstated by the ONF in the description of the SDN architecture\n[54], \u201cthe NFV concept differs from the virtualization concept\nas used in the SDN architecture. In the SDN architecture, vir-\ntualization is the allocation of abstract resources to particular\nclients or applications; in NFV, the goal is to abstract NFs\naway from dedicated hardware, for example to allow them\nto be hosted on server platforms in cloud data centers\u201d. It\ncan be observed that the highest efforts in promoting and\nstandardizing SDN is in data center and cloud computing areas\nwhile telecom carriers are driving similar efforts for NFV.\nFinally, an important distinction is that while NFV can work\non existing networks because it resides on servers and interacts\nwith specific traffic sent to them, SDN requires a new network\nconstruct where the data and control planes are separate. We\nsummarize the relationship between SDN and NFV in Table\nII.\n2) Research on SDN-based NFV: There is currently a lot of\nwork involving the combination of SDN and NFV to enhance\neither of them; including: a ForCES-based framework [61],\nNFV-based monitoring for SDN [62], an abstraction model\nfor both the forwarding model and for the network functions\n[61]. As these efforts show, the unique demands of NFV will\npotentially necessitate a massively complex forwarding plane,\nblending virtual and physical appliances with extensive control\nand application software, some of it proprietary [63]. There\nare two major aspects of SDN that may need to be improved\nin order to meet the requirements of NFV: the Southbound\nAPI (mainly OpenFlow), and controller designs. We discuss\nadvances in each of these two aspects below.\na) Southbound API: OpenFlow is the de-facto imple-\nmentation of a southbound API for SDN. However, before\nwe consider NFV support, even in current SDN environments\nOpenFlow is by no means a mature solution [64]. Since Open-\nFlow targets L2-L4 flow handling, it has no application-layer\nprotocol support and switch-oriented flow control. Therefore,\nusers have to arrange additional mechanism for upper-layer\nflow control. Furthermore, executing a lot of flow matching\non a single switch (or virtual switch) can cause difficulties in\nnetwork tracing and overall performance degradation [65].\nTherefore, OpenFlow will have to be extended to include\nlayers L5-L7 to be able to support NFV. Basta et al. [66]\ninvestigated the current OpenFlow implementation in terms\nof the basic core operations such as QoS, data classification,\ntunneling and charging, concluding that there is a need for an\nenhanced OpenFlow to be able to support some functions in\nan NFV environment. In an implementation of a virtual EPC\nfunction [9], [67] extends OpenFlow 1.2 by defining virtual\nports to allow encapsulation and to allow flow routing using\nthe GTP Tunnel Endpoint Identifier (TEID).\nFinally, while OpenFlow assumes a logically centralized\ncontroller, which ideally can be physically distributed, most\ncurrent deployments rely on a single controller. This does not\nscale well and can adversely impact reliability. In addition,\nnetwork devices in an NFVI require collaboration to be able to\nprovide services, which cannot currently be provided by SDN.\nThere is therefore still a need to improve SDN by considering\ndistributed architectures [68], [69]. It may also be important\nfor TSPs, InPs and ETSI to consider other possible solutions\nsuch as NETCONF [70].\nb) Controller Design: While there are multiple con-\ntrollers that may be used in an SDN environment, all of them\nrequire improvements to be able to support NFV requirements,\nespecially with regard to distributed network management and\nscalability. OpenNF [71], [65] proposes a control plane that\nallows packet processing to be redistributed across a collection\nof NF instances, and provides a communication path between\neach NF and the controller for configuration and decision mak-\ning. It uses a combination of events and forwarding updates to\naddress race conditions, bound overhead, and accommodate a\nvariety of NFs. [72] also designed a protocol to implement the\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 11\ncommunication between the controllers and the VNFs. Finally,\n[73] proposes an architecture that considers the control of both\nSDN and NFV.\nOpenDaylight [74] is one of the few SDN control plat-\nforms that supports a broader integration of technologies in\na single control platform [75]. A collaborative project hosted\nby the Linux Foundation, OpenDaylight is a community-led\nand industry-supported open source framework to accelerate\nadoption, foster new innovation and create a more open and\ntransparent approach to SDN and NFV. The objective of the\nOpenDaylight initiative is to create a reference framework for\nprogrammability and control through an open source SDN and\nNFV solution. The argument of OpenDaylight is that building\nupon an open source SDN and NFV controller enables users\nto reduce operational complexity, extend the life of their\nexisting infrastructure hardware and enable new services and\ncapabilities only available with SDN.\nC. Summary: NFV, SDN and Cloud Computing\nTo summarize the relationship between NFV, SDN, and\ncloud computing, we use Fig. 95. We observe that each of\nthese fields is an abstraction of different resources: compute\nfor cloud computing, network for SDN, and functions for NFV.\nThe advantages that accrue from each of them are similar;\nagility, cost reduction, dynamism, automation, resource scaling\netc.\nThe question is not whether NFs will be migrated to the\ncloud, as this is in fact the general idea of NFV. It is\nwhether the cloud will be a public one like Amazon, or if\nTSPs will prefer to user private ones distributed across their\ninfrastructure. Either way, work will have to be done to make\nthe cloud carrier-grade in terms of performance, reliability,\nsecurity, communication between functions, etc.\nOn the other hand, NFV goals can be achieved using non-\nSDN mechanisms, and relying on the techniques currently in\nuse in many data centers. However, approaches relying on\nthe separation of the control and data forwarding planes as\nproposed by SDN can enhance performance, simplify com-\npatibility with existing deployments, and facilitate operation\nand maintenance procedures. In the same way, NFV is able\nto support SDN by providing the infrastructure upon which\nthe SDN software can be run. Finally, the modern variant of\na data center (the cloud and it\u2019s self-service aspect) relies on\nautomated management that may be obtained from SDN and\nNFV. In particular, aspects such as network as a service, load\nbalancing, firewall, VPN etc. all run in software instantiated\nvia APIs\nV. STATE-OF-THE-ART\nAs the ETSI continues work on NFV, several other standards\norganizations, academic and industrial research projects and\nvendors are working in parallel with diverse objectives, and\nsome of them in close collaboration with the ETSI. In this\nsection, we explore these NFV activities.\n5It is worth remarking that OpenFlow is not the only SDN protocol. In the\nsame way, OpenStack is not the only cloud computing platform. The reason\nwe present only these two in Fig. 9 is that, as already mentioned, they have\nreceived more attention in general, and with regard to NFV.\nNFV\nCloudSDN\nEnables resources sharing, allows \nflexibility and resource pooling hence \nbenefits from economies of scale\nCreates network abstractions to \nenable faster innovation, network \nflexibility and holistic management\nDecouples functions from hardware \nto reduce network operator CAPEX \nand OPEX, and increase service agility\nFunction Abstraction\nNetworking Abstraction Computation Abstraction\nAutomation\nAgility\nOrchestration\nElasticity\nIsolation Resource Pooling\nOpenFlow OpenStack\nVirtual-\nization\nNetworking \nAPIs\nFig. 9. Relationship between NFV, SDN & Cloud Computing\nA. NFV Standardization Activities\n1) IETF Service Function Chaining Working Group: Func-\ntions in a given service have strict chaining and/or ordering\nrequirements that must be considered when decisions to place\nthem in the cloud are made. The Internet Engineering Task\nForce (IETF) [76] has created the Service Function Chaining\nWorking Group (IETF SFC WG) [77] to work on function\nchaining. The IETF SFC WG is aimed at producing an\narchitecture for service function chaining that includes the nec-\nessary protocols or protocol extensions to convey the service\nfunction chain (SFC) and service function path information\n[78] to nodes that are involved in the implementation of service\nfunctions and SFCs, as well as mechanisms for steering traffic\nthrough service functions.\n2) IRTF NFV Research Group (NFVRG): The Internet\nResearch Task Force (IRTF) has created a research group,\nNFVRG [79], to promote research on NFV. The group is aimed\nat organizing meetings and workshops at premier conferences\nand inviting special issues in well-known publications. The\ngroup focuses on research problems associated with NFV-\nrelated topics and on bringing a research community together\nthat can jointly address them, concentrating on problems that\nrelate not just to networking but also to computing and storage\naspects in such environments.\n3) ATIS NFV Forum: The ATIS NFV Forum [33] is an\nindustry group created by the Alliance for Telecommunica-\ntions Industry Solutions (ATIS), a North American telecom\nstandards group. The group is aimed at developing specifi-\ncations for NFV, focusing on aspects of NFV which include\ninter-carrier inter-operability and new service descriptions and\nautomated processes. ATIS NFV Forum plans to develop tech-\nnical requirements, the catalog of needed capabilities and the\nservice chaining necessary for a third party service provider or\nenterprise to integrate the functions into a business application.\nThis process is expected to result in creation of specifications\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 12\nthat are complementary with existing industry work products\nand that extend the current environment for inter-provider\nNFV. The forum also engages open source activities for the\nimplementation of these capabilities in software.\n4) Broadband Forum: The Broadband Forum (BB Forum)\n[80] is an industry consortium dedicated to developing broad-\nband network specifications. Members include telecommuni-\ncations networking and service provider companies, broadband\ndevice and equipment vendors, consultants and independent\ntesting labs (ITLs). BB Forum collaborates with the ETSI after\nagreeing a formal liaison relationship in 2013. The BB Forum\nis working on how NFV can be used in the implementation of\nthe multi-service broadband network (MSBN). To this end, the\nforum has many work items in progress, including: migrating\nto NFV in the context of TR-178 (WT-345), introducing NFV\ninto the MSBN (SD-340), virtual business gateway (WT-328),\nflexible service chaining (SD-326) [81].\n5) Standardization of Related Paradigms: In addition to the\nNFV standardization efforts, other bodies continue to work on\nstandardization of related fields, SDN and cloud computing,\nwhich may also play a significant role in the success of NFV.\nThe DMTF defined the Open Virtualization Format (OVF)\n[82] to address the portability and deployment of physical\nmachines, virtual machines and appliances. OVF enables the\npackaging and secure distribution of virtual machines or\nappliances, providing cross-platform portability and simplified\ndeployment across multiple platforms including cloud envi-\nronments. OVF has adopted by both ANSI as a National\nStandard and ISO as the first international virtualization and\ncloud standard. It takes advantage of the DMTF\u2019s Common\nInformation Model (CIM) [83], where appropriate, to allow\nmanagement software to clearly understand and easily map\nresource properties by using an open standard. OVF and CIM\nmay be used as one option for capturing some or all of\nthe VNF package and/or Virtual Deployment Unit (VDU)\ndescriptor [18], [84]. Although OVF does a great job enabling\nthe provisioning of workloads across various clouds, it is\nstill insufficient for new era cloud applications and runtime\nmanagement.\nIn the same way, the ONF is standardizing the OpenFlow\nprotocol and related technologies. ONF defines OpenFlow as\nthe first standard communications interface defined between\nthe control and forwarding layers of an SDN architecture. ONF\nhas more than 123 member companies, including equipment\nvendors, semiconductor companies, computer companies, soft-\nware companies, telecom service providers, etc.\nIn Table III, we summarize all the activities in the standard-\nization of NFV and related technologies. In general, it can be\nsaid that there is sufficient involvement of standards bodies\nin NFV activities. While many of them work in liaison with\nthe ETSI, some of them such as ATIS and 3GPP SA5 have\nidentified and are working on specific aspects of NFV that\nhave not yet been sufficiently developed by the ETSI. What\nremains to be seen is whether the output in terms of standards\nwill match with the speed at which vendors and TSPs propose\nNFV solutions.\nB. Collaborative NFV Projects\n1) Zoom: Zero-time Orchestration, Operations and Man-\nagement (ZOOM) [85] is a TM Forum project aimed at\ndefining an operations environment necessary to enable the de-\nlivery and management of VNFs, and identifying new security\napproaches that will protect NFVI and VNFs. To achieve these\nobjectives, the project regularly conducts a range of hands-on\ntechnology demos each of which is developed from what they\ncall a catalyst project. Each catalyst project is sponsored by\none or more network operators and equipment and software\nvendors in a real-world demo. The project currently runs about\n9 catalysts with a focus on NFV aspects such as end-to-end\nautomated management, security orchestration, function and\nservice modeling, and using big data technologies and open\nsoftware principles for workload placement.\n2) Open Platform for NFV (OPNFV): OPNFV [86] is\nan open source project founded and hosted by the Linux\nFoundation, and composed of TSPs and vendors. It aims to\nestablish a carrier-grade, integrated, open source reference\nplatform to advance the evolution of NFV and to ensure\nconsistency, performance and inter-operability among multiple\nopen source components. The first outcome of the project is\nreferred to as OPNFV Arno [87], and was released in June\n2015. The release provides an initial build of the NFVI and\nVirtual Infrastructure Manager (VIM) components of the ETSI\narchitecture. It is developer-focused, and can therefore be used\nto explore NFV deployments, develop VNF applications, or to\nevaluate NFV performance and for use case-based testing. In\nparticular, Arno has capabilities for integration, deployment\nand testing of components from other projects such as Ceph,\nKVM, OpenDaylight, OpenStack and Open vSwitch. In addi-\ntion, end users and developers can deploy their own or third\nparty VNFs on Arno to test its functionality and performance\nin various traffic scenarios and use cases.\n3) OpenMANO: OpenMANO [88] is an open source\nproject led by Telefonica, which is aimed at implementing\nETSI\u2019s NFV MANO framework. Specifically, it attempts to\naddress aspects related to performance and portability by\napplying Enhanced Platform Awareness (EPA) [89] principles.\nThe OpenMANO architecture is made up of three main com-\nponents: openmano, openvim and a graphical user interface\n(GUI). OpenMANO has a northbound interface (openmano\nAPI), based on REST, where MANO services are offered\nincluding the creation and deletion of VNF templates, VNF\ninstances, network service templates and network service in-\nstances. Openvim is a lightweight, NFV-specific virtual infras-\ntructure manager implementation directly interfacing with the\ncompute and storage nodes in the NFVI, and with an openflow\ncontroller in order to create the infrastructural network topol-\nogy. It offers a REST-based northbound interface (openvim\nAPI) where enhanced cloud services are offered including\nthe lifecycle management of images, flavors, instances and\nnetworks. The REST interface of openvim is an extended\nversion of the OpenStack API to accommodate EPA.\n4) Mobile Cloud Networking (MCN): MCN [90] is a con-\nsortium consisting of network operators, cloud providers, ven-\ndors, university and research institutes, as well as SMEs. The\nobjective is to cloudify all components of a mobile network\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 13\nTABLE III\nSUMMARY OF NETWORK FUNCTION VIRTUALIZATION STANDARDIZATION EFFORTS\nDescription Focus Area Description of NFV-Related Work\nETSI Industry-led ETSI StandardsGroup NFV\nNFV architectural framework, infrastructure description, MANO,\nsecurity and trust, resilience and service quality metrics.\n3GPP SA5 3GPP\u2019s Telecom Managementworking group\nMobile\nBroadband\nWorking in liaison with the ETSI. Studying the management of\nvirtualized 3GPP network functions.\nIETF SFC\nWG IETF Working Group NFV\nTo propose a new approach to service delivery and operation, an\narchitecture for service function chaining, management and security\nimplications.\nIRTF\nNFVRG IRTF Research Group NFV\nOrganizing NFV-related research activities in both academia and\nindustry through workshops, research group meetings etc. at premier\nconferences.\nATIS NFV\nForum Industry-led Standards Group NFV\nDeveloping specifications for NFV, focusing on inter-carrier\ninteroperability.\nONF Industry-led consortium forstandardization of OpenFlow SDN\nStandardizing the OpenFlow protocol and related technologies. Defines\nOpenFlow as the first standard communications interface defined\nbetween the control and forwarding layers of an SDN architecture.\nDMTF OVF Industry-led consortium Cloud DMTF\u2019s OVF and the CIM may be used as one option for capturingsome or all of the VNF package and/or VDU [18] Descriptor.\nBB Forum\nIndustry-led consortium that\ndevelops broadband network\nspecifications\nNFV in\nBroadband\nNetworks\nCollaborating with the ETSI to achieve a consistent approach and\ncommon architecture for the infrastructure needed to support VNFs.\noperation such as: the access - Radio Access Network (RAN);\nthe core - EPC; the services - IP Multimedia Subsystem (IMS),\nContent Delivery Networks (CDN) and Digital Signage (DSS);\nthe Operational Support Systems (OSS) and the Business\nSupport Systems (BSS).\n5) UNIFY: UNIFY [91] is aimed at researching, developing\nand evaluating the means to orchestrate, verify and observe\nend-to-end service delivery from home and enterprise net-\nworks through aggregation and core networks to data centers.\nTo this end, the project plans to develop an automated,\ndynamic service creation platform, leveraging a fine-granular\nservice chaining architecture. They will also create a service\nabstraction model and a service creation language to enable\ndynamic and automatic placement of networking, computing\nand storage components across the infrastructure. Finally, they\nwill develop a global orchestrator with optimization algorithms\nto ensure optimal placement of elementary service components\nacross the infrastructure.\n6) T-NOVA: T-NOVA [92] aims at promoting the NFV con-\ncept, by proposing an enabling framework, allowing operators\nnot only to deploy VNFs for their own needs, but also to offer\nthem to their customers, as value added services. For this pur-\npose, T-NOVA leverages SDN and cloud management archi-\ntectures to design and implement a management/orchestration\nplatform for the automated provision, configuration, moni-\ntoring and optimization of Network Functions-as-a-Service\n(NFaaS) over virtualized network/IT infrastructures.\n7) CONTENT: CONTENT [93] is an EU funded project\naimed at offering a network architecture and overall\ninfrastructure solution to facilitate the deployment of\nconventional cloud computing as well as mobile cloud\ncomputing. The main objectives of the project include:\n(1) proposing a cross-domain and technology virtualization\nsolution allowing the creation and operation of infrastructure\nslices including subsets of the network and computational\nphysical resources, and (2) supporting dynamic end-to-end\nservice provisioning across the network segments, offering\nvariable QoS guarantees, throughout the integrated network.\nSummary: To summarize, in Table IV we present all the\nprojects giving their main objective, their focus with respect to\nNFV and related areas, and entities leading or funding them.\nAll these projects are guided by the proposals coming out\nof the standardization described earlier, in particular ETSI,\n3GPP and DMTF. It is interesting to observe that all the\nthree industrial projects (ZOOM, OPNFV and OpenMANO)\nsurveyed are focused on MANO. This underlines the im-\nportance of MANO in NFV. MANO is a critical aspect\ntowards ensuring the correct operation of the NFVI as well as\nthe VNFs. Just like the decoupled functions, NFV demands\na shift from network management models that are device-\ndriven to those that are aware of the orchestration needs of\nnetworks which do not only contain legacy equipment, but\nalso VNFs. The enhanced models should have improved oper-\nations, administration, maintenance and provisioning focused\non the creation and lifecycle management of both physical and\nvirtualized functions. For NFV to be successful, all probable\nMANO challenges should be addressed at the current initial\nspecification, definition and design phase, rather than later\nwhen real large scale deployments commence.\nC. NFV Implementations\nIn order to demonstrate the possibility to implement the\nideas proposed by NFV, and to determine performance char-\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 14\nTABLE IV\nSUMMARY OF NETWORK FUNCTION VIRTUALIZATION PROJECTS\nProject Type Leader and/orFunding Focus Areas Main Objective\nZOOM Association ofSPs TM Forum NFV\nEnable more rapid deployment of services by automating\nthe provisioning process and modernizing OSS/BSS models.\nOPNFV CollaborativeProject\nLinux\nFoundation NFV\nBuild an open source reference platform to advance the\nevolution of NFV.\nOpenMANO Vendor Project Telefonica SDN, NFV Implementation of ETSI\u2019s MANO framework.\nMCN Research Project EuropeanUnion SDN, NFV Cloudify all components of a mobile network operation.\nUNIFY Research Project EuropeanUnion NFV\nDevelop an automated, dynamic service creation platform,\nleveraging fine-granular service chaining.\nT-NOVA Research Project EuropeanUnion SDN, NFV Design and implement a MANO platform for NFV.\nCONTENT Research Project EuropeanUnion\nMobile\nNetworks,\nCloud\nProviding a technology platform interconnecting\ngeographically distributed computational resources that can\nsupport a variety of Cloud and mobile Cloud services.\nOpenStack Working Group OpenStackFoundation Cloud, NFV\nIdentify requirements needed to deploy, manage, and run\ntelecom services on top of OpenStack.\nOpenDaylight CollaborativeProject\nLinux\nFoundation SDN, NFV Develop an open platform for SDN and NFV.\nacteristics, a number of use cases for NFV, mostly based on\nthose defined by ETSI [9], have already been implemented.\nThese have mainly been based on implementing single virtual\nfunctions such as routing [94], Broadband Remote Access\nServer [95], policy server [96], deep packet inspection [97],\nEPC [98], [73], RAN [99], [100], [101], [102], monitoring\n[62], CPE [103], [104], [105], [106], [107], [108], GPRS\n[109] and access control [110], in cloud environments. All\nthese originate from the research community. Perhaps not\nsurprisingly, the biggest implementations have arisen from\nequipment vendors. In the remainder of this section, we\nintroduce some key NFV implementations and products from\nindustry.\n1) HP OpenNFV: The HP OpenNFV [111] is a platform,\nbased on HP\u2019s NFV Reference Architecture, upon which\nservices and networks can be dynamically built. The HP\nNFV Reference Architecture is aligned towards providing\nsolutions to each of the functional blocks defined in the ETSI\narchitecture, as a starting point. The NFVI and VNFs parts of\nthe architecture mainly include HP servers and virtualization\nproducts, while MANO is based on three solutions; NFV\nDirector, NFV Manager, and Helion OpenStack. The NFV\nDirector is an orchestrator that automatically manages the\nend-to-end service, by managing its constituent VNFs. It also\nperforms global resource management, allocating resources\nfrom an appropriate pool based on global resource manage-\nment policies. VNF managers are responsible for the VNFs\nlifecycle actions, for example, by deciding to scale in or out.\nIt also includes a Helion OpenStack cloud platform for running\nVNFs.\n2) Huawei NFV Open Lab: The Huawei NFV Open Lab\n[112] is aimed at providing an environment to ensure that NFV\nsolutions and carrier grade infrastructure are compatible with\nemerging NFV standards and with the OPNFV [86]. The lab\nis dedicated to being open and collaborative, expanding joint\nservice innovations with partners, and developing the open\neco-system of NFV to aggregate values and help customers\nachieve business success. They also plan to collaborate with\nthe open source community to innovate on NFV technologies\nto provide use cases for multi-vendors inter-operability around\nNFVI, and VNF-based services.\n3) Intel Open Network Platform (Intel ONP): Intel ONP\n[113] is an ecosystem made up of several initiatives to advance\nopen solutions for NFV and SDN. The initiatives are focused\non Intel product development (such as the Intel ONP Server),\nparticipation in open source development and standardization\nactivities and collaborations with industry for proof of con-\ncepts and trials.\nThe main result of the ONP so far is the Intel ONP Server.\nThis is a reference architecture that integrates open-source and\nhardware ingredients optimized for SDN/NFV. It is aimed at\nenabling manageability by exposing health, state, and resource\navailability, for optimal workload placement and configuration.\nIts software stack consists of released open-source software\nbased on the work done in community projects, including\ncontributions provided by Intel. Some of the key open-source\nsoftware ingredients forming the Intel ONP Server software\nstack are OpenStack, OpenDaylight, DPDK, Open vSwitch,\nand Linux KVM.\n4) CloudNFV: CloudNFV [114] is an NFV, SDN and cloud\ncomputing platform resulting from cooperation between six\ncompanies (6WIND, CIMI Corporation, Dell, EnterpriseWeb,\nOverture Networks, and Qosmos). CloudNFV proposed their\nown NFV architecture [114] which is made up of 3 main\nelements: active virtualization, NFV orchestrator, and NFV\nManager. Active virtualization is a data model which rep-\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 15\nresents all aspects of services, functions and resources. The\nVNF orchestrator has policy rules, which, combined with\nservice orders and the status of available resources, determines\nthe location of the functions that make up the service as\nwell as connections between them. The VNF Manager uses\na data/resource model structured according to TMF rules and\nthe concept of \u201cderived operations\u201d is used to manage VNFs.\nDerived operations are used to integrate the status of available\nresources with the resource commitments for functions of a\ngiven NFV service. The main difference between the ETSI\nNFV MANO and CloudNFV is that unlike the former, the\nlatter considers both management and orchestration as appli-\ncations that can run off a unified data model.\n5) Alcatel-Lucent CloudBand: Alcatel-Lucent\u2019s CloudBand\n[115] is a two-level platform implementing NFV. First, it\nincludes nodes that provide resources like VMs and storage,\nand then, the CloudBand Management System which is the\nfunctional heart of the process. It operates as a work dis-\ntributor that makes hosting and connection decisions based\non policy, acting through cloud management APIs. Virtual\nfunctions are deployed using recipes that define packages of\ndeployable components and instructions for their connection.\nThe recipes can be used to set policies and determine how\nspecific components are instantiated and then connected. The\nplatform uses the Nuage SDN technology [116] and its related\nlinks to create an agile connection framework for the collection\nof nodes and functions, and to facilitate traffic management.\nAlcatel-Lucent recently teamed with RedHat [117] such that\nthe latter could fill the gaps required to use CloudBand and\nOpenStack to promote the inclusion of more NFV require-\nments in the OpenStack upstream and hence build a solution\nthat is optimized for telco NFV environments. Within this\ncollaboration, the CloudBand node uses the RedHat Enterprise\nLinux OpenStack platform as the VIM.\n6) Broadcom Open NFV: The Broadcom Open NFV plat-\nform [118] is aimed at accelerating creation of NFV ap-\nplications across multiple system on chip (SoC) [119] pro-\ncessors, and to allow system vendors to be able to migrate\nvirtual functions between platforms based on various vendor\nsolutions. Broadcom\u2019s platform supports open API standards\nsuch as Linaro\u2019s Open Data Plane (ODP)[120] to access\nacceleration components for scaling critical functionality and\nreducing time-to-market. The ETSI has recently accepted a\nVNF state migration and inter-operability proof of concept in\nwhich Broadcom is demonstrating an implementation of an\nEPC and migrating the virtual function state from operating\non one instruction set architecture (ISA) to a different ISA.\n7) Cisco Open Network Strategy: Cisco\u2019s Open Network\nStrategy (OPN) [121] includes an Evolved Services Platform\n(ESP) and an Evolved Programmable Network (EPN). The\nESP and EPN include a service orchestrator, a VNF manager,\nand a SDN controller, all of which are aimed at providing\nimplementations for some of the functional blocks of ETSI\u2019s\nMANO framework. The service orchestrator is responsible for\nproviding the overall lifecycle management at the network\nservice level. The VNF manager provides scalable, automated\nVNF lifecycle management, including the creation, provision-\ning, and monitoring of both Cisco and third-party VNFs. The\nVNF manager is also responsible for the scale-up and scale-\ndown of the VNFs based on dynamic and fluctuating service\ndemands. It uses cloud-computing resource managers such\nas OpenStack and VMware at the VIM layer to configure\nand provision compute and storage resources across multi-\nvendor data center networks. Finally, the SDN Controller is\nresponsible for connecting the virtualized services (a VNF or\na set of chained VNFs) to the service provider VPNs, the\nInternet, or both. It is designed around open standards and\nAPIs and uses a holistic systems-based approach to manage\nmulti-vendor and multi-tenant data centers, and a common\npolicy-based operating model to reduce costs.\n8) F5 Software Defined Application Services: F5 Software\nDefined Application Services (F5 SDAS) [122], [123], [124]\nprovides Layer 4-7 capabilities to supplement existing Layer\n2-3 network and compute initiatives such as SDN. It enables\nservice injection, consumption, automation, and orchestration\nacross a unified operating framework of pooled resources. It\nis is comprised of three key components: (1) The application\nservice platform supports programmability of both control and\ndata paths. It is extensible and enables new service creation.\n(2) The application services fabric provides core services such\nas scalability, service isolation, multi-tenancy, and integration\nwith the network, and (3) Application services, which are the\nheart of F5 SDAS, are a rich catalog of services across the\napplication delivery spectrum.\n9) ClearWater: ClearWater [125] is an open source imple-\nmentation of an IMS built using web development methods\nto provide voice, video and messaging services to users. It\nleans heavily on established design patterns for building and\ndeploying scalable web applications, adapting these design\npatterns to fit the constraints of SIP and IMS. In particular, all\ncomponents scale out horizontally using simple, stateless load-\nbalancing. In addition, long-lived state is not stored on cluster\nnodes, avoiding the need for complex data replication schemes.\nInstead, long-lived state is stored in back-end service nodes\nusing cloud-optimized storage technologies such as Cassandra.\nFinally, interfaces between the front-end SIP components\nand the back-end services use RESTful web services APIs.\nInterfaces between the various components use connection\npooling with statistical recycling of connections to ensure load\nis spread evenly as nodes are added and removed from each\nlayer.\nMetaswitch [126] contributed the initial code base for\nthe ClearWater project to software developers and systems\nintegrators, and continues to drive the evolution of the code\nbase.\n10) Overture Virtual Service Edge (vSE): Overture vSE\n[24] is an open carrier Ethernet platform for hosting VNFs\nat the service edge. It allows TSPs to instantly deploy on-\ndemand VNFs at the customer premise. It combines carrier\nEthernet access with the benefits of virtualization, openness\nand software-defined services. The result is a single platform\nfor both services and network access, which allows for VNFs\nto be turned up, down, expanded and removed dynamically\nso that compute and storage resources are used only when\nneeded. Additionally, it supports multiple wireline and wire-\nless connections to the WAN, allowing access to all end\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 16\nTABLE V\nSUMMARY OF STATE-OF-THE-ART NFV IMPLEMENTATIONS\nFunctionality Platform Driving Standards\nHP\nOpenNFV\nOpen standards-based NFV reference architecture, labs as a\nsandbox in which carriers and equipment vendors can test vEPC. OpenStack ETSI\nNFV Open\nLab\nSupports the development of NFV infrastructure, platforms and\nservices. OpenStack, OpenDaylight ETSI\nIntel ONP\nProvides developers with a validated template for quickly\ndeveloping and showcasing next-generation, cloud-aware network\nsolutions.\nOpenStack, OpenDaylight 3GPP or TMF\nCloudNFV Provides a platform for virtual network service creation,deployment, and management. OpenStack TMF and ETSI\nAlcatel\nCloudBand\nCan be used for standard IT needs as well as for CSPs who are\nmoving mobile networks into the cloud.\nRed Hat Linux OpenStack\nPlatform ETSI\nBroadBand\nNFV\nMigrate virtual functions between platforms based on various\nvendor solutions. ETSI\nCisco ONS Automated service delivery, improved network and data centeruse, fast deployment of personalized offerings. OpenStack, OpenDaylight ETSI\nF5 SDAS Extensible, context-aware, multi-tenant system for serviceprovisioning\nOpenStack, BIG-IP,\nBIG-IQ [122]\nIETF, 3GPP,\nGSMA, ETSI, ONF\nClearWater SIP-based call control for voice and video communications andfor SIP-based messaging applications.\nApache Cassandra,\nMemcached\n3GPP IMS, ETSI\nTS\nOverture vSE\nHost multiple VNFs in one box, Accelerate service creation,\nactivation and assurance, Decrease inventory and management\ncosts, Optimize service flexibility, Eliminate trucks rolls\nLinux Overture Ensemble\nOSA [24], OpenStack\ncustomer locations.\nThe platform implements an Ethernet access as a VNF,\nand is based on a virtualization platform comprising a Linux\nKVM/QEMU hypervisor, an optimized virtual switch, and\nincludes supports for OpenStack integration with another\nproduct - the Ensemble Service Orchestrator.\nSummary: In Table V we summarize the different state-of-\nart implementations stating their functionality, the standards\nbodies they closely follow and platforms on which they run. It\nis worth remarking that although NFV is gaining momentum,\nit is still an emerging technology and solutions based on\nfinal specifications, and widespread deployments for end-users\nmay take a few years to appear. As the survey above shows,\nmany organizations are investing in and are willing to test\nNFV-based solutions. In addition, it can be observed from\nthese early implementations and platforms, that two aspects\nre-appear in a big number of them: (1) the high focus on\nopen source, and (2) the ability of current SDN and cloud\ntechnologies to support NFV.\nVI. RESEARCH CHALLENGES\nEven with all the anticipated benefits, and despite the\nimmense speed at which it is being accepted by both academia\nand industry, NFV is still in early stages. There still remain\nimportant aspects that should be investigated and standard\npractices which should be established. This section discusses\ncrucial research directions that will be invaluable as NFV\nmatures.\nA. Management and Orchestration\nThe deployment of NFV will greatly challenge current\nmanagement systems and will require significant changes to\nthe way networks are deployed, operated and managed. Such\nchanges are required, not just to provide network and service\nsolutions as before, but also to exploit the dynamism and\nflexibility made possible by NFV [127], [128]. It will likely\nlead to scenarios where functions that provide a service to\na given customer are scattered across different server pools.\nThe challenge then will be to have an acceptable level of\norchestration to make sure that on a per service (or user)\nlevel, all the required functions are instantiated in a coherent\nand on-demand basis, and to ensure that the solution remains\nmanageable [129].\nETSI is working on a MANO framework [18] required\nfor the provisioning of VNFs, and the related operations,\nsuch as the configuration of the VNFs and the infrastructure\nthese functions run on. In a related effort, Cloud4NFV [130],\n[131] has proposed an end-to-end management platform for\nVNFs, which is based on the ETSI architectural specifica-\ntion. Clayman et al. [132] describe an architecture based on\nan orchestrator that ensures the automatic placement of the\nvirtual nodes and the allocation of network services on them\nsupported by a monitoring system that collects and reports\non the behaviour of the resources. NetFATE [133] proposes\nan orchestration approach for virtualized functions, taking\ninto account the service chains needed by traffic flows and\nthe desired QoE. In addition, other MANO frameworks and\narchitectures have been proposed in [134], [135], [136], [137],\n[138], [139], [140].\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 17\nTABLE VI\nSUMMARY OF CHANGES IN ENERGY CONSUMPTION FROM VIRTUALIZING NETWORK FUNCTIONS\nTraffic\n(EXABYTES/MONTH)\nTotal Efficiency\n(MBITS/J)\nTotal Power\n(MWATTS)\nPower Savings\n(MWATTS)\nCummulative Savings\n(2013 - 2018) GJ\nBaseline Network 1, 153.05 0.0328510 116, 203 0.0\nVirtual EPC 1, 153.05 0.0422222 92, 159.8 24, 044.1 5.0\u00d7 109\nVirtual CPE 1, 205.11 0.0352130 113.500 2, 703.63 5.5\u00d7 109\nVirtual RAN 1, 227.88 0.0463708 89, 599.5 26, 604.4 7.5\u00d7 109\nVirtual Video CDN 810.22 0.0346562 80, 029.3 36, 174.6 7.5\u00d7 109\nVirtual Broadband\nNetwork Gateway 1, 169.69 0.0333016 116.260 \u221276.794 \u22121.7\u00d7 10\n7\nVirtual Provider Edge 1, 151.91 0.0328255 116, 180 22.9517 3.8\u00d7 106\nHowever, there are still some open issues. Current ap-\nproaches are focused on NFV management, without con-\nsidering the management challenges in SDN [141]. While\ntraditional management approaches must be improved to ac-\ncommodate each one of them, the demands for management\nare even higher in environments including both. In such cases.\nwe no longer just need to create dynamic traffic flows, but the\nswitching points (locations of functions) are also changing dy-\nnamically. Therefore, a complete management solution should\ncombine requirements from both SDN and NFV.\nIn addition, support for inter-operability is a key require-\nment for NFV. However, looking at the ETSI MANO frame-\nwork, most effort has been on defining intra-operator inter-\nfaces, without clear guidelines on inter-operability. This is\nwhy, while current vendor products are \u201cbased on the ETSI\nMANO framework\u201d, most of them use custom models and/or\nrepresentation for functions and services. Furthermore, the\nneed for dynamism in function means that functions will likely\nbe moved from one VM to another. This underscores the\nimportance of a higher focus on possibilities of an availability\nmonitoring mechanism as part of the end-to-end manage-\nment solution. Finally, while the ETSI-proposed NFV MANO\nframework considers the management and orchestration re-\nquirements of both virtualized and non-virtualized functions\nvia interfaces to traditional network management functions\nOSS/BSS, the relationship between them is yet to be fully\ndefined [142]\nB. Energy Efficiency\nSince energy bills represent more than 10% of TSPs\u2019 OPEX\n[143], reduced energy consumption is one of the strong selling\npoints of NFV. The argument is that with the flexibility\nand ability to scale resource allocations up and down, as\ntraffic demands ebb and flow, TSPs could potentially reduce\nthe number of physical devices operating at any point, and\nhence reduce their energy bills. Yet, NFV will likely make\ndata centers an integral part of telecommunication networks.\nAccording to an analysis in the SMARTer 2020 report from\nGeSI [144], the cloud, if it were a country, would rank 6th\nin the world in terms of its energy demand, and yet this\ndemand is expected to increase by 63% by 2020 [145]. While\nsome progress on energy efficient cloud computing has been\nmade, the fast growing energy needs of data centers continue\nto receive a lot of attention [146], [147]. Therefore, there is\nan urgent need to study whether NFV will meet its energy\nsavings expectations, or whether\u2212like the NFs\u2212the energy\nconsumption will just be transferred to the cloud.\nChina Mobile recently published [148] their experiences\nin deploying a Cloud Radio Access Network (C-RAN). One\nof the tests was performed on their 2G and 3G networks,\nwhere it was observed that by centralizing the RAN, power\nconsumption could be reduced by 41% due to shared air-\nconditioning. In addition, Shehab et al. [149] analyzed the\ntechnical potential for energy savings associated with shifting\nU.S. business software to the cloud. The results suggested a\nsubstantial potential for energy savings. In fact, the authors\nnoted that if all U.S. business users shifted their email,\nproductivity software, and CRM software to the cloud, the\nprimary energy footprint of these software applications could\nbe reduced by as much as 87%.\nIn order to determine the possible effect of energy con-\nsumption on the evolution to VNFs, Bell Labs has recently\nextended its G.W.A.T.T. tool [143]. The tool is able to show\nthe effect of virtualizing different network functions based on\nforecasts for traffic growth. G.W.A.T.T. divides the network\ninto six domains (Home & Enterprise, Access & Aggregation,\nMetro, Edge, Core and Service Core & Data Centers). Each\nnetwork domain can be edited to select different network\nmodels and technologies and hence analyze its energy impact.\nBased on the tool\u2019s default settings and using EPC network\nmodels for 2015, the tool shows that total network energy\nefficiency is 0.0422222 MBITS/J, total energy consumption\nis 92, 159.8 MWATTS, and that the energy savings resulting\nfrom virtualizing the EPC would be 24, 044.1 MWATTS. For\nthe same use case, the tool showed that the total energy savings\nover a five year period (using 2013 as baseline) would be\n5.0\u00d7109 GJ, and that the energy efficiency of the core network\n1.86393 MBITS/J. The results for some other NFV use cases,\nincluding those for the baseline network6 are summarized in\nTable VI. However, while the tool is an important step in\nattaching numbers to the energy savings expected from NFV,\nit can still be improved. In particular, it does not yet have a\n6A baseline network is one where all functions are run in physical\nequipment, using the tool\u2019s default technologies and settings.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 18\ndetailed technical documentation. For example, Cisco\u2019s visual\nnetworking index [150] forecasts that annual global IP traffic\nwill reach 1000 exabytes in 2016. Based on this, the (monthly,\n2015) traffic values in Table VI seem to be too high, yet it is\ncurrently not possible to know how these values are derived.\nTherefore, we expect that the energy efficiency of cloud\nbased NFs will continue to receive attention. NFV will put\nInPs under even more pressure to manage energy consumption\n[138] not to only to cut down energy expenses, but also to meet\nregulatory and environmental standards. Topics with regard\nto energy efficient hardware which could allow reductions in\nCPU speeds and partially turning off some hardware com-\nponents, more energy-aware function placement, scheduling\nand chaining algorithms, will be important. An example could\nbe to track the cheapest prices for energy costs and adapt the\nnetwork topology and/or operating parameters to minimize the\ncost of running the network [60]. However, all these should\nbe carefully considered to ensure that there is a balance in the\ntrade-off between energy efficiency and function performance\nor service level agreements.\nC. NFV Performance\nThe concept of NFV is to run NFs on industry standard\nservers. This means that server providers should produce\nequipment without knowledge of the characteristics of func-\ntions that could run on them in future. In the same way, VNF\nproviders should ensure that the functions will be able to run\non commodity server. This raises the question of whether\nfunctions run on industry standard servers would achieve\na performance comparable to those running on specialized\nhardware, and whether these functions would be portable\nbetween the servers [60]. Finding answers to these questions\nhas been another focus of the ETSI, and resulted into a\n\u201cPerformance & Portability Best Practises\u201d specification [151].\nThe specification gives performance test results on NFV use\ncases such as DPI, C-RAN, BRAS, etc. The results proved\nthat if \u201cbest practices were followed\u201d it was not only possible\nto achieve high performance (upto 80 Gbps for a server)\nin a fully virtualized environment, but that the performance\nwas predictable, consistent and in vendor-agnostic manner,\nleveraging features commonly available in current state-of-the-\nart servers [60].\nIn a related effort, results from China Mobile\u2019s C-RAN\ndeployment [148] indicated that the Common Public Radio In-\nterface (CPRI) [152] over a wavelength-division multiplexing\n(WDM) front-haul transport solution gives ideal performance,\nwith no impact on radio performance. The tests also verified\nthe feasibility of using a general purpose platform (GPP)\nand the NFV implementation. In particular, a GPP based C-\nRAN prototype with the ability to support as many as 90\nTD-LTE carriers, 15 FDD-LTE carriers and 72 GSM carriers\nwas developed. The prototype demonstrated a similar level of\nperformance to the traditional DSP/FPGA based systems.\nHowever, performance at high speeds is an issue even in\nnon-virtualized NFs [29], [153]. Therefore, techniques such\nas hardware acceleration will also be important for NFV. In\nfact, hardware acceleration has been shown to improve the\nperformance of some VNFs. Ge et. al [28] determine that for\nsome functions (e.g. DPI, Dedup and NAT), industry standard\nservers may not achieve the required levels of performance.\nFrom the authors\u2019 tests, a virtualized Dedup could only achieve\n267 Mbps throughput in each core at most. It was also proved\nby Yamazaki et. al [154] who reported achieving a better\nperformance and energy efficiency by deploying a virtualized\nDPI on Application Specific Instruction-set Processor (ASIP)\nrather than commodity servers.\nTherefore, there are some high performance NFs that may\nbe difficult to virtualize without degradation in performance.\nWhile hardware acceleration may be used for such functions,\nsuch specialization is against the concept of NFV which aims\nat high flexibility. There should be defined ways of managing\nthe trade-off between performance and flexibility. It will also\nbe appropriate to have phased migrations to NFV where those\nfunctions that have acceptable performance are virtualized first\nand allowed to run alongside unvirtualized or physical ones.\nD. Resource Allocation\nTo achieve the economies of scale expected from NFV,\nphysical resources should be used efficiently. It has been\nshown that default deployment of some current use cases\nmay result in sub-optimal resource allocation and consumption\n[10].\nThis calls for efficient algorithms to determine on to which\nphysical resources (servers) network functions are placed, and\nbe able to move functions from one server to another for\nsuch objectives as load balancing, energy saving, recovery\nfrom failures, etc. The task of placing functions is closely\nrelated to virtual network embedding [155] and virtual data\ncenter embedding [156] and may therefore be formulated as\nan optimization problem, with a particular objective. Such an\napproach has been followed by [157], [158], [159], [160],\n[161].\nFor example, Basta et. al [157] investigated the influence of\nvirtualizing the S-GW and P-GW functions on the transport\nnetwork load and data-plane delay. For these two functions, the\nauthors showed differences in performance (of upto 8 times)\nwhen the functions were either fully virtualized and when their\ndata and control planes were separated. The authors proposed\na model for placing the functions in a way that minimizes the\nnetwork load overheads introduced by the SDN control plane\ninteractions. In addition to placement, Mehraghdam [160]\nproposes a model for formalizing the chaining of NFs. To\nthis end, for each service deployment request, their approach\nconstructs a VNFFG which is then mapped to the physical\nresources, considering that the network resources are limited\nand that functions have specific requirements. The mapping is\nformulated as a Mixed Integer Quadratically Constrained Pro-\ngram (MIQCP). The authors concluded that in order to obtain\nefficient use of resources, the placement of functions should\nbe different according to the desired placement objective (i.e.\nremaining data rate, latency, number of used network nodes).\nFinally, Moens et. al [158] formulate the placement problem as\nan Integer Linear Program (ILP) with an objective of allocating\na service chain onto the physical network minimizing the\nnumber of servers used.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 19\nHowever, when formulated as an optimization problem,\nfunction placement and chaining would reduce to a binary in-\nteger program, which is NP-Hard [162], and hence intractable\nfor big instances of the problem. This calls for heuristics such\nas those proposed in [163], [164], [165], [132]. For example,\nXia et. al [163] formulate the placement and chaining problem\nas binary integer programming (BIP), and propose a greedy\nheuristic to improve computational efficiency. The proposed\ngreedy algorithm first sorts VNFs according their resource de-\nmand, and thereafter, VNFs with the highest resource demands\nare given priority for placement and chaining.\nIn addition, NFV systems should allow for one or a group\nof VNFs to be migrated to disparate physical servers. The\nphysical servers may be in different InP domains, and hence\nuse different tunneling addresses or be managed by different\nprotocols. This does not only call for efficient algorithms to\ndetermine where the functions can be moved, but will also\nrequire comprehensive management of function and server\nstates, as well as maintain communications. ViRUS [166]\nallows the runtime system to switch between blocks of code\nthat perform equivalent functionality at different QoS levels\nwhen the system is under stress, while [167] presents a model\nthat can be used to derive some performance indicators, such\nas the whole service downtime and the total migration time,\nso as to make function migration decisions.\nFinally, to ensure scalable NFV implementations, functions\nshould only be allocated the resources they need. Contrary\nto most current proof of concept implementations, it is not\nfeasible to deploy a VM per subscriber or per function as the\nresulting VM footprint would be too high. This is because each\nVM is like a computer running its own operating system, and\nis meant to be isolated from other VMs and hence independent\non a network level. This approach could become wasteful of\nresources for two reasons: (1) some of the functions such as\nDHCP in a CPE are so light that they would not justify a\ndedicated operating system on the scale of multiple functions\nper user, (2) some functions do not need to be strictly isolated\nfrom each other. Therefore, depending on the requirements of\na given function, containers could be a more efficient way\nto use resources. Linux containers [168] are an alternative\nto dedicated VMs in which a Docker [169] may be used\nto achieve the automated resource isolation and namespacing\nwhich allows for partitioning of memory, network, processes\netc. The use of containers avoids the overhead of starting\nand maintaining virtual machines since they do not require a\ncomplete duplication of an operating system. Using containers\ncould lead to up to a 30% savings in server costs to support\nthe same number of virtual hosting points [170].\nMoreover, even if given functions must utilize the same\nresources in a VM\u2019s operating system, it is possible to use\nscheduling techniques to allow the functions to share the\nresources. To this end, the proposals in [171], [172], [173]\nformulate the problem as a Resource Constrained Project\nScheduling Problem (RCPSP) [174] and solve it using a job\nshop scheduling approach [175]. Specifically, Mijumbi et. al\n[171] formulate an online VNF mapping and scheduling prob-\nlem and propose a set of greedy algorithms and a Tabu Search\n(TS) [176] heuristic for solving it. The greedy algorithms\nperform the mapping and scheduling of VNFs based on a\ngreedy criterion such as available buffer capacity for the node\nor the processing time of a given VNF on the possible nodes,\nwhile the TS algorithm starts by creating an initial solution\nrandomly, which is iteratively improved by searching for better\nsolutions in its neighborhood.\nIn addition, existing scheduling tools such as Google\u2019s Borg\n[177] and Apache Mesos [178] may be considered for schedul-\ning of VNFs. Borg uses task-packing, over-commitment, and\nmachine sharing with process-level performance isolation to\nrun multiple jobs, from many applications, across a number\nof clusters. Users of the Borg system submit jobs consisting\nof one or several tasks that are run from the same executable.\nThe scheduler in Borg monitors queues and schedules jobs\nconsidering the resources available on individual machines.\nThe jobs may have requirements such as CPU and OS.\nHowever, unlike the functions in NFV, the tasks in Borg are\nrun directly on hardware not in a virtualized environment. In\naddition, while Borg may have the scalability (cells usually\ncontain 10K servers) that would be required in an NFV\nenvironment, it would have to be improved to meet carrier\nclass requirements. For example, unlike the functions that\nmake up a service in NFV, the tasks considered in Borg do\nnot have ordering requirements. Finally, a task start up latency\nof 25s, and the 4 nines (99.99%) availability that Borg is able\nto give may need to be enhanced for NFV.\nTherefore, it can be observed that there are still many open\nareas with regard to how physical resources are shared among\nthe VNFs. First of all, the results in each of the above areas\nmay still be improved. In particular, the efficiency and applica-\nbility of containers needs to be studied more, just like there is\nneed to study and propose more efficient function scheduling\nalgorithms. In addition, given the dynamic requirements of\nNFV, there is need for resource allocation proposals that\nare able to find solutions online, consider multi-domain and\ndistributed VNFs [179], [180], network survivability [181],\ndynamic resource management [182] etc.\nE. Security, Privacy and Trust\nDespite the enormous potential of cloud computing, con-\nsumer uncertainty and concern regarding issues of privacy,\nsecurity and trust remain a major barrier to the switch to\ncloud models [183]. Therefore, cloud privacy issues will be\namong the key concerns for TSPs if they have to move to\npublic clouds. Because the functions to be virtualized represent\nsubscriber services, personally identifiable information may be\ntransferred to the cloud. This will present unique challenges\nespecially as the functions will be distributed, making it hard\nto know where this data is and who has access to it. In the case\nwhere the functions are deployed in third party clouds, users\nand Telecom service providers would not have access to the\nphysical security system of data centers. Even if the service\nproviders do specify their privacy and security requirements,\nit may still be hard to ensure that they are fully respected.\nEmphasizing its importance, ETSI constituted a security\nexpert group to focus on this concern. The group started\nby identifying potential security vulnerabilities of NFV and\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 20\nTABLE VII\nPOTENTIAL SECURITY THREATS IN NFV [184]\nSecurity Threat\nTopology Validation & Enforcement\nAvailability of Management Support Infrastructure\nSecured Boot\nSecure Crash\nPerformance Isolation\nUser/Tenant Authentication, Authorization and Accounting\nAuthenticated Time Service\nPrivate Keys within Cloned Images\nBack-Doors via Virtualized Test & Monitoring Functions\nMulti-Administrator Isolation\nestablishing whether they are new problems, or just existing\nproblems in different guises [184]. The evaluation confirmed\nthat indeed NFV creates new security concerns as shown in\nTable VII. After identifying the possible threats, the group\nproposed some solutions. In particular, they have provided a\nsecurity and trust guidance that is unique to NFV development,\narchitecture and operation [30]. However, this does not consist\nof prescriptive requirements or specific implementation details.\nHowever, it was noted that while solutions for these threats\nare available, there are currently no processes to take advan-\ntage of these solutions and, once in place, they will add proce-\ndural complexity [60], [184]. Moreover, for some of the threats\n(such as topology validation, network performance isolation\nand multi-administrator isolation), the group determined that\nsolutions are not yet available [60]. As NFV gets deployed\nand more important functions virtualized, we can expect it to\nattract even more security and privacy threats. More than ever,\nthere will be threats based on data interception (whether lawful\nor otherwise). Therefore, security, privacy and trust are other\nimportant research directions in NFV.\nF. Modeling of Resources, Functions and Services\nNFV\u2019s potential is based on its ability to deliver high levels\nof automation and flexibility. However, the resources and func-\ntions in NFV will be provided by different entities. Therefore,\nthe availability of well understood, open and standardized\ndescriptors for these multi-vendor resources, functions and\nservices will be key to large-scale NFV deployments. Models\nshould consider both initial deployment as well as lifecycle\nmanagement - reconfiguration. As part of the MANO spec-\nification [18], the ETSI provided a possible set of models\nthat may be useful in NFV. These include OVF, TOSCA,\nYANG and SID. OVF was introduced in section V-A5. In\nwhat follows, we introduce the other three models.\n1) Topology & Orchestration Standard for Cloud Applica-\ntion (TOSCA): TOSCA [185] is an OASIS standard language\nto describe a topology of cloud based web services, their\ncomponents, relationships, and the processes that manage\nthem. It describes what is needed to be preserved across\nservice deployments in different environments to enable inter-\noperable deployment of cloud services and their management\nwhen the applications are ported over alternative cloud envi-\nronments [18]. TOSCA may be used for VNF definition, node\nmonitoring and active policies like healing and scaling.\n2) NETCONF/YANG: NETCONF [186] is a protocol de-\nfined by the IETF to \u201cinstall, manipulate, and delete the\nconfiguration of network devices\u201d. NETCONF operations are\nrealized on top of a Remote Procedure Call (RPC) [187]\nlayer using an XML encoding and provide a basic set of\noperations to edit and query configuration on a network device.\nNETCONF is based on the YANG data modeling language.\nYANG is used to model both configuration and state data of\nnetwork elements. Furthermore, YANG can be used to define\nthe format of event notifications emitted by network elements\nand it allows data modelers to define the signature of remote\nprocedure calls that can be invoked on network elements via\nthe NETCONF protocol.\n3) Information Framework (SID): SID [188] is a\ncomponent of TM Forum\u2019s Frameworx aimed at providing\nan information model and common vocabulary for all the\ninformation shared among things of interest (entities) to an\nenterprise such as customer, location and network element,\nand relationships (associations) between these entities, such\nas a network element is situated at a location. Entities\nare further characterized by facts (attributes) that describes\nthem and their behavior (operations) that describe how the\nentities work. SID was originally based on Unified Modeling\nLanguage (UML) [189], but was extended to include XML\nSchema Definition (XSD) representations.\nDiscussion: Table VIII summarizes the information and data\nmodeling possibilities for NFV. All the models defined above\nhave relatively wide adoption, and may therefore be considered\nfor modeling of resources and functions in NFV. For example,\nto enable simple and scalable gradual deployment of VNFs and\nother NFV concepts, VNFs need to co-exist with traditional\nnon NFV-based NFs. To provide an integration with existing\nOSS/BSS systems, end-to-end network services that include\nVNFs or VNF Forwarding Graphs may be able to be mapped\nto the SID service model [18].\nHowever, these models were not initially developed with\nexplicit considerations for some of the more specific require-\nments expected by NFV deployments and can therefore only\nbe used as starting points and should continue to evolve for this\npurpose. For example, portability of data models and support\nfor federated services have been identified [190], [191] as\noutstanding improvements for TOSCA. TOSCA also needs im-\nprovement to support run-time management of services. With\nregard to NETCONF/YANG, there is need to improve them to\nbe able to cope with situations when multiple administrators\n(multi-domain environment) are present [192]. A lot of work is\nongoing to extend some of the models for NFV. For example,\nSID has been extended using the ZOOM information model\n[193] to define four concepts (VirtualResource, NetworkFunc-\ntion, NetworkService, and Graph) aimed at modeling NFV-\nbased systems. In addition, The TOSCA TC recently formed\na workgroup focused on creating a \u201cTOSCA Simple Profile\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 21\nTABLE VIII\nSUMMARY OF CHOICE OF INFORMATION AND DATA MODELS FOR NFV\nOVF TOSCA NETCONF/YANG SID\nOrganization DTMF OASIS IETF TMF\nObjective\nDescribe the packaging and \ndistribution of software to be run \nin one or more VMs\nStandardize interaction between \ncloud platforms and to provide \ncross-platform compatibility for \napplications and services.\nInstall, manipulate, and delete the \nconfiguration of network devices\nIdentify the business entities that \nplay role in the business processes \nof a telecommunications service \nprovider.\nRoots Server Virtualization IT applications\nConfiguration of network services, \ndevices\nIdentification and modelling of TSP \nbusiness processes\nData Model CIM YAML / XML YANG UML\nApplicability to NFV\nCapturing some or all of the VNF \npackage and/or VDU descriptor\nFunction template modelling for \ndeployment\nRuntime configuration of VNFs\nMay be used on the interface \nbetween OSS/BSS and NFV \nMANO and also on the interface \nbetween OSS/BSS and EM.\nEncoding XSD XML XSD\nLanguage Declarative, Imperative Procedural (Yang)\nNFV Project Using \nModel\nClearWater, Multi-vendor PoCs \n[199], ExperiaSphere [200]\nONF ZOOM\nResearch Challenges\nSupport for runtime management, \npossibly more stringent \nrequirements of VNFs\nPortability of data models, support \nfor federated services, runtime \nmanagement\nCapability to support easier \nmodelling/deployment template \ndesigns, protocol independence\nAs SID is fundamentally an \ninformation model with a defined \ndata model, it still lacks protocol \nand implementation details\nfor NFV.\u201d\nAs the models continue to improve, it may be important to\nhave solutions that combine them so as to avoid some of their\ndisadvantages. For example, A TOSCA template can install a\nvirtual router, but it cannot subsequently create/modify/delete\nconfiguration on demand on the same router during run-time.\nTherefore, fulfilling VNF requirements requires more than\nTOSCA. In the same way, YANG is designed for writing\nmachine readable schema, and is hence difficult to use for\ndesign of templates for initial service deployment. In this case,\nTOSCA may be combined with NETCONF/YANG where the\nfile-based templates in TOSCA may be used for deploying\nVNFs on cloud infrastructure, while NETCONF can be used\nto provide a runtime API both for configuring VNFs after they\nhave been installed, bringing VNFs to a state of operational\nreadiness, and while they are running in the cloud, fulfilling\nthe service requirements of a particular customer [142].\nG. Research Directions in Selected NFV Use Cases\n1) The Internet of Things: Like NFV, the Internet of Things\n(IoT) [194] paradigm has recently drawn a lot of industrial\nattention. The IoT is a network of physical objects or \u201cthings\u201d\ninto which sensors with unique identifiers are embedded. Such\nsensors may collect and transfer various kinds of (big) data\nover a network without requiring human-to-human or human-\nto-computer interaction. Inevitably, by networking zillions of\ndevices, the IoT will lead to networks of unbelievable scale\nand complexity with tremendous implications on network\nmanagement. It will lead to security, scalability and resource\nmanagement challenges in networks that should simultane-\nously transport, process and act on this data in real time.\nNFV has been proposed as a key enabler of the IoT [195],\n[196]. The idea in [195] is to limit the functionality embedded\nin deployed sensors, and provide virtualized functions such as\nsecurity, intelligence, computation and storage to the devices.\nThese would take advantage of the scalable distribution capa-\nbilities of NFV as well as the configuration flexibility of SDN.\nOn the other hand, Omnes et. al [196] propose multi-layered\nIoT architecture involving SDN and NFV, and illustrate how\nthe proposed architecture is able to cope with some of the\nchallenges in IoT.\nHowever, there are serious questions on the management\nof big amounts of IoT-generated data with better network\nefficiency. It is therefore critical to study efficient ways of\ntransporting (big) data over such sofwarized networks, and\nwhether current cloud data management applications such as\nHadoop and Cassandra would be able to support the real time\nrequirements in such environments.\n2) Information-Centric Networking: Motivated by the fact\nthat the Internet is increasingly used for information dis-\nsemination rather than for pair-wise communication between\nend hosts, Information-Centric Networking (ICN) [197] has\nemerged as a promising candidate for the architecture of the\nFuture Internet. ICN addresses named data rather than named\nhosts. This way, content distribution is implemented directly\ninto the network fabric rather than relying on the complicated\nmapping, availability, and security mechanisms currently used\nto map content to a single location.\nThe separation between information processing and\nforwarding in ICN is related to both the decoupling of\nfunctions from devices in NFV, and to the decoupling\nof control from data plane in SDN. While the relationship\nbetween NFV, SDN and cloud computing has already received\nsome attention, that between NFV and ICN has not. Yet, ICN\nmay be used in NFV to determine the best position to place\nnetwork functions. For example, Arumaithurai et al. [198]\npropose a function-centric service chaining (FCSC) approach\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 22\nTABLE IX\nSUMMARY OF STATE-OF-THE-ART AND RESEARCH CHALLENGES\nChallenge Description Reference Contribution / Objective Research Opportunities\nETSI MANO \nFramework\n[18]\nSpecifies a management and \norchestration framework for NFV\nVendor Products [111], [114], [115], [121]\nVendor specific products for different \ncomponents or specifications of the \nETSI MANO framework\nProjects\n[85], [86], [88], [91], [92], \n[130], [131]\nImplementation and/or proposals based \non the ETSI MANO framework\nResearch Papers\n[132], [133], [134], [135], \n[136], [137], [138], [139], \n[140]\nManagements and orchestration \nframeworks and architectures\nETSI Performance \n& Portability Best \nPractices\n[151]\nDefines the \"best practices\" that need \nto followed to obtain acceptable \nperformance in NFV. Also gives \nperformance test results on on NFV use \ncases such as DPI, C-RAN, BRAS, etc\nPractical \nMeasurements\n[148]\nexperiences in deploying a C-RAN on \na 2G and 3G network\nHardware \nAcceleration\n[26], [28], [29], [154]\nVarious proposals for applying \nhardware acceleration to enhance the \nperformance of some VNFs such as \nDPI, dedup and NAT\nPractical \nMeasurements\n[148], [149]\nMeasurements on the effect of \ntransferring network and user functions \nto the cloud\nSimulation [143]\nVendor tool that simulates possible \nenergy saving resulting from NFV\nPlacement\n[157], [158], [159], [160], \n[161]\nDeciding the optimal placement of \nfunctions in the operator\u2019s network or \nthe cloud, following specific functions \nrequirements and resource constraints\nMigration [166], [167]\nAllow for one or a group of VNFs to be \nmigrated to disparate physical servers\nScheduling [171], [172], [173]\nAllow multiple VNFs to be hosted in a \nsingle VM and schedule their efficient \nutilization of resources\nETSI Security \nProblem Statement\n[184]\nDefines the security, trust and privacy \nthreats in NFV\nETSI Security \nGuidance\n[30]\nProvides guidance on how security, \nprivacy and trust may be achieved in \nNFV.\nIoT [195], [196]\nArchitecture combining NFV and IoT, \nand an application scenario involving a \nvirtualized sensor function\nICN [198]\nexploits ICN to provide flexibility and \ndynamism in placing VNFs\nETSI Use Cases\n[62], [73], [94], [95], [96], \n[97], [98], [100], [101], \n[102], [103], [104], [105], \n[106], [107], [108], [109], \n[110]\nImplementation, demonstrations and \nproofs of concepts based on the ETSI \nuse cases\nResource \nAllocation\nUse of containers, function \nscheduling, multi-domain function \nplacement and chaining, \nsurvivability of VNFs in case of \nnetwork failures, dynamic resource \nallocation (scaling up and down)\nSecurity, \nPrivacy, Trust\nTopology validation, network \nperformance isolation, multi-\nadministrator isolation, data \ninterception\nNFV Use Cases\nMonitoring and metering of \ncarrier\u2010scale virtualized networks. \nApplication of big data \napproaches, ICN-based placement \nof VNFs, proof of concepts and \nimplementations involving chains \nof VNFs\nManagement \nand \nOrchestration\nTraffic and function monitoring, \ninter-operability and interfacing, \nprogrammability and Intelligence, \ndistributed management, combined \nmanagement of cloud, SDN and \nNFV, autonomic (self) \nmanagement technologies in NFV \n(e.g., processing of alarms)\nNFV \nPerformance\nMore studies on the applicability \nof hardware acceleration to some \nNFs, and on the resulting trade-off \nbetween performance and \nflexibility\nEnergy \nEfficiency\nStill limited number of real world \ndeployments to give actual vales, \nenergy efficient hardware, energy-\naware function placement \nchaining, consideration of inter-\ndata center communications\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 23\nwhich exploits ICN to provide flexibility and dynamism in\nplacing VNFs.\nSummary: In Table X, we summarize the state-of-art in each\nof the identified research challenges, as well as specific open\nquestions in each one of them. We have noted that despite\nthe significant and rapidly increasing activity on NFV, there\nare still major gaps especially with regard to standardization\nthat may slow down NFV deployment and undermine the\npossibilities to fulfill its anticipated business case. While\nthe ETSI-defined reference architecture covers most of the\naspects needed to operationalize NFV, current specifications\nare still too general to envelope all the essential pillars of\nrequired evolution such as inter-operability, legacy support,\nand management of both legacy and NFV-based systems.\nFor example, currently, different vendors depend on dif-\nferent languages to model resources and functions in NFV.\nTOSCA has been used in modeling services for a multi-\nvendor E2E proof of concept [199], for ClearWater, and\nExperiaSphere [200]. On the other hand, the descriptors in\nthe HP NFV Director are not based on TOSCA, and ONF has\nchosen YANG as the modeling language. Similar examples\ncan be given for vendor implementations of the NFVI, VNFs\nand MANO. This could result into inter-operability challenges\nwhere vendor-specific Command Line Interfaces (CLIs) re-\nquire manual configuration or expensive integration by service\nproviders themselves or systems integrators with their own\nproprietary tools and equipment-specific adapters. Therefore,\nthough there are many options for modeling of functions and\nresources, the techniques remain generally in their infancy.\nWith regard to performance, most current PoCs are based on\na rather limited list of use cases proposed by the ETSI. While\nthese PoCs are important to prove technical principles unique\nto NFV, they do not give a complete view of performance\nand benefits for a wide range of end-to-end services. Finally,\nresearch on possible enablers of NFV such as ICN, and on the\napplication areas such as IoT are still largely unexplored.\nVII. CONCLUSION\nDue to user demands for real-time, on-demand, online,\ninexpensive, short-lived services, TSPs have been forced to\nlook for new ways of delivering these services in ways that are\nagile, and with OPEX and CAPEX savings. NFV has emerged\nas a possible approach to make network equipment more open,\nand hence allow TSPs to become more flexible, faster at ser-\nvice innovations and reduce operation & maintenance (O&M)\ncosts. It is clear that NFV, together with the closely related\nand complementary fields of SDN and cloud computing may\nbe big parts of future telecommunication service provision.\nIn this paper, we introduced NFV, described its architecture\nas defined by ETSI, proposed a reference business model, and\nexplored important design considerations. We then compared\nNFV with closely related fields, SDN and cloud computing,\ndiscussing current research for combining them. We have\nalso presented major specification and standardization efforts,\nresearch projects, commercial products and early NFV proof\nof concept implementations. Finally, we discussed the key\nresearch areas that will be pivotal to the success of NFV as\nwell as to its application to ICN and IoT, and summarized the\nfindings of the survey. We believe that before these areas are\nexplored, TSPs who deploy NFV may end up being reliant on\nvendor-proprietary solutions to solve these gaps, which would\nbe against the original objective of NFV.\nWe have noted that many current NFV solutions, especially\nfrom the industry, have been mainly about pooling vendor\nspecific resources hosted in a cloud rather than real support for\nflexibility, inter-operability, integrated management, orchestra-\ntion and service automation all of which are core requirements\nfor NFV. It is expected that such implementations will continue\nto increase before NFV gets completely standardized. As NFV\nmoves from labs and PoCs to trials and commercial deploy-\nments, vendors are investing significant resources to develop\nthese NFV solutions. It is therefore urgent for specification\nand standardization bodies to complete specifications before\nit becomes too late for the standards to change or influence\nwhat has already been deployed.\nACKNOWLEDGMENT\nThe authors are indebted to the Editor-in-Chief for coordi-\nnating the review process, and to the anonymous reviewers\nfor their insightful comments and suggestions. This work\nwas partly funded by FLAMINGO, a Network of Excellence\nproject (318488) supported by the European Commission un-\nder its Seventh Framework Programme, and project TEC2012-\n38574-C02-02 from Ministerio de Economia y Competitivi-\ndad.\nREFERENCES\n[1] J. Wu, Z. Zhang, Y. Hong, and Y. Wen, \u201cCloud radio access network\n(C-RAN): a primer,\u201d Network, IEEE, vol. 29, no. 1, pp. 35\u201341, Jan\n2015.\n[2] China Mobile Research Institute, \u201cC-RAN: The Road Towards Green\nRAN. White Paper. Version 2.5.\u201d October 2011.\n[3] B. Han, V. Gopalakrishnan, L. Ji, and S. Lee, \u201cNetwork function\nvirtualization: Challenges and opportunities for innovations,\u201d Commu-\nnications Magazine, IEEE, vol. 53, no. 2, pp. 90\u201397, Feb 2015.\n[4] R. Guerzoni, \u201cNetwork Functions Virtualisation: An Introduction,\nBenefits, Enablers, Challenges and Call for Action. Introductory white\npaper,\u201d in SDN and OpenFlow World Congress, June 2012.\n[5] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS NFV\n002 V1.2.1: Network Functions Virtualisation (NFV); Architectural\nFramework,\u201d http://www.etsi.org/deliver/etsi gs/NFV/001 099/002/01.\n02.01 60/gs NFV002v010201p.pdf, December 2014.\n[6] ETSI, \u201cEuropean Telecommunications Standards Institute,\nIndustry Specification Groups (ISG) - NFV,\u201d http://www.etsi.\norg/technologies-clusters/technologies/nfv, 2015, Accessed: June 03,\n2015.\n[7] ETSI Industry Specification Group (ISG) NFV, \u201cETSI Group Speci-\nfications on Network Function Virtualization. 1st Phase Documents,\u201d\nhttp://docbox.etsi.org/ISG/NFV/Open/Published/, January 2015.\n[8] \u201cThe 3rd Generation Partnership Project (3GPP),\u201d http://www.3gpp.\norg/about-3gpp/about-3gpp, 2015, Accessed: February, 10 2015.\n[9] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS\nNFV 001 V1.1.1: Network Function Virtualization. Use Cases,\u201d\nwww.etsi.org/deliver/etsi gs/NFV/001 099/001/01.01.01 60/gs\nNFV001v010101p.pdf, October 2013.\n[10] P. Veitch, M. J. McGrath, and V. Bayon, \u201cAn instrumentation and\nanalytics framework for optimal and robust NFV deployment,\u201d Com-\nmunications Magazine, IEEE, vol. 53, no. 2, pp. 126\u2013133, Feb 2015.\n[11] H. Hawilo, A. Shami, M. Mirahmadi, and R. Asal, \u201cNFV: state of the\nart, challenges, and implementation in next generation mobile networks\n(vEPC),\u201d Network, IEEE, vol. 28, no. 6, pp. 18\u201326, Nov 2014.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 24\n[12] D. Cotroneo, L. De Simone, A. Iannillo, A. Lanzaro, R. Natella, J. Fan,\nand W. Ping, \u201cNetwork Function Virtualization: Challenges and Direc-\ntions for Reliability Assurance,\u201d in Software Reliability Engineering\nWorkshops (ISSREW), 2014 IEEE International Symposium on, Nov\n2014, pp. 37\u201342.\n[13] D. Kreutz, F. Ramos, P. Esteves Verissimo, C. Esteve Rothenberg,\nS. Azodolmolky, and S. Uhlig, \u201cSoftware-Defined Networking: A\nComprehensive Survey,\u201d Proceedings of the IEEE, vol. 103, no. 1, pp.\n14\u201376, Jan 2015.\n[14] Q. Zhang, L. Cheng, and R. Boutaba, \u201cCloud computing: state-of-the-\nart and research challenges.\u201d J. Internet Services and Applications,\nvol. 1, no. 1, pp. 7\u201318, 2010.\n[15] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS NFV 003\nV1.2.1: Network Functions Virtualisation (NFV); Terminology for\nMain Concepts in NFV,\u201d http://www.etsi.org/deliver/etsi gs/NFV/001\n099/003/01.02.01 60/gs NFV003v010201p.pdf, December 2014.\n[16] Q. P and N. T, \u201cService Function Chaining Problem Statement.\nInternet-Draft draft-ietf-sfc-problem-statement-10,\u201d Active Internet-\nDraft, IETF Secretariat, Tech. Rep., August 2014.\n[17] R. Mijumbi, \u201cSelf-managed Resources in Network Virtualization En-\nvironments,\u201d Ph.D. dissertation, Technical University of Catalunta,\nBarcelona, Spain, November 2014.\n[18] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS NFV-MAN\n001 V1.1.1: Network Functions Virtualisation (NFV); Management\nand Orchestration,\u201d http://www.etsi.org/deliver/etsi gs/NFV-MAN/\n001 099/001/01.01.01 60/gs NFV-MAN001v010101p.pdf, December\n2014.\n[19] \u2014\u2014, \u201cETSI GS NFV-INF 004 V1.1.1: Network Functions\nVirtualisation (NFV); Infrastructure; Hypervisor Domain,\u201d\nhttp://www.etsi.org/deliver/etsi gs/NFV-INF/001 099/004/01.01.\n01 60/gs NFV-INF004v010101p.pdf, January 2015.\n[20] N. M. K. Chowdhury and R. Boutaba, \u201cA survey of network\nvirtualization,\u201d Computer Networks, vol. 54, no. 5, pp. 862 \u2013\n876, 2010. [Online]. Available: http://www.sciencedirect.com/science/\narticle/pii/S1389128609003387\n[21] F. Samuel, M. Chowdhury, and R. Boutaba, \u201cPolyViNE: policy-\nbased virtual network embedding across multiple domains,\u201d Journal\nof Internet Services and Applications, vol. 4, no. 1, p. 6, 2013.\n[22] Harvey, A. F. et. al, \u201cDMA Fundamentals on Various PC Platforms.\nApplication Note 011, National Instruments,\u201d http://cires.colorado.edu/\njimenez-group/QAMSResources/Docs/DMAFundamentals.pdf, April\n1991.\n[23] W. Peterson and D. Brown, \u201cCyclic Codes for Error Detection,\u201d\nProceedings of the IRE, vol. 49, no. 1, pp. 228\u2013235, Jan 1961.\n[24] \u201cOverture 65vSE: Open Platform for Virtualization at the Service\nEdge,\u201d http://www.overturenetworks.com/products/overture-65vse,\n2015, Accessed: February, 06 2015.\n[25] S. Byma, J. Steffan, H. Bannazadeh, A. L. Garcia, and P. Chow, \u201cFpgas\nin the cloud: Booting virtualized hardware accelerators with open-\nstack,\u201d in Field-Programmable Custom Computing Machines (FCCM),\n2014 IEEE 22nd Annual International Symposium on, May 2014, pp.\n109\u2013116.\n[26] Z. Bronstein, E. Roch, J. Xia, and A. Molkho, \u201cUniform handling\nand abstraction of nfv hardware accelerators,\u201d Network, IEEE, vol. 29,\nno. 3, pp. 22\u201329, May 2015.\n[27] J. DiGiglio and D. Ricci, \u201cHigh Performance, Open StandardVirtu-\nalization with NFV and SDN. Joint Technical White Paper by Intel\nCorporation and Wind River,\u201d http://www.windriver.com/whitepapers/\novp/ovp whitepaper.pdf, 2015, Accessed: June, 05 2015.\n[28] X. Ge, Y. Liu, D. H. Du, L. Zhang, H. Guan, J. Chen, Y. Zhao, and\nX. Hu, \u201cOpenANFV: Accelerating Network Function Virtualization\nwith a Consolidated Framework in Openstack,\u201d in Proceedings of the\n2014 ACM Conference on SIGCOMM, ser. SIGCOMM \u201914. New\nYork, NY, USA: ACM, 2014, pp. 353\u2013354.\n[29] L. Nobach and D. Hausheer, \u201cOpen, elastic provisioning of hardware\nacceleration in nfv environments,\u201d in Networked Systems (NetSys),\n2015 International Conference and Workshops on, March 2015, pp.\n1\u20135.\n[30] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS NFV-SEC\n003 V1.1.1: Network Functions Virtualisation (NFV); NFV Security;\nSecurity and Trust Guidance,\u201d http://www.etsi.org/deliver/etsi gs/\nNFV-SEC/001 099/003/01.01.01 60/gs NFV-SEC003v010101p.pdf,\nDecember 2014.\n[31] ETSI ISG NFV, \u201cETSI GS NFV-REL 001 V1.1.1: Network\nFunctions Virtualisation (NFV); Resiliency Requirements,\u201d\nhttp://www.etsi.org/deliver/etsi gs/NFV-REL/001 099/001/01.01.\n01 60/gs NFV-REL001v010101p.pdf, January 2015.\n[32] Andreas Lemke, Alcatel Lucent, \u201cWhy service providers need an NFV\nplatform: Strategic White Paper,\u201d January 2015.\n[33] ATIS NFV, \u201cAlliance for Telecommunications Industry Solutions,\nNetwork Functions Virtualization Forum,\u201d http://www.atis.org/NFV/\nindex.asp, January 2015.\n[34] Allot, \u201cEvolution of Network Service Enablement Utilizing Network\nFunctions Virtualization (NFV). Techinical White Paper,\u201d Allot Com-\nmunications, Tech. Rep., July 2013.\n[35] M. Peter and G. Timothy, \u201cThe NIST Definition of Cloud Computing,\nRecommendations of the National Institute of Standards and Technol-\nogy,\u201d http://www.nist.gov/itl/cloud/, National Institute of Standards and\nTechnology(NIST) Special Publication 800-145, Tech. Rep., September\n2011.\n[36] Distributed Management Task Force, \u201cCloud Management Work-\ning Group (CMWG),\u201d http://www.dmtf.org/standards/cmwg, February\n2015.\n[37] N. McKeown, T. Anderson, H. Balakrishnan, G. Parulkar, L. Peterson,\nJ. Rexford, S. Shenker, and J. Turner, \u201cOpenFlow: Enabling\nInnovation in Campus Networks,\u201d SIGCOMM Comput. Commun.\nRev., vol. 38, no. 2, pp. 69\u201374, Mar. 2008. [Online]. Available:\nhttp://doi.acm.org/10.1145/1355734.1355746\n[38] D. R. Mauro and K. J. Schmidt, Essential SNMP, Second Edition.\nO\u2019Reilly Media, Inc., 2005.\n[39] G. Wedge and L. Barbara, \u201cCarrier-Grade: Five Nines, the Myth and\nthe Reality,\u201d Pipeline Publications, vol. 3, no. 1, June 2006.\n[40] K. V. Vishwanath and N. Nagappan, \u201cCharacterizing Cloud Computing\nHardware Reliability,\u201d in Proceedings of the 1st ACM Symposium on\nCloud Computing, ser. SoCC \u201910. New York, NY, USA: ACM, 2010,\npp. 193\u2013204. [Online]. Available: http://doi.acm.org/10.1145/1807128.\n1807161\n[41] \u201cNetwork Equipment-Building System (NEBS),\u201d http://en.wikipedia.\norg/wiki/Network Equipment-Building System, 2015, Accessed:\nFebruary, 07 2015.\n[42] M. Scharf, T. Voith, W. Roome, B. Gaglianello, M. Steiner, V. Hilt,\nand V. Gurbani, \u201cMonitoring and abstraction for networked clouds,\u201d\npp. 80\u201385, Oct 2012.\n[43] A. Mandal, Y. Xin, I. Baldine, P. Ruth, C. Heerman, J. Chase,\nV. Orlikowski, and A. Yumerefendi, \u201cProvisioning and Evaluating\nMulti-domain Networked Clouds for Hadoop-based Applications,\u201d in\nCloud Computing Technology and Science (CloudCom), 2011 IEEE\nThird International Conference on, Nov 2011, pp. 690\u2013697.\n[44] D. Lopez, \u201cNetwork functions virtualization: Beyond carrier-grade\nclouds,\u201d in Optical Fiber Communications Conference and Exhibition\n(OFC), 2014, March 2014, pp. 1\u201318.\n[45] Henrik, Basilier and Marian, Darula and Joe, Wilke, \u201cVirtualizing\nnetwork services the telecom cloud. Techinical White Paper,\u201d Ericsson,\nTech. Rep., March 2014.\n[46] ETSI Industry Specification Group (ISG) NFV, \u201cETSI, OpenStack\nLiason Statement: NFV Requirements,\u201d https://wiki.openstack.org/w/\nimages/c/c7/NFV(14)000154r2 NFV LS to OpenStack.pdf, Septem-\nber 2014, NFV(14)000154r2.\n[47] F. Callegati, W. Cerroni, C. Contoli, and G. Santandrea, \u201cPerformance\nof Network Virtualization in cloud computing infrastructures: The\nOpenStack case,\u201d in Cloud Networking (CloudNet), 2014 IEEE 3rd\nInternational Conference on, Oct 2014, pp. 132\u2013137.\n[48] R. Glitho, \u201cCloudifying the 3GPP IP Multimedia Subsystem: Why and\nHow?\u201d in New Technologies, Mobility and Security (NTMS), 2014 6th\nInternational Conference on, March 2014, pp. 1\u20135.\n[49] A. Tolonen, \u201cDynamic Virtualized Network Functions on an OpenStack\nCloud,\u201d Master\u2019s thesis, Aalto University, Espoo, Finland, 9 2014.\n[50] H. Jamjoom, D. Williams, and U. Sharma, \u201cDon\u2019t Call Them Middle-\nboxes, Call Them Middlepipes,\u201d in Proceedings of the Third Workshop\non Hot Topics in Software Defined Networking, ser. HotSDN \u201914. New\nYork, NY, USA: ACM, 2014, pp. 19\u201324.\n[51] F. Hu, Q. Hao, and K. Bao, \u201cA Survey on Software-Defined Network\nand OpenFlow: From Concept to Implementation,\u201d Communications\nSurveys Tutorials, IEEE, vol. 16, no. 4, pp. 2181\u20132206, Fourthquarter\n2014.\n[52] A. Doria, J. H. Salim, R. Haas, W. Wang, L. Dong, and R. Gopal,\n\u201cForwarding and Control Element Separation (ForCES),\u201d http://www.\nietf.org/rfc/rfc5810.txt, March 2010, Protocol Specification. Internet\nEngineering Task Force.\n[53] A. Lara, A. Kolasani, and B. Ramamurthy, \u201cNetwork Innovation\nusing OpenFlow: A Survey,\u201d Communications Surveys Tutorials, IEEE,\nvol. 16, no. 1, pp. 493\u2013512, First 2014.\n[54] Open Networking Foundation, \u201cSDN Architecture. Issue 1. ONF\nTR 502,\u201d https://www.opennetworking.org/images/stories/downloads/\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 25\nsdn-resources/technical-reports/TR SDN ARCH 1.0 06062014.pdf,\nJune 2014.\n[55] M. Taylor, \u201cA Guide to NFV and SDN.White Paper by Metaswitch\nNetworks,\u201d http://www.metaswitch.com/sites/default/files/Metaswitch\nWhitePaper NFVSDN final rs.pdf, December 2014.\n[56] VMWARE, \u201cThe VMware NSX Network Virtualization Platform.\nTechnical White Paper.\u201d https://www.vmware.com/files/pdf/products/\nnsx/VMware-NSX-Network-Virtualization-Platform-WP.pdf, 2015,\nAccessed: June, 05 2015.\n[57] B. Nunes, M. Mendonca, X.-N. Nguyen, K. Obraczka, and T. Turletti,\n\u201cA Survey of Software-Defined Networking: Past, Present, and Fu-\nture of Programmable Networks,\u201d Communications Surveys Tutorials,\nIEEE, vol. 16, no. 3, pp. 1617\u20131634, Third 2014.\n[58] \u201cOpen Networking Foundation (ONF),\u201d https://www.opennetworking.\norg/, 2015, Accessed: February, 03 2015.\n[59] M. Jarschel, T. Zinner, T. Hossfeld, P. Tran-Gia, and W. Keller,\n\u201cInterfaces, attributes, and use cases: A compass for SDN,\u201d IEEE\nCommunications Magazine, June 2014.\n[60] C. Cui et. al, \u201cNetwork Functions Virtualisation: Network Operator\nPerspectives on Industry Progress. White Paper No. 3, Issue 1,\u201d in\nSDN and OpenFlow World Congress, Dusseldorf-Germany, October\n2014.\n[61] E. Haleplidis, J. Hadi Salim, S. Denazis, and O. Koufopavlou, \u201cTowards\na Network Abstraction Model for SDN,\u201d Journal of Network and\nSystems Management, pp. 1\u201319, 2014.\n[62] T. Choi, S. Kang, S. Yoon, S. Yang, S. Song, and H. Park, \u201cSuVMF:\nSoftware-defined Unified Virtual Monitoring Function for SDN-based\nLarge-scale Networks,\u201d in Proceedings of The Ninth International\nConference on Future Internet Technologies, ser. CFI \u201914. New York,\nNY, USA: ACM, 2014, pp. 4:1\u20134:6.\n[63] Z. Michael, A. David, C. Marc, D. Nabil, K. Christos, M. Jeff,\nM. Serge, M. Dave, R. Evelyne, and S. Meral, \u201cOpenFlow-enabled\nSDN and Network Functions Virtualization. ONF Solution Brief,\u201d Open\nNetworking Foundation, Tech. Rep., February 2014.\n[64] W. Xia, Y. Wen, C. Foh, D. Niyato, and H. Xie, \u201cA Survey on\nSoftware-Defined Networking,\u201d Communications Surveys Tutorials,\nIEEE, vol. PP, no. 99, pp. 1\u20131, 2014.\n[65] R. Kawashima, \u201cvNFC: A Virtual Networking Function Container for\nSDN-Enabled Virtual Networks,\u201d in Network Cloud Computing and\nApplications (NCCA), 2012 Second Symposium on, Dec 2012, pp. 124\u2013\n129.\n[66] A. Basta, W. Kellerer, M. Hoffmann, K. Hoffmann, and E.-D. Schmidt,\n\u201cA Virtual SDN-Enabled LTE EPC Architecture: A Case Study for S-\n/P-Gateways Functions,\u201d in Future Networks and Services (SDN4FNS),\n2013 IEEE SDN for, Nov 2013, pp. 1\u20137.\n[67] J. Kempf, B. Johansson, S. Pettersson, H. Luning, and T. Nilsson,\n\u201cMoving the mobile Evolved Packet Core to the cloud,\u201d in Wireless\nand Mobile Computing, Networking and Communications (WiMob),\n2012 IEEE 8th International Conference on, Oct 2012, pp. 784\u2013791.\n[68] A. Tootoonchian and Y. Ganjali, \u201cHyperFlow: A Distributed Control\nPlane for OpenFlow,\u201d in Proceedings of the 2010 Internet Network\nManagement Conference on Research on Enterprise Networking,\nser. INM/WREN\u201910. Berkeley, CA, USA: USENIX Association,\n2010, pp. 3\u20133. [Online]. Available: http://dl.acm.org/citation.cfm?id=\n1863133.1863136\n[69] V. Yazici, M. Sunay, and A. Ercan, \u201cArchitecture for a distributed\nopenflow controller,\u201d in Signal Processing and Communications Ap-\nplications Conference (SIU), 2012 20th, April 2012, pp. 1\u20134.\n[70] J. Yu and I. Al Ajarmeh, \u201cAn Empirical Study of the NETCONF\nProtocol,\u201d in Networking and Services (ICNS), 2010 Sixth International\nConference on, March 2010, pp. 253\u2013258.\n[71] A. Gember-Jacobson, R. Viswanathan, C. Prakash, R. Grandl, J. Khalid,\nS. Das, and A. Akella, \u201cOpenNF: Enabling Innovation in Network\nFunction Control,\u201d in Proceedings of the 2014 ACM Conference on\nSIGCOMM, ser. SIGCOMM \u201914. New York, NY, USA: ACM, 2014,\npp. 163\u2013174.\n[72] J. Batalle, J. Ferrer Riera, E. Escalona, and J. Garcia-Espin, \u201cOn the\nImplementation of NFV over an OpenFlow Infrastructure: Routing\nFunction Virtualization,\u201d in Future Networks and Services (SDN4FNS),\n2013 IEEE SDN for, Nov 2013, pp. 1\u20136.\n[73] M. R. Sama, L. M. Contreras, J. Kaippallimalil, I. Akiyoshi, H. Qian,\nand H. Ni, \u201cSoftware-defined control of the virtualized mobile packet\ncore,\u201d Communications Magazine, IEEE, vol. 53, no. 2, pp. 107\u2013115,\nFeb 2015.\n[74] \u201cOpenDayLight,\u201d http://www.opendaylight.org/project, 2015,\nAccessed: February, 06 2015.\n[75] D. Kreutz, F. Ramos, P. Esteves Verissimo, C. Esteve Rothenberg,\nS. Azodolmolky, and S. Uhlig, \u201cSoftware-Defined Networking: A\nComprehensive Survey,\u201d Proceedings of the IEEE, vol. 103, no. 1, pp.\n14\u201376, Jan 2015.\n[76] \u201cThe Internet Engineering Task Force (IETF),\u201d https://www.ietf.org/,\n2015, Accessed: February, 06 2015.\n[77] \u201cThe Internet Engineering Task Force (IETF) Service Function Chain-\ning (SFC) Working Group (WG),\u201d https://datatracker.ietf.org/wg/sfc/\ncharter/, 2015, Accessed: February, 06 2015.\n[78] \u201cThe Internet Engineering Task Force (IETF) Service Function Chain-\ning (SFC) Working Group (WG). Documents,\u201d https://datatracker.ietf.\norg/wg/sfc/documents/, 2015, Accessed: February, 06 2015.\n[79] \u201cInternet Research Task Force, Network Function Virtualization Re-\nsearch Group (NFVRG),\u201d https://irtf.org/nfvrg, 2015, Accessed: Febru-\nary, 03 2015.\n[80] \u201cThe Broadband Forum,\u201d https://www.broadband-forum.org/, 2015,\nAccessed: February, 10 2015.\n[81] \u201cThe Broadband Forum, Technical Work in Progress,\u201d\nhttps://www.broadband-forum.org/technical/technicalwip.php, 2015,\nAccessed: February, 28 2015.\n[82] Distributed Management Task Force (DMTF), \u201cOpen Virtualization\nFormat (OVS),\u201d http://www.dmtf.org/standards/ovf, June 2015, Ac-\ncessed: June 14, 2015.\n[83] DMTF, \u201cCommon Information Model (CIM),\u201d http://www.dmtf.org/\nstandards/cim, June 2015, Accessed: June 14, 2015.\n[84] Huawei Technologies, \u201cHuawei Observation to NFV. White Paper,\u201d\nFebruary 2015.\n[85] TMF, \u201cZero-time Orchestration, Operations and Management\n(ZOOM),\u201d TeleManagement Forum, Tech. Rep., August 2014.\n[86] \u201cOpen Platform for NFV (OPNFV),\u201d https://www.opnfv.org/about,\n2015, Accessed: January, 26 2015.\n[87] OPNFV, \u201cOPNFV\u2019s Arno Release,\u201d https://www.opnfv.org/arno, June\n2015.\n[88] D. R. Lopez, \u201cOpenMANO: The Dataplane Ready Open Source NFV\nMANO Stack,\u201d in IETF Meeting Proceedings, Dallas, Texas, USA,\nMarch 2015.\n[89] Intel, \u201cOpenStack Enhanced Platform Awareness. White Paper,\u201d https://\n01.org/sites/default/files/page/openstack-epa wp fin.pdf, March 2015.\n[90] \u201cMCN: The Mobile Cloud Networking EU Project,\u201d http://www.\nmobile-cloud-networking.eu/site/, 2015, Accessed: February, 12 2015.\n[91] A. Csaszar, W. John, M. Kind, C. Meirosu, G. Pongracz, D. Staessens,\nA. Takacs, and F.-J. Westphal, \u201cUnifying Cloud and Carrier Network:\nEU FP7 Project UNIFY,\u201d in Utility and Cloud Computing (UCC), 2013\nIEEE/ACM 6th International Conference on, Dec 2013, pp. 452\u2013457.\n[92] \u201cT-NOVA: Network Functions-as-a-Service (NFaaS) over Virtualized\nInfrastructures,\u201d http://www.t-nova.eu/, 2015, Accessed: January, 26\n2015.\n[93] \u201cConvergence of Wireless Optical Network and IT REsources IN Sup-\nporT of Cloud Services (CONTENT) EU Project,\u201d http://content-fp7.\neu/theproject.html, January 2015, accessed on February 09, 2015.\n[94] B. O. Josep, \u201cExperimentation on Virtualized Routing Function Mi-\ngration Using OpenFlow,\u201d Master\u2019s thesis, Universitat Politecnica de\nCatalunya, Barcelona, Spain, 9 2014.\n[95] H. Masutani, Y. Nakajima, T. Kinoshita, T. Hibi, H. Takahashi,\nK. Obana, K. Shimano, and M. Fukui, \u201cRequirements and design of\nflexible NFV network infrastructure node leveraging SDN/OpenFlow,\u201d\nin Optical Network Design and Modeling, 2014 International Confer-\nence on, May 2014, pp. 258\u2013263.\n[96] T. C. BA\u02d8lan, \u201cNetwork Policy Function Virtualization via SDN and\nPacket Processing,\u201d Review of the Air Force Academy, vol. 27, no. 3,\npp. 73\u201378, 2014.\n[97] A. Bremler-Barr, Y. Harchol, D. Hay, and Y. Koral, \u201cDeep packet in-\nspection as a service,\u201d in Proceedings of the 10th ACM International on\nConference on Emerging Networking Experiments and Technologies,\nser. CoNEXT \u201914. New York, NY, USA: ACM, 2014, pp. 271\u2013282.\n[98] S. Gebert, D. Hock, T. Zinner, P. Tran-Gia, M. Hoffmann, M. Jarschel,\nE.-D. Schmidt, R.-P. Braun, C. Banse, and A. Ko\u00a8psel, \u201cDemonstrating\nthe Optimal Placement of Virtualized Cellular Network Functions in\nCase of Large Crowd Events,\u201d in Proceedings of the 2014 ACM\nConference on SIGCOMM, ser. SIGCOMM \u201914. New York, NY,\nUSA: ACM, 2014, pp. 359\u2013360.\n[99] M. Peng, Y. Li, J. Jiang, J. Li, and C. Wang, \u201cHeterogeneous cloud\nradio access networks: a new perspective for enhancing spectral and\nenergy efficiencies,\u201d Wireless Communications, IEEE, vol. 21, no. 6,\npp. 126\u2013135, December 2014.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 26\n[100] R. Wang, H. Hu, and X. Yang, \u201cPotentials and Challenges of C-RAN\nSupporting Multi-RATs Toward 5G Mobile Networks,\u201d Access, IEEE,\nvol. 2, pp. 1187\u20131195, 2014.\n[101] C.-L. I, J. Huang, R. Duan, C. Cui, J. Jiang, and L. Li, \u201cRecent Progress\non C-RAN Centralization and Cloudification,\u201d Access, IEEE, vol. 2, pp.\n1030\u20131039, 2014.\n[102] D. Sabella, P. Rost, Y. Sheng, E. Pateromichelakis, U. Salim, P. Guitton-\nOuhamou, M. di Girolamo, and G. Giuliani, \u201cRAN as a service:\nChallenges of designing a flexible RAN architecture in a cloud-based\nheterogeneous mobile network,\u201d in Future Network and Mobile Summit\n(FutureNetworkSummit), 2013, July 2013, pp. 1\u20138.\n[103] R. Vilalta, R. Muoz, R. Casellas, R. Martinez, V. Lopez, and D. Lopez,\n\u201cTransport PCE network function virtualization,\u201d in Optical Commu-\nnication (ECOC), 2014 European Conference on, Sept 2014, pp. 1\u20133.\n[104] R. Vilalta, R. Munoz, A. Mayoral, R. Casellas, R. Martinez, V. Lopez,\nand D. Lopez, \u201cTransport Network Function Virtualization,\u201d Lightwave\nTechnology, Journal of, vol. PP, no. 99, pp. 1\u20131, 2015.\n[105] \u201cArinet vCPE,\u201d https://www.sdxcentral.com/products/\nvirtual-cpe-vcpe-framework/, 2015, Accessed: January, 26 2015.\n[106] \u201cAnuta Networks vCPE,\u201d http://www.anutanetworks.com/\nroad-to-virtualizing-cpe/, 2015, Accessed: January, 26 2015.\n[107] \u201cCalsoftlabs vCPE,\u201d http://sdn.calsoftlabs.com/\nnetwork-function-virtualization/virtual-cpe.html, 2015, Accessed:\nJanuary, 26 2015.\n[108] S. Aleksic and I. Miladinovic, \u201cNetwork virtualization: Paving the\nway to carrier clouds,\u201d in Telecommunications Network Strategy and\nPlanning Symposium (Networks), 2014 16th International, Sept 2014,\npp. 1\u20136.\n[109] M. Nagy and I. Kotuliak, \u201cUtilizing OpenFlow, SDN and NFV in GPRS\nCore Network,\u201d in Testbeds and Research Infrastructure: Development\nof Networks and Communities, ser. Lecture Notes of the Institute\nfor Computer Sciences, Social Informatics and Telecommunications\nEngineering, V. C. Leung, M. Chen, J. Wan, and Y. Zhang, Eds.\nSpringer International Publishing, 2014, vol. 137, pp. 184\u2013193.\n[110] E. Jacob, J. Matias, A. Mendiola, V. Fuentes, J. Garay, and C. Pinedo,\n\u201cDeploying a virtual network function over a software defined network\ninfrastructure: experiences deploying an access control VNF in the\nUniversity of Basque Countrys OpenFlow enabled facility,\u201d 2014.\n[111] \u201cHP OpenNFV Reference Architecture,\u201d http://www8.hp.com/us/en/\ncloud/nfv-overview.html?, 2015, Accessed: February, 05 2015.\n[112] \u201cHuawei NFV Open Lab,\u201d http://pr.huawei.com/en/news/, January\n2015, Accessed: February, 09 2015.\n[113] \u201cIntel Open Network Platform,\u201d http://www.intel.com/ONP, 2015, Ac-\ncessed: February, 03 2015.\n[114] \u201cCloudNFV,\u201d http://www.cloudnfv.com/, 2015, Accessed: January, 26\n2015.\n[115] \u201cAlcatel-Lucent\u2019s ClouBand,\u201d http://www.alcatel-lucent.com/solutions/\ncloudband, 2015, Accessed: January, 26 2015.\n[116] Nuage Networks, \u201cNuage Networks Virtualized Services Platform,\u201d\nhttp://www.nuagenetworks.net/, February 2015, An Alcatel-Lucent\nventure.\n[117] Alcatel-Lucent, \u201cCloudBand with OpenStack as NFV Platform. Strate-\ngic White Paper, NFV Insgights Series,\u201d www.alcatel-lucent.com/,\nAlcatel Lucent and RedHat, Tech. Rep., August 2014.\n[118] \u201cBroadcom Open NFV,\u201d http://www.broadcom.com/press/release.php?\nid=s827048, 2015, Accessed: January, 26 2015.\n[119] A. Khan, \u201cRecent developments in high-performance system-on-chip\nIC design,\u201d in Integrated Circuit Design and Technology, 2004. ICICDT\n\u201904. International Conference on, 2004, pp. 151\u2013158.\n[120] ODP, \u201cOpenDataPlane project,\u201d http://www.opendataplane.org/, Febru-\nary 2015.\n[121] Cisco, \u201cNFV Management and Orchestration: Enabling Rapid Service\nInnovation in the Era of Virtualization,\u201d http://www.cisco.com/, Cisco,\nTech. Rep., June 2015.\n[122] F5, \u201cNFV: Beyond Virtualization. Techinical White Paper,\u201d F5 Net-\nworks, Inc., Tech. Rep., February 2014.\n[123] F. Yue, \u201cNetwork Functions Virtualization - Everything Old Is New\nAgain. Techinical White Paper,\u201d F5 Networks, Inc., Tech. Rep., Febru-\nary 2014.\n[124] L. MacVittie, \u201cSoftware Defined Application Services. Techinical\nWhite Paper,\u201d F5 Networks, Inc., Tech. Rep., February 2014.\n[125] \u201cClearwater,\u201d http://www.metaswitch.com/clearwater, 2015, Accessed:\nJanuary, 26 2015.\n[126] \u201cMetaswitch,\u201d http://www.metaswitch.com/nfv, 2015, Accessed: Jan-\nuary, 26 2015.\n[127] J. Keeney, S. v. d. Meer, and L. Fallon, \u201cTowards real-time management\nof virtualized telecommunication networks,\u201d in Network and Service\nManagement (CNSM), 2014 10th International Conference on, Nov\n2014, pp. 388\u2013393.\n[128] L. Bondan, C. R. P. d. Santos, and L. Z. Granville, \u201cManagement\nrequirements for ClickOS-based Network Function Virtualization,\u201d in\nNetwork and Service Management (CNSM), 2014 10th International\nConference on, Nov 2014, pp. 447\u2013450.\n[129] Z. Bronstein and E. Shraga, \u201cNFV virtualisation of the home envi-\nronment,\u201d in Consumer Communications and Networking Conference\n(CCNC), 2014 IEEE 11th, Jan 2014, pp. 899\u2013904.\n[130] J. Soares, M. Dias, J. Carapinha, B. Parreira, and S. Sargento,\n\u201cCloud4NFV: A platform for Virtual Network Functions,\u201d in Cloud\nNetworking (CloudNet), 2014 IEEE 3rd International Conference on,\nOct 2014, pp. 288\u2013293.\n[131] J. Soares, C. Goncalves, B. Parreira, P. Tavares, J. Carapinha, J. P. Bar-\nraca, R. L. Aguiar, and S. Sargento, \u201cToward a telco cloud environment\nfor service functions,\u201d Communications Magazine, IEEE, vol. 53, no. 2,\npp. 98\u2013106, Feb 2015.\n[132] S. Clayman, E. Maini, A. Galis, A. Manzalini, and N. Mazzocca,\n\u201cThe dynamic placement of virtual network functions,\u201d in Network\nOperations and Management Symposium (NOMS), 2014 IEEE, May\n2014, pp. 1\u20139.\n[133] V. Riccobene, A. Lombardo, A. Manzalini, and G. Schembra, \u201cNet-\nwork Functions At The Edge (NetFATE): Design and Implementation\nIssues,\u201d 2014.\n[134] E. Maini and A. Manzalini, \u201cManagement and Orchestration of Vir-\ntualized Network Functions,\u201d in Monitoring and Securing Virtualized\nNetworks and Services, ser. Lecture Notes in Computer Science,\nA. Sperotto, G. Doyen, S. Latr, M. Charalambides, and B. Stiller, Eds.\nSpringer Berlin Heidelberg, 2014, vol. 8508, pp. 52\u201356.\n[135] W. Shen, M. Yoshida, T. Kawabata, K. Minato, and W. Imajuku,\n\u201cvConductor: An NFV management solution for realizing end-to-end\nvirtual network services,\u201d in Network Operations and Management\nSymposium (APNOMS), 2014 16th Asia-Pacific, Sept 2014, pp. 1\u20136.\n[136] W. Shen, M. Yoshida, K. Minato, and W. Imajuku, \u201cvConductor:\nAn enabler for achieving virtual network integration as a service,\u201d\nCommunications Magazine, IEEE, vol. 53, no. 2, pp. 116\u2013124, Feb\n2015.\n[137] P. Donadio, G. Fioccola, R. Canonico, and G. Ventre, \u201cA PCE-based ar-\nchitecture for the management of virtualized infrastructures,\u201d in Cloud\nNetworking (CloudNet), 2014 IEEE 3rd International Conference on,\nOct 2014, pp. 223\u2013228.\n[138] R. Bolla, C. Lombardo, R. Bruschi, and S. Mangialardi, \u201cDROPv2:\nenergy efficiency through network function virtualization,\u201d Network,\nIEEE, vol. 28, no. 2, pp. 26\u201332, March 2014.\n[139] W. Shen, M. Yoshida, T. Kawabata, K. Minato, and W. Imajuku,\n\u201cvconductor: An nfv management solution for realizing end-to-end\nvirtual network services,\u201d in Network Operations and Management\nSymposium (APNOMS), 2014 16th Asia-Pacific, Sept 2014, pp. 1\u20136.\n[140] K. Giotis, Y. Kryftis, and V. Maglaris, \u201cPolicy-based orchestration of\nnfv services in software-defined networks,\u201d in Network Softwarization\n(NetSoft), 2015 1st IEEE Conference on, April 2015, pp. 1\u20135.\n[141] J. Wickboldt, W. De Jesus, P. Isolani, C. Both, J. Rochol, and\nL. Granville, \u201cSoftware-defined networking: management requirements\nand challenges,\u201d Communications Magazine, IEEE, vol. 53, no. 1, pp.\n278\u2013285, January 2015.\n[142] C. Chappell, \u201cDeploying Virtual Network Functions: The Comple-\nmentary Roles of TOSCA and NETCONF/YANG,\u201d February 2015,\nTechnical White Paper. Heavy Reading, Cisco, Alcatel-Lucent.\n[143] Bell Labs, Alcetel Lucent, \u201cG.W.A.T.T. (Global What if Analyzer of\nNeTwork Energy ConsumpTion). Bell Labs application able to measure\nthe impact of technologies like SDN & NFV on network energy\nconsumption. White Paper.\u201d http://gwatt.net/intro/1, 2015.\n[144] \u201cGlobal e-Sustainability Initiative (GeSI) SMARTer2020,\u201d http://gesi.\norg/SMARTer2020, 2015, Accessed: June, 08 2015.\n[145] GREENPEACE, \u201cClicking Clean: How Companies are Creating the\nGreen Internet,\u201d www.greenpeace.org, April 2014.\n[146] The Natural Resources Defense Council (NRDC), \u201cData Center Ef-\nficiency Assessment. Scaling Up Energy Efficiency Across the Data\nCenter Industry: Evaluating Key Drivers and Barriers. Issue Paper.\u201d\nAugust 2014.\n[147] A. Beloglazov, R. Buyya, Y. C. Lee, and A. Y. Zomaya, \u201cA\nTaxonomy and Survey of Energy-Efficient Data Centers and Cloud\nComputing Systems.\u201d Advances in Computers, vol. 82, pp. 47\u2013111,\n2011. [Online]. Available: http://dblp.uni-trier.de/db/journals/ac/ac82.\nhtml#BeloglazovBLZ11\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 27\n[148] C.-L. I, J. Huang, R. Duan, C. Cui, J. Jiang, and L. Li, \u201cRecent Progress\non C-RAN Centralization and Cloudification,\u201d Access, IEEE, vol. 2, pp.\n1030\u20131039, September 2014.\n[149] E. Masanet, A. Shehabi, L. Ramakrishnan, J. Liang, X. Ma, B. Walker,\nV. Hendrix, and P. Mantha, \u201cThe Energy Efficiency Potential of\nCloud-Based Software: A US Case Study. Lawrence Berkely National\nLaboratory, Berkerly California.\u201d 2013.\n[150] Cisco, \u201cThe Zettabyte Era: Trends and Analysis,\u201d Tech. Rep., May\n2015.\n[151] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS\nNFV-PER 001 V1.1.1: Network Functions Virtualisation\n(NFV); NFV Performance & Portability Best Practises,\u201d\nhttp://www.etsi.org/deliver/etsi gs/NFV-PER/001 099/001/01.01.\n01 60/gs nfv-per001v010101p.pdf, June 2014.\n[152] Ericsson AB et. al, \u201cCommon Public Radio Interface (CPRI) Specifica-\ntion V6.0,\u201d http://www.cpri.info/downloads/CPRI v 6 0 2013-08-30.\npdf, August 2013.\n[153] Napatech, \u201cTime to Rethink SDN and NFV Performance,\u201d Tech. Rep.,\nDecember 2014.\n[154] K. Yamazaki, T. Osaka, S. Yasuda, S. Ohteru, and\nA. Miyazaki, \u201cAccelerating sdn/nfv with transparent offloading\narchitecture,\u201d in Presented as part of the Open Networking\nSummit 2014 (ONS 2014). Santa Clara, CA: USENIX,\n2014. [Online]. Available: https://www.usenix.org/conference/ons2014/\ntechnical-sessions/presentation/yamazaki\n[155] A. Fischer, J. Botero, M. Till Beck, H. de Meer, and X. Hesselbach,\n\u201cVirtual Network Embedding: A Survey,\u201d Communications Surveys\nTutorials, IEEE, vol. 15, no. 4, pp. 1888\u20131906, Fourth 2013.\n[156] M. Rabbani, R. Pereira Esteves, M. Podlesny, G. Simon, L. Zam-\nbenedetti Granville, and R. Boutaba, \u201cOn tackling virtual data center\nembedding problem,\u201d in Integrated Network Management (IM 2013),\n2013 IFIP/IEEE International Symposium on, May 2013, pp. 177\u2013184.\n[157] A. Basta, W. Kellerer, M. Hoffmann, H. J. Morper, and K. Hoffmann,\n\u201cApplying NFV and SDN to LTE Mobile Core Gateways, the Functions\nPlacement Problem,\u201d in Proceedings of the 4th Workshop on All\nThings Cellular: Operations, Applications, &#38; Challenges, ser.\nAllThingsCellular \u201914. New York, NY, USA: ACM, 2014, pp. 33\u201338.\n[158] H. Moens and F. D. Turck, \u201cVnf-p: A model for efficient placement of\nvirtualized network functions,\u201d in Network and Service Management\n(CNSM), 2014 10th International Conference on, Nov 2014, pp. 418\u2013\n423.\n[159] M. Bagaa, T. Taleb, and A. Ksentini, \u201cService-aware network function\nplacement for efficient traffic handling in carrier cloud,\u201d in Wireless\nCommunications and Networking Conference (WCNC), 2014 IEEE,\nApril 2014, pp. 2402\u20132407.\n[160] S. Mehraghdam, M. Keller, and H. Karl, \u201cSpecifying and placing chains\nof virtual network functions,\u201d in Cloud Networking (CloudNet), 2014\nIEEE 3rd International Conference on, Oct 2014, pp. 7\u201313.\n[161] M. Bouet, J. Leguay, and V. Conan, \u201cCost-based placement of vdpi\nfunctions in nfv infrastructures,\u201d in Network Softwarization (NetSoft),\n2015 1st IEEE Conference on, April 2015, pp. 1\u20139.\n[162] A. Schrijver, Theory of Linear and Integer Programming. New York,\nNY, USA: John Wiley & Sons, Inc., 1986.\n[163] M. Xia, M. shirazipour, Y. Zhang, H. Green, and A. Takacs, \u201cNetwork\nFunction Placement for NFV Chaining in Packet/Optical Datacenters,\u201d\nLightwave Technology, Journal of, vol. PP, no. 99, pp. 1\u20131, 2015.\n[164] M. Yoshida, W. Shen, T. Kawabata, K. Minato, and W. Imajuku,\n\u201cMORSA: A multi-objective resource scheduling algorithm for NFV\ninfrastructure,\u201d in Network Operations and Management Symposium\n(APNOMS), 2014 16th Asia-Pacific, Sept 2014, pp. 1\u20136.\n[165] O. Hyeonseok, Y. Daeun, C. Yoon-Ho, and K. Namgi, \u201cDesign of\nan Efficient Method for Identifying Virtual Machines Compatible\nwith Service Chain in a Virtual Network Environment,\u201d International\nJournal of Multimedia and Ubiquitous Engineering, vol. 11, no. 9, pp.\n197\u2013208, 2014.\n[166] L. F. Wanner and M. B. Srivastava, \u201cViRUS: Virtual Function Replace-\nment Under Stress,\u201d in 6th Workshop on Power-Aware Computing and\nSystems, HotPower \u201914, Broomfield, CO, USA, October 5, 2014., 2014.\n[167] W. Cerroni and F. Callegati, \u201cLive migration of virtual network\nfunctions in cloud-based edge networks,\u201d in Communications (ICC),\n2014 IEEE International Conference on, June 2014, pp. 2963\u20132968.\n[168] LXC, \u201cLinux Containers,\u201d https://linuxcontainers.org/, January 2015.\n[169] S. Hykes, \u201cDocker,\u201d https://www.docker.com/, June 2015.\n[170] T. Nolle, \u201cIs NFV and Cloud Computing Missing the Docker Boat.\u201d\nhttp://blog.cimicorp.com/?p=1911, October 2014.\n[171] R. Mijumbi, J. Serrat, J.-L. Gorricho, N. Bouten, F. De Turck, and\nS. Davy, \u201cDesign and Evaluation of Algorithms for Mapping and\nScheduling of Virtual Network Functions,\u201d in IEEE Conference on\nNetwork Softwarization (NetSoft). University College London, April\n2015.\n[172] J. Ferrer Riera, X. Hesselbach, E. Escalona, J. Garcia-Espin, and\nE. Grasa, \u201cOn the complex scheduling formulation of virtual network\nfunctions over optical networks,\u201d in Transparent Optical Networks\n(ICTON), 2014 16th International Conference on, July 2014, pp. 1\u20135.\n[173] J. Ferrer Riera, E. Escalona, J. Batalle, E. Grasa, and J. Garcia-\nEspin, \u201cVirtual network function scheduling: Concept and challenges,\u201d\nin Smart Communications in Network Technologies (SaCoNeT), 2014\nInternational Conference on, June 2014, pp. 1\u20135.\n[174] P. Brucker, A. Drexl, R. Mhring, K. Neumann, and E. Pesch,\n\u201cResource-constrained project scheduling: Notation, classification,\nmodels, and methods,\u201d European Journal of Operational Research, vol.\n112, no. 1, pp. 3 \u2013 41, 1999.\n[175] J. Baewicz, W. Domschke, and E. Pesch, \u201cThe job shop scheduling\nproblem: Conventional and new solution techniques,\u201d European Jour-\nnal of Operational Research, vol. 93, no. 1, pp. 1 \u2013 33, 1996.\n[176] F. Glover and M. Laguna, Tabu Search. Norwell, MA, USA: Kluwer\nAcademic Publishers, 1997.\n[177] A. Verma, L. Pedrosa, M. Korupolu, D. Oppenheimer, E. Tune, and\nJ. Wilkes, \u201cLarge-scale cluster management at google with borg,\u201d in\nProceedings of the Tenth European Conference on Computer Systems,\nEuroSys 2015, Bordeaux, France, April 21-24, 2015, 2015, p. 18.\n[Online]. Available: http://doi.acm.org/10.1145/2741948.2741964\n[178] B. Hindman, A. Konwinski, M. Zaharia, A. Ghodsi, A. D. Joseph,\nR. Katz, S. Shenker, and I. Stoica, \u201cMesos: A platform for fine-grained\nresource sharing in the data center,\u201d in Proceedings of the 8th USENIX\nConference on Networked Systems Design and Implementation,\nser. NSDI\u201911. Berkeley, CA, USA: USENIX Association, 2011,\npp. 295\u2013308. [Online]. Available: http://dl.acm.org/citation.cfm?id=\n1972457.1972488\n[179] A. Ahmed and P. Panagiotis, \u201cMIDAS: Middlebox Discovery and\nSelection for On-Path Flow Processing,\u201d in IEEE COMSNETS, 2015,\np. 8.\n[180] R. Rosa, M. Silva Santos, and C. Esteve Rothenberg, \u201cMd2-nfv: The\ncase for multi-domain distributed network functions virtualization,\u201d\nin Networked Systems (NetSys), 2015 International Conference and\nWorkshops on, March 2015, pp. 1\u20135.\n[181] M. G. Rabbani, F. Z. Mohamed, and R. Boutaba, \u201cOn Achieving High\nSurvivability in Virtualized Data Centers,\u201d IEICE Transactions, vol.\n97-B, no. 1, pp. 10\u201318, 2014.\n[182] R. Mijumbi, J.-L. Gorricho, J. Serrat, M. Claeys, F. De Turck, and\nS. Latre, \u201cDesign and evaluation of learning algorithms for dynamic\nresource management in virtual networks,\u201d in Network Operations and\nManagement Symposium (NOMS), 2014 IEEE, May 2014, pp. 1\u20139.\n[183] S. Pearson and G. Yee, Privacy and Security for Cloud Computing.\nSpringer, Series on Computer Communications and Networks, 2013.\n[184] ETSI Industry Specification Group (ISG) NFV, \u201cETSI GS NFV-SEC\n001 V1.1.1: Network Functions Virtualisation (NFV); NFV Security;\nProblem Statement,\u201d http://www.etsi.org/deliver/etsi gs/NFV-SEC/\n001 099/001/01.01.01 60/gs NFV-SEC001v010101p.pdf, October\n2014.\n[185] \u201cTopology and Orchestration Specification for Cloud Applications Ver-\nsion 1.0,\u201d http://docs.oasis-open.org/tosca/TOSCA/v1.0/os/TOSCA-v1.\n0-os.pdf, November 2013, oASIS Standard.\n[186] J. Schonwalder, M. Bjorklund, and P. Shafer, \u201cNetwork configuration\nmanagement using netconf and yang,\u201d Communications Magazine,\nIEEE, vol. 48, no. 9, pp. 166\u2013173, Sept 2010.\n[187] A. D. Birrell and B. J. Nelson, \u201cImplementing remote procedure\ncalls,\u201d ACM Trans. Comput. Syst., vol. 2, no. 1, pp. 39\u201359, Feb. 1984.\n[Online]. Available: http://doi.acm.org/10.1145/2080.357392\n[188] J. P. Reilly, \u201cImplementing the TM Forum Information\nFramework (SID). A Practitioner\u2019s Guide. Version 1.0,\u201d\nhttp://inform.tmforum.org/wp-content/uploads/2014/05/\nImplementing-the-SID-v1dot0b-Chapters-1-through-3.pdf, September\n2011.\n[189] J. Rumbaugh, I. Jacobson, and G. Booch, Unified Modeling Language\nReference Manual, The (2Nd Edition). Pearson Higher Education,\n2004.\n[190] G. Katsaros, M. Menzel, A. Lenk, J. Rake-Revelant, R. Skipp, and\nJ. Eberhardt, \u201cCloud application portability with tosca, chef and\nopenstack,\u201d in Cloud Engineering (IC2E), 2014 IEEE International\nConference on, March 2014, pp. 295\u2013302.\nIEEE COMMUNICATIONS SURVEYS & TUTORIALS 28\n[191] T. Binz, U. Breitenbu\u00a8cher, F. Haupt, O. Kopp, F. Leymann, A. Nowak,\nand S. Wagner, \u201cOpentosca\u2013a runtime for tosca-based cloud applica-\ntions,\u201d in Service-Oriented Computing. Springer, 2013, pp. 692\u2013695.\n[192] Y. Lee and J. Lee, \u201cOptimizing the operation layer algorithm\nof netconf protocol,\u201d in Multimedia and Ubiquitous Engineering,\nser. Lecture Notes in Electrical Engineering, J. J. J. H. Park,\nS.-C. Chen, J.-M. Gil, and N. Y. Yen, Eds. Springer Berlin\nHeidelberg, 2014, vol. 308, pp. 249\u2013258. [Online]. Available:\nhttp://dx.doi.org/10.1007/978-3-642-54900-7 36\n[193] TMF Forum, \u201cTM Forum Information Framework Enhancements\nto Support ZOOM. TR224, Release 15.0.0,\u201d https://www.tmforum.\norg/resources/suite/gb922-information-framework-sid-r15-0-0/, Tech.\nRep., May 2015.\n[194] J. Gubbi, R. Buyya, S. Marusic, and M. Palaniswami, \u201cInternet of\nThings (IoT): A Vision, Architectural Elements, and Future Directions,\u201d\nFuture Gener. Comput. Syst., vol. 29, no. 7, pp. 1645\u20131660, Sep. 2013.\n[Online]. Available: http://dx.doi.org/10.1016/j.future.2013.01.010\n[195] F. Van den Abeele, J. Hoebeke, G. Teklemariam, I. Moerman,\nand P. Demeester, \u201cSensor Function Virtualization to Support\nDistributed Intelligence in the Internet of Things,\u201d Wireless Personal\nCommunications, vol. 81, no. 4, pp. 1415\u20131436, 2015. [Online].\nAvailable: http://dx.doi.org/10.1007/s11277-015-2481-4\n[196] N. Omnes, M. Bouillon, G. Fromentoux, and O. Le Grand, \u201cA\nprogrammable and virtualized network it infrastructure for the internet\nof things: How can nfv sdn help for facing the upcoming challenges,\u201d\nin Intelligence in Next Generation Networks (ICIN), 2015 18th Inter-\nnational Conference on, Feb 2015, pp. 64\u201369.\n[197] G. Xylomenos, C. Ververidis, V. Siris, N. Fotiou, C. Tsilopoulos,\nX. Vasilakos, K. Katsaros, and G. Polyzos, \u201cA Survey of Information-\nCentric Networking Research,\u201d Communications Surveys Tutorials,\nIEEE, vol. 16, no. 2, pp. 1024\u20131049, Second 2014.\n[198] M. Arumaithurai, J. Chen, E. Monticelli, X. Fu, and K. K. Ramakrish-\nnan, \u201cExploiting ICN for Flexible Management of Software-defined\nNetworks,\u201d in Proceedings of the 1st International Conference on\nInformation-centric Networking, ser. INC \u201914. New York, NY, USA:\nACM, 2014, pp. 107\u2013116.\n[199] Intel, Brocade, Cyan, Red Hat, and Telefonica, \u201cEnd to End Network\nFunction Virtualization Architecture Instantiation,\u201d http://pressoffice.\ntelefonica.com/documentos/EndtoEndNFVArchitectureFinal.pdf,\nFebruary 2015, Joint White Paper.\n[200] T. Nolle, \u201cExperiaSphere: Take The First Step to Open Orchestration,\u201d\nhttp://blog.experiasphere.com/, June 2014.\nRashid Mijumbi obtained a degree in electrical\nengineering from Makerere University, Uganda in\n2009, and a PhD in telecommunications engineer-\ning from the Universitat Polite`cnica de Catalunya\n(UPC), Spain in 2014. He is currently a Postdoctoral\nResearcher in the Network Engineering Department\nat the UPC. His research interests are in autonomic\nmanagement of networks and services. Current focus\nis on management of resources for virtualized net-\nworks and functions, cloud computing and software\ndefined networks.\nJoan Serrat received a degree of telecommunication\nengineering in 1977 and a PhD in the same field\nin 1983, both from the Universitat Polite`cnica de\nCatalunya (UPC). Currently, he is a full professor\nat UPC where he has been involved in several col-\nlaborative projects with different European research\ngroups, both through bilateral agreements or through\nparticipation in European funded projects. His topics\nof interest are in the field of autonomic networking\nand service and network management. Currently, he\nis the contact point of the TM Forum at UPC.\nJuan-Luis Gorricho received a telecommunication\nengineering degree in 1993, and a Ph.D. degree\nin 1998, both from the UPC. He is currently an\nassociate professor at the UPC. His recent research\ninterests are in applying artificial intelligence to\nubiquitous computing and network management;\nwith special interest on using smartphones to achieve\nthe recognition of user activities and locations;\nand applying linear programming and reinforcement\nlearning to resource management in virtualized net-\nworks and functions.\nNiels Bouten obtained a masters degree in computer\nscience from Ghent University, Belgium, in June\n2011. In August 2011, he joined the Department of\nInformation Technology at Ghent University, where\nhe is active as a Ph.D. student. His main research\ninterests are the application of autonomic network\nmanagement approaches in multimedia delivery. The\nfocus of this research is mainly on the end-to-end\nQuality of Experience optimization, ranging from\nthe design of a single autonomic control loop to the\nfederated management of these distributed loops.\nFilip De Turck is a professor at the Department\nof Information Technology of Ghent University and\niMinds in Belgium, where he leads the network\nand service management research group. His main\nresearch interests include scalable software architec-\ntures for network and service management, design\nand performance evaluation of novel QoE-aware\nmultimedia delivery systems. He served as TPC\nchair of the IEEE/IFIP Network Operations and\nManagement Symposium (NOMS 2012) and the\nIFIP/IEEE Integrated Network Management Sympo-\nsium (IM 2013). He is associate editor of the Journal on Network and System\nManagement, the International Journal of Network Management and IEEE\nTransactions on Network and Service Management.\nRaouf Boutaba received the MSc and PhD degrees\nin computer science from the Universite\u00b4 de Pierre\net Marie Curie, Paris, France, in 1990 and 1994,\nrespectively. He is currently a full professor of\ncomputer science at the University of Waterloo, Wa-\nterloo, ON, Canada, and a distinguished visiting pro-\nfessor at the Pohang University of Science and Tech-\nnology (POSTECH), Korea. His research interests\ninclude network, resource and service management\nin wired and wireless networks. He has received\nseveral best paper awards and other recognitions\nsuch as the Premier\u2019s Research Excellence Award, the IEEE Hal Sobol Award\nin 2007, the Fred W. Ellersick Prize in 2008, the Joe LociCero and the Dan\nStokesbury awards in 2009, and the Salah Aidarous Award in 2012. He is a\nfellow of the IEEE and the Engineering Institute of Canada.\n",
      "id": 31329057,
      "identifiers": [
        {
          "identifier": "223075192",
          "type": "CORE_ID"
        },
        {
          "identifier": "55825883",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:archive.ugent.be:7017758",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1109/inm.2015.7140291",
          "type": "DOI"
        },
        {
          "identifier": "209155073",
          "type": "CORE_ID"
        }
      ],
      "title": "Algorithms for advance bandwidth reservation in media production networks",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:archive.ugent.be:7017758"
      ],
      "publishedDate": "2015-01-01T00:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://biblio.ugent.be/publication/7017758/file/7017775"
      ],
      "updatedDate": "2022-11-01T14:38:58",
      "yearPublished": 2015,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/55825883.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/55825883"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/55825883/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/55825883/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/31329057"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Frick, Natalie Mims"
        },
        {
          "name": "Schellenberg, Josh A"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/635937094"
      ],
      "createdDate": "2025-01-20T07:51:34",
      "dataProviders": [
        {
          "id": 183,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/183",
          "logo": "https://api.core.ac.uk/data-providers/183/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "This report discusses a new maturity model that regulators and utilities can use to guide and expand demand flexibility programs and enable the resources to provide more grid services. The model has six demand flexibility categories: planning and design; customer engagement; program operations; evaluation, measurement and verification; distributed energy resource orchestration; and data infrastructure. Within each category, capabilities are identified and described on a maturity scale that ranges from performing below expectations to improving on best practices",
      "doi": null,
      "downloadUrl": "https://core.ac.uk/download/635937094.pdf",
      "fieldOfStudy": null,
      "fullText": "Lawrence Berkeley National LaboratoryLBL PublicationsTitleMoving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand FlexibilityPermalinkhttps://escholarship.org/uc/item/0r5672n3AuthorsSchellenberg, Josh AFrick, Natalie MimsPublication Date2025-01-16Copyright InformationThis work is made available under the terms of a Creative Commons Attribution-NonCommercial-NoDerivatives License, available at https://creativecommons.org/licenses/by-nc-nd/4.0/ Peer reviewedeScholarship.org Powered by the California Digital LibraryUniversity of California    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility  January 2025     Josh Schellenberg, Berkeley Lab affiliate Natalie Mims Frick, Berkeley Lab      Disclaimer  This document was prepared as an account of work sponsored by the United States Government. While this document is believed to contain correct information, neither the United States Government nor any agency thereof, nor The Regents of the University of California, nor any of their employees, makes any warranty, express or implied, or assumes any legal responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. Reference herein to any specific commercial product, process, or service by its trade name, trademark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof, or The Regents of the University of California. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof, or The Regents of the University of California.  Ernest Orlando Lawrence Berkeley National Laboratory is an equal opportunity employer.  Copyright Notice  This manuscript has been authored by an author at Lawrence Berkeley National Laboratory under Contract No. DE-AC02-05CH11231 with the U.S. Department of Energy. The U.S. Government retains, and the publisher, by accepting the article for publication, acknowledges, that the U.S. Government retains a non-exclusive, paid-up, irrevocable, worldwide license to publish or reproduce the published form of this manuscript, or allow others to do so, for U.S. Government purposes.           Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility     Prepared for the U.S. Department of Energy Office of Energy Efficiency and Renewable Energy    Principal Authors Josh Schellenberg Natalie Mims Frick     Ernest Orlando Lawrence Berkeley National Laboratory 1 Cyclotron Road, MS 90R4000 Berkeley CA 94720-8136      January 2025      The work described in this study was funded by the U.S. Department of Energy\u2019s Office of Energy Efficiency and Renewable Energy under Lawrence Berkeley National Laboratory Contract No. DE-AC02-05CH11231.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u2502i  Acknowledgements The work described in this study was conducted at Lawrence Berkeley National Laboratory and supported by the U.S. Department of Energy\u2019s Office of Energy Efficiency and Renewable Energy under Contract No. DE-AC02-05CH11231.  The authors thank Paul Spitsen, Michelle Boyd, Stacey Miller, JP Carvallo and Robert Margolis, U.S. Department of Energy, for supporting our work, and the following experts for reviewing this report (affiliations do not imply that their organizations support or endorse this work):  Philip Chao and Paul Heitmann, New Jersey Board of Public Utilities Robin Maslowski, Trillium Energy Consulting Nicholas Papanastassiou, EnergyHub George Twigg, New England Conference of Public Utilities Commissioners          Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u2502ii  Table of Contents Table of Contents ........................................................................................................................................ ii Table of Figures ...........................................................................................................................................iii Executive Summary..................................................................................................................................... iv 1. Introduction ......................................................................................................................................... 1 2. Demand Flexibility Maturity Model Overview ...................................................................................... 4 2.1 DF Maturity Model Categories and Capabilities ........................................................................ 5 2.2 Example Applications ................................................................................................................. 9 3. References .......................................................................................................................................... 10 Appendix: Demand Flexibility Maturity Model ......................................................................................... 12 1. Category: Planning & Design ................................................................................................................ 13 2. Category: Customer Engagement ......................................................................................................... 20 3. Category: Program Operations ............................................................................................................. 26 4. Category: EM&V ................................................................................................................................... 32 5. Category: DER Orchestration ................................................................................................................ 37 6. Category: Data Infrastructure ............................................................................................................... 42        Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u2502iii  Table of Figures Figure ES - 1. Berkeley Lab Demand Flexibility Maturity Model.................................................................. iv Figure 1-1. Advanced Meter Growth in the United States (2007\u20132022) ..................................................... 1 Figure 1-2. Retail DR Program Potential Peak Demand Savings in the United States (2014\u20132023) ............ 2 Figure 1-3. Retail DR Program Potential Peak Demand Savings by Census Division (2018 \u2013 2022) ............. 3 Figure 2-1. Berkeley Lab Demand Flexibility Maturity Model ..................................................................... 5 Figure 2-2. Berkeley Lab Demand Flexibility Maturity Model Categories and Capabilities ......................... 6 Figure 2-3. Comparison across Utilities for Vegetation Management and Inspections Category ............. 10         Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u2502iv  Executive Summary Despite the widespread adoption of advanced meters and increased need for demand flexibility1 (DF) due to load growth and increasing renewable energy supply on the grid, utilities have generally not moved beyond traditional direct load control (DLC) programs to realize the promise of DF. Based on an in-depth review, Murphy et al. (2024) finds that most DF efforts focus on reducing demand during summer peaks driven by space conditioning consumption, similar to the findings of a 2006 Federal Energy Regulatory Commission (FERC) survey. Since 2007, the number of advanced meters has increased by over 112 million, from 4.7% penetration in 2007 to 72.3% in 2022 (FERC 2024). Prior to this growth, FERC estimated that the total potential demand response2 (DR) resource contribution from existing programs and rates in 2006 was 37.5 GW (FERC 2006), but recent data shows that nationwide DR capacity may currently be lower. While many factors have introduced uncertainty into assessing multi-year DF trends throughout the country, it is clear that DF programs have not grown or changed substantially, even though DF potential has increased as utilities have rapidly deployed advanced meters and consumers have adopted a wide range of connected devices.  With surging electricity load growth from data centers, manufacturing facilities, buildings and transportation, DF is urgently needed to mitigate capacity constraints and power interruptions. Given the slow progress with DF programs recently, utilities and regulators are seeking novel approaches for driving DF progress. Therefore, Berkeley Lab has developed the DF maturity model (Figure ES-1), based on well-documented industry best practices and barriers to broader DF adoption.  Figure ES - 1. Berkeley Lab Demand Flexibility Maturity Model   1 Demand flexibility includes any type of flexible behind-the-meter Distributed Energy Resource (DER), including solar, storage, electric vehicles, and traditional demand response (DR). It is defined as \"the capability provided by on-site DERs to reduce, shed, shift, modulate, or generate electricity\" (DOE 2021). 2 DR and DF are used interchangeably in this report for the purposes of assessing progress.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u2502v  This detailed, practical guidance based on a wide range of lessons learned fills a gap in the literature by providing an extensive tool to help utilities and regulators realize the promise DF. Importantly, the maturity model primarily applies to retail DF programs run by utilities, with involvement of third-party technology providers and DER aggregators. The model could also apply to dispatchable time-varying pricing programs (e.g., Critical Peak Pricing), though it does not include key pricing-related capabilities such as rate design. States and utilities can also adapt the maturity model to their jurisdiction as needed.  The Berkeley Lab DF maturity model scores utility programs on 34 DF capabilities, organized into the six categories in Figure ES-1. Similar to utility capability maturity models for wildfire mitigation (Office of Energy Infrastructure Safety 2020), cybersecurity (DOE 2022) and smart grid (Carnegie Mellon 2018), the DF maturity model is a framework for assessing current capabilities and developing a plan for improvement. Similar to the California Wildfire Mitigation Maturity Model (Office of Energy Infrastructure Safety 2020), each DF capability is scored at one of five possible levels of maturity:  1. Below expectations 2. Meets minimum expectations 3. Beyond minimum expectations, but not consistent with best practice 4. Consistent with best practice 5. Improvement over best practice  Industry literature, conference presentations, and reviewer feedback have informed maturity levels, including best practices and reasonable expectations of utility capabilities.  By measuring maturity levels across 34 DF capabilities, states and utilities can prioritize investment, identify gaps, and drive continuous improvement to realize the promise of DF and move beyond DLC.  In general, the levels of maturity drive DF programs in the following direction:  \u2022 From inflexible and uninformed by grid needs and data (low maturity) to highly flexible and driven by grid needs and accurate, granular data (high maturity) \u2022 From a limited understanding of performance (low maturity) to frequent, ongoing performance assessment that proactively identifies scaling constraints and continuous improvements (high maturity) \u2022 From infrequent, reactive testing and iteration (low maturity) to proactive testing and monitoring of key leading indicators based on randomized tests, leading to rapid iteration including \u201cfailing fast\u201d when necessary (high maturity) \u2022 From a focus on enrollment as the primary success metric (low maturity) to expected customer lifetime value based on the projected net benefits by customer group (high maturity) \u2022 From new pilots and initiatives that do not scale efficiently (low maturity) to a focus on driving value at scale, with close integration of DF program planning, operations, and external parties, including system operators and third parties as needed to scale efficiently (high maturity)     Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25021 1. Introduction Despite the widespread adoption of advanced meters and increased need for demand flexibility3 (DF) due to load growth and increasing renewable energy supply on the grid, utilities have generally not moved beyond traditional direct load control (DLC) programs to realize the promise of DF. Based on an in-depth review of 148 programs throughout the United States, Murphy et al. (2024) finds that most DF efforts focus on reducing demand during summer peaks driven by space conditioning consumption. This finding is remarkably similar to a 2006 Federal Energy Regulatory Commission (FERC) survey, which concluded that the most common demand response4 (DR) programs nearly 20 years ago were traditional peak shedding programs, most notably air-conditioning DLC aimed at peak load shedding.  The 2006 FERC survey also found that interest in DR programs was growing, and results from recent programs and pilots were encouraging, based on responses from 3,365 organizations in all 50 states representing every aspect of the electric delivery industry. However, this increased interest has not resulted in a significant change in the types of DF programs being implemented, despite growth of advanced meters that enable a wider range of grid services.   Source: FERC (2024) Figure 1-1. Advanced Meter Growth in the United States (2007\u20132022)   3 Demand flexibility includes any type of flexible behind-the-meter Distributed Energy Resource (DER), including solar, storage, electric vehicles, and traditional demand response (DR). It is defined as \"the capability provided by on-site DERs to reduce, shed, shift, modulate, or generate electricity\" (DOE 2021). 4 DR and DF are used interchangeably in this report for the purposes of assessing progress, though DF is generally more associated with the broader range of grid services that DERs can provide.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25022 Since 2007, the number of advanced meters has increased by over 112 million, from 4.7% penetration in 2007 to 72.3% in 2022 (Figure 1-1). Prior to this growth, FERC estimated that the total potential resource contribution from all existing DR programs and rates nationwide in 2006 was 37.5 GW (FERC 2006). Recent data from the U.S. Energy Information Administration5 (EIA) shows that retail DR program capacity is lower, at about 30.5 GW, as measured by the potential peak demand savings (Figure 1-2) (EIA 2023). Furthermore, the EIA data shows that potential peak demand savings have not increased from 31.2 GW in 2014, after increasing to nearly 36 GW in 2016 and then declining. Regionally, FERC (2024) reports an annual increase in retail DR program potential peak demand savings in seven of the nine census divisions in 2022 (Figure 1-3), but consistent multi-year growth is not evident in any region.   Source: EIA (2023) Figure 1-2. Retail DR Program Potential Peak Demand Savings in the United States (2014\u20132023)   Source: FERC (2024), based on Form EIA-861 data   5 EIA started collecting retail DR program data from utilities via Form EIA-861 in 2013. The potential peak demand savings estimates do not include dynamic pricing programs, also known as time-based rates.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25023 Figure 1-3. Retail DR Program Potential Peak Demand Savings by Census Division (2018 \u2013 2022)  While changes in metrics, measurement methods, market participation rules, and other factors have introduced uncertainty into assessing multi-year DF trends throughout the country, it is clear that DF programs have not grown or changed substantially, even though DF potential has increased as utilities have rapidly deployed advanced meters and consumers have adopted a wide range of connected devices. As emphasized in Murphy et al. (2024), DF programs will need to evolve and grow to achieve a vision of DF that involves the provision of a wider variety of grid services, including using on-site DERs to reduce, shed, shift, modulate, or generate electricity.   Part of the slower-than-expected DF evolution may have been due to low load growth in the past 20 years. With surging electricity load growth from data centers, manufacturing facilities, buildings and transportation, DF is now urgently needed to mitigate capacity constraints and power interruptions. Given the slow progress with DF programs recently, utilities and regulators are seeking novel approaches for driving DF progress, which may include applying the Berkely Lab DF maturity model in their jurisdiction. Vast DF potential remains for existing behind-the-meter technology to alleviate grid constraints at a low cost. Industry best practices and impediments to DF progress are well-documented, including barriers to broader adoption of:  \u2022 DR (Delurey 2013); \u2022 Integrated Demand Side Management (Potter et al. 2018); \u2022 Grid-Interactive Efficient Buildings (DOE 2021); \u2022 Virtual Power Plants (DOE 2023); and \u2022 Third-party DF participation (see text box).  Berkeley Lab has integrated this knowledge base into the DF maturity model, summarized in Section 2 and provided in its entirety in the Appendix. Similar to the California Wildfire Mitigation Maturity Model (Office of Energy Infrastructure Safety 2020), each DF capability is scored at one of five possible levels of maturity. By measuring maturity levels across 34 DF capabilities, states and utilities can prioritize investment, identify gaps, and drive continuous improvement to realize the promise of DF and move beyond DLC. In combination with other metrics, states can also use the maturity levels as indicators of DF progress as part of utility financial incentives.  The remainder of this report includes a DF maturity model overview, references to further resources, and an Appendix with the full maturity model that can be adapted as needed.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25024   2. Demand Flexibility Maturity Model Overview The Berkeley Lab DF maturity model scores utility programs on 34 DF capabilities, organized into six categories in Figure 2-1. Similar to the California Wildfire Mitigation Maturity Model, each DF capability is scored at one of five possible levels of maturity:  1. Below expectations 2. Meets minimum expectations 3. Beyond minimum expectations, but not consistent with best practice 4. Consistent with best practice 5. Improvement over best practice  For each capability, states and utilities can measure maturity levels to prioritize investment, identify gaps, and drive continuous improvement. In combination with other metrics, states can also use the maturity levels as indicators of DF progress as part of broader utility financial incentives. Third-party DF Participation in the DR Auction Mechanism in California  Given the increased interest in third-party DF, the maturity model draws from well-documented recent learnings and challenges with third-party participation, most notably as part of the DR Auction Mechanism (DRAM) in California. DRAM started out in 2015 with the promise that, \"For the first time, aggregations of customer-sited resources of at least 100 kW will have access to the state\u2019s electricity markets\" (Walton 2015). It was an opportunity for third-party DR providers to participate in the wholesale market. However, after several years and over $100M allocated to the statewide DRAM procurement budget, the CPUC decided to close the program (CPUC 2024), citing an evaluation report which could not affirmatively find that DRAM met all six success criteria, particularly in the areas of performance and reliability (Schellenberg et al. 2022). The key issues identified by the evaluation were:  \u2022 Widely varying performance, and consistent underperformance in some cases, have significantly lowered the overall effectiveness of DRAM \u2022 Lack of availability during critical hours, such as the August 2020 heatwave \u2022 Given the above two issues, the additional system capacity (if any) that each third-party DR provider has delivered is highly uncertain and varies substantially \u2022 Data errors and reporting inconsistencies, leading to over-compensation and a lack of confidence and transparency regarding overall DRAM performance \u2022 Significant administrative burden for all parties involved  The DF maturity model builds from the learnings of DRAM by emphasizing that states and utilities closely monitor performance and availability during critical hours, ensuring that avoided costs are tied to demonstrably offsetting grid investments. The maturity model also includes standalone categories for DER orchestration and data infrastructure to highlight the importance of data accuracy and reducing administrative burden for all parties involved at high levels of maturity.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25025   Figure 2-1. Berkeley Lab Demand Flexibility Maturity Model  Importantly, the DF maturity model is not necessarily a progression with a higher level clearly being more appropriate than a lower level for every jurisdiction. States and utilities can skip levels or stay at current maturity if that is what is cost-effective based on grid needs, market conditions, and the relative cost of meeting or exceeding best practices. It also may be cost-effective to have a mix of maturity levels within a DF portfolio. For example, a legacy air-conditioning DLC program may have a lower level of maturity on average, but the program can provide significant load shedding that is valuable under system peaking conditions. The same utility may also seek a high level of maturity for programs that deliver a wider range of grid services, including using on-site DERs to reduce, shift, modulate, or generate electricity.  2.1 DF Maturity Model Categories and Capabilities Each of the six maturity model categories has 5 to 7 capabilities (Figure 2-2). Maturity levels are generalized, with limited use of terms specific to certain jurisdictions or technologies, so that the maturity model can apply to varying regulatory environments, market structures and types of grid services available. Nonetheless, states and utilities can adapt the maturity model as needed. In a few cases, there is some overlap between capabilities to ensure that maturity is tracked from more than one perspective when capabilities are interconnected (such as the role of third parties from the perspectives of Planning & Design, Customer Engagement and DER Orchestration). Finally, while the maturity model details the requirements for meeting a given level of maturity level for each capability, comprehensive implementation details are beyond the scope of this report.  The remainder of this section summarizes each category and how each jurisdiction can adapt the model to their region.      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25026  Figure 2-2. Berkeley Lab Demand Flexibility Maturity Model Categories and Capabilities  2.1.1 Planning & Design The Planning & Design category details capabilities related to creating DF programs that are operationally effective, economically justified, and adaptable over time, including involvement of third-party DER aggregators and device makers.6 By maturing in these capabilities, utilities can ensure that DF programs are well-positioned to support grid needs, strategic goals, and regulatory requirements with cost-effective DF resources that demonstrably offset other types of grid investments.  States and utilities can adapt the Planning & Design category based on projected grid needs, the expected role of third parties, and state objectives, priorities and valuation frameworks. Given that other categories require existing programs to assess maturity, this category can be adapted and applied on its own for new initiatives, including pilots and new programs.    6 \u201cDevice makers\u201d is a general term that may include everything from a smart thermostat to an electric vehicle. 1. Planning & Design1.1. Dispatch Strategy1.2. Valuation1.3. Incentive Design1.4. Budget Allocation1.5. Third-party Enablement1.6. Long-term Forecasting1.7. Scaling Initiatives2. Customer Engagement2.1. Messaging2.2. Targeting2.3. Recruitment2.4. Enrollment2.5. Event Communications2.6. Third-party Involvement3. Program Operations3.1. Short-term Forecasting3.2. Event Trigger3.3. Resource Aggregation 3.4. Monitoring and Control3.5. Reporting3.6. Settlement4. Evaluation, Measurement & Verification (EM&V)4.1. Counterfactual4.2. Impact Estimation4.3. Effective Capacity4.4. Customer Lifetime Value4.5. Continuous Improvement5. Distributed Energy Resource (DER) Orchestration5.1. Technology Roadmap5.2. Agile Development5.3. System Operator Integration5.4. Standards and Interoperability5.5. Third-party Integration6. Data Infrastructure6.1. Resource Registry6.2. Processing Time6.3. Security and Tracking6.4. Quality and Granularity6.5. Data Sharing   Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25027 2.1.2 Customer Engagement The Customer Engagement category encompasses the strategies, tools, and processes that enable utilities to attract, onboard, and retain DF program participants in DF programs. It focuses on creating an effective customer experience that drives participation and performance, while also leveraging third parties to expand reach and enhance engagement. Importantly, this category focuses on direct customer engagement and does not cover broader marketing via social media, paid advertising, community events, and trade shows.  By maturing in these capabilities, utilities can ensure that DF programs deliver compelling value propositions, maximize participation from high-value customer segments, and foster sustained engagement. Importantly, the highest level of maturity commonly features the use of \u201crandomized groups,\u201d which draws from best practices for causal inference in other fields.7 Using randomized treatment and control groups has also been applied in the utilities industry to behavioral energy conservation programs and time-varying pricing (Wolfram 2018).  States and utilities can adapt the Customer Engagement category based on program objectives, customer demographics, and the anticipated role of third parties. Its applicability spans from pilots to full-scale programs, enabling tailored strategies for outreach, recruitment, and event communications that align with specific regulatory and market contexts.  2.1.3 Program Operations The Program Operations category focuses on the capabilities necessary to effectively manage the ongoing operations of DF programs, most notably running DF events from initial short-term forecasting to dispatch and settlement. The category emphasizes operational efficiency, reliability, and performance optimization.  By maturing in these capabilities, utilities can streamline the operational aspects of DF programs, enhance coordination with grid operators, and ensure that DF resources deliver reliable and measurable benefits. Effective program operations are critical for building confidence among participants, stakeholders, and regulators, while also enabling continuous improvement through performance monitoring and reporting.  States and utilities can adapt the Program Operations category based on grid needs, resource availability, and operational frameworks. This category is particularly valuable for mature programs with established participants, but its principles can also guide pilot operations to test and refine processes before scaling.    7 Marketing and technology developers commonly use the term \u201cA/B testing,\u201d whereas researchers typically refer to \u201crandomized controlled trials,\u201d including for pharmaceutical drug trials.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25028 2.1.4 Evaluation, Measurement & Verification (EM&V) The EM&V category focuses on the methodologies and processes used to assess the effectiveness of DF programs. This category assesses how to validate performance, optimize program design, and demonstrate the value of DF investments. By maturing in these capabilities, utilities can enhance program accountability, refine planning, and maximize customer and grid benefits. EM&V also supports regulatory compliance by ensuring transparency in program results and fostering trust among stakeholders.    States and utilities can adapt the EM&V category based on regulatory requirements, data availability, and the maturity of other interconnected capabilities, most notably within the Data Infrastructure category. EM&V capabilities apply across pilot evaluations to ongoing assessments of established DF programs, enabling continuous improvement and alignment with evolving grid and customer needs.  2.1.5 Distributed Energy Resource (DER) Orchestration The DER Orchestration category focuses on the software integration related to operating DF resources, including on-site DERs. This includes developing the technological frameworks necessary to enable coordination among utilities, system operators, and DER aggregators. By emphasizing interoperability and scalability, this category ensures that DF resources can be effectively monitored, dispatched and controlled to meet grid needs.  By maturing in these capabilities, utilities can integrate a robust DER orchestration platform8 that supports real-time operations, enhances grid reliability, and maximizes the value of DERs. Importantly, this category draws on common agile software development terminology, such as \u201csprints\u201d and \u201cminimum viable product.\u201d There are many online glossaries and overviews that explain these concepts (for example, see Kaley and Krause 2023). Regardless of the specific terms used, the key for higher levels of maturity is to ensure that utilities integrate the software required to scale DF resources efficiently while maintaining adaptability to new technologies and evolving requirements.  States and utilities can adapt the DER Orchestration category based on the regulatory environment, status of existing technologies, scale required to meet grid needs, and the expected number and type of DF programs, third parties, and devices. This category is particularly useful for jurisdictions that expect to scale multiple DF programs and technologies.  2.1.6 Data Infrastructure The Data Infrastructure category focuses on the systems and processes needed to collect, manage, and share high-quality, secure, and detailed data about DF resources and performance. It ensures that utilities and third parties can efficiently exchange validated information, enabling effective program management and decision-making. By maturing in these capabilities, utilities can build reliable, secure,   8 \u201cDER orchestration platform\u201d is a general term that may include DER Management Systems, or DERMS, which are typically developed by technology providers and integrated into utility operations in an agile manner    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u25029 and scalable data systems that support accurate dispatch, robust analysis, and third-party integration, forming the backbone of successful DF programs.  States and utilities can adapt the Data Infrastructure category based on the regulatory environment, status of existing technologies, scale required to meet grid needs, and the expected number and type of DF programs, third parties, and devices. While this category is particularly useful for jurisdictions that expect to scale multiple DF programs and technologies, mature Data Infrastructure capabilities are important to ensure transparency and accountability for any DF program.  2.2 Example Applications This section includes two example maturity model applications, though there are many more potential applications. In particular, any utility, including municipal and cooperatives, can also use the DF maturity model to conduct a self-evaluation, which is how the Cybersecurity Capability Maturity Model (DOE 2022) and Smart Grid Capability Maturity Model (Carnegie Mellon 2018) are implemented.  2.2.1 Example Utility Incentive Application This example application shows how regulators can select capabilities to use as metrics for a utility Performance Incentive Mechanism (PIM).9 The DF maturity model starts with characterizing a utility\u2019s Dispatch Strategy capability within the Planning & Design category. It shows how a utility\u2019s maturity with respect to Dispatch Strategy evolves from a lack of alignment with system needs (inflexible resources that are rarely dispatched) to close alignment with the needs of the distribution and bulk power systems (highly flexible resources that are frequently dispatched, both locally for a subset of DF program participants and for all DF program participants).  The PIM associated with the DF portfolio could have metrics that initially focus on Planning capabilities and then evolve over time. As the utility achieves a higher level of maturity for Dispatch Strategy and other capabilities in the Planning category, the metric weighting could change to emphasize a different category (e.g., Program Operations or DER Orchestration), including third-party provider integration. The metric could also start to emphasize outcome-based performance tied to shedding, shifting and shaping load, such as the metrics that Xcel Energy reports in its Minnesota Compliance Filing (Xcel Energy 2024).   2.2.2 Example Benchmarking Application States and utilities can also use the maturity model to benchmark capabilities. Maturity model benchmarking results are not available for DF programs, so this example draws from the California   9 \u201cPIMs can be implemented using a tiered approach that rewards the utility for measurable progress toward specified targets or penalizes the utility for failing to meet targets within an allotted timeframe. \u2018Upside-only\u2019 PIMs provide only financial benefits for achievement of specified targets, while \u2018downside-only\u2019 PIMs apply utility penalties when targets are not achieved. PIMs do not necessarily include both reward and penalty components, but each can be useful in driving a utility\u2019s investments and business decisions to achieve the intended outcomes\u201d (NARUC 2023).    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250210 Wildfire Mitigation Maturity Model. Figure 2-3 benchmarks three California utilities on the current and projected maturity within the vegetation management and inspections category. By assessing the underlying capabilities within vegetation management and inspections, each utility is able to identify how to improve and can prioritize programmatic changes accordingly.  Using the DF maturity model, utilities can also benchmark capabilities and identify specific improvements. For example, three utilities may find that they have widely varying average maturity levels within the Program Operations category. Digging deeper, the utility with relatively low maturity may find that its low score for the Monitoring and Control capability is driving down its overall Program Operations score relative to the other utilities. Reviewing the capability maturity levels, the utility is able to identify how to improve the ability of program operators to review, verify, and optimize DF performance.   Source: Office of Energy Infrastructure Safety (2023) Figure 2-3. Comparison across Utilities for Vegetation Management and Inspections Category  3. References Carnegie Mellon (2018). Smart Grid Capability Maturity Model Compass Assessment Survey, Version 2.0. https://insights.sei.cmu.edu/library/sgmm-compass-assessment-survey-version-20 CPUC (2024). Decision Sunsetting The Investor-Owned Utilities\u2019 Demand Response Auction Mechanism Pilot Programs. https://docs.cpuc.ca.gov/PublishedDocs/Published/G000/M530/K195/530195415.PDF Delurey, Dan (2013). Demand Response: The Road Ahead. http://www.wedgemere.com/wp-content/uploads/2013/03/Evolution-of-DR-Dialogue-Project-Report.pdf DOE (2021). A National Roadmap for Grid-Interactive Efficient Buildings. https://gebroadmap.lbl.gov    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250211 DOE (2022). Cybersecurity Capability Maturity Model (C2M2). https://www.energy.gov/sites/default/files/2022-06/C2M2%20Version%202.1%20June%202022.pdf DOE (2023). Pathways to Commercial Liftoff: Virtual Power Plants. https://liftoff.energy.gov/wp-content/uploads/2023/10/LIFTOFF_DOE_VVP_10062023_v4.pdf EIA (2023). Demand response - yearly energy and demand savings. https://www.eia.gov/electricity/annual/xls/epa_10_03.xlsx FERC (2006). Assessment of Demand Response and Advanced Metering Staff Report. https://www.ferc.gov/sites/default/files/2020-04/demand-response_4.pdf FERC (2024). 2024 Assessment of Demand Response and Advanced Metering. https://www.ferc.gov/news-events/news/ferc-staff-issues-2024-assessment-demand-response-and-advanced-metering Kaley, Anna and Rachel Krause (2023). Lean UX & Agile Glossary. https://www.nngroup.com/articles/agile-glossary Murphy, Sean, Cesca Miller, Jeff Deason, Diana Dombrowski, and Portia Awuah (2024). The State of Demand Flexibility Programs and Rates. https://emp.lbl.gov/publications/state-demand-flexibility-programs-and NARUC (2023). Demand Flexibility within a Performance-Based Regulatory Framework. https://pubs.naruc.org/pub/2A466862-1866-DAAC-99FB-E054E1C9AB13 Office of Energy Infrastructure Safety (2020). Utility Wildfire Mitigation Maturity Model. https://energysafety.ca.gov/wp-content/uploads/docs/wmp-2020/news/2.-utility-wildfire-mitigation-maturity-model-copy-correction_clean_final.pdf Office of Energy Infrastructure Safety (2023). Decision on PG&E's 2023-2025 Wildfire Mitigation Plan. https://efiling.energysafety.ca.gov/eFiling/Getfile.aspx?fileid=56134&shareable=true Potter, Jennifer, Elizabeth Stuart, and Peter Cappers (2018). Barriers and Opportunities to Broader Adoption of Integrated Demand Side Management at Electric Utilities: A Scoping Study. https://emp.lbl.gov/publications/barriers-and-opportunities-broader Schellenberg, Josh, George Jiang, Candice Potter, Aimee Savage, Jeremy Smith, Andrew Hauser, Dan Lesperance, Anna-Elise Smith, and Kallie Wells (2022). Demand Response Auction Mechanism Evaluation. https://docs.cpuc.ca.gov/PublishedDocs/Efile/G000/M502/K977/502977264.PDF Walton, Robert (2015). California\u2019s new demand response future begins. https://www.utilitydive.com/news/californias-new-demand-response-future-begins/407966 Wolfram, Catherine (2018). Smart Meters but Dumb Pricing? Not in Sacramento. https://energyathaas.wordpress.com/2013/11/18/smart-meters-but-dumb-pricing-not-in-sacramento Xcel Energy (2024). Compliance Filing. Demand Response Compliance Docket Nos. E002/M-20-421, E002/Rp-19-368, E002/M-21-101 & E002/CI-17-401     Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250212 Appendix: Demand Flexibility Maturity Model    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250213 1. Category: Planning & Design 1.1. Capability: Dispatch Strategy \u2013 Planned dispatch and criteria for when and how DF resources can be utilized  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice System needs assessment Rudimentary understanding of current bulk power system needs High-level understanding of current distribution and/or bulk power system needs 8,760-hour analysis of current distribution and/or bulk power system needs 8,760-hour analysis of future distribution and bulk power system needs Thorough, sub-hourly analysis of future distribution and bulk power system needs Notification lead time Only with advanced notice (24+ hours) during limited time periods, such as summer weekday afternoons Day-of notice during limited time periods, such as summer weekday afternoons Day-of notice during more than one time period throughout the day, week and year, depending on system need Short notice (15 minutes or less) throughout the day, week and year Same as level 4 Resource availability Only during grid emergency conditions (typically less than two times per year) Primarily during grid emergency conditions (typically less than five times per year) During grid emergency conditions, and occasionally based on economic factors (typically five or more times per year) Dispatched regularly based on grid reliability, economic factors and/or decarbonization factors (typically 10 or more times per year) Same as level 4 Test events   Rare test events to evaluate how DF resources respond under limited weather and system conditions Test events to evaluate how DF resources respond under a variety of weather and system conditions Same as level 4, with randomized groups for test events Local dispatch    DF resources can be dispatched locally to alleviate distribution constraints or for all DF program participants to reduce system load Same as level 4       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250214 1. Category: Planning & Design 1.2. Capability: Valuation \u2013 Process of determining the value of a DF resource from a policy perspective, based on estimated costs and benefits  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Cost estimation Portfolio level total Portfolio level with primary categories (e.g., administration and incentives) Portfolio and program level with primary categories Program level with more granular categories (including fixed costs) Same as level 4 Benefits estimation Portfolio level, without using established valuation frameworks Portfolio level using valuation frameworks that were designed for non-flexible resources (such as EE or emergency DR) Program level based on current avoided bulk power system capacity costs (avoided distribution costs may also be included, but valuation does not align how the program is actually dispatched) Same as level 3, with avoided capacity costs for the distribution system, accounting for location, dispatch strategy and future grid needs Same as level 4, with accounting for effective capacity based on the forecasted magnitude and variation of load impacts Benefit-cost Ratio (BCR) estimate  Portfolio level with limited understanding of key assumptions and value drivers within the portfolio Program level with general understanding of key assumptions, future grid needs, and value drivers within each program Program level by customer class, including benefits for participating customers, with sensitivity analysis to understand key assumptions, future grid needs and value drivers within each program Same as level 4, including benefits for resiliency and decarbonization, with sensitivity analysis to identify key leading indicators that iteratively update the BCR, leading to strategic \u201cpivots\u201d as needed Validation of avoided costs     Avoided costs are only used in valuation when DF resource demonstrably offsets grid investments (e.g. in an IRP), using metrics such as levelized cost of energy to directly compare to utility-scale resources       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250215 1. Category: Planning & Design 1.3. Capability: Incentive Design \u2013 Level and structure of financial compensation offered to DF participants  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Basis for incentive levels No clear rationale, benchmarking or alignment with valuation Benchmarking (with publicly available data sources and/or reports) Benchmarking (with publicly available data sources and/or reports) and general alignment with program-level BCR estimate Same as level 3, including sensitivity analysis and alignment with program-level BCR estimate by customer class Randomized test groups to optimize program-level BCR estimate by tailoring incentives for specific customer groups that drive value for the program Incentive structure Upfront incentives that do not vary based on performance or customer type Upfront incentives that vary across residential and non-residential segments, but do not consider customer performance (such as the magnitude and reliability of load impacts) Upfront and retention incentives that vary across residential and non-residential segments, but do not consider customer performance (such as the magnitude and reliability of load impacts) Upfront and retention incentives that vary by customer size, location and across residential and non-residential segments, with the ability to remove customers from the program if they do not actively participate Upfront, retention and/or performance incentives that vary by expected customer lifetime value, with the ability to remove customers from the program if they do not actively participate and enforce penalties if performance is unreliable Accounting for other programs  Incentive eligibility accounts for participation in other DF programs or grid services to avoid double counting of the same resource Same as level 2 Same as level 2 Incentives vary based on participation in other DF programs or grid services to maximize value of existing resources without over-compensating       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250216 1. Category: Planning & Design 1.4. Capability: Budget Allocation \u2013 Process of determining and adjusting the DF program budget  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Basis for budget Limited rationale, alignment with valuation or benchmarking (e.g., relative to prior years, other utilities and types of resources such as EE) Simple benchmarks, such as budget from prior year, regardless of DF value as compared to other types of resources Same as level 2, with high-level consideration of DF value as compared to other types of resources Determined based on cost-effectively meeting strategic goals and regulatory requirements, with consideration of DF value as compared to other types of resources, accounting for how each DF program is dispatched and future grid needs DF budget determined based on maximizing value (net benefits) relative to the alternatives available to address future grid needs, accounting for how each DF program is dispatched and performance incentives Analysis of existing DF programs to inform budget  Limited High-level (e.g., scaling of prior year cost based on projected enrollment) In-depth, including how costs may change as the DF program evolves to meet strategic goals and regulatory requirements In-depth, including how costs may change as the DF program evolves to maximize value (including portfolio-level investments necessary to meet goals and requirements) Budget flexibility   Limited flexibility to reallocate program budget based on performance and changing conditions (including costs and grid needs) Annual reviews and reallocation based on performance and changing conditions (including costs and grid needs) Same as level 4, with quarterly reviews       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250217 1. Category: Planning & Design 1.5. Capability: Third-party Enablement \u2013 Mechanisms and processes for enabling third parties to participate in the DF program delivery  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Third-party ability to participate Utility-managed programs with legacy DF technologies (e.g., one-way communicating DLC devices)  Same as level 1 Same as level 1, with integration of established third-party device makers or DER aggregators Multiple established and emerging third-party device makers or DER aggregators that enable a Level 4-5 Dispatch Strategy (see Section 1.1) Same as level 4 Third-party opportunity  Infrequent, multi-year competitive RFP procurements for new third-party providers Multi-year competitive RFP procurements and partnerships established third-party device makers or DER aggregators Expanded opportunities for new third-party providers through performance-based contracts and partnerships with multiple established and emerging third-party device makers or DER aggregators that enable a Level 4-5 Dispatch Strategy (see Section 1.1) Open opportunities for new third-party providers through flexible, performance-based contracts with any third-party device maker or DER aggregator that enables a Level 5 Dispatch Strategy (see Section 1.1) Contracting process  Significant administrative burden for onboarding new third-party providers, enforcing penalties or terminating the agreement, regardless of performance Same as level 2 Moderate administrative burden for onboarding new third-party providers, enforcing penalties and terminating the agreement for consistent underperformance Minimal administrative burden for onboarding new third-party providers, enforcing penalties and terminating the agreement for unreliable performance       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250218 1. Category: Planning & Design 1.6. Capability: Long-term Forecasting \u2013 Multi-year projections of DF load impacts, based on enrollment and expected performance, for use in resource planning  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Basis for forecast No clear rationale, benchmarking or empirical analysis Enrollment and event load impact forecasts determined using benchmarking (with publicly available data sources and/or reports) Same as level 2, with high-level estimates from evaluation report for existing programs Enrollment and hourly load impact forecasts determined using location and customer segment-specific estimates from evaluation report for existing programs, with sensitivity analysis to identify key assumptions Same as level 4, with randomized groups to inform forecast (especially for new programs)and assessment of forecast error to evaluate uncertainty Market potential assessment   Drives forecast assumptions and goals based on end-use adoption projections, with minimal adjustments based on evaluation report findings Informs forecast assumptions and goals based on end-use adoption projections by customer segment, with calibration to evaluation report findings, future grid needs and expected program changes (including dispatch strategies and grid services provided) Forecast is primarily based on the specific customer groups that are expected to drive value for the program, based on rigorous data analysis, future grid needs and expected program changes (including dispatch strategies and grid services provided) Alignment with other programs and plans   Limited consideration of other programs and plans (includes integrated resources plans, grid modernization plans, transmission and distribution plans, electrification plans, energy efficiency program plans, etc.) Moderate consideration of other programs and plans Close alignment with other programs and plans      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250219 1. Category: Planning & Design 1.7. Capability: Scaling Initiatives \u2013 Planning and analysis related to scaling pilots, new program features, and new programs  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Questions/ assumptions prior to launching initiative No key questions or assumptions identified Focus primarily on how a specific DF technology works with a small, unique set of customers Focus primarily on how a specific DF technology works under current grid needs and rules Focus on how a DF program cost-effectively scales under future grid needs Focus on how a DF program cost-effectively scales under future grid needs, rules (e.g., FERC Order 2222), and customer expectations (e.g., a frictionless experience) Scaling plan No scaling plan Limited scaling plan that applies to a narrow group of customers Same as level 3 High-level plan for scaling the initiative to a broader group of customers, with constraints to scale as a secondary consideration for the initiative design Detailed plan for scaling the initiative to a broader group of customers, with constraints to scale as a primary consideration for the initiative design, including selection of DF technologies, vendor partners, and third-party providers Valuation analysis    Analyses of initiatives produce overall cost-effectiveness estimates, informing valuation, incentive design, and budget allocation for scaling plan Analyses of initiatives produce reliable estimates of expected customer lifetime value relative to acquisition cost by customer group, informing valuation, incentive design, and budget allocation for scaling plan Adaptive strategy    Clear articulation of goals that indicate when to move from initiative to full scale deployment Same as level 4, with initiatives that have strategic \u201cpivots\u201d and contingencies tied to key leading indicators       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250220 2. Category: Customer Engagement 2.1. Capability: Messaging \u2013 Communication and tools used to convey the value proposition of DF enrollment and performance  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Program marketing No focused and consistent messaging Focuses on how DF saves money Limited messages (e.g., DF saves money and supports grid reliability) Consistently highlights key messages (e.g., DF saves money, supports grid reliability and decarbonization, and may not cause substantial inconvenience or discomfort) Same as level 4, with randomized groups to identify which messages are most effective for each type of customer Participant messaging  Primarily emphasizes convenience and the ability to opt out of events Briefly indicates the importance of frequent, automated response (if applicable), with consistent performance (including low opt-outs) Same as level 3, with additional emphasis on the importance Same as level 4, with randomized groups to identify which messages are most effective for each type of participant Surveys  Verify that customers understand that DF saves money, most notably DF program participants Occasionally verify that customers understand limited messages, most notably DF program participants Same as level 3, with consistent frequency Integrated into ongoing customer communications to verify that customers understand key messages assigned to randomized groups, most notably DF program participants Customer support center    Basic understanding of DF talking points Understands and reinforces DF messaging       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250221 2. Category: Customer Engagement 2.2. Capability: Targeting \u2013 Process of identifying and focusing efforts on high value customers  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Basis of targeting No customer targeting Propensity to enroll in the DF program, regardless of customer-specific potential to deliver load impacts Propensity to enroll in the DF program, with rudimentary screening criteria based on overall usage and customers that are known to have eligible devices Propensity to enroll, customers that are known to have eligible devices and hourly interval data to estimate customer-specific expected DF value Same as level 4, with sub-hourly interval data to estimate customer-specific expected DF value, using randomized groups to inform propensity model for different program options Customer segments  Marketing personas based on predefined groups, regardless of outcomes related to DF program enrollment and usage Same as level 2, with minor adjustments based on DF program enrollment and usage Marketing personas based on DF program enrollment propensity, hourly usage profiles, and target segments (such as low income customers) Customers are individually ranked based on estimates of customer-specific expected DF value, aligning with grid needs Device adoption    Analyze hourly interval data and other customer characteristics to estimate device adoption likelihood (such as the percent chance of a customer having an EV or central AC) Same as level 4, with the support of third-party data (e.g., DMV or dealer lists for EVs)       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250222 2. Category: Customer Engagement 2.3. Capability: Recruitment \u2013 Process and options by which the DF program engages customers to participate  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Adaptive process Keep recruitment as originally planned, without identifying and implementing improvements Identify one major point of friction during recruitment (e.g., email click-through rates), then identify and implement improvements for the next program year Same as level 2, with two or more points of friction during recruitment Identify nearly all points of friction during recruitment, then identify and quickly implement improvements Same as level 4, with randomized groups to test and quickly implement improvements Enrollment options Passively support one option for each program Focus on supporting one primary option for each program Passively support other enrollment options for each program, informing device makers and other incentive programs that they may also deliver recruitment materials Streamline enrollment options for each DF program, collaborating with device makers and other incentive programs to deliver periodic co-branded recruitment materials, with default DF enrollment and a clear process to opt-out (if applicable) Same as level 4, with consistent, co-branded recruitment materials and integration of default DF with other programs Channels One method to recruit customers for each program, regardless of effectiveness Use email, phone calls and/or direct mail to recruit customers, without prioritizing the most cost-effective methods Prioritize email recruitment, but supplement with phone calls and/or direct mail, particularly for larger non-residential accounts Prioritize low-cost digital recruitment options, including email, text, referrals, and in-app (in partnership with device makers), but supplement recruitment with phone calls and/or direct mail, particularly for larger non-residential accounts and customers that have not engaged digitally Same as level 4, with randomized groups to test phone calls and/or direct mail recruitment for cost-effectiveness       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250223 2. Category: Customer Engagement 2.4. Capability: Enrollment \u2013 Process and options by which the DF program fully onboards participants  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Adaptive process Keep enrollment process as originally planned, without identifying and implementing improvements Identify one major point of friction during enrollment (e.g., account verification), then identify and implement improvements for the next program year Same as level 2, with two or more points of friction during enrollment Identify nearly all points of friction during enrollment , then identify and quickly implement improvements Same as level 4, with randomized groups to test and quickly implement improvements Energy audit No upfront audit of customer energy usage For large customers only, conduct upfront energy audit to identify DF opportunities (primarily depending on end-uses, regardless of usage) Same as level 2, with interval data analysis to identify DF opportunities (depending on end-uses, load patterns and aggressiveness of curtailment) Same as level 3, with streamlined audit and interval data analysis for medium and large customers Same as level 4, with automated audit and interval data analysis for all customers Technology installation support   High-cost support, verification, and testing available as an upfront incentive for large customers only Support, verification, and testing available as an upfront incentive for medium to large customers, and streamlined support for high usage residential customers Streamlined support, verification, and testing available as an upfront incentive when cost-effective based on customer-specific expected DF value Encouraging more effective DF options    If customers are recruited into a relatively passive DF option (by default if possible), identify and implement potentially effective ways to retain them and nudge them toward more automated and effective DF Same as level 4, with randomized groups to identify and implement most effective ways to retain customers and nudge them toward more automated and effective DF       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250224 2. Category: Customer Engagement 2.5. Capability: Event Communications \u2013 Pre- and post-event communications that inform DF participants of event timing and performance  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Scope and messaging No pre- or post-event communications Basic pre-event communications via email or phone call Same as level 2, with basic post-event communications via email or phone call Pre- and post-event communications via email, text and/or phone call that increase the reliability of performance Same as level 4, with randomized groups to identify most effective timing, frequency, and messaging Post-event reports  Performance reports available in web portal two or more days later, without a focus on benefits to the customer Performance reports available in web portal the next day, including money saved Performance reports available in web portal the next day, including all benefits, with follow-up actions that may resolve issues impacting performance and incentives Performance reports available in web portal within a few hours, including all benefits, pushed to customer via email and text when there are follow-up actions that may resolve issues impacting performance and incentives Encouraging active DF   Reactive communications after a customer has not actively participated across multiple events, passively encouraging improvement Ongoing proactive communications as a customer starts to show signs of not actively participating in events, indicating that they may be removed from the DF program Same as level 4, with normative comparisons, offers of alternative DF program options and notices that they may be removed from the DF program and have further penalties     Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250225 2. Category: Customer Engagement 2.6. Capability: Third-party Involvement \u2013 Mechanisms and tools for utilizing third parties to engage customers and manage DF resources  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Mechanism No third-party involvement in engaging customers Select third-party providers focus on enrolling customers or delivering technology and provide minimal incremental value Fixed incentives throughout service territory for multiple aggregators selected through a competitive RFP to recruit customers, onboard DF resources, and manage the interconnection process (if applicable) Varying incentives by location for any eligible aggregator to recruit customers, onboard DF resources, and manage the interconnection process (if applicable) Same as level 4, with a competitive marketplace (and bids to lower costs) Tools    Utilities make maps and other tools available upon request to communicate grid needs and high value locations for DF resources Same as level 4, with openly available maps and other tools        Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250226 3. Category: Program Operations 3.1. Capability: Short-term Forecasting \u2013 Day-of or day-ahead projections of load impacts, developed by DF program to integrate DF resources into grid operations  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Timing and granularity No short-term forecasting of load impacts Day-ahead forecasting of system-level average load impacts, based on previous year\u2019s evaluation or settlement results Same as level 2, with more recent evaluation or settlement results Day-ahead and day-of forecasting of hourly load impacts throughout the system, based on recent evaluation and settlement results, adjusted for baseline error Day-ahead and day-of forecasting of hourly load impacts throughout the system, down to the feeder level, based on recent evaluation results (using Level 4-5 EM&V methods in Section 4) and varying control strategies Adjusting for recent data and forecasts   Minor adjustments based on recent trends, such as enrollment Potentially significant adjustments based on weather forecasts and recent data related to load patterns and enrollment for each DF program participant Potentially significant adjustments based on weather forecasts and near real-time data related to device connectivity, opt outs, overrides, load patterns, and enrollment for each DF program participant      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250227 3. Category: Program Operations 3.2. Capability: Event Trigger \u2013 Criteria for dispatching and prioritizing DF resources  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Criteria for DF dispatch Bulk power system day-ahead emergency alerts with advanced notice (24+ hours), as long as resource is available at that time Same as level 1, with day-of emergency alerts (notice of over 15 minutes) Same as level 2, with day-ahead price thresholds Transmission/distribution constraints and bulk power system day-ahead price thresholds or day-of emergency alerts (with notice of 15 minutes or less when necessary) Same as level 4, with real-time price thresholds or emergency alerts Coordinating with grid operators    Limited coordination between distribution and bulk power system operators to ensure that resources are triggered in priority order Same as level 4, with close coordination Other grid services     DF is dispatched to provide other grid services (e.g., frequency response) or support grid decarbonization based on carbon intensity signals or renewable generation needs      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250228 3. Category: Program Operations 3.3. Capability: Resource Aggregation \u2013 Process of combining, prioritizing, and ordering DF resources for dispatch  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Objective Maximize the initial load reduction for the bulk power system Same as level 1 Maximize the initial load reduction, accounting for the timing of bulk power system needs and forecasted average load impacts Maximize value to the grid, accounting for the timing and location of grid needs, expected event duration, and forecasted hourly load impacts, including increases in load before and after the event Same as level 4, with accounting for customer fatigue and forecasted sub-hourly load impacts, including increases in load before and after the event  Scale    Sufficient scale to monitor and accurately measure load impacts for settlement and evaluation purposes Same as level 4, with randomized groups when a portion of the resource can be withheld Accounting for other programs     DF aggregations are prioritized for dispatch across markets (if applicable) and levels of the system, based on maximizing value to the grid, accounting for when there are multiple DERs in the same location      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250229 3. Category: Program Operations 3.4. Capability: Monitoring and Control \u2013 Ability of program operators to review, verify, and optimize DF performance   Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Program operator role Dispatch DF resources and review DF performance at end of season Same as level 1, with review of DF performance days later Same as level 2, with review of DF performance the next day Optimize dispatch based on grid needs and review DF performance shortly after events Same as level 4, with DF performance monitoring in near real-time Dispatch verification One-way dispatch signal without verification that device received signal Same as level 1, with ad hoc verification based on interval data two or more days later One-way or two-way dispatch signal with next-day verification based on interval data or device-level data Two-way dispatch signal with verification that has a delay of 5 minutes or longer Two-way dispatch signal with near real-time verification and connectivity checks leading up to and throughout DF events      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250230 3. Category: Program Operations 3.5. Capability: Reporting \u2013 Post-event reports for operators of grid, DF program and DERs to identify performance issues and provide initial load impact estimates  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Level of detail No event reporting Basic event reports that focus on average load impact during event period using a settlement baseline Same as level 2, with hourly load impacts In-depth event reports that detail performance issues and hourly load impacts during event period using a settlement baseline and evaluation counterfactual Same as level 4, with assessment of customer fatigue and sub-hourly load impacts Report availability  Two or more days later and not shared with other parties Next day and shared with other parties upon request Shortly after events and automatically shared with other parties, particularly grid operators and those who may help resolve performance issues Same as level 4, with notifications during events and follow-ups to resolve issues      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250231 3. Category: Program Operations 3.6. Capability: Settlement \u2013 Process of determining financial compensation for DF participants  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Baseline Same for all customers and has not been validated for accuracy, including reliance on simplifying assumptions (e.g., an EV would have been plugged in and charging throughout a DF event) Same for all customers and has been validated for accuracy when applied to large aggregations of DF resources Varies by customer type and has been validated for accuracy when applied to aggregations of DF resources by customer type Same as level 3, with quantification of over- and under-payment Same as level 4, with use of comparable groups of non-participating customers to further assess accuracy Processing time Over 96 hours after event, primarily due to accessing and validating data Up to 96 hours after event Up to 8 hours after event Up to 2 hours after event, with automated data validation Up to 30 minutes after event, with continuous data validation and quick access Basis for capacity payments (if applicable) Unvalidated load impact estimates Validated load impact estimates for a single event Validated load impact estimates across multiple events Validated load impact estimates that are consistent at the hourly level throughout events (e.g., capacity payments are not based on a single event hour estimate) Same as level 4, with consistency at the sub-hourly level      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250232 4. Category: EM&V 4.1. Capability: Counterfactual \u2013 Estimate of what load would have been in the absence of a DF event, which informs load impact estimates  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Establishing counter-factual No control or comparison group, leading to a reliance on simplifying assumptions (e.g., an EV would have been plugged in and charging throughout a DF event) Comparison group developed without statistical load matching Matched control group with moderate differences in peak load during non-event days with the highest system load Matched control group without statistically significant differences in peak load during non-event days with the highest system load Randomized control group without statistically significant differences in peak load during non-event days with the highest system load Role of settlement baseline Relied on for evaluation counterfactual Option for evaluation counterfactual due to inaccuracy of comparison group Not used for evaluation counterfactual due to relative accuracy of control group Same as level 3 Same as level 3       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250233 4. Category: EM&V 4.2. Capability: Impact Estimation \u2013 Process of evaluating and quantifying the DF program load reductions and shifting   Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Calculation Difference between event usage and assumed counterfactual or settlement baseline (if applicable) for all customers Difference between event usage and comparison group for all customers Estimated load impacts using matched control group and difference-in-differences Same as level 3, with a regression model that estimates confidence bands Same as level 4, with a randomized control group Granularity Single average event impact estimate based on limited events during rare grid emergency conditions Average impacts by event day during limited time periods, such as summer weekday afternoons Hourly impacts by event day for five or more events in a year across more than one time period in the day, week or year (including test events) Hourly impacts by event day for ten or more events in a year under a variety of weather and system conditions (including test events) Same as level 4, with sub-hourly impacts by event day Load shifting analysis   Hourly pre- and post-event load shifting estimates to evaluate the full DF impact Same as level 3, with analysis of the net benefits of pre- and post-event load shifting Same as level 4, with sub-hourly pre- and post-event load shifting estimates Customer segments    Load impact estimates by dispatch group to account for the varying number of customers that participate in each event (primarily due to local dispatches) Same as level 4, with load impact estimates by key customer characteristics to identify high/low value segments      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250234 4. Category: EM&V 4.3. Capability: Effective Capacity \u2013 Estimate of DF resource capacity adjusted for variation of average load impacts, contribution to grid reliability, and other factors  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Basis for DF capacity estimate Single average event impact from limited events during rare grid emergency conditions Average impact across event days during limited time periods, such as summer weekday afternoons Relationship between temperature and average impact per customer for each event day to estimate capacity under varying weather conditions and enrollment scenarios Same as level 3, with hourly impacts per customer for each dispatch group Relationship between temperature and sub-hourly impact per customer for each event day to estimate capacity under varying weather conditions, times of day, event durations, grid service type and enrollment scenarios for each dispatch group Approach to adjusting capacity   Based on system planning input and models, adjust capacity based on the magnitude and variation of average load impacts Same as level 3, with hourly load impacts and consistent use of adjusted capacity metrics such as Effective Load Carrying Capability (ELCC), which reflects contribution to meeting grid reliability needs Same as level 4, with accounting for variation of sub-hourly load impacts and availability based on how well DF resource has aligned with grid needs Accounting for other programs   Simplifying assumptions to adjust for overlapping capacity of other DF programs Identify dual-enrolled customers to adjust for overlapping capacity of other DF programs Same as level 4, with accounting for which program takes precedence for planners and system operators Increases in load     Consider capacity value of increases in load when needed, such as during renewable curtailments      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250235 4. Category: EM&V 4.4. Capability: Customer Lifetime Value \u2013 Metric that represents the estimated total net benefits expected from a customer throughout DF program enrollment  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Value estimation No estimation of DF benefits Evaluate DF program-level cost-effectiveness based on load impacts and minor updates to planning assumptions based on evaluation results Same as level 2, with further updates to planning assumptions based on evaluation results Evaluate Customer Lifetime Value (CLV) based on the present value of net benefits, using effective capacity to estimate avoided costs, and ongoing retention costs, adjusting for historical attrition Evaluate CLV based on the present value of net benefits by customer group, using effective capacity to estimate avoided costs, and ongoing retention costs (including excess payment due to baseline error), adjusting for attrition using a rigorous customer retention forecast Considering customer acquisition cost    Evaluate the average Customer Acquisition Cost (CAC) and calculate CLV-to-CAC ratio to assess the value of each participant as the DF program scales Same as level 4, with analysis by customer group to assess the value of each type of participant as the DF program scales Applying CLV    Evaluate the impact of CLV and CAC on overall DF program cost-effectiveness based on various enrollment scenarios Calculate the break-even point of the required number of each type of participant to cover ongoing costs that support program operations and portfolio-level investments, and compare to achievable number of potential participants      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250236 4. Category: EM&V 4.5. Capability: Continuous Improvement \u2013 Ongoing effort to identify changes that increase DF program value based on data, metrics and EM&V results  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Nature of process Unstructured and reactive, focused on mitigating damage as problems arise, without data-driven insights from prior program cycle or other utilities Primarily reactive, focused on mitigating damage as problems arise, with limited data-driven insights from prior program cycle or other utilities Reactive and proactive, focused on identifying opportunities with data-driven insights from prior program cycle or other utilities Primarily proactive, focused on identifying opportunities with data-driven insights from prior program cycle and other utilities Same as level 4, with focus on identifying opportunities to maximize value (net benefits) Monitoring changes made  Basic plan for monitoring high-level metrics, but no effort to identify further improvement opportunities Basic plan for monitoring key metrics and identifying further improvement opportunities Same as level 3, with a detailed plan Same as level 4, with randomized groups, monitoring granular metrics and identifying further improvement opportunities tied to results of testing Engaging other parties    Utility leadership, grid operators and stakeholders are moderately engaged in the continuous improvement process Same as level 4, with more engagement and clearly defined metrics that are broadly understood       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250237 5. Category: DER Orchestration 5.1. Capability: Technology Roadmap \u2013 Strategic plan that outlines the steps and technology features required to scale a platform that meets DER orchestration needs  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Nature of roadmap No roadmap for DER orchestration platform Reactive and focused on up to two DF programs Focused on current grid needs and up to four DF programs Prioritized features that align with near-to-long term planning and grid needs Prioritized features that align with near-to-long term grid needs and value, with more detail for near-term features Frequency of updates  Roadmap is static and rarely changes Roadmap changes annually as new requirements, DF resources, and devices are identified, with over one year lead times to deliver new features Roadmap changes semi-annually, integrating open standards such as OpenADR and IEEE 2030.5, with less than one year lead times to deliver new features Same as level 4, with quarterly changes and less than 6-month lead times to deliver new features Integrating other DF programs    Defined plan to iteratively integrate nearly all DF programs onto one DER orchestration platform to allow for multi-DER management and cross-DER optimization Same as level 4, with plan to integrate all DF programs       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250238 5. Category: DER Orchestration 5.2. Capability: Agile Development \u2013 Flexible and iterative approach for deploying a DER orchestration platform that adapts to evolving requirements while mitigating risks  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Planning approach No plan for a DER orchestration platform Long-term planning using a waterfall development process, with limited agreement on highest priority near-term needs Asynchronous sprint planning with a vaguely defined minimum viable product (MVP) and limited agreement on highest priority needs Joint sprint planning with a clearly defined MVP, using diagrams and mockups to capture and agree on highest priority needs Same as level 4 Iteration process  Infrequent demos of new features to utility users before release Two-week sprints with sporadic, asynchronous demos of new features (when available) so that utility users can reactively validate DER orchestration enhancements and their ability to meet DF goals and regulatory requirements Same as level 3, with live demos of new features (when available) to enable proactive validation  Same as level 4, with live demos of distinct features that can be delivered by the end of each sprint      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250239 5. Category: DER Orchestration 5.3. Capability: System Operator Integration \u2013 Ability of distribution and bulk power system operators10 to monitor and control DF resources via a DER orchestration platform  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Role of distribution system operator No interaction with a DER orchestration platform Provide input on when to dispatch all available DF resources in response to a grid emergency Provide input on how to optimize DF dispatch based on grid needs, and receive DF performance reports the next day Control DF resources via Advanced Distribution Management System (ADMS) integration, optimize dispatch based on grid needs, and receive DF performance reports shortly after events Same as level 4, with ability to monitor DF performance in near real-time Role of bulk power system operator, including ISOs and RTOs (if appliable) No interaction with a DER orchestration platform Provide input on when to dispatch all available DF resources in response to a grid emergency Provide input on how to optimize DF dispatch based on grid needs, and receive DF performance reports the next day Control DF resources via operational systems integration, optimize dispatch based on grid needs, and receive DF performance reports shortly after events Same as level 4, with ability to monitor DF performance in near real-time     10 The roles that operators of the distribution system and bulk power system (generation and transmission) vary by jurisdiction. In some cases, one DF program may be operated at both the distribution and bulk power levels, in which case close coordination between operators is required. This coordination and integration between distribution and bulk power system operators is outside the scope of the maturity model.    Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250240 5. Category: DER Orchestration 5.4. Capability: Standards and Interoperability \u2013 Scalable rules and guidelines for dispatching, managing, and exchanging data with DF resources, including devices and controls  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Approach Custom development for one DF program Use available open standards and interoperability for data, devices, and controls Same as level 2 Prioritize open standards and interoperability for data, devices, and controls to have one system that can cost-effectively scale by integrating with a wide range of DER aggregators and technologies Same as level 4, with co-development of open standards Proprietary standards and custom APIs  Multiple required to integrate more than two DF programs Multiple required to integrate all DF programs Used as a secondary option when necessary to integrate all DF programs Same as level 4 Testing new integrations  Reactive testing after the technology onboarding process (including alignment with any applicable open standards such as OpenADR and IEEE 2030.5) Same as level 2, with spot testing during the technology onboarding process Same as level 3, with thorough testing during the technology onboarding process Thorough, proactive testing and verification of consistent performance and alignment with any applicable open standards such as OpenADR and IEEE 2030.5, including improvements to standards that are co-developed      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250241 5. Category: DER Orchestration 5.5. Capability: Third-party Integration \u2013 Process of onboarding new device and aggregations and validating DF resources  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Onboarding new devices and aggregators No onboarding process Slow and manual process with significant administrative burden for all parties involved, especially when transferring DF resources between aggregators or programs Semi-automated process with moderate administrative burden for all parties involved Semi-automated, user-friendly process with limited administrative burden Automated, user-friendly process with minimal administrative burden Validating DF resources  Limited, reactive validation of third-party DF commitments that only identifies major issues after a prolonged period of underperformance Same as level 2, with validation shortly after significant underperformance issues arise Same as level 3, with proactive validation of third-party DF commitments using load data Same as level 4, with ongoing performance-based adjustments to third-party DF commitments as events are called, including test events      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250242 6. Category: Data Infrastructure 6.1. Capability: Resource Registry \u2013 Centralized database that tracks and manages information about attributes and dispatches of DF resources, including on-site DERs  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Availability of validated DF resource attributes Not validated or readily available DF resources are tied to a utility account and meter ID, but information could be outdated and requires at least 4 hours of manual effort to manage and report on each time Same as level 2, with up to 4 hours of manual effort to manage and report on each time DF resources are tied to a frequently validated utility account and meter ID that are readily available with limited manual effort, but other resource information could be outdated and requires up to 4 hours of manual effort to manage and report on each time Central registry of DF resources with validated information on location, technology, utility account, meter ID, eligibility checks, availability, and capacity, all of which are readily available with limited manual effort Availability of DF dispatch information   Limited information on resource availability, dispatches, and response available Resource availability, dispatches, and response are tracked at the utility account and meter ID level, including critical information for certain technology types (such as consumption, discharge, and state of charge for EVs and batteries) Same as level 4       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250243 6. Category: Data Infrastructure 6.2. Capability: Processing Time \u2013 Duration it takes for a system to process DF resource and dispatch data from its input stage to validated output  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice DF resource data No reliable data within 48 hours Disparate datasets that require up to 48 hours to access and validate for enrollment reporting and processing purposes Same as level 2, with up to four hours to access and validate Same as level 3, with up to one hour to access and validate Central registry that is continuously validated, updated, and readily available to access for enrollment reporting and processing purposes DF dispatch data No reliable data within 48 hours Requires up multiple days to access and validate for settlement purposes and event reporting that is available to participants, aggregators, system operators and other stakeholders Same as level 2, with up to one day to access and validate Same as level 3, with up to two hours to access and validate DF dispatch data is continuously validated, updated, and available within 30 minutes to access for settlement purposes and all event reporting System operator needs     Based on system operator requirements, select DF dispatch data is available in near real-time to closely monitor and control resources during events      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250244 6. Category: Data Infrastructure 6.3. Capability: Security and Tracking \u2013 Processes and practices for securely sharing and storing data and tracking how source data has been validated and managed  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Sharing and storage security Data is shared manually between parties, including via email and stored locally on employee computers Sensitive customer information is only shared and stored using secure, approved means, but aggregated reports may be shared via email and stored locally Same as level 2 All data are only shared and stored using secure, approved means, including aggregated reports Same as level 4 Tracking customer data No reliable customer data tracking All parties track sensitive customer information and can permanently delete the data upon request, but it requires a manual process that takes up to a week Same as level 2, with a manual process that takes up to a day Automated tracking to revoke access to customer data upon request within 1 hour, ensuring that all parties no longer have access to sensitive information Same as level 4, with ability to immediately revoke access Tracking original source data   Limited tracking and inconsistent documentation on how source data has been validated and managed in subsequent datasets Detailed tracking and consistent documentation on how source data has been validated and managed in subsequent datasets Same as level 4, with continuously updated documentation, including data that originate from third parties      Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250245 6. Category: Data Infrastructure 6.4. Capability: Quality and Granularity \u2013 Overall reliability and level of detail of the information captured within a dataset  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Data to inform load impact estimation No validated data Limited (e.g., device-level runtime data, kWh readings that are not revenue-quality or available in 1-hour intervals) Validated data based on revenue-quality kWh readings is available in intervals of up to 1 hour, with corroboration by device-level data when available Same as level 3, with intervals of up to 15 minutes Same as level 4, with intervals of up to 5 minutes Time and location of dispatch signals  Based on DF resource participation start and end dates Same as level 2, with limited raw data on dispatch signals available at the individual customer level Validated data on the time (to the minute) and location of every dispatch signal is available at the individual customer level for all DF resources, including those dispatched by third parties Same as level 4, with two-way verification of every dispatch signal Checks of data quality and availability  Ad hoc when major errors or gaps arise, with workarounds to temporarily resolve the issue Same as level 2, with initial checks before going live Weekly (or more frequent) monitoring of data quality and availability, with manual notifications to DF program managers, customers, and third parties (if applicable) when data errors or gaps arise Same as level 4, with continuous monitoring of data quality and availability and automatic notifications Third-party data providers, including device makers and aggregators   Limited reactive communication to clarify data units and interpretations, fix data structures that change and update systems accordingly Same as level 3, with more frequent communication to resolve data issues quickly Same as level 4, with proactive communication to identify when data structures may change and update systems accordingly       Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility \u250246 6. Category: Data Infrastructure 6.5. Capability: Data Sharing \u2013 Transfer and consistency of data exchange to and from third parties  Maturity Level Maturity Indicator 1 Below expectations  2 Meets minimum expectations 3 Beyond minimum expectations 4 Consistent with best practice 5 Improvement over best practice Data transfers Reliance on manual transfers for data sharing to and from third parties Certain data transfers to and from third parties are well documented, which includes identification of the source data and all subsequent data management steps Same as level 2, with most data transfers being well documented Same as level 3, with most data transfers being automated, streamlining routine data-related processes (e.g., accessing interval data after a third party receives customer consent, verifying a customer account and eligibility when a third party enrolls participants) Nearly all data transfers to and from third parties are automated and well documented Data and reporting between the utility and third parties Frequently inconsistent due to unclear processes, human error, and a lack of validated data that is accurately interpreted Inconsistent for data transfers that are not well documented Same as level 2 Same as level 3 Rarely inconsistent Burden for all parties involved with data sharing Overwhelming  Unsustainable Significant Manageable Limited   ",
      "id": 274719080,
      "identifiers": [
        {
          "identifier": "635937094",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:escholarship.org:ark:/13030/qt0r5672n3",
          "type": "OAI_ID"
        }
      ],
      "title": "Moving Beyond Direct Load Control: A Maturity Model for Realizing the Promise of Demand Flexibility",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:escholarship.org:ark:/13030/qt0r5672n3"
      ],
      "publishedDate": "2025-01-16T00:00:00",
      "publisher": "eScholarship, University of California",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://escholarship.org/content/qt0r5672n3/qt0r5672n3.pdf"
      ],
      "updatedDate": "2025-02-24T12:27:35",
      "yearPublished": 2025,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/635937094.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/635937094"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/635937094/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/635937094/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/274719080"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": "2007.07971",
      "authors": [
        {
          "name": "Anderson, Tor"
        },
        {
          "name": "Cortes, Jorge"
        },
        {
          "name": "Haghi, Hamed Valizadeh"
        },
        {
          "name": "Kleissl, Jan"
        },
        {
          "name": "Martinez, Sonia"
        },
        {
          "name": "Muralidharan, Manasa"
        },
        {
          "name": "Srivastava, Priyank"
        },
        {
          "name": "Washom, Byron"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/484116776"
      ],
      "createdDate": "2020-07-18T00:00:43",
      "dataProviders": [
        {
          "id": 144,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/144",
          "logo": "https://api.core.ac.uk/data-providers/144/logo"
        },
        {
          "id": 183,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/183",
          "logo": "https://api.core.ac.uk/data-providers/183/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "This paper presents one of the first real-life demonstrations of coordinated\nand distributed resource control for secondary frequency response in a power\ndistribution grid. We conduct a series of tests with up to 69 heterogeneous\nactive devices consisting of air handling units, unidirectional and\nbidirectional electric vehicle charging stations, a battery energy storage\nsystem, and 107 passive devices consisting of building loads and photovoltaic\ngenerators. Actuation commands for the test devices are obtained by solving an\neconomic dispatch problem at every regulation instant using distributed\nratio-consensus, primal-dual, and Newton-like algorithms. The distributed\ncontrol setup consists of a set of Raspberry Pi end-points exchanging messages\nvia an ethernet switch. The problem formulation minimizes the sum of device\ncosts while tracking the setpoints provided by the system operator. We\ndemonstrate accurate and fast real-time distributed computation of the\noptimization solution and effective tracking of the regulation signal by\nmeasuring physical device outputs over 40-minute time horizons. We also perform\nan economic benefit analysis which confirms eligibility to participate in an\nancillary services market and demonstrates up to $53K of potential annual\nrevenue for the selected population of devices",
      "doi": null,
      "downloadUrl": "http://arxiv.org/abs/2007.07971",
      "fieldOfStudy": null,
      "fullText": "1Frequency Regulation with Heterogeneous Energy\nResources: A Realization using Distributed Control\nTor Anderson\u2217 Manasa Muralidharan\u2217 Priyank Srivastava\u2217 Hamed Valizadeh Haghi\nJorge Corte\u00b4s Jan Kleissl Sonia Mart\u0131\u00b4nez Byron Washom\nAbstract\u2014This paper presents one of the first real-life demon-\nstrations of coordinated and distributed resource control for\nsecondary frequency response in a power distribution grid. We\nconduct a series of tests with up to 69 heterogeneous active devices\nconsisting of air handling units, unidirectional and bidirectional\nelectric vehicle charging stations, a battery energy storage system,\nand 107 passive devices consisting of building loads and photo-\nvoltaic generators. Actuation commands for the test devices are\nobtained by solving an economic dispatch problem at every regu-\nlation instant using distributed ratio-consensus, primal-dual, and\nNewton-like algorithms. The distributed control setup consists of\na set of Raspberry Pi end-points exchanging messages via an\nethernet switch. The problem formulation minimizes the sum of\ndevice costs while tracking the setpoints provided by the system\noperator. We demonstrate accurate and fast real-time distributed\ncomputation of the optimization solution and effective tracking of\nthe regulation signal by measuring physical device outputs over\n40-minute time horizons. We also perform an economic benefit\nanalysis which confirms eligibility to participate in an ancillary\nservices market and demonstrates up to $49K of potential annual\nrevenue for the selected population of devices.\nI. INTRODUCTION\nMany recent efforts seek to integrate renewable energy\nresources with the power grid to reduce carbon footprint.\nThe high variability associated with renewables can be bal-\nanced with distributed energy resources (DERs) providing\nancillary services, such as frequency regulation. For market\noperators, this has resulted in a growing interest in DER\naggregations with flexible generation and load capabilities\nto balance fluctuations in grid frequency and minimize area\ncontrol errors (ACE). The fast ramping rate and minimal\nmarginal standby cost of most DERs puts them at an advantage\nagainst conventional generators and makes them suitable for\nparticipation in the frequency regulation market.\nThe fast ramping rates reduce the required power capacity\nof DERs to only 10% of an equivalent generator to balance\na frequency drop within thirty seconds. However, most indi-\nvidual DERs have small capacities (typically kW compared\nTor Anderson, Priyank Srivastava, Jorge Corte\u00b4s, and Sonia Mart\u0131\u00b4nez\nare with the Department of Mechanical and Aerospace Engineering, UC\nSan Diego, CA, USA. Email: {tka001, psrivast, cortes,\njkleissl, soniamd}@ucsd.edu.\nManasa Muralidharan, Jan Kleissl, and Hamed Valizadeh Haghi\nare with the Department of Mechanical and Aerospace Engineer-\ning and the Center for Energy Research, UC San Diego, CA,\nUSA. Email: m1murali@ucsd.edu, valizadeh@ieee.org,\njkleissl@ucsd.edu.\nByron Washom is with Strategic Energy Initiatives, UC San Diego, CA,\nUSA. Email: bwashom@ucsd.edu.\nThis research was supported by the Advanced Research Projects Agency\n- Energy (ARPA-e) under the NODES program, Cooperative Agreement de-\nar0000695.\n\u2217: These authors contributed to the paper equally.\nto 10s of MW for a conventional frequency control resource).\nCommanding the required thousands to millions of DERs to\nreplace existing frequency regulation resources over a large\nbalancing area entails aggregating DERs that are distributed\nat end points all over the grid on customer premises. The\ndynamic nature, large number, and distributed location of\nDERs thereby requires coordination. This is in contrast to\nexisting frequency regulation [1] implementation with con-\nventional energy resources. For example, CAISO requires all\ngenerators to submit their bids once per regulation interval\nand then the setpoints are assigned centrally to all resources\nevery 2-4 seconds without any consideration of operational\ncosts [2]. While distributed control offers a viable path to\nenable enable DER participation in the frequency regulation\nmarket, e.g., [3], there is a general lack of large-scale testing\nto prove its effectiveness for widespread adoption by system\noperators. The 2017 National Renewable Energy Workshop\non Autonomous Energy Grids [4] concluded that \u201cA major\nlimitation in developing (...) new technologies for autonomous\nenergy systems is that there are no large-scale test cases (...)\nThese test cases serve a critical role in the development,\nvalidation, and dissemination of new algorithms\u201d.\nThe results of this paper are the outcome of a project under\nthe ARPA-e Network Optimized Distributed Energy Systems\n(NODES) program1, which postulates DER aggregations as\nvirtual power plants and aims at bringing the renewable\npenetration to at least 50%. The vision of the NODES program\nwas to employ state-of-the-art tools from control systems,\ncomputer science, and distributed systems to optimally re-\nspond to dynamic changes in the grid by leveraging DERs\nwhile maintaining customer quality of service, and had a\nstrong testing requirement of employing at least 100 devices at\npower. Here, we demonstrate the challenges and opportunities\nof carrying out this testing on a heterogeneous fleet of DERs\nfor eventual operationalization of optimal distributed control\nat frequency regulation time scales.\nLiterature Review. To the best of our knowledge, real-world\ntesting of frequency regulation by DERs has been limited. A\nVehicle-to-Grid (V2G) electric car [5] and two Battery Energy\nStorage Systems (BESS) [6] provided frequency regulation.\n76 bitumen tanks were integrated with a simplified power\nsystem model to provide frequency regulation via a decen-\ntralized control algorithm in [7]. In buildings, a decentralized\ncontrol algorithm controlled lighting loads in a test room [8].\nCentralized frequency control was applied to the power of an\nair handling unit (AHU) in buildings [9], [10], an inverter and\n1https://arpa-e.energy.gov/arpa-e-programs/nodes\nar\nX\niv\n:2\n00\n7.\n07\n97\n1v\n1 \n [e\nes\ns.S\nY]\n  1\n5 J\nul \n20\n20\n2four household appliances [11] and four heaters in different\nrooms of a building [12]. A laboratory home consisting of\nan EV and an AHU, and a number of simulated homes were\nconsidered for demand response in [13] through an aggregator\nat a 10 second level by NREL.Technologies for widespread,\nbut centrally controlled, cycling of air conditioners directly\nby utilities cf. [14] and aggregators are common place for\npeak shifting, but occur over time scales of minutes to hours.\nIndustrial solutions enabling heterogeneous DERs to provide\nrequired power also exist, but they are either centralized,\ncf. [15] or require all-to-all communication [16].\nThis literature review exposes the following gaps: (i) cen-\ntralized control or need for all-to-all communication [5], [6],\n[9]\u2013[16], which does not scale to millions of devices; (ii) small\nnumbers of DERs [5], [6], [9]\u2013[13]; (iii) lack of diversity in\nDERs [5]\u2013[10], [12], with associated differences in tracking\ntime scales and accuracy. No trial has been reported that\ncredibly demonstrated generalizability to a real scenario with\n(i) scalable distributed control; and a (ii) large number of (iii)\nheterogeneous devices.\nStatement of Contributions. To advance the field of real-\nworld testing of DERs for frequency control, we conduct a\nseries of tests using a group of up to 69 active and 107 passive\nheterogeneous devices inside the University of California,\nSan Diego (UCSD) microgrid [17]. This is one of the first\nbodies of work to consider such a large, diverse portfolio\nof real physical devices for secondary frequency response.\nAs such, the first major contribution of this work is the\ndetailed account of the testbed, including the device actuation\nand sampling interfaces and the distributed optimization setup\nand communication framework. Further, throughout the paper,\nwe describe techniques that we employed to work around\ntechnical barriers and other lessons that were learned and\nprovide suggestions for future improvement. Finally, we report\non the various experiments that were conducted on this testbed\nand evaluate the performance of both the cyber and physical\nlayers. This includes an economic analysis of the potential\nbenefit of this system participating in the ancillary services\nmarket, where our eligibility to do so is verified using real\nmarket eligibility requirements.\nPaper Overview. Frequency regulation is simulated using\nreal DERs in the UCSD microgrid to follow the RegD signal\nfrom PJM [18], interpolated from 0.5Hz to 1Hz (cf. Section\nIII-A). The DER setpoint tracking is formulated as an eco-\nnomic dispatch problem at every regulation instant (cf. Section\nIII-E), and uses three types of provably convergent distributed\nalgorithms from [19]\u2013[22] to solve the optimization problem\n(cf. Appendix A). Setpoints are computed on a distributed\ncomputing setup run on multiple Raspberry Pi\u2019s communi-\ncating via ethernet switches (cf. Section III-B). The setpoints\nare implemented on up to 176 physical power devices using\ndedicated command interfaces via TCP/IP communication (cf.\nSection III-C), the device power outputs monitored (cf. Section\nIII-D), and their tracking performance evaluated (cf. Section\nIII-F). Results for the various test scenarios (cf. Section IV-A)\nshow that the test system tracks the signal with reasonable er-\nror despite delays in response and inaccurate tracking behavior\nof some groups of DERs and qualifies for participation in the\nPJM ancillary services market (cf. Section IV-B).\nII. PROBLEM SETTING\nThis paper validates real-world DER controllability for par-\nticipation in secondary frequency regulation through demon-\nstration tests implemented on a real distribution grid. The\ntests showcase the ability of aggregated DERs to function as\na single market entity that responds to frequency regulation\nrequests from the independent system operators (ISO) by\noptimally coordinating DERs. The goal is to actuate and\nmonitor a set of real controllable power devices to collectively\ntrack a typical automatic generation control (AGC) signal\nissued by the ISO.\nThree different distributed coordination schemes optimize\nthe normalized contribution of each device to the cumulative\nactive power signal. Unlike simulated models, the use of real\npower hardware exposes implementation challenges associated\nwith measurement noise, data communication problems, and\nsampling errors. To that end, precise load tracking is pursued\nat timescales that are consistent with device responsiveness\nand communication latencies yet meet frequency regulation\nrequirements, and is assumed to produce the successful mini-\nmization of the ACE.\nThe 69 kV substation and 12 kV radial distribution system\nowned by UCSD to operate the 5 km2 campus was the chosen\ndemonstration testbed. It has diverse energy resources with\nreal-time monitoring and control capabilities, allowing for\nactive load tracking. This includes over 3 MW of PV systems,\n2.5 MW/5 MWh of BESS, building heating ventilation and\nair conditioning (HVAC) systems in 14 million square feet of\noccupied space, and over 200 electric vehicle (EV) chargers.\nThe demonstration tests used a representative population of\nup to 176 such heterogeneous DERs to investigate tracking\nbehavior of specific DER types as well as their cooperative\ntracking abilities. While the available DER capacity at UCSD\nfar exceeds the minimum requirements for an ancillary service\nprovider set by most ISOs (typically \u223c 1 MW), logistical\nconsiderations and controller capabilities dictated the choice\nof a DER population size with less aggregate power capacity\n(up to 184.3 kW) for this demonstration. Since this magnitude\nof power rating is insufficient to measurably impact the actual\ngrid frequency, we chose to simulate frequency regulation by\nfollowing a frequency regulation signal.\nIII. DESCRIPTION OF TEST ELEMENTS\nHere we elaborate on the different elements of the validation\ntests. These include the identified reference AGC signal and\ntypes of physical devices used to track it (cf. Section III-A),\nthe computing platform (cf. Section III-B), the actuation (cf.\nSection III-C) and monitoring interfaces (cf. Section III-D),\nthe optimization formulation employed to compute device\nsetpoints (cf. Section III-E), and the performance metrics used\nto assess the cyber and physical layers, and eligibility for\nmarket participation (cf. Section III-F).\nA. Regulation Signal\nThe 40-minute Reg-D signal published by PJM [18] served\nas the reference AGC signal. This normalized signal, when\ninterpolated from 0.5 Hz to 1 Hz and appropriately scaled,\nis characterized by steep positive and negative ramps that\n3range from -14 kW to +16 kW over 1-second intervals and an\naverage absolute ramp-rate of 1.7 kW/second (we describe the\nscaling approach more in Section III-E). This reference signal\nwas to be collectively tracked using actuation devices such as\nHVAC AHUs, BESS, V1G and V2G EVs, PV systems and\nwhole-building loads. Since PV systems and building loads\nwere not controllable, they participated in the test as passive\ndevices. Consequently, the active devices were commanded\nto track a modified target signal derived by subtracting the\nnet active power output of passive devices from the reference\nAGC signal, further described in Section III-E. Table I lists\nthe typical power ratings of the different active device types.\nThe contribution of each active power device to the target\nsignal was defined with respect to a baseline power to enable\ntracking of both positive and negative ramps in the target\nsignal. For devices like V2G EVs and BESS, which were\ncapable of power adjustments in both directions, the baseline\nwas defined to be 0 kW. For AHUs, which were only capable\nof on-off control, the baseline was defined to be half of their\npower ratings and the continuous setpoints were rounded to\nthe closest discrete setpoint. Similarly, the baseline power for\nV1G EVs was defined to be halfway between their allowed\nminimum and maximum charging rates.\nB. Computing Setup\nThe device active power setpoints were computed using a\nset of 9 Linux-based nodes, named C1-C9, that communicate\nwith each other over an undirected ring topology, cf. Figure 1.\nAs one of the sparsest network topologies, where message\npassing occurs only between a small number of neighbors, the\nring topology presents a challenging scenario for distributed\ncontrol. Since there are more active power devices than\ncomputing nodes, the 9 nodes were mapped subjectively to\nthe 69 active power devices such that nodes C1-C2 computed\nthe actuation setpoints for the AHUs, C3 for V1G EVs, C4-C8\nfor V2G EVs and C9 for the BESS.\nEach computing node generated actuation commands as\nCSV files containing the power setpoints for their respective\ngroup of devices at a uniform update rate of 1 Hz. Preliminary\ntesting revealed different response times across device types,\nwith AHUs and V1G EVs exhibiting slower response than\nother active devices. Devices with response times greater than\n1 second were subject to a stair-step control signal with a\nsignal update time consistent with device responsiveness and\nconstant setpoints during intermediate time steps. Table I lists\nthe signal update times for the different device types.\nC. Actuation Interfaces and Communication Framework\nThe actuation commands were issued using fixed IP com-\nputers through dedicated interfaces that varied by device type\nas depicted in Fig. 1. The setpoints for AHUs were issued\nthrough a custom Visual Basic program that interfaced with\nthe Johnson Control Metasys building automation software.\nThe power rate of the BESS was set via API-based com-\nmunication with a dedicated computer that controlled the\nbattery inverter. The V1G and V2G EVs charging rates were\nadjusted through proprietary smart EV charging platforms of\nthe charging station operators. EVs using ChargePoint V1G\nstations were manually controlled via the load shedding feature\nof ChargePoints station management software. The actuation\nof EVs using PowerFlex V1G chargers and Nuvve V2G\nchargers was automated and commands were issued via API-\nbased communication.\nD. Power Measurements\nThe active power of all devices was metered at a 1 Hz fre-\nquency. The power outputs of passive devices like PV inverters\nand building loads were obtained prior to the test from their\nrespective ION meters by logging data from the UCSD ION\nSupervisory Control and Data Acquisition (SCADA) system.\nA moving average filter with a 20-second time horizon was\nused to remove noise from the measured data for these passive\ndevices. The responses of active devices like V2G EVs and\nBESS were monitored using the same interfaces that were used\nfor their actuation and with dedicated power meters.\nSince neither AHUs nor the ChargePoint V1G EVs had\ndedicated meters, they were monitored via their respective\nbuilding ION meters by subtracting the baseline building load\nfrom the building meter power output. In essence, the baseline\nbuilding load was assumed to be constant and any change in\nthe meter outputs was attributed to the actuation of AHUs and\nV1G EVs. This assumption is justifiable considering that the\ntests were conducted at 0400 PT to 0600 PT on a weekend,\nwhen building occupancy is likely zero and building load\nremained largely unchanged. Noise in the ION meter outputs\nobserved as frequent 15 - 30 kW spikes in the measured data\nfor AHUs (cf. Fig. 2) and ChargePoint V1G EVs was treated\nby removing outliers and passing the resulting signal through\na 4-second horizon moving average filter. Here, outliers refer\nto points that change in excess of 50% of the mean of the\n40-minute signal in a 1-second interval.\nE. Optimization Formulation\nThe optimization model can be mathematically stated as\na separable resource allocation problem subject to box con-\nstraints. That is, at each 1-second time step of a 40-minute\ntime horizon, the following optimization is solved:\nmin\np\u2208Rn\nf(p) =\nn\u2211\ni=1\nfi(pi),\ns.t.\nn\u2211\ni=1\npi = Pref,\npi \u2208 [pi, pi], \u2200i \u2208 N = {1, . . . , n}.\n(1)\nThe agents i \u2208 N each have local ownership of a decision\nvariable pi \u2208 R, representing an active power generation\nor consumption quantity, a local convex cost function fi,\nand local box constraints [p, p]. Pref is a given active power\nreference value determined by the ISO and transmitted to a\nsubset of the agents as problem data, see e.g. [23]. Pref is\na signal that changes over time, so a new instance of (1) is\nsolved in 1-second intervals corresponding to these changes.\nFor this test, we used two types of cost functions: constant\nand quadratic. Constant functions were used for the Ratio-\nConsensus (RC) solver, which turns the optimization into a\n4Fig. 1: Communication architecture for computation and actuation of control policies.\nfeasibility problem. Quadratic functions were used for the\nprimal-dual based (PD) and Distributed Approximate Newton\nAlgorithm (DANA) methods, cf. Appendix A. The quadratic\nfunctions were artificially chosen to produce satisfactorily\ndiverse and representative solutions for each device population.\nWe split the 40-minute horizon into three equal 13 minute and\n20 second segments and implemented RC, PD, and DANA\non those three segments in that order. Box constraints [p\ni\n, pi]\nwere typically centered at zero for simplicity, which is also\nhighlighted in Section III-A, and the typical net capacity pi\u2212pi\nfor each device type can be found in Table I. Finally, the Pref\nvalue was obtained from the PJM RegD test signal [18], which\nis a normalized signal contained in [\u22121, 1]. We treated this data\nby subtracting normalized building load and PV data from the\nUCSD ION server as described in Section III-A. Finally, this\nnormalized signal was scaled by a factor proportional to the\ntotal device capacity\n\u2211\ni(pi \u2212 pi) prior to being sent to the\noptimization solvers in each trial. More precisely,\nPref = \u03b2\n\u2211\ni(pi \u2212 pi)\n\u2016PRegD + PPV \u2212 Pb\u2016\u221e (PRegD + PPV \u2212 Pb) , (2)\nwhere PRegD refers to the normalized PJM data, PPV and Pb\nrefer to the normalized PV and building load data, resp., and\n0 < \u03b2 < 1 is an arbitrary scaling constant typically chosen to\nbe 0.75 (in particular, \u03b2 < 1 to give some \u201cbreathing room\u201d\nso that not all devices are required to operate at either pi\nor p\ni\nsimultaneously, which may be infeasible in some time\nsteps due to slower signal update times, see Table I). In (2),\neach P can be thought of as a vector with 2401 elements\ncorresponding to each 1-second time step\u2019s instance of (1)\nover the 40-minute time horizon.\nF. Performance Metrics\nThe performance of the distributed implementation (cyber-\nlayer) was measured in the form of mean-squared-error (MSE)\nbetween the distributed and true optimization solutions, where\nthe \u201ctrue/exact\u201d solutions were computed for each instance\nof (1) using a centralized CVX solver in MATLAB [24]. In\nother words, the MSE of the distributed optimization solutions\nwas computed as the summed squared difference between the\ncentralized \u201ctrue\u201d solutions and the distributed outputs divided\nby the summed squared \u201ctrue\u201d solutions (and thus are unitless).\nThe tracking performance of the physical test devices\n(physical-layer) was evaluated through (i) root-mean-squared-\nerror (rMSE) in tracking defined as rMSE between com-\nmanded and measured signal normalized by the root-mean-\nsquare of the target signal,\nrMSE =\n\u221a\u221a\u221a\u221a\u2211Tt=1(P provt \u2212 P tart )2\u2211T\nt=1(P\ntar\nt )\n2\n, (3)\nwhere P provt is the total power that was provided (measured),\nand P tart is the target (commanded) regulation power at time\nstep t \u2208 {1, . . . , T = 2401}; and (ii) tracking delay, computed\nas the time shift of the measured signal which yields the lowest\nrMSE between the commanded and measured signals.\nLastly, the PJM Performance Score S following [25, Section\n4.5.6] was computed as a test for eligibility to participate in\nthe ancillary services market, and is given by the mean of a\nCorrelation Score Sc, Delay Score Sd, and Precision Score Sp:\nSc =\n1\nT \u2212 1\nT\u2211\nt=1\n(P provt \u2212 \u00b5prov)(P tart \u2212 \u00b5tar)\n\u03c3prov\u03c3tar\n,\nSd =\n\u2223\u2223\u2223\u2223\u03b4 \u2212 5 minutes5 minutes\n\u2223\u2223\u2223\u2223, Sp = 1\u2212 1T\nT\u2211\nt=1\n\u2223\u2223\u2223\u2223P provt \u2212 P tart\u00b5tar\n\u2223\u2223\u2223\u2223,\nS = 1/3(Sc + Sd + Sp),\nwhere P provt and P\ntar\nt are as in (3), \u00b5\nprov, \u00b5tar and \u03c3prov, \u03c3tar\ndenote their respective means and standard deviations, and \u03b4\nis the corresponding maximum device delay for when Sc was\nmaximized. A performance score of at least 0.75 is required\nfor participating in the ancillary services market.\n5IV. TEST SCENARIOS AND RESULTS\nIn this section we describe the test scenarios carried out in\nthe UCSD microgrid and present their outcome, elaborating on\nthe challenges we faced and the differences across the tests.\nA. Test Scenarios\n1) Commonalities: A series of three tests were conducted\non December 12, 2018 (Test 0), April 14, 2019 (Test 1) and\nDecember 17, 2019 (Test 2). All three tests involved a 40\nmin preparatory run followed by a 40 min final test. Table I\nlists the number and type of devices used in each test. All\ntests were carried out during non-operational hours (between\n0400 PT and 0540 PT) to maximize fleet EV availability and\nto avoid potential disruptions to building occupants. Day-time\nPV output data from February 24, 2019 was used as a proxy\nfor an actual daytime PV signal.\nNote that the level of control allowed by UCSD Facilities\nfor the demonstration was restricted to specifying only device\nsetpoints and duration of actuation. In other words, there\nwas not a possibility to modify the device controllers and\ndevelop model-based designs. This is because, being run on\nreal physical infrastructure, any malfunctioning of or disrup-\ntions caused during the testing could result in the loss of\nessential operations (as an example, the AHUs are a part of\na networked building management system that also controls\nlighting, security, and fire protection systems).\nDevice Type AHU V1G EV V2G EV BESS\n# devices for\nTest 0 7 4 5 1\n# devices for\nTest 1 34 29 5 1\n# devices for\nTest 2 34 17 6 1\nSignal update\ntimes 1 min\n5 min (Test 0 & 1),\n1 min (Test 2) 1 sec 20 sec\nTypical power\nrating per device 2 kW\n3.3 kW (Test 0 & 1),\n4.9 kW (Test 2) 5 kW 3 kW\nTABLE I: Device counts and characteristics for Air Handler\nUnits (AHUs), V1G and V2G EVs, and Battery Energy\nStorage (BESS) in each test.\n2) Test 0: Test 0 was a preliminary calibration that used\nonly a representative sample of 17 devices. The purpose\nof Test 0 was to examine the response times and tracking\nbehavior of every device type and gauge issues related to\ncommunication bottlenecks and actuation interfaces.\n3) Test 1: Test 1 was identical to Test 0, but it used a larger\npopulation of 69 active power devices and 107 passive devices.\na) Devices. The V1G and V2G population for Test 1 was\ncomposed of UCSD fleet EVs plugged in at ChargePoint and\nNuvve charging stations. The minimum charging rate for V1G\nEVs was restricted by the SAE J1772 charging standard to\n1.6 kW. Considering that the ChargePoint V1G EVs were\noperated via manual input of device setpoints (an interface to\ntheir API had not been developed yet), to avoid overloading\nthe (human) operators they were grouped into three groups\nand actuated in a staggered fashion such that each of the three\ngroups maintained a signal update time of 5 minutes but were\ncommanded 1 minute apart from each other.\nb) Computing Setup. For both Tests 0 and 1, 9 laptops\nrunning a Robotic Operating System (ROS) communicated via\nlocal Wi-Fi hotspot to implement the distributed coordination\nalgorithms and compute the device setpoints. Given that the\navailable power capacity of fast-responding devices such as\nV2G and BESS was smaller than slow-responding devices,\nthe steep ramping demands of the target signal were met by\nupscaling the power of the fast responding devices in solving\nfor the contribution of individual devices. Another option\nwould have been to reduce the number of slow responding\ndevices, but stipulations from the funding agency suggested\nprioritizing the number and types of heterogeneous devices\nover accuracy in signal tracking. A real DER aggregator would\ninstead need to have a more balanced capacity of slow and fast\nresponding devices to ensure feasibility of tracking these ramp\nfeatures.\n4) Test 2: Test 2 also used the entire population of devices\nbut substituted the cumbersome and coarse V1G population\nwith more capable devices and used a new distributed com-\nputing setup and method of actuation based on lessons learned\nfrom Test 1.\na) Devices. The V1G EVs used in Test 1 performed poorly\nowing to an unreliable actuation-interface that experienced\nseemingly random stalling and lacked automated control capa-\nbilities. Therefore, 17 PowerFlex V1G charging stations at one\nlocation replaced the distributed 29 V1G charging stations in\nTest 1. Since the PowerFlex interface did not permit actuating\nindividual stations, the 17 charging stations participated in the\ntest as a single aggregate device. The 0930 1010 PT timing of\nthe test coincided with the start of the workday and a V1G EV\npopulation that had only recently plugged in and therefore had\nample remaining charging capacity. The EVs were contributed\nby UCSD employees and visitors plugging in at the PowerFlex\ncharging stations just before the start of the trial. An aggregate\nsignal of 15 kW to 19 kW was distributed equally amongst\nthe 17 EVs that were present on the day on the trial.\nIn addition to the new V1G EVs, the V2G population in\nTest 2 was replaced with a different set of Nuvve chargers\nto resolve a tracking/noise issue during discharge-to-grid ob-\nserved in Test 1 and expanded to include an additional charger,\namounting to a total of six V2Gs charging six 5 kW EVs.\nThe order of AHU actuation was modified to allow for\ndevice settling time and prevent interference. In particular, in\nTests 0 and 1, individual AHUs were ordered and actuated\nusing a protocol that was not cognizant of settling times or\nbuilding groupings, while the protocol was revised in Test 2\nto systematically iterate through the entire population of AHUs\nin a manner which maximized time between consecutive actu-\nations for an individual unit and minimized correlation effects\nof actuating devices on the same meter in quick succession.\nb) Computing Setup. Test 2 featured a fully distributed\narchitecture unlike the ROS-based semi-centralized comput-\ning setup in Test 1. The new distributed setup consisted of\na network of Raspberry Pis that asynchronously communi-\ncated with each other via an ethernet switch. In addition,\na modified synchronization technique was implemented in\nthe software which improved the fidelity and robustness of\nmessage-passing. This upgraded message-passing framework\nand synchronization technique for both software and hardware\n6resulted in significantly faster communication between nodes.\nc) Two-Stage Actuation. Test 2 also featured a two-stage\napproach of actuation that was a result of the device char-\nacterization based on their tracking behavior in Test 1. The\napproach was motivated by some devices such as BESS,\nV1G EVs and V2G EVs exhibiting good tracking behavior\nwhereas others such as AHUs tracking poorly. Overall tracking\nperformance was improved by using \u201cwell-behaved\u201d devices\nto compensate for poorly tracking ones. Test 2 achieved this\nby incorporating the error signal from actuating AHUs in\nStage 1 to the cumulative target signal for BESS, V1G EVs\nand V2G EVs in Stage 2. Although synchronous actuation of\nall participating DERs is preferred in practice, this approach\nhighlights the significance of systematic characterization of\ndevices in effectively minimizing ACE.\nB. Test Results\n1) Distributed Optimization/Cyber-Layer Results: In Ta-\nble II, we present results of our 1-second real-time Raspberry-\npi distributed optimization solutions (the \u201ccyber-layer\u201d of the\nsystem) in the sense of MSE from the true optimization\nsolutions computed as described in Section III-F.\nDevice Type RC Primal-Dual DANA all\nAir Handler 0 1.4\u00d7 10\u22127 2.8\u00d7 10\u22129 4.6\u00d7 10\u22128\nV1G EVs 0 7.0\u00d7 10\u22128 1.7\u00d7 10\u22129 2.3\u00d7 10\u22128\nV2G EVs 0 6.6\u00d7 10\u22125 5.0\u00d7 10\u22127 2.1\u00d7 10\u22125\nBESS 0 2.0\u00d7 10\u22126 9.1\u00d7 10\u22128 6.5\u00d7 10\u22127\nTotal 0 1.8\u00d7 10\u22125 1.1\u00d7 10\u22127 4.9\u00d7 10\u22126\nTABLE II: Mean-squared-errors of distributed solutions ob-\ntained from real-time 1 second time intervals as compared to\nthe solution obtained from a centralized solver.\nWe note that RC converged to the exact solution in all\ninstances. This is unsurprising, as the RC problem formulation\ndoes not account for individual device costs and thus is a\nmuch simpler problem with a closed-form solution. For PD\nand DANA, we obtain very satisfactory convergence, with\nerrors on the order of 0.001% in the worst cases. In general,\nDANA tended to converge faster than PD and obtained more\naccurate solutions. For our application with 1-second real-time\nwindows, accuracy and convergence differences did not affect\nthe physical layer results in any tangible way, but applications\nwith more stringent accuracy or speed requirements may\nbenefit from using a faster algorithm like DANA. As for\ndifferences between device populations, these can be largely\nattributed to the faster time scale of the V2G EVs (and to\na lesser extent the BESS), see Table I. In this sense, the\nV2G EVs tended to be responsible for the high-frequency\ncomponent of Pref; thus, the solver was required to converge\nto new solutions at every time step, which induced more\nerror compared to the slow V1G EVs and Air Handlers with\nrelatively static solutions.\n2) Physical-Layer Test Results: We now present the results\nof the tracking performance pertaining to the physical-layer\nof the experiment. We provide only some selective plots for\nTest 0 and Test 1, cf. Fig. 2, and a complete set of plots for\neach Test 2 device population in Fig. 3. Error and tracking\ndelay data defined in Section III-F is given in Table III for\nTest 1 and Test 2, where data for Test 0 is omitted due to\nits preliminary nature (few total devices and lack of practical\nimplementation techniques only employed in Tests 1 and 2).\nThe plots are given with the optimal shift described in Section\nIII-F in effect (and hence some areas in plots appear to be\nnon-causal), and the rMSE numbers we report are similarly\nobtained after applying these optimal time-shifts.\nFig. 2: Top: Air Handler response in Test 0. Middle: V2G\nresponse in Test 1. Bottom: Total response in Test 1.\nSignal tracking accuracy in Test 0 was generally bad de-\nspite the small number of devices employed, largely due to\ninexperience in actuating the AHUs and V1Gs. In particular,\nFig. 2 reveals some oscillations in the Air Handler response\nand is overall difficult to determine if even large-feature, low-\nfrequency components of the signal were tracked. Further,\ndata gathering for V1Gs and AHUs was done via noisy and\nunreliable building ION meters, which motivated the need for\noutlier treatment (cf. Section III-D) in Tests 1 and 2, and\nresulted in the smoother signal seen in the top plot of Fig. 3\nwhich is more appropriate to interpret.\nTest 1 yielded a 111.34% rMSE for AHUs, and we speculate\nthat the small 4-second delay is not representative of the\nactual AHU delay due to this massive error number. This is\nconfirmed by a much better AHU response in Test 2 with\nrMSE 11.91%, where a 105 second delay is revealed and is\nmore likely to be representative of the true AHU actuation\ndelay. Overall, given the poor visibility into AHU and V1G\ndevice controllers explained in Section IV-A, we speculate\na major source of error for these devices in Test 1 to be\nin the device metering. This was largely resolved in Test 2\nby utilizing a different population of V1Gs with dedicated\ncharging meters and by modifying the actuation scheme for\nAHUs to be less susceptible to metering errors as described\nin Section IV-A4. Additionally, the actuation-interface stalling\nfor V1G EVs described in Section IV-A3 was dominant in\nthe preparatory 0400 PT test, resulting in the poor tracking\nfor V1Gs in Test 1. This was similarly resolved in Test 2 by\n7Fig. 3: From top to bottom, AHU, V2G EVs, V1G EVs,\nBESS, and Total responses in Test 2.\nutilizing a more automated control scheme for the V1Gs which\nlent to significantly lower error.\nThe BESS emerged as the star performer achieving very\naccurate tracking across all tests with no delay, and the\nV2G EVs also performed relatively well aside from a signal\novershoot issue observed during the discharge cycle in Test 1\nseen in Fig. 2. The issue was resolved in Test 2 by using\na different set of V2G EV charging stations as described\nin Section IV-A4 and validating their response prior to the\ntest. The inability of the AHUs to respond to steep, short\nramps, seen in Fig. 3, could be due to transients associated\nwith driving their AC induction electric motors. Tackling this\nwould require finer control using dynamic models. With the\nnew V1G EV population in Test 2, tracking delay reduced\nfrom 40 seconds to 10 seconds and the tracking performance\nsignificantly improved. The 1 kW bias seen in Fig. 3 is likely\ndue to rounding errors arising from the inability of PowerFlex\ncharging stations to accept non-integer setpoints.\nUltimately, the superior performance of the BESS and\nV2Gs motivated the two-stage actuation scheme described in\nSection IV-A4, which contributed to reducing the total rMSE\nsignificantly from 50.40% in Test 1 to 9.69% in Test 2. This is\nalso observed by comparing the bottom plot of Figs 2 and 3.\nThe two-stage approach necessitates a sufficiently large pro-\nportion of strongly-performing devices to compensate for the\nerrors of the first stage, in which tracking is relatively worse.\nIn this manner, the poorly-performing devices such as AHUs\ncan still provide a substantial contribution by loosely tracking\nsome large-feature, low-frequency components of the target\nsignal. This contribution plays a role by reducing the required\ntotal capacity of the strongly-performing devices in the second\nstage and allowing for more fine-tuned signal tracking. Some\nrules of thumb that we recommend for this approach are: (i)\ntotal capacity of first-stage devices is less than or roughly\nequal to total capacity of second-stage devices, (ii) devices\nin the first stage are capable of tracking with < 50% rMSE,\nand (iii) device cost functions are such that the deviation\nfrom the baseline is lower cost for first-stage devices than for\nsecond-stage devices. Note that (iii) ensures that a significant\nportion of the target signal is initially allocated to the first-\nstage devices, freeing up device capacity in the second-stage\nfor error compensation (instead of signal tracking).\nDevice Type Test 1 Test 2\nAir Handler 1.1134 0.1191\nV1G EVs 0.6775 0.0773\nV2G EVs 0.3004 0.0602\nBESS 0.0541 0.0175\nTotal 0.5040 .0969\nDevice Type Test 1 Test 2\nAir Handler 4 105\nV1G EVs 40 10\nV2G EVs 5 3\nBESS 0 0\nTotal N/A N/A\nTABLE III: Left: Relative root mean-squared-error of tracking\nerror by device type. Right: Delay (optimal time-shift) of\ndevice responses in seconds.\n3) Economic Benefit Analysis: Here, we evaluate the eco-\nnomic benefit of the proposed test system as it is vital for wider\nscale adoption of DERs as a frequency regulation resource\nin real electricity markets. To this end, we take an approach\nsimilar to [9] to first demonstrate that the testbed is eligible to\nparticipate in the PJM ancillary services market. Following the\nPJM Manual 12 [25] (see also Section III-F), we compute a\nCorrelation Score Sc = 0.9767, Delay Score Sd = 0.6500, and\nPrecision Score Sp = 0.9125 from data for Test 2, and obtain\na Performance Score S = 0.8464 \u2265 0.75, which confirms the\neligibility to participate in the PJM ancillary service market.\nNext, we proceed by computing an estimated annual revenue\nfor the case of resource availability of (a) 8 hours per day\nand (b) 24 hours per day. Using PJM\u2019s capability clearing\nprice data2 for July 9, 2020 with our total active device\ncapacity of 184.3 kW and performance score of 0.8464, the\napproximated potential annual revenue for this population of\nresources (cf. [26, Section 4]) is (a) $16,403 and (b) $49,210.\nNote that the 184.3 kW device capacity employed in this work\nrepresents less than 5% of the total DER capacity and less than\n0.5% of the total capacity of the UCSD microgrid, cf. [17].\nAs such, the revenue estimated here is conservative and has\na much higher potential if more UCSD microgrid resources\nwere utilized.\nV. CONCLUSIONS\nWe have presented one of the first real-world demonstrations\nof secondary frequency response in a distribution grid using up\n2https://dataminer2.pjm.com/feed/reg prices\n8to 176 heterogeneous DERs. The devices we employ include\nAHUs, V1G and V2G EVs, a Lithium-Ion Battery Energy\nStorage System, and passive building loads and PV generators.\nThe computation setup utilizes state-of-the-art distributed al-\ngorithms to find the solution of an economic dispatch problem.\nWe show that the real-time distributed solutions are close to\nthe true centralized solution in an MSE sense, and physical\ndevice tests closely track the given real-power reference signal.\nThese tests highlight the importance of dedicated and noise-\nfree measurement sensors and a well-understood and reliable\ndevice control interface for precise signal tracking. Further, our\neconomic benefit analysis shows a potential revenue of $49K\nusing this device population. As is already recognized by the\npower systems community and federal funding agencies such\nas ARPA-e and NSF, large-scale power-in-the-loop testing\nis needed for transitioning distributed technologies to real\ndistribution systems. We hope that this work spurs further\ntesting and ultimately widespread adoption of coordinated\nresource control algorithms by relevant players in industry.\nAPPENDIX A\nDISTRIBUTED COORDINATION ALGORITHMS\nIn this section we describe the algorithms used in our\ndistributed computing platform to solve (1).\nRatio-Consensus (RC): The ratio-consensus of [19] com-\nputes equitable contributions from all devices without device-\nspecific cost functions (or constant device costs). The ratio-\nconsensus algorithm for providing Pref is given by\nyi[k + 1] =\n\u2211\nj\u2208N i\n1\n| N i |yj [k], zi[k + 1] =\n\u2211\nj\u2208N i\n1\n| N i |zj [k],\nyi[0] =\n{\nPref\n| I | \u2212 pi, i \u2208 I,\n\u2212p\ni\n, i /\u2208 I, zi[0] = pi \u2212 pi,\nwhere, k is the iteration number, yi and zi are two auxiliary\nvariables maintained by each agent, N i denotes the neigh-\nboring devices of device i, and p\ni\nand pi are the minimum\nand maximum power level for device i from the problem\nformulation in Section III-E. I denotes the subset of devices\nwhich know the value of the reference signal. One can see that\np?i = pi + limk\u2192\u221e\nyi[k]/zi[k](pi \u2212 pi)\n= p\ni\n+\nPref \u2212\n\u2211\ni pi\u2211\ni pi \u2212 pi\n(pi \u2212 pi),\nwhere p?i is then the power assignment for device i.\nPrimal-Dual (PD): Both this dynamics and DANA (de-\nscribed next) take into account the cost functions of the\ndevices when computing the power setpoints, i.e., fi are\nnonconstant. These functions are modeled as quadratics, which\nis a common choice in generator dispatch [27]. The dynamics\nis based on the discretization of the primal-dual dynamics [21]\nfor the augmented Lagrangian of the equivalent reformulated\nproblem, see [20], and it has a linear rate of convergence to\nthe optimizer. The algorithm is given by\uf8ee\uf8f0p\u02d9iy\u02d9i\n\u03bb\u02d9i\n\uf8f9\uf8fb =\n\uf8ee\uf8ef\uf8ef\uf8f0\n\u2212\n(\nf \u2032i(pi) + \u03bbi + pi\n\u2211\nj\u2208N i Lijyj \u2212 Pref/n\n)\n\u2212\n(\u2211\nj\u2208N i Lij(\u03bbj + xj \u2212 Pref/n) +\n\u2211\nj\u2208N 2i L\n2\nijyj\n)\npi +\n\u2211\nj\u2208N i Lijyj \u2212 Pref/n\n\uf8f9\uf8fa\uf8fa\uf8fb ,\nwhere, L is the Laplacian matrix of the communication graph\n(see [28]), yi is an auxiliary variable, and \u03bbi is the dual\nvariable associated with agent i. The update step is followed by\na projection of the primal variable pi onto the box constrained\nlocal feasible set. These dynamics converge from any set of\ninitial conditions. Since this algorithm evolves in continuous\ntime, we use an Euler discretization with fixed step-size to\nimplement it in discrete time.\nDistributed Approximate Newton Algorithm (DANA): The\nDistributed Approximate Newton Algorithm (DANA) of [22]\nhas an improved rate of convergence compared to PD. This\nalgorithm solves the equivalent reformulated problem\nmin\nz\u2208Rn\nf(p0 + Lz) =\nn\u2211\ni=1\nfi(p\n0\ni + Liz),\nsubject to p\u2212 p0 \u2212 Lz \u2264 0n,\np0 + Lz \u2212 p \u2264 0n,\n(4)\nwhere p0 is a vector of initial power levels of all the devices\nwith\n\u2211\ni p\n0\ni = Pref, and z is the new variable of optimization.\nThe continuous time dynamics are given by\nz\u02d9 = \u2212Aq\u2207z L(z, \u03bb),\n\u03bb\u02d9 = [\u2207\u03bb L(z, \u03bb)]+\u03bb ,\nwhere L is the Lagrangian of (4) and Aq is a positive definite\nweighting on the gradient direction which provides distributed\nsecond-order information. For brevity, we do not provide the\nfull details of the algorithm here, which can instead be found\nin [22]. The cost functions are again taken to be quadratic with\nstrictly positive leading coefficients.\nACKNOWLEDGEMENTS\nWe would like to thank numerous people in the UCSD\ncommunity and beyond for their generous contributions of\ntime and resources to enable such an ambitious project to come\ntogether. We extend thanks to: (i) Aaron Ma and Jia (Jimmy)\nQiu for assisting with hardware setup and software devel-\nopment for the distributed computation systems; (ii) Kevin\nNorris for coordinating the fleet vehicles; (iii) Abdulkarim\nAlamad for overseeing V1G drivers in Test 2; (iv) Kelsey\nJohnson for managing the Nuvve contributions; (v) Ted Lee,\nPatrick Kelly, and Steven Low for managing the PowerFlex\ncontribution; (vi) Marco Arciniega, Martin Greenawalt, James\nGunn, Josh Kavanagh, Jennifer Rodgers, Patricia Roman and\nLashon Smith from UCSD parking for reserving EV charging\nstation parking spaces; (vii) Charles Bryant, Harley Crace,\nJohn Denhart, Nirav Desai, John Dilliott, Mark Gaus, Mar-\ntin Greenawalt, Gerald Hernandez, Brandon Hirsch, Mark\nJurgens, Josh Kavanagh, Jose Moret, Chuck Morgan, Curt\nLutz, Jose Moret, Cynthia Wade, Raymond Wampler and\nEd Webb for contributing their EVs in Test 1 (viii) Adrian\nArmenta, Adrian Gutierrez and Minghua Ong who helped with\nChargePoint manual control; (ix) Bob Caldwell (Centaurus\nPrime), Gregory Collins, Charles Bryant, and Robert Austin\nfor programming and enabling the AHU control; (x) Gary\nMatthews and John Dilliott for permitting the experimentation\non \u201clive\u201d buildings and vehicles; and (xi) Antoni Tong and\nCristian Cortes-Aguirre for supplying the BESS. Finally, we\n9would like to extend a sincere thanks to the ARPA-e NODES\nprogram for its financial support and to its leadership, includ-\ning Sonja Glavaski, Mario Garcia-Sanz, and Mirjana Marden,\nfor their vision and push for the development of large-scale\npower-in-the-loop testing environments.\nREFERENCES\n[1] M. Kintner-Meyer, \u201cRegulatory policy and markets for energy storage\nin North America,\u201d Proceedings of the IEEE, vol. 102, no. 7, pp. 1065\u2013\n1072, 2014.\n[2] CAISO, \u201cPay for performance regulation: Draft final\nproposal addendum,\u201d February 22 2012. [Online]. Available:\nhttp://www.caiso.com/Documents/Addendum-DraftFinalProposal-Pay\nPerformanceRegulation.pdf\n[3] P. Srivastava, C.-Y. Chang, and J. Corte\u00b4s, \u201cParticipation of microgrids\nin frequency regulation markets,\u201d in American Control Conference,\nMilwaukee, WI, May 2018, pp. 3834\u20133839.\n[4] B. Kroposki, \u201cBasic research needs for autonomous energy grids-\nSummary report of the workshop on autonomous energy grids,\u201d NREL,\nTech. Rep., September 13-14 2017, NREL/TP-5D00-70428.\n[5] W. Kempton, V. Udo, K. Huber, K. Komara, S. Letendre, S. Baker,\nD. Brunner, and N. Pearre, \u201cA test of vehicle-to-grid (V2G) for energy\nstorage and frequency regulation in the PJM system,\u201d 2008, available at\nhttp://www1.udel.edu/V2G/resources/test-v2g-in-pjm-jan09.pdf.\n[6] M. Swierczynski, D. Stroe, A. Stan, R. Teodorescu, R. Lrke, and P. C.\nKjr, \u201cField tests experience from 1.6MW/400kWh Li-ion battery energy\nstorage system providing primary frequency regulation service,\u201d in IEEE\nPES ISGT Europe, 2013, pp. 1\u20135.\n[7] M. Cheng, J. Wu, S. J. Galsworthy, C. E. Ugalde-Loo, N. Gargov,\nW. W. Hung, and N. Jenkins, \u201cPower system frequency response from\nthe control of bitumen tanks,\u201d IEEE Transactions on Power Systems,\nvol. 31, no. 3, pp. 1769\u20131778, 2016.\n[8] J. Liu, W. Zhang, and Y. Liu, \u201cPrimary frequency response from the con-\ntrol of led lighting loads in commercial buildings,\u201d IEEE Transactions\non Smart Grid, vol. 8, no. 6, pp. 2880\u20132889, 2017.\n[9] Y. Lin, P. Barooah, S. Meyn, and T. Middelkoop, \u201cExperimental evalua-\ntion of frequency regulation from commercial building HVAC systems,\u201d\nIEEE Transactions on Smart Grid, vol. 6, no. 2, pp. 776\u2013783, 2015.\n[10] E. Vrettos, E. C. Kara, J. MacDonald, G. Andersson, and D. S. Callaway,\n\u201cExperimental demonstration of frequency regulation by commercial\nbuildingspart II: Results and performance evaluation,\u201d IEEE Transac-\ntions on Smart Grid, vol. 9, no. 4, pp. 3224\u20133234, 2018.\n[11] B. Lundstrom, S. Patel, S. Attree, and M. V. Salapaka, \u201cFast primary\nfrequency response using coordinated DER and flexible loads: Frame-\nwork and residential-scale demonstration,\u201d in 2018 IEEE Power Energy\nSociety General Meeting, Portland, OR, Aug. 2018, pp. 1\u20135.\n[12] L. Fabietti, T. T. Gorecki, F. A. Qureshi, A. Bitlisliog\u02d8lu, I. Lymper-\nopoulos, and C. N. Jones, \u201cExperimental implementation of frequency\nregulation services using commercial buildings,\u201d IEEE Transactions on\nSmart Grid, vol. 9, no. 3, pp. 1657\u20131666, 2018.\n[13] K. Baker, X. Jin, , D. Vaidhynathan, W. Jones, D. Christensen, B. Sparn,\nJ. Woods, H. Sorensen, and M. Lunacek, \u201cFrequency regulation services\nfrom connected residential devices: Short paper,\u201d in Proceedings of the\n3rd ACM International Conference on Systems for Energy-Efficient Built\nEnvironments, Palo Alto, CA, 2016, pp. 119\u2013122.\n[14] SDGE, \u201cAC saver for business.\u201d [Online]. Available: https://www.\nsdge.com/businesses/savings-center/energy-management-programs/\ndemand-response/summer-saver-program\n[15] S. Cherian and P. Asmus, \u201cLiberating microgrids (and all DER): Align-\ning customer needs with solutions provider offerings,\u201d White Paper,\nNavigant Research, 2016.\n[16] A. Tuckey, S. Zabihi, and S. Round, \u201cDecentralized control of a micro-\ngrid,\u201d in European Conference on Power Electronics and Applications,\nWarsaw, Poland, Sep. 2017, pp. 1\u201310.\n[17] B. Washom, J. Dilliot, D. Weil, J. Kleissl, N. Balac, W. Torre, and\nC. Richter, \u201cIvory tower of power: Microgrid implementation at the\nUniversity of California, San Diego,\u201d IEEE Power and Energy Magazine,\nvol. 11, no. 4, pp. 28\u201332, 2013.\n[18] \u201cPJM markets and operations: Anciliary services,\u201d https://www.pjm.\ncom/markets-and-operations/ancillary-services.aspx, 2019, regD Nor-\nmalized Signal Test (after 1.30.2017).\n[19] A. D. Dom\u0131\u00b4nguez-Garc\u0131\u00b4a, C. N. Hadjicostis, and N. H. Vaidya, \u201cRe-\nsilient networked control of distributed energy resources,\u201d IEEE Journal\non Selected Areas in Communications, vol. 30, no. 6, pp. 1137\u20131148,\nJuly 2012.\n[20] A. Cherukuri and J. Corte\u00b4s, \u201cDistributed algorithms for convex network\noptimization under non-sparse equality constraints,\u201d in Allerton Conf. on\nCommunications, Control and Computing, Monticello, IL, Sep. 2016,\npp. 452\u2013459.\n[21] A. Cherukuri, B. Gharesifard, and J. Corte\u00b4s, \u201cSaddle-point dynamics:\nconditions for asymptotic stability of saddle points,\u201d SIAM Journal on\nControl and Optimization, vol. 55, no. 1, pp. 486\u2013511, 2017.\n[22] T. Anderson, C.-Y. Chang, and S. Mart\u0131\u00b4nez, \u201cDistributed approximate\nNewton algorithms for constrained optimization,\u201d Automatica, vol. 109,\np. 108538, 2019.\n[23] CAISO, \u201cBusiness practice manual for market operation,\u201d May 24\n2018, version 57. [Online]. Available: https://bpmcm.caiso.com/Pages/\nBPMDetails.aspx?BPM=Market%20Operations\n[24] M. Grant and S. Boyd, \u201cCVX: Matlab software for disciplined convex\nprogramming, version 2.1,\u201d http://cvxr.com/cvx, Mar. 2014.\n[25] \u201cPJM manual 12: Balancing operations,\u201d March 26 2020, revision 40.\n[Online]. Available: https://www.pjm.com/-/media/documents/manuals/\nm12.ashx\n[26] \u201cPJM manual 28: Operating agreement accounting,\u201d December 3\n2019, revision 83. [Online]. Available: https://www.pjm.com/-/media/\ndocuments/manuals/m28.ashx\n[27] G. S. A. Wood, B. Wollenberg, Power Generation, Operation, and\nControl, 3rd ed. John Wiley, 2012.\n[28] F. Bullo, J. Corte\u00b4s, and S. Mart\u0131\u00b4nez, Distributed Control of Robotic\nNetworks, ser. Applied Mathematics Series. Princeton University Press,\n2009.\n",
      "id": 86735010,
      "identifiers": [
        {
          "identifier": "oai:escholarship.org:ark:/13030/qt6t4979c0",
          "type": "OAI_ID"
        },
        {
          "identifier": "2007.07971",
          "type": "ARXIV_ID"
        },
        {
          "identifier": "oai:arxiv.org:2007.07971",
          "type": "OAI_ID"
        },
        {
          "identifier": "334970424",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:escholarship.org/ark:/13030/qt6t4979c0",
          "type": "OAI_ID"
        },
        {
          "identifier": "484116776",
          "type": "CORE_ID"
        },
        {
          "identifier": "327048848",
          "type": "CORE_ID"
        }
      ],
      "title": "Frequency Regulation with Heterogeneous Energy Resources: A Realization\n  using Distributed Control",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:escholarship.org:ark:/13030/qt6t4979c0",
        "oai:escholarship.org/ark:/13030/qt6t4979c0",
        "oai:arxiv.org:2007.07971"
      ],
      "publishedDate": "2021-02-04T00:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://escholarship.org/uc/item/6t4979c0",
        "http://arxiv.org/abs/2007.07971"
      ],
      "updatedDate": "2023-03-04T00:25:45",
      "yearPublished": 2021,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "http://arxiv.org/abs/2007.07971"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/86735010"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Brown, Merwin"
        },
        {
          "name": "Cibulka, Lloyd"
        },
        {
          "name": "Mateer, Niall"
        },
        {
          "name": "von Meier, Alexandra"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/484236704"
      ],
      "createdDate": "2020-03-27T11:58:55",
      "dataProviders": [
        {
          "id": 183,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/183",
          "logo": "https://api.core.ac.uk/data-providers/183/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "This white paper describes the circumstances in California around the turn of the 21st century that led the California Energy Commission (CEC) to direct additional Public Interest Energy Research funds to address critical electric grid issues, especially those arising from integrating high penetrations of variable renewable generation with the electric grid. It contains an assessment of the beneficial science and technology advances of the resultant portfolio of electric grid research projects administered under the direction of the CEC by a competitively selected contractor, the University of California\u2019s California Institute for Energy and the Environment, from 2003-2014",
      "documentType": "research",
      "doi": null,
      "downloadUrl": "https://core.ac.uk/download/288432726.pdf",
      "fieldOfStudy": null,
      "fullText": "UC Berkeley\nElectric Grid\nTitle\nAn Assessment of PIER Electric Grid Research 2003-2014 White Paper\nPermalink\nhttps://escholarship.org/uc/item/9hz5h2sd\nAuthors\nBrown, Merwin\nCibulka, Lloyd\nvon Meier, Alexandra\net al.\nPublication Date\n2015\neScholarship.org Powered by the California Digital Library\nUniversity of California\nWHITE PAPER\nAN ASSESSMENT OF PIER \nELECTRIC GRID RESEARCH, \n2003-2014\nMARCH 2015\nPrepared for: California Energy Commission\nPrepared by:California Institute for Energy and Environment \n\nPrepared by:\nPrimary Author(s):\nMerwin Brown\nLloyd Cibulka\nAlexandra von Meier\nNiall Mateer\nCalifornia Institute for Energy and Environment\nUniversity of California\n2087 Addison Street\nBerkeley, CA 94704\n916-643-1440\nwww.uc-ciee.org\nContract Number: 500-10-055\nWork Authorization Number: 10-007\nPrepared for:\nCalifornia Energy Commission\n\nACKNOWLEDGEMENTS\nThe authors wish to acknowledge the leadership and technical guidance of the \nPublic Interest Energy Research (PIER) staff of the California Energy Commission. \nAlso, the authors are appreciative of the principal investigators, researchers and \nmembers of the electricity delivery community who provided the current status of \nmuch of the technology developments described in this paper.\ni\nPREFACE\nAn Assessment of PIER Electric Grid Research, 2003-2014 is the report for the \nEnergy Commission project Characterization of the Electric Grid, Issues, and \nChallenges (contract number 500-10-055, work authorization number WA007: White\nPaper on An Assessment of the Impacts of the Electric Grid Research Program, \n2003-2014), conducted by the California Institute for Energy and Environment. The \ninformation from this project contributes to PIER\u2019s Energy Systems Integration \nProgram.\nii\nABSTRACT\nThis white paper describes the circumstances in California around the turn of the \n21st century that led the California Energy Commission (CEC) to direct additional \nPublic Interest Energy Research funds to address critical electric grid issues, \nespecially those arising from integrating high penetrations of variable renewable \ngeneration with the electric grid. It contains an assessment of the beneficial science\nand technology advances of the resultant portfolio of electric grid research projects \nadministered under the direction of the CEC by a competitively selected contractor, \nthe University of California\u2019s California Institute for Energy and the Environment, \nfrom 2003-2014. \nKeywords: California Energy Commission, research, public interest, renewables, \nefficiency, performance metrics, electric grid, transmission, distribution, Smart Grid.\nPlease use the following citation for this report:\nBrown, Merwin; Cibulka, Lloyd; von Meier, Alexandra; Mateer, Niall. 2015. An \nAssessment of PIER Electric Grid Research, 2003-2014. California \nInstitute for Energy and Environment.\niii\nTABLE OF CONTENTS\nACKNOWLEDGEMENTS.............................................................................i\nPREFACE................................................................................................ii\nABSTRACT.............................................................................................iii\nTABLE OF CONTENTS.............................................................................iv\nExecutive Summary...........................................................................ES-1\nIntroduction......................................................................................ES-1\nChallenges Facing the California Electric Grid and Shaping the PIER TRPES-\n1\nThe TRP Strategy..............................................................................ES-2\n1. New Technology for Providing Access to the Grid by Putting New Transmission \nLines in a \u201cBetter Light\u201d...............................................................................ES-3\n1.1. Transmission Cost Allocation Methodologies.............................................ES-3\n1.2. Demonstration of Advanced Conductors for Overhead Transmission Lines.ES-\n4\n2. New Technology for Accommodating Variable Renewable Generator Behaviors\n..................................................................................................................... ES-4\n2.1. Critical Operating Constraints Forecasting for California Independent System \nOperator (CAISO) Decision Support...........................................................ES-5\n2.2. Tools for Online Analysis and Visualization of Operational Impacts of Wind \nand Solar Generation.................................................................................ES-6\n2.2.1. Transmission Forecasting Tool...........................................................ES-6\n2.2.2. Ramping Forecasting Tool..................................................................ES-7\n2.2.3. Day Ahead Regulation Requirement Prediction Tool..........................ES-7\n2.3. Wide-Area Energy Storage and Management System (WAEMS) to Balance \nIntermittent Resources in the California ISO..............................................ES-8\n2.4. Improved Generator and Load Models.......................................................ES-9\n2.4.1. WECC Wind Generator Modeling........................................................ES-9\n2.4.2. Load Modeling Transmission Research............................................ES-10\niv\n3. New Technology for Increasing Transmission Capacity by Optimizing the Grid \nfor Greater Power Flow...............................................................................ES-11\n3.1. New Capacity Thermal Capability............................................................ES-12\n3.1.1. Multi-area Real-Time Transmission Line Rating Study.....................ES-12\n3.2. New Capacity Voltage Stability Capability...............................................ES-13\n3.2.1. California ISO Real-Time Voltage Security Assessment (VSA)..........ES-13\n3.3. New Capacity Transient Stability Capability............................................ES-13\n3.4. New Capacity Dynamic Stability Capability.............................................ES-14\n3.5. New Capacity Transmission Expansion Planning Capability.....................ES-14\n3.5.1. Extreme Events................................................................................ES-15\n3.6. Transmission Congestion Assessment and Probabilistic Forecasting.......ES-16\n3.6.1. California Transmission Congestion Assessment.............................ES-16\n3.6.2. Probabilistic Transmission Congestion Forecasting..........................ES-16\n3.7. New High Power Managing Capability......................................................ES-17\n3.7.1. Development of Fault Current Controller Technology......................ES-17\n3.8. Real-Time System Operations..................................................................ES-19\n3.8.1. A Business Case Study on Applying Synchrophasor Measurement \nTechnology and Applications in the California and the Western Electricity\nCoordinating Council \nGrid\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..ES-\n19\n3.8.2. Real-Time Applications of Phasors for Monitoring, Alarming and Control. \nES-20\n3.8.3. Real-Time Oscillation Detection, Analysis and Mitigation.................ES-21\n3.9. Advanced Protection Systems Using Wide Area Measurement................ES-23\n3.9.1. Scoping Study of Intelligent Grid Protection Systems......................ES-23\n3.9.2 Advanced Protection Systems Using Wide Area Measurements.......ES-24\n3.9.3. Application of Advanced Wide Area Early Warning Systems with \nAdaptive \n          Protection.........................................................................................ES-25\nv\n4. New Cross-cutting Technology for Improving the Transmission System \nReliability, Flexibility and Resiliency...........................................................ES-26\n4.1. Increased Seismic Robust Performance of Transmission Substation \nComponents.............................................................................................ES-27\n4.1.1. Evaluation of the Seismic Performance of High-Voltage Transformer \nBushings...........................................................................................  ES-27\n4.1.2. Seismic Performance of Substation Insulator Posts for Vertical-Break \nDisconnect Switches..........................................................................ES-27\n5. Electric Distribution System and Renewable Generation Integration.........ES-29\n5.1. Advanced Monitoring of Distribution Systems.........................................ES-29\n5.1.1. Distribution System Field Study with California Utilities to Assess \nCapacity for Renewables and Electric Vehicles.................................ES-30\n5.2. Reliability of Underground Distribution Systems.....................................ES-30\n5.2.1. Underground Cable Diagnostics Miniaturization Research, \nDevelopment, Field Test,\n and Commercialization.....................................................................ES-31\nConcluding Statements....................................................................ES-32\nIntroduction...........................................................................................1\nThe Beginnings of the CEC\u2019s PIER and TRP...............................................1\nThe Challenges Facing the California Electric Grid and the Shaping of the \nPIER TRP................................................................................................2\nThe TRP Strategy...................................................................................4\n1. New Technology for Providing Access to the Grid by Putting New Transmission \nLines in a \u201cBetter Light\u201d....................................................................................4\n1.1 Transmission Cost Allocation Methodologies...................................................5\n1.2 Demonstration of Advanced Conductors for Overhead Transmission Lines....8\n2. New Technology for Accommodating Variable Renewable Generator Unique \nBehaviors........................................................................................................11\n2.1 Critical Operating Constraints Forecasting for California Independent System \nOperator (CAISO) Decision Support..............................................................11\n2.2 Tools for Online Analysis and Visualization of Operational Impacts of Wind \nand Solar Generation....................................................................................14\nvi\n2.2.1 Transmission Forecasting Tool...............................................................14\n2.2.2 Ramping Forecasting Tool......................................................................15\n2.2.3 Day Ahead Regulation Requirement Prediction Tool..............................17\n2.3 Wide-Area Energy Storage and Management System (WAEMS) to Balance \nIntermittent Resources in the California ISO.................................................21\n2.4 Improved Generator and Load Models..........................................................23\n2.4.1 WECC Wind Generator Modeling............................................................24\n2.4.2 Load Modeling Transmission Research..................................................29\n3. New Technology for Increasing Transmission Capacity by Optimizing the Grid \nfor Greater Power Flow....................................................................................32\n3.1 New Capacity Thermal Capability..................................................................32\n3.1.1 Multi-Area Real-Time Transmission Line Rating Study...........................33\n3.2 New Capacity Voltage Stability Capability.....................................................34\n3.2.1 California ISO Real-Time Voltage Security Assessment (VSA)................34\n3.3 New Capacity Transient Stability Capability..................................................35\n3.4 New Capacity Dynamic Stability Capability...................................................35\n3.5 New Capacity Transmission Expansion Planning Capability..........................36\n3.5.1 Extreme Events......................................................................................36\n3.6 Transmission Congestion Assessment and Probabilistic Forecasting............39\n3.6.1 California Transmission Congestion Assessment...................................39\n3.6.2 Probabilistic Transmission Congestion Forecasting................................40\n3.7 New High Power Flow Managing Capability...................................................42\n3.7.1 Development of Fault Current Controller Technology............................43\n3.8 Real-Time System Operations.......................................................................49\n3.8.1 A Business Case Study on Applying Synchrophasor Measurement \nTechnology \nand Applications in the California and the Western Electricity \nCoordinating Council Grid.......................................................................49\nvii\n3.8.2 Real-Time Applications of Phasors for Monitoring, Alarming and Control\n...............................................................................................................53\n3.8.3 Real-Time Oscillation Detection, Analysis and Mitigation.......................55\n3.9 Advanced Protection Systems Using Wide Area Measurement.....................61\n3.9.1 Scoping Study of Intelligent Grid Protection Systems.............................61\n3.9.2 Advanced Protection Systems Using Wide Area Measurements.............64\n3.9.3 Application of Advanced Wide Area Early Warning Systems with Adaptive\nProtection...............................................................................................69\n4. New Cross-cutting Technology for Improving the Transmission System \nReliability, Flexibility and Resiliency................................................................74\n4.1 Increased Robust Seismic Performance of Transmission Substation \nComponents..................................................................................................74\n4.1.1 Evaluation of the Seismic Performance of High-Voltage Transformer \nBushings.................................................................................................74\n4.1.2 Seismic Performance of Substation Insulator Posts for Vertical-Break \nDisconnect Switches...............................................................................77\n4.2 Energy Storage..............................................................................................79\n5. Electric Distribution System and Renewable Generation Integration..............80\n5.1 Reliability of Underground Distribution Systems...........................................80\n5.1.1 Underground Cable Diagnostics Miniaturization Research, Development, \nField Test, and Commercialization..........................................................80\n5.2 Advanced Monitoring of Distribution Systems...............................................83\n5.2.1 Distribution System Field Study with California Utilities to Assess \nCapacity for Renewables and Electric Vehicles......................................83\nConcluding Statements.........................................................................87\nGLOSSARY...........................................................................................88\nviii\nES-9\nExecutive Summary\nIntroduction\nIn 2000-2001, California experienced high electricity prices and consequential \nsevere financial problems, along with electric power shortages and rolling \nblackouts. These crises demonstrated the public interest value of the electric grid, \nalong with its inadequacies and vulnerabilities, prompting the California Legislature \nto pass the Reliable Electric Service Investments Act of 2000. Other similar state \npolicy actions reflected these concerns over the readiness of California\u2019s electric \ngrid, and provided the guidance for PIER-funded research and development for that \ncritical infrastructure. The state began an expanded research effort in the PIER \nprogram to develop new technologies to enhance electric power delivery \ncapabilities. In 2002, the CEC developed the Transmission Research Program (TRP) \nin response to legislation. The primary objective of the TRP was to foster research \nthat would address critical transmission issues. \nThe Energy Commission had responsibility for the TRP and selected a contractor to \nprovide program vision and strategy development, to administer and facilitate the \nstakeholder relationships, and to deliver research results for new electric grid \ntechnologies. The California Institute for Energy and Environment (CIEE) of the \nUniversity of California was competitively selected as that contractor in 2003.\nAn advisory system of stakeholders of the electric grid community was critical for \nthe design and execution of the TRP, and for the transfer of the research program\u2019s \nresults to the end users. It helped to assure that the TRP had the right portfolio of \nresearch projects, and assisted in making the research products used and useful to \nCalifornians.  The TRP advisory structure brought together informally electric grid \ntechnology \u201cresearch\u201d experts from academia, national labs, architect engineers, \nproduct vendors and consultants to focus on specific grid-related problems. \n\u201cDeliver a kilowatt-hour from anywhere to anyone at any time\u201d was the TRP Policy \nAdvisory Committee vision statement of the ideal transmission system. Mission \nsuccess depended critically on avoiding blackouts and enabling the consumer to \naccess clean, low-cost, reliable electricity.\nChallenges Facing the California Electric Grid and \nShaping the PIER TRP\nAfter 2000\u20132001, the electric grid in California faced the consequences of two \ndecades of under investment in transmission, and increasing difficulty with siting, \npermitting and building new transmission. The results were rising electricity costs \ndue to congestion, and later, a threat to the state\u2019s renewable energy generation \ngoals. Attempting to increase economic efficiencies and maintain reliability, while \naccommodating new power markets and new generation technologies and loads, \ntransmission operators were impaired in their ability to plan, dispatch and regulate \ngeneration. The ever-increasing reliance on long-distance multi-state transmission \nlines in the western U.S. electric grid increased the risk of large widespread \nES-1\noutages, such as the 1996 blackout in the western U.S. caused by growing \ndestabilizing dynamic power flow behaviors. Reductions in transmission capacities \nto provide more margins for operators to better manage instabilities, increasing \neconomic inefficiencies and congestion. The lack of wide-area, real-time system \nvisualization by operators was painfully apparent, which gave rise to the \ndeployment of synchrophasors, an emerging monitoring technology that was \nexpected to do for transmission system diagnostics what magnetic resonance \nimaging (MRI) did for medical diagnostics versus old-fashioned X-rays.\nExtreme events, such as the cascading blackout described above, shook public \nconfidence in electric grids. Lawmaker and regulatory actions, such as the U.S. \nEnergy Policy Act of 2005, toughened operational requirements, creating additional \ncomplexity for grid operations and planning. New technologies, such as demand \nresponse and distributed generation, offered opportunities for improved grid \noperations, but only if the challenges of integrating these technologies with the \ndistribution and transmission systems could be overcome. More recently, and most \nsignificantly, the growth in renewable energy electric generation has further \nchallenged grid operations.\nIn 2006, the California legislature directed the PIER TRP to emphasize renewable \nenergy delivery, along with reliability and costs of the power grid, to be consistent \nwith emerging energy policy in the state, which was driven to reduce greenhouse \ngas emissions. Most of the problems described above facing the electric grid in \nCalifornia would still need to be addressed in order to facilitate the integration of \nrenewable generation with the electric grid. In addition, the integration of many \nrenewable generators \u201cfueled\u201d by variable wind and solar energy resources called \nfor an additional new TRP focus on technology solutions for the challenges unique to\nthese particular generators.\nWith the advent of variable renewable generation in the electric grid, for the first \ntime in history electric generators did not come with built-in energy storage, \nnamely, in the forms of stored fuel and the inertia of the rotating mass of the \nelectric generator. Most solar and wind powered generators cannot be run with \ncertainty and consistency. Additionally, instead of using rotating generators, solar \nand wind generators usually use electronic power conversion equipment which \ntends to ramp (i.e., increase or decrease power output) much faster than the \ntraditional power plants for which the electric grid was designed. California\u2019s \naggressive goals to increase the fraction of electricity generated by renewables, at \nthe transmission and, more recently the distribution levels, made these issues real, \nposing challenges for timely and adequate grid delivery capacity, maintaining \nreliability and power quality, and avoiding economic inefficiencies. \nNew or expanded capabilities for the grid would be needed. In the beginning, \nbuilding new transmission and distribution infrastructure using traditional \u201cwires\u201d \ntechnology seemed sufficient, but as time passed it became increasingly clear that \nnew technologies offered the prospect of providing a substantial portion of the new \nor expanded capabilities, and would be needed to supplement the traditional \n\u201cbuild\u201d solutions. \nES-2\nMany of these new technologies required additional development before they could \nbe commercially or routinely deployed. The process for identifying the research \nactivities of most value started with identifying the most critical issues facing the \nelectric industry community, and matching new technologies to address those \nissues. However, there often were gaps between the current and desired status of \neach technology. These gaps were identified along with the research, development \nand demonstration needed to work toward closing the gaps. The degree of success \nof this process depended largely on obtaining the best and latest knowledge \nregarding policy, industry and technology by engaging public and private \nstakeholders and technology developers.\nThe TRP Strategy\nEmerging technologies offered solutions if they could be developed and \ncommercialized. The TRP pursued a set of evolving technology research strategies \nthat focused on new technologies to provide faster access for new, remotely located\nrenewable power plants by putting new transmission lines in a \u201cbetter light\u201d \nthrough streamlining of the siting process, use of advanced counductors and other \nmeasures; accommodate unique aspects of variable renewable generators through \na smarter and more flexible transmission and distribution grid; and increase the \ntransmission capacity of the grid through improved hardware and \u201csmart grid\u201d \nenhancements.\n1. New Technology for Providing Access to the Grid by \nPutting New Transmission Lines in a \u201cBetter Light\u201d\nFor many remote renewable power plants, access to the transmission system \nmeans building new transmission lines between the power plant and the existing \ntransmission grid. The time to site and permit a new transmission project can now \nbe around 10 to 12 years for a major line, which is longer than it takes to build the a\nrenewable power plant, and increases costs. The major barriers to building a new \ntransmission line are societal resistance to siting, e.g., \u201cnot in my backyard,\u201d and \nbenefit identification and cost allocation.\nTwo general approaches were taken to put new transmission in a \u201cbetter light.\u201d  \nOne helped the public, and other concerned parties and decision makers, to better \nunderstand and communicate the costs and benefits \u2013 both economic and strategic \n\u2013 of transmission projects. The other approach reduced the visual profile and other \nenvironmental and siting impacts of a transmission line.\n1.1.Transmission Cost Allocation Methodologies\nThis project documented case histories for addressing the cost allocation problem \nand developed new methods and approaches for expanding the planning tools for \nmaking these investment decisions and sharing in the cost of transmission projects, \ni.e., cost allocation. There was a need to research new approaches for assessing \nbenefit streams, beneficiaries, and quantification of benefits for cost allocation and \ncost recovery for new transmission investments.\nES-3\nUse of a screening tool can perform quick what-if screening analyses, but it is not a \nsubstitute for detailed production costing simulation for comprehensive benefit \nanalysis. In economic transmission projects, the principle of \u201cbeneficiaries pay\u201d \nshould be the basis for cost allocation. \nThe primary benefits of transmission, such as improved network reliability, were \nusually well identified in most proceedings, but some other categories of benefits \nwere not. Since the transmission system had increasingly become a public good, \nthe use of social rate of discount, instead of allowed weighted cost of capital, was \nrecommended for calculating the present worth of benefits of a new transmission \nproject. Additional research was identified as needed to quantify societal benefits of\ntransmission in providing insurance value against extreme events that are low-\nprobability/high-impact events. (see 3.5.1. Extreme Events)\nA project presentation to the California Public Utilities Commission (CPUC) led the \nCalifornia Division of Ratepayer Advocates (now the Office of Ratepayer Advocates) \nto file a motion in 2008 to supplement the record for Investigation \n08-03-010/Rulemaking 08-03-009 pertaining to an Order Instituting Investigation on\nthe Commission\u2019s Own Motion, so actively to promote the development of \ntransmission infrastructure to provide access to renewable energy resources for \nCalifornia.\n1.2.Demonstration of Advanced Conductors for Overhead \nTransmission Lines\nAs loading on the electric system increases, transmission lines approach their limits \non the amount of power they can carry, at which point transmission line conductors \nare often replaced with ones of higher capacity. But there is a limit to how much \ngreater the replacement conductor diameter can be. To avoid high costs of \nrebuilding the line, it could be cheaper to use advanced conductors allowing higher \npower flow with a form factor similar to the old conductor.\nThis collaborative project, led by the Electric Power Research Institute (EPRI), \nevaluated the operational performance of advanced High-Temperature, Low-Sag \n(HTLS) conductors over three years. Five specific designs of HTLS conductors were \nevaluated: Aluminum Conductor Steel Supported/ Trapezoidal Wire, Gap-type \nAluminum Conductor Steel Reinforced, Aluminum Conductor Invar Steel Reinforced, \nAluminum Conductor Composite Reinforced, and Aluminum Conductor Composite \nCore. Key information is provided on design, installation, operation, and \nmaintenance of selected HTLS conductors and their hardware accessories. The \nproject involved field trials with CenterPoint Energy, HydroOne, Arizona Public \nService, and San Diego Gas & Electric (SDG&E). The report provides data and \ninstrumentation details for each site.\nThe project objectives were to gain practical experience in handling, installing, and \nterminating new types of conductors developed by manufacturers for use in high-\nvoltage transmission lines, and to verify in practice the claims of manufacturers \nregarding their performance in an operating transmission line.\nThis project documented stringing, sagging, and clipping in commercially available \nHTLS conductor systems and evaluated the actual physical behavior of HTLS \nES-4\nconductors in operating transmission lines. The results of this work will help utility \nparticipants choose when to use such conductors, how to choose between various \ntypes, and how to avoid problems during installation and over the life of the line.  \nCIEE acted as the coordinator for the field test at SDG&E.\nDepending on the uprating situation, stress-strain models for each of the HTLS \nconductors are available for utility engineers to evaluate which systems are most \nappropriate. The best conductor choice depends on the existing clearance buffer, \noriginal design margins, environmental loading conditions, and the desired rating \nincrease. This study shows how HTLS conductors can be successfully used to obtain \nthermal rating increases of at least 50 percent, thus minimizing the need for \nmodifications or replacement of expensive structures, e.g., transmission tower.\n2. New Technology for Accommodating Variable \nRenewable Generator Behaviors\nTechnologies that lessen the impact of variable renewable generation help electric \ngrid operators react to problems such as especially fast power ramp rates \ncharacteristic of solar and wind generators, and to better forecast variable \nrenewable behaviors. \nSolar power characteristically ramps up in the morning and down in the evening \nwith no nighttime output, but with a power profile that varies with the season. Solar \nphotovoltaic (PV) generators use solid-state inverters without the physical inertia \ndescribed earlier, and they will react much more quickly to transients. Little was \nknown about the effects of large penetrations of these low-inertia generators on the\ntransmission and distribution systems.\nWind power tends to be higher at night in California and also is subject to short-\nterm variability from changes in wind speed. The dynamic behavior of wind \ngenerators is different from typical thermal generators and generally has lower \ninertia. Generator models used for transmission planning did not accurately model \nwind generator behavior in the transmission system, and increased the level of \nuncertainty for the operator and threats to reliability. \nThe power ramp rates for both solar and wind generators are faster compared with \nconventional utility generators, and can pose challenges in maintaining reliability, \npower quality, and low regulation and ancillary costs.\nThe TRP focused on developing \u201csmart\u201d technologies that would help operators \nreduce uncertainty and minimize costs by forecasting the future state of the grid. \nThe TRP also advanced the development of an analytical modeling tool to reduce \nthe costs of managing renewable generation through the optimum shared use of \nresources such as energy storage, demand response and distributed generation \namong control areas over a wide region. Likewise, research was done to improve \nand update load and generator models used for planning in the WECC and California\nelectric grid thereby improving the capability to maintain reliability.\nES-5\n2.1.Critical Operating Constraints Forecasting for California \nIndependent System Operator Decision Support\nWhen transmission resource margins become very short, knowing in advance when \nand how severe various transmission operating constraints become of significant \nvalue to the grid operators. During the 2005 summer season, the California \nIndependent System Operator (CAISO) encountered conditions of very tight \nresource margins and serious congestion problems in Southern California. In \nanticipation that conditions in future summers could likely be much worse due to \nincreasing demand for electricity and the limited transmission capacities into \nSouthern California, this research project was initiated. Avoiding a blackout can \npotentially save Californians hundreds of million dollars or more. The risk of \nblackouts will likely increase in the future with the high penetration of renewable \ngeneration, power markets and new electric customer appliances and equipment, \nso improvements in forecasting critical operating constraints could yield significant \ncost savings, help achieve California\u2019s policy goals for CO2 reduction, and provide \nreliable and low cost electricity to the State\u2019s power consumers with minimum \nenvironmental impacts. \nThe main goal of this research project was to provide CAISO with the decision \nsupport capability to look ahead for the next 24 hours and predict whether the \nsystem will be able to get through the day without running into critical operating \nconstraints. Specific objectives were to enable the simulation of various scenarios of\npower importation or other alternatives such as load reduction to find the best way \nto avoid such problems and to provide a functional specification for the \ndevelopment of a commercial version of the tool. \nThis project consisted of the development of a prototype tool based on the Electric \nPower Research Institute (EPRI) Community Activity Room that was evaluated using \nhistorical data and its predictions were compared with actual observations. The \nresults of the research were presented in a workshop November 7, 2007 in Folsom, \nCalifornia, with the intent to make this technology available to any commercial \nsoftware developer who wished to turn this method into a commercial product. \nThis project successfully developed the methodology for Critical Operating \nConstraint Forecast (COCF) tool, and used it in a prototype with support from CAISO \nfor testing and demonstration. The results showed that this method is capable of \nforecasting loading of transmission paths over the next 24 hours, using current data\non the transmission paths flows and assumptions about where the generation deficit\nwould be supplied for the rest of the day. \nThe significance of this project is that a technically viable tool can be developed by \ncommercial vendors of Energy Management Systems, using the functional \nspecifications in a companion report of this project, which was presented and made \navailable at the workshop mentioned above. The knowledge for developing such a \ndecision support tool is now in the public domain. \nEPRI continues to use the techniques of the COCF work in developing an industry \ntool for Visualization of Operating Boundaries and conducting research in support of\non-line analysis and situation awareness in the control center. The research results \nES-6\nwere also used in a PhD thesis at Stanford, and in numerous professional \npresentations and publications.\n2.2.Tools for Online Analysis and Visualization of Operational \nImpacts of Wind and Solar Generation\nTo facilitate more economical high penetration of renewable resources without \ncompromising system reliability, three tools were developed for the CAISO power \ngrid operators to predict and display operational impacts of uncertainties in \nforecasts of loads and renewable generation. The first tool (\u201cRamping Tool\u201d) \naddressed real-time capacity and ramping requirements, the second (\u201cTransmission\nTool\u201d) addressed voltage stability and transmission congestion, while the third tool \n(\u201cDay Ahead Regulation Tool\u201d) predicted capacity, ramping rate and ramp duration \nrequirements of regulation, including upward and downward requirements, for each \noperating hour of a day. The Ramping Tool became an industry-grade product \nconnected to the CAISO systems and operated in real time in the CAISO Control \nCenter. The Transmission Tool and the Day Ahead Regulation Tool have been \ndeveloped to the prototype stage.\n2.2.1. Transmission Forecasting Tool\nThis work was to develop a prototype tool to identify transmission problems posed \nby the variability of wind and solar generation, 1 to 3 hours ahead, and inform \noperators about potential risks for the purposes of early warning and preventive \ncontrol. The transmission tool prototype demonstrates the key features and \nadvantages of the methodology developed, but development and integration with \nvendor-supported software at CAISO are necessary for deployment. \nAfter the start of this project, CAISO implemented a PIER-funded real-time voltage \nstability analysis tool (see 3.2.1. CAISO Real-Time Voltage Security Assessment \n(VSA)), and advanced visualization and data processing tools. Based on the \nrecommendation of the CAISO project support team, a decision was made to \ndevelop a transmission tool prototype and a methodology integrate it with the VSA \nand visualization tools already installed and used by CAISO. The connectivity issues \nwere addressed in this effort from the methodology and system model perspective \nto provide future connectivity of the future industry-grade applications with the \nCAISO systems.\nThe developed methodology was based on statistical simulations and analyses of \nvarious sources of uncertainty that can impact the transmission network. The \ndeveloped methodology also included a linear power flow model to calculate \nincremental active power flows in the transmission network caused by forecasting \nerrors.\nThe prototype tool that was developed demonstrated the methodology, design \nconsiderations, system architecture, simulation results, and the graphical user \ninterface. The power system model and the methodology to determine the \nprobabilistic thermal congestion limits based on power transfer distribution factor \nwere presented. The five key system modules, i.e., power flow module, power \ntransfer distribution factors module, forecast error module, probability congestion \nmodule and interface module, were also demonstrated. Future work needed is to \nES-7\ninstall and test the tool in a real control center using actual system models and \ndata.\n2.2.2. Ramping Forecasting Tool\nThe power system process that balances supply and demand, which includes \nscheduling, real-time dispatch (load following), and regulation processes, is \ntraditionally based on deterministic models.\nUncertainties in forecasting the output of variable resources such as wind and solar \ngeneration, as well as system loads, were not reflected in existing energy \nmanagement systems or tools for generation commitment, dispatch, and market \noperation. With the growing penetration of intermittent resources, these \nuncertainties could result in significant unexpected load-following and dispatch \nproblems, and pose serious risks to control and operation performance as well as to \nthe reliability of a power grid. Without knowing the risks posed by the uncertainties, \nsystem operators had limited means to weigh the likelihood of occurrence and the \nmagnitude of problems to mitigate adverse impacts caused by them. Some \nimportant questions needed to be addressed in counteracting the impact of \nuncertainties; for instance, whether and when one should start more units to \nbalance against possible fast ramps from renewable generation.  Providing the \nability to forecast generation ramping requirement s made this research project a \nsignificant step forward toward the objective of incorporating wind, solar, load, and \nother uncertainties into power system operations.\nA probabilistic algorithm was created to assess the capacity and ramping \nrequirements, and a simulation was performed using the CAISO system model and \ndata.  Innovative methodology and software tools were developed to evaluate \nfuture generation requirements, including the required capacity, ramping capability,\nand ramp duration capability. The approach includes three stages: 1) forecast and \nactual data acquisition, 2) statistical analysis of retrospective information, and 3) \nprediction of future grid balancing requirements for specified time horizons and \nconfidence intervals. \nAs stated earlier, this tool has been put into routine use at the CAISO.  \n2.2.3. Day Ahead Regulation Requirement Prediction Tool\nRegulation provides minute-to-minute system balance by adjusting power output of \nunits connected to the automatic generation control system. At the time of this \nresearch effort, the annual price of regulation exceeded $120 million in California.  \nCAISO is concerned that the increasing penetration of variable renewable resources \nin California could add to the amount of regulation needed. The loss of the \nregulation capability from the retirement of \u201conce-through cooling \u201d generating \nunits located along California\u2019s Pacific coast was expected to compound the \nsituation. (Unknown at the time, the later shutdown of the San Onofre Nuclear \nGenerating Station exacerbated this problem.)\nThese challenges motivated CAISO to obtain a tool capable of predicting the needed\nprocurement of up- and down-regulation services in the day-ahead market.\nES-8\nThis project developed an approach for procuring regulation capacity that would \nminimize the regulation capacity required during some operating hours without \ncompromising CAISO\u2019s control performance characteristics.  Three methods were \ndeveloped that differed by the approach used to calculate the regulation \nrequirement and by the type of control performance criteria used. All three methods\nuse historical information, obtained prior to the analyzed operating day (a moving \nwindow for a user-specified period). A prototype tool for estimating regulation \nrequirements accommodating the new control performance standard was \ndeveloped and simulations showed that CAISO regulation requirements could be \nsubstantially reduced.\nThe project identified next steps that would increase the robustness and \nperformance of the prototype tool, while handling imperfect information typically \navailable in control centers.  \nThe results of these three research efforts just described have been used for \nnumerous follow-on or related funded efforts (about $4 million) that complement \nthe PIER funding. The CAISO is modifying the Ramping Tool to move it to production\nlevel for 24/7 operation in the Control Center. Building on this research, AWS \nTruepower (project manager), CAISO, Southern California Edison (SCE), and \nSiemens are participating in a DOE SunShot project, \u201cComprehensive Solutions for \nIntegration of Solar Resources into Grid Operations,\u201d to demonstrate integration of \nuncertainty information into grid system operations and probability-based controls. \nBased on the Ramping Tool development, a Dynamic Interchange Adjustment tool \n(DINA) was developed for Independent System Operator-New England (ISO-NE). This\nprobability-based tool predicts the secure range of intra-hour interchange \nadjustments to trading balancing capacity with the neighbors. ISO-NE intends to \nmove the tool to a production level. Some key concepts developed in this research \njust described will be used for new research projects in predictive state estimation \nbeing done by Pacific Northwest National Laboratory, who was the principal \ninvestigator and developer for these three tools with Bonneville Power \nAdministration (BPA) and DOE.\nUse of some of the tools for online analysis and visualization of operational impacts \nof variable renewable generation demonstrated the capability to eliminate real-time\nmarket price spikes. For example, ISO-NE will be able to show other ISOs that its \nbalancing capacity can be traded with its neighbors without compromising its grid \nperformance and reliability.\n2.3.Wide-Area Energy Storage and Management System (WAEMS) to\nBalance Intermittent Resources in the California ISO\nThe higher penetration of variable renewable generation resources in the CAISO and\nBPA control areas may require expensive additional fast grid balancing services and\nfast up and down power ramps in the electric supply system. The successful use of \nwide-area energy storage to reduce the need for more expensive fast acting \nbalancing services depends, due to statistical fluctuations, on the collective power \ngrid regulation of the two control areas being less than the sum of individual area \nneeds. This issue was addressed through the exchange of variable renewable \nenergy between the participating control areas and the use of energy storage, \ndispatchable load, and distributed generation resources. \nES-9\nThe goal of the multiphase effort was to develop principles, algorithms, market \nintegration rules, functional design and technical specifications for a wide-area \nenergy storage and intermittent energy exchange management system to mitigate \nunexpected rapid changes in wind generation power output. The results of this \nphase provided specific numerical information necessary for a detailed wide-area \ndesign system design.\nAn evaluation showed excellent performance of the control algorithm, which \nseparates the faster regulation effort provided by the energy storage from the \nslower one provided by a conventional regulating unit. The WAEMS combined \nservice has the same fast-response characteristic (within six seconds) as that \nprovided by flywheel energy storage alone, the fast acting energy storage used in \nthis project, and reduces wear and tear to allow the hydro unit to operate more \neffectively.\nThe break-even price for flywheel energy storage to provide bi-directional service (1\nMW regulation-up and 1 MW regulation-down) at the time was $20.37/MW. Because \nthe average bi-directional regulation price of the CAISO balancing authority was \n$11.95/MW (January-July, 2010) and that of the BPA balancing authority was $9.38/\nMW (2010), regulation service provided by a stand-alone flywheel energy storage \nwas projected not be economical unless the regulation price increased or the fast \nregulation service would be paid at a higher rate. Assuming that the minimum \nregulation price of regulation provided by a hydro power plant was $4/MW, the \nbreakeven price of the combined flywheel-hydro regulation service was calculated \nto be $12.19/MW; therefore, the flywheel-hydro regulation service breakeven price \nis found to be slightly higher than the average CAISO ($11.95/MW) and BPA ($9.38/\nMW) regulation prices. Because regulation prices are expected to increase when \nmore renewable generation resources are integrated into the power grids, the \nflywheel-hydro regulation service was expected to become economical in the CAISO\nand BPA balancing authorities soon.\nThe technology developed potentially enables a 50 percent or more reduction in the\nregulation capacity requirement when implemented. Utilization of this approach by \nutilities is currently pending. This research resulted in almost a dozen professional \npublications.\n2.4.Improved Generator and Load Models\nIt is important for grid planners and operators to be able to forecast how various \nelectric grid components will behave under stressed conditions. Generator and load \nmodels are used in computer simulations of the electric grid to predict power flows \nand dynamics under different circumstances. Variable renewable generators and \nnew types of consumer appliances, as well as distributed generators, connected to \nthe electric grid are rendering the old generator and load models inadequate. This \nsituation threatens the planning and operation of a reliable and cost-efficient \nelectric supply and delivery system. \nES-10\n2.4.1. WECC Wind Generator Modeling\nOlder wind turbine models used in transmission system planning and reliability \nanalyses were inaccurate, and did not represent the new generation of wind \nmachines correctly, adversely affecting economic and reliable operations.  \nProprietary models of wind turbine manufacturers for specific generators were not \nappropriate for use in a collaboratively controlled transmission system such as the \nWECC, including California, creating a need for developing standard, non-\nproprietary wind turbine models. While the models were designed specifically to \nmeet WECC modeling requirements, the results could also be used by the industry \nas a whole throughout the world, thereby advancing the deployment of wind power \nglobally.\nThis research project, which was a joint effort of the California PIER TRP and DOE\u2019s \nNational Energy Renewable Laboratory (NREL), improved transmission planning and\noperating modeling tools needed to better prepare the transmission grids in \nwestern North America to accommodate growth in wind power generation to meet \nRenewable Portfolio Standard goals, especially California\u2019s. These are the first-ever \naccurate, non-proprietary models of the various types of wind turbines in \ncommercial use today, and are now in the permanent library of software for General\nElectric\u2019s Positive Sequence Load Flow, Siemens Power Technologies International\u2019s \nPower System Simulator for Engineering (PSSE), and PowerWorld\u2019s Simulator, used \nby grid managers around the world. The widespread adoption of these models \ndeveloped and validated in this research helps assure a competitive source of \ncommercially available software compatible with California\u2019s electric grid needs, \nand its on-going maintenance and updating. This project also developed an \nequivalencing methodology, validated by Hydro Quebec, to aggregate individual \nwind generators into a model that represents an entire wind power plant.\nThis research created far-reaching interactions among many entities in the wind \ngeneration industry around the world.\nCAISO is benefiting in its studies of integration of renewables into the California \ngrid.  It also helped to build a bridge between the power engineering and wind \nenergy communities to improve California\u2019s ability to add renewables reliably to the\ngrid. \nThis research has been identified by the National Energy Reliability Corporation \n(NERC) as an area of significant need in the report of the NERC Integrating Variable \nGeneration Task Force as being in the national interest by providing a secure power \ngrid. The result of this work are in line with FERC Order 661 and 661A and are in the\nnational interest in providing a secure and reliable power system grid.\nThese wind generator dynamic models formed the foundation of other renewable \nenergy dynamic models.  For example, the WECC PV dynamic model was developed\nbased on the Type 4 Wind Turbine Generator dynamic model developed and \nvalidated in this research project. The dynamic model of Adjustable Speed (AS) \nPumped Storage Hydro (PSH) power plant was developed based on the Type 3 Wind\nTurbine Generator dynamic model..  This AS-PSH model is currently being \nimplemented as a \u201cuser defined model\u201d on the PSSE software platform before \nES-11\nmoving to the permanent PSSE library. These dynamic models were also \nimplemented, with some technical support from NREL, on the PSCAD \u00ae platform by \nNREL and implemented on the RSCAD \u00ae platform, which is the main interface for \nReal Time Digital Simulation used by SCE.\nEducation has also benefited from this research project. The Equivalencing Wind \nPower Plant method developed is being used in Power System courses. These \ndynamic models have been implemented by the national Power Systems \nEngineering Research Center (PSERC) and its academic members as planning tools, \nresearch tools, and teaching materials for power engineering students. \nBecause of the widespread impacts this research has had, numerous follow-on \nresearch projects have been spawned around the world. The DOE Office of Energy \nEfficiency and Renewable Energy has funded subsequent works related to Solar/PV \ndynamic modeling (NREL and Sandia National Laboratory) and Adjustable Speed \nPump Storage Hydro AS-PSH (NREL, Idaho National Laboratory, and Argonne \nNational Laboratory) in both positive sequence dynamic modeling and \nelectromagnetic transient modeling. The WECC Renewable Energy Modeling Task \nForce continues with extension of the WECC Wind Generation Modeling. As a follow \non project, the WECC Renewable Energy Modeling Task Force has developed \n\u201cSpecification of the Second Generation Generic Models for Wind Turbine \nGenerators\u201d prepared under Subcontract No. NFT-1-11342-01 with NREL \n(collaboration between NREL, Sandia, EPRI, and WECC). Tutorials on dynamic \nmodeling for renewable energy are offered periodically to the members of the \nWECC, which included California utilities. Numerous workshops and professional \npublications have been based on this research. All of these works have benefited \nand have leveraged the previous work of the PIER-funded WECC Wind Generator \nModeling research.\n2.4.2 .Load Modeling Transmission Research\nExisting dynamic load models do not correctly represent actual observed modern \nload behavior. For example, the dynamic effects of the addition of residential and \ncommercial solar photovoltaic generators on nearby customer loads are largely \nunknown. Fault Induced Delayed Voltage Recovery (FIDVR) caused by the stalling of\nresidential air conditioners after a brief power instability, was another important \nmodern load behavior occurring in Southern California and the U.S. Southwest not \nadequately modeled that urgently needed resolution because it threatened the \nsecurity of the California and WECC grid.\nThis research addressed the voltage instability in Southern California that occurred \nafter a brief voltage disturbance in the electric grid. Load modeling improvement \nresolves this problem through better predictability of damping and stability issues \nrelated to the California-Oregon Intertie critical to the security of the California and \nentire WECC system. Better understanding of anticipated network behavior aided in \nplanning for the appropriate deployment of electric grid infrastructure investments. \nIt sought to improve the accuracy of dynamic load models used in power system \nanalysis and simulation tools by providing (1) an accurate model of residential air \nconditioners, (2) potential solutions to FIDVR, and (3) tools and methodologies for \ndetermining the mix and balance of different types of electrical loads. This project \nalso included a scoping study that investigated the impact of increasing penetration\nES-12\nof residential and commercial photovoltaic systems on load modeling accuracy. This\nresearch was a coordinated effort by members of the WECC to enhance the \nunderstanding of the behavior of loads, especially air conditioners, and to improve \nsimulations of dynamic behavior of the power system. Because of the prevalence of \nthis problem in Southern California, SCE was one of the leaders of this research, \nwith PG&E and SDG&E as significant contributors. Significant staff time was \nprovided by a number of utilities and grid operating entities in the Western \nInterconnection in reviewing and implementing the composite load model. Two \nmajor project participants, SCE and BPA, made in-kind contributions of \napproximately $170,000 and more than $1M, respectively.\nExtensive testing of single-phase residential air conditioners, under various voltage \nand frequency transients, resulted in both an accurate dynamic model and \nconfirmation of air conditioners as the cause of FIDVR. A new load composition tool \nto help build load models for simulations was developed. An uncertainty analysis \nwas completed that led to a recommendation for future load monitoring to validate \nthe tool. Manufacturing standards were recommended to deal with the issue in the \nlong term. \nDissemination of project results was accomplished via the WECC Load Modeling \nTask Force, conference presentations, technical papers, and interactions with \nutilities and air conditioning unit manufacturers.\nThis research paved the way for the development and implementation of the \ncomposite load model \u2013 the most significant grid modeling advancement of the last \ndecade, and has been implemented in all major commercial grid simulators used in \nNorth America (see 2.4.1. WECC Wind Generator Modeling). The model has been \napproved for planning and operational studies in the WECC, including California, \nwhich are used to make capital investments in the power grid and compliance with \nNERC Reliability Standards. The operating studies are used to set system operating \nlimits. The electric grid planning and operations in California and the WECC are \nbetter prepared with the potential to reduce large-scale system outage caused by \nFIDVR.\n3. New Technology for Increasing Transmission Capacity \nby Optimizing the Grid for Greater Power Flow\nUnderinvestment in transmission infrastructure in the latter decades of the 20th \ncentury had resulted in congestion and threats to reliability, and was a barrier to \nmeeting California\u2019s renewable energy goals.\nTransmission lines have physical limits on the amount of power that can be \ntransmitted, which depend on the conditions of that particular line and the broader \nwide-area transmission grid. There are two fundamental classes of limits, thermal \nand stability, the latter of three types: voltage, transient and dynamic. The \ntechnological sophistication of situational monitoring was never accurate or precise \nin the past, conservative static operating limits had been set that were often far \nbelow the physical limits, which in effect de-rated the capacity of a line, often by 20 \nto 50 percent or more. \nES-13\nEmerging technologies could reduce the margins of operating limits required for \nsafety, and even raise the physical limits, thereby adding substantial \u201cnew\u201d \ncapacity without building new transmission lines or reducing reliability. These \ncapabilities would prove vital to meeting renewable energy goals if building all \nneeded transmission capacity falls short, especially in dense urban load centers. It \nmight be preferred as a cheaper way to get greater transmission capacity through \noptimizing operations for greater power flow.\n3.1.New Capacity Thermal Capability\nThermal limits are static constraints imposed on the amount of power or current a \nline can carry, under all anticipated conditions, before reaching limiting \ntemperature, above which excesive line sag or physical damage may occur. The \nTRP explored ways to relax the conservative static limit by enabling current flows \ncloser to the real physical limit through real- time \u201cthermal\u201d rating monitoring, \nyielding incremental capacity increases. It also sought to increase the physical \nthermal limits through new line conductor material technologies. These new \nmaterials could handle considerably higher temperatures without excessive sagging\nor damage. They did, however, require some special handling during installation \nbecause of a greater susceptibility to damage from excessive bending. New \nconnectors and special splices were required in some situations. TRP monitored a \nfield demonstration of one of these new conductors at a California Independently \nOperated Utility (see 1.2. Demonstration of Advanced Conductors for Overhead \nTransmission Lines).\n3.1.1.Multi-area Real-Time Transmission Line Rating Study \nPrior PIER research showed that thermal limits and voltage limits interact to cause \ncombined dispatch restrictions in California\u2019s transmission network. This project \nfocused on finding solutions to this problem, using the Sacramento area as a test \nbed because thermal limitations in the Sacramento area interacted with voltage \nconstraints to restrict economy energy imports into the area. \nThe objectives of this project were to identify conditions where combined \nconstraints restricted dispatch, and to investigate prediction of line ratings in the \ntimeframe that would be useful for dispatch purposes.\nThe project found that one of the key limitations on economy power imports into the\nSacramento area was the thermal static line rating of the O\u2019Banion-Elverta 230 kV \ncircuits, which resulted in at least three curtailments of the Sutter hydro generation \nfacility during the time period of the study. Increasing the thermal rating above the \nstatic limit of the O\u2019Banion-Elverta circuits by 20 MW with real-time thermal ratings, \nthe minimum possible during the curtailment periods, could increase import \ncapacity to the area by over 250 MVA, or by about ten times, due to increased flow \nnow allowed on adjacent circuits in addition to the O\u2019Banion-Elverta lines.\nExtensive studies of various available rating prediction algorithms were conducted. \nNone of the algorithms were found to have acceptable accuracy for predicting \nratings in the targeted time range of 4-24 hours. The day-to-day rating patterns \nusually exhibited a high degree of similarity, especially during the summer, but the \nactual predictability of rating values varied greatly. The O\u2019Banion-Elverta circuits \nES-14\nhad a median real-time rating of approximately150 percent of the static rating, but \nonly a 110-115 percent capability with a probability of 90 percent during the most \ncritical loading periods (late afternoon \u2013 early evening). Conversely, the lowest real-\ntime ratings could occasionally be slightly below the static rating. Ratings were \nalways safely over the static rating at night, but the circuits were never heavily \nloaded.\nRatings had \u201cpersistence\u201d even though they were not sufficiently predictable to be \nused for daily dispatch purposes. That is, ratings could increase rapidly during a \nstorm, for example, but ratings could not decrease rapidly, which would require \neither a rapid increase in ambient temperature or an abrupt reduction of kinetic \nenergy in the atmosphere. Persistence of ratings could have a major impact on the \nmanagement of contingency events in the network. It could increase operating \neconomies because operators could either avoid changes in system dispatch, or \nminimize them via other available remedies. It could also substantially increase \nsystem reliability, especially during times of high system loads.\n3.2.New Capacity Voltage Stability Capability\nOperators may not know how susceptible the system is at any given time to \nundesirable voltage changes as a function of power transfer, which could lead to \nvoltage collapse and a resulting blackout. Voltage stability constraints on power \nflow capacities of lines are intended to provide margins for safety in the absence of \nprecise knowledge.  The TRP developed and demonstrated a predictive analytic and\nmodeling voltage security analysis tool for improving situation awareness and \npermitting smaller, better defined, constraint margins. Rights to the technology \nwere obtained by a vendor that commercialized the new tool.\n3.2.1. California ISO Real-Time Voltage Security Assessment (VSA)\nAnalysis of over two dozen blackouts indicated a need for developing real-time tools\nfor monitoring system voltage security margins under normal and contingency \nconditions. Use of real-time security monitoring on a regional scale would prevent \nfuture voltage collapses. Following the June 2-3, 1996, major blackout in the WECC \nsystem, including California, DOE recommended that the WECC should consider the \nuse of real-time security monitoring on a regional scale to prevent future voltage \ncollapse events. The WECC pursued a security monitoring and analysis tool that \nwould enable operators to identify potential problems and take corrective action.  \nThis project was to provide CAISO with a prototype voltage security assessment tool\nthat runs in real-time within CAISO\u2019s reliability and congestion management system.\nThe project developed a prototype that incorporated state-of-art algorithms (such \nas the continuation power flow, direct method, boundary orbiting method, and \nhyperplanes) into a framework most suitable for operations. A functional \nspecification was prepared for a commercial grade system that CAISO has used to \nprocure a production-quality tool that is now a part of a suite of advanced \ncomputational commercial tools provided by Bigwood Systems, Inc., a developer \nand vendor of software tools for power grid assessment, monitoring, analysis, \noperation, control and optimization, located in Ithaca, NY (headquarters) and San \nFrancisco, CA.\nES-15\n3.3.New Capacity Transient Stability Capability\n The time frame for the transmission grid to regain its equilibrium after a transient \ndisturbance, such as a line fault or generator trip, is typically milliseconds to \nseconds. Generator and load models are used to plan the operating configuration of\nthe electric transmission system to anticipate and better handle transient \nbehaviors. But if the models are inaccurate, then the operating plans might not be \nable to address certain transient behaviors potentially leading to reliability and \npower quality problems. The TRP improved the generator models for wind \ngenerators, and the load models for new air conditioner technologies. These models\nare now in use in California. (see 2.4. Improved Generator and Load Models)\n3.4.New Capacity Dynamic Stability Capability\nDynamic stability is the ability of the transmission grid to regain its equilibrium over\n1-30 minutes. Problematic instabilities can manifest in a number of different \nbehaviors, with low frequency oscillations being one of the most egregious in the \nWestern grid as a reason for transmission line capacity de-ratings. Low-frequency \noscillations, which cause power to surge back and forth through wide areas of the \ngrid, typically have a period of a few seconds and can build over periods of minutes \nto hours. They have been identified as the initiating event of some costly major \nmulti-state blackouts, such as the widespread blackout in the western United States\nand Canada in 1996. The root causes of these dynamic instabilities were not all well\nknown and research was needed. There is a growing concern that these dynamic \ninstabilities might be exacerbated by changes to the electric system, such as \nrenewable energy sources that reduce system inertia and add more uncertainty, \nand energy efficient loads that introduce new dynamics, as well as uncertainty (see \n2.4. Improved Generator and Load Models). \nThe TRP conducted a significant number of research efforts to develop and \ndemonstrate stability operating tools based on synchrophasor measurements, \nwhich were new current and voltage measurement devices using time-stamping \nthat for the first time enabled wide-area real-time status and event monitoring, \ndetection, alarming, analysis, and visualization. The resulting tools enhanced the \noperator awareness for greater reliability and promised the transmission system the\nability to use smaller dynamic margins. In conjunction with certain control \ntechnologies, for example energy storage, these tools might be used to mitigate \ndynamic instability threats, such as to damp oscillations. \nThe TRP conducted a business case study for the use of synchrophasor \nmeasurements that examined applications and their economics, and include a \nroadmap for technology development (see 3.8.1. A Business Case Study on \nApplying Synchrophasor Measurement Technology and Applications in the California\nand the Western Electricity Coordinating Council Grid). This study provided \nguidance for California. It encouraged TRP research in synchrophasor measurement \nbased tools for rapid oscillation detection, analysis and mitigation; enhanced state \nestimation; smart adaptive relaying to prevent protection system actions from \naggravating cascading blackouts; and voltage angle changes for stress indication.  \nThe TRP also contributed to the development of the platform for gathering and \nmanaging synchrophasor measurement data, and enabling application deployment. \nMuch of this research has resulted in commercial products and uses.\nES-16\n3.5.New Capacity Transmission Expansion Planning Capability\nTraditional deterministic planning tools increasingly became inadequate to support \naccurate expansion planning in a future of growing uncertainty and complexity, \nwhich was expected partly because of the growing use of variable renewable \ngeneration. The TRP anticipated that new planning tools based on probabilistic, \nmultivariate statistical, risk assessment, and other advanced analytical science and \nmathematical techniques, along with faster computational tools, would be needed. \n3.5.1. Extreme Events\nA small initial power system disturbance can cascade into a complicated chain of \ndependent failures leading to a widespread blackout. Although such extreme events\nare infrequent, they can disrupt commerce, vital infrastructure and societal security\nwith economic costs to society potentially in the billions of dollars for each event. \nCurrent planning practice for assuring the reliability of a large electric grid \ninterconnection, such as the WECC, is to plan the configuration and operation of the\ngrid for all contingencies involving the failure any one of these components, known \nas an \u201cN-1\u201d planning analysis. The computational logistics of studying all possible \ncontingencies of two or more simultaneous component failures is highly \nimpracticable or even impossible, even with today\u2019s supercomputers. Another, more\nefficient, approach is needed. Recall that one of the recommendations of the \nTransmission Cost Allocation Methodologies project described earlier was the \nQuantification of Extreme Event Benefits (Insurance Value) (see 1.1. Transmission \nCost Allocation Methodologies).\nThe TRP took on the challenge to develop just such a planning tool for cascading \nblackouts, aiming for new and innovative methodologies to simulate extreme \nevents, and to determine the remedial actions that would allow system operators to\nkeep the power system from collapsing and planners to enhance the grid\u2019s \nresistance to cascading outages. This research pursued multiple approaches in \norder to better determine the strengths and weaknesses of both existing methods \nand the new methods, e.g., probabilistic, multivariate statistical forecasting, \ndeveloped in the project, and produced encouraging results that these techniques \nwould work to better characterize the resistance to cascading outages for a given or\nplanned grid infrastructure configuration.\nThe \u201cExtreme Events\u201d research project developed and tested in a small-scale \nnetwork model, the science and conceptual framework and advanced mathematical\ntechniques needed for the complexity of multiple component and system failures in \na transmission system, such as the \"N-20\" equivalent analysis. Results included \nidentification of critical corridors, event frequency and probability, and superior \noperational response strategies. Phase II applied Phase I methodologies to realistic \nnetwork models to test their practicality. \nThe project achieved a number of firsts in the analysis of large interconnections and\ncascading outages:\n\uf0b7 Developed the first, full-size WECC model for cascading analyses using \nTRELSS, an EPRI software package for bulk power transmission system \nES-17\nreliability evaluation using contingency enumeration as an expansion of \ntraditional deterministic analysis.\n\uf0b7 Developed a methodology and extensive sets of initiating events for \ncascading analyses in the Western Interconnection.\n\uf0b7 Performed a total of 33,000 simulations to analyze the WECC system \nvulnerability to cascading events, that provided:\n\u2013 a ranking of initiating events by severity\n\u2013 an identification of the most frequent sequences of cascading outages \n(critical events corridors)\n\uf0b7 Developed a reduced, 1500 bus WECC model that has been the basis of \nseveral other analyses.\nThe DOE Office of Electricity subsequently funded $1.25 million to the Pacific \nNorthwest National Laboratory (PNNL), the principal investigator for the PIER-funded\n\u201cExtreme Events\u201d project, to conduct a new project, \u201cDynamic Contingency Analysis\nTool\u201d (DCAT) that will leverage the experience from the \u201cExtreme Events\u201d project \nand will overcome several of the gaps that were identified in the that effort. The \npurpose of the project is to develop a dynamic extreme events analysis tool to \nevaluate the risk of load loss due to extreme events, identify the most probable and\nimpactful events, and evaluate the impact of system reinforcements. This tool \nshould strengthen the capabilities of grid planners to assess the impact of extreme \ncontingencies and potential cascading events across their systems and \ninterconnections. The project directly supports new NERC \u201cStandard TPL-001-4 \nTransmission System Planning Performance Requirements\u201d to be enforced in 2015 \nand 2016, and a similar \u201cTransmission System Planning Performance WECC \nRegional Criterion TPL-001-WECC-CRT-3\u201d currently under development in the WECC \nsystem.\nThe \u201cExtreme Event\u201d project resulted in numerous professional publications.\n3.6.Transmission Congestion Assessment and Probabilistic \nForecasting \nCongestion costs in California can be high and mitigating these costs involves long \nterm planning and expensive upgrades to the grid, such as new transmission lines. \nIn 2004, the CAISO\u2019s gross congestion and Reliability Must Run Generation (RMR) \ncosts were estimated to be $1 billion annually, with congestion accounting for \napproximately half of the total, which did not include congestion on non-CAISO \ntransmission facilities. Improved understanding of the nature of California\u2019s \ncongestion issues is a necessary precursor to effectively managing the problem. \nImprovements in congestion management will help achieve the State\u2019s goals for \nCO2 reduction and renewable generation deployment, and to provide reliable and \nlow cost electricity with minimum environmental impacts. \n3.6.1. California Transmission Congestion Assessment\nThis project documented the scope and magnitude of the congestion problems \nfacing California and reported the challenges in forecasting. \nES-18\nThe scoping study found that the CAISO congestion cost data understated the \ncongestion. It captured information related only to schedules attempted, and not \nthe full economic potential for transactions. Inter-zonal congestion caused higher \nprices for all energy within the zone. RMR was the largest single component of \ncongestion costs. Without the construction of new local generation, RMR costs could\nonly be reduced by expanding the transmission capabilities into constrained local \nareas. Congestion could be avoided by planning and constructing sufficient \ntransmission in advance to manage remaining congestion costs to acceptable \nlevels. Metrics would be needed to identify and classify congestion costs as \nactionable, manageable, or to be monitored. \n3.6.2. Probabilistic Transmission Congestion Forecasting\nThere are many factors that combine to determine how electricity flows on an \ninterconnected power grid, and the uncertainties of these factors compound the \ndifficulty of forecasting transmission congestion for any particular transmission \npath. This difficulty will be more pronounced with high penetrations of variable \nrenewable generation in California. Making forecasts under high uncertainty often \nmeans using probabilistic methodologies.\nThis research developed new probabilistic forecasting methods for short term and \nlong-term transmission congestion in California, for use in transmission planning \nand forecasting tools that recognize uncertainties created by independent market \nparticipants. The mathematical models and the time frames of the simulation differ \nbetween the short term (24 hours) and the long term (10-20 years), therefore two \ncomputer models were developed. This research determined and specified how to \nmodel the key input assumptions in order to derive valid confidence levels of the \nforecasted congestion variables. \nFor long term probabilistic forecasting, the quality of results was highly dependent \non load forecasts and future resource projections, but probabilistic forecasting gave \nsignificant information regarding incremental improvements and timing of future \ntransmission upgrade requirements. Short term simulations also showed a strong \ndependence on load forecasts and on generation dispatch. It was found that high \nvariability in daily wind patterns that affect wind generation, would increase \ncongestion and the uncertainty of forecasts. \nThis project developed an approach that accounts for significant uncertainty caused\nby load and generation forecasts as well as random unplanned equipment outages. \nCAISO reports that annual congestion costs on the California-Oregon Intertie path \nincreased to $12 million in 2006 from $6.7 million in 2005, with costs expected to \nincrease. Improvements in congestion management would save costs and help \nachieve California\u2019s goals for reducing greenhouse gas emissions and providing \nreliable and low-cost electricity to California consumers with minimum \nenvironmental impacts.\nBuilding on this start, EPRI, the principal investigator, has continued development of\nprobabilistic forecasting capabilities, including for wind power integration. Many of \nthe forecasting and hedging techniques developed in this connected collection of \nresearch are available to ISOs, energy traders, and utilities.\nES-19\n3.7.New High Power Managing Capability\nIncreasing the power flow capacity of transmission lines raises the risk of grid \nequipment damage, injury, and greater security and reliability vulnerabilities from \nmore power being concentrated in fewer pathways. The TRP research in extreme \nevent analysis (see 3.5.1. Extreme Events) addressed the latter threat in part.  \nProtecting the grid and people from higher fault currents, however, required new \nhardware development because in many cases anticipated fault currents \nthreatened to exceed the ability of existing circuit breakers to safely and reliably \ninterrupt the faults. This required a new class of higher capability circuit breakers \nthat are not readily available from vendors, are expensive, or are of uncertain \nreliability. New types of equipment called fault current controllers were currently in \nthe RD&D phase, with several manufacturers testing prototypes in the 15 kV class. \nPrototype devices needed to be demonstrated in actual utility systems in order to \nidentify implementation issues and utility resource requirements, and to provide the\nrequisite field experience to refine the designs for utility acceptance. The TRP \ndeveloped a project to test prototypes in the field with SCE as the host for the \ndemonstration.\n3.7.1. Development of Fault Current Controller Technology\nOverall electric current loading on the transmission system has been rapidly \nclimbing due to the growth in demand for electricity, which has increased the \npotential fault current magnitudes at locations throughout the transmission system. \nFault currents, in many instances, may exceed the capability of existing protection \nsystems (circuit breakers) to interrupt the faults safely and reliably, and represent \nan imminent threat to electrical equipment and the safety of utility workers and the \npublic. Consequently, utilities must either upgrade their circuit breakers and \nassociated equipment, or reconfigure their systems to reduce the potential fault \ncurrent. Both solutions are costly, and frequently reduce system reliability and \npower transfer capability. Application of fault current controller (FCC) technology, \nalso frequently referred to as fault current limiter (FCL) technology, has been \nidentified as a viable solution for managing fault currents to keep them within the \nexisting short circuit capacity ratings of the system.   \nThis project developed and evaluated two prototype designs of FCC technologies. \nThe work established criteria for FCC performance and tested the new designs \nagainst those criteria. The ultimate program goal was to enable the \ncommercialization of FCC technology for the benefit of California and the United \nStates.\nWhen the project started, there were no industry standards for such a device, \ncomplicating the development of testing protocols. There were significant \nengineering challenges in developing the prototypes to withstand the currents and \nvoltages in the field. Finally the prototype FCCs had to meet SCE\u2019s specifications for \nfield demonstration on their system. The FCCs had to demonstrate the ability to \nwithstand live circuit events and severe environmental conditions.  \nThe project was a focused effort to develop a workable test plan, which needed to \nincorporate engineering standards for electrical apparatus. Zenergy Power worked \nclosely with Georgia Tech's National Electric Energy Testing, Research and \nES-20\nApplications Center and several of its member utilities, including SCE, to implement \na detailed FCC test program based on selected IEEE and CIGRE standards and \nprotocols for transformers and reactors. The EPRI/Silicon Power team created their \nplan based on ANSI C39.09-1999 and ANSI C37.06-2000, covering the entire \nspectrum of possible tests that needed to be carried out on their FCC, including \ncomponent level factory tests, system level factory tests, acceptance tests, and \nsystem field tests. \nThis project led to the successful field demonstration of the Zenergy Power high-\ntemperature superconducting (HTS) FCL, marking a milestone event in the history \nof FCL development. The experience gained from the research contributed to a \nmore reliable controller, a dramatic reduction of the FCL\u2019s size (with a slight \nincrease in weight), and the replacement of liquid nitrogen cryogenic refrigeration \nby a low-maintenance, dry (i.e., non-HTS) cooling system for increased reliability \nand reduced maintenance.\nHTS FCL technology is being improved to reduce basic device manufacturing cost, \nand it is being scaled up for higher voltages and currents. The latter may be more \nimportant in terms of value. Larger renewable power generators will connect to the \ntransmission system, and high-voltage tie-lines have become more common as \nmore power comes from long distances and as grid interconnections occur to \nimprove reliability and better control power flows. Higher-rated components cannot \nbe retrofitted in the available space, leading to lengthy and costly major upgrades \nof grid infrastructure. Economic studies and performance models show that at \ncurrent performance levels and price points, FCC technologies can be very cost-\neffective compared to major upgrade projects at high voltages. \nThe Zenergy Power HTS FCL project has already led to a scaled-up design for a \ntransmission-level 138 kV FCL application, which Zenergy is actively marketing to \nutilities around the world. \nThe EPRI/Silicon Power Solid State FCL represents another potentially cost-effective \nsolution to the rapidly increasing fault current levels in utility systems. One \nadvantage of this type of FCL is the flexibility to be configured as either interruptive \n(i.e., to act as a \u201csolid-state circuit breaker\u201d) or as simply limiting the fault current \n(and leaving the fault interruption to existing protective devices), with only minor \ndesign differences. A solid-state FCL may be used to limit the current of \nsuperconducting cables to enable the use of smaller cable sizes. The solid state FCL \nalso has a unique capability to limit inrush currents, even for capacitive loads.\nThe EPRI/Silicon Power team identified some potential thermal management issues \nin their initial design. An improved system design was completed, and the major \ntechnical design challenges, such as the thermal management system, and the \ncontrol circuit architecture and timing issues, were resolved. The cost to construct \nthe device was constrained by the project budget. Thus, this FCL prototype was not \nable to advance to the laboratory test and field demonstration stages under this \nproject.   \nThe FCC technology is a cost-effective alternative to the capital-intensive upgrades \nof the power system. The demonstration projects in this phase have already \nES-21\nresulted in two test plans and two full FCC designs, and have contributed to one \ncommercial sale and one migration to a transmission-level application. \nAdvanced development of FCC technology is strongly recommended and should be \nput on a fast-track to maintain the required levels of electric system availability and\nreliability. Significant amounts of investments in capital upgrades are potentially \navoidable, if suitable FCC technologies are made available to California utilities. An \naccelerated program of FCC technology focused on reducing the cost, improving the\nreliability, and increasing the voltage and current ratings of FCC technology is \nneeded.  \n3.8.Real-Time System Operations\n3.8.1.A Business Case Study on Applying Synchrophasor Measurement \nTechnology and Applications in the California and the Western \nElectricity Coordinating Council Grid\nPhasor measurement units (PMUs) collect time-synchronized grid data to provide \nreal-time information about the status of a point on the grid, and the development \nof synchrophasor measurement-based technologies is needed for securely and \nreliably operating the modern electric transmission system under growing \nuncertainty, such as created by high penetrations of variable renewable generation \nconnected to the electric grid. \nThe value of synchrophasor measurements is proportional to their deployment \nthroughout California and the WECC, because of the heavy reliance California places\non having access to power imported from states throughout the West. Transmission\nowners and operators will usually deploy new technologies only if a business case \ncan be made. This business case study provided sound rationales for the \ninvestment needed to obtain the benefits of these tools. \nThis \u201cbusiness case\u201d study evaluated the potential benefits, costs and \nunderstanding of who benefits and who bears the cost of expanded deployment of \nsynchrophasor-based technologies, and what are the best research and \ndevelopment opportunities to advance the most promising applications of this \ntechnology for the benefit of electricity consumers and the electric industry. It \nprovided organized consolidated information for use by the electric industry, policy \nmakers, and researcher planners. This study was conducted to identify economic \nand financial barriers to commercial deployment, and technology development \ngaps. Especially important in this case, it also sought to obtain information to help \ndevelop technology transfer strategies and educate potential users for increased \nadoption of these technologies. It found that synchrophasor measurements would \nenable improvements in planning, operating, and maintaining the electrical grid \nthat would otherwise not be possible.\nIt identified a large number of existing and potential applications of synchrophasor \nmeasurement technology. \nTwo key areas would benefit from applying synchrophasor measurement \ntechnology:\nES-22\n\uf0b7 Analyzing and avoiding power outages that can lead to catastrophic \nblackouts. Synchrophasor measurement applications can improve early \nwarning systems to detect conditions that lead to catastrophic events, help \nwith restoration, and improve the quality of data for event analysis. \n\uf0b7 Improving market and system operations. Synchrophasor measurement \napplications help facilitate congestion mitigation through better system \nmargin management. They also allow real time knowledge of actual system \nconditions as opposed to conditions defined by system models that may not \nreflect current conditions. In addition, state estimation solutions can be \nimproved significantly for use in locational marginal pricing calculations, \nthereby improving the overall accuracy of the calculations and the associated\nenergy clearing charges. \nThe results of this study served as a base to develop a near-, mid-, and long-term \ndevelopment and deployment roadmap. This roadmap and the process to transition \nPMU technology to full commercial application in California and the WECC, were key\noutcomes of this study that helped California, the WECC and the overall industry \nbenefit from PMU technology.\nThe study raised industry awareness of the benefits of using PMU technology to \nimprove grid reliability and support various grid applications.  This report \ncommunicated both to industry executives and technical leaders that PMU data are \nthe foundation on which various wide-area monitoring, protection and control \napplications, including wide-area situational awareness, could be built.  \nDOE used results of this report to identify and justify needs for Smart Grid \ninvestment in Transmission. A majority of funding for transmission was related to \nthe synchrophasor technology for the DOE Smart Grid Investment Grant, and \nsections from the report were used in the DOE solicitation. Investments co-funded \nby DOE plus other private entities (such as SCE and SDG&E) resulted in deployment\nof approximately 1,700 PMUs by 2013. SCE has used the results of the report to \njustify investment in PMUs for their rate case, which was approved. SCE has \ninvested heavily in order to deploy synchrophasor technology. The North American \nSynchrophasor Initiative, initially funded by DOE and later by NERC, used the PIER \nsynchrophasor roadmap as a base for their roadmap. \nIt is believed that vendors have used the report results and the roadmap to guide \ntheir deployment. Utilities and RTOs have used the report results and the roadmap \nto guide their plans. Researchers in academia have used the results as guidelines \nfor research initiatives. Activities initiated by this report have influenced \ninternational research and deployment of synchrophasors. Concrete examples from \na number of countries around the world include Brazil, Columbia, and India.\n3.8.2. Real-Time Applications of Phasors for Monitoring, Alarming and \nControl\nThe efforts funded for this project represent one phase of a multi-project RD&D \nactivity that was being coordinated by the Consortium for Electric Reliability \nTechnology Solutions (CERTS) for the Energy Commission\u2019s TRP.  The overall goal of\nthe synchrophasor applications project was to accelerate adoption and foster \nES-23\ngreater use of new, more accurate, time-synchronized phasor measurements by \nconducting research and prototyping applications on the CAISO\u2019s synchrophasor \nplatform that provided previously unavailable information on the dynamic stability \nof the grid. This platform is called the Real-Time Dynamics Monitoring System \n(RTDMS). \nThe key result of this project was the development of the RTDMS. Feasibility \nassessment studies utilizing synchrophasor measurements validated and improved \nexisting stability nomograms, evaluated small-signal stability monitoring algorithms,\nconducted frequency-response analyses, and obtained real-time sensitivity \ninformation on grid-stress directly from synchrophasor measurements. The project \nsuccessfully developed prototype applications offering a rich set of features for \nwide-area monitoring and analytics, which were factory- and field-tested at the \nCAISO and at BPA. In addition, two new dedicated displays for measurement-based \nangle sensitivity and voltage sensitivity were developed as key indicators of grid-\nstress and proximity to instability. \nThis led the CAISO to adopt time-synchronized phasor measurements for real-time \napplications in the WECC, and also made significant investments in the underlying \nhardware and supporting maintenance practices to host the prototypes and enable \nneeded future research to develop functional specifications to facilitate acquisition \nof commercially-supported, production-quality tools.  The project team \nrecommended continuing RD&D for prototype applications towards development of \nfunctional specifications that CAISO can use to acquire production-quality tools from\ncommercial vendors. The funding for this research came from three sources: U.S. \nDOE, the Energy Commission/PIER, and the Electric Power Group (EPG) in Pasadena,\nCA. EPG continued to invest in RTDMS after the Energy Commission/PIER and DOE \nfunding ceased.\nSince this research was done, the RTDMS and applications have been deployed at, \nin addition to CAISO, other major independent system operators, including PJM, New\nYork ISO, the Electric Reliability Council of Texas and many utilities including Duke, \nDominion, Lower Colorado River Authority, Salt River Project, ONCOR Electric \nDelivery Company, SCE, Los Angeles Department of Water and Power, HydroOne, \nand the Southern Company. \nRTDMS has been deployed at different universities such as UCLA Smart Grid Energy \nResearch Center, University of Illinois, Clemson, and Texas Tech University. It has \nbeen integrated with Intel technology for cyber security protection of critical \ninfrastructures and demonstrated as integrated software (RTDMS with Security \nFabric) at Texas Tech University. Three patents have come from the work:  US \n7,233,843 B2, dated June 19, 2007, US 8,060,259 B2, dated November 15, 2011, \nand US 8,401,710 B2 dated March 19, 2013. SCE has utilized RTDMS in their RTDS \nLab in Westminster, CA. \nHere are some examples of cases where the RTDMS has been used: \n\uf0b7 Detection and corrective action for Pacific DC Intertie Integration with \nEMS/SCADA systems. \n\uf0b7 Detection and mitigation of oscillations from wind power plants\u2019 faulty \ncontroller settings.\nES-24\n\uf0b7 Simulation and replay of system events for use in training. \n\uf0b7 Wide-area situational awareness monitoring by ISOs covering large regions. \n\uf0b7 Monitoring of dynamic metrics \u2013 phase angles, oscillations, damping, voltage \nand angle sensitivities, frequency instability. \n\uf0b7 Automated event analyzer displays for diagnostics of events in real time to \nguide operator actions. \nNumerous presentations and papers presented in different industry forums, such as \nWECC Joint Synchronized Information Subcommittee, NASPI, and IEEE.\n3.8.3. Real-Time Oscillation Detection, Analysis and Mitigation\nElectromechanical oscillations occur frequently on power grid systems that often die\nout on their own, oscillations can lead to grid instability and potentially large-scale \nblackouts costing billions of dollars (also see 3.4. New Capacity Dynamic Stability \nCapability). In August 1996 a western system breakup resulted from undamped \nsystem-wide small-signal oscillations. About 7.5 million customers (24 million \npeople) lost their power supply for several minutes to 6 hours, principally in \nCalifornia. Given the wide-area nature of oscillation problems, California sits at one \nend of the oscillation mass and would be an area experiencing the consequences. \nCalifornia is also an area that can implement control actions to mitigate oscillation \nproblems. The challenge is how to determine when to take control actions, what \ncontrol actions to take, and what effects to expect after the actions are taken.  \nTherefore, significant efforts have been devoted in the past few decades to \nmonitoring system oscillatory behaviors from real-time measurements. The \nrelatively recent development and deployment of PMUs have provided the \ncapability to obtain in real-time over the entire interconnection, high-precision time-\nsynchronized data needed for estimating oscillation modes. A mode is the \ncharacterization of an oscillation in terms of its (modal) frequency and shape used \nto communicate the nature of an oscillation to grid operators and engineers.\nThe methods and tools developed in these two projects described here provide grid \nplanners and operators the potential to have significant impact on power grid \noperation, as it will improve reliability and avoid significant economic losses, \nespecially under high penetrations of variable renewable generation. This research \nlaid the foundation for achieving the goal of not only the rapid detection and \nanalysis of oscillations but also their control through proscribed grid operations to \nchange inter-area oscillation modes and achieve a new grid operating state so as to \nmitigate threats. \nThe first project was a tool to improve real-time situational awareness of oscillation \nproblems in the Western Interconnection by developing an intelligent algorithm for \noscillation detection and analysis, evaluate its performance and usefulness using \nfield measurement data, build a prototype graphical user interface, and then \ndevelop a real-time prototype tool for monitoring and analyzing power grid \noscillations. This oscillation tool development was a major breakthrough in that it \nsignificantly lowers false and missing alarms, as well as shortening detection time \nby applying oscillation detection and analysis algorithms properly.\nES-25\nRecall that the California power grid is in an area that can implement control actions\nto mitigate oscillation problems. The challenge is how to determine when to take \ncontrol actions, what control actions to take, and what effects to expect after the \nactions are taken. The second project was to advance modal analysis beyond \ndetection to action, by developing a method and establishing a modal analysis for \ngrid operation (MANGO) procedure to provide recommended actions (such as \ngeneration re-dispatch), and aid grid operation decision making for mitigating inter-\narea oscillations. \nA MANGO procedure was established with practical considerations. The key step in \nthe procedure is the modal sensitivity. A method for estimating relative modal \nsensitivity was formulated and studied with promising results from a medium-size \nsystem and the full WECC system, and the impact of topology change on damping \nwas studied. The simulation studies were conducted with commercialized software, \nand the resulting experience and data paved the road for large-scale MANGO \napplication. \nDue to limited synchrophasor measurement availability, all the tests were \nperformed with simulated data, thus further testing needs to be done with actual \nsynchrophasor measurements once the installation underway of an additional 250+ \nPMUs in the WECC is completed. \nThis PIER research was supplemented and continued by more than $500,000 of \nfunding from the DOE Office of Electricity and Energy Reliability through the \nadministration of the CERTS program. The technology developed has been well \nreceived by the electric grid community as state-of-the-art and the basis for follow-\non research. Part of the work was included in an IEEE special publication, which was \nsupported by a special IEEE Task Force.\nThe intellectual property of this technology has been protected for \ncommercialization through two software copyrights: (1) MANGO version 1.0, and \nOscillation Detection version 1.0. The BPA has installed the Oscillation Detection \nsoftware for testing, and discussions regarding testing the MANGO software tool are\nongoing with several power companies.\nThis research has resulted in twenty professional publications.\nPotentially, with these two tools, the transfer capabilities of stability-limited \ntransmission lines can be increased, which in turn would increase asset utilization \nand free up transmission capacity for the California electric grid.\n3.9.Advanced Protection Systems Using Wide Area Measurement\n3.9.1. Scoping Study of Intelligent Grid Protection Systems\nThis study explored the state of the art of synchrophasor (phasor measurement \nunit, or PMU) technology and of remedial action schemes and special protection \nschemes (SPSs), and the transmission constraints of importing power into California.\nIt recommended appropriate projects to further explore the applications of \nsynchrophasor technology in electric grid protection systems in California.\nES-26\nThe purpose of this project was to analyze transmission system protection issues, \nidentify state-of-the-art technical protection solutions and their value for an \nintelligent system, and develop stakeholder-supported recommendations for a \ntechnology program. \nThe project found that almost all protection and control schemes on the grid today \nare local in nature, which means that the sensing of faults and tripping of \nequipment take place in one substation, typically telecommunications between \nadjacent substations to coordinate the protection to some limited extent. The \nparticular benefit of applying synchrophasors is because of the intelligence \ngathered over a wide area to detect stressed system conditions, which cannot be \ndone on a local basis. Some potential applications that hold promise are wide area \nvoltage control, small signal stability control and transient/dynamic stability control.\nSpecial protection schemes are the primary means of wide area control today, \nalthough some are used for local problems as well. However, presently SPSs are \nprescriptive in nature, in that typically load flow and transient stability studies must \nbe done assuming worst case conditions to ensure that there is adequate protection\nduring those times. Since worst case conditions are by definition rare, this means \nthat most of the time system capacity will be underutilized or remedial actions will \nbe more severe than usually necessary.\nThe next step should be to develop methods to control transient stability that are \nless dependent on off-line studies and use more on-line computation. Techniques \nusing pattern recognition, neural networks and expert systems hold great potential \nfor developing feasible and effective control actions that are proactive in nature \nrather than reactive: action could be taken ahead of time to prevent outages from \noccurring in the first place.\nSynchrophasor technology has proven to be extremely valuable in post-disturbance \nanalysis, providing unique insight into finding the root causes for major system \ndisturbances, including the August 10, 1996 and August 14, 2003 Western \nblackouts. A demonstration project employing synchrophasors for protection \napplications would provide the needed experience to advance real-time reliability \nmethods. \n3.9.2 Advanced Protection Systems Using Wide Area Measurements\nProtection systems for electric grids can operate in an unanticipated fashion during \ntimes of transmission system stress, and such operations are often an important \ncontributing factor in the sequence of events leading to cascading outages. This has\nbeen documented as \u201cthe hidden-failure\u201d phenomenon in protection systems. Other\ncontributing factors to catastrophic failures are unexpected power system \nconfigurations that were not foreseen when protection systems were set, errors in \nsetting and calibration of relays, or undiscovered design flaws in the protection \nsystems.\nThe project objective was to research, develop and evaluate the use of advanced \ntechnologies, specifically synchrophasor data and data mining algorithms, in the \nmonitoring, supervision, and modification of protection systems in real time, for \nincreased electric system reliability, security and situational awareness. \nES-27\nThe project focused on four tasks:  \n1. Development and validation of an equivalent California transmission system \nmodel.\n2. Development of an algorithm for adaptive adjustment of dependability and \nsecurity during conditions of system stress, in which false trips might \ncontribute to further system deterioration.\n3. Development of an alarm for potential load encroachment upon the trip zone \nof impedance relays.  \n4. Development of a more intelligent out-of-step relaying tool. \nThe results of the project were:\n\uf0b7 Model Validation: A reduced West Coast power system model was developed \nbased on the California model provided and the WECC system information \nprovided by PG&E. This model was proven to reflect the behavior of the full \nWECC model for the major disturbances considered for this project.\n\uf0b7 Adaptive Security/Dependability Balance: An algorithm based on Heavy \nSummer and Heavy Winter decision trees using synchrophasor data from key \nPMU locations was developed. Performance evaluation of the algorithm with \nnew test cases created by simulating circuit element outages was performed \nto assess the robustness of the decision trees to topology changes. The \nmisclassification rates for topology changes were found to be acceptably low.\nA functional analysis of the proposed system determined that it can be \nimplemented with available commercial PMUs, computers and data \nconcentrators, provided the communication links are available at the selected\nPMU locations.\n\uf0b7 Alarms for Encroachment of Relay Trip Characteristics: A reduced West Coast \npower system model was developed and validated. Analysis showed that this \nmodel reflects the behavior of the full WECC model for the major \ndisturbances considered for this task. A supervisory boundary, which is a \nconcentric circle with a radius 50 percent larger than the radius of the relay \ntrip zone, was established as the point at which alarms would be set. \nContingency analysis of the Heavy Winter and Heavy Summer models \nrevealed that for no combinations of outages and three phase faults did \neither the power swing or the post-disturbance load flow cause encroachment\nof distance relays on critical 230 kV and 500 kV lines in California.\n\uf0b7 Adaptive Out-of-step Relaying: A reduced West Coast power system was \ndeveloped and validated; generator coherence detection algorithms were \ndeveloped. Alarms for out-of-step relays were set based on identifying \ncontingencies that cause significant changes in the location of the swing \ncenter and the size and speed of stable swings at the location of the out-of-\nstep relay. An algorithm was developed to determine the contingencies that \nmake out-of-step relays lose their ability to differentiate stable swings from \nunstable swings. The performance of the algorithms was evaluated; none of \nthe stable swings were tagged as unstable and all unstable swings were \nproperly identified as such.\nThe results of this project were further developed and used in field demonstrations \nby a subsequent research project, Application of Advanced Wide-Area Early Warning\nSystems with Adaptive Protection (see below). That project adapted two of the \nES-28\nalgorithms developed in this project, Security/Dependability Balance and Relay \nZone Encroachment Alarms, for field implementation and demonstration by two \nCalifornia utilities, PG&E and SCE.\n3.9.3. Application of Advanced Wide Area Early Warning Systems with \nAdaptive Protection\nThe primary goal of this project, co-funded by the DOE, the Energy Commission and \nthe project participants, was to demonstrate, in real-world utility systems and with \nthe participation of practicing utility engineers, three specific high-value \napplications in adaptive protection technology. \nFirst, synchrophasor data were used as input to a Security/Dependability Balance \nalgorithm. Modern grid protection systems use redundancy, i.e., multiple sets of \nindependent relays, to ensure reliable fault clearing (\u201cDependability\u201d). However, the\nprobability of \u201cfalse trips\u201d is somewhat increased, which is usually not a problem if \nsystem conditions are normal. However, when the system is not healthy, false \ntripping can exacerbate the conditions leading to system collapse, i.e., blackouts. \nBy using synchrophasor data in an algorithm that is trained to recognize such \nabnormal system conditions, a supervisory logic can be quickly implemented to \nrequire a \u201cvoting\u201d scheme for the relays, in which at least two of the multiple sets of\nrelays must agree there is a fault before tripping is implemented. Thus, system \n\u201cSecurity\u201d can be maintained even when the system is in a weakened condition. \nSecond, synchrophasor data were used as input to an Impedance Zone \nEncroachment algorithm. Impedance relays are set to detect conditions when the \nimpedance they \u201csee\u201d in the system drops into an unacceptably low range, usually \nat a low point of a dynamic oscillation due to a major disturbance, and the relay \ntrips to avoid unstable system swings. Over time, as system conditions such as \nloading or equipment additions are made, the relay\u2019s setting will no longer \ncorrespond to previous conditions, and the relay may operate for stable swings, an \nundesirable outcome. The Zone Encroachment algorithm sets up a buffer zone \naround the relay\u2019s normal zone, and when system swings start to encroach on the \nbuffer zone, an alarm and display message is sent to the system operator, who can \nrelay the warnings to the protection engineer, who can then re-evaluate, and if \nnecessary re-program, that relay\u2019s settings to avoid undesired operations. \nAnd third, in order for utility engineers to absorb synchrophasor data quickly so as \nto facilitate the required real-time responses, this project developed methods for \ndisplay and visualization of protection system data and validated those methods \nwith utility engineers in interactive interviews and workshops.\nEach of the three applications of protection systems described above were \ndemonstrated using a three-part technical process: research and development; pilot\ndemonstration; and field demonstration.\nIn the R&D phase, university researchers at Virginia Tech adapted both the \nSecurity/ Dependability Balance and Zone Encroachment algorithms from previously\ndeveloped, non-real-time research versions, with the necessary modifications to \nallow them to run in real time with streaming synchrophasor data. Researchers at \nES-29\nMississippi State University built upon previous research to develop new \nvisualizations of synchrophasor data.\nIn the Pilot Demonstration phase, the Security/Dependability Balance and Zone \nEncroachment algorithms were first implemented in Virginia Tech\u2019s laboratory using\nrelaying and synchrophasor devices similar to that used by utilities; then they were \nexported to the proof-of-concept laboratory facilities at utilities PG&E and SCE, to \nverify correct performance and instruct utility engineers in their use. A Data \nEvaluation Plan was developed as a protocol for evaluating the performance of the \nalgorithms against real data, to be collected in the final, Field Demonstration Phase.\nThe synchrophasor visualizations developed in the R&D phase were presented to \nPG&E and SCE engineers and technicians in interactive workshop settings and \ninterviews; feedback and comments were elicited; and further refinement were \nmade to the visualizations.\nIn the Field Demonstration phase, the two adaptive relaying algorithms were \nimplemented into utility operations systems by the utilities themselves, using the \nsame devices, equipment, personnel and systems that would be used in actual \npractice, with the difference that the systems were in \u201cmonitor\u201d mode, i.e., the \nsystems were fully functional but did not impact actual relay operation prior to \nvalidation with field data. Data collected over several months were evaluated by the\nproject team according to the Data Evaluation Plan. The data visualizations were \nmodified according to the utility feedback received in the Pilot Demonstration \nphase, and a second round of interviews and workshops were conducted with the \nrevised visualizations to ensure operator and engineer acceptability. \nThis project was, arguably, the first real-world utility demonstration of the use of \nsynchrophasor data in advanced protective relaying applications, one that should \ninspire other researchers and utilities to implement the applications described here,\nas well as applications in other areas of electric grid operations and planning. The \nproject demonstrated a feasible approach for implementing the \nSecurity/Dependability Balance algorithm in a real-time operations environment. In \nfact, two somewhat different approaches were used by PG&E and SCE in terms of \nthe specific hardware used and where the algorithm software was installed, but \nachieving the same result: an adaptive protection system using synchrophasor data\nto enhance the reliability and security of a major transmission path. \nThe project also demonstrated an economical and feasible approach to \nimplementing an Impedance Zone Encroachment system to inform protection \nengineers via on-screen alarms and notifications when impedance relay settings \nshould be re-evaluated and/or updated for increased system security.\nImportant knowledge was gained from practicing utility engineers, operators and \ntechnicians regarding methods of visualizing synchrophasor-based protection \nsystem data. The prototype visualization tools were developed and vetted to meet \nthe demands of utility personnel for clear and concise representations that can be \nquickly absorbed, allowing problems to be efficiently analyzed, and decisions \nformulated and carried out expeditiously. \nES-30\n4. New Cross-cutting Technology for Improving the \nTransmission System Reliability, Flexibility and \nResiliency\nSome of the TRP research cut across several of the strategies described above, such\nas seismic damage resistance and another was energy storage.\nBecause much of the California electric system is in active seismic regions, post-\nearthquake functioning of utility systems is a vital need for rapid response, recovery\nand preservation of public health and safety. Building an electric system that is \nmore resistant to seismic motion damage will reduce the consequences and costs of\nelectric service disruptions caused by strong ground motions. The TRP conducted \nanalyses, simulations and lab tests on substation post insulators and transformer \nbushings. \n4.1.Increased Seismic Robust Performance of Transmission \nSubstation Components\nSome of the TRP research was conducted on technical topics or areas that cut \nacross several of the strategies described above. One such area was seismic \ndamage resistance and another was energy storage.\n4.1.1. Evaluation of the Seismic Performance of High-Voltage Transformer \nBushings\nPrior research has identified several areas of high-value seismic research that can \nlead to a more reliable, robust and resilient electric system, in particular the \ndynamic interactions between the high voltage transformer bushings and other \ncomponents in large substation transformers due to seismic motions. When such \ncomponents fail in earthquakes, or their oil contents catch fire in the aftermath of \nan earthquake, there is a danger that the entire grid might be affected.\nCurrently accepted standards for certifying the seismic performance of transformer \nbushings, based on IEEE Standard 693-2005 protocols, are not valid.  Procedures \nused by the electric equipment industry do not properly account for the dynamics of\nthe as-installed bushing/transformer combination in practice. This project \ndetermined the seismic response of the combined transformer-bushing interaction \nand to enable more accurate analysis and physical seismic qualification of bushing-\ntransformer systems. \nThe research identified weaknesses of the current qualification procedures that \nignore the as-installed conditions and also minimize the importance of strength \ncapacity-demand issues. This work highlighted key measurement and protocol \nrequirements for qualification of bushings, so that bushings can withstand predicted\nlevels of seismic events when installed in service. Recommendations were \ndeveloped for consideration by the IEEE Working Group tasked with revising or \nupdating IEEE Standard 693.\nRecommendations for changes to the current qualification procedures for bushings \ninclude the following: (1) Develop qualification procedures that compare the \nstrength demands to strength capacities in mechanical terms; (2) Determine the \nES-31\nstrength capacity of bushings by either testing them to failure, statically or \ndynamically, or by strength computations by manufacturers; (3) Test the bushings \nto generate seismic strength demand using seismic simulators (shake tables) \naccording to a desired severity (qualification level); (4) Determine the desired \nseverity of seismic demand including the identified dynamic properties of bushings \nand mounting conditions, through use of interaction factors or simplified analytical \nmodels; (5) Modify the design requirements for transformer tank covers to reduce \nor eliminate the interaction issues; and (6) Further develop methods of reducing \nseismic demands on all components of transformers by using protective systems.\nThese proposed revisions to the IEEE Standard are currently before the appropriate \nIEEE Task Forces and Working Groups for approval.\n4.1.2.Seismic Performance of Substation Insulator Posts for Vertical-Break\nDisconnect Switches\nDisconnect switches are a key component of power transmission and distribution \nsystems that either control the flow of electricity between all types of substation \nequipment or isolate the equipment for maintenance. To mitigate the vulnerability \nof new disconnect switches and other electrical substation equipment to \nearthquakes, there are guidelines for the seismic qualification and testing of \ndisconnect switches. \nA new testing approach to accommodate required modifications in the disconnect \nswitch or its support structure is based on the concept of real time hybrid \nsimulations using a small shaking table for testing only a single insulator post with \nan online computational model for the support structure. The hybrid simulation \ntesting is the essence of the experimental testing program conducted in this study.\nThe research conducted finite element (FE) simulations and provided \nrecommendations to IEEE 693 for seismic qualification of different types of high-\nvoltage electrical substation disconnect switches. The experimental framework \nconsisted of static and dynamic testing with complimentary material \ncharacterization and resonance-search tests. The FE simulations included linear and\nnonlinear static and dynamic analyses of a single insulator post. The static tests \nwere conducted for 230 kV and 550 kV porcelain insulator posts. These tests \nincluded ramp cyclic-loading tests to obtain the force-displacement relationship of \nthe insulator posts and fragility tests to determine the failure cantilever loads, \ndisplacements, and maximum strains. Six cylindrical specimens were prepared from\nthe broken 230 kV insulator parts for material testing. In addition, the vibration \nproperties of the single porcelain insulator post were determined using hammer \nimpact tests.\nThe project aimed at developing accurate computational FE models for a single 230 \nkV porcelain insulator post. These models were used to conduct eigen-value, linear, \nand nonlinear static and dynamic FE analyses. The FE model developed for \nnonlinear analyses was also used to conduct a parametric study focusing on ranking\nthe different sources of uncertainties that affect the structural response of the \ninsulator posts. Different model parameters were varied to study how the force and \ncorresponding displacement at failure were affected. A Tornado diagram analysis \nwas used to illustrate and summarize which model parameters affect the behavior \nES-32\nmore. The outcome of this Tornado diagram analysis is a representation of the \nimportant candidates to focus on in future research to reduce uncertainties in the \ncomputational modeling of insulator posts.\nThe nonlinear FE model was used to conduct dynamic analyses using the same \nsignal applied for the 230 kV substructured tests. The base excitation was applied \nat different scales to capture the insulator failure under dynamic loading which was \nnot possible to determine experimentally due to shaking table limitations. The \ncomputational study was concluded by obtaining the maximum response nonlinear \ncurves for the different scales used in the analysis for a single porcelain insulator \npost used in 230 kV electrical substation disconnect switches.\nThe study also focused on conducting linear and nonlinear static analyses to rank \nthe sources of uncertainties in porcelain insulator computational modeling, and on \ndynamic analyses to determine failure load under earthquake loading. The final \nconclusions drawn from the experimental study and the FE simulations were used to\nprovide proposed revisions to the IEEE 693 Standard for consideration by the IEEE \nStandards Working Groups and Task Forces for seismic qualification of high-voltage \ndisconnect switches.\n4.2 Energy Storage\nEnergy storage is expected to play a larger role in generation resource \nmanagement, integration of variable resources, and peak management \napplications. On September 29, 2010, Governor Arnold Schwarzenegger approved \nAssembly Bill 2514, Skinner, Energy Storage Systems. This bill required the CPUC to\ndetermine appropriate targets, if any, for privately owned electric utilities to procure\nviable and cost-effective energy storage systems. For public utilities, the bill \nrequired the Energy Commission to review and approve plans to determine \nappropriate targets and procure viable and cost-effective energy storage systems to\nmeet the targets. Also, the bill recognized that despite many benefits of energy \nstorage, there are significant barriers to obtaining the benefits of energy storage \nsystems. To assist in the decisions to be made, the Energy Commission charged the\nTRP to conduct a strategic analysis of energy storage technology, called the Energy \nStorage Vision 2020. It reviewed the technical status and the remaining research \nand development needs of current storage technologies, developed a strategic \nvision of how California might best implement its energy storage needs over the \nnext 10 years.\n5. Electric Distribution System and Renewable Generation \nIntegration\nIn 2010, with the expectation of 12,000 MW of new distributed generation, mostly \nsolar PV, to be installed in California by 2020, attention on renewable energy \nintegration with the grid shifted toward electric distribution. Largely in the form of \nsmall photovoltaic generators located at or near electric customers\u2019 facilities, \ndistributed generation represented unprecedented challenges for the distribution \nsystem.\nES-33\nConventional distribution systems are largely radial, designed for one-way power \nflow, while transmission systems are networked and designed for power flows in \ndifferent directions at different times. Another significant difference between \ntransmission and distribution is the degree of monitoring capability, with \ntransmission systems being heavily monitored compared to distribution systems in \nspite of smart meter penetration late in the 2000\u20132013 period.  Anticipation of high \npenetrations of variable solar PV distributed generation has raised concerns about \nislanding, relay desensitization because of being designed for one-way power flow, \nvoltage regulation and flicker, and the increased need for line and transformer \nreplacements. \nBecause so little is known about the distribution system, this project began with an \neffort to characterize the distribution system in sufficient detail to assess the effects\nof high penetrations of distributed PV. This project collected and analyzed data to \ndefine the requirements for an intentional monitoring plan to characterize the \nelectric distribution system in California for high penetrations of distributed PV.\nSome distribution circuits are underground (insulated cables) rather than the more \ntypical overhead (lines and poles).  Underground circuits provide higher reliability \nfor electric customers, and many more circuits might be placed underground if the \nconstruction costs could be reduced and the cost and difficulty of locating and \nrepairing failures in cables could be mitigated. The following research projects begin\nto address these issues.\n5.1.Advanced Monitoring of Distribution Systems\nA difference between transmission and distribution is the degree of monitoring \ncapability. Transmission systems have become more monitored compared to \ndistribution systems beyond the distribution substation, despite increased \npenetration of smart meters.\nAnticipation of high penetrations of variable solar PV distributed generators have \nraised concerns about islanding; relay desensitization; voltage regulation and \nflicker; increased line and transformer replacements; and resonant conditions. \nBecause little is known about the distribution system, CIEE began to characterize \nthe distribution system in sufficiently to address the effects of high penetrations of \ndistributed PV. This project collected and analyzed available data, then defined the \nrequirements for an intentional monitoring plan to characterize the electric \ndistribution system for high penetrations of distributed PV.\n5.1.1.Distribution System Field Study with California Utilities to Assess \nCapacity for Renewables and Electric Vehicles\nA significant and growing amount of new renewable generation is being installed at \nthe distribution level of the electric grid, accompanied by the proliferation of \ntechnologies such as plug-in hybrids and electric vehicles (EVs). There is thus a \nneed for information about the impacts of these technologies, and data to support \nthe analysis and control of distribution systems in the future. \u201cOne-size-fits-all\u201d \nsolutions, such as the 15 percent rule of thumb for installation of distributed \ngeneration on a feeder, are rapidly becoming unacceptable \nES-34\nThe purpose of this project was to advance the state-of-the-art in electric \ndistribution systems by supporting safe and reliable operation with a substantially \nincreased presence of renewable generation, distributed generation, EVs, and other \nnew technologies and applications. \nMost of the distribution system monitoring activities by the utilities are \u201cad hoc\u201d \nefforts that focus on specific behaviors, e.g., of PV systems, energy storage \ninstallations, EV charging, microgrid demonstrations, smart meter implementations,\nand demand response programs. There was considerable variation found in data \nquality and analytical methods. Evaluation of the overall monitoring situation gave a\nreasonably good picture of the baseline monitoring practices used in distribution \nsystems today, and the gaps that need to be filled in order to manage and operate \ndistribution systems effectively, both today and in the future. \nA Data Repository was established at the University of California San Diego \nSupercomputer Center for the secure storage of utility data, and it is hoped that this\neffort be continued and expanded in a Phase 2 research project. The project \nacquired system data, of both physical feeder models and the associated measured \ndata, to validate the feeder models. Utility validation of their system models is not \nconsistent, but it is a necessary requirement to perform planning studies, to know \nor estimate what the actual system conditions are, or to operate the system reliably\nand efficiently. \nThe supplied data had missing data, bad data, \u201coutliers,\u201d and non-uniform sampling\nintervals requiring additional evaluation and processing before the data could be \nanalyzed. The project was able to develop methods for dealing with these \nanomalies so that analysis could be efficiently performed.\nThe blueprint for an Advanced Monitoring Plan (AMP) was developed, which is the \nbasis for follow-on research on the current gaps in available data and in data \nmonitoring practices, as well as the future needs based on high levels of new \ntechnologies, such as renewable and EVs. The results from the first part of the \nproject provided information on current needs and monitoring practices. The project\nincluded a survey of distribution engineers and experts to explore and expand the \ndesign and features of the AMP. The product is a practical basis from which to learn \nmore about distribution systems in California.\nThis collaborative research effort was the first systematic look at a representative \nsample of distribution circuits across California. The primary benefits of this project \ninclude increased visibility of the distribution system, resulting in more reliable and \nefficient operations, better planning for system upgrades and expansions, and \nproactive detection, analysis and mitigation of the potential impacts of new \ntechnologies and applications on distribution systems. \n5.2.Reliability of Underground Distribution Systems\nUnderground distribution circuits increase electric reliability. Despite the cost, more \ncircuits would be underground if the cost and difficulty of reducing, predicting and \nlocating failures could be reduced. CIEE has administered research projects on \nunderground cable for that purpose. One project investigated three methods for \ndetecting, in advance of failure, a common degradation of cable insulation (known \nES-35\nas \u201cwater trees\u201d). These methods can be applied while the cable is in service. Two \nmethods showed promise. Another project investigated four methods for online \ndiagnosis of underground power distribution cable from in situ measurements of \ncables. Two looked promising.\n5.2.1.Underground Cable Diagnostics Miniaturization Research, \nDevelopment, Field Test, and Commercialization\nThe aging and in-service deterioration of underground distribution cables is a major \nissue for electric utilities in California and throughout the U.S. There are over \n100,000 miles of underground power distribution cables in and around the West \nCoast area. Older cables have a higher probability of failure due to development of \ndefects in the cables because of aging and exposure to the elements. These defects\ncan lead to catastrophic cable failures that are not only hazardous to the \ncommunity around the location of the failure, but can result in large economic costs\nto affected businesses that lose power from the time of the cable failure to \nrestoration of power.\nThis project addressed two primary causes of failure in underground cables: \n\uf0b7 Broken or corroded concentric neutral (CN) wires.  This research provided the\nfoundation for the design of an advanced sensing mechanism, a device \ntermed the \u201cGrabber,\u201d which utility technicians simply push onto the \nenergized cable using an industry-standard \u201chot stick.\u201d Pivoting jaws close to \nform a ring around the cable, with 10 to 12 micro-sensors arrayed around the\ncable to sense the magnetic fields from the CNs. Sensor data from the \ngrabber is transmitted wirelessly via Bluetooth to the technician\u2019s laptop, \ntablet or smart phone. The Grabber easily releases the cable when the \ntechnician pulls back on the hot stick. The technician can then review the \nsensor data, quickly assess the cable\u2019s health, and determine if a cable \nreplacement or further testing is necessary.\n\uf0b7 Failure of the polyethylene insulation due to \u201cwater trees.\u201d The research \nteam determined that a technique using radio frequency (RF) coupling in the \ncable was the most promising method. This technique requires the insertion \nof an RF generation source at one end of the cable and a detector at the \ninput end to detect reflections, or at the other end of the cable coupling. By \ncomparing the cable\u2019s attenuation and other characteristics with the \ncharacterization of a \u201chealthy\u201d cable, technicians can quickly identify the \npresence of water trees or other cable abnormalities. Armed with this \nknowledge, utilities can replace cable sections before they fail, as well as \navoid unnecessary cable replacements.\nThe primary benefits of this knowledge are that utility personnel have advance \nwarning that a cable may fail and cause an outage; customers will experience more \nreliable service; utilities will avoid excess costs due to emergency replacements and\nrepairs, and will be able to better control their available maintenance dollars; and \nimproved safety of utility maintenance personnel. A Commercialization Plan was \ndeveloped to assure transfer of the developed technologies to the private sector. \nDiscussions were held with technology firms and promising commercialization \npartners were identified. A patent application was submitted for the RF technique \nfor detecting water trees in energized cables, and the patent was issued. A \nES-36\nprovisional patent application for the Grabber device for detecting faults in \nconcentric neutrals was also submitted. \nConcluding Statements\nThe research projects included in this white paper were chosen as representative of \nthe Transmission Research Program and other PIER-funded electric grid research, \nled, administered, managed, and/or conducted for the Energy Commission by the \nCalifornia Institute for Energy and Environment at the University of California. Some \nof the research projects were not explicitly included, but still accounted for, because\nthey were precursors to projects of continuing efforts included here. Other research \nefforts not explicitly described here were of research planning, including \ncharacterization, issue definition, technology solution identification, gap analysis \nand technology roadmaps. \nPublic interest energy research lies at the nexus of service quality, environmental \nimperatives, and economic objectives. At the intersection of these three objectives, \nintegration of renewable resources throughout the electric grid to meet these goals \nhas been a guiding theme during 2000\u20132013. Work sponsored through PIER \nsystematically sought to expand the grid\u2019s technical hosting capacity for various \ntypes of renewable and distributed resources through a diverse range of \napproaches. The remarkable progress on renewable and DER integration would not \nhave been possible without the contributions of PIER. While the explicit charge of \nPIER is to serve the interests of California, the success of the California experiment \nin the context of the present status of global climate negotiations, and the long-\nterm public benefit even beyond our State\u2019s borders, cannot be overstated.\nES-37\nES-38\nIntroduction\nThe start of the 21st century in California was a turning point for electric grid \ntechnology research funded by the California Energy Commission (CEC) Public \nInterest Energy Research (PIER) program. The California electric grid entered the \nnew millennium during the California Electricity Crisis of 2000-2001, an outcome of \nCalifornia\u2019s restructuring and deregulation of the regulated electricity industry in \n1998. By 2000, and into 2001, as an unintended consequence of deregulation, \nCalifornia and its utilities were experiencing very high electricity prices and severe \nfinancial problems, along with electric power shortages and rolling blackouts\u2014\nreally, two crises in one. These crises demonstrated the public interest value of the \nelectric grid, along with its inadequacies and vulnerabilities, prompting the \nCalifornia Legislature, with Senate Bill (SB) 1194 and Assembly Bill (AB 995), to pass\nthe Reliable Electric Service Investments Act of 2000. Other similar state policy \nactions reflected these concerns over the readiness of California\u2019s electric grid, \nproviding the bases and important guidance for PIER-funded research and \ndevelopment for that critical infrastructure. In summary, the state began an \nexpanded research effort in the PIER program to develop new technologies to \nenhance electric power delivery capabilities.\nThe Beginnings of the CEC\u2019s PIER and TRP\nUntil 2000, although electric system reliability was included among the possible \ncore areas for research in the public interest identified by legislation, the PIER \nprogram mainly emphasized the underrepresented core areas seen as not being \nadequately pursued by entities with competitive or regulated interests. This left \nmuch of the research on transmission and distribution technologies to be pursued \nby the California investor owned utilities (IOUs) and similar entities. \nThe inadequacies of the electric grid experienced during the California Electricity \nCrisis of 2000 -2001, however, raised doubts that research on the electric grid, \nespecially transmission, was being done at an adequate level. In 2002, SB 1038 \nrevised PIER legislation by adding an emphasis for transmission research. The CEC \ndeveloped the Transmission Research Program (TRP) in response to this legislation, \nas well as other related state administration and agency policies. The primary \nobjective of the TRP was to foster research that would address critical transmission \nissues. \nWhile the CEC maintained responsibility and overall decision-making for the TRP \nprogram and reported results to the California Legislature, a program administrator \ncontractor was selected to provide program vision and strategy development, to \nadminister and facilitate the stakeholder relationships and interactions, to conduct \ncertain project administrative functions, and to supply staff, namely, the TRP \ndirector, an executive assistant, and research coordinators with electric utility \nindustry and R&D management experience. The California Institute for Energy and \nEnvironment (CIEE) of the University of California was selected as that contractor by\na competitive solicitation in 2003.\n1\nThe design and use of an advisory system of stakeholders of the electric grid \ncommunity were key success factors for a practical strategy, design and execution \nof the TRP, and for the timely and effective transfer of the research program\u2019s \nresults to the end users, particularly California electric utilities and the California \nIndependent System Operator (CAISO). It helped to assure that the TRP had the \nright portfolio of research projects, and assisted in making the research products \nused and useful to Californians. The TRP Policy Advisory Committee (PAC) was a \nhigh level advisory committee chaired by an Energy Commissioner and populated \nby a variety of transmission stakeholders such as senior management of the \nCalifornia IOUs, namely Pacific Gas and Electric Co. (PG&E), San Diego Gas and \nElectric Co. (SDG&E) and Southern California Edison (SCE), and by the CAISO, the \nCalifornia Public Utilities Commission (CPUC), renewable advocacy groups, and U.S. \nfederal agencies such as the Department of Energy\u2019s (DOE\u2019s) Office of Electricity \nand Bonneville Power Administration (BPA). The TRP PAC provided guidance on \nstrategy development and priorities, reviewed the TRP performance, and, just as \nimportantly, participated in the \u201cpaths to market\u201d for the research products. \nSubordinate technical advisory committees, consisting of similar stakeholder \nrepresentation as the TRP PAC, but at the engineering manager and practitioner \nlevels, offered technical advice to help design the most productive and effective \nresearch projects, and reviewed the performance of the projects underway. They \ntoo enhanced technology transfer through active participation of the members. \nEach of these advisory committees typically met three or more times a year.\nA hallmark activity of the TRP advisory structure was to bring together informally \nthe advisory committee members and electric grid technology \u201cresearch\u201d experts \nfrom academia, national labs, architect engineers, product vendors and consultants \nto focus on specific grid-related problems. Through iterative interactions these \nteams would better define the problem, and identify possible technology solutions \nand the research needed to close any technology gaps. The ultimate result of these \nexchanges was a TRP portfolio of research projects tailored to solving specific high-\nimportance problems with the best and latest technologies. Another hallmark \nactivity was the increased incidence of research projects that were hosted at \nadvisory committee member grid facilities, thus greatly enhancing the effectiveness\nand timeliness of technology transfer.\n\u201cDeliver a kilowatt-hour from anywhere to anyone at any time\u201d was the TRP PAC \nvision statement of the ideal transmission system. It provided a rich strategic \ncontext and an \u201casymptotic\u201d long-term goal for the TRP. Inherent to the vision, the \nelectric system was seen as a critical infrastructure for efficient markets, public \ngood and national security, where the generators and consumers were clients of the\ntransmission grid\u2019s services. The term \u201cgenerator\u201d included central and distributed \nresources, and the term \u201cconsumer\u201d encompassed a spectrum from local \ndistribution companies to individuals. Accordingly, the TRP saw the mission of a \ntransmission system as one to serve the public interest by delivering adequate, \naffordable, reliable, safe and environmentally-sound electricity from any generator \nto any consumer. Mission success depended critically on avoiding blackouts and \nenabling the consumer to access clean, low-cost, reliable electricity. At the time \nthese two critical success factors were the ones most likely to cause transmission \npolicy makers, planners, owners and operators to lose sleep during the early \nbeginnings of the TRP.\n2\nThe Challenges Facing the California Electric \nGrid and the Shaping of the PIER TRP\nComing out of the electricity crises of 2000\u20132001, the electric grid in California \nfaced a number of challenges. Under investment in transmission during the last two\ndecades of the 20th century, and increasing difficulty with siting, permitting and \nbuilding new transmission, were resulting in rising congestion costs and threatening\nto hamper attainment of the state\u2019s renewable energy generation goals. In the \nattempt to increase economic efficiencies and reliability, while also accommodating \npower markets along with new generation technologies and loads, transmission \noperators found their ability to plan, dispatch and regulate generation impaired \u2013 \nespecially with a growing dependence on the wide-area interconnection in the \nwestern area of North America, known as the Western Electricity Coordinating \nCouncil (WECC). Inadvertent changes to the dynamic behavior of the grid led to \ngreater operational risk, reduction in transmission capacities to provide more \nmargins for managing voltage and dynamic instabilities, and increasing economic \ninefficiencies and congestion. The growth in variable renewable generation was \ncreating rapid ramp-rates, which further challenged grid operations.\nThe ever-increasing reliance on more long-distance multi-state transmission lines in \nthe interconnection to the large, fragile power grid in the WECC was increasing the \nrisk of large widespread outages. Past wide-area outages, such as the 1996 \nblackouts in the western U.S and the 2003 Northeast blackout, had revealed \ndeficiencies in system protection that aggravated the extent of blackouts. \nMeanwhile, the inadequate capability for wide-area, real-time system visualization \nby operators was becoming painfully apparent. This motivated the deployment of \nsynchrophasors, also called phasor measurement units (PMUs), an emerging \nmonitoring technology which, compared to the typical state-of-the-art supervisory \ncontrol and data acquisition (SCADA) systems, was expected to do for transmission \nsystem diagnostics and situational awareness what magnetic resonance imaging \n(MRI) did for medical diagnostics versus old-fashioned X-rays.\nExtreme events, such as the cascading blackouts described above, and storms, \nsuch as \u201cKatrina,\u201d were shaking public confidence in the ability of government and \nprivate institutions to provide robust and resilient infrastructure systems throughout\nmuch of the U.S. The transmission-related effects of the U.S. Energy Policy Act \n(EPACT) of 2005, such as transmission corridors and the Electric Reliability \nOrganization (ERO) Enterprise reliability compliance, were creating complexity for \ngrid operations and planning. Power market competition and budget constraints and\nincreasing replacement costs were leading to aging infrastructure, raising concerns \nabout power system reliability. New public policies and \u201cconsumer\u201d technologies \nsuch as demand response (DR) and distributed generation (DG) offered \nopportunities for improved grid operations, but only if the challenges of integrating \nthese new technologies with the existing grid could be overcome.\nIn 2006, the California legislature passed SB 1250 that contained PIER program \nfunding reauthorization, and direction for electric transmission research to \nemphasize renewable energy delivery, along with reliability and costs of the power \ngrid, to be consistent with emerging energy policy in the state, which was driven to \n3\nreduce greenhouse gas emissions. An evaluation of the PIER TRP in the context of \nSB 1250 showed that the majority of the TRP strategy and portfolio were consistent \nwith new legislative direction. Most of the problems described above facing the \nelectric grid in California would still need to be addressed in order to facilitate the \nintegration of renewable generation with the electric grid. In addition, the \nintegration of many renewable generators \u201cfueled\u201d by variable wind and solar \nenergy resources called for an additional new TRP focus on technology solutions for \nthe challenges unique to these particular generators.\nWith the advent of variable renewable generation in the electric grid, for the first \ntime in history, electric generators did not come with energy storage built-in, i.e., in \nthe forms of stored fuel and the inertia of the rotating mass of the generator. \nWithout the fuel-based energy storage, most solar and wind powered generators \ncannot be dispatched with much certainty and consistency, thus limiting their \ncapacity value. Without the latter characteristic of rotating inertia, solar and wind \ngenerators using electronic power conversion tend to ramp (i.e., increase or \ndecrease power output) much faster than the traditional power plants on which the \nelectric grid was designed to rely, and often in a somewhat random manner. \nCalifornia\u2019s aggressive goals to substantially increase the fraction of electricity \ngenerated by renewables, at both the transmission and distribution levels, \neventually made these issues real, posing special challenges for providing timely \nand adequate grid delivery capacity, maintaining reliability and power quality, and \navoiding economic inefficiencies. \nNew or expanded capabilities for the grid would be needed. In the beginning, \nbuilding new transmission and distribution infrastructure using traditional \u201cwires\u201d \ntechnology seemed sufficient, but as time passed it became increasingly clear that \nnew technologies offered the prospect of providing a substantial portion of the new \nor expanded capabilities, and would be needed to supplement the traditional \n\u201cbuild\u201d solutions. \nMany of these new technologies required additional development before they could \nbe commercially or routinely deployed. The process for identifying the research \nactivities of most value started with identifying the most critical issues facing the \nelectric industry community, and matching new technologies to address those \nissues. However, there often were gaps between the current and desired status of \neach technology. These gaps were identified along with the research, development \nand demonstration needed to work toward closing the gaps. The degree of success \nof this process depended largely on obtaining the best and latest knowledge \nregarding policy, industry and technology by engaging public and private \nstakeholders and technology developers.\nThe TRP Strategy\nEmerging technologies offered solutions if they could be developed and \ncommercialized. To assure acceptable levels of transmission adequacy, reliability, \nsecurity, affordability and environmental compatibility, and to fulfill state policies \nand goals, the TRP since its beginning pursued a consistent set of evolving \ntechnology research strategies ultimately focused on new technologies to:\n4\n\uf0b7 Provide faster access for new remotely-located renewable power plants by \nputting new transmission lines in a \u201cbetter light\u201d through streamlining of the \nsiting process, use of advanced conductors and other measures;\n\uf0b7 Accommodate unique behaviors of variable renewable generators through a \nsmarter and more flexible transmission and distribution grid;\n\uf0b7 Increase transmission capacity by optimizing the grid for greater power flow \nthrough improved hardware and \u201csmart grid\u201d enhancements.\n1. New Technology for Providing Access to the Grid by \nPutting New Transmission Lines in a \u201cBetter Light\u201d\nFor most new remotely located renewable power plants, access to the transmission \nsystem means building new transmission lines between the power plant and the \nexisting transmission grid. By the end of the 21st century, the time for siting and \npermitting processes for new transmission projects had grown to take typically 10 \nto 12 years for a major line. This situation raised concerns that it would take longer \nto build the new transmission extension to a renewable power plant than it would to\nbuild the power plant. It also tended to raise costs.\nThe major barriers to building a new transmission line were societal resistance to \nsiting, e.g., \u201cnot in my backyard,\u201d and benefit identification and cost allocation. In \npursuit of the strategy to provide enhanced access to transmission, technology \nresearch goals were established that (1) reduced the visual profile, and other \nenvironmental and siting impacts, of a transmission line, and perhaps other grid \ninfrastructure, and enabled public process techniques that facilitated \nenvironmental/societal issue definition and resolution and stakeholder interactions; \nand (2) helped the public, and other concerned parties and decision makers, to \nbetter understand and communicate the costs and values \u2013 both economic and \nstrategic \u2013 of transmission projects.\nA wide array of research and development was being done by vendors, federal \nresearch programs, universities and others in advanced compact transmission \ndesigns, new components and materials, undergrounding of lines, and related \nefforts aimed at reducing the footprint and visual impacts of transmission \ninfrastructure. These activities were tracked by the TRP team and communicated to \nCalifornia grid stakeholders through the Policy Advisory and Technical Advisory \nCommittees as strategic input into the CEC\u2019s research portfolio planning process. \nAlso, technology research projects in the TRP portfolio that were primarily targeted \ntoward increasing the power handling capacity of the existing electric grid \ninfrastructure, explained and expanded upon below, could be applied to new \ninfrastructure to enhance public acceptance of siting of new installations. Web-\nbased interactive models were pursued to enable a broader and deeper stakeholder\nengagement with the siting processes for better understanding of environmental, \nsocietal and economic tradeoffs.\nTo facilitate investment in, and permitting of, transmission infrastructure, the \nsecond technology goal was to better understand the value, benefits and costs of a \ntransmission project. It was clear that more transmission infrastructure would be \nneeded, either as new installations or upgrading of existing facilities, especially to \nprovide new generators with access to connect to the backbone transmission \n5\nsystem. It also was clear that building new transmission lines, or even upgrading \nexisting lines, was becoming increasingly contentious and difficult to do because of \nissues with identifying who got what benefits and who should pay for them. The TRP\nlooked for science and technology-based solutions to enhance processes for \npermitting new transmission line corridors and reduce the approval times. To \nfacilitate transmission investment decision-making, the TRP considered research \nthat could develop methodologies for estimating the strategic value of new \ninfrastructure projects, and bring some science to bear on how to allocate the \ninvestment and other costs among those stakeholders enjoying the benefits. To \nbetter understand what conditions drove the need for new investment and where to\nput it, the TRP conducted research in congestion management planning and \nextreme event modeling and management. \n1.1Transmission Cost Allocation Methodologies\nThis project was performed by the Lawrence Berkeley National Laboratory and \nthe Electric Power Group, LLC. The Principal Investigator was Joe Eto.\nThis project documented case histories for addressing the cost allocation \nproblem and developed new methods and approaches for expanding the \nplanning tools for making these investment decisions and providing additional \ninformation for stakeholders involved in decisions, including sharing in the cost \nof transmission projects, i.e., cost allocation. \nWhile reliability-related transmission investments were moving forward, projects \nwhich were viewed as serving an economic, market or policy objective had no \nclear path forward, owing in part to issues related to cost recovery and cost \nallocation. There was a need to research new approaches for assessing benefit \nstreams, beneficiaries, and quantification of benefits for cost allocation and cost \nrecovery for new transmission investments.\nIn early stages of the project, it was found that the use of a screening tool can \nbe very productive to perform quick what-if screening analysis, but not as a \nsubstitute for detail production costing simulation for detailed benefit analysis. In\neconomic transmission projects, the principle of \u201cbeneficiaries pay\u201d should be \nthe basis for cost allocation. The project asserted that attempts should be made \nto quantify primary and strategic benefits of transmission projects in a \ntransparent way so that project participants and beneficiaries can agree on the \nlevel of benefits and who gets what share of these benefits and who pays what \nshare of the costs.\nThe primary benefits of transmission, such as improved network reliability \u2013 \nmeet reliability standards and guidelines, lower cost of energy and capacity \nadjusted for transmission losses as a result of reduced congestion, access to \nlower cost resources, and increased inter-regional power trading \u2013\u00a0were usually \nwell identified in most proceedings, but some other categories of benefits were \nnot.\nSince the transmission system had increasingly become a public good, the use \nof social rate of discount, instead of allowed weighted cost of capital, calculating \nthe present worth of benefits of a new transmission project was recommended. \n6\nAdditional research was identified as needed on quantification of societal \nbenefits of transmission in providing insurance value against extreme events \nthat are low-probability/high-impact events. These conclusions and \nrecommendation along with others are listed next. \nThe research study produced five areas of key conclusions and \nrecommendations:\n1. Assessment of model based traditional benefit quantification methods \ncommonly used in the industry, such as production cost modeling and \npresent worth analysis, showed a number of deficiencies:\na. Models understate benefits of long life assets (50+years) by \ndiscounting future benefits using high interest rate based on cost of \ncapital\u2014essentially reducing the impact of benefits beyond the first 10 \nyears.\nb. Models utilize an expected value approach that tends to minimize the \nconsequences of high impact but low probability (extreme) events.\nc. Models are data intensive\u2014requiring assumptions about future \ngeneration mix, fuel prices, and transmission network.\nd. Models are static with no feedback\u2014they assume no change in \ninvestment for new generation resulting in a zero sum benefit \ndistribution game.\ne. Extreme market volatility and multiple contingency system events, \nwhich can be very costly and risky to society, are not captured in \ncurrent models.\ni. 2001 California market dysfunction\u2014$20\u201340 billion.\nii. 2003 Northeast Blackout\u2014$5\u201310 billion.\n2. The CAISO\u2019s Transmission Economic Assessment Methodology (TEAM) was \nfound to be comprehensive and incorporated many enhancements to \ntraditional production simulation analysis.\n3. Research identified several areas that are amenable to advancement in \nexisting benefit quantification methods as well as quantification of strategic \nbenefits including:\na. Use a social rate of discount to present worth benefits rather than \nutility cost of capital.\nb. Quantifying fuel diversity benefit by taking into account the price \nelasticity of natural gas.\nc. Application of Delphi or other stakeholder consensus generation \nmethods to quantify benefits of mitigating low probability high societal \nimpact events such as major blackouts and market dysfunctions.\nd. Application of dynamic analysis.\ne. Application of portfolio analysis methods commonly used in the \nfinancial services industry.\nf. Developing model based techniques to quantify extreme event \nbenefits.\n4. With acceptance by regulators and policy makers, methods in use could be \naugmented to recognize additional strategic benefits in the following three \nareas:\na. Public Good\nUse a social rate of discount to calculate the present value of benefits \nfor the new transmission project.\n7\nb. Fuel Diversity\nInclude the benefit from a potential decrease of natural gas price due \nto the construction of a new transmission project that integrates a \nsignificant amount of new renewable resources which also reduces \nnatural gas consumption and emissions.\nc. Low-Probability/High-Impact (Extreme) Events\nAdd risk mitigation benefit to society for low probability/high impact \nextreme market events and extreme system multiple contingency \nevents\u2014scenarios or Delphi method for stakeholder consensus.\n5. The study recommended additional research on benefit quantification \nmethods in the following areas:\na. Dynamic Analysis to recognize the impact of new transmission projects\non construction of new generation capacity in exporting regions.\nb. Portfolio Analysis to assess performance of different combination of \ndemand response, renewables and fuel based generation, transmission\nand energy conservation programs. Portfolio analysis methods are \nutilized in the financial industry but research is needed to adapt these \ntechniques to transmission expansion planning.\nc. Quantification of Extreme Event Benefits (Insurance Value) in terms of \nreliability and reduced market volatility. Quantification methods to be \nresearched include application of Value at Risk, Option Value, and \ninsurance premium concept. Reliability benefits can be measured in \nterms of reducing blackout footprint due to extreme (N-n) events \u2013 for \nexplanation, see Extreme Events project described below \u2013 and \nsocietal value of reduced risk and exposure to run away market prices.\nA project presentation to the CPUC on April 23, 2008, made by the CIEE Senior \nAdvisor, Virgil Rose, led the California Division of Ratepayer Advocates (now the \nOffice of Ratepayer Advocates) to file a motion on May 28, 2008, to supplement \nthe record for Investigation 08-03-010/Rulemaking 08-03-009 pertaining to an \nOrder Instituting Investigation on the Commission\u2019s Own Motion to actively \npromote the development of transmission infrastructure to provide access to \nrenewable energy resources for California.\nA project presentation to Transmission Expansion Planning Policy Committee of \nthe Western Electricity Coordinating Council (WECC/TEPPC) led to follow-up from \nDOE, Midwest ISO, Southwest Power Pool, and American Electric Power.\nPublications:\n\uf0b7 Budhraja, Vikram, \u201cImproving Electricity Resource-Planning Processes by \nConsidering the Strategic Benefits of Transmission,\u201d paper LBNL-2547E, \nPeer Reviewed, Lawrence Berkeley National Laboratory, March 15, 2010. \n[http://escholarship.org/uc/item/7dp8d14r]\nSources:\n\uf0b7 Budhraja, Vikram, John Ballance, Jim Dyer, and Fred Mobasheri, (Electric \nPower Group, LLC). 2008. Transmission Benefit Quantification, Cost \nAllocation and Cost Recovery. California Energy Commission, PIER Energy-\nSystems Integration Program. June 2008. CEC-CEC-500-2013-121.\n8\n[http://www.energy.ca.gov/2013publications/CEC-500-2013-121/CEC-500-\n2013-121.pdf]\n\uf0b7 Eto, Joe, Principal Investigator, et al., \u201cTransmission Cost Allocation (and \nStrategic Benefits) Methodologies,\u201d Transmission Research Program \nColloquium, Sacramento, CA, 09/11/2008.\n[http://www.energy.ca.gov/research/notices/2008-09-11_colloquium/\npresentations/02_Transmission_Cost_Allocation_Methodologies.pdf]\n\uf0b7 Before the Public Utilities Commission of the State of California, \nInvestigation 08-03-010, Rulemaking 08-03-009, filed February 5, 2009. \n[http://docs.cpuc.ca.gov/efile/RULINGS/97073.pdf]\n1.2Demonstration of Advanced Conductors for Overhead \nTransmission Lines\nThis project was performed by the Electric Power Research Institute (EPRI). The \nPrincipal Investigator was John Chan.\nAs the overall loading on the electric system increases, the loading on specific \ntransmission lines can approach their steady-state thermal limits. When this \nhappens, the preferred approach is to replace the transmission line conductors \nwith ones of higher capacity. But there is a practical limit to the size (diameter) \nof the conductor that can be installed in place of the old one. Rather than incur \nthe expense of rebuilding the line, which requires considerable capital \ninvestment in new towers, insulators, footings, wider right-of-way and upgraded \nsubstation equipment, a potentially economic approach is to use newer, higher-\ncapacity conductors characterized by advanced materials or physical design, \nallowing higher power flow with a form factor similar to the old conductor.\nThe use of such conductors can be a highly desirable and economic alternative \nfor utilities who need to increase power transfer through a restricted right-of-\nway. Typically, the new advanced conductor is physically similar in most \nrespects to the old conductor, so environmental and permitting issues are \nrelatively minor. Such is not the case with the alternatives, such as voltage \nuprating, which is much more costly, time-consuming, and requires a \ncomprehensive regulatory review and approval process.\nThis project comprised a collaborative research effort to evaluate the operational\nperformance of advanced High-Temperature, Low-Sag (HTLS) conductors \nthrough approximately three years of field experience with conductors installed \nin actual utility systems. Five specific designs of HTLS conductors were \nevaluated, including: Aluminum Conductor Steel Supported/Trapezoidal Wire \n(ACSS and ACSS/TW), Gap-type Aluminum Conductor Steel Reinforced \n[G(Z)TACSR], Aluminum Conductor Invar Steel Reinforced [(Z)TACIR], Aluminum \nConductor Composite Reinforced (ACCR), and Aluminum Conductor Composite \nCore (ACCC). The project was intended to provide general information on \ninstallation methods and requirements; actual in-service performance vis-\u00e0-vis \ndesign specs, e.g., sagging, creep, etc.; and information about their long-term \nbehavior at different electrical current levels and in various geographical locales.\nKey information is provided on design, installation, operation, and maintenance \nof selected HTLS conductors and their hardware accessories.\n9\nResults and Findings\nThe project involved field trials at four utility test sites: CenterPoint Energy, \nHydroOne, Arizona Public Service, and San Diego Gas & Electric. The project \nreport includes descriptions of data monitoring systems and instrumentation for \neach site. The report specifically includes information on the accessories used \nwith HTLS conductors (splices, dead-ends, and terminations) and discusses the \ncomplex process of estimating service life of HTLS conductors based on the \nmanufacturers\u2019 technical and laboratory test data as well as the field data \nobtained in this study.\nSeveral manufacturers in United States and abroad have developed advanced \nnew HTLS conductors for use in high-voltage transmission lines. These \nconductors are designed to overcome the traditional limiting factors in conductor\nperformance in terms of strength loss and sag increase by being capable of \ncontinuous operation at temperatures above 100\u00baC while exhibiting low thermal \nelongation with temperature. The goal of this project was to gain practical \nexperience in handling, installing, and terminating these new types of \nconductors and to verify in practice the claims of manufacturers regarding their \nperformance in an operating transmission line.\nThis project documented specific aspects of stringing, sagging, and clipping of \nvarious commercially available HTLS conductor systems and evaluated the \nactual physical behavior of HTLS conductors in operating transmission lines as \ncompared to the various manufacturer-supplied design parameters in use by \nutilities. The results of this work will help utility participants choose when to use \nsuch conductors, how to choose between various types, and how to avoid \nproblems during installation and over the life of the line.\nProject Conclusions:\n\uf0b7 One of the primary limitations on high temperature operation of ordinary \nbare stranded aluminum conductors is loss of aluminum tensile strength. \nEven when the aluminum strands have a substantial steel stranded \nreinforcing core, continuous operation is typically limited to 100oC or less. \nHTLS conductors can operate continuously at temperatures between 150oC \nand 250oC depending on the particular design and wire materials.\n\uf0b7 Those HTLS conductors which employ annealed aluminum are observed to \nhave a lower elastic modulus than conventional ACSR. In geographical \nareas which experience severe ice loadings, this type of HTLS conductor \nmay yield sags under heavy loading conditions which are comparable or \neven larger than the sag at high temperature.\n\uf0b7 If HTLS conductors with annealed aluminum strands are pre-stressed, one \nmay expect their self-damping properties to be very favorable and initial \nstringing sags may be quite small without causing vibration fatigue.\n\uf0b7 Those HTLS conductors which employ high temperature resistant alloys of \naluminum (e.g., TAL and ZTAL), have an elastic modulus which is \ncomparable to conventional ACSR of the same stranding. While the sag \nunder heavy loading conditions observed with these HTLS conductors is \nlikely to be less than their high temperature sag, their high elastic modulus \nis likely to result in relatively high structure loads.\n10\n\uf0b7 HTLS conductors with TAL or ZTAL aluminum are likely to yield self-damping\nproperties which are similar to conventional ACSR.\n\uf0b7 Limited corona testing of the various HTLS conductors indicates that these \nconductors are likely to yield corona noise levels similar to conventional \nACSR of the same diameter.\n\uf0b7 Each of the HTLS conductors studied appears to have suitable connectors \nand hardware available. There is no reason to suspect that these conductor \nsystems are unreliable in the short run (up to 5 years).\n\uf0b7 The installation of the various HTLS conductors does not appear to be a \nproblem. The most complex conductor system to install is the Gapped HTLS\n(G(Z)TACSR). The simplest conductor system is probably the ZTACIR \nconductor since the aluminum is not subject to damage during stringing \nand the core is not particularly sensitive to shear forces.\n\uf0b7 There does not appear to be a compelling reason to choose one of the HTLS\nconductors over the others except possibly for cost. All of the HTLS \nconductors studied have the following characteristics:\n\u2013 Has a low thermal elongation rate.\n\u2013 Can operate continuously at temperatures well above 100oC without \nany deterioration of mechanical or electrical properties.\n\u2013 Has the same or lower resistance as the original conductor of the same \nouter diameter.\nIt is less clear which of the HTLS conductors studied in this project will work best \nin a particular uprating situation. However, stress-strain models for each of the \nHTLS conductors are available and utility engineers can evaluate each of the \nchoices in a given uprating problem.\nThe best conductor choice ultimately depends on the existing clearance buffer, \noriginal design margins, environmental loading conditions, and the magnitude of\nthe desired rating increase. The case study shows how HTLS conductors can be \nsuccessfully used to obtain thermal rating increases of at least 50% and \nminimizing the need for expensive structure modifications.\nSources:\n\uf0b7 J. Chan, B. Clairmont, D. Rueger, D. Childs, S. Karki, D. Douglass. \n\u201cDemonstration of Advanced Conductors for Overhead Transmission Lines.\u201d\nEPRI, Palo Alto, CA: 2008. \n\uf0b7 Douglass, Dale. 2001. \u201cThe Objectives of Ampacity Uprating.\u201d IEEE PES \nMeeting, May 2001. Volume 1, Issue, 2001 Page (s):169\u2013174.\n\uf0b7 J. Maz\u00f3n; I. Zamora; P. Egu\u00eda; E. Torres; S. Migu\u00e9lez; R. Medina; J. R. Saenz. \n\u201cGap-type Conductors: Influence of High Temperature in the Compression \nClamp Systems.\u201d IEEE Bologna Power Technical Conference, June 23rd-26th,\nBologna, Italy, 2003.\n\uf0b7 Ahmad Alawar, Eric J. Bosze, and Steven R. Nutt. \u201cA Composite Core \nConductor for Low Sag at High Temperatures.\u201d IEEE Transactions on Power \nDelivery, Vol. 20, No. 3, July 2005.\n\uf0b7 F. R. Thrash. \u201cACSS/TW \u2013 An Improved High Temperature Conductor for \nUpgrading Existing Lines or New Construction.\u201d Power Engineering Society \n11\nSummer Meeting, 2001. IEEE Transactions, Volume 1, Issue, 2001, pp. 182-\n185.\n\uf0b7 EPRI. 2000. \u201cTransmission Line Upgrading Guide.\u201d EPRI, Palo Alto, CA: 2000.\n\uf0b7 Lee Sung-Doo, Koo-Yong Shin, Hyuk-Jin Song, Dong-II Lee, Byung-Uk Min. \n\u201cThe Sag and Fatigue Properties of STACIR/AW as a High Temperature, Low \nSag Conductor.\u201d International Conference on Power System Technology, \nChongqing, China, 22-26 October, 2006.\n\uf0b7 EPRI. 2002. \u201cHigh Temperature Low Sag Transmission Conductors.\u201d EPRI, \nPalo Alto, CA: 2002.\n\uf0b7 3M. 2004. \u201cAluminum Conductor Composite Reinforced Technical Notebook \n(795 kcmil family): Conductor and Accessory Testing.\u201d 3M, St. Paul, MN.\n\uf0b7 P. Springer. 2002. Techniques for In-service and Laboratory Assessment of \nSplices and Conductors from Overhead Lines.\u201d IEEE Power Engineering \nSociety Summer Meeting, Volume 2, Page (s):710 \u2013 712.\n\uf0b7 Kinectrics, 2004. \u201cHigh Temperature \u2013 Sag Characterization Test on 1020 \nKcmil ACCC/TW Conductor for Composite Technology Corporation.\u201d \nKinectrics North America Inc., Toronto, Ontario, Report No.: K-422024-RC-\n0003-R00.\n\uf0b7 Tamm, C.R. 2003. Application Dynamics of High Temperature Conductors in\nFull Tension Splices and Dead-ends.\u201d 2003 IEEE PES Transmission and \nDistribution Conference and Exposition, 7-12 Sept. 2003, Volume: 3, \npage(s): 865- 869.\n\uf0b7 Dale Douglass and Abdel-Aty Edris. 2002. \u201cMaximize Use of Existing \nRoutes.\u201d Transmission & Distribution World, May 1, 2002.\n\uf0b7 CIGRE, Technical Brochure 244: \u201cConductors for the Uprating of Overhead \nLines.\u201d Working Group B2.12, April 2004.\n2. New Technology for Accommodating Variable Renewable\nGenerator Unique Behaviors\nTechnologies that mitigate variable renewable generation impacts help operators \nprepare for and react to problems such as fast ramp rates, and better forecast the \nvariable renewable behaviors for solar and wind all supported the goal of \naccommodating these generators on the grid, and ultimately recruiting them for \nbeneficial contributions. \nSolar power characteristically ramps up in the morning and down in the evening \nwith no nighttime output, but with a power profile that varies with the season. It \nalso exhibits short-term variations due to cloud cover. Solar photovoltaic (PV) \ngenerators use solid-state inverters without the physical inertia described earlier, \nand therefore will react much more quickly to transients. Little was known about the\neffects of large penetrations of these low-inertia generators on the transmission and\ndistribution systems.\nWind power tends to be higher at night in California and also is subject to short-\nterm variability from changes in wind speed. The dynamic behavior of wind \ngenerators is different from typical thermal generators and generally has lower \ninertia, and exhibits significant differences among different types of wind turbine \ndesigns. Generator models used for transmission planning did not accurately model \n12\nwind generator behavior in the transmission system, and increased the level of \nuncertainty for the operator and threats to reliability. \nThe up and down power ramp rates for both solar and wind generators tend to be \nmuch faster than those for conventional utility generators. These rapid ramp rates \nposed significant challenges in maintaining reliability, power quality, and low \nregulation and ancillary costs.\nThe TRP focused on developing \u201csmart\u201d technologies that would help operators \nreduce uncertainty and minimize costs by forecasting the future state of the grid \nand the system resource needs for handling the ramp rates and variability of \nrenewable generators. The TRP also advanced the development of an analytical \nmodeling tool to reduce the costs of managing renewable generation through the \noptimum shared use of resources such as energy storage, demand response and \ndistributed generation among control areas over a wide region. Likewise, research \nwas done to improve and update load and generator models used for planning in \nthe WECC and California electric grid thereby improving the capability to maintain \nreliability.\n2.1Critical Operating Constraints Forecasting for California \nIndependent System Operator (CAISO) Decision Support\nThis project was performed by the Electric Power Research Institute (EPRI). The \nPrincipal Investigator was Stephen T. Lee.\nIn California\u2019s power market, while demand forecasting is well handled, tools for \nprojecting the balance of energy supply and demand through the rest of the day \nare not adequate. When resource margins become very short, knowing in \nadvance when and how severe various transmission operating constraints would \nbecome is tremendously valuable to the grid operators. \nDuring the 2005 summer season, CAISO encountered conditions of very tight \nresource margins and serious congestion problems in Southern California. It was \nfortunate that Southern California had a mild summer in 2005 with peak \ntemperature reaching only 95 degrees, far short of the possible peak of 102 \ndegrees. In anticipation that conditions in future summers could likely be much \nworse due to increasing demand for electricity and the limited transmission \ncapacities into Southern California, this research project was initiated.\nAdvance knowledge of even a few hours of where these constraints would \nappear would enable the operators to take action to mitigate the problem before\nit occurs. Improved forecasting of critical operating constraints in the next 24 \nhours can increase the reliability and efficiency of the California electricity \nsystem. With the increased levels of renewable penetration, the volatility of \npotential transmission constraints due to wind and solar generation will be \nmagnified and create significant challenges for CAISO in managing the power \ngrid. Avoiding a blackout can potentially save Californians hundreds of million \ndollars. The risk of blackouts will likely increase in the future with the high \npenetration of renewable generation, power markets and new electric customer \nappliances and equipment, so improvements in forecasting critical operating \nconstraints could yield significant cost savings, help achieve California\u2019s policy \n13\ngoals for CO2 reduction, and provide reliable and low cost electricity to the \nState\u2019s power consumers with minimum environmental impacts. \nThe main goal of this research project was to provide CAISO with the decision \nsupport capability to look ahead for the next 24 hours and predict whether the \nsystem will be able to get through the day without running into critical operating\nconstraints, such as line overloads or low voltages, under credible contingencies.\nSpecific objectives were to enable the simulation of various scenarios of power \nimportation or other alternatives such as load reduction to find the best way to \navoid such problems and to provide a functional specification for the \ndevelopment of a commercial version of the tool. \nThis project consisted of the development of a prototype tool based on the \nElectric Power Research Institute (EPRI) Community Activity Room (CAR). The \nCAR presents constraints as boundaries in a space with the current status as a \nposition in that space and the distance to a boundary as the margin. The \nprototype was evaluated using historical data and its predictions were compared\nwith actual observations.\nTo promote the commercialization of this concept, the methodology of the \nprototype tool was specified in detail in a functional specification document. The \nresults of the research were presented in a workshop November 7, 2007 in \nFolsom, California, with the intent to make this technology available to any \ncommercial software developer who wished to turn this method into a \ncommercial product. \nThis project successfully developed the methodology for Critical Operating \nConstraint Forecast (COCF) tool, and tested it in a prototype with support from \nCAISO for testing and demonstration. The results showed that this method is \ncapable of forecasting loading of transmission paths over the next 24 hours, \nusing current data on the transmission paths flows and assumptions about \nwhere the generation deficit would be supplied for the rest of the day. The model\nprovided the ability to the user to try different import scenarios to simulate how \nto avoid the potential critical operating constraints. Knowing an approximate \ntime when the constraints might become critical will be very useful for the grid \noperators to prepare for any emergency remedial actions, such as appealing for \nload reduction, etc. The results of the COCF tool compared well with the results \nof the planning study. \nThe significance of this project is that a technically viable tool can be developed \nby commercial vendors of Energy Management Systems, using the functional \nspecifications in a companion report of this project, which was presented and \nmade available at the previously mentioned workshop. The knowledge for \ndeveloping such a decision support tool is now in the public domain. \nOn a normal day, such critical conditions may not occur. However a tool like this \ncan ascertain that this is indeed the fact for the current day, and provide \nsituational awareness of a reassuring kind. When the conditions become more \nstressed, e.g., when there are transmission lines on scheduled or unscheduled \noutages, and when loads are increasing and imports or exports are also \nincreasing, the ability to look through the rest of the day would become critically\n14\nneeded. Such an emergency operation tool would pay for itself with one such \nuse. \nEPRI continues to use the techniques of the COCF work in developing an industry\ntool for Visualization of Operating Boundaries (VOB) and conducting fundamental\nresearch in support of on-line analysis and situation awareness in the control \ncenter.\nAmong the recent reports and other deliverables on this subject are:\n\u2190 T. Tinoco De Rubira (2015). Numerical Optimization and Modeling \nTechniques for Power System Operations and Planning, PhD Thesis, \nStanford University.\n\u2190 R. Entriken, W. Murray, and T. Tinoco De Rubira (2015). \"Linear analysis for \ndetermining and visualizing critical thermal boundaries of power systems\" \nProceedings of the 2015 IEEE PES Innovative Smart Grid Technologies \nConference, February 2015.\n\u2190 Visualization of Operating Boundaries: Case Study for ISO-NE. EPRI, Palo \nAlto, CA: 2014. 3002004872. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000003002004872 \n\u2190 Critical Operating Boundaries: Automated Identification and Visualization of \nThermal and Voltage Limits. EPRI Palo Alto, 2014. 3002002875. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000003002002875 \n\u2190 Visualization of Operating Boundaries: Case Study for Southern Company. \nEPRI, Palo Alto, CA: 2013. 3002002496. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000003002002496 \n\u2190 T. Yong, R. Entriken, and P. Zhang (2009). Program on Technology \nInnovation: An Investigation of the Stability Region Concept Applied to \nStability-Constrained Optimal Power Flows. EPRI, Palo Alto, CA. 1018392.\nWhile the research progress has been full of success, the research efforts are \nongoing The technology is not yet mature enough for commercial use. \nSources:\n\uf0b7 Lee, Stephen, 2008. \u201cCritical Operating Constraints Forecasting \u2013 A Decision\nSupport Tool.\u201d California Energy Commission, PIER Program. CEC-500-2012-\n067. [http://www.energy.ca.gov/2012publications/CEC-500-2012-067/CEC-\n500-2012-067.pdf]\n\uf0b7 \u201cCritical Operating Constraints Forecasting for California Independent \nSystem Operator (CAISO) Decision Support,\u201d Research Project Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nCOCF_FactSheet.pdf]\n15\n\uf0b7 Personal Communication: Robert Entriken, Electric Power Research \nInstitute, Palo Alto, CA.\n2.2Tools for Online Analysis and Visualization of Operational \nImpacts of Wind and Solar Generation\nThese projects were performed by the Pacific Northwest National Laboratory \n(PNNL). The Principal Investigator was Yuri Makarov.\nInteracting wind, solar, and load forecast errors can create significant \nunpredictable impacts on the transmission system, including increased \ncongestion, reduced voltage and reactive power stability margins, among others.\nThese impacts will increase along with the increasing penetration levels of \nvariable renewable generation in the Western Interconnection and California \npower systems. To maintain a secure system reliability level, the probability and \nthe magnitude of the impacts should be evaluated and communicated to the \nsystem operators. Based on this information, the system power flow limits, \ngeneration dispatch, voltage levels, and available reactive power margins could \nbe adjusted to minimize the risk of system problems and failures to an \nacceptable level whenever it is required.\nTo facilitate wider penetration of renewable resources without compromising \nsystem reliability, three tools intended for use by California Independent System \nOperator (CAISO) power grid operators were developed for predicting and \ndisplaying the operational impacts of uncertainties in forecasts of loads and \nrenewable generation. The first tool (\u201cRamping Tool\u201d) addressed real-time (load \nfollowing) capacity and ramping requirements, the second (\u201cTransmission Tool\u201d) \naddressed voltage stability and transmission congestion caused by renewables \nresources (mainly wind power and solar power generation), while the third tool \n(\u201cDay Ahead Regulation Tool\u201d) predicted capacity, ramping rate and ramp \nduration requirements of regulation, including upward and downward \nrequirements, for each operating hour of a day. The Ramping Tool is an industry-\ngrade product connected to the CAISO systems and operated in real time in the \nCAISO Control Center. The Transmission Tool and the Day Ahead Regulation Tool\nhave been developed to the prototype stage.\n2.2.1 Transmission Forecasting Tool\nThe objective of this work was to develop a prototype tool to identify \ntransmission problems, posed by the variability of wind and solar generation, \n1 to 3 hours ahead of time, and inform operators about potential risks for the \npurposes of early warning and preventive control. As noted before, the scope \nwas limited to developing a prototype tool that implements and \ndemonstrates the main developed methods and models, and fully illustrates \nthe advantages of the methodology.\nThe transmission tool is a standalone working prototype product that \ndemonstrates the key features and advantages of the methodology \ndeveloped. The initial design incorporated all required essential \ninformational, analytical, and visualization functions. Further development \n16\nand integration with vendor-supported software at CAISO are necessary for \ndeployment. \nAfter the beginning of this project, CAISO implemented a real-time voltage \nstability analysis (RTVSA) tool (VSA&E tool initially developed by the \nConsortium for Electric Reliability Solutions (CERTS) and commercialized by \nBigwood Systems Company, described elsewhere in this paper), and \nadvanced visualization and data processing tools (developed by Space Time \nInsight Company). In this situation, the priorities and scope for project were \nchanged by CAISO. Development of a stand-alone, fully-functional \ntransmission tool would have been redundant. Based on the recommendation\nof the CAISO project support team, a decision was made to develop a \ntransmission tool prototype and its integration approach with the tools \nalready installed and used by CAISO. The connectivity issues were addressed \nin this effort from the methodology and system model perspective to provide \nfuture connectivity of the future industry-grade applications with the CAISO \nsystems generally, and with the Bigwood real-time stability analysis \napplications, as well as with the Space Time Insight visualization tools.\nThe developed methodology was based on Monte Carlo simulations and \nstatistical analysis of various sources of uncertainty that can impact the \ntransmission network. The developed methodology also included a linearized \npower flow model to calculate incremental active power flows in the \ntransmission network caused by forecasting errors.\nThe prototype tool that was developed demonstrated the methodology, \ndesign considerations, system architecture, simulation results, and the \ngraphical user interface (GUI). The power system model and the methodology\nto determine the probabilistic thermal congestion limits based on power \ntransfer distribution factor were presented. The five key system modules, i.e.,\npower flow module, power transfer distribution factors (PTDF) module, \nforecast error module, probability congestion module and interface module, \nwere also demonstrated. Currently, the developed transmission tool is in a \nprototype stage, based on a simplified model and data. Future work is to \ninstall and test the tool in a real control center using actual system models \nand data.\n2.2.2 Ramping Forecasting Tool\nBecause conventional generators need time to be committed and dispatched \nto a desired megawatt level, scheduling and load following processes use \ncustomer load and wind power production forecasts to achieve future balance\nbetween conventional generation and energy storage on the one side and \nsystem load, variable resources (such as wind and solar generation), and \nscheduled interchange on the other side. The power system process that \nbalances supply and demand, which includes scheduling, real-time dispatch \n(load following), and regulation processes, is traditionally based on \ndeterministic models.\nUncertainties in forecasting the output of variable resources such as wind and\nsolar generation, as well as system loads, were not reflected in an existing \n17\nenergy management system (EMS) or tools for generation commitment, \ndispatch, and market operation. With the growing penetration of intermittent \nresources, these uncertainties could result in significant unexpected load-\nfollowing and dispatch problems, and pose serious risks to control and \noperation performance characteristics as well as the reliability of a power \ngrid. Without knowing the risks posed by the uncertainties, system operators \nhad limited means to weigh the likelihood of occurrence and the magnitude \nof problems to mitigate adverse impacts caused by them. Some important \nquestions needed to be addressed in counteracting the impact of \nuncertainties; for instance, whether and when one should start more units to \nbalance against possible fast ramps in the future over a given time horizon.\nIt was recognized that it is very important to address the uncertainty problem\ncomprehensively by taking all sources of uncertainty (load, intermittent \ngeneration, generators\u2019 forced outages, etc.) into consideration. All aspects of\nuncertainty, such as the imbalance size (which is the same as the capacity \nneeded to mitigate the imbalance) and generation ramping requirement, \nmust be taken into account. The latter unique features made this research \nproject a significant step forward toward the objective of incorporating wind, \nsolar, load, and other uncertainties into power system operations.\nThe product estimated and incorporated uncertainty ranges for wind power \ngeneration forecasting, demand forecasting, and generation supply \ninterruptions caused by forced outages to provide the required generation \nperformance envelope including balancing capacity, ramping capability, and \nramp duration. A probabilistic algorithm, based on a histogram analysis to \nassess the capacity and ramping requirements, is presented. A simulation \nwas performed using the California Independent System Operator (CAISO) \nsystem model and data. The project report also presented these simulation \nresults confirming the validity and efficiency of the proposed solutions.\nThe work pursued the following objectives: \n\uf0b7 Develop a probabilistic model to evaluate uncertainties of wind and load \nforecast errors and to provide rapid (every 5 minutes) look-ahead (up to \n5-8 hours ahead) assessments of their uncertainty ranges. \n\uf0b7 Improve existing models to evaluate uncertainties caused by generator \nrandom forced outages, failures to start up, and contingency reserve \nactivation processes.\n\uf0b7 Create an integrated tool that consolidates the above-mentioned \ncontinuous and discrete random factors contributing to the overall \nuncertainty, to evaluate look-ahead, worst-case balancing generation \nrequirements (performance envelopes) in terms of the required capacity,\nramping capability, and ramp duration.\n\uf0b7 Build a methodology and procedures for self-validation of the predicted \nperformance envelope for each look-ahead interval.\n\uf0b7 Develop visualization displays to communicate information about the \nexpected ramps and their uncertainty ranges.\n\uf0b7 Develop a framework for integration of the tool into the CAISO\u2019s Energy \nManagement System (EMS) and market systems.\n18\n\uf0b7 Use actual CAISO data to perform simulation. \nThe following results have been achieved in this work:\nInnovative methodology and software tools were developed that are capable \nof evaluating future generation requirements, including the required \ncapacity, ramping capability, and ramp duration capability (performance \nenvelope) in view of uncertainties caused by wind and solar generation and \nload forecast errors. The approach includes three stages: 1) forecast and \nactual data acquisition, 2) statistical analysis of retrospective information, \nand 3) prediction of future grid balancing requirements for specified time \nhorizons and confidence intervals.\nAssessment of the capacity and ramping requirements was performed using \na specially developed probabilistic algorithm based on a histogram analysis \nincorporating all sources of uncertainty and parameters of a continuous and \ndiscrete nature:\n\uf0b7 A \u201cflying brick\u201d method has been developed to assess the look-ahead \nworst-case performance envelope requirement to be able to enable the \nsystem to accommodate the uncertainties with certain specified degree \nof confidence. The \u201cflying brick\u201d concept is to simultaneously include the\nramp rate, ramp duration, and capacity requirements directly in the \nbalancing process.\n\uf0b7 A self-validation approach has been used. The purpose of the self-\nvalidation algorithm is to verify that the uncertainty ranges predicted \nbased on retrospective information are valid for the future dispatch \nintervals.\n\uf0b7 An industrial software tool has been developed and tested. \n\uf0b7 Simulations using actual data provided by this project\u2019s CAISO \nengineering support team have been carried out. Simulation results \nhave shown that the proposed methodology is quite accurate and \nefficient. \n\uf0b7 The concept of probabilistic tool integration into EMS has been \ndeveloped. The concept includes three levels of integration: a passive \nlevel, an active level, and a proactive level. The passive integration level\nintegrates wind forecast information and its visualization without \nintroducing any changes to the EMS algorithms. On the active level, the \nunit commitment (UC) and economic dispatch (ED) procedures are \nrepeated several times for every dispatch interval to determine whether \nthe system can meet the limits of generation requirements caused by \nuncertainties for a certain confidence level. The system \u201cbreaking \npoints\u201d are communicated to the user. The proactive level required \nsome modifications of the UC and ED algorithms in order to directly \nincorporate uncertainties into these procedures. In this case, the \ngeneration units will be committed and dispatched, so that these \nuncertainties would not create \u201cbreaking points.\u201d\n19\n2.2.3 Day Ahead Regulation Requirement Prediction Tool\nRegulation is a process of providing minute-to-minute system balance by \nadjusting power output of units connected to the automatic generation \ncontrol (AGC) system. Regulation is an expensive resource; the annual price \nof regulation at the time of this research significantly exceeded $120 million  \nin California.  At the time of this project, the regulation capacity was \ncalculated by the CAISO on a day head basis, for each operating hour of the \nnext day. There is a growing concern at the CAISO that the increasing \npenetration of variable renewable resources in California could result in \nadditional regulation needs.\nMost of CAISO\u2019s \u201conce-through cooling (OTC)\u201d generating units using \nseawater for cooling, located along California\u2019s Pacific coast, are expected to \nbe retired or retrofitted within the next decade. These units have traditionally\nbeen used to provide balancing services for CAISO, and their retirement could\npotentially create a deficiency in available regulation resources. (The later \nunexpected shutdown of the San Onofre Nuclear Generator exacerbated this \nproblem.) The consequent decline in available regulation resources could \npotentially increase the price of regulation as more regulation procurement is\nneeded. These challenges motivated CAISO to obtain a tool capable of \npredicting the needed procurement of up- and down-regulation services in \nthe day-ahead market.\nThe goal of this project was to minimize the cost of regulation by developing \nan operational tool for providing a more scientific forecast of the CAISO\u2019s \nregulation requirement on the day-ahead basis for some operating hours \nwithout compromising CAISO\u2019s control performance characteristics. The tool \ncan be used to calculate the regulating capacity, ramping and ramp duration \nrequirements for each operating hour of a day, separately for the power \nupward and downward generation requirements.\nThe objective of this project was to develop an approach to procuring \nregulation capacity that would minimize the regulation capacity required \nduring some operating hours without compromising CAISO\u2019s control \nperformance characteristics. The chosen approach predicted CAISO\u2019s \nregulation requirement on a day-ahead basis by calculating the required \nregulating capacity, ramping rate (rate of change of the regulating units\u2019 \noutput) and ramp duration (how long the ramp should be maintained), \nincluding upward and downward, for each operating hour of a day.\nIn this project, three methods were developed. The methods differ by the \napproach used to calculate the regulation requirement and by the type of \ncontrol performance criteria used. The first and second methods are close in \nphilosophy to the existing Control Performance Standard 2, (CPS2), which \nlimits ten-minute averages of the area control error (ACE) to below a certain \nvalue, \u201cL10,\u201d specified by the North American Electric Reliability Corporation \n(NERC).\n\uf0b7 The first method evaluates regulation requirements based on statistical \nanalysis of all components of the regulation requirement: forecast errors\n20\n(load, wind and solar generation), uninstructed generation unit \ndeviations, frequency errors, and metering error correction.\n\uf0b7 The second method predicts regulation requirements based on a \nstatistical analysis of ACE signals and actual regulation applied in the \nsystem.\n\uf0b7 The third method was based on a new standard that was currently under\ntrial use in the industry. It evaluates the regulation requirement in order \nto meet the new Balancing Authority ACE Limit (BAAL) standard, by \nwhich instantaneous values of ACE are limited by frequency-sensitive \nACE limits. Like the second method, it is based on a statistical analysis of\nthe actual ACE and frequency information.\nA methodology for estimating regulation requirements taking into account \nthe new control performance standard (BAAL) was developed in this project. \nSimulations showed that CAISO regulation requirements can be substantially \nreduced because the BAAL standard allows a BA to operate in a wider ACE \nrange compared with the previous CPS2 standard.\nAll three methods use historical information, obtained prior to the analyzed \noperating day (a moving window for a user-specified period). The \nperformance of the proposed methods can be further improved by \nincorporating ramp and uncertainty information provided by the CAISO wind \nand solar forecast service providers.\nA software tool was developed, which includes a graphical user interface \n(GUI), algorithms for detecting and correcting input data outliers, an Oracle-\nbased database, and a self-validation procedure. The tool implements the \nfollowing main features:\n\uf0b7 Prediction of hourly-specific regulation requirements for the next \noperating day, which can potentially help the CAISO to save money on \nregulation cost;\n\uf0b7 Detailed visualization of input data and results, making the process \ntransparent and user-friendly to the CAISO operators and engineers;\n\uf0b7 Flexibility (different confidence levels, moving-window sizes, etc.) \nallowing CAISO engineers to fine-tune the tool to their needs, including \nthe level of compliance with the existing control performance standards;\n\uf0b7 Self-validation of predicted results, providing a self-control feature for \nthe accuracy of the algorithm; and\n\uf0b7 Detection of outliers and statistical analysis of input data (distribution, \nstandard deviation, mean value) to help in detecting and eliminating bad\ndata.\nThe project identified next steps that would increase the robustness and \nperformance of the tool while handling imperfect information typically \navailable in control centers. These steps include: \n\uf0b7 Improving the probabilistic models to additionally reduce regulation \nrequirements\n\uf0b7 Adding model components reflecting new sources of uncertainty \n21\n\uf0b7 Putting more emphasis on the regulation requirements posed by the \nnew NERC control performance standards\n\uf0b7 Deploying the tool in the CAISO control center, and potentially in the \nIOUs\u2019 and other control centers in California. \nThe results of these research efforts have been used for some follow-on \ndevelopments:\n\uf0b7 The CAISO is modifying the Ramping Tool to move it to production level for \n24/7 operation in the Control Center. The Ramping Tool predicts potential \ndeficiencies of the balancing capacity in the system. \n\uf0b7 Building on this research, AWS Truepower (project manager), CAISO, \nSouthern California Edison (SCE), and Siemens are participating in a DOE \nSunShot project: \u201cComprehensive Solutions for Integration of Solar \nResources into Grid Operations,\u201d to demonstrate integration of uncertainty \ninformation into grid system operations and probability-based controls.\n\uf0b7 Based on the Ramping Tool development, a Dynamic Interchange \nAdjustment tool (DINA) was developed for ISO-New England (ISO-NE). This \nprobability-based tool predicts the secure range of intra-hour interchange \nadjustments to trading balancing capacity with the neighbors. ISO-NE \nintends to move the tool to a production level.\n\uf0b7 In new PNNL projects with BPA and DOE, some key concepts developed in \nthis research will be used for predictive state estimation.\nThere have been a number of follow-on or related funded efforts that \ncomplement these PIER-funded projects just described:\n\uf0b7 FY2010: DOE Office of Energy Efficiency and Renewable Energy (EERE) \nproject \u201cIncorporating Wind Generation and Load Forecast Uncertainties \ninto Power Grid Operations,\u201d $700 K.\n\uf0b7 FY2012-FY2013: Internal PNNL Use at Facility Funds (UAFF) project \u201cRamp \nand Uncertainty Tool,\u201d $75 K.\n\uf0b7 FY2013-FY2014: DOE OE project \u201cStochastic Operations and Planning,\u201d \n$100K.\n\uf0b7 2012-2013: ISO New England (NE) project \u201cAnalysis of ISO NE Balancing \nRequirements: Uncertainty-based Secure Ranges for ISO New England \nDynamic Interchange Adjustments,\u201d $90K.\n\uf0b7 2014: CAISO project \u201cRamping Tool Modification,\u201d $60K.\n\uf0b7 FY2013-FY2015: DOE OE project \u201cProbabilistic Methods for Planning and \nOperations,\u201d $700 K.\n\uf0b7 FY2014-FY2015: DOE EERE SunShot Initiative project \u201cComprehensive \nSolutions for Integration of Solar Resources into Grid Operations,\u201d led by \nAWS Truepower, $820K.\n\uf0b7 FY2013-FY2015: Internal PNNL Laboratory-directed Research and \nDevelopment (LDRD) project \u201cOperations and Planning Fusion,\u201d $612K.\n\uf0b7 FY2014-FY2015: BPA/DOE/Alstom project \u201cFaster Than Real Time State \nEstimation with Forecast for Multiple Contingency Analysis,\u201d $800K.\nThese projects bring about $4M additional funding to advance this technology \narea.\n22\nUse of some of the tools for online analysis and visualization of operational \nimpacts of variable renewable generation demonstrated capability to eliminate \nreal-time market price spikes. ISO NE will be able to trade its balancing capacity \nwith its neighbors without compromising its performance and reliability. A \ncost/benefit analysis is part of the DOE OE project \u201cProbabilistic Methods for \nPlanning and Operations\u201d described above.\nPublications:\n\uf0b7 P. V. Etingov, Y. V. Makarov,  N. A. Samaan, J. Ma, C. Loutan,  and M. \nRothleder, \u201cPrediction of  Regulation Reserve Requirements in California ISO\nControl Area based on BAAL Standard,\u201d  IEEE PES General Meeting, \nVancouver, British Columbia, Canada, July 21-25, 2013.\n\uf0b7 Y. V. Makarov, P. V. Etingov, N. A. Samaan, J. Ma and  C. Loutan, \u201cPredicting \nDay-Ahead Regulation Requirement for CAISO Balancing Area,\u201d Final Project\nReport, PNNL-20676, California Energy Commission. CEC-500-2011-XXX, \nAugust 2011. [http://uc-ciee.org/downloads/Day-\nahead_Regulation_Final_Report.pdf]\n\uf0b7 Y.V. Makarov, P.V. Etingov, and J. Ma, \u201cIncorporating Forecast Uncertainty in\nUtility Control Center,\u201d in L. E. Jones (Ed.), Renewable Energy Integration: \nPractical Management of Variability, Uncertainty & Flexibility in Power Grids,\nElsevier, 2014, invited.\n\uf0b7 P.V. Etingov, Y.V. Makarov, D. Wu, and Y. Sun, \u201cAnalysis of ISO NE Balancing\nRequirements: Uncertainty-based Secure Ranges for ISO New England \nDynamic Interchange Adjustments,\u201d PNNL-22222, Pacific Northwest \nNational Laboratory, Richland, WA, February 2013.\n[http://www.pnnl.gov/main/publications/external/technical_reports/PNNL-\n22222.pdf]\n\uf0b7 Y. V. Makarov, Z. Huang, P. V. Etingov, J. Ma, R. T. Guttromson, K. Subbarao,\nand B. B. Chakrabarti, \u201cIncorporating Wind Generation and Load Forecast \nUncertainties into Power Grid Operations,\u201d PNNL-19189, prepared for the \nDepartment of Energy, Pacific Northwest National Laboratory, Richland, WA,\nJanuary 2010. \n[http://www.pnl.gov/main/publications/external/technical_reports/PNNL-\n19189.pdf]\nSources:\n\uf0b7 Brown, Merwin; Miller, Larry; Cibulka, Lloyd; von Meier, Alexandra; Hwang, \nLorraine; California Institute for Energy and Environment, 2012. \nTransmission Grid Research, California Energy Commission. Publication \nnumber: CEC-500-2013-098. \n[http://www.energy.ca.gov/2013publications/CEC-500-2013-098/CEC-500-\n2013-098.pd]\n\uf0b7 Makarov, Yuri V., Pavel V. Etingov, Krishnappa Subbarao, Jian Ma (Pacific \nNorthwest National Laboratory), and Clyde Loutan (CAISO). 2012. Online \nAnalysis of Wind and Solar \u2013Part 1: Ramping Tool, Final Project Report. \nCalifornia Energy Commission. \n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nOT_Final_Ramping_Tool_Report.pdf]\n23\n\uf0b7 Makarov, Yuri V., Pavel V. Etingov, Krishnappa Subbarao, Jian Ma (Pacific \nNorthwest National Laboratory), and Clyde Loutan (CAISO) \u201cOnline Analysis \nof Wind and Solar\u2013Part 2: Transmission Tool,\u201d Final Project Report, 2012. \nCalifornia Energy Commission.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nOT_Final_Transmission_Tool_Report.pdf]\n\uf0b7 \u201cDeveloping Tools for Online Analysis and Visualization of Operational \nImpacts of Wind and Solar Generation,\u201d Fact Sheet. \n[http://uc-ciee.org/images/downloadable_content/electric_grid/OT_FactSheet\n.pdf]\n\uf0b7 \u201cDay Ahead Regulation Requirement Prediction Tool,\u201d Fact Sheet.\n[http://uc-ciee.org/downloads/Fact_Sheet_500-07-\n037_Day_Ahead_Regulation.pdf]\n\uf0b7 Makarov, Yuri V., Pavel V. Etingov, Nader A Samaan, Jian Ma. (Pacific \nNorthwest National Laboratory), and Clyde Loutan (CAISO), \u201cPredicting Day-\nAhead Regulation Requirement for the CAISO Balancing Area,\u201d Final Project \nReport. California Energy Commission. 2011.\n[http://uc-ciee.org/downloads/Day-ahead_Regulation_Final_Report.pdf]\n\uf0b7 Personal Communications: Makarov, Yuri, Principal Project Contributor, \nPacific Northwest National Laboratory, Richland, WA.\n2.3Wide-Area Energy Storage and Management System (WAEMS) \nto Balance Intermittent Resources in the California ISO\nThis project was performed by the Pacific Northwest National Laboratory (PNNL). \nThe Principal Investigator was Yuri Makarov.\nThe higher penetration of variable generation resources (including wind and \nsolar generation) in the Bonneville Power Administration (BPA) and California \nIndependent System Operator (CAISO) control areas raises issue of requiring \nexpensive additional fast grid balancing services in response to additional \nintermittency and fast up and down power ramps in the electric supply system. \nThe premise of wide area energy storage is that, due to statistical fluctuations, \ncollective power grid regulation needs are less than the sum of individual area \nneeds. This issue was addressed through the exchange of variable renewable \nenergy between the participating control areas and the use of energy storage, \ndispatchable load, and distributed generation resources. This project was the \nsecond phase of a three-phase project funded by multiple parties. In the first \nphase, proof of concept work was completed. The results of this second phase \nprovided specific numerical information necessary for a detailed wide area \ndesign system design.\nThe goal of the multiphase effort was to develop principles, algorithms, market \nintegration rules, functional design and technical specifications for a wide-area \nenergy storage and intermittent energy exchange management system to \nmitigate unexpected rapid changes in wind generation power output. The goal of\nthis specific project, which was the second phase of the larger project, was to \ndetermine the extent that energy storage technologies can mitigate the impact \nof the \u201cvariable and fast ramping\u201d nature of wind generation upon the \ntransmission system managed by CAISO.\n24\nBecause of the existence of Beacon Power Flywheels in California, and hydro \nplants in BPA\u2019s area, field experiments were done on the flywheels, and then an \nevaluation of the combined flywheel and hydro system was done. It concluded \nthat a combined system could effectively provide the fast regulation service of a \nstandalone flywheel without its strict energy limit constraints, while offering a \ncost approaching that of conventional regulation resource. The operation over \ntwo control areas (BPA and CAISO) also reduced the total regulation \nrequirements.\nIn general, the performance evaluation showed excellent performance of the \nWAEMS control algorithm, which separates the faster regulation effort provided \nby the energy storage from the slower one provided by a conventional \nregulating unit. The WAEMS combined service is not strictly constrained by \nenergy storage limits because the hydro plant supports the desired flywheel\u2019s \nenergy level. In addition, the WAEMS combined service has the same fast-\nresponse characteristic (within 6 seconds) as that provided by the flywheel \nenergy storage alone. Furthermore, the WAEMS control algorithm could reduce \nwear and tear on the hydro unit and allow the hydro unit to operate closer to its \npreferred operating point.\nThe break-even price for flywheel energy storage to provide bi-directional \nservice (1 MW regulation-up and 1 MW regulation-down) at the time was $20.37/\nMW. Because the average bi-directional regulation price of the CAISO balancing \nauthority was $11.95/MW (Jan.-July, 2010) and that of the BPA balancing \nauthority was $9.38/MW (2010), regulation service provided by a stand-alone \nflywheel energy storage was projected not be economical unless the regulation \nprice increased or the fast regulation service would be paid at a higher rate. \nAssuming that the minimum regulation price of regulation provided by a hydro \npower plant was$4/MW, the breakeven price of the combined flywheel-hydro \nregulation service was calculated to be $12.19/MW; therefore, the flywheel-\nhydro regulation service breakeven price is found to be slightly higher than the \naverage CAISO ($11.95/MW) and BPA ($9.38/MW) regulation prices. Because \nregulation prices are expected to increase when more renewable generation \nresources are integrated into the power grids, the flywheel-hydro regulation \nservice was expected to become economical in the CAISO and BPA balancing \nauthorities soon.\nAs explained above, this effort was multiphase and multi-funded. Thus, in \naddition to the PIER funding for this particular project, it leveraged other \nresources provided by BPA: Phase I, $130 K, Phase II, $191 K. In June, 2014, U.S. \nPatent No. 8,754,547 \u2013 Controller for Hybrid Energy Storage \u2013 was issued.\nThe technology developed potentially enables a 50 percent or more reduction in \nthe regulation capacity requirement when implemented.  Utilization of this \napproach by utilities is currently pending.\nPublications:\n\uf0b7 C. Jin, N. Lu, S. Lu, .Y.V. Makarov, and R.A. Dougal, \u201cA Coordinating \nAlgorithm for Dispatching Regulation Services Between Slow and Fast Power\nRegulating Resources,\u201d IEEE Trans. on Smart Grid: Special Selection Papers \n25\non Energy Storage Applications for Smart Grid, Vol. 5, No. 2, March 2014. \n(Special selection paper).\n\uf0b7 C. Jin, N. Lu, S. Lu, Y.V. Makarov, and R.A. Dougal, \u201cCoordinated Control \nAlgorithm for Hybrid Energy Storage Systems,\u201d Proceedings of the 2011 \nIEEE PES General Meeting, 24-29 July 2011, Detroit, Michigan, USA. (Panel \npaper). \n\uf0b7 N. Lu, Y. V. Makarov, M. Weimar, F. J. Rudolph, S. N. Murthy, J. Arseneaux, C.\nLoutan, S. Chowdhury, J. Pease, B. McManus, L. Miller, M. Brown, and J. \nPatterson, \u201cBalancing Renewable Generation Using the Wide-area Energy \nStorage and Management System,\u201d Windpower 2011 Conference & \nExhibition, Anaheim, CA May 22-25, 2011.\n\uf0b7 N. Lu, M. R. Weimar, Y. V. Makarov, F. J. Rudolph, S. N. Murthy, J. Arseneaux,\n\u201cThe Flywheel Potential for Providing Regulation Service in California,\u201d \nWindpower 2011 Conference & Exhibition, Anaheim, CA May 22-25, 2011.    \n\uf0b7 N. Lu, M. R. Weimar, Y. V. Makarov, and C. Loutan, \u201cAn Evaluation of the \nNaS Battery Storage Potential for Providing Regulation Service in \nCalifornia,\u201d Power Systems Conference and Exposition (PSCE) 2011, \nPhoenix, AZ, March 20-23, 2011.                       \n\uf0b7 N. Lu, Y. V. Makarov, M. R. Weimar, \u201cThe Wide-area Energy Storage and \nManagement System: Phase 2 Final Report,\u201d Final Project Report PNNL-\n19720, Prepared by: Pacific Northwest National Laboratory, Prepared for: \nthe Bonneville Power Administration and the California Energy Commission \nunder Contract DE-AC05-76RL01830, August 2010.\n[http://www.pnl.gov/main/publications/external/technical_reports/PNNL-\n19669.pdf]\n\uf0b7 N. Lu, Y. V. Makarov, M. R. Weimar, F. J. Rudolph, S. N. Murthy, J. Arseneaux,\nC. Loutan, and S. Chowdhury, \u201cThe Wide-Area Energy Management System:\nPhase II Final Report\u2013Flywheel Field Tests,\u201d Report PNNL-19669, Prepared \nfor the Bonneville Power Administration and the California Energy \nCommission, Pacific Northwest National Laboratory under Contract DE-\nAC05-76RL01830 , Richland, WA, August 2010.\n[http://www.pnl.gov/main/publications/external/technical_reports/PNNL-\n19669.pdf]\n\uf0b7 N. Lu, M.R. Weimar, Y.V. Makarov, J. Ma, and V.V. Viswanathan, \u201cThe Wide-\nArea Energy Storage and Management System \u2013 Battery Storage \nEvaluation,\u201d PNNL-18679, Pacific Northwest National Laboratory, Richland, \nWA, August 2009. \n[http://www.pnl.gov/main/publications/external/technical_reports/\nPNNL-18679.pdf]\n\uf0b7 Y.V. Makarov, J. Ma, S. Lu, and T.B. Nguyen, \u201cAssessing the Value of \nRegulation Resources Based On Their Time Response Characteristics\u201d, PNNL\nProject Report PNNL-17632, Prepared for CERTS and California Energy \nCommission, June 2008. \n[http://www.pnl.gov/main/publications/external/technical_reports/\nPNNL-17632.pdf]\n\uf0b7 Y.V. Makarov, J. Ma, S. Lu, and T.B. Nguyen, \u201cAssessing the Value of \nRegulation Resources Based On Their Time Response Characteristics,\u201d PNNL\nProject Report PNNL-17632, Prepared for CERTS and California Energy \nCommission, June 2008. \n26\n[http://www.pnl.gov/main/publications/external/technical_reports/\nPNNL-17632.pdf] \n\uf0b7 Y.V. Makarov, B. Yang, J. DeSteese, S. Lu, C. Miller, P. Nyeng, J.  Ma, D. \nHammerstrom, V. Viswanathan, \u201cWide-Area Energy Storage and \nManagement System to Balance Intermittent Resources in the Bonneville \nPower Administration and California ISO Control Areas,\u201d PNNL Project Report\nPNNL-17574, Prepared for the Bonneville Power Administration under \nContract BPA 00028087/PNNL 52946, June 2008.\n[http://www.pnl.gov/main/publications/external/technical_reports/PNNL-\n17574.pdf]\nSources:\n\uf0b7 Wide-Area Energy Storage and Management System (WAEMS) Research \nFact Sheet. [http://uc-ciee.org/images/downloadable_content/electric_grid/\nFact_Sheet_500-07-037_WAEMS.pdf]\n\uf0b7 Ning Lu, Yuri V. Makarov, and Mark R. Weimar, \u201cWide-Area Energy Storage \nand Management System Phase II,\u201d (CEC PIER contract number: 500-07-\n037, work authorization number: TRP-08-05) conducted by Pacific \nNorthwest National Laboratory. August 2010.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nFinal_WAEMS_Report_CIEE.pdf] \n\uf0b7 Personal Communications: Makarov, Yuri, Principal Project Contributor, \nPacific Northwest National Laboratory, Richland, WA.\n2.4Improved Generator and Load Models\nElectric grid planning and operating decisions rely on simulations of dynamic \nbehavior of the power system. Both technical and commercial segments of the \nindustry must be confident that the simulation models and database are \naccurate and up to date. Having realistic models is very important to ensure \nreliable and economic power system operation. A power system model consists \nof generation, transmission power flow and load models. \nThe ways that electric generators and customer electric loads behave under \nvarying situations on the electric grid greatly affect the reliability and power \nquality of the entire electric supply and delivery system, such as the WECC, of \nwhich the California electric system is a subset. So it is important for grid \nplanners and operators to be able to forecast how the various electric grid \ncomponents will behave especially under conditions when the grid is stressed, \nfor example, when there is voltage sag for some reason. Generator and load \nmodels are used in computer simulations of the electric grid to predict power \nflows and dynamics under different circumstances. For decades, generator and \nload behaviors in response to fluctuations in the electric grid did not change \nmuch, so the models for them did not need to change much. In modern times, \nhowever, new generators, such as variable renewable generators and new \nconsumer appliances, such as modern air conditions and computerized \nequipment, being connected to the electric grid are increasingly rendering the \nold generator and load models inadequate. Allowed to continue, this situation \n27\nthreatens the ability to plan and operate a reliable and cost-efficient electric \nsupply and delivery system. \n2.4.1 WECC Wind Generator Modeling\nThis project was performed by the National Renewable Energy Laboratory. \nThe Principal Investigator was Eduard Muljadi.\nAt the time of this research project, the wind turbine models that were being \nused in transmission system planning and reliability analyses were known to \nbe inaccurate, and did not represent the new generation of wind machines \ncorrectly. Incorrect or uncertain analyses of the impacts of wind power \ngenerators dynamic behaviors on the grid could adversely affect both \nplanning, and economic and reliable operation, of the California electric \ndelivery system.  \nProprietary models written by turbine manufacturers for specific generators \nexisted, but in many cases were not readily available, and typically required \na non-disclosure agreement (NDA), which constrained their use in a \ncollaboratively controlled transmission system such as the WECC.\nThe WECC assigned the task of developing standard, non-proprietary wind \nturbine models to their Wind Generator Modeling Group (WGMG), and chose \nfour specific generic types of wind turbine machine designs that were \nbelieved to represent the vast majority of the utility-scale wind turbine \ngenerators in the market. Utilizing WECC funding, the WGMG completed the \nresearch and development of each of these four models for use in WECC \nsystem simulation studies. While the models were designed specifically to \nmeet WECC modeling requirements, the results could also be used by the \nindustry as a whole.\nThe PIER-funded research project was cost shared with and managed by the \nNational Renewable Energy Laboratory (NREL). The overall result of this \nresearch was to improve transmission planning and operating modeling tools \nneeded to better prepare the transmission grids in California and western \nNorth America to accommodate the expected growth in wind power \ngeneration in order to meet Renewable Portfolio Standard goals, especially \nCalifornia\u2019s relatively aggressive ones. This research and development effort \nproduced the first-ever accurate, non-proprietary (generic) models of the \nvarious types of wind turbines in commercial use today. The specific \nobjectives of this project were to validate the new WECC wind turbine \nmodels, and to develop aggregation methods to use the individual models to \ndevelop an equivalent, aggregated model of an entire wind farm. The models \nare now included in the permanent library of software for General Electric\u2019s \n(GE) Positive Sequence Load Flow (PSLF), Siemens Power Technologies \nInternational\u2019s (PTI) Power System Simulator for Engineering (PSSE), and \nPowerWorld\u2019s Simulator.\nThe project collected and monitored data from several wind power plants \nrepresenting the four types of wind turbine models developed. Validation of \nthe models was done through two processes. First, dynamic model \n28\npredictions were compared to the field measurement transient data collected\nfrom operating wind power through collaboration with Public Service of New \nMexico, Bonneville Power Authority, and many other resources. Additionally, \nmodel performance was compared to available high order proprietary models\nfrom manufacturers. The dynamic models for each of the four types of wind \nturbines were successfully validated \nThe project also developed an equivalencing methodology to aggregate \nindividual wind generators into a model that represents an entire wind power \nplant by an equivalent single turbine representation or, if necessary, with a \nsmall number of turbine representation. This method enables representing \nhundreds of wind turbine generators into a single or several turbine \ngenerators. Two guide books, \u201cWind Power Plant Power Flow Modeling \nGuideline,\u201d prepared by WECC-WGMG (2008), and \u201cWind Power Plant \nDynamic Modeling Guide,\u201d prepared by WECC- Renewable Energy Modeling \nTask Force (REMTF) (2010), for doing this aggregation, the former for power \nflow and the latter for dynamic modeling, were produced to provide \nguidelines and recommended practices for wind turbine model and wind \npower plant representation. This equivalencing method has been validated by\nHydro Quebec. \nThis research created far-reaching interactions among many entities in the \nwind generation industry, stretching from California to around the world \ninvolved in model development and use, electric grid integration, standards, \nand the like:\n\uf0b7 Electric utilities, through the WECC Wind Generator Modeling Group and \nWECC Renewable Energy Modeling Task Force: SCE, PG&E, CAISO, Puget\nSound Electric, and BPA.\n\uf0b7 Wind turbine manufacturers and wind generating plant developers: \nMitsubishi, Vestas, Siemens, GE, Nordex, RePower, and Oak Creek \nEnergy Systems\n\uf0b7 Software vendors for power flow and dynamic models for the use of wind\npower in the electric grid: GE, Siemens PTI (PSSE), PowerWorld, \nOperation Technologies, and Power Tech Lab.)\n\uf0b7 Industry consultants and associations, and National labs and university \nresearchers: EnerNex, Operation Technologies Inc., Power Tech Lab, \nUtility Variable-Generation Integration Group (UVIG), , Electric Power \nResearch Institute (EPRI), NREL, Sandia, PNNL, University of Michigan - \nAnn Arbor, and University of Texas \u2013 Austin\n\uf0b7 Professional and international agencies: Institute of Electrical and \nElectronics Engineers (IEEE), International Electrotechnical Commission \n(IEC), International Energy Agency (IEA), and International Council on \nLarge Electric Systems (CIGRE)\nThis research also has had many regional, national, technical and educational\nimpacts. Before this work, there were no wind plant models. The new models \nfor wind generators are being used to address numerous questions related to \nelectric system dynamic behavior.  Accordingly, CAISO is benefiting in its \nstudies of integration of renewables into the California grid.  It also helped to \n29\nbuild a bridge between the power engineering and wind energy communities \nin California and elsewhere and it has helped to improve California\u2019s ability to\nadd renewables reliably to the grid. It helped to increase the level of \nunderstanding of this important topic, which is still not well understood, \nthroughout the industry; and this activity provided education on the subject \nmatter for many people. WECC continues to be a leader in the development \nof the models.\nNationally, this research has since been identified by NERC as an area of \nsignificant need in the report of the NERC Integrating Variable Generation \nTask Force (IVGTF 2009). The results of this work are in line to support FERC \nOrder 661 and 661A and are in the national interest in providing a secure and\nreliable power system grid.\nThis research also had a number of important technical impacts on wind \ngenerator modeling. The initial work was done on the software platforms of \nPSLFTM (vendor: General Electric) and PSSETM (vendor: Siemens PTI).  \nSubsequently, other software vendors implement these WECC dynamic \nmodels in the development of wind generator models on their own software \nplatforms (PowerWorld Simulator, ETAP, TSAT, etc.) using the same \nspecifications described on the block diagrams in the final report.  These \ndynamic models are part of the software library and are no longer in the form\nof a \u201cuser defined model.\u201d The widespread adoption of the models developed\nand validated in this research helps assure a competitive source of \ncommercially available software compatible with California\u2019s electric grid \nneeds, and its on-going maintenance and updating.\nThese wind generator dynamic models formed the foundation of other \nrenewable energy dynamic models.  For example, the WECC PV dynamic \nmodel was developed based on the Type 4 Wind Turbine Generator dynamic \nmodel developed and validated in this research project.  These models were \nimplemented in PSLF, PSSE and Power World Simulator software.  The \ndynamic model of Adjustable Speed (AS) Pumped Storage Hydro (PSH) power \nplant was developed based on the Type 3 Wind Turbine Generator dynamic \nmodel.  This AS-PSH model is currently being implemented as a \u201cuser defined\nmodel\u201d on the PSSE software platform before moving to the permanent PSSE \nlibrary. These dynamic models were also implemented, with some technical \nsupport from NREL, on the PSCAD platform by NREL and implemented on the \nRSCAD platform, which is the main interface for Real Time Digital Simulation \n(RTDS) used by Southern California Edison.\nEducation has also benefited from this research project. The method of \nEquivalencing Wind Power Plant (from hundreds of wind turbine generators) \ndeveloped as part of this project, is currently being used as part of the \ncurriculum in Power System courses. These dynamic models have been \nimplemented in PSSE, PSLF, PowerWorld, TSAT, and many other modeling \nplatforms, and has been used by the industry members [www.pserc.wisc.edu/\nabout/industry_members.aspx] of the Power Systems Engineering Research \nCenter (PSERC) [www.pserc.org] and the university members of PSERC \n[www.pserc.wisc.edu/about/university_members.aspx] as planning tools, \n30\nresearch tools, and teaching materials for power engineering students. \nPSERC is National Science Foundation Industry-University Cooperative \nResearch Center. Finally, various research publications by university \nprofessors and graduate students have been published utilizing the WECC \ndynamic models.\nAs one might suspect from the widespread impacts this research has had, a \nnumber of new follow-on research projects have been spawned. The DOE \nEERE has funded subsequent works related to Solar/PV dynamic modeling \n(NREL and Sandia) and Adjustable Speed Pump Storage Hydro AS-PSH (NREL,\nIdaho National Laboratory, and Argonne National Laboratory) in both positive \nsequence dynamic modeling and electromagnetic transient modeling.  All of \nthese works have benefited and have leveraged the previous work of the \nWECC Wind Generator Modeling.\nThe International Electrotechnical Commission (IEC) TC88 Working Group 27 \n(Wind turbines \u2013 Electrical simulation models for wind power generation \u2013 \nChair: P. Sorensen, Denmark Technical University) also uses the WECC \n(generic) dynamic models as a foundation to define standard dynamic \nsimulation models: the IEC 61400-27-1 (PART 1) generic wind turbine models,\nand IEC 61400-27-2 (PART 2) generic wind power plant models specified to be\nindependent of any software simulation tool.\nThe Utility Variable-Generation Integration Group (UVIG) \u2013 led by V. Zheglov \nof Enernex \u2013 has developed a \u201cwind-wiki,\u201d a resource (similar to Wikipedia) \nrelated to renewable energy dynamic models which disseminates information\nregarding publications, and the validation and dynamic modeling efforts \nrelated to the WECC Wind Turbine Generator project. \nThe WECC Renewable Energy Modeling Task Force (REMTF), chaired by A. \nEllis, Sandia, continues with extension of the WECC Wind Generation \nModeling. As a follow on project, the WECC Renewable Energy Modeling Task \nForce has developed \u201cSpecification of the Second Generation Generic Models \nfor Wind Turbine Generators\u201d prepared under Subcontract No. NFT-1-11342-\n01 with NREL (collaboration between NREL, Sandia, EPRI, and WECC). This \nspecification is currently being implemented in the PSLF, PSSE, and \nPowerWorld Simulator software. Tutorials on dynamic modeling for renewable\nenergy are offered periodically to the members of the WECC, which included \nCalifornia utilities.\nThe IEEE Dynamic Performance of Wind Generation Working Group \u2013 Chair: P.\nPourbeik, EPRI  continues these efforts. The Working Group organizes panel \nsessions related to the dynamic modeling of wind turbine generators and \noffers tutorials at the IEEE PES General Meetings and IEEE Power System \nConference and Expositions.  The tutorial is currently being planned (with the \ntitle \u201cRenewable Energy Systems Modeling and Dynamic Performance\u201d) for \nthe IEEE PES-General Meeting, July 2015, to be held in Denver, CO.\nNERC IVGTF has embarked with \u201cTask 1-1: Standard Models for Variable \nGeneration Scope, with the emphasis on attributes such as \u201cstandard, valid, \ngeneric, non-confidential, and public\u201d.  It covers power flow and stability \n31\nmodels (variable generation) to be developed to enabling planners to \nmaintain bulk power system reliability, and to make recommendations and to\nidentify changes needed to NERC\u2019s MOD Standards.\nWorkshops:\n\uf0b7 WECC \u2013 2009 Generator Model Validation Workshop, held at Tristate \nGenerator and Transmission Association, Westminster, CO May 18-19, \n2009\n\uf0b7 WECC \u2013 2009 Modeling Workshop for Planning Engineers, held at PG&E, \nSan Francisco, CA, April 16-17, 2009.\n\uf0b7 IEEE Dynamic Performance of Wind Power Generation Task Force \n(DPWPGTF) \u201cTutorial on Wind Generation Modeling and Controls,\u201d IEEE \nPSCE Conference, Seattle, WA, USA, March 2009.\n\uf0b7 Tutorial: \u201cWind Energy Boot Camp,\u201d organized by New Mexico State \nUniversity, PNM, and NREL at Albuquerque, NM, Nov 12-14, 2008.\n\uf0b7 IEEE Dynamic Performance of Wind Power Generation Task Force \n(DPWPGTF), \u201cTutorial on Wind Generation Modeling and Controls,\u201d IEEE \nPES General Meeting, Pittsburgh, PA, USA, July 2008.\n\uf0b7 \u201cWECC Wind Generator Modeling Project,\u201d Policy Advisory Committee, \nCalifornia Energy Commission (CEC), Irwindale, CA, August 20, 2007, and\nKickoff Meeting for the WECC Wind Generator Modeling Project, Los \nAngeles, CA, August 21, 2007.\n\uf0b7 \u201cWind Generator Modeling\u201d, CEC/PIER TRP Technical Advisory \nCommittee Meeting, Sacramento, CA, October 3, 2006.\n\uf0b7 \u201cEquivalencing Large Wind Power Plants,\u201d WECC 2006 Modeling \nWorkshop, Las Vegas, NV, June 14-15, 2006.\nPublications:\n\uf0b7 Brochu, J., Larose, C., Gagnon, R., \u201dGeneric Equivalent Collector System \nParameters for Large Wind Power Plants,\u201d IEEE Transactions on Energy \nConversion, Volume: 26, Issue: 2, 2011, pp. 542 \u2013 549. \n\uf0b7 Brochu, J., Larose, C., Gagnon, R., \u201cValidation of Single- and Multiple-\nMachine Equivalents for Modeling Wind Power Plants,\u201d IEEE Transactions\non Energy Conversion, Volume: 26, Issue: 2, 2011, pp. 532-541.\n\uf0b7 D. Burnham, S. Santoso, E. Muljadi, \u201cVariable Rotor Resistance Control of\nWind Turbine Generators,\u201d submitted to the IEEE Power Engineering \nSociety, General Meeting, Calgary, Alberta, Canada, July 26-30, 2009.\n\uf0b7 M. Singh, K. Faria, S. Santoso, E. Muljadi \u201cValidation and Analysis of Wind\nPower Plant Models Using Short-Circuit Field Measurement Data,\u201d IEEE \nPower Engineering Society, General Meeting, Calgary, Alberta, Canada, \nJuly 26-30, 2009.\n\uf0b7 E. Muljadi, T. Nguyen, M.A. Pai, \u201cTransient Stability of the Grid with a \nWind Power Plant,\u201d IEEE Power System Conference and Exposition, \nSeattle, WA, Mar. 15-18, 2009.\n\uf0b7 E. Muljadi, T. Nguyen, M.A. Pai, \u201cImpact of Wind Power Plants on Voltage \nand Transient Stability of Power Systems,\u201d IEEE Energy2030 conference,\nAtlanta, Georgia, Nov. 17-18, 2008.\n32\n\uf0b7 A. Ellis, E. Muljadi, \u201dWind Power Plant Representation in Large-Scale \nPower Flow  Simulations in WECC,\u201d IEEE Power Engineering Society, \nGeneral Meeting, Pittsburgh, PA, July 20-24, 2008.\n\uf0b7 E. Muljadi, A. Ellis,\u201d Validation of Wind Power Plant Dynamic Models,\u201d \ninvited panel discussion presented at the IEEE Power Engineering \nSociety, General Meeting, Pittsburgh, PA, July 20-24, 2008.\n\uf0b7 E. Muljadi, Z. Mills, R. Foster, J. Conto, A. Ellis, \u201cFault Analysis at a Wind \nPower Plant for a One Year of Observation,\u201d presented at the IEEE Power\nEngineering Society, General Meeting, Pittsburgh, PA, July 20-24, 2008.\n\uf0b7 E. Muljadi, S. Pasupulati, A. Ellis, D. Kosterov,\u201d Method of Equivalencing \nfor a Large Wind Power Plant with Multiple Turbine Representation,\u201d \npresented at the IEEE Power Engineering Society, General Meeting, \nPittsburgh, PA, July 20-24, 2008.\n\uf0b7 R. Zavadil, N. Miller, A. Ellis, E. Muljadi, E. Camm, and B. Kirby, \u201cQueuing \nUp,\u201d the IEEE Power and Energy Magazine, November/December 2007\n\uf0b7 E. Muljadi, C.P. Butterfield, B. Parsons, A. Ellis, \u201dCharacteristics of \nVariable Speed Wind Turbines Under Normal and Fault Conditions,\u201d \npresented at the IEEE Power Engineering Society, Annual Conference, \nTampa, Florida, June 24-28, 2007.\n\uf0b7 M. Behnke, A. Ellis, Y. Kazachkov, T. McCoy, E. Muljadi, W. Price, J. \nSanchez- Gasca, \u201cDevelopment and Validation of WECC Variable Speed \nWind Turbine Dynamic Models for Grid Integration Studies,\u201d presented at\nthe Windpower 2007, WINDPOWER 2007 Conference & Exhibition, Los \nAngeles, CA, June 24-28, 2007.\nSources:\n\uf0b7 Muljadi, Eduard; Abraham Ellis. \u201cWestern Electric Coordinating Council \nWind Generator Development,\u201d National Renewable Energy Laboratory, \n2010. Report to the California Energy Commission. Publication number: \nCEC-500-2014-043. [http://www.energy.ca.gov/2014publications/CEC-\n500-2014-043/CEC-500-2014-043.pdf]\n\uf0b7 \u201cWECC Wind Generator Modeling,\u201d Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nWGM_FactSheet.pdf]\n\uf0b7 Personal Communications: Muljadi, Eduard, a Principal Author and the \nProject Manager, National Renewable Energy Laboratory, Golden, CO.\n2.4.2 Load Modeling Transmission Research\nThis project was performed by the Lawrence Berkeley National Laboratory, \nthe Pacific Northwest National Laboratory, Southern California Edison Co., the\nUniversity of Wisconsin \u2013 Madison, and others. The Principal Investigator was \nBernard Lesieutre.\nThe situation today is that existing load models in dynamic programs do not \ncorrectly represent the actual load behavior observed in the system under \nmany system conditions. The dynamic effects of the addition of residential \nand commercial solar photovoltaic (PV) generator systems on nearby \ncustomer loads are largely unknown. One particular phenomenon known as \nFault Induced Delayed Voltage Recovery (FIDVR), generally understood to be \n33\ncaused in this case by the stalling of residential air conditioners after a brief \nperiod of power instability, had become of increasing importance and was not\nreflected in current load models.  \nThe primary problem addressed, which was not adequately represented in \nthe load models being used, was voltage instability in Southern California, \nand the U.S. Southwest in general, after a brief voltage disturbance in the \nelectric grid. Improving load modeling was one method of addressing this \nproblem through improved predictability of damping and stability issues \nrelated to the California- Oregon Intertie and other major interties, critical to \nthe security of the California and entire WECC system. The improved models \nwould lead to more reliable operation of the grid in the West, and reduce the \nrisk (and costs) of widespread blackouts. Moreover, a better understanding of\nanticipated network behavior would aid in planning for appropriate \ndeployment of capital investments, including new controllers, protection, \ngeneration and transmission.\nTherefore, the ultimate objective of this research was to improve the \naccuracy of dynamic load models used in power system analysis and \nsimulation tools. Specific objectives included the development of: \n\uf0b7 An accurate model of residential air conditioners, \n\uf0b7 Potential solutions to FIDVR, \n\uf0b7 Tools and methodologies for determining the mix and balance of \ndifferent types of electrical loads, and \n\uf0b7 A scoping study for the impact of increasing penetration of residential \nand commercial photovoltaic systems. \nThis research was a coordinated effort by members of the WECC to enhance \nthe understanding of the behavior of loads, especially air conditioners, and to\nimprove simulations of dynamic behavior of the power system. Because of \nthe prevalence of this problem in Southern California, SCE was one of the \nleaders of this research, with PG&E and SDG&E as significant contributors. \nSpecific tasks included testing of residential air conditioners and \ndevelopment of an accurate model, testing and analysis of possible solutions \nfor FIDVR, development of improved load modeling techniques including \nmethodology and tools for load composition, evaluation of the merits of \nfuture load monitoring and development of a monitoring placement plan, \ndevelopment of an uncertainty analysis for load modeling, and a scoping \nstudy to assess solar generation characteristics and associated impacts on \nload modeling. Technical oversight was provided by the WECC Load Modeling\nTask Force in cooperation with a significant number of utilities, national \nlaboratories, and system operators. \nExtensive testing of single-phase residential air conditioners, under various \nvoltage and frequency transients, resulted in both an accurate dynamic \nmodel and confirmation of air conditioners as the cause of FIDVR. Load \nmodels that match the testing results were constructed. A new load \ncomposition tool to help build load models for simulations was developed. An \nuncertainty analysis was completed which led to a strong recommendation \n34\nfor future load monitoring to validate the tool. Potential FIDVR solutions at \nthe system level were analyzed and some existing devices that could be \nsolutions at the HVAC unit-level were tested. None were found to be \ncompletely satisfactory. Manufacturing standards were recommended to deal\nwith the issue in the long term. In anticipation of high penetrations of \ndistributed PV electric generators, a scoping study of inverter models was \nincluded in this research. It was determined that, as penetration increases, \ndistributed PV could have significant impact on the grid. No suitable inverter \nmodels for use in load modeling currently exist, but a candidate approach \nwas proposed. It was recommended that testing of inverters be done. Load \nmonitoring, uncertainty analysis, and motor protection were some other \nareas identified in this project where additional research was needed.\nSpecifically, a number of ground-breaking results were obtained through this \nwork. These included:\n\uf0b7 Measurements that showed the characteristics of single-phase air \nconditioning units under stall conditions (high reactive power draw)\n\uf0b7 Measurement of the speed of stalling in single-phase air conditioning \nunits (3 to 5 cycles)\n\uf0b7 Determination of voltage levels causing single-phase air conditioning \nunit to stall (60 \u2013 70% of nominal voltage depending on outside air \ntemperature and design of unit)\n\uf0b7 Construction and validation of single-phase air conditioning unit models \n(against AC unit test data) for use with GE Positive Sequence Load Flow \n(PSLF) model.\n\uf0b7 Examination and laboratory testing of potential solutions to the air \nconditioning stalling problem (most of which would help the immediate \nproblem of low voltage, but would cause an uncontrolled high voltage \ntransient a short time later)\n\uf0b7 Analysis of load composition \u2013 regional and seasonal load composition \nvalues for system studies\nDissemination of project results was through the WECC Load Modeling Task \nForce, conference presentations, technical papers, and interactions with \nutilities and air conditioning unit manufacturers. Some examples of these are:\n\uf0b7 Numerous presentations at meeting of the WECC Load Modeling Task \nForce attended by engineers from several western US utilities\n\uf0b7 Presentations at conferences and meetings:\n\u2013 IEEE Conference, special session on Load Modeling\n\u2013 EPRI PQ Applications Conference 2007 and 2008 \n\u2013 AHRI Unitary Small Equipment Engineering Committee Meeting 2008 \n(AC manufacturers association)\n\u2013 Background for two SCE IEEE Conference papers in 2013/2014 on \nFIDVR\n\uf0b7 Contribution to NERC Transmission Issues Subcommittee paper on FIDVR\n(2009)\n\uf0b7 Provided background for two DOE/NERC-sponsored workshops on FIDVR/\nAC Stalling (2008 and 2009)\n35\nIn addition to the specific technical benefits just described, based on supplied\nguidelines, there were a number of other benefits of this research as well. \nAlthough difficult to quantify since these FIDVR/AC events are low-probability/\nhigh-impact events, based on professional experience and judgment, there \nwere a number of reliability and economic benefits to ratepayers. The electric\ngrid planning and operations in California and the WECC are better prepared \nwith the potential to reduce large-scale system outage caused by FIDVR.\nSignificant staff time was provided by a number of utilities and grid operating\nentities in the Western Interconnection in reviewing and implementing the \ncomposite load model. Two major project participants, SCE and BPA, made in-\nkind contributions of ~ $170k and >$1M, respectively.\nThis CEC PIER work paved the way for the development and implementation \nof the composite load model \u2013 the most significant grid modeling \nadvancement of the last decade. The composite load has been implemented \nin all major commercial grid simulators used in North America \u2013 General \nElectric\u2019s PSLF, Siemens PTI PSS\u00aeE and PowerWorld (See discussion on the \n\u201cWECC Wind Generator Modeling\u201d project described elsewhere in this paper.).\nThe model has been approved for planning and operational studies in the \nWECC, which are used to make capital investments in the power grid and \ncompliance with NERC Reliability Standards. The operating studies are used \nto set system operating limits.\nSources:\n\uf0b7 Lesieutre, Bernard, Richard Bravo, Dave Chassin, Ian Hiskens, Henry \nHuang, Ning Lu, Giri Venkataramanan, and Robert Yinger. 2010. Load \nModeling Transmission Research Project. California Energy Commission, \nPIER Program. CEC-500-2013-118.\n{http://www.energy.ca.gov/2013publications/CEC-500-2013-118/\nCEC-500-2013-118.pdf]\n\uf0b7 \u201cLoad Modeling Research,\u201d Project Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nLM_FactSheet.pdf]\n\uf0b7 Personal Communications: Lesieutre, Bernard, the Project Manager and \na Primary Author and Contributor, then at Lawrence Berkeley National \nLaboratory, now at the University of Wisconsin-Madison.\n\uf0b7 Personal Communications: Yinger, Robert, a Primary Author and \nContributor, Sothern California Edison, Westminster, CA\n\uf0b7 Personal Communications, Kosterev, Dmitry, a Primary Author and \nContributor, Bonneville Power Administration, Vancouver, WA\n3. New Technology for Increasing Transmission Capacity by\nOptimizing the Grid for Greater Power Flow\nUnderinvestment in transmission infrastructure in the latter decades of the 20th \ncentury, when transmission capacity did not expand at the same rate as growth in \npower demand, resulted in congestion and threats to reliability. Although this \n36\ncapacity limitation affects any power plant connected to the grid, it certainly \nrepresented a barrier to meeting California\u2019s renewable energy goals.\nAny transmission line has physical limits on the amount of power that can be \ntransmitted. Which particular limit is the dominant factor constraining the capacity \nof a given line at a given time depends on the conditions of that particular line and \nthe broader wide-area transmission grid. Because the technological sophistication of\nsituational monitoring was never particularly accurate or precise in the past, \nconservative static operating limits had been set which were often far below the \nphysical limits, which in effect de-rated the capacity of a line, often by 20 to 50% or \nmore. \nThere are two fundamental classes of limits, thermal and stability. \n\uf0b7 Thermal Limits: The amount of power or current a line can carry, under all \nanticipated conditions, before reaching its limiting temperature. The primary \nsource of heat (known as I2R heating) comes from the interaction between the \nelectrical resistance (R) of the line material and the electric current (I) flowing \nthrough it. If driven above its limiting temperature, a line may excessively sag \ndue to thermal expansion, creating a safety hazard or an outage, or be \ndamaged by irreversible stretching. Because the assumed environmental \nconditions are extremely conservative (typically 109\u00baF and 2 ft/sec wind) when\nestablishing thermal limits, real-time ambient information could allow \nsubstantially increased capacity limits in operations.\n\uf0b7 Stability Limits: Poor voltage support and dynamic and transient instabilities \ncan result in lower capacity limits, even substantially below the thermal limits \nin some situations, especially for long transmission lines. It is not unusual for a \nmajor interconnection path to be operationally limited by instabilities to half its\nrated static thermal limit. This effect imposes severe constraints on the amount\nof renewable power that can be imported into California, and into major load \ncenters within the state.\nThere were emerging technologies that could, in principle, provide the capabilities \nto reduce the margins of operating limits required for safety, and even raise the \nphysical limits, thereby adding substantial \u201cnew\u201d capacity without building new \ntransmission lines or reducing reliability. These capabilities would prove vital to \nmeeting renewable energy goals if building all of the new transmission capacity \nneeded falls short, especially likely in dense urban load centers, and might be \npreferred as a cheaper way to get greater transmission capacity.\n3.1New Capacity Thermal Capability\nThe TRP explored two avenues for mitigating thermal limits. One was to relax \nthe conservative static limit by enabling current flows closer to the real physical \nlimit through dynamic (real time) \u201cthermal\u201d rating monitoring, yielding \nincremental capacity increases. TRP conducted a number of assessment and \ndeployment studies, and demonstration, of monitoring devices and data \nmanagement and analysis. The second approach was to increase the physical \nthermal limits through new line conductor material technologies. These new \nmaterials could handle considerably higher temperatures without sagging or \ndamage, and without the use of larger heavier cables that required new poles or \n37\ntowers. They did however require some special handling during installation \nbecause of a greater susceptibility to being damaged from excessive bending. \nAlso, new connectors and special splices were required in some situations. TRP \nmonitored a field demonstration of one of these new conductors at a California \nIOU.\n3.1.1 Multi-Area Real-Time Transmission Line Rating Study\nThis project was performed by The Valley Group. The Principal Investigator \nwas Tapani Seppa.\nPrior PIER research recognized that both thermal limits and voltage limits \ninteract to cause combined dispatch restrictions in California\u2019s transmission \nnetwork. The analysis from that project concluded that a solution was \nrequired for the combined restrictions that were limiting power dispatch in \nthe Sacramento area. The objectives of this project were to: 1) identify \nconditions where combined constraints restricted dispatch; 2) quantify the \nmagnitude and cost of such restraints; and 3) investigate prediction of line \nratings in the timeframe that would be useful for dispatch purposes.\nIn terms of lesson learned, coordination of schedules with the three utility \nparticipants became complex and difficult. Each faced a different set of \nlimitations regarding funding availability, availability of engineering \nmanpower, contractual negotiations, communications systems, \ncommunications interface to supervisory control and data acquisition \n(SCADA) systems, confidentiality requirements, scheduling constraints and \npriorities. Different SCADA and communications systems required \nmodification of data collection and analysis systems for all three participants,\nwhich in turn required significant modifications in software. This complicated \nand prolonged the data analysis process. \nThere were thermal limitations in the Sacramento area that interacted with \nvoltage constraints and limited the energy imports to the area. One of these \nlimitations was the O\u2019Banion-Elverta static line rating, which resulted in at \nleast three curtailments of the Sutter generation facility; the actual real-time \ncapability of the circuits during peak loading periods was at least 20 MW \nhigher than the static rating. Increasing the thermal rating of the O\u2019Banion-\nElverta circuits by 20 MW with real-time ratings could increase import \ncapacity to the area by over 250 MVA.\nExtensive studies of various available rating prediction algorithms were \nconducted. None of the algorithms were found to have acceptable accuracy \nfor predicting ratings in the targeted time range of 4-24 hours. The day-to-\nday rating patterns usually exhibited a high degree of similarity, especially \nduring the summer, but the actual predictability of rating values varied \ngreatly. The O\u2019Banion-Elverta circuits had a median real-time rating of \napproximately 150 percent of the static rating, but only a 110-115 percent \ncapability with a probability of 90 percent during the most critical loading \nperiods (late afternoon \u2013 early evenings). The lowest ratings could \noccasionally be slightly below the static rating. Ratings were always safely \nover the static rating at night, but the circuits were never heavily loaded.\n38\nThe original objective was to identify prediction methods that could be used \nin daily dispatch. It became increasingly clear as market rules changed and \ntightened during the project that there were no opportunities for economic \ndispatch that were applicable to \u201cprobable\u201d capacity since operation of \npresent-day markets was based only on firm capacity.\nRatings had \u201cpersistence\u201d even though they were not sufficiently predictable \nto be used for daily dispatch purposes. That is, ratings could increase rapidly \nduring a storm, for example. Ratings could not decrease rapidly, however, as \nit would require either a rapid increase in ambient temperature or an abrupt \nreduction of kinetic energy in the atmosphere.\nPersistence of ratings could have a major impact on the management of \ncontingency events in the network. It could increase operating economies \nbecause operators could either avoid changes in system dispatch or minimize\nthem. It could also substantially increase system reliability, especially during \ntimes of high system loads.\nResults of the analysis showed that dispatch constraints in the Sacramento \narea changed significantly over the time frame of the project. Several of the \nvoltage constraints were alleviated by the installation of volt-ampere reactive\n(VAR) support. Further changes in system configuration and operations \nimpacted the applicability of this project\u2019s results.\nThe indications of real time ratings persistence provided a template for \napplication of real time ratings in California. This could increase operating \neconomies and could also substantially increase system reliability by \nmanaging contingencies, especially during times of high system loads. The \nstudy of the combined constraints in the Sacramento area also provided an \nexcellent example of how real time ratings could be used to mitigate import \nconstraints to a large area.\nSources: \n\uf0b7 Seppa, Tapani; Seppa, Timo; Mohr, Robert; Salehian, Afshin; Faisal, Zaki.\n2005. \u201cMulti-Area Real Time Transmission Line Rating Study.\u201d California \nEnergy Commission. Publication number: CEC-500-2014-025. \n[http://www.energy.ca.gov/2014publications/CEC-500-2014-025/CEC-\n500-2014-025.pdf]\n\uf0b7 Seppa, Tapani; Douglass, Dale; Reppen, Dag; Clark, Harrison. 2005. \n\u201cSacramento Area Ratings.\u201d California Energy Commission, PIER \nProgram. Publication number: CEC-500-2005-095.\n[http://www.energy.ca.gov/2005publications/CEC-500-2005-095/CEC-\n500-2005-095.PDF]\n\uf0b7 Seppa, Tapani, et al. 2005. \u201cIntegration of Real-Time Transmission Line \nData with Utility and CAISO Operations.\u201d California Energy Commission, \nPIER Program. Publication number: CEC 500-99-03.\n39\n3.2New Capacity Voltage Stability Capability\nOperators may not know how susceptible the system is at any given time to \nundesirable voltage changes as a function of power transfer, which could lead to \nvoltage collapse and a resulting blackout. Voltage stability constraints are \nintended to provide margins for safety, in the absence of precise knowledge. TRP\ndeveloped and demonstrated a predictive analytic and modeling voltage security\nanalysis tool for improving situation awareness and permit smaller, better \ndefined, constraint margins. Licensing rights to the technology were obtained by \na vendor that commercialized the new tool (see 3.2.1 California ISO Real-Time \nVoltage Security Asessment).\n3.2.1 California ISO Real-Time Voltage Security Assessment (VSA)\nThis project was performed by the Lawrence Berkeley National Laboratory, \nConsortium for Electric Reliability Technology Solutions. The Principal \nInvestigator was Joe Eto.\nAnalysis of over two dozen blackouts that had occurred in various places \naround the world indicated a need in developing real-time tools for \nmonitoring system voltage security margins under the normal and \ncontingency conditions. Regarding the June 2-3, 1996, major blackout in the \nWECC system, including California, the U.S. Department of Energy \nrecommended that the WECC should consider the use of real-time security \nmonitoring on regional scale to prevent future voltage collapse events. The \nWECC accepted this recommendation later in 1996 by deciding it would \npursue a security monitoring and analysis tool that would enable operators to\nidentify potential problems and take corrective action.  \nThe goal of the California ISO Real-Time Voltage Security Assessment (VSA) \nproject was to provide CAISO with a prototype voltage security assessment \ntool that runs in real time within CAISO\u2019s reliability and congestion \nmanagement system. The project conducted a technical assessment of \nappropriate algorithms, developed a prototype incorporating state-of-art \nalgorithms (such as the continuation power flow, direct method, boundary \norbiting method, and hyperplanes) into a framework most suitable for an \noperations environment. A functional specification was prepared for a \ncommercial grade system. CAISO has used the functional specifications to \nprocure a production-quality tool that is now a part of a suite of advanced \ncomputational commercial tools provided by Bigwood Systems, Inc. (BSI), a \ndeveloper and vendor of software tools for power grid assessment, \nmonitoring, analysis, operation, control and optimization, located in Ithaca, \nNY (headquarters) and San Francisco, CA.\nSources:\n\uf0b7 Eto, Joe, Manu Parashar, Bernard Lesieutre, and Nancy Jo Lewis. October \n2008. \u201cReal-Time Grid Reliability Management,\u201d California ISO Real-Time\nVoltage Security Assessment (VSA) Summary Report, Appendix B. \nCalifornia Energy Commission. CEC-500-2008-049-APB.\n[http://www.energy.ca.gov/2008publications/CEC-500-2008-049/CEC-\n500-2008-049-APB.PDF]\n40\n\uf0b7 \u201cReal Time System Operation 2006\u20132007,\u201d Project Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/RTSO2006\n-07_FactSheet.pdf]\n3.3New Capacity Transient Stability Capability\nTransient stability is the ability of the transmission grid to regain its equilibrium \nin the event of a transient disturbance, such as a line fault or generator trip. \nTime frames are typically milliseconds to seconds. Generator and load models \nare used to plan the operating configuration of the electric transmission system \nto anticipate and better handle transient behaviors. But if the models are wrong, \nthen the operating plans might not be able to address certain transient \nbehaviors potentially leading to reliability and power quality problems. TRP \nconducted research and demonstration to improve the generator models for \nwind generators, and the load models for new air conditioner technologies. \nThese models are now in use in California, the WECC, and other parts of the \nworld.  (See elsewhere in this paper, \u201cImproved Generator and Load Models,\u201d \nunder \u201cNew Technology for Accommodating Variable Renewable Generator \nUnique Behaviors.\u201d)\n3.4New Capacity Dynamic Stability Capability\nDynamic stability is the ability of the transmission grid to regain its equilibrium \nover time frames of 1 minute to as much as 30 minutes. Problematic instabilities\ncan manifest in a number of different behaviors, with low frequency oscillations \nbeing perhaps the most egregious in the Western grid as a reason for capacity \nde-ratings. Low-frequency oscillations, which cause power to surge back and \nforth through wide areas of the grid, typically have a period of a few seconds \nand can build over periods of minutes to hours. They have been identified as the \ninitiating event of some costly major multi-state blackouts, such as the \nwidespread blackout in the western United States and Canada in 1996. The root \ncauses of these dynamic instabilities were not all well known and research was \nneeded. There is a growing concern that these dynamic instabilities might be \nexacerbated by changes to the electric system, such as renewable energy \nsources that reduce system inertia and add more uncertainty; and energy \nefficient loads that introduce new dynamics, as well as uncertainty. These all \nchange system oscillation behaviors and make it more difficult to manage \nthrough traditional modulation control tuned with a system model. \nTRP conducted a significant number of research efforts to develop and \ndemonstrate stability operating tools based on synchrophasor measurements, \nwhich were new current and voltage measurement devices using time-stamping \nthat for the first time enabled wide-area real-time status and event monitoring, \ndetection, alarming, analysis and visualization.\nThe resulting operator tools considerably enhanced the operator situational \nawareness for greater reliability and promised enable operation of the \ntransmission system with smaller dynamic margins. In conjunction with certain \ncontrol technologies, perhaps energy storage, the tools might be used to \nmitigate dynamic instability threats, such as to damp oscillations. The TRP \nconducted a business case study for the use of synchrophasor measurements \n41\nthat examined applications and their economics, and include a roadmap for \ntechnology development. This study provided guidance for California and for \nmany other entities across the nation. It encouraged TRP research in \nsynchrophasor measurement based tools for rapid oscillation detection, analysis \nand mitigation; enhanced state estimation; smart adaptive relaying to prevent \nprotection system actions from aggravating cascading blackouts; voltage angle \nchanges for stress indication; etc. TRP also contributed substantial to the \ndevelopment of the platform for gathering and managing synchrophasor \nmeasurement data, and enabling application deployment. Much of this research \nhas resulted in commercial products and uses.\n3.5New Capacity Transmission Expansion Planning Capability\nAlthough reasonably precise, the traditional deterministic planning tools were \nincreasingly becoming inadequate to support accurate expansion planning in a \nfuture of growing uncertainty and complexity, which was expected partly \nbecause of the growing use of variable renewable generation. The TRP \nanticipated that new planning tools based on probabilistic, multivariate \nstatistical, risk assessment, and other advanced analytical science and \nmathematical techniques, along with faster computational tools, would be \nneeded. Recall that a recommendation of the Transmission Cost Allocation \nMethodologies project described earlier was the Quantification of Extreme Event \nBenefits (Insurance Value) in terms of reliability using an insurance premium \nconcept. Reliability benefits can be measured in terms of reducing blackout \nfootprint due to extreme (N-n) events and societal value of reduced risk of a \npower supply disruption.\n3.5.1 Extreme Events\nThe TRP took on the challenge of developing a planning tool for cascading \nblackouts caused by extreme events. A small initial power system \ndisturbance can cascade into a complicated chain of dependent failures \nleading to a widespread blackout. On August 10, 1996, a blackout started in \nthe Northwest USA and spread by cascading to disconnect power to about \n7,500,000 customers, including millions of customers in both Northern and \nSouthern California. The blackout of August 14, 2003 on the East Coast \naffected 50 million people and caused an estimated $10 billion in economic \nlosses in the USA. Although such extreme events are infrequent, the direct \ncosts are estimated to be in the billions of dollars, disrupting commerce and \nvital infrastructure. These blackouts also incur indirect costs including those \nfrom socioeconomic disruptions.\nA current practice for reasonably and routinely assuring the reliability of a \nlarge electric grid interconnection, such as the WECC, which might have well \nover 10,000 components that could fail, is to plan the configuration and \noperation of the grid for any one of these components to fail without an \nelectrical disruption. The short hand expression for this practice is the N-1 \nanalysis, where \u201cN\u201d is the number of nodes (components) in the \ninterconnection and \u201c1\u201d represents one of these nodal components failing. \nThe N-1 reliability analysis is done repeatedly for the failure of each nodal \ncomponent in turn. Traditional direct analytic approaches using N-1, or even \n42\nselected N-2, contingencies do not even begin to provide the capability to \nanalyze cascading blackouts, which have been characterized as \u201cN-20\u201d \ncontingency events, because many components usually fail in a given large \nspread electric system outage event. \nPerforming extreme event analysis for an interconnection such as the WECC \nusing the traditional approaches and the fastest computers in the U.S. was \nestimated for even an N-3 to take many months, and an N-4 analysis to take \nover a thousand years. Clearly the traditional analytical tools would not \nsuffice for extreme event modeling. Hence there was a need to develop new \nand innovative methodologies to simulate power systems to address the \nextreme events using practical power systems and come up with remedial \nactions that would allow system operators to keep the power system away \nfrom collapse, and designers to enhance the resistance to cascading outages.\nThis research pursued multiple approaches in order to better determine the \nstrengths and weaknesses of both existing methods and the new methods, \ne.g., probabilistic, multivariate statistical forecasting, developed in the \nproject, and produced encouraging results that these techniques would work \nto better characterize the resistance to cascading outages for a given or \nplanned grid infrastructure configuration.\nThe \u201cExtreme Events\u201d research project developed, and tested in a small-\nscale network model, the science and conceptual framework and advanced \nmathematical techniques needed for the complexity of multiple component \nand system failures in a transmission system, such as the \"N-20\" equivalent \nanalysis. Results included identification of critical corridors, event frequency \nand probability, and superior operational response strategies. Phase II applied\nPhase I methodologies to realistic network models to test their practicality. \nA joint industry, national laboratory, and university team addressed the \nchallenges of large blackouts caused by cascading failure by a combination of\nmodeling, simulation and analysis techniques. Multiple approaches were \npursued in order to better determine the strengths and weaknesses of both \nexisting methods and the new methods developed in the project.\nThe project developed transmission grid models for cascading failure at \nseveral levels of detail for the California grid. These grid models were used \nwith both industry and research-grade software to simulate the sequence of \ncascading events when there are one or several initial disturbances in the \npower grid. These simulated cascades were then analyzed and methods \ndeveloped to detect critical elements and conditions and recurring sequences\nof events. The project analyzed historical data on blackouts, analyzed \nsimulated blackouts statistically, studied the grid as an evolving complex \nsystem, and suggested factors that influenced the risk of cascades and ways \nto measure these factors. The understanding and methods developed can be \napplied to future studies to identify grid vulnerabilities, investigate the \neffectiveness of mitigation techniques, and quantify and explain the blackout \nrisk.\n43\nThe project achieved a number of firsts in the analysis of large \ninterconnections and cascading outages:\n\uf0b7 Developed the first-ever, full-size WECC model for cascading analyses \nusing TRELSS, an Electric Power Research Institute (EPRI) software \npackage for bulk power transmission system reliability evaluation using \ncontingency enumeration as an expansion of traditional deterministic \nanalysis.\n\uf0b7 Developed a methodology and extensive sets of initiating events for \ncascading analyses in the Western Interconnection.\n\uf0b7 Performed a total of 33,000 simulations to analyze the WECC system \nvulnerability to cascading events, providing:\n\u2013 A ranking of initiating events by severity\n\u2013 Identification of the most frequent sequences of cascading outages \n(critical events corridors)\n\uf0b7 Compared results obtained in Phase II against reduced models\n\uf0b7 Developed a reduced, 1500 bus WECC model that has been the basis of \nseveral other analyses, such as: Benjamin Carreras et al., \u201cValidating \nOPA with WECC Data,\u201d 46th Hawaii International Conference on System \nSciences, January 2013.\n\uf0b7 This model was provided under a non-disclosure agreement (NDA) to \nOregon State University for use by staff and students.\nThe U.S. Department of Energy\u2019s Office of Electricity (DOE-OE) subsequently \nfunded at $1.25M the Pacific Northwest National Laboratory (PNNL), the \nprincipal investigator for the \u201cExtreme Events\u201d project, to conduct a new \nproject, \u201cDynamic Contingency Analysis Tool\u201d (DCAT) that will leverage the \nexperience built in the extreme event project and will overcome several of \nthe gaps that were identified in the previous effort. The purpose of the \nproject is to develop a dynamic extreme events analysis tool to evaluate the \nrisk of load loss due to extreme events, identify the most probable and \nimpactful events, and evaluate the impact of system reinforcements. The \ngoal of this project is to strengthen the capabilities of grid planners to assess \nthe impact of extreme contingencies and potential cascading events across \ntheir systems and interconnections. This project will develop the necessary \nmodels and methods for analysis and identification of cascading events in the\ncontext of large dynamic systems.  The project directly supports new NERC \n\u201cStandard TPL-001-4 \u2014 Transmission System Planning Performance \nRequirements\u201d to be enforced in 2015 and 2016, and a similar \u201cTransmission \nSystem Planning Performance WECC Regional Criterion TPL-001-WECC-CRT-\n3\u201d currently under development in the WECC system.\nPublications, Presentations and Industry Interactions:\n\uf0b7 Presented \u201cExtreme Events Analysis in the full WECC System \u2013 \nMethodologies and Results\u201d to the WECC Reliability Subcommittee on \nJanuary 14, 2011.\n\uf0b7 Provided sample results to Project Advisory Committee (PAC) members \nfrom Idaho Power and PG&E to further examine simulation results.\n\uf0b7 Verified a limited set of actual cascading events from WECC disturbance \nreports in TRELSS and compared the results.\n44\n\uf0b7 Y.V. Makarov, N. Samaan, R. Diao, M. Kumbale, Y. Chen, R. Singh, and \nM.P. Morgan, \u201cAssessment of Critical Events Corridors through \nMultivariate Cascading Outages Analysis,\u201d 2011 PES General Meeting, \n24-29 July 2011, Detroit, Michigan, USA. (Panel paper)\n\uf0b7 Active participation in the IEEE Task Force on Understanding, Prediction, \nMitigation and Restoration of Cascading Failures, that resulted in several\npublications such as: Papic M, K Bell, Y Chen, I Dobson, L Fonte, E Haq, P \nHines, D Kirschen, X Luo, S Miller, NA Samaan, M Vaiman, M Varghese, \nand P Zhang.  2011. \u201cSurvey of Tools for Risk Assessment of Cascading \nOutages,\u201d IEEE Power and Energy Society General Meeting, July 24-29, \n2011. Detroit, Michigan.\n\uf0b7 Submitted and published in IEEE Transactions:  Vaiman, M.; Bell, K.; \nChen, Y.; Chowdhury, B.; Dobson, I.; Hines, P.; Papic, M.; Miller, S.; \nZhang, P., \u201cRisk Assessment of Cascading Outages: Methodologies and \nChallenges,\u201d Power Systems, IEEE Transactions on , vol.27, no.2, pp.631-\n641, May 2012.\n\uf0b7 Presented at the 2011 IEEE PES General Meeting: Vaiman, M.; Bell, K.; \nChen, Y.; Chowdhury, B.; Dobson, I.; Hines, P.; Papic, M.; Miller, S.; \nZhang, P., \u201cRisk Assessment of Cascading Outages: Part I \u2013 Overview of \nMethodologies,\u201d IEEE Power and Energy Society General Meeting, vol., \nno., pp.1-10, 24-29 July 2011.\nSources:\n\uf0b7 Extreme Event Research Fact Sheet:\nhttp://uc-ciee.org/images/downloadable_content/electric_grid/EE_FactSh\neet.pdf \n\uf0b7 Extreme Events (Contract Number 500\u201002\u2010004, UCMR\u2010076), conducted \nby Pacific Northwest National Laboratory, University of Wisconsin\u2010\nMadison, Electric Power Research Institute, BACV Solutions, Southern \nCompany, CIEE, University of Alaska\u2013Fairbanks. CEC-500-2013-031, \nMarch 2011. [http://www.energy.ca.gov/2013publications/CEC-500-2013-\n031/CEC-500-2013-031.pdf \n\uf0b7 Personal Communications: Mark Morgan, Project Manager, Pacific \nNorthwest National Laboratory, Richland, WA.\n3.6Transmission Congestion Assessment and Probabilistic \nForecasting \nCongestion costs in California can be very high and mitigating these costs \ngenerally involves long term planning and expensive upgrades to the grid in the \nform of new transmission lines or expansion of existing ones. In 2004, California \nIndependent System Operator (CAISO) gross congestion and Reliability Must Run\nGeneration (RMR) costs were estimated to be in the neighborhood of $1 billion \nannually, with congestion accounting for approximately half of the total. This \nfigure did not include congestion that may be experienced on the California \ntransmission facilities operated separate from CAISO. The problems of \ncongestion also have an adverse impact on reliability, environment, and \nefficiency. Improved understanding of the nature of California\u2019s congestion \nissues is a necessary precursor to effectively managing the problem. Improved \n45\nforecasting of transmission congestion in both the short term and the long term \ncan increase the reliability, efficiency and long term of the California electricity \nsystem. Improvements in congestion management will help achieve the State\u2019s \ngoals for CO2 reduction and renewable generation deployment, and to provide \nreliable and low cost electricity with minimum environmental impacts. \n3.6.1 California Transmission Congestion Assessment\nThis project was performed by the Electric Power Group. The Principal \nInvestigator was Jim Dyer.\nThe purpose of this project was to perform a scoping study to document in \nexplicit detail the scope and magnitude of the congestion problems facing the\nstate of California and to report the challenges in forecasting. The specific \nobjective was to develop a primer document on congestion on the California \ngrid that would: \n\uf0b7 Explain the problem of congestion \n\uf0b7 Identify the key metrics and thresholds for establishing critical levels of \ncongestion. \n\uf0b7 Present historical congestion patterns \n\uf0b7 Discuss the challenges of forecasting congestion \n\uf0b7 Describe the current transmission system sources of information \nregarding congestion and identify sources of inconsistencies.\nThe project consisted of two primary approaches to gathering information \u2013 \ndata collection and interviews. The data collection process was to obtain \nhistorical data on congestion from a number of California transmission control\narea operators as well as the California Energy Commission. Interviews were \nthen conducted with several California transmission control area operators to \nobtain their inputs and assessments. \nThe scoping study found that the CAISO congestion cost data understated the\namount of congestion that exists. It captured information related only to \nschedules attempted, as compared to the full economic potential for \ntransactions. Inter-zonal congestion caused higher prices for all energy within\nthe zone. This price impact was not captured in current congestion cost \nassessments. Reliability Must Run (RMR) was the largest single component of \ncongestion costs. Without the construction of new local generation, RMR \ncosts could only be reduced by expanding the transmission capabilities into \nconstrained local areas. Congestion could only be avoided by planning and \nconstructing sufficient transmission in advance to manage any remaining \ncongestion costs to acceptable levels. Metrics would be needed to identify \nand classify congestion costs as actionable, manageable, or to be monitored. \nIn general, the findings provided an essential building block for developing a \ncongestion planning methodology in future research.\nSources:\n\uf0b7 Dyer, Jim; John Ballance. (Electric Power Group, LLC). 2007. California \nTransmission Congestion Assessment. California Energy Commission. \nPublication number: CEC-500-2011-007. \n46\n[http://www.energy.ca.gov/2011publications/CEC-500-2011-007/CEC-\n500-2011-007.pdf]\n\uf0b7 \u201cCalifornia Transmission Congestion Assessment,\u201d Research Project Fact\nSheet. [http://uc-ciee.org/images/downloadable_content/electric_grid/\nTCAM_FactSheet.pdf]\n3.6.2 Probabilistic Transmission Congestion Forecasting\nThis project was performed by the Electric Power Research Institute (EPRI). \nThe Principal Investigator was Stephen T. Lee.\nBecause there are many factors that combine to determine how electricity \nflows on an interconnected power grid, the uncertainties of these factors, for \nexample random loss of a generator or a transmission line, a load coming on \nor dropping off line, or the variability of a renewable generator, compound \nthe uncertainty and the difficulty of forecasting transmission congestion for \nany particular transmission path. This difficulty will become even more \npronounced with the advent of high penetrations of variable renewable \ngeneration in California. Making forecasts under high uncertainty often \nmeans using probabilistic methodologies.\nThis research developed new probabilistic forecasting methods, for both short\nterm and long-term transmission congestion in California, for use in \ntransmission planning and forecasting tools that recognize uncertainties \ncreated by independent market participants, especially variable renewable \nresources, and distributed generation, and by consumer participation, \nparticularly demand response. The mathematical models and the time frames\nof the simulation differ between the short term (24 hours) and the long term \n(10-20 years), and therefore two computer models were developed to \naddress the two time frames. An important aspect of this research was that it\ndetermined and specified how to accurately model the key input assumptions\nin order to derive valid confidence levels of the forecasted congestion \nvariables. Methodology was demonstrated using the equivalent model of the \nWECC system, with focus on the impact of such congestion on the California \npower grid and consumers \nFor long term probabilistic forecasting, the quality of results was highly \ndependent on load forecasts and future resource projections, but probabilistic\nforecasting gave significant information regarding incremental improvements\nand timing of future transmission upgrade requirements. Short term \nsimulations also showed a strong dependence on load forecasts and on \ngeneration dispatch. It was found that high variability in daily wind patterns \naffecting wind generation would increase congestion and the uncertainty of \nforecasts. \nThis project developed an approach that accounts for significant uncertainty \ncaused by load and generation forecasts as well as random unplanned \nequipment outages. Meeting California\u2019s Renewable Portfolio Standard goals \nwill increase the volatility of congestion due to wind generation and present \ntremendous challenges for the CAISO in managing the power grid. The CAISO \nreported that annual congestion costs on the California-Oregon Intertie (COI) \n47\npath increased to $12 million in 2006 compared to $6.7 million in 2005. \nCongestion costs will likely increase even more with the higher penetration of\nwind power, so improvements in congestion management could yield \nsignificant cost savings and help achieve California\u2019s goals for reducing \ngreenhouse gas emissions and providing reliable and low-cost electricity to \nCalifornia consumers with minimum environmental impacts.\nThe successes of this PIER funded project were built upon by EPRI in follow-on\nresearch:\n\uf0b7 The EPRI P40 (Grid Planning) members continued one year funding \nsupport in 2008 and development of a software package based on this \nCEC/CIEE research project: Probabilistic Transmission Congestion and \nConstraints Forecast (PCF) Version 1.0 (1015997)  Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000000001015997  \n\uf0b7  Some of probabilistic modeling approaches developed through the CEC/\nCIEE research project were also applied to address wind integration, \nwhich was supported by EPRI P173 members (Renewable Integration). \nThe final report is Advanced Planning Method for Integrating Large-Scale\nVariable Generation. Available:  \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000000001017903 Congestion Risk Assessment, EPRI, \nPalo Alto, CA. 1013809. Available: http://www.epri.com/abstracts/Pages/\nProductAbstract.aspx?ProductId=000000000001013809 \nOther research conducted by EPRI built upon this CEC/CIEE research project: \n\uf0b7 Probabilistic Transmission Congestion and Constraints Forecast (PCF) \nVersion 1.0 (1015997): Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000000001015997 \n\uf0b7 Hedging the Long-Term Transmission Price Risks Associated with \nGeneration Investments. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000000001010693 \n\uf0b7 Transmission Price Risk Management. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000000001012475 \n\uf0b7 Managing Transmission Risk. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=TR-114276 \n\uf0b7 Managing Transmission Curtailment Risk Through Forecasts of \nTransmission Loading Relief Calls. Available: \nhttp://www.epri.com/abstracts/Pages/ProductAbstract.aspx?\nProductId=000000000001015871 \nMany of the forecasting and hedging techniques developed in this connected \ncollection of research is available to ISOs, energy traders and utilities.\n48\nSources:\n\uf0b7 Lee, Stephen, December 2012. Probabilistic Transmission Congestion \nForecasting. California Energy Commission, PIER Program. CEC-500-\n2013-120. Available: http://www.energy.ca.gov/2013publications/CEC-\n500-2013-120/CEC-500-2013-120.pdf \n\uf0b7 \u201cProbabilistic Transmission Congestion Forecasting,\u201d Research Project \nFact Sheet, Available: \nhttp://uc-ciee.org/images/downloadable_content/electric_grid/TPCF_Fact\nSheet.pdf \n\uf0b7 Personal Communication: Robert Entriken and Liang Min, Electric Power \nResearch Institute, Palo Alto, CA\n3.7New High Power Flow Managing Capability\nIncreasing the capacity of transmission lines, however, brings with it the threats \nof substantial grid equipment damage and injury to humans from higher fault \ncurrents, and greater security and reliability vulnerabilities from more power \nbeing concentrated in fewer pathways. These threats needed to be addressed \nalong with achieving increased power capacities in the grid. The TRP research in \nextreme event analysis described above addressed in part the latter threat. \nProtecting the grid and people from higher fault currents required hardware \ndevelopment because in many cases anticipated fault currents threatened to \nexceed the ability of circuit breakers to safely and reliably interrupt the faults. \nAside from undesirable solutions such as installing substation neutral reactors, \nsplitting substation buses, or derating circuit paths, what was needed was a new \nclass of devices to control the fault currents by keeping them within the \ncapabilities of the available circuit breakers. Fault current controllers were \ncurrently in the RD&D phase, with several manufacturers testing prototypes in \nthe 15 kV class. Prototype devices needed to be demonstrated in actual utility \nsystems in order to identify implementation issues and utility resource \nrequirements, and to provide the requisite field experience to refine the designs \nfor utility acceptance. The TRP developed a project to test prototypes in the field\nwith a California utility as the host for the demonstration.\n3.7.1Development of Fault Current Controller Technology\nThis project was performed by the Electric Power Research Institute (EPRI), \nSC Power Corp. (later Zenergy Corp.), and the University of California - Irvine.\nThe Principal Investigator was Carl Blumstein, CIEE.\nOverall electric current loading on the transmission system has been rapidly \nclimbing due to the growth in demand for electricity. The resulting higher \nelectrical energy levels have increased the potential fault current magnitudes\nat locations throughout the transmission system. Fault currents, in many \ninstances, may exceed the capability of existing protection systems (circuit \nbreakers) to interrupt the faults safely and reliably, and represent an \nimminent threat to electrical equipment and the safety of utility workers and \nthe public. Consequently, utilities must either upgrade their circuit breakers \nand associated equipment, or reconfigure their systems to reduce the \npotential fault current. Both solutions are costly, and frequently reduce \n49\nsystem reliability and power transfer capability. Application of fault current \ncontroller (FCC) technology, also frequently referred to as fault current limiter\n(FCL) technology, has been identified as a potentially viable solution for \nmanaging fault currents to keep them within the existing short circuit \ncapacity ratings of the system, in order to expand and extend the \ntransmission system\u2019s capacity and service life while minimizing capital \ncosts. This approach allows utilities to continue to meet the growing demand \nfor electricity reliably and cost-effectively.   \nThis project developed and evaluated two prototype designs of FCC \ntechnologies. The goals of the proposed research were to establish the \ndesired criteria for FCC performance and to test the two prototype FCC \ntechnologies against those criteria by means of controlled laboratory testing \nand field demonstration in a commercially operating Southern California \nEdison Co. (SCE) distribution system. The overall objective of this project is to\nfacilitate the improved, safe and reliable operation of the power system by \nadvancing FCC technology as a cost-effective and environmentally-preferred \noption to breaker upgrades or system reconfiguration, and by evaluating the \nrealistic potential of this technology to mitigate fault current levels at higher \nvoltages in the electric system through real-world utility testing. The ultimate \nprogram goal is to enable the commercialization of FCC technology for the \nbenefit of California and the United States.\nThe objectives of the proposed research were to:\n\uf0b7 Establish an FCC test plan including test criteria, test protocol, test site \nselection, test scheduling, data collection plans, and interface \nrequirements for both the laboratory testing and field demonstration.\n\uf0b7 Develop two prototype FCCs, one saturable-core type developed by \nZenergy Power plc, and one solid-state type developed by the Electric \nPower Research Institute (EPRI) and Silicon Power Corp. team.\n\uf0b7 Conduct laboratory testing of the two FCCs against the criteria, including\npre-connection high-voltage insulation tests, normal operation tests, and\nfault current limiting tests.\n\uf0b7 Install the FCCs on the SCE distribution system and perform field \ndemonstration for a minimum of six months.\n\uf0b7 Complete the evaluation of the technologies on the basis of \nperformance, respective strengths and weaknesses, costs, reliability, \ninstallation, operation and maintenance issues, and potential for \ndevelopment to high-voltage design. \nA project team was formed, in which the California Institute for Energy and \nEnvironment (CIEE) as the Performing Institution was responsible for overall \nproject direction, coordination and administration; University of California, \nIrvine (UCI) as the Principal Investigator was responsible for project technical \nmanagement, coordination, and contractor oversight; Southern California \nEdison Co. (SCE) was the host utility for the field demonstration and support; \nand Zenergy Power, plc and the EPRI/Silicon Power team were engaged to \nprototype and field-test a passive-type FCC and an active-type FCC, \n50\nrespectively. In addition, a Project Advisory Group (PAG) was assembled with \nexperts from utility companies, national laboratories, regulatory boards, and \nother relevant stakeholder organizations to provide technical guidance and \nevaluation of project results.\nThe project started in September 2007. This was not the first attempt in the \nUnited States to develop a distribution-level FCC and demonstrate it on an \noperating power system. However, none of the earlier efforts had led to a \nsuccessful field demonstration in the US. The obstacles to be overcome were \nchallenging. First, there were no industry standards for such a device, \ncomplicating the development of testing protocols. Second, there were \nsignificant engineering challenges in developing the prototypes to withstand \nthe currents and voltages in the field. Third, the prototype FCCs had to meet \nSCE\u2019s specifications for field demonstration on their system. Finally, the FCCs \nhad to demonstrate the ability to withstand live circuit events and severe \nenvironmental conditions.  \nAn important step taken in the early stages of the project was a focused \neffort to develop the test plan acceptable to SCE and workable for the teams. \nThis test plan needed to incorporate, to the extent possible, the relevant \nengineering standards that apply to electrical apparatus. Zenergy Power \nworked closely with Georgia Tech's National Electric Energy Testing, \nResearch and Applications Center (NEETRAC) and several of its member \nutilities, including SCE, to implement a detailed FCC test program based on \nselected IEEE and CIGRE standards and protocols for transformers and \nreactors. The EPRI/Silicon Power team created their plan based on ANSI \nC39.09-1999 and ANSI C37.06-2000, covering the entire spectrum of possible\ntests that needed to be carried out on their FCC, including component level \nfactory tests, system level factory tests, acceptance tests and system field \ntests. Many technical issues related to laboratory test and field \ndemonstration interfacing were resolved via a series of meetings with \nknowledgeable SCE engineers. Both teams completed their test plans, which \nprovided valuable design and testing guidelines.  \nZenergy Power completed the design, construction, and testing of an FCC \nprototype based on the saturable-core concept. This type of FCC is basically a\ncoil wound on an iron core and connected in series with the power line. In the\nnormal state, the core is biased into magnetic saturation by a dedicated DC \nelectromagnet, so that the inductance of the magnetically saturated coil and \nthe corresponding voltage drop across the coil terminals are negligible. \nTherefore, the coil has no deleterious effect on the system during normal \noperation. However, in the event of a fault, the magnetic core is driven out of\nsaturation by the fault current. Consequently, the coil becomes highly \ninductive, effectively inserting a large impedance into the power circuit and \nlimiting the fault current, without any need for active sensing or switching. A \nkey enabling feature of the Zenergy Power HTS FCL is the use of a high-\ntemperature superconducting (HTS) winding for the DC bias circuit, which \nreduces bias circuit power loss while increasing the intensity of the bias field; \nthus the Zenergy Power device is referred to as an HTS FCL. \n51\nThe prototype HTS FCL went through a series of rigorous laboratory tests in \nBC Hydro\u2019s Powertech Laboratory in Surrey, BC, Canada. A total of 65 \nseparate tests were performed, including 32 full-power fault tests with first \npeak fault current levels up to 59 kA at the rated voltage. Fault tests included\nindividual fault events of 20-30 cycles duration, as well as multiple fault \nevents in rapid sequence (to simulate automatic re-closer operation) and \nextended fault events of up to 82 cycles duration, simulating primary \nprotection failure scenarios. The HTS FCL passed the test criteria in all cases. \nOnly minor modifications to high-voltage isolation layout were needed. The \nunit was then transferred to the SCE Westminster High-Voltage Test Facility \nfor acceptance tests by SCE per IEEE Standard C57-12.01-2005 (Attachments\nIII-VI).  \nUpon the successful completion of the acceptance tests, the HTS FCL was \ninstalled in SCE\u2019s Avanti Circuit of the Future and operated from March 2009 \nthrough October 2010. The unit was integrated into SCE\u2019s SCADA system and\noperated in real time to provide protection to the distribution circuit during its\nfield demonstration. A monitoring and data acquisition system was installed \nto archive performance data of the HTS FCL throughout the field testing \nperiod. \nDuring the course of the field demonstration, several deficiencies in the \noriginal design and construction were revealed, including a PLC RAM overflow\nprogramming issue, HVAC shutdown due to excessive ambient temperature, \nhelium leaks in the cryogenic coolers, nitrogen pressure instabilities \nassociated with the liquid nitrogen cooling system, and a terminal block \nshort. These events provided valuable learning experiences for the team to \nidentify design weaknesses and make necessary corrections along the way, \nresulting in significant design and implementation enhancements. \nThe immediate research benefits obtained from the Zenergy Power HTS FCL\u2018s\noperational experience included validation of the importance of a more \ncompact, more reliable, and easier to maintain non-HTS design for the FCL, \nand one which is scalable to transmission voltages. Operations manuals for \nthe device are provided as Attachments VII-IX.\nThe field demonstration has been instrumental in furthering the development\nof FCL technology and contributing to Zenergy Power\u2019s first commercial sale \nof a medium-voltage device. Furthermore, Zenergy Power has extended the \nresearch results to prototype development and applications at the \ntransmission voltage level.   \nThe Electric Power Research Institute (EPRI) and Silicon Power Corp. team \ncompleted an initial design for an FCL based on solid-state circuit technology \nemploying their Super GTO (SGTO) thyristor switches. The FCL design \nconsists of a set of standard building blocks (SBB), each containing an SGTO-\nbased circuit designed for 5 kV voltage blocking and 2000 A continuous \ncurrent ratings. The SBBs are used in multiples to form standard power stack \n(SPS) assemblies rated for 50 kV voltage blocking and 2000 A continuous \ncurrent ratings. One SPS per phase is required for the 15kV-class system. \n52\nThree SPSs are then housed in an oil-filled tank to form a complete three-\nphase FCL, referred to as the Solid State FCL (SSFCL) unit. In the normal \nstate, the SGTO switches are turned on, which allows continuous rated \ncurrent to flow through the circuit; upon detection of a fault, the control \ncircuits open the SGTO switches to insert a current limiting reactor (CLR) into \nthe circuit to limit the fault current.   \nThe 15kV, 1200A SSFCL was designed for outdoor use according to the \nC57.12.00-2010 IEEE Standard for General Requirements for Liquid-Immersed\nDistribution, Power, and Regulating Transformers. The overall SSFCL package\nis physically similar to a typical substation transformer tank with an external \nradiator bank for the cooling system. A comprehensive test plan was also \ndeveloped for the SSFCL.\nDuring initial simulation of the thermal performance of the SSFCL design, less\nthan optimal thermal performance was predicted, which could have led to \nundesirable effects on the stability and reliability of the final, manufactured \nSSFCL. The designs of the thermal management system and the control \nboards were therefore modified during the course of the project, to provide a \nmore efficient thermal management system and to improve the noise \nimmunity of the controls. An unfortunate result of this necessary re-design \nwas a much higher projected construction cost than allowed by the available \nproject budget; therefore, this part of the project was terminated by mutual \nconsent of the CEC, CIEE and EPRI at the conclusion of the design stage. EPRI \nwas able to incorporate this and other lessons learned into a newer SSFCL \ndesign, to be developed within their normal program funding structure and \ndemonstrated at some point in the future.\nConclusions:\nThe research in this project has led to the successful field demonstration of \nthe Zenergy Power HTS FCL, marking a milestone event in the history of FCL \ndevelopment in the United States. The experience gained from the research \ncontributed to a more reliable controller, a dramatic reduction of the FCL\u2019s \nsize (with a slight increase in weight), and the replacement of liquid nitrogen \ncryogenic refrigeration by a low-maintenance, dry (non-HTS) cooling system \nfor increased reliability and reduced maintenance requirements.\nThe first-generation \u201cSpider-core\u201d HTS FCL design had a dry-type transformer\n(air dielectric) structure, total overall dimensions of 19\u2019x19\u2019x7\u2019, and weighed \napproximately 50,000 lb. The second-generation \u201cCompact\u201d HTS FCL that \nfollowed from this demonstration employed innovative core architecture and \noil dielectric transformer construction techniques that led to a much more \ncompact size of approximately 8\u2019x10\u2019x11\u2019 and a somewhat increased weight \nof approximately 67,000 lb. The Compact FCL has a power rating similar to \nthe Spider-core FCL, but with a much higher fault current limiting \nperformance. The new Compact FCL design is an improved option for \napplications where real estate is limited, albeit with somewhat increased \nweight.\n53\nRegarding cost-effectiveness, as the first-generation device had a relatively \nlow power rating, on the order of 25 MVA, the present manufacturing cost \nmay not represent a high value proposition. This issue is being addressed on \ntwo fronts: HTS FCL technology is being improved to reduce basic device \nmanufacturing cost, and it is being scaled up for higher voltages and \ncurrents. The latter may be more important in terms of cost-effectiveness \nand value proposition, considering the fact that higher voltage substations \ncan often be more crowded and have fewer options for expansion, and higher\nvoltage components (switchgear, insulators, transformers, bus-work) are \nexponentially more expensive than their low-voltage counterparts. \nFurthermore, the larger renewable power generators will most likely desire to\nconnect to the transmission system, and high-voltage tie-lines have become \nincreasingly more common as more power is wheeled from long distances \nand as grid interconnections occur to improve reliability and better control \npower flows. All of these factors are projected to continue to increase energy \nlevels within the grid, leading to potentially unsafe fault current levels. In \nsome cases, higher-rated components cannot be retrofitted in the available \nspace, leading to lengthy and costly major upgrades of grid infrastructure. \nEconomic studies and performance models show that at current performance \nlevels and price points, FCC technologies can be very cost-effective \ncompared to major upgrade projects at high voltages. \nA key area for improvement identified during the field testing was the liquid \nnitrogen cooling system, which required periodic maintenance of the \ncryostat, including drying, establishing vacuum, and refilling the liquid \nnitrogen. This may not be practical, considering the fact that the unit would \ntypically be installed in a high-voltage substation area. However, this issue \nwas resolved in the second-generation FCL design by replacing the liquid \nnitrogen HTS system with a cryogen-free, \u201cdry-type\u201d conductive cooling \nsystem, available as a commercial off-the-shelf unit, resulting in a more \nreliable and robust system requiring less maintenance. \nOverall, the Zenergy Power HTS FCL project is considered to have been an \nimportant success and it has already led to a scaled-up design for a \ntransmission-level 138 kV FCL application, which Zenergy is actively \nmarketing to utilities around the world. \nThe EPRI/Silicon Power SSFCL represents another potentially cost-effective \nsolution to the rapidly increasing fault current levels in utility systems. One \nadvantage of this type of FCL is the flexibility to be configured as either \ninterruptive (i.e., to act as a \u201csolid-state circuit breaker\u201d) or simply limiting \nthe fault current (and leaving the fault interruption to existing protective \ndevices), with only minor design differences. Also, a solid-state FCL may be \nused to limit the current of superconducting cables to enable the use of \nsmaller cable sizes. The solid state FCL also has a unique capability to limit \ninrush currents, even for capacitive loads.\nThe EPRI/Silicon Power team identified some potential thermal management \nissues in their initial design. An improved system design was completed, and \nthe major technical design challenges, such as the thermal management \n54\nsystem, and the control circuit architecture and timing issues, have been \nresolved. However, the resulting cost increase to actually construct the \ndevice was constrained by the project budget. Thus, this FCL was not able to \nadvance to the laboratory test and field demonstration stages under this \nproject.   \nAccording to the design predictions, the system size and weight would be \n6.5\u2019x12\u2019x12\u2019 and weight would be 62,000 lb. with oil cooling. These size and \nweight specifications would have been considered acceptable for utility \napplications.   \nThe SSFCL employs a modular and scalable design. The SSFCL designed for \nthe 12 kV line in this project period is composed of 10 SBBs in series. A future\nconsideration with this design is that voltage sharing to maintain all the SBBs \nunder the blocking voltage under dynamic conditions may be a technical \nchallenge for transmission level applications where the voltage level is above \n100 kV.\nOverall, the EPRI/Silicon Power team made a substantial amount of progress \nin the design, development and improvement of the SSFCL concept. During \nthe project period, many engineering challenges were identified and a new \ndesign was completed.   \nRecommendations:\nFault Current Controller (FCC) technology is a potentially cost-effective \nalternative to the capital-intensive upgrades of the power system that would \nordinarily be required to meet growth in electrical demand. The \ndemonstration projects in this phase have already resulted in two test plans \nand two full FCC designs, and have contributed to one commercial sale and \none migration to a transmission-level application. \nFurther fast-paced and more advanced development of FCC technology is \nstrongly recommended. As the demand for electrical energy rapidly \nincreases, particularly in response to renewable power and \u201cgreen \ntechnology\u201d initiatives, and in the absence of better alternatives, substantial \ninvestments in system upgrades would have to be made on a fast-track basis \nin order to maintain the required levels of electric system availability and \nreliability. Significant amounts of these investment are potentially avoidable, \nif suitable FCC technologies are available to California utilities, and if \nCalifornia utilities are given reasonable incentives to deploy the new \ntechnologies. An accelerated program of FCC technology focused on reducing\nthe cost, improving the reliability, and increasing the voltage and current \nratings of FCC technology is needed in order for California utilities and \nratepayers to reap the benefits. New and promising technologies are also \nimportant for economic recovery and the creation of new jobs.  \nSources:\n\uf0b7 K. Smedley, A. Abramovitz. (University of California, Irvine). 2011. \n\u201cDevelopment of Fault Current Controller Technology.\u201d California Energy\nCommission. Publication number: CEC-500-2013-134. \n55\n\uf0b7 T. Taylor, A. Hanson, D. Lubkeman, M. Mousavi. \u201cFault Current Review \nStudy,\u201d ABB Report No. 2005-11222-1-R.04, pp. 41-45, December 22, \n2005.\n\uf0b7 P. G. Slade, R. E. Voshall, J. L. Wu, J. J. Bonk, E. J. Stacey, W. F. Stubler, J. \nPorter, L. Hong. \u201cThe Utility Requirements for a Distribution Fault \nCurrent Limiter,\u201d IEEE Transactions on Power Delivery, vol. 7, no. 2, pp. \n507-515, April 1992.\n\uf0b7 S. Eckroad. \u201cUtility Needs Survey for Fault Current Limiters,\u201d \nInternational Workshop on Coated Conductors for Applications (CCA08), \nElectric Power Research Institute, \np. 7, December 4-6, 2008.\n\uf0b7 C. Meyer, S. Schr\u00f6der, R. W. De Doncker. \u201cSolid-State Circuit Breakers \nand Current Limiters for Medium-Voltage Systems Having Distributed \nPower Systems,\u201d IEEE Transactions on Power Electronics, vol. 19, no. 5, \npp. 1333-1340, Sep. 2004.\n\uf0b7 M. Noe, M. Steurer. \u201cHigh-temperature Superconductor Fault Current \nLimiters: Concepts, Applications, and Development Status,\u201d \nSuperconductor Science & Technology, vol. 20, pp. R15-29, January 15, \n2007.\n\uf0b7 M. M. R. Ahmed, G. Putrus, Li Ran, R. Penlington. \u201cDevelopment of a \nPrototype Solid-State Fault-Current Limiting and Interrupting Device for \nLow-Voltage Distribution Networks,\u201d IEEE Transactions on Power \nDelivery, vol. 21, no. 4, pp. 1997-2005, Oct. 2006.\n\uf0b7 H. J. Boenig and D. A. Paice. \u201cFault Current Limiter Using a \nSuperconducting Coil,\u201d IEEE Transactions on Magnetics, vol. 19, no.3, pp.\n1051-1053, May 1983.\n\uf0b7 B. P. Raju, K. C. Parton, T. C. Bartram. \u201cA Current Limiting Device Using \nSuperconducting DC Bias, Applications and Prospects,\u201d IEEE \nTransactions on Power Apparatus and Systems, vol. 101, pp. 3173\u20133177,\n1982.\n\uf0b7 G. A. Oberbeck, W. E. Stanton, A. W. Stewart. \u201cSaturable Reactor Limiter \nfor Current,\u201d US Patent 4152637, May 1979.\n\uf0b7 M. Iwdiara, S. C. Mukl, S. Yaniada, et al. \u201cDevelopment of Passive Fault \nCurrent Limiter in Parallel Biasing Mode,\u201d IEEE Transactions on \nMagnetics, vol. 35, no. 3, pp. 3523-3525, 1999.\n\uf0b7 V. Rozenshtein, A. Friedman, Y. Wolfus, F. Kopansky, E. Perel, Y. \nYeshurun, Z. Bar-Haim, Z. Ron, E. Harel, N. Pundak. \u201cSaturated Cores \nFCL\u2014A New Approach,\u201d IEEE Transactions on Applied Superconductivity,\nvol. 17, no. 2, pp. 1756-1759, June 2007.\nPublications:\n\uf0b7 F. Moriconi, N. Koshnick, F. de la Rosa, A. Singh, \u201cModeling and Test \nValidation of a 15kV 24MVA Superconducting Fault Current Limiter,\u201d \n2010 IEEE PES Transmission and Distribution Conference and Exposition,\npp. 1-6, April 19-22, 2010. \n\uf0b7 A. Nelson, L. Masur, F. Moriconi, F. de la Rosa, D. Kirsten. \u201cSaturated-\nCore Fault Current Limiter Experience at a Distribution Substation,\u201d 21st \nInternational Conference on Electricity Distribution, June 6-9, 2011.\n\uf0b7 F. Moriconi, F. de la Rosa, F. Darmann, A. Nelson, L. Masur. \n\u201cDevelopment and Deployment of Saturated-Core Fault Current Limiters \n56\nin Distribution and Transmission Substations,\u201d IEEE Transactions on \nApplied Superconductivity, vol. 21, no. 3, pp. 1288-1293, June 2011.\n\uf0b7 C. R. Clarke, F. Moriconi, A. Singh, A. Kamiab, R. Neal, A. Rodriguez, F. de\nla Rosa, N. Koshnick. \u201cResonance of a Distribution Feeder with a \nSaturable Core Fault Current Limiter,\u201d 2010 IEEE PES Transmission and \nDistribution Conference and Exposition, pp. 1-8, April 19-22, 2010.\n\uf0b7 C.R. Clarke, A. Kamiab, A. Abramovitz. \u201cCurrent Limiter Performance \nUnder an Actual Multiple Fault Event,\u201d IEEE Power and Energy Society \nGeneral Meeting, July 2012.\n\uf0b7 A. Abramovitz, K. Smedley. \u201cReview of the Saturable Core Fault Current \nLimiter Technology,\u201d submitted to IEEE Transactions on Power Delivery, \nNov. 2010. \n\uf0b7 A. Abramovitz, K. Smedley, F. de la Rosa, F. Moriconi. \u201cPrototyping and \nTesting of a 15kV/1.2kA Saturable Core Reactor High Temperature \nSuperconductive Fault Current Limiter,\u201d IEEE Transactions on Power \nDelivery, vol. 8, no. 3, July 2013.\n\uf0b7 A. Abramovitz, K. Smedley. \u201cSurvey of Solid State Fault Current \nLimiters,\u201d IEEE Transactions on Power Electronics, vol. 27, no. 6, June \n2012.\n\uf0b7 L. Sanford. \u201cFirst HTS FCL Goes into a US Grid,\u201d Modern Power Systems, \nMay 2009.\n3.8Real-Time System Operations\n3.8.1A Business Case Study on Applying Synchrophasor \nMeasurement Technology and Applications in the California and\nthe Western Electricity Coordinating Council Grid\nThis project was performed by KEMA, Inc. The Principal Investigator was \nDamir Novosel.\nPhasor measurement units (PMUs) collect time-synchronized grid data to \nprovide real-time information about the status of a point on the grid. The \ndevelopment of new synchrophasor measurement-based technologies for \nanalysis, modeling, visualization and control can produce previously \nunavailable, greatly needed tools for securely and reliably operating the \nmodern electric transmission system under growing uncertainty, such as \ncreated by high penetrations of variable renewable generation connected to \nthe electric grid. \nSynchrophasor measurements can potentially transform the way the electric \ngrid is operated, reducing costs, improving reliability, and reducing the \nnumber and scale of major power outages. Some observers have likened its \nability to improve grid situational awareness as akin to the medical diagnostic\nadvancements in moving from x-rays to MRIs. \nThe value of synchrophasor measurement applications to California electric \ncustomers is largely proportional to the degree they are deployed throughout\n57\nCalifornia and the Western Electricity Coordinating Council (WECC), because \nof the heavy reliance California places on having access to power imported \nfrom states throughout the West. Transmission owners and operators, who \nhave the means to purchase, install and operate phasor-based applications, \nwill usually deploy new technologies only if a business case can be made. \nWhile policy can have a strong influence on the degree and timing of \ndeployment, policy makers need to know the high-value public benefits, and \neconomic and financial barriers to commercial deployment. While the \npotential applications of synchrophasor measurements were recognized by \nmany, some industry professionals and policymakers remained uninformed or\nunconvinced of the financial soundness of the investment. This business case\nstudy provided sound rationales for the investment needed to obtain the \nbenefits of these tools. \nThis \u201cbusiness case\u201d study evaluated the potential benefits, costs and \nunderstanding of who benefits and who bears the cost of expanded \ndeployment of synchrophasor-based technologies and what are the best \nresearch and development opportunities to advance the most promising \napplications of this technology for the benefit of electricity consumers and \nthe electric industry. It provided organized consolidated information for use \nby the electric industry players, policy makers and researcher planners. This \nstudy was conducted to identify economic and financial barriers to \ncommercial deployment, and technology development gaps. Especially \nimportant in this case, it also sought to obtain information to help develop \ntechnology transfer strategies and educate potential users for increased \nadoption of these technologies. \nThis \u201cbusiness case\u201d analysis and R&D roadmap were developed through a \nconsensus process by the Principal Investigator in cooperation with major \nCalifornia utilities, the California Independent System Operator, and other \nelectric power stakeholders.. The project identified applications, benefits, \nbusiness rationales, and development and deployment barriers. It also \ncreated a roadmap for technology development and deployment. Results \nwere obtained through collaboration with stakeholders, from interviews, \ngroup meetings, literature, and high-level analysis. An industry workshop was\nheld to assist in publicizing the project results. \nThis study found that synchrophasor measurements would enable \nimprovements in planning, operating, and maintaining the electrical grid that \nwould otherwise not be possible. It identified a large number of existing and \npotential applications (either already deployed or under development) of \nsynchrophasor measurement technology. Additionally, the study \ndemonstrated that significant financial benefits may potentially be realized in\nusing PMUs in market operations, such as more accurate locational marginal \npricing\u2010based clearing price calculations and improved congestion \nmanagement through accurate detection of transfer capabilities. Some new \napplications also were identified, such as real\u2010time system model adjustment \nfor fault location calculations and monitoring phase unbalance with state \nestimation applications. \n58\nThe study also concluded that as this technology is deployed and applied and\nas users gain experience and comfort, new applications will continue to be \nidentified. Although there are a huge number of potential applications, this \nstudy identified two key areas that would benefit from applying \nsynchrophasor measurement technology. \nThe first is analyzing and avoiding power outages that lead to catastrophic \nblackouts. PMU technology is a paradigm shift that enables the higher levels \nof reliability improvement required for outage and blackout prevention. \nSynchrophasor measurement applications can improve early warning \nsystems to detect conditions that lead to catastrophic events, help with \nrestoration, and improve the quality of data for event analysis. \nThe second application is improving market and system operations. \nSynchrophasor measurement applications help facilitate congestion \nmitigation through better system margin management. They also allow real \ntime knowledge of actual system conditions as opposed to conditions defined\nby system models that may not reflect current conditions. In addition, state \nestimation solutions can be improved significantly for use in locational \nmarginal pricing calculations, thereby improving the overall accuracy of the \ncalculations and the associated energy clearing charges. \nIn addition to this general analysis, very detailed analysis of key individual \napplications demonstrated that many applications have a major improvement\nimpact with PMUs or cannot be implemented without PMUs. These \napplications include angle/frequency monitoring and visualization and post-\nmortem analysis (including compliance monitoring). \nThe results of this study can serve as a base to develop a near-, mid-, and \nlong-term development and deployment roadmap. This roadmap and the \nprocess to transition PMU technology to full commercial application in \nCalifornia and the WECC were key outcomes of this study that should help \nCalifornia, the WECC and the overall industry benefit from PMU technology. \nThis study concluded that synchrophasor measurement applications offer \nlarge reliability and financial benefits for customers, society, and the \nCalifornia and WECC electrical grid if implemented across the interconnected \ngrid. Therefore, it provides motivation for regulators to support deploying this\ntechnology and its applications. \nThe study report has raised industry awareness of the needs and benefits of \nusing the PMU technology to improve grid reliability and support various grid \napplications.  This report communicated both to industry executives and \ntechnical leaders that PMU data are the foundation on which various wide-\narea monitoring, protection and control applications, including wide-area \nsituational awareness, could be built.  Presently, those applications enable \nearly warning of conditions that could lead to catastrophic events, facilitate \nsystem restoration, enable accurate component and system models, improve\nevent analysis, and more.  \n59\nDOE used results of this report to identify and justify needs for Smart Grid \ninvestment in Transmission. A majority of funding for transmission was \nrelated to the synchrophasor technology for the DOE Smart Grid Investment \nGrant (SGIG) DE-FOA-0000036 in 2009, and sections from the report were \nused in this FOA. Investments co-funded by DOE plus other private entities \n(such as SCE and SDG&E) have resulted in deployment of approximately \n1,700 PMUs by 2013. SCE has used the results of the report to justify \ninvestment in PMUs for their rate case. The rate case was approved and SCE \nhas invested significant effort to deploy synchrophasor technology. The North\nAmerican Synchrophasor Initiative (NASPI), initially funded by DOE and later \non by NERC, has used the PIER synchrophasor roadmap as a base for their \nroadmap.\nIt is believed that vendors have used the report results and the roadmap to \nguide their deployment. Utilities and RTOs have used the report results and \nthe roadmap to guide their plans. Researchers in academia have used the \nresults as guidelines for research initiatives. Activities initiated by this report \nhave influenced international research and deployment of synchrophasors. \nConcrete examples among a number of countries around the world are Brazil,\nColumbia, India, and others.\nThis study was a collaborative effort of power system technical and business \nprofessionals, leading researchers, and academics. Success of this project \nwas based on continued guidance and contributions by direct participants \nsuch as Bonneville Power Administration (BPA), Pacific Gas and Electric \n(PG&E), Sempra Utilities (SDG&E), and Southern California Edison (SCE), and \nby contributing participants such as U.S. DOE, CAISO, TVA, Energy, NERC, \nand the WECC Remedial Action Scheme Reliability Subcommittee. There were\nother contributors and reviewers such as PNNL, Virginia Tech, Georgia Tech, \nand AEP. The project was reviewed by the Eastern Interconnection Phasor \nProject leadership and comments were incorporated in its report.\nPublications:\n\uf0b7 D. Novosel, V. Madani, B. Bhargava, K. Vu, and J. Cole, \u201cDawn of the Grid\nSynchronization,\u201d IEEE Power and Energy Magazine, Vol. 6, pp. 49-60, \nJanuary/February 2008. \n\uf0b7 A. Phadke, D. Novosel and V. Madani, \u201cThe Wide World of Wide-Area \nMeasurements: WAMS Initiatives in North America,\u201d IEEE Power and \nEnergy Magazine, September/October 2008.\n\uf0b7 Yi Hu, R. Moraes, V. Madani, and D. Novosel, \u201cRequirements of Large-\nScale Wide Area Monitoring, Protection and Control Systems,\u201d 10th \nAnnual Fault and Disturbance Analysis Conference, Georgia Tech, April \n2007.\n\uf0b7 D. Novosel, K. Vu, S. Skok, and M. Begovic, \u201cBenefits of Synchronized-\nMeasurement Technology for Power-Grid Applications,\u201d HICSS 39, 39th \nInternational Conference on System Sciences, Hawaii, January 2007. \n\uf0b7 M. Parashar, D. Novosel, et. al. \u201cWide Area Monitoring and Situational \nAwareness,\u201d chapter 15, contribution to Power System Stability by L. \nGrigsby, CRC Press, Third Edition, 2012\n60\n\uf0b7 Damir Novosel, et al, \"Business Case Study: Results and \nRecommendations,\" a PowerPoint presentation at a California Energy \nCommission workshop held to present the project and its results in \nNovember, 2006.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nPMU_Business_Case_Final_Presentation.pdf]\n\uf0b7 Results also were presented at large number of US and international \nindustry conferences and meetings including IEEE, CIGRE, NASPI, WECC, \nCERTS, i-PCGRID, etc.\nSources:\n\uf0b7 Novosel, Damir, Bill Snyder, Khoi Vu, (KEMA Inc.) and Jim Cole (University\nof California, California Institute for Energy and Environment). 2013. \u201cA \nBusiness Case Study on Applying Synchrophasor Measurement \nTechnology and Applications in the California and the Western Electricity\nCoordinating Council Grid.\u201d California Energy Commission, CEC-500-\n2013-045. [http://www.energy.ca.gov/2013publications/CEC-500-2013-\n045/CEC-500-2013-045.pdf]\n\uf0b7 \u201cPublic Interest Technology Assessment of Phasor-Based, Real-Time \nDynamic Information Systems,\u201d Project Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nPMTA_FactSheet.pdf]\n\uf0b7 Personal Communications, Novosel, Damir, Principal Investigator and \nPrimary Author, with KEMA, Inc, at the time, now president of Quanta \nTechnology, Raleigh, NC.\n3.8.2 Real-Time Applications of Phasors for Monitoring, Alarming and\nControl\nThis project was performed by the Lawrence Berkeley National Laboratory, \nand Electric Power Group. The Principal Investigator was Joe Eto.\nThe efforts funded for this project represent one phase of a multi-project \nresearch, development, and demonstration (RD&D) activity that was being \ncoordinated by the Consortium for Electric Reliability Technology Solutions \n(CERTS) for the Energy Commission\u2019s TRP.\nThe overall goal of the synchrophasor applications project was to accelerate \nadoption and foster greater use of new, more accurate, time-synchronized \nphasor measurements by conducting research and prototyping applications \non the CAISO\u2019s synchrophasor platform that provided previously unavailable \ninformation on the dynamic stability of the grid. This platform is called the \nReal-Time Dynamics Monitoring System (RTDMS). Feasibility assessment \nstudies were conducted on potential applications of this technology for small-\nsignal stability monitoring, validating/improving existing stability nomograms \n(a graphical representation of two or more variables used to define critical  \nconditions based on simulations to aid in power system operations), \nconducting frequency response analysis, and obtaining real-time sensitivity \ninformation on key metrics to assess grid stress. Based on study findings, \n61\nprototype applications for real-time visualization and alarming, small-signal \nstability monitoring, measurement-based sensitivity analysis and frequency \nresponse assessment were developed, factory- and field-tested at the CAISO \nand at BPA. \nThe key result of this project was the development of the RTDMS. The CERTS \nteam conducted feasibility assessment studies utilizing synchrophasor \nmeasurements to validate and improve existing stability nomograms, \nevaluated small-signal stability monitoring algorithms, conducted frequency-\nresponse analyses, and obtained real-time sensitivity information on grid-\nstress directly from synchrophasor measurements. These rigorous RD&D \nstudies enabled the project team to successfully develop prototype \napplications offering a rich set of features for wide-area monitoring and \nanalytics, which were factory- and field-tested at the CAISO and at BPA. In \naddition, two new dedicated displays for measurement-based angle \nsensitivity and voltage sensitivity were developed as key indicators of grid-\nstress and proximity to instability. \nThe success of this research led the CAISO to adopt time-synchronized \nphasor measurements for real-time applications in the WECC. CAISO also \nmade significant investments in the underlying hardware and supporting \nmaintenance practices to host the prototypes and enable needed future \nresearch to develop functional specifications to facilitate acquisition of \ncommercially-supported, production-quality tools.\nThe project team designed RTDMS to do wide-area monitoring and analytics. \nWide-area monitoring allowed operators to evaluate stability margins across \ncritical transmission paths, detect potential grid instabilities in real time, and \nmitigate these problems through the system\u2019s manual or automatic controls. \nThe system may also be used to improve state estimations and to determine \nthe optimal location for additional phasor measurements. \nThe project team recommended continuing RD&D for prototype applications \ntowards development of functional specifications that California ISO can use \nto acquire production-quality tools from commercial vendors. The project \nteam also recommended continuing efforts through the Western Electricity \nCoordinating Council (WECC) to expand and link phasor measurement units \nacross the entire Western Interconnection.\nThe funding for this research came from three sources: U.S. DOE, \nCEC/PIER/CIEE and the Electric Power Group (EPG) in Pasadena, CA. EPG is \ncontinued to invest in RTDMS after the CEC/PIER/CIEE and DOE funding was \nstopped.\nSince this research was done, the RTDMS and applications have been \ndeployed at, in addition to CAISO, other major ISOs including PJM, New York \n(NY) ISO, the Electric Reliability Council of Texas (ERCOT) and many utilities \nincluding Duke, Dominion, Lower Colorado River Authority (LCRA), Salt River \nProject (SRP), ONCOR Electric Delivery Company, SCE, Los Angeles \nDepartment of Water and Power (LADWP), HydroOne, Southern Company, \nand others. \n62\nRTDMS has been deployed at different Universities such as UCLA Smart Grid \nEnergy Research Center (SMERC), University of Illinois, Clemson, and Texas \nTech University (TTU). It has been integrated with Intel technology for cyber \nsecurity protection of critical infrastructures and demonstrated as integrated \nsoftware (RTDMS with Security Fabric) at TTU. RTDMS being used as part of a \nDOE-funded cost-share project with EPG, SCE and ERCOT to develop Phasor \nSimulator for Operator Training (PSOT). Three patents have come from the \nwork:  US 7,233,843 B2, dated June 19, 2007, US 8,060,259 B2, dated \nNovember 15, 2011, and US 8,401,710 B2 dated March 19, 2013. SCE has \nutilized RTDMS in their RTDS Lab in Westminster, CA. \nHere are some examples of cases where the RTDMS has been used: \n\uf0b7 Detection and corrective action for Pacific DC Intertie Integration with \nEMS/SCADA systems. \n\uf0b7 Detection and mitigation of oscillations from wind power plants\u2019 faulty \ncontroller settings.\n\uf0b7 Simulation and replay of system events for use in training. \n\uf0b7 Wide area situational awareness monitoring by ISOs covering large \nregions. \n\uf0b7 Monitoring of dynamic metrics \u2013 phase angles, oscillations, damping, \nvoltage and angle sensitivities, frequency instability. \n\uf0b7 Automated event analyzer displays for diagnostics of events in real time \nto guide operator actions. \nNumerous presentations and papers presented in different industry forums \nsuch as WECC Joint Synchronized Information Subcommittee (JSIS), NASPI, \nand IEEE.\nSources:\n\uf0b7 Eto, Joseph H., Manu Parashar, Nancy Jo Lewis. Consortium for Electric \nReliability Technology Solutions (CERTS). 2009. Synchrophasor \nApplications for Grid Dynamic Models and the Monitoring of System \nParameters. California Energy Commission, PIER Transmission Research \nProgram. CEC-500-2013-125. \n[http://www.energy.ca.gov/2013publications/CEC-500-2013-125/CEC-\n500-2013-125.pdf]\n\uf0b7 Personal Communications, Budhraja, Vikram, President of Electric Power \nGroup, Pasadena, CA.\n3.8.3 Real-Time Oscillation Detection, Analysis and Mitigation\nThese two projects were performed by the Pacific Northwest National \nLaboratory (PNNL). The Principal Investigators were Dr. Ning Zhou and \nZhenyu (Henry) Huang. \nElectromechanical oscillations occur frequently on power grid systems, \ntypically when the system is perturbed in some fashion or is otherwise \nstressed. While they often die out on their own, i.e., are properly damped, the\noscillations can grow out of control leading to grid reliability issues and \n63\npotentially large-scale blackouts with costs estimated in the billions of dollars.\nOf those incidents, the most notable is the August 10, 1996 western system \nbreakup, a result of undamped system-wide small-signal oscillations, here \nafter called \u201coscillations.\u201d During the outage in 1996, about 7.5 million \ncustomers (24 million people) lost their power supply for several minutes to 6\nhours. One of the major areas affected was California. Given the wide-area \nnature of oscillation problems, California sits at one end of the oscillation \nmass and would be an area experiencing the consequences. California is also \nan area that can implement control actions to mitigate oscillation problems. \nThe challenge is how to determine when to take control actions, what control \nactions to take, and what effects to expect after the actions are taken.  \nIn power systems, an oscillation is the result of poor electromechanical \ndamping. Considerable understanding and literature have been developed on\nthe small-signal stability problem over the past 50+ years. These studies \nmainly utilized component-based models and eigenvalue analysis of their \ncharacteristic matrix. However, its practical feasibility is greatly limited \nbecause power system models are often inadequate in describing real-time \noperating conditions. Because of this threat of outages, and the few options \ngrid operators have had to detect and respond to these dynamic instabilities, \ntransmission planners have limited the power that can be transmitted over \nsome major interconnections to substantially less than they could otherwise \nhandle. This practice provides a dynamic stability margin of safety but at a \ncost of infrastructure asset capacity to deliver power, e.g., 1000s of \nmegawatts, which limits the ability of the California and the Western \nInterconnection to economically exchange power and can lead to electricity \nshortages. \nTherefore, significant efforts have been devoted in the past few decades to \nmonitoring system oscillatory behaviors from real-time measurements. The \nrelatively recent development and deployment of phasor measurement units \n(PMU) have provided the capability to obtain in real-time over the entire \ninterconnection high-precision time-synchronized data needed for estimating \noscillation modes. A mode is the characterization of an oscillation in terms of \nits (modal) frequency and shape used to communicate the nature of an \noscillation to grid operators and engineers.\nThe methods and tools developed in these two projects provide grid planners \nand operators the capability to detect and mitigate power grid oscillations, \nand they are expected to improve reliability and avoid significant economic \nlosses, especially under high penetrations of variable renewable generation. \nThis research laid the foundation for achieving the goal of not only the rapid \ndetection and analysis of oscillations but also their control through proscribed\ngrid operations to change inter-area oscillation modes and achieve a new grid\noperating state so as to mitigate threats. \nThe overall goal of the first research project was a tool to improve real-time \nsituational awareness of oscillation problems in the Western Interconnection. \nTo achieve this goal the project specifically had to develop an intelligent \nalgorithm for oscillation detection and analysis, evaluate its performance and \n64\nusefulness using field measurement data, build a prototype graphical user \ninterface (GUI), and then develop a real-time prototype tool for monitoring \nand analyzing power grid oscillations. \nThe development of this tool took advantage of past work on measurement-\nbased modal analysis, also known as a ModeMeter, which uses real-time \nsynchrophasor measurements to estimate system oscillation modes and their\ndamping. Low damping indicates potential system stability issues, which \nshould lead to the issuance of oscillation alarms when the power system is \nlightly damped. A good oscillation alarm tool can provide time for operators \nto take remedial reaction and reduce the probability of a system breakup due\nto a light damping condition. To facilitate ModeMeter development and \nevaluation, the WECC had conducted a number of system tests in the decade \nbefore this research project was initiated. Real-time oscillation monitoring \nrequires ModeMeter algorithms to have the capability to work with various \nkinds of measurements: oscillation data (ringdown signals), noise probing \ndata, and ambient data. \nSeveral measurement-based modal analysis algorithms had already been \ndeveloped. Each is effective for certain situations, but not as effective for \nsome other situations. For example, the traditional \u201cProny\u201d algorithm analysis\nworks well for oscillation data, but not for ambient data. However, the \u201cYule-\nWalker\u201d algorithm was designed for ambient data only. Even in an algorithm \nthat works for both oscillation data and ambient data, such as \u201cR3LS,\u201d \nlatency results from the relatively long time window used in the algorithm is \nan issue in timely estimation of oscillation modes. Because power system \nsituations change over time, and oscillations can occur at any time, this \nresearch project developed an intelligent ModeMeter tool that could rapidly \nand adaptively select from these different algorithms and adjust parameters \nfor various situations. \nTesting and validation for accuracy and speed, based on both simulation data\nand field measurement data from various system events on the WECC power \ngrid, were done on the new ModeMeter tool. A real-time prototype tool for \nmonitoring and analyzing power grid oscillations was developed around this \nnew smart ModeMeter, integrated with a GUI. Finally the prototype tool was \ntested with real-time streaming synchrophasor measurement data. \nThe resultant prototype tool can automatically detect and analyze power grid \noscillations in near real time using ringdown data from synchrophasor \nmeasurement units (PMUs), i.e., early oscillatory signals resulting within \nseconds after large sudden disturbances on the grid, such as a power line or \na power generator dropping out of service. By effectively identifying \nringdown data, the algorithm can identify the oscillation modes thereby \nproviding the necessary information to operators accurately within a short \ntime window. This oscillation tool development was a major breakthrough in \nthe sense that it significantly lowers false and missing alarms, as well as \nshortens detection time by applying oscillation detection and analysis \nalgorithms properly.\n65\nRecall that the California power grid is in an area that can implement control \nactions to mitigate oscillation problems. The challenge is how to determine \nwhen to take control actions, what control actions to take, and what effects to\nexpect after the actions are taken. The overall goal of the second research \nproject was to advance modal analysis beyond detection (see the first project\nabove) to action, by developing a method and establishing a modal analysis \nfor grid operation (MANGO) procedure to provide recommended actions (such\nas generation re-dispatch), and aid grid operation decision making for \nmitigating inter-area oscillations. \nThe challenge of managing oscillations is growing. For example, variable \nrenewable energy generation reduces system inertia and adds more \nuncertainty; energy efficient loads with lower electrical resistance introduce \nnew dynamics, as well as uncertainty. These all change system oscillation \nbehaviors and make it more difficult to manage oscillations through \ntraditional modulation control tuned with a system model. MANGO control \ndoes not rely on an acknowledged system model, which is becoming less \neffective as the grid evolves in the 21st century, but uses real-time \nsynchrophasor and other synchronized measurements of the electric grid. \nWhen an oscillation with low damping is detected using the tool developed in \nthe first project described above, MANGO can be used by a grid operator, or \nautomated operation schemes, to potentially utilize generator re-dispatch or \nresponsive loads (demand response) to adjust system power flow patterns so \nas to increase system oscillatory damping to a benign level. MANGO can also \nutilize some other smart grid technologies, such as storage, distributed \ngeneration or electric vehicle charging, for power flow pattern adjustment. \nTherefore, MANGO can improve grid reliability and efficiency, and also help to\nfacilitate the deployment of renewable energy, demand response, and energy\nstorage, which has both economic and environmental implications. \nThe fundamental part of this work explored the relationship between low \ndamping and grid operating conditions, and then used the relationship to \ndevelop recommended actions for grid operations for increasing damping, \ntherefore reducing the chance of system breakup and power outages. \nDifferent from traditional power system stabilizers and other modulation \ncontrol mechanisms, MANGO increase damping through operating point \nadjustments. Traditionally, the modulation-based methods do not change the \nsystem\u2019s operating point, but improve damping through automatic feedback \ncontrol, leaving the system a vulnerable as before. The significance of the \nuse of synchrophasor measurements to achieve this distinction perhaps can \nbe seen in how the MANGO procedure works.\nThe MANGO procedure consists of three major steps: \n\uf0b7 Recognition \u2013 operator recognizes the need for operating point \nadjustment through online ModeMeter monitoring (see the first project \ndiscussion); \n\uf0b7 Implementation \u2013 operator implements the adjustment per \nrecommendations by the MANGO procedure; and \n66\n\uf0b7 Evaluation \u2013 operator evaluates the effectiveness of the adjustment \nusing ModeMeter and repeats the procedure if necessary.\nThe recognition and evaluation steps in the MANGO procedure rely on a good \nModeMeter to estimate the current modes, while the implementation step \nbuilds on modal sensitivity, i.e., the relationship of oscillation modes and the \ngrid operating parameters. The relationship is generally nonlinear, and it is \nimpractical to derive a closed-form analytical solution for this relationship. \nTheoretically, the sensitivity can be calculated from the model of a power \nsystem, but the model is usually not able to reflect real-time operating \nconditions. Therefore, this research project primarily focused on estimating \nmodal sensitivity from real-time measurements. Furthermore, a new concept \nof relative sensitivity was proposed for this procedure. Testing with power \nplants in the WECC indicated strong correlation of power flow patterns to the \ndamping, giving clear guidance on how to adjust generator outputs to \nimprove damping.\nIn summary, a MANGO procedure was established with practical \nconsiderations. The key step in the procedure is the modal sensitivity. A \nmethod for estimating relative modal sensitivity was formulated and studied \nwith promising results from a medium-size system and the full WECC system,\nand the impact of topology change on damping was studied. The simulation \nstudies were conducted with commercialized software, and the resulting \nexperience and data paved the road for large-scale MANGO application. \nPlease note that, due to limited synchrophasor measurement availability at \nthe time of this research project, all the tests were performed with simulated \ndata. To fully demonstrate the benefit of the developed MANGO method, \nfurther testing needs to be done with actual synchrophasor measurements \nonce the installation underway of an additional 250+ PMUs in the WECC is \ncompleted. Other future work includes evaluation of the impact of mode \nmeter accuracy on modal sensitivity estimation, and further enhancement of \nthe understanding of the topology impact on oscillation mitigation measures. \nAs MANGO aims at an operator-oriented measure, it is important to identify \nimplementation strategies with operating procedures. Only when the MANGO \nmeasure is included in operating procedures can the benefit be actually \nrealized in improving power grid reliability.\nThis PIER research was supplemented and continued by more than $500,000 \nof funding from the U.S. DOE Office of Electricity and Energy Reliability \nthrough the administration of the CERTS program. \nThe technology developed has been well recognized by the electric grid \ncommunity as state-of-the-art and the basis for follow-on research as listed in\nthe references below. Part of the work was included in an IEEE special \npublication, which was supported by a special IEEE Task Force: (See \nPublication #3 below.) Several of the publications listed below were invited \npapers at prestigious international conferences. (See Publications #2, #7, \n#10 below.) And several papers have been well cited by other researchers. \n67\n(See Publications #4, #8, #9, #10 below). Many of the citations were by \nstudents in performing their graduate studies.\nThe intellectual property of this technology has been protected for \ncommercialization through two software copyrights: (1) (MANGO) Model \nAnalysis for Grid Operations version 1.0, and Oscillation Detection version \n1.0. The Bonneville Power Administration has installed the Oscillation \nDetection software for testing, and discussions regarding testing the MANGO \nsoftware tool are ongoing with several power companies.\nPotentially; with these two tools, the transfer capabilities of stability-limited \ntransmission lines can be increased, which in turn would increase asset \nutilization and free up transmission capacity for the California electric grid, as\ndiscussed above in this paper.\nPublications:\n\uf0b7 Luke Dosiek, Ning Zhou, John W. Pierre, Zhenyu Huang, and Daniel J. \nTrudnowski. \u201cMode Shape Estimation Algorithms Under Ambient \nConditions: A Comparative Review\u201d, IEEE Transactions on Power \nSystems, Volume: 28, Issue: 2, Page(s): 779 \u2013 787, May 2013. \n\uf0b7 M. Crow, J. Sanchez-Gasca, J. Chow, J. Hauer, Z. Huang, J. Pierre, D. \nTrudnowski, L. Vanfretti, N. Zhou, \u201cLinear Ringdown Analysis Methods\u201d, \nIEEE Power & Energy Society, Power System Dynamic Performance \nCommittee, Power System Stability Subcommittee, Task Force on \nIdentification of Electromechanical Modes. In: Proceedings of the 2013 \nIEEE Power and Energy Society General Meeting, Vancouver, BC, \nCanada, July 21 \u2013 25, 2013. (invited paper)\n\uf0b7 M. Crow, J. Sanchez-Gasca, J. Chow, J. Hauer, Z. Huang, J. Pierre, D. \nTrudnowski, L. Vanfretti, N. Zhou, \u201cIdentification of Electromechanical \nModes in Power Systems: Linear Ringdown Analysis Methods\u201d, IEEE \nSpecial Publication TP462. IEEE Power & Energy Society, Power System \nDynamic Performance Committee, Power System Stability \nSubcommittee, Task Force on Identification of Electromechanical Modes,\nJune 2012.  \n\uf0b7 N Zhou, JW Pierre, and D Trudnowski, \u201cA stepwise regression method for \nestimating dominant electromechanical modes\u201d, Power Systems, IEEE \nTransactions on 27 (2), 1051-1059, 2012. (cited 16 times)\n\uf0b7 Ning Zhou, Zhenyu Huang, Francis Tuffner, and Daniel Trudnowski, \u201cA \nModified Stepwise Linear Regression Method for Estimating Modal \nSensitivity\u201d, in: Proceedings of the 2011 IEEE Power and Energy Society \nGeneral Meeting, Detroit, Michigan, USA, July 24-29, 2011.\n\uf0b7 Ruisheng Diao, Zhenyu Huang, Ning Zhou, Yousu Chen, Francis Tuffner, \nJason Fuller, Shuangshuang Jin, Jeff Dagle, \u201cDeriving Optimal Operational\nRules for Mitigating Inter-area Oscillations\u201d, in: proceedings of the 2011 \nIEEE Power and Energy Society Power System Conference and Exposition\n(PSCE), Phoenix, AZ, USA, March 20-23, 2011.\n\uf0b7 Zhenyu Huang, Ning Zhou, Frank Tuffner, and Dan Trudnowski, \u201cUse of \nModal Sensitivity to Operating Conditions for Damping Control in Power \nSystems\u201d, in: Proceedings of the 44th Hawaii International Conference \n68\non System Sciences (HICSS), Kauai, Hawaii, January 4-7, 2011. (invited \npaper)\n\uf0b7 Zhenyu Huang, Ning Zhou, Francis Tuffner, Yousu Chen, Daniel \nTrudnowski, William Mittelstadt, John Hauer, and Jeffery Dagle, \n\u201cImproving Small Signal Stability through Operating Point Adjustment\u201d, \nin: Proceedings of the IEEE Power and Energy Society General Meeting \n2010, Minneapolis, MN, July 25-29, 2010. (cited 25 times)\n\uf0b7 Ning Zhou, Zhenyu Huang, Francis Tuffner, John Pierre, and \nShuangshuang Jin, \u201cAutomatic Implementation of Prony Analysis for \nElectromechanical Mode Identification from Phasor Measurements\u201d, in: \nProceedings of the IEEE Power and Energy Society General Meeting \n2010, Minneapolis, MN, July 25-29, 2010. (cited 18 times)\n\uf0b7 Ning Zhou, Zhenyu Huang, Luke Dosiek, Dan Trudnowski, and John W. \nPierre, \u201cElectromechanical Mode Shape Estimation Based on Transfer \nFunction Identification Using PMU Measurements\u201d, in: Proceedings of \nPES-GM2009 \u2013 the IEEE Power and Energy Society General Meeting \n2009, Calgary, Canada, July 26-30, 2009. (invited paper) (cited 19 times)\n\uf0b7 Z Huang, N Zhou, FK Tuffner, R Diao, DJ Trudnowski, Y Chen, JF Fuller, S \nJin, JF Hauer, and JE Dagle, \u201cModal Analysis for Grid Operation (MANGO): \nUse of Modal Sensitivity for Damping Improvement through Generation \nAdjustment\u201d, Prepared for the US Department of Energy, Pacific \nNorthwest National Laboratory, Richland, WA, October 2011.\n\uf0b7 Zhenyu Huang, Ning Zhou, Frank Tuffner, Yousu Chen, John Hauer, \nDaniel Trudnowski, Jason Fuller, Ruisheng Diao, and Jeffery Dagle, \n\u201cModal Analysis for Grid Operation (MANGO): Feasibility, Solution \nMethods, and Application to the WECC System\u201d, Prepared for the \nCalifornia Institute for Energy and Environment and the California Energy\nCommission, Pacific Northwest National Laboratory, Richland, WA, \nDecember 2010.\n\uf0b7 Z Huang, N Zhou, F Tuffner, Y Chen, D Trudnowski, R Diao, J Fuller, W \nMittelstadt, J Hauer, J Dagle, \u201cMANGO \u2013 Modal Analysis for Grid \nOperation\u201d, prepared for US Department of Energy Office of Electricity \nDelivery and Energy Reliability, September 2010. \n\uf0b7 Ning Zhou, Zhenyu Huang, Francis Tuffner, Shuanshaung Jin, Jenglung \nLin, and Matthew Hauer, \u201cOscillation Detection and Analysis: Final \nReport\u201d, Prepared for the California Institute for Energy and Environment\nand the California Energy Commission, Pacific Northwest National \nLaboratory, Richland, WA, August 2010.\n\uf0b7 Ning Zhou, Zhenyu Huang, Frank Tuffner, Yousu Chen, John Hauer, \nDaniel Trudnowski, Jason Fuller, Ruisheng Diao, and Jeffery Dagle, \n\u201cModal Analysis for Grid Operations (Mango): Model and Methodology\u201d, \nPrepared for the California Institute for Energy and Environment and the \nCalifornia Energy Commission, Pacific Northwest National Laboratory, \nRichland, WA, March 2010.\n\uf0b7 Ning Zhou, Zhenyu Huang, Frank Tuffner, Shuangshuang Jin, Jenglung \nLin, Matthew Hauer, \u201cAlgorithm Summary and Evaluation: Automatic \nImplementation of Ringdown Analysis for Electromechanical Mode \nIdentification from Phasor Measurements\u201d, Prepared for the California \nInstitute for Energy and Environment and the California Energy \n69\nCommission, Pacific Northwest National Laboratory, Richland, WA, \nFebruary 2010.\n\uf0b7 Ning Zhou, Zhenyu Huang, Frank Tuffner, and Shuangshuang Jin, \n\u201cOscillation Detection Algorithm Development Summary Report and Test\nPlan\u201d, Prepared for the California Institute for Energy and Environment \nand the California Energy Commission, Pacific Northwest National \nLaboratory, Richland, WA, October 2009.\n\uf0b7 Zhenyu Huang, N Zhou, FK Tuffner, Y Chen, D Trudnowski, JE Dagle, and \nJF Hauer, \u201cMANGO Framework and Its Applicability for the Western \nInterconnection\u201d, PNNL-18680, Prepared for U.S. Department of Energy \nOffice of Electricity Delivery and Energy Reliability, the California \nInstitute for Energy and Environment and the California Energy \nCommission under Contract DE-AC05-76RL01830 Related Services, \nPacific Northwest National Laboratory, Richland, WA, August 2009. \n\uf0b7 Ning Zhou, and Zhenyu Huang, \u201cDevelopment of Core ModeMeter \nFunctions for Demonstration\u201d, Technical Report for Beijing Sifang \nAutomation Co., Ltd., Pacific Northwest National Laboratory, Richland, \nWA, April 2009. \n\uf0b7 Frank Tuffner, Zhenyu Huang, Ning Zhou, and Ross Guttromson, \u201cInitial \nStudies on Operator Actionable Control for Improving Small Signal \nStability in Interconnected Power Systems\u201d, PNWD-4069, Technical \nReport for Areva T&D, Pacific Northwest National Laboratory, Richland, \nWA, April 2009.\nSources:\n\uf0b7 Zhou, Ning, Zhenyu Huang, Francis Tuffner, Shuanshaung Jin, Jenglung \nLin, Matthew Hauer, Pacific Northwest National Laboratory, August, \n2010, Oscillation Detection and Analysis, PIER Transmission Research \nProgram. [http://uc-ciee.org/images/downloadable_content/electric_grid/\nOsc_Det_Pubs.pdf]\n\uf0b7 \u201cOscillation Detection and Analysis,\u201d Research Project Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nODA_Final_Report.pdf]\n\uf0b7 Zhenyu, Huang, Ning Zhou, Francis Tuffner, Yousu Chen, John Hauer, \nDaniel Trudnowski, Jason Fuller, Ruisheng Diao, Shuangshuang Jin, \nWilliam Mittelstadt, and Jeffery Dagle. (Pacific Northwest National \nLaboratory). 2010. Modal Analysis for Grid Operation (MANGO): \nFeasibility, Solution Methods, and Application to the WECC System, \nPNNL-20094.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nMANGO_Final_Report_CIEE-1.pdf]\n\uf0b7 \u201cApplication of Modal Analysis for Grid Operation (MANGO) on the \nWestern Interconnection,\u201d Research Project Fact Sheet.\n[http://uc-ciee.org/images/downloadable_content/electric_grid/\nMANGO_FactSheet.pdf]\n\uf0b7 Brown, Merwin; Miller, Larry; Cibulka, Lloyd; Von Meier, Alexandra; \nHwang, Lorraine; California Institute for Energy and Environment, 2012. \nTransmission Grid Research, California Energy Commission. Publication \nnumber: CEC-500-2013-098.\n70\n[http://www.energy.ca.gov/2013publications/CEC-500-2013-098/CEC-\n500-2013-098.pdf]\n\uf0b7 Personal Communications, Henry Huang, Pacific Northwest National \nLaboratory, Richland, WA, and Ning Zhou, SUNY-Binghamton, \nBinghamton, NY.\n3.9Advanced Protection Systems Using Wide Area Measurement\n3.9.1 Scoping Study of Intelligent Grid Protection Systems\nThis project was performed by Stuart Consulting. The Principal Investigator \nwas Bob Stuart.\nThis study explored the state of the art of synchrophasor (phasor \nmeasurement unit, or PMU) technology and of remedial action schemes (RAS)\nand special protection schemes (SPS), and the transmission constraints of \nimporting power into California. It recommended appropriate projects to \nfurther explore the applications of synchrophasor technology in electric grid \nprotection systems in California.\nIn virtually all of the major blackouts dating back to the first big New York \nblackout in 1965, protective relays have played a major role in either \ncontributing to the cause of the blackout or failing to mitigate the speed of \nthe blackout. Unusual circumstances in terms of weather and configuration of\nthe high voltage transmission grid that was not anticipated or studied by \nprotection and operation engineers also contributed to these blackouts. \nTwo major trends over the last fifteen to twenty years have had an impact on\nthe vulnerability of the high voltage transmission grid to withstand major \nblackouts. Utilities have been operating the high voltage transmission grid \ncloser to the margin, meaning a smaller difference between reliable and \nunreliable operation. At the same time, remedial action schemes (RAS) and \nspecial protection schemes (SPS) have become widely used to protect against\nmultiple contingencies. While these schemes provide a safety net to protect \nagainst extreme conditions, they are prescriptive by nature. The protection \nand operation engineers must anticipate these conditions and set the special \nprotection schemes accordingly. This oftentimes means taking overly \ncautious remedial actions, or backing off on system transfer capability, \nleaving transmission capacity underutilized, at increased cost of operation.\nThe purpose of this project was to analyze transmission system protection \nissues, identify state-of-the-art technical protection solutions and their value \nfor an intelligent system, and develop stakeholder-supported \nrecommendations for a technology program. The specific project objectives \nwere to:\n\uf0b7 Evaluate system protection issues, needs and opportunities in \nconsultation with the organizations participating in the TRP Policy \nAdvisory Committee (PAC);\n71\n\uf0b7 Review the state-of-the-art in intelligent system protection technologies \nfor addressing these issues, needs and opportunities with manufacturers\nand suppliers of promising system protection technologies;\n\uf0b7 Review ongoing system protection R&D, field test validation projects and\nindustry standards activities and explore opportunities to collaborate on \nRD&D that is synergistic with California\u2019s system protection issues, \nneeds and opportunities;\n\uf0b7 Develop prioritized recommendations for intelligent system protection \nR&D, field test validation and other related technology transfer activities\nthat offer the potential to yield significant reliability, increased transfer \ncapacity and other benefits for California\u2019s electricity consumers; and\n\uf0b7 Review and obtain feedback on this recommended system protection \nR&D agenda from the TRP PAC, Technical Advisory Committees, \nequipment manufacturers and other industry experts.\nThe findings of the project are as follows:\nUtilities in the Western United States have been installing PMUs since the \nearly to mid 1990s. BPA has accepted the responsibility of being the \nrepository for most if not all of the PMU data at their Ditmer control center in \nVancouver, Washington. The data are primarily used for disturbance analysis,\ngeneration modeling and data modeling. As of the writing of this report, no \noperator actions based on PMU data had been implemented because no \nengineering studies had been done to correlate phase angles to system \nconditions requiring remediation. \nPacific Northwest National Laboratories (PNNL) has been in the forefront of \nresearch to provide real-time displays and operator screens to enhance \nsituational awareness for operators. They have been doing advanced \nresearch into simulating actual real-time operating scenarios at control \ncenters to include the trending of data and an RTDM (real time display \nmonitor).\nThe IEEE (Institute of Electrical and Electronic Engineers) established the first \nsynchrophasor standard, C37.118-2005. It defines measurement convention, \nmeasurement quality and communication protocol; all PMUs must meet these\nrequirements to be compliant. Communication latency, performance under \ndynamic conditions, aliasing and instrument transformer errors are areas that\nneed to be better defined and further researched.\nThere are over 14 manufacturers of PMUs that can be grouped into two \ncategories: manufacturers whose primary product lines are disturbance \nrecorders and monitoring equipment, and who produce stand-alone PMUs; \nand manufacturers whose primary product lines are protective relays, and \nwho produce a combined relay/PMU package. All equipment is high quality, \nbut there are tradeoffs to be considered in choosing one or the other \napproach.\nAlmost all protection and control schemes on the grid today are local in \nnature.  This means that the sensing and tripping take place in one \n72\nsubstation, typically with some schemes utilizing telecommunications \nbetween adjacent substations to coordinate the protection. The particular \nbenefit of applying synchrophasors is because of the intelligence gathered \nover a wide area to detect stressed system conditions, which cannot be done \non a local basis. Some potential applications that hold promise are wide area \nvoltage control, small signal stability control and transient/dynamic stability \ncontrol.\nSpecial protection schemes (SPS) are the primary means of wide area control \ntoday although some are used for local problems as well. However, presently \nSPSs are prescriptive in nature, in that typically load flow and transient \nstability studies must be done assuming worst case conditions to ensure that \nthere is adequate protection during those times. Since worst case conditions \nare by definition rare, this means that most of the time system capacity will \nbe underutilized or remedial actions will be more severe than usually \nnecessary.\nThe next step should be to develop methods to control transient stability that\nare less dependent on off-line studies and use more on-line computation. \nTechniques using pattern recognition, neural networks and expert systems \nhold great potential for developing feasible and effective control actions that \nare proactive in nature rather than reactive: action could be taken ahead of \ntime to prevent outages from occurring in the first place.\nSynchrophasor technology has been used to date primarily as a system \nmonitoring and analysis tool. In post-disturbance analysis it has provided \ninvaluable insight into finding the root causes for major system disturbances \nincluding the August 10, 1996 and August 14, 2003 disturbances. \nCalifornia relies heavily on imported power from both the Northwest and \nSouthwest, and many special protection schemes determine how much \npower can be imported based on voltage and transient stability limits. More \nintelligent special protection schemes that would take action based on actual \nreal time conditions would allow power to be imported nearer the maximum \nlimit.    \nNo American utility has yet implemented a synchrophasor-based application \nin actual practice. NERC has been very supportive of the use of the \ntechnology. It is very important to apply the technology in a real-time \napplication as quickly as possible, to build confidence in the technology and \nto work out implementation issues, such as telecommunications latency and \ndynamic response.\nBoth PG&E and SCE have extensive RAS/SPS applications that impact both \npower imported into California as well as internal generation in California. All \nof these special protection schemes protect against multiple contingencies. \nBoth utilities have installed a significant number of PMUs on their bulk \ntransmission system and have extensive high-speed telecommunications \ninfrastructure, and would therefore be good candidates for a demonstration \nproject. \n73\nA demonstration project employing synchrophasors for protection application \nwould provide the needed experience to advance real-time reliability \nmethods. An excellent candidate would be SCE\u2019s Big Creek project; the \ninstallation of a phasor data concentrator (PDC), a centralized programmable \nlogic controller (PLC) and the software to program the PLC as a special \nprotection scheme would be a feasible and economical demonstration \nproject. It would show how operating Big Creek at higher levels of generation,\nwhile backing down more costly generation, would save Californians a \nsignificant amount in generation costs with a small investment of money and \neffort.\nIn the long term, the knowledge gained from the demonstration project could \nbe transferred to more complicated special protection schemes such as the \nCalifornia \u2013 Oregon RAS scheme. The potential for savings is very large \nassuming that more economic hydroelectric power could be imported into \nCalifornia at least part of the time, and more costly thermal generation in \nCalifornia backed down.\nSources:\n\uf0b7 Stuart, Robert. (Stuart Consulting). 2008. Scoping Study of Intelligent \nGrid Protection Systems. California Energy Commission. Publication \nnumber: CEC-500-2014-052.\n]http://www.energy.ca.gov/2014publications/CEC-500-2014-052/CEC-\n500-2014-052.pdf]\n\uf0b7 IEEE Standard C37.118-2005 (Revision of IEEE Std 1344-1995) \u201cIEEE \nStandards for Synchrophasors for Power Systems,\u201d Institute of \nElectrical and Electronics Engineers, 2005.\n\uf0b7 J. Depablos, V. Centeno, A. Phadke, M.Ingram, \u201cComparative Testing of \nSynchronized Phasor Measurement Units,\u201d February 2004.\n\uf0b7 J. Hauer, N. Bhatt, K. Shah, S. Kolluri, \u201cPerformance of \u2018WAMS East\u2019 in \nProviding Dynamic Information for the Northeast Blackout of August \n14, 2003, Power Engineering Society General Meeting, \n\uf0b7 R. Wilson, C. Taylor, \u201cUsing Dynamic Simulations to Design the Wide-\nArea stability and voltage Control System (WACS),\u201d IEEE PSCE 04\n\uf0b7 C. Taylor, D. Erickson, K. Martin, R Wilson, V. Venkatasubramanian, \n\u201cWACS \u2013 Wide Area Stability and Voltage Control System: R&D and \nOnline Demonstration,\u201d Proceedings of the IEEE, Vol. 93, NO. 5, May \n2005\n\uf0b7 Yang, Qixun; Bi, Tianshu; Wu, Jingtao; \u201cWAMS Implementation in China \nand the Challenges for Bulk Power System Protection,\u201d Power \nEngineering Society General Meeting, 2007. IEEE, 4-28 June 2007 \nPage(s):1 - 6 \n\uf0b7 Xiying Chen; Weixing Li; He Chen; Zhizhong Guo; \u201cResearch of Out-of-\nStep Protection System Based on Wide Area Measurement System,\u201d \n2006 International Conference on Power System Technology \n(PowerCon), October 2006. \n\uf0b7 Martin, K.E.; \u201cPhasor Measurement Systems in the WECC,\u201d IEEE Power \nEngineering Society General Meeting, 18-22 June 2006. \n\uf0b7 Fahid, K A; Gopalakrishnan, Prasanth; Cherian, Sushil; \u201cPhasorNet \u2013 A \nHigh Performance Network Communications Architecture for \n74\nSynchrophasor Data Transfer in Wide Area Monitoring, Protection and \nControl Applications,\u201d Bulk Power System Dynamics and Control - VII. \nRevitalizing Operational Reliability, 2007 iREP symposium 19-24 Aug. \n2007.\n\uf0b7 Dagle, J.E.; \u201cNorth American SynchroPhasor Initiative,\u201d Proceedings of \nthe 41st Annual Hawaii International Conference on System Sciences, \nJanuary 2008. \n\uf0b7 Bonian Shi; Xiaorong Xie; Yingduo Han; \u201cWAMS-based Load Shedding \nfor Systems Suffering Power Deficit,\u201d 2005 IEEE/PES Transmission and \nDistribution Conference and Exhibition: Asia and Pacific, 2005.\n3.9.2 Advanced Protection Systems Using Wide Area Measurements\nThis project was performed by Virginia Polytechnic Institute and State \nUniversity (Virginia Tech). The Principal Investigator was Virgilio Centeno.\nProtection systems can operate in an unanticipated fashion during times of \ntransmission system stress, and such operations are often an important \ncontributing factor in the sequence of events leading to cascading outages. \nConsidering the very large number of relaying systems in existence (by a \nrough estimate over 5 million on the North American Power Grid), it is to be \nexpected that some of these unanticipated operations are due to defective \nrelays. This has been documented as \u201cthe hidden-failure\u201d phenomenon in \nprotection systems. Other contributing factors to catastrophic failures are \nunexpected power system configurations which were not foreseen when \nprotection systems were set, errors in setting and calibration of relays, or \nundiscovered design flaws in the protection systems.\nIn recent years, innovations in the field of power system protection, power \nsystem operation and power system devices have made possible new \nproactive approaches to the supervision of protection systems so that the \nlikelihood of catastrophic failures of the power grid are significantly reduced, \nthe regions of the power system affected by such events are limited, and the \npower system restoration process can be sped up. The project objective was \nto research, develop and evaluate the use of these technologies in the \nCalifornia system to monitor, supervise, and modify the protection systems in\nreal time based upon the information about the state of the power system \nprovided by the phasor measurements. Three particular aspects of protection\nsystem supervision and control were selected for research, because they \naddress the principal concerns regarding protection system responses, and \nare inter-related and complementary in their scope. Such measures are \nwithin the capabilities of technology available today, and when successfully \napplied can reduce the frequency and intensity of power system blackouts.\nThis R&D effort was conducted in close cooperation with PG&E, CAISO and \nSCE, who were key members of the Technical Advisory Group (TAG). The \nstudy system selected was from the California power grid, and the results of \nthe research were intended to provide proofs-of-concept of the proposed \nproject, as well as complete functional specifications for implementing these \nideas on the California system. It is expected that when fully tested by the \n75\nutilities the results of the research can be directly integrated into the Energy \nManagement Systems (EMS) of the California utilities.\nThe project focused on four tasks:  \n[1] Development and validation of a California transmission system model: \nDevelop equivalent models for the electric system outside California, \nand validate the operation of the California-only model with respect to \nthe full WSCC electric system model.\n[2] Development of an algorithm for adaptive adjustment of dependability \nand security. Determine the key locations in the California electric \nsystem where an insecure relaying operation during stressed system \nconditions would be detrimental to the viability of the power system, and\ndevelop a decision tree that uses synchrophasor measurements from \nthe selected locations to determine when the system is in stressed \nconditions, implementing a voting scheme to supervise the relaying \nsystem logic to prevent incorrect operation during these times.\n[3] Development of an alarm for potential load encroachment, using real-\ntime wide area synchrophasor data and the existing protection system \ndata base to determine which of the relay characteristics are in danger \nof being encroached upon during a catastrophic event.  \n[4] Development of a more intelligent out-of-step relaying tool. Determine \nthe coherent generator groups in the California system model and use \nthem to implement a technique that uses wide-area measurements to \nprovide a more appropriate out-of-step decision.\nThe results of the project were:\n\uf0b7 Model Validation: A reduced West Coast power system model was \ndeveloped based on the California model provided and the WECC system\ninformation provided by PG&E. The model consists of 3996 buses, 1124 \ngenerators (647 with dynamic models), 1913 loads, and a single \ngenerator representing the WECC external to California. The validation \nprocess performed at Virginia Tech show that this model reflects the \nbehavior of the full WECC model for the major disturbances considered \nfor this project. The voltage and frequency responses of the reduced \nCalifornia model are consistent with the full WECC California model for \nthe large disturbances, generation drop and line loss, considered for this\nproject. Conclusion: For the major disturbances considered for this \nproject, the derived California model is considered valid.\n\uf0b7 Adaptive Security/Dependability Balance: The optimal location for the \nadaptive protection scheme was derived using a systematic procedure \nto identify and rank critical location in power systems. The critical \nlocation was confirmed, based on practical experience, by the Technical \nAdvisory Group, to be the Midway-Vincent 500 kV transmission path. \nDecision trees were generated for the Heavy Winter and Heavy Summer \nModels with acceptably low misclassification rates. PMU locations and \nthe signals to be monitored were determined from the decision trees to \n76\nbe Los Ba\u00f1os, Devers, El Dorado, and Pittsburg. Performance evaluation \nof the algorithm with new test cases created by simulating circuit \nelement outages was performed to assess the robustness of the trees to \ntopology changes. The misclassification rates for topology changes were \nfound to be acceptably low. A functional analysis of the proposed system\ndetermined that it can be implemented with available commercial PMUs,\ncomputers and data concentrators, provided the communication links \nare available at the selected PMU locations.\n\uf0b7 Alarms for Encroachment of Relay Trip Characteristics: A reduced West \nCoast power system model, consisting of 3996 buses, 1124 generators \n(647 with dynamic models), 1913 loads, and a single generator \nrepresenting the WECC external to California, was developed. The \nvalidation process performed at Virginia Tech showed that this model \nreflects the behavior of the full WECC model for the major disturbances \nconsidered for this task. Critical locations for the proposed \nencroachment alarm system were determined with the help of the TAG, \nwho recommended focusing only on California\u2019s Path 15 and Path 26. \nThe following critical locations were determined at the following \ntransmission lines:\n\u2013 Midway \u2013 Vincent #3 500 kV\n\u2013 Midway \u2013 Vincent #2 500 kV\n\u2013 Midway \u2013 Vincent #1 500 kV\n\u2013 Los Banos \u2013 Midway #2 500 kV\n\u2013 Diablo \u2013 Midway #3 500 kV\n\u2013 Diablo \u2013 Midway #2 500 kV\n\u2013 Vaca-Dixon \u2013 Cottonwood 230 kV\nBased on the analysis of the system model and the selected critical \nlocations, PMU placement for this class was determined at the following \nsubstation locations: Midway 500 kV, Los Banos 500 kV, Diablo 500 kV, \nand Vaca-Dixon 230 kV. Based on an exhaustive contingency analysis, \ncritical relays were determined as those that are most at risk of \nencroachment: distance relays, loss-of-excitation relays and out-of-step \nrelays. A supervisory boundary, which is a concentric circle with a radius\n50% larger than the radius of the relay trip zone, was established as the \npoint at which alarms would be set. Contingency analysis of the Heavy \nWinter and Heavy Summer models revealed that for no combinations of \noutages and three phase faults did either the power swing or the post-\ndisturbance load flow cause encroachment of distance relays on critical \n230kV and 500kV lines in California.\nAlarms for out-of-step relays were based on identifying contingencies \nthat cause significant changes in the location of the swing center and \nthe size and speed of stable swings at the location of the out-of-step \nrelay. An algorithm was developed to determine the contingencies that \nmake out-of-step relays lose their ability to differentiate stable swings \nfrom unstable swings. The advantage of this system is that it will be fully\nautomated in GE-PSLF so that as the model changes or new out-of-step \nrelays are inserted it can be easily re-run. If sufficient phasor \nmeasurement units are available it may be possible to automatically \ndetect the N-1 or N-2 conditions for which an out-of-step relay\u2019s settings \n77\nare incorrect and issue an alarm accordingly. The following \ncountermeasures were identified for the selected relay types:\n\u2013 Shrinking or reshaping of the trip region of distance relays and loss-\nof-excitation relays to prevent load encroachment without impacting\ntheir security. \n\u2013 Power swing blocking for out-of-step relays can prevent false \ntripping when the speed of the apparent impedance trajectory \nindicates that it is not a fault. \n\u2013 Automatic actions depend heavily on the proper functioning of \nphasor measurement units, digital relays, and communication \nchannels. Defects in any of these elements could result in false \ntripping or a failure to trip.\n\u2013 The alarms developed in this task call the protection engineer\u2019s \nattention to a potential problem. For encroachment of distance \nrelays and loss-of-excitation relays, the trajectory of the apparent \nimpedance before and after the encroachment should be stored by \nthe proposed system along with all the power system variables \nmeasured at the relay\u2019s terminals. Alarms for out-of-step relays, \nshould indicate which system condition triggered the outage, and \nthe location of the new swing center of the system.\nA functional analysis of the proposed system determined that it can be \nimplemented with available commercial PMUs, computers and data \nconcentrators if the communication links are available at the selected \nPMU locations.\n\uf0b7 Adaptive Out-of-Step Protection: A reduced West Coast power system \nwas developed based on the California model provided and the WECC \nsystem information provided by PG&E. The model consists of 3996 \nbuses, 1124 generators (647 with dynamic models), 1913 loads, and a \nsingle generator representing the WECC external to California. The \nvalidation process performed at Virginia Tech showed that this model \nreflected the behavior of the full WECC model for the major disturbances\nconsidered for this task. Moving-window and growing-window coherence \ndetection algorithms were developed to detect coherent generator \ngroups, and the following 10 PMU locations are proposed to detect and \nmonitor coherent groups in the California system:\n\u2013 Los Ba\u00f1os 500 kV\n\u2013 Morro Bay 230 kV\n\u2013 Diablo Canyon 500 kV\n\u2013 Imperial Valley 230 kV\n\u2013 Magunden 230 kV\n\u2013 Kramer 230 kV\n\u2013 Mountain View 230 kV\n\u2013 Haynes 230 kV\n\u2013 Vulcan I 92 kV\n\u2013 Litehipe 230 kV\nAn autoregressive model was developed to predict angle swings, and an \nangle difference of 150 degrees for two consecutive samples was shown \nto be an effective trigger for detecting unstable swings. The \nperformance of the proposed adaptive out-of-step algorithms was \nevaluated. The average time between system separation and its \n78\ndetection is 217 ms. None of the stable swings were tagged as unstable \nand all unstable swings were properly identified as such. Operation of \nthe proposed system depends heavily on the proper functioning of PMU, \ndata concentrator, out-of-step computer and communication channels. \nDefects in any of these elements could result in mis-operation of the \nproposed system. A functional analysis of the proposed system \ndetermined that the system can be implemented with available \ncommercial PMUs, computers and data concentrators if the \ncommunication links are available at the selected PMU locations. A \npreferred sampling rate of 30 samples/second is recommended for PMUs\nand a real-time operating system is recommended for the out-of-step \ncomputer.\nThe results of this project were further developed and used in field \ndemonstrations by a subsequent research project, Application of Advanced \nWide Area Early Warning Systems with Adaptive Protection (see below). That \nproject adapted two of the algorithms developed in this project, \nSecurity/Dependability Balance and Relay Zone Encroachment Alarms, for \nfield implementation and demonstration by two California utilities, PG&E and \nSCE.\nSources: \n\uf0b7 Centeno, V.; Thorp, J.; Phadke, A.: \u201cAdvanced Protection Systems Using \nWide Area Measurements,\u201d project report #CEC-500-2013-078, \nCalifornia Energy Commission, September 2010.\n[http://www.energy.ca.gov/2013publications/CEC-500-2013-078/\nCEC-500-2013-078.pdf]\n\uf0b7 Novosel, D.; Snyder, W.; Vu, K.; Cole, J.: \u201cA Business Case Study on \nApplying Synchrophasor Measurement Technology and Applications in \nthe California and the Western Electricity Coordinating Council Grid,\u201d \nCEC PIER Report #CEC-500-2013-045, June 2007.\n[http://www.energy.ca.gov/2013publications/CEC-500-2013-045/\nCEC-500-2013-045.pdf]\n\uf0b7 United States Department of Energy (US DOE): \u201cThe Electric Power \nOutages in the Western United States, July 2-3, 1996,\u201d Report to the \nPresident, August 1996.\n\uf0b7 U.S.-Canada Power System Outage Task Force: \u201cFinal Report on the \nAugust 14, 2003 Blackout in the United States and Canada: Causes and \nRecommendations,\u201d April 2004.\n\uf0b7 Centeno, V.; Castro, N.; Benton, J.; Edris, A.; Michel, G.; Murphy, R.J.; \nPhadke, A.: \u201cAdaptive Out-of-Step Relaying Implementation and Field \nTests,\u201d Proceedings of the FACTS Conference, Baltimore, MD, October 5-\n7, 1994.\n\uf0b7 Rovnyak, S.; Kretsinger, S.; Thorp, J.; Brown, D.: \u201cDecision Trees for Real-\ntime Transient Stability Prediction,\u201d IEEE Transactions on Power \nSystems, vol. 9, no. 6, pp. 1417-1426, August 1994. \n79\n3.9.3 Application of Advanced Wide Area Early Warning Systems \nwith Adaptive Protection\nThis project was performed by the California Institute for Energy and \nEnvironment (University of California, Berkeley), Virginia Tech, Mississippi \nState University, Pacific Gas & Electric Co., and Southern California Edison Co.\nThe Principal Investigator was Carl Blumstein. .\nAnalysis of recent blackouts of power systems has shown that unanticipated \noperation of protection systems can contribute to cascading phenomena that \nlead to blackouts. This project developed and field-tested two methods of \nAdaptive Protection systems utilizing synchrophasor data that are intended to\navoid the unintended and undesired operation of protection systems and \nthereby reduce the probability of blackouts. One method detects conditions \nof system stress that can lead to unintended relay operation, and initiates a \nsupervisory signal to modify relay response in real time to avoid false trips. \nThe second method detects the possibility of false trips of impedance relays \nas stable system swings \u201cencroach\u201d on the relays\u2019 impedance zones, and \nproduces an early warning so that relay engineers can re-evaluate relay \nsettings. In addition, real-time synchrophasor data produced by this project \nwas used to develop advanced visualization techniques for display of \nsynchrophasor data to utility operators and engineers.\nProtection systems for the electric grid have evolved significantly in recent \ndecades. Up until about the 1980s grid protection consisted of a collection of \nindependent electromechanical relays, which were calibrated for an assumed\nset of normal conditions, together with power circuit breakers to \u201ctrip out\u201d \nlines and generators to protect them when a fault (short circuit or other \nsystem disturbance) unexpectedly occurred. Design of such systems erred on\nthe side of dependability (reliability in clearing actual system faults). But \nerrors in relay operation, such as false tripping when no fault actually \noccurred, while hopefully minimized, nevertheless sometimes occurred, \ncompromising system security. \nNowadays electromechanical relays have mostly been supplanted with digital\nrelays, which, being essentially microprocessor-based, are capable of being \nre-set quickly, and even remotely, if real-time system information is available\nand the prevailing conditions call for it. Also, given wide-area system \ninformation, special relaying schemes can be implemented that can \ncoordinate and optimize relay operations for regional or area-wide objectives \nthat were not possible with the older technology. But, given that relay \noperations happen very quickly, sometimes as fast as a few milliseconds (a \ncouple of cycles at the 60 Hz power frequency), it is necessary to time-\nsynchronize the wide-area measurement data in order to overcome the \nproblems of latency in data transmission, thereby ensuring correct analysis, \nimplementation and operation of such a relaying scheme. Fortunately, here \ntoo in recent years the technology to achieve this time-synchronization has \nbecome widely and economically available: global positioning systems (GPS). \nBy time-stamping the system measurements via the GPS clock, the resultant \ndata being labeled as \u201csynchrophasor\u201d data to distinguish output from non-\ntime-correlated (\u201cphasor\u201d) measurements, a multitude of advanced \n80\napplications becomes possible, including adaptive relaying, as the area of \nprotection system technology described above has come to be known. These \napplications can provide substantial benefits to the electric system and its \ncustomers in the form of economical, safe, reliable and resilient electric \nservice.\nThe primary goal of this project was to demonstrate, in real-world utility \nsystems and with the participation of practicing utility engineers, three \nspecific high-value applications in adaptive protection technology. \nFirst, synchrophasor data was used as input to a Security/Dependability \nBalance algorithm. One of the defining characteristics of modern grid \nprotection systems is redundancy: in order to ensure that when a fault occurs\nit is dependably cleared, more than one set of independent relays is \nemployed in every relaying application; this guarantees that, if one of the \nrelays fails to operate, the probability that all the relays will fail to operate is \nextremely small (Dependability). However, every relay system also has a \nsmall probability of operating when no fault is present: this is called a \u201cfalse \ntrip.\u201d Redundant sets of relays will have a correspondingly higher probability \nof false trips, which fortunately are exceedingly rare, and when system \nconditions are normal, i.e., the system is \u201chealthy,\u201d false trips are usually just\na nuisance and not a significant problem, and the \u201cSecurity\u201d of the system is \nconsidered satisfactory. However, when the system is not healthy, as when \nseveral lines or generators have gone out of service for unexpected reasons, \nrelays are more likely to false-trip because their settings do not necessarily \ncorrespond to the new conditions. And false tripping very much needs to be \navoided during conditions of stress, because it will likely exacerbate the \nprocess of system collapse. By using synchrophasor data in an algorithm that\nis trained to recognize such abnormal system conditions, a supervisory logic \ncan be quickly implemented to require a \u201cvoting\u201d scheme for the relays. \nSimply put, this means that when conditions are stressed, the logic requires \nthat at least two of the multiple sets of relays must agree there is a fault \nbefore tripping is implemented. Thus, by using the intelligence available from\nsynchrophasors, the balance between Dependability and Security can be \nmaintained even when the system is in a weakened condition. The Midway \u2013 \nVincent 500 kV transmission line, jointly owned and operated by PG&E and \nSCE, was chosen as the test bed for this application.\nSecond, synchrophasor data was used as input to an Impedance Zone \nEncroachment algorithm. Some relays, called \u201cimpedance relays\u201d \n(impedance is a quantity that combines electrical resistance and inductance),\nare set to detect conditions when the impedance they \u201csee\u201d in the system \ndrops into an unacceptably low range, usually at a low point of a dynamic \noscillation due to a major disturbance. The objective is to avoid unstable \nsystem swings. Over time, as system conditions such as loading or \nequipment additions are made, the relay\u2019s setting will no longer correspond \nto previous conditions, and the relay may operate for stable swings, an \nundesirable outcome. The Zone Encroachment algorithm sets up a buffer \nzone around the relay\u2019s normal zone, and when system swings start to \nencroach on the buffer zone, an alarm and display message is sent to the \n81\nsystem operator, who can relay the warnings to the protection engineer, who \ncan then re-evaluate, and if necessary re-program, that relay\u2019s settings to \navoid undesired operations. The Midway terminal of the Midway \u2013 Vincent \n500 kV line was chosen for this application.\nAnd third, in order for utility engineers to absorb synchrophasor data quickly \nso as to facilitate the required real-time responses, this project developed \nmethods for display and visualization of protection system data and validated\nthose methods with utility engineers in interactive interviews and workshops.\nEach of the three applications of protection systems described above were \ndemonstrated using a three-part technical process: research and \ndevelopment; pilot demonstration; and field demonstration.\nIn the R&D phase, university researchers at Virginia Tech adapted both the \nSecurity/Dependability Balance and Zone Encroachment algorithms from \npreviously developed, non-real-time research versions, with the necessary \nmodifications to allow them to run in real time with streaming synchrophasor \ndata. University researchers at Mississippi State built upon previous research \nto develop new visualizations of synchrophasor data.\nIn the Pilot Demonstration phase, the Security/Dependability Balance and \nZone Encroachment algorithms were first implemented in Virginia Tech\u2019s \nlaboratory using relaying and synchrophasor devices similar to that used by \nutilities; then they were exported to the proof-of-concept laboratory facilities \nat utilities PG&E and SCE, to verify correct performance and instruct utility \nengineers in their use. A Data Evaluation Plan was developed as a protocol \nfor evaluating the performance of the algorithms against real data, to be \ncollected in the final, Field Demonstration Phase. The synchrophasor \nvisualizations developed in the R&D phase were presented to PG&E and SCE \nengineers and technicians in an interactive workshop setting, their feedback \nand comments were elicited, and used to further refine the visualizations.\nIn the Field Demonstration phase, the two adaptive relaying algorithms were \nimplemented by the utilities themselves into utility operations systems, using\nthe same devices, equipment and systems employed in actual practice; with \nthe difference that the systems were in \u201cmonitor\u201d mode, i.e., the systems \nwere fully functional, and data collected from their performance over several \nmonths was evaluated by the project team according to the Data Evaluation \nPlan. The data visualizations were modified according to the utility feedback \nreceived in the Pilot Demonstration phase, and a second round of interviews \nand workshops conducted with the revised visualizations to ensure operator \nand engineer acceptability. \nThe project demonstrated a feasible approach for implementing the Security/ \nDependability Balance algorithm in a real-time operations environment. In \nfact, two somewhat different approaches were used by PG&E and SCE in \nterms of the specific hardware used and where the algorithm software was \ninstalled, but achieving the same result: an adaptive protection system using \nsynchrophasor data to enhance the reliability and security of a major \ntransmission path. The project also demonstrated that periodic re-analysis of \n82\nwide area system conditions and updating of the programming logic is \ndesirable for optimum performance of the algorithm. While not possible in a \nresearch project due to time and budget constraints, utility protection \nengineers can perform this task on a routine basis.\nThe project also demonstrated an economical and feasible approach to \nimplementing an Impedance Zone Encroachment system to inform protection\nengineers via on-screen alarms and notifications when impedance relay \nsettings should be re-evaluated and/or updated for increased system \nsecurity.\nImportant knowledge was gained from practicing utility engineers, operators \nand technicians regarding methods of visualizing synchrophasor-based \nprotection system data. The prototype visualization tools were developed and\nvetted to meet the demands of utility personnel for clear and concise \nrepresentations that can be quickly absorbed, allowing problems to be \nefficiently analyzed, and decisions formulated and carried out expeditiously. \nThe primary benefit to the public from widespread use of the \nSecurity/Dependability Balance and Zone Encroachment technologies, is a \nmore reliable and secure electric grid, one that suffers from fewer blackouts, \nand therefore fewer customer outages. Residential customers will experience \nless inconvenience from lack of electric service; commercial and industrial \ncustomers will experience significantly lower costs in terms of production not \nlost and personnel not idled. Electric rates will also be lower than would \notherwise be the case, due to the avoided costs of extended system outages.\nThis project was also, arguably, the first real-world utility demonstration of \nthe use of synchrophasor data in advanced protective relaying applications, \none that should inspire other researchers and utilities to implement the \napplications described here as well as others. The Phasor Business Case \nStudy [Novosel et al., 2007] outlined numerous other potential applications \nthat would benefit from synchrophasors, not just in the relaying area (Out of \nStep Relaying, Generator Protection, etc.) but in six other major areas of the \nutility business: Real-Time Monitoring and Control, System Benchmarking and\nModel Validation, Post-Disturbance Analysis, Power System Restoration, \nProtection and Control of Distributed Generation, and Overload Monitoring \nand Dynamic Rating of Transmission Lines. The use of synchrophasor data \neither enables or enhances applications in these areas, all of which contribute\nto improved power system reliability, security and economics. \nMany utilities are currently in the process of procuring and installing \nsynchrophasor infrastructure, studying the feasible business applications \ngermane to their respective utilities, and estimating the economic benefits to\nbe realized therefrom. Making the leap from research applications to \nproduction business applications is typically the most difficult step in the long\nprocess from original idea to real-world implementation. This project has \nprovided a demonstration of how it can be done with synchrophasor \napplications.\n83\nSources:\n\uf0b7 Begovic, M.: \u201cWide Area Protection and Monitoring,\u201d Protection, \nAutomation and Control World, Autumn 2009. \n\uf0b7 Benmouyal, G.; Schweitzer, E.; Guzm\u00e1n, A.: \u201cSynchronized Phasor \nMeasurement in Protective Relays for Protection, Control, and Analysis of\nElectric Power Systems,\u201d 29th Annual Western Protective Relay \nConference, Spokane, Washington, October 22-24, 2002.\n\uf0b7 Bernabeu, E.: \u201cMethodology for a Security-dependability Adaptive \nProtection Scheme Based on Data Mining,\u201d Ph.D. dissertation, Virginia \nPolytechnic Institute and State University, 2009. \n[http://scholar.lib.vt.edu/theses/available/etd-12172009-201325/]\n\uf0b7 Centeno, V.; Thorp, J.; Durbha, S.; Cibulka, L.: \u201cApplication of Advanced \nWide Area Early Warning Systems with Adaptive Protection \u2013 Phase 1 \nTechnical Report,\u201d interim project report to the US DOE, December \n2010.\n\uf0b7 Centeno, V.; Thorp, J.; Babski-Reeves, K.; Cibulka, L.: \u201cApplication of \nAdvanced Wide Area Early Warning Systems with Adaptive Protection \u2013 \nPhase 2 Technical Report,\u201d interim project report to the US DOE, \nDecember 2011.\n\uf0b7 Centeno, V.; Thorp, J.; Phadke, A.: \u201cAdvanced Protection Systems Using \nWide Area Measurements,\u201d project report #CEC-500-2013-078, \nCalifornia Energy Commission, September 2010. \n[http://www.energy.ca.gov/2013publications/\nCEC-500-2013-078/CEC-500-2013-078.pdf]\n\uf0b7 Dahal, N.; Durbha, S.; King, R.; Younan, N.: \u201cSensor Web for \nInteroperability in Power Systems,\u201d 2009 North American Power \nSymposium (NAPS), pp. 1-4, October 2009.\n\uf0b7 Dahal, N.; Mohan, V.M.; Durbha, S.S.; Srivastava, A.K.; King, R.L.; \nYounan, N.H.; Schulz, N.N.: \u201cWide Area Monitoring Using Common \nInformation Model and Sensor Web,\u201d IEEE/PES 2009 Power Systems \nConference and Exposition (PSCE \u201909), pp. 1-7, March 2009. \n\uf0b7 Elizondo, D.: \u201cHidden Failures in Protection Systems and Its Impact on \nPower System Wide Area Disturbances,\u201d M.S. dissertation, Virginia \nPolytechnic Institute and State University, 2000.\n\uf0b7 Institute of Electrical and Electronics Engineers (IEEE): \u201cWide Area \nProtection and Emergency Control System,\u201d IEEE Power Engineering \nSociety, Power System Relaying Committee, Protection Subcommittee \nWorking Group C-6, 2002. [http://www.pes-psrc.org/Reports/\nWide%20Area%20Protection%20and%20Emergency\n%20Control_2002-.pdf]\n\uf0b7 North American Electric Reliability Corporation (NERC): \u201cReal-Time \nApplication of Synchrophasors for Improving Reliability,\u201d October 2010. \n[http://www.nerc.com/docs/oc/rapirtf/RAPIR%20final%20101710.pdf]]\n\uf0b7 Novosel, D.; Snyder, W.; Vu, K.; Cole, J.: \u201cA Business Case Study on \nApplying Synchrophasor Measurement Technology and Applications in \nthe California and the Western Electricity Coordinating Council Grid,\u201d \nCEC PIER Report #CEC-500-2013-045, June 2007.\n[http://www.energy.ca.gov/2013publications/CEC-500-2013-045/\nCEC-500-2013-045.pdf]\n84\n\uf0b7 Schweitzer, E.; Whitehead, D.; Guzm\u00e1n, A.; Gong, Y.; Donolo, M.; Moxley,\nR.: \u201cApplied Synchrophasor Solutions and Advanced Possibilities,\u201d 2010 \nIEEE/PES Transmission and Distribution Conference and Exposition, pp. \n1-8, April 2010.\n\uf0b7 Thomas, M.K.: \u201cImplementation of the Security-dependability Adaptive \nVoting Scheme,\u201d Virginia Polytechnic Institute and State University, \n2011.  [http://scholar.lib.vt.edu/theses/available/etd-05102011-225623/]\n\uf0b7 United States Department of Energy (US DOE): \u201cThe Electric Power \nOutages in the Western United States, July 2-3, 1996,\u201d Report to the \nPresident, August 1996.\n\uf0b7 U.S.-Canada Power System Outage Task Force: \u201cFinal Report on the \nAugust 14, 2003 Blackout in the United States and Canada: Causes and \nRecommendations,\u201d April 2004.\n\uf0b7 Western Electricity Coordinating Council (WECC): Western Interconnect \nSynchrophasor Program (WISP). [http://www.wecc.biz/awareness/Pages/\nWISP.aspx]\n\uf0b7 Western Systems Coordinating Council (WSCC): \u201cWestern Systems \nCoordinating Council Disturbance Report for the Power System Outage \nThat Occurred on the Western Interconnection, August 10, 1996,\u201d \nOctober 1996.\nPublications:\n\uf0b7 Bernabeu, E.; Thorp, J.; Centeno, V: \u201cMethodology for a Security-\ndependability Adaptive Protection Scheme Based on Data Mining,\u201d IEEE \nTransactions on Power Delivery, vol. 27, no.1, January 2012.\n\uf0b7 Dahal, N.; Durbha, S.; King, R.; Younan, N.: \u201cGeo-enabled Synchrophasor\nData Exchange Framework Based on Sensor Web,\u201d IEEE Power and \nEnergy Society General Meeting, pp. 1-6, July 2012.\n\uf0b7 Dahal, N.; King, R.L.; Madani, V.: \u201cOnline Dimension Reduction of \nSynchrophasor Data,\u201d 2012 IEEE PES Transmission and Distribution \nConference, pp. 1-7, May 2012.\n\uf0b7 Habibi-Ashrafi, F.; Johnson, A.; Vo, S.; Catanese, D.: \u201cPhasors Point the \nWay,\u201d Transmission & Distribution World, Vol. 63, No. 1, pp. 26-32, \nJanuary 2011.\n\uf0b7 Madani, V.; Parashar, M.; Giri, J.; Durbha, S.; Rahmatian, F.; Day, D.; \nAdamiak, M.; Sheble, G.: \u201cPMU Placement Considerations \u2013 A Roadmap \nfor Optimal PMU Placement,\u201d 2011 IEEE/PES Power Systems Conference \nand Exposition (PSCE), pp. 1-7, 2011.\n\uf0b7 Mazur, D.; Quint, R.; Centeno, V.: \u201cTime Synchronization of Automation \nControllers for Power Applications,\u201d IEEE Transactions on Industry \nApplications, Vol. 50, Issue 1, pp. 25-32, 2014.\n\uf0b7 Quint, R.; Mazur, D.; Badayos, N.: \u201cA Protective Relay Voting Scheme \nUtilizing Automation Controllers,\u201d 2012 IEEE Industry Applications \nSociety Annual Meeting (IAS), pp. 1-8, 2012.\n85\n4. New Cross-cutting Technology for Improving the \nTransmission System Reliability, Flexibility and \nResiliency\nSome of the TRP research was conducted on technical topics or areas that cut \nacross several of the strategies described above. One such area was seismic \ndamage resistance and another was energy storage.\n4.1Increased Robust Seismic Performance of Transmission \nSubstation Components\nMuch of the California electric system is in highly active seismic regions, \nincluding most of the large urban areas. Post-earthquake functioning of utility \nsystems is viewed by emergency responders and society in general as an \nabsolutely vital need for rapid response, recovery and preservation of public \nhealth and safety. Building an electric system that is more resistant to seismic \nmotion damage will reduce the consequences and costs of electric service \ndisruptions caused by strong ground motions. TRP conducted analyses, \nsimulations and lab tests on substation post insulators and transformer \nbushings. Prior tests and field experience indicated that current qualified \nstandards were based on inadequate tests or procedures. The TRP research \nresulted in better knowledge of equipment failures during seismic events for \nrevising qualification procedures for relevant IEEE standards.\n4.1.1 Evaluation of the Seismic Performance of High-Voltage \nTransformer Bushings\nThis project was performed by the Multi-Disciplinary Center for Earthquake \nEngineering Research (MCEER) at the State University of New York \u2013 Buffalo. \nThe Principal Investigator was Andrei Reinhorn.\nMuch of the California electric system, including most of the large urban \nareas, is in highly active seismic regions. Previous research studies have \nresulted in significant knowledge of electric system seismic behavior, have \nled to substantial improvements in key areas, and have identified remaining \nvulnerabilities in the electric system. These studies have also identified \nseveral areas of high-value seismic research that can lead to a more reliable, \nrobust and resilient electric system.\nOne of these high-value research areas is also one of the least understood: \nthe dynamic interactions between the high voltage transformer bushings and \nother components in large substation transformers (the transformer tank, \ntank cover, mounting turret, attached buswork and switches, etc.) due to \nseismic motions. When such components fail in earthquakes, or their oil \ncontents catch fire in the aftermath of an earthquake, there is a danger that \nthe entire grid might be affected, leading to power interruptions and losses to\nthe economy. \n86\nThe consensus of the electric power community, based on experience from \nlaboratory tests and analysis of damage from actual earthquakes, was that \nthe currently-accepted standards and qualification procedures for certifying \nthe seismic performance of transformer bushings are not entirely valid. These\nprocedures, as provided in the current industry standards and used by the \nelectric equipment industry to certify their products, do not properly account \nfor the dynamics of the as-installed bushing/\ntransformer combination in actual practice, as indicated by actual \nunexpected performance, including catastrophic failure during seismic events\nwhen the equipment was certified to more severe levels of seismic motion \nthan experienced in real events. \nCurrent evaluations and qualification procedures, based on IEEE Standard \n693-2005 protocols, consider both the bushing and the transformer in \nisolation from the other, but fail to explicitly recognize the influence of \nbushing installation on, and interaction with, the transformer in actual in-\nservice conditions. Such interactions include the flexibility of the transformer \ntank walls and roof, the effect of use of a turret at the interface of the tank \nroof and the bushing flange, and the effect of bus connections at the top of \nthe bushings. The purpose of this project was to determine the seismic \nresponse of the combined transformer-bushing interaction and to enable \nmore accurate analysis and physical seismic qualification of bushing-\ntransformer systems. \nThe goals were to develop experimental techniques to determine the true \nstrength capacity of bushings, and, by using advanced mathematical and \nanalytical modeling of bushings and transformers, to derive mechanical \nmodels that enable better evaluation of seismic demands and adequacy. \nMoreover, since the issues address usage practices, the project aimed to \ndevelop and explore the ability of simplified qualification procedures to \nconsider the significant interactions among the assemblies and the structure \nof the entire transformer. A key goal was to provide improved scientific data \nto support recommended revisions to the IEEE 693 Standard.\nThe research identified weaknesses of the current qualification procedures \nthat ignore the as-installed conditions and also minimize the importance of \nstrength capacity-demand issues. Through adequate quantification, this \nstudy highlights key measurement and protocol requirements for qualification\nof bushings, so that bushings can withstand predicted levels of seismic \nevents when installed in service. Recommendations were developed for \nconsideration by the IEEE Working Group tasked with revising or updating \nIEEE Standard 693.\nSuch recommendations for changes to the current qualification procedures \nfor bushings include the following: (1) Develop qualification procedures that \ncompare the strength demands to strength capacities in mechanical terms; \n(2) Determine the strength capacity of bushings by either testing them to \nfailure, statically or dynamically, or by strength computations by \nmanufacturers; (3) Test the bushings to generate seismic strength demand \nusing seismic simulators (shake tables) according to a desired severity \n87\n(qualification level); (4) Determine the desired severity of seismic demand \nincluding the identified dynamic properties of bushings and mounting \nconditions, through use of interaction factors or simplified analytical models; \n(5) Modify the design requirements for transformer tank covers to reduce or \neliminate the interaction issues; and (6) Further develop methods of reducing\nseismic demands on all components of transformers by using protective \nsystems.\nThe first three recommendations can be implemented using revisions to the \nexisting IEEE Standard 693 with cooperation from bushing manufacturers and\nthe electric utility industry. The last three issues require further basic \nresearch and development, building upon the findings from this project to \ndevelop additional tools, procedures, models and specifications for the \nqualification of transformer bushings. The additional research results will \nprovide even greater benefits to manufacturers, utilities and regulatory \nbodies as they work in partnership to improve the earthquake reliability of \nthe electric power system. \nThese proposed revisions to the IEEE Standard are currently before the \nappropriate IEEE Task Forces and Working Groups for approval.\nSources:\n\uf0b7 Reinhorn, A.; Filiatrault, A.; Muhammad, F.; Kong, D.; Koliou, M.; \nOikonomou, K.; Oliveto, N.; Schiff, A.: \u201cEvaluation of the Seismic \nPerformance of High-voltage Transformer Bushings,\u201d report to the \nCalifornia Energy Commission, March 2012.\n\uf0b7 ASEA Brown Boveri (ABB) Inc., \u201cSeismic Qualification of Transformer \nBushing,\u201d Report #1ZUA938501-ACA, Power Technology Products \nDivision USA, Alamo, Tennessee, November 2004.\n\uf0b7 Chieh, S.; Chen, T.; Ch'eng, K.: \u201cSeismic Reliability Analysis of High-\nVoltage Transformer,\u201d World Information on Earthquake Engineering, \nVolume 17 (MCEER Collection), 2001.\n\uf0b7 Elder, L.: \u201cSeismic Qualification Report of XXX kV Bushing \u2013 Qualified to \nthe High Level (0.5g ZPA of the RRS) of IEEE Std. 693-2005,\u201d ABB Inc., \nPower Technology Products Division, USA, 2008.\n\uf0b7 Filiatrault, A.; Matt, H.: \u201cSeismic Response of High-Voltage Transformer-\nBushing Systems,\u201d Journal of Structural Engineering, 132(2), pp. 287-\n295, 2006.\n\uf0b7 Gilani, A. S. J.; Chavez, J. W.; Fenves, G. L.; and Whittaker, A. S.: \u201cSeismic\nEvaluation of 196 kV Porcelain Transformer Bushings,\u201d Pacific \nEarthquake Engineering Research (PEER) Center, Report No. PEER \n98/02, University of California at Berkeley, Berkeley, California, 1998.\n\uf0b7 Gilani, A. S. J.; Whittaker, A. S.; Fenves, G. L.; and Fujisaki, E.: \u201cSeismic \nEvaluation of 550 kV Porcelain Transformer Bushings,\u201d Pacific \nEarthquake Engineering Research (PEER) Center, Report No. PEER \n99/05, University of California at Berkeley, Berkeley, California, 1999.\n\uf0b7 Gilani, A. S. J.; Whittaker, A. S.; Fenves, G. L.; and Fujisaki, E.: \u201cSeismic \nEvaluation and Retrofit of 230-kV Porcelain Transformer Bushings,\u201d \nPacific Earthquake Engineering Research (PEER) Center, Report No. \n88\nPEER 99/14, University of California at Berkeley, Berkeley, California, \n1999.\n\uf0b7 Gilani, A. S. J.; Whittaker, A. S.; Fenves, G. L.; Chen, C.H.; Ho, H.; and \nFujisaki, E.: \u201cSeismic Evaluation and Analysis of 230 kV Disconnect \nSwitches,\u201d Pacific Earthquake Engineering Research (PEER) Center, \nReport No. PEER 00/06, University of California at Berkeley, Berkeley, \nCalifornia, 2000.\n\uf0b7 Gundy, W.: \u201cSeismic Qualification of a 230 kV Power Transformer,\u201d \nReport 1018-54, W.E. Gundy & Associates, Inc., Hailey, Idaho, 2000. \n\uf0b7 Gundy, W.: \u201cSeismic Qualification of a 500 kV Power Transformer,\u201d \nReport 1018-58, W.E. Gundy & Associates, Inc., Hailey, Idaho, 2002.\n\uf0b7 Institute of Electrical and Electronics Engineers (IEEE): IEEE Standard \n693-2005, Recommended Practices for Seismic Design of Substations, \n2006.\n\uf0b7 Koliou, M.: \u201cSeismic Protection of Electrical Transformer Bushing \nSystems by Stiffening Techniques,\u201d Master of Science in Civil \nEngineering Thesis, University at Buffalo, The State University of New \nYork, Buffalo, New York, 2010.\n\uf0b7 Muhammad, F.: \u201cSeismic Evaluation and Qualification of Transformer \nBushings,\u201d Ph. D. Dissertation, University at Buffalo \u2013 the State \nUniversity of New York, Buffalo, New York, 2011.\n\uf0b7 Nishenko, S.; Abrahamson, N.; Ferr\u00e9, K.; Fujisaki, E.; Cluff, L.: \u201cElectric \nSystem Seismic Safety and Reliability,\u201d PG&E/PEER, California Energy \nCommission, report #CEC-500-2005-007, January 2005.\n[http://www.energy.ca.gov/2005publications/CEC-500-2005-007/CEC-\n500-2005-007.PDF]\n\uf0b7 Reinhorn, A. M.; Filiatrault, A.; Muhammad, F.; Oliveto, N.; Oikonomou, \nK.; and Koliou, M.: \u201cEvaluation of Transformer Bushings: Current and \nRecommended Practice,\u201d MCEER Task Report MCEER-TR-11-01, \nUniversity at Buffalo \u2013 the State University of New York, Buffalo, New \nYork, 2011.\n\uf0b7 Reinhorn, A. M. and Oikonomou, K.: \u201cModeling of Transformers: 500 kV \nand 230 kV Cover Amplifications,\u201d MCEER Task Report MCEER-TR-10-01, \nUniversity at Buffalo \u2013 the State University of New York, Buffalo, New \nYork, 2010.\n\uf0b7 Reinhorn, A. M.; Oikonomou, K.; Roh, H.; Schiff, A.; and Kempner, L., Jr.: \n\u201cModeling and Seismic Performance Evaluation of High Voltage \nTransformers and Bushings,\u201d MCEER Technical Report MCEER-11-0004, \nUniversity at Buffalo \u2013 the State University of New York, Buffalo, New \nYork, 2011.\n\uf0b7 Saadeghvaziri, M. A.; Feizi, B.; Kempner, L.; and Alston, D.: \u201cOn Seismic \nResponse of Substation Equipment and Application of Base Isolation to \nTransformers,\u201d IEEE Transactions on Power Delivery, 25(1), pp. 177-186,\n2010.\n\uf0b7 Schiff, A.: \u201cGuide to the Improved Earthquake Performance of Electric \nPower Systems,\u201d ASCE Manuals and Reports on Engineering Practice No.\n96 (A. Schiff, editor), American Society of Civil Engineers, 1999. \n\uf0b7 Schiff, A.: \u201cSeismic Qualification of Transformer/Bushing Systems,\u201d white\npaper and personal communication, March 4, 2007.\n89\n\uf0b7 Schiff, A. and Kempner, L., Jr.: \u201cIssues and Guidance for IEEE 693 \nEquipment Qualification Tests,\u201d Precision Measurement Instruments, Los\nAltos Hills, California, 2003.\n\uf0b7 Villaverde, R.; Pardoen, G. C.; and Carnalla, S.: \u201cGround Motion \nAmplification at Base of Bushings Mounted on Electric Substation \nTransformers,\u201d PEER/PG&E Award No. PGE-09566, University of \nCalifornia at Irvine, Irvine, California, 1999.\n\uf0b7 Villaverde, R.; Pardoen, G. C.; and Carnalla, S.: \u201cGround Motion \nAmplification at Flange Level of Bushings Mounted on Electric Substation\nTransformers,\u201d Earthquake Engineering and Structural Dynamics, 30(5), \npp. 621-632, 2001.\n4.1.2 Seismic Performance of Substation Insulator Posts for Vertical-\nBreak Disconnect Switches\nThis project was performed by the University of California \u2013 Berkeley. The \nPrincipal Investigator was Khalid Mosalam.\nDisconnect switches are a key component of power transmission and \ndistribution systems that either control the flow of electricity between all \ntypes of substation equipment or isolate the equipment for maintenance. To \nmitigate the vulnerability of new disconnect switches and other electrical \nsubstation equipment to earthquakes in the United States, the Institute for \nElectrical and Electronics Engineers (IEEE) develops guidelines for the seismic\nqualification and testing of disconnect switches. Due to the severe damage to\nelectrical substation equipment over the past years caused by earthquakes, \nthe IEEE guidelines for seismic testing and qualification of disconnect \nswitches are in continuous development and update. \nIf the disconnect switch or its support structure did not qualify according to \nthe IEEE guidelines, modifications of the switch design such as adding braces \nto increase the lateral stiffness of the support structure should be performed. \nThis process, of repeating the shaking table test for the disconnect switch, \nafter such design modification, is time-consuming, expensive, and sometimes\nnot practical. This is the motivation for developing a new testing approach \nthat can easily accommodate performing such required modifications in the \ndisconnect switch or its support structure. The approach used here is based \non the concept of real time hybrid simulations using a small shaking table for \ntesting only a single insulator post with an online computational model for \nthe support structure. The main advantage of the hybrid simulation (HS) \napproach lies in the flexibility of evaluating any support structure as a \nnumerical simulation model. This implies that there will be no need for \nconducting expensive large shaking table tests for every time a modification \nin the support structure is made. Only a simple modification in the computer \nmodel will suffice. The hybrid simulation testing is the essence of the \nexperimental testing program conducted in this study.\nThe study presented in this report aimed at developing an experimental \nframework, conducting finite element (FE) simulations and providing \nrecommendations to IEEE 693 for seismic qualification of different types of \n90\nhigh voltage electrical substation disconnect switches. The experimental \nframework consisted of static and dynamic testing with complimentary \nmaterial characterization and resonance-search tests. The FE simulations \nincluded linear and nonlinear static and dynamic analyses of a single \ninsulator post. The static tests were conducted for 230 kV and 550 kV \nporcelain insulator posts. These tests included ramp cyclic-loading tests to \nobtain the force-displacement relationship of the insulator posts and fragility \ntests to determine the failure cantilever loads, displacements, and maximum \nstrains. Six cylindrical specimens were prepared from the broken 230 kV \ninsulator parts for material testing. In addition, the vibration properties of the \nsingle porcelain insulator post were determined using hammer impact \n(resonance-search) tests.\nThe project aimed at developing accurate computational FE models for a \nsingle 230 kV porcelain insulator post. These models were used to conduct \neigenvalue, linear, and nonlinear static and dynamic FE analyses. The FE \nmodel developed for nonlinear analyses was also used to conduct a \nparametric study focusing on ranking the different sources of uncertainties \nthat affect the structural response of the insulator posts. Different model \nparameters were varied to study how the force and corresponding \ndisplacement at failure were affected. A Tornado diagram analysis was used \nto illustrate and summarize which model parameters affect the behavior \nmore. The outcome of this Tornado diagram analysis is a representation of \nthe important candidates to focus on in future research to reduce \nuncertainties in the computational modeling of insulator posts.\nThe nonlinear FE model was used to conduct dynamic analyses using the \nsame signal applied for the 230 kV substructured tests. The base excitation \nwas applied at different scales to capture the insulator failure under dynamic \nloading which was not possible to experimentally determine due to shaking \ntable limitations. The computational study was concluded by obtaining the \nmaximum response nonlinear curves for the different scales used in the \nanalysis for a single porcelain insulator post used in 230 kV electrical \nsubstation disconnect switches.\nThe main purpose of the study was to develop a simple hybrid simulation \nsystem (HSS) for testing a single insulator post that can be used in making \ndesign decisions on suitable insulator types and support structure \nconfigurations to minimize the probability of switch failure in earthquakes. \nThe study also focused on conducting linear and nonlinear static analyses to \nrank the sources of uncertainties in porcelain insulator computational \nmodeling, and on dynamic analyses to determine failure load under \nearthquake loading. The final conclusions drawn from the experimental study\nand the FE simulations were used to provide proposed revisions to the IEEE \n693 Standard for consideration by the IEEE Standards Working Groups and \nTask Forces for seismic qualification of high voltage electrical substation \ndisconnect switches.\nSources:\n91\n\uf0b7 Mosalam, K.; Moustafa, M.A.; G\u00fcnay, S.; Triki, I.; Takhirov, S.: \u201cSeismic \nPerformance of Substation Insulator Posts for Vertical-Break Disconnect \nSwitches,\u201d report to the California Energy Commission, March 2012.\n\uf0b7 Chopra, A.K.: \u201cDynamics of Structures: Theory and Applications to \nEarthquake Engineering.\u201d Prentice Hall, Englewood Cliffs, New Jersey, \n2007.\n\uf0b7 Darby, A.P.; Blakeborough, A.; Williams, M.S.: \u201cReal-time Substructure \nTest Using Hydraulic Actuator.\u201d Journal of Engineering Mechanics, ASCE, \n125(10):1133-1139, 1999.\n\uf0b7 Gilani, A.S.J.; Whittaker, A.S.; Fenves, G.L.; Chen, C-H.; Ho, H.; Fujisaki, \nE.: \u201cSeismic Evaluation and Analysis of 230-kV Disconnect Switches,\u201d \nPacific Earthquake Engineering Research Center, Report 2000/06. PEER, \nUniversity of California at Berkeley, 2000.\n\uf0b7 Institute of Electrical and Electronics Engineers: IEEE Standard 693-\n2005, \u201cRecommended Practice for Seismic Design of Substations,\u201d May \n2006.\n\uf0b7 International Electrotechnical Commission: IEC Standard 61462, ed 1.0, \n\u201cComposite Hollow Insulators \u2013 Pressurized and Unpressurized Insulators\nfor Use in Electrical Equipment with Rated Voltage Greater than 1000V \u2013 \nDefinitions, Test Methods, Acceptance Criteria and Design \nRecommendations,\u201d February 2007.\n\uf0b7 Takhirov, S.; Fenves, G.; Fujisaki, E.: \u201cSeismic Qualification and Fragility \nTesting of Line Break 550-kV Disconnect Switches,\u201d Pacific Earthquake \nEngineering Research Center, Report 2004/08. PEER, University of \nCalifornia at Berkeley, 2004. \n\uf0b7 Takhirov, S.; Schiff, A.; Kempner, L.; Fujisaki, E.: \u201cBreaking Strength of \nPorcelain Insulator Sections Subjected to Cyclic Loading,\u201d TCLEE-2009 \nProceedings, Oakland, CA, 2009.\n4.2Energy Storage\nEnergy storage is expected to play a larger role in generation resource \nmanagement, integration of variable resources, and peak management \napplications. On September 29, 2010, Governor Arnold Schwarzenegger \napproved Assembly Bill 2514 (AB 2514), Skinner, Energy Storage Systems. This \nbill required the California Public Utilities Commission (CPUC) to determine \nappropriate targets, if any, for privately owned electric utilities to procure viable \nand cost-effective energy storage systems. For public utilities, the bill required \nthe CEC to review and approve plans to determine appropriate targets and \nprocure viable and cost-effective energy storage systems to meet the targets. \nAlso, the bill recognized that despite many benefits of energy storage, there are \nsignificant barriers to obtaining the benefits of energy storage systems. To assist\nin the decisions to be made, the CEC charged the TRP to conduct a strategic \nanalysis of energy storage technology, called the Energy Storage Vision 2020. It \nreviewed the technical status and the remaining research and development \nneeds of current storage technologies, developed a strategic vision of how \nCalifornia might best implement its energy storage needs over the next 10 \nyears.\n92\n5. Electric Distribution System and Renewable Generation \nIntegration\nIn 2010, in large part because of Governor Brown\u2019s Campaign Promise that included\n12,000 MW of distributed \u2013 mostly renewable \u2013 generation installed in California by \n2020, attention on renewable energy integration with the grid shifted toward \ndistribution. Largely in the form of small photovoltaic generators located at or near \nelectric customers\u2019 facilities, distributed generation represented unprecedented \nchallenges for the distribution system.\nConventional distribution systems are still today largely radial, designed for one-\nway power flow, while transmission systems are networked and designed to handle \npower flows in different directions at different times. While transmission systems \ntend to \u201clook alike,\u201d distribution circuits are very diverse and each is unique, with \ndifferent lengths, amounts of above ground and underground lines, phase \nimbalances, types of loads, voltage regulation equipment, and so forth. Distribution \ncircuits exhibit many local idiosyncrasies. Load profiles vary substantially among \ncustomer classes, and of course the mix of load classes vary significantly among \ndistribution circuits. Transmission systems are more balanced among sections \nbecause of the statistics of aggregating large numbers of customers. Distribution \ncircuits are older than most transmission systems, and more vulnerable to \ndisruptions from weather events, accidents, animals, trees, and so on. \n5.1Reliability of Underground Distribution Systems\nSome distribution circuits are underground, substantially increasing electric \nreliability for customers on these circuits. Despite the construction cost, many \nmore circuits would likely be underground if the cost and difficulty of reducing, \npredicting and locating failures in underground lines when they do occur could \nbe reduced. CIEE has administered research projects on underground cable for \nthat purpose. One project investigated three methods for detecting, in advance \nof failure, a common degradation of cable insulation (known as \u201cwater trees\u201d) \nand specifically degradation of the concentric neutrals of underground power \ndistribution cables. Importantly, these methods can be applied while the cable is \nin service (energized). Two methods showed promise, with one being able to \ndetect the break in the concentric neutral at least 200 feet from the fault \nlocation. Another project investigated four potential methods for online diagnosis\nof underground power distribution cable from in situ measurements of cables. It \nconcluded that of the four, two looked promising but more research would be \nrequired.\n5.1.1 Underground Cable Diagnostics Miniaturization Research, \nDevelopment, Field Test, and Commercialization\nThis project was performed by the University of California \u2013 Berkeley. The \nPrincipal Investigator was Richard White.\nThe aging and in-service deterioration of underground distribution cables is a \nlooming issue facing electric utilities in California and throughout the U.S. \nThere are over 100,000 miles of underground power distribution cables in \nand around the West Coast area of the United States. Older cables have a \n93\nhigher probability of failure due to development of defects in the cables \nbecause of aging and exposure to the elements. These defects can lead to \ncatastrophic cable failures that are not only hazardous to the community \naround the location of the failure, but can result in large economic costs to \naffected businesses that lose power from the time of the cable failure to \nrestoration of power. Utilities today mostly use a simple age-of-operation \nschedule to determine which cables to replace. This scheduled replacement \nmethod is not optimal and definitely not cost-effective; what\u2019s needed is a \ncondition-based inspection method that functions with the cable energized \n(i.e., in service). The scheduled replacement method also does not solve the \nfailure problem with new cables or replacement cables installed in the future.\nThe goal of this project was to address two primary causes of failure in \nunderground cables: broken or corroded concentric neutral (CN) wires, and \nfailure of the polyethylene insulation due to \u201cwater trees.\u201d The research team\ndeveloped two scenario-specific solutions that enable grid operators to \nassess the health of energized cables and pre-empt catastrophic cable \nfailures.\nAssessment of Concentric Neutrals:\nIn a previous project [Paprotny et al., 2011 (3)] the fundamental methods for \ndiagnosing failed CNs were investigated. The results of this research provided\nthe foundation for the design of an advanced sensing mechanism, a device \ntermed the \u201cGrabber,\u201d which utility technicians simply push onto the \nenergized cable using an industry-standard \u201chot stick.\u201d Pivoting jaws close to \nform a ring around the cable, with 10 to 12 micro-sensors arrayed around the\ncable to sense the magnetic fields from the CNs. Sensor data from the \ngrabber is transmitted wirelessly via Bluetooth to the technician\u2019s laptop, \ntablet or smart phone. The Grabber easily releases the cable when the \ntechnician pulls back on the hot stick. The technician can then review the \nsensor data, quickly assess the cable\u2019s health, and determine if a cable \nreplacement or further testing is necessary. The Grabber is also being \ndesigned so that it could be left attached to the cable indefinitely as a \ncondition-based monitoring solution. \nOnline Cable Diagnostics using RF Coupling:\nIn a previous project [Paprotny et al., 2011 (2)] the mechanisms by which \nwater trees develop in polyethylene were investigated. Once the fundamental\nscience was understood, methods for diagnosing the existence of water trees\nin energized cables were investigated for feasibility as well as practicality in \nthe field. The research team determined that a technique using radio \nfrequency (RF) coupling in the cable was the most promising method. This \ntechnique requires the insertion of an RF generation source at one end of the \ncable and a detector at the input end to detect reflections, or at the other \nend of the cable coupling. By comparing the cable\u2019s attenuation and other \ncharacteristics with the characterization of a \u201chealthy\u201d cable, technicians can\nquickly identify the presence of water trees or other cable abnormalities. \nArmed with this knowledge, utilities can replace cable sections before they \nfail, as well as avoid unnecessary cable replacements.\n94\nProject Benefits:\nThe primary objective of this project was to diagnose the two most common \nproblems in underground cables that indicate the cable is likely to fail in the \nnear future. The primary benefits of this knowledge are:\n1. Utility personnel have advance warning that a cable may fail and cause\nan outage. They can schedule the cable for immediate replacement, \nreducing the probability that a failure will cause customer outages.\n2. Customers will experience more reliable service, and will suffer less \ninconvenience and the economic costs that accompany outages.\n3. Utilities will avoid excess costs due to emergency replacements and \nrepairs, and will be able to better control their available maintenance \ndollars.\n4. The safety of utility maintenance personnel and customers will both be\nimproved.\nTechnology Commercialization and Tech Transfer:\nA key deliverable for this project was a Commercialization Plan that would \naccelerate the transfer of the developed technologies to the private sector. A \nnumber of discussions were held with various technology firms regarding \nlicensing and marketing of the diagnostic methods developed in this project, \nand the most promising commercialization partners were identified. A patent \napplication was submitted for the RF technique for detecting water trees in \nenergized cables, and the patent was issued. A provisional patent application \nfor the Grabber device for detecting faults in concentric neutrals was also \nsubmitted. \nWhile these patent applications were being processed and filed, a temporary \nhiatus in commercialization discussions with potential companies was in \nplace. Once the patents were filed and disclosed, permission was granted by \nthe Berkeley Office of Intellectual Property & Industry Research Alliances to \ncontinue these discussions in pursuit of commercialization. The Berkeley \nteam plans to resume these efforts in early 2015.\nSources:\n\uf0b7 R. White, J. Evans, P. Wright, R. Xu, C. Sherman, C. Gregg, S. Croshere, \nE. Talamantez, S. Wihera, L. Cibulka. University of California at Berkeley.\n2014. \u201cUnderground Cable Diagnostics Miniaturization Research, \nDevelopment, Field Test, and Commercialization.\u201d Project report to the \nCalifornia Energy Commission (not yet published). \n\uf0b7 I. Paprotny, P. Wright, R. White, J. Evans, T. Devine. University of \nCalifornia, Berkeley. 2011. \u201cFault Analysis in Underground Cables.\u201d \nCalifornia Energy Commission. Publication number: CEC-500-2013-094. \nAvailable: http://www.energy.ca.gov/2013publications/CEC-500-2013-\n094/CEC-500-2013-094.pdf \n\uf0b7 I. Paprotny, P. Wright, R. White, J. Evans, T. Devine. University of \nCalifornia, Berkeley. 2011. \u201cConcentric Neutral Degradation and Failure \nAnalysis: Sensors and Methods for In-Service Diagnosis.\u201d Project report \nto the California Energy Commission.\n95\n\uf0b7 F. Ciuprina, A.  Hornea, L. Andrei. \u201cAC Breakdown Strength and Dielectric\nResponse of Water-treed Low Density Polyethylene,\u201d 8th International \nSymposium on Advanced Topics in Electrical Engineering (ATEE), \nBucharest, Romania, pp. 1-4, May 23-25, 2013.\n\uf0b7 S. Hvidsten, E. Ildstad, J. Sletbak, H. Faremo. \u201cUnderstanding Water \nTreeing Mechanisms in the Development of Diagnostic Test Methods,\u201d \nIEEE Transactions on Dielectrics and Electrical Insulation, vol. 5, no. 5, \npp. 754-760, October 1998.\n\uf0b7 S. Hvidsten, E. Ildstad, B. Holmgren, P. Werelius. \u201cCorrelation between \nAC Breakdown Strength and Low Frequency Dielectric Loss of Water \nTree Aged XLPE Cables,\u201d IEEE Transactions on Power Delivery, vol. 13, \nno. 1, pp. 40-45, January 1998.\n\uf0b7 M. Kuschel, W. Kalkner. \u201cDielectric Response Measurements in Time and \nFrequency Domain of Different XLPE Homo- and Co-polymer Insulated \nMedium Voltage Cables,\u201d IEE Proceedings \u2013 Science Measurement and \nTechnology, 146(5), pp. 243-248, 1999.\n\uf0b7 E. Moreau, C. Mayoux, C. Laurent, A. Boudet. \u201cThe Structural \nCharacteristics of Water Trees in Power Cables and Laboratory \nSpecimens,\u201d IEEE Transactions on Dielectrics and Electrical Insulation, \nvol. 28, No.1, pp. 54-64, February 1993.\n5.2Advanced Monitoring of Distribution Systems\nPerhaps the most significant difference between transmission and distribution is \nthe degree of monitoring capability. Transmission systems have become \nrelatively heavily monitored over time compared to distribution systems, which \nseldom have had monitoring beyond the distribution substation. This is true \ndespite the relative large penetration of smart meters late in the 2000 \u2013 2013 \nperiod, since advanced metering generally has not yet provided much real-time \ndata to operators.\nAnticipation of, and in some local instances, experiences with, high penetrations \nof variable solar PV distributed generators have raised concerns about islanding \n(unintentional for reasons of safety, and intentional for grid resiliency); relay \ndesensitization because of being designed for one-way power flow; voltage \nregulation and flicker, due in part to the variability of the solar resource and the \nrapid ramp rates of PV units; line and transformer replacements due to extra use\nand higher frequency of duty cycles; and resonant conditions. \nGiven how little is known about the distribution system, the CEC selected CIEE to\nconduct a research project to begin to characterize the distribution system in \nfine enough granularity to answer questions regarding the effects of high \npenetrations of distributed PV. This project collected and analyzed some of the \navailable data, and will define the requirements for an intentional monitoring \nplan to characterize the electric distribution system in California for high \npenetrations of distributed PV.\n96\n5.2.1 Distribution System Field Study with California Utilities to \nAssess Capacity for Renewables and Electric Vehicles\nThis project was performed by the University of California \u2013 Berkeley, the \nUniversity of California \u2013 San Diego, and the University of California \u2013 Irvine. \nThe Principal Investigators were Carl Blumstein and Alexandra von Meier.\nA significant and growing amount of new renewable generation is being \ninstalled at the distribution level of the electric grid, accompanied by the \nproliferation of technologies such as plug-in hybrids and electric vehicles \n(EVs). As a result, the need for information about the potential impacts of \nthese technologies, and data to support the analysis and control of \ndistribution systems in the future, is becoming clear and urgent. \u201cOne-size-\nfits-all\u201d solutions such as the 15% rule of thumb for installation of distributed \ngeneration on a feeder are rapidly becoming unacceptable as a means of \nmanaging the integration of new technologies in distribution and proactively \ndealing with the unforeseen impacts of renewable integration. New analytical\nand control methodologies are being developed and used, but more and \nbetter data about the distribution system is required for these methods to be \npracticable.\nExtensive monitoring of distribution circuits by utilities was historically not \ncost-effective given the lack of business need for such information, so there is\nlittle if any comparative data of sufficient quality to provide a baseline or \nreference for measurements on distribution feeders with and without high \npenetrations of renewables. Furthermore, monitoring systems capable of \ndiscovering any new unanticipated distribution system phenomena are \ngenerally not in widespread use. As a result, utility operations personnel \ncurrently have very little information, real-time or otherwise, about the status\nof the distribution network they are charged with operating. This situation is \ndescribed as a lack of observability, poor \u201csituational awareness,\u201d or lack of \n\u201cvisibility\u201d of the electrical phenomena resulting from new sources and users \nof electricity on distribution circuits, or even of normal and routine \noccurrences on the system. Monitoring locations today may consist of only \none point per feeder: the meter measuring power flow and voltage at the \ndistribution substation transformer. It will be increasingly important to have \nsome knowledge of what happens beyond the substation because of the \npotential impacts on the reliability and economic efficiencies of the \ndistribution system.\nGoals and Objectives:\nThe purpose of this project was to advance the state of the art in electric \ndistribution systems by supporting safe and reliable operation with a \nsubstantially increased presence of renewable generation, distributed \ngeneration, electric vehicles (EVs), and other new technologies and \napplications. By analyzing the available monitoring data from utilities, the \nproject\u2019s goals were to: characterize the impacts of these technologies on \nelectric distribution system operation and performance; increase the \noperational visibility and situational awareness beyond the substation; \nprovide a better understanding of the requirements for strategic upgrades \n97\nand new technologies in the distribution system infrastructure and \noperational tools to accommodate desired levels of DG; and to inform \nupdated DG specifications and interconnection standards that allow the \nincreased use of distributed renewable generation resources without adverse \nimpacts on safety and reliability.\nThe project technical approach consisted of two avenues of effort. First, a \ncollaborative process of sharing data was established, using typical \nmeasurements available from existing devices installed in a number of utility \ndistributions systems in California. Intended to establish a baseline of current \nmonitoring practices and methodologies, analysis of these existing \nmeasurements aimed to begin characterizing distribution feeders with and \nwithout distributed energy resources (DER), validating distribution feeder \nmodels, and identifying gaps in available data. The second part of the project\nused the results and lessons learned from the first part, along with \ninformation from a number of other sources, including a utility survey and a \nworkshop with invited experts and utility colleagues, to develop an Advanced \nMonitoring Plan (AMP), the principal deliverable of the project. Expressly \ndesigned to be a blueprint or roadmap for follow-on research efforts to this \nproject, the AMP would expand the distribution database with measurements \nfrom new line sensors and substation monitors installed by participating \nutilities in collaborative efforts, for the express purpose of analyzing the \nimpacts and requirements imposed by high levels of renewables and other \nnew technologies in the distribution system, and informing the development \nof advanced applications for the planning, design and operation of the \ndistribution systems of the future.\nProject Results:\nCalifornia utilities are engaged in, and have accomplished, a number of \nmonitoring activities, indicating that that there is a general awareness that \nmore needs to be known about the behavior of distribution systems, and \nespecially the current and potential impacts of increased levels of \nrenewables, EVs and other technologies. Most of these monitoring activities \nare \u201cad hoc\u201d efforts focusing on investigating specific behaviors, e.g., of PV \nsystems, energy storage installations, EV charging, microgrid \ndemonstrations, smart meter implementations, demand response programs, \nand so forth. While mostly concerned with understanding the behavior of the \nindividual devices, some projects also include feeder-level analysis, such as \nvolt/VAR control algorithms. There was considerable variation found in data \ncollection, data quality, data resolution and accuracy, placement strategies \nfor the monitoring devices, and analytical methods employed. Evaluation of \nthe overall monitoring situation gave a reasonably good picture of the \nbaseline monitoring practices used in distribution systems today, and the \ngaps that need to be filled in order to manage and operate distribution \nsystems effectively, both today and in the future. A sobering caveat must be \noffered: the current commitment of utilities in terms of human resources and \nbudget needs to be substantially increased in order to accomplish these \nintended goals, which will require support and approval of both utility \nmanagements and regulatory agencies.\n98\nA Data Repository was established at the UC-San Diego Supercomputer \nCenter for the secure storage of utility data. The data acquired from utilities \nwas analyzed to the extent possible in terms of spatial and temporal \ncharacteristics. More data would have been desirable; indeed, considerably \nmore data would be needed to perform the feeder characterization originally \nenvisioned for this project, in terms of categorizing feeders by general type, \nby levels of renewable generation, or other key parameters. It was \nrecommended that this effort be continued and expanded in a Phase 2 \nresearch project.\nThe project team did acquire enough actual system data, in the form of both \nphysical feeder models and the associated measured data, to perform \nvalidation of the feeder models. While some utilities have made efforts to \nvalidate their system models, it is unclear how universal a practice this is, but\nit is a requirement that must be fulfilled. Unless the physical system model is \naccurate, it is not possible to perform meaningful planning studies, to know \nor estimate what the actual system conditions are, or to operate the system \nintelligently (which is to say, reliably and efficiently). Therefore, model \nvalidation will likely be the necessary first task for utilities when acquiring \ndata from new, advanced monitoring systems, that is intended for use in \nadvanced applications.\nData quality also needs to be addressed. The supplied data had missing data,\nbad data, \u201coutliers,\u201d non-uniform sampling intervals, and so forth, which \nrequired that additional evaluation and processing be done before the data \ncould be used in analysis programs. Also, since there are a number of \nsoftware packages marketed to utilities for analysis of distribution systems, \nthe data supplied by the utilities varied in format. The upside is that the \nproject team was able to develop methods for dealing with these anomalies \nso that analysis could be efficiently performed, which should prove to be \nvaluable time-savers in follow-on research efforts.\nFinally, the blueprint for an Advanced Monitoring Plan (AMP) was developed. \nThe AMP is intended to be the basis for follow-on research efforts to address \nthe current gaps in available data and in data monitoring practices, as well as\nthe future needs based on high levels of new technologies, such as \nrenewables, EVs, etc. The results from the first part of the project provided \ninformation on current needs and monitoring practices; additional efforts in \nthe second part of the project included a survey of distribution engineers and \nexperts, and an all-day interactive workshop, to further explore and expand \nthe design and features of the AMP. The resulting product is, we believe, a \npractical basis for further research to learn more about distribution systems \nin California, and in particular the impacts of new technologies such as such \nrenewables and EVs on the design and operation of those systems.\nProject Benefits:\nThis collaborative research effort represented, arguably, the first systematic \nlook at a representative sample of distribution circuits across the State of \nCalifornia. It began with an inventory of typical feeder data that was gleaned \nfrom existing utility instrumentation, and an evaluation of efforts that have \n99\nalready been made by individual utilities to improve visibility on distribution \ncircuits. It proceeded with analysis of the received data in terms of \ncharacterization of feeders, and validation of system models. Finally, an \nAdvanced Monitoring Plan was developed and is proposed as a potential \nframework for additional research in distribution monitoring, for the purpose \nof filling the gaps in available data and methods that will needed for the \nplanning and operation of distribution systems now and in the future.\nThe primary benefits to be derived from this project and its follow-on \nresearch efforts include increased visibility of the distribution system, \nresulting in more reliable and efficient operations, better planning for system \nupgrades and expansions, and proactive detection, analysis and mitigation of\nthe potential impacts of new technologies and applications on distribution \nsystems. \nCalifornia electric ratepayers, customers and stakeholders will benefit from \ndistribution systems that will be better able to handle the unprecedented \nchallenges placed upon them.\nSources:\n\uf0b7 A. von Meier, M. Brown, R. Arghandeh, L. Mehrmanesh, L. Cibulka, R. \nRuss. University of California, Berkeley. 2014. \u201cDistribution System Field \nStudy with California Utilities to Assess Capacity for Renewables and \nElectric Vehicles.\u201d Project report to the California Energy Commission \n(not yet published). \n\uf0b7 J. Bank. \u201cDevelopment of a Distribution Level Data Acquisition System \nand Preliminary Results,\u201d NREL, 2012 IEEE Power and Energy Society \n(PES) General Meeting, 2012.\n\uf0b7 J. Bank, B. Mather. \u201cAnalysis of the Impacts of Distribution Connected PV\nUsing High-Speed Datasets,\u201d NREL, 2013 IEEE Green Technologies \nConference, 2013.\n\uf0b7 D. Brooks, J. Smith. \u201cEPRI Distributed PV (DPV) Feeder Analysis Project,\u201d \n2011.\n[http://www.uwig.org/mauisolar/Brooks_DPV-FeederImpacts.pdf]\n\uf0b7 California Public Utilities Commission (CPUC): \u201cOrder Instituting \nRulemaking Regarding Policies, Procedures and Rules for Development \nof Distribution Resources Plans Pursuant to Public Utilities Code Section \n769,\u201d August 14, 2014. \n[http://docs.cpuc.ca.gov/PublishedDocs/Published/G000/M102/K036/102\n036703.pdf]\n\uf0b7 D. Della Giustina, S. Repo, S. Zanini, L. Cremaschini. \u201cICT Architecture \nfor an Integrated Distribution Network Monitoring,\u201d 2011 IEEE \nInternational Workshop on Applied Measurements for Power Systems \n(AMPS), 2011.\n\uf0b7 P. DeMartini. \u201cMore than Smart: A Framework to Make the Distribution \nGrid More Open, Efficient and Resilient,\u201d Greentech Leadership Group, \n2014.\n[http://greentechleadership.org/wp-content/uploads/2014/08/More-Than-\nSmart-Report-by-GTLG-and-Caltech.pdf]\n100\n\uf0b7 National Energy Technology Laboratory (NETL). \u201cAdvanced Metering \nInfrastructure,\u201d NETL Magazine, Vol. 1, 2008.\n\uf0b7 E. Rahm, H. Do. \u201cData Cleaning: Problems and Current Approaches,\u201d \nIEEE Data Engineering Bulletin, vol. 23, pp. 3-13, 2000.\n\uf0b7 San Diego Gas & Electric Co.: SDG&E Smart Grid Communication System\n(SGCS), 2013.\n[http://www.smartgrid.gov/project/san_diego_gas_electric_company_sdg\ne_grid_communication_system]\n\uf0b7 K. Schneider, Y. Chen, D. Chassin, R. Pratt, D. Engel, S. Thompson. \n\u201cModern Grid Initiative Distribution Taxonomy Final Report,\u201d Pacific \nNorthwest National Laboratory (PNNL), report to the US Dept. of Energy, \nNovember 2008.\n\uf0b7 A. von Meier, M. Brown, R. Arghandeh, L. Mehrmanesh, L. Cibulka, R. \nRuss. \u201cAdvanced Monitoring Plan,\u201d report to the California Energy \nCommission, September 2014.\n\uf0b7 A. von Meier, L. Cibulka, M. Brown, L. Miller. \u201cPreliminary Data Inventory \nReport: Overview of Distribution Feeder Characteristics for Renewables \nIntegration,\u201d project report to the California Energy Commission, \nSeptember 2013.\n\uf0b7 A. von Meier, G. Rodriguez. \u201cMonitoring for Impacts of Distributed \nResources: Initial Planning Considerations,\u201d IEEE Power and Energy \nSociety (PES) General Meeting, 2013.\nConcluding Statements\nThe research projects included in this white paper were chosen as representative of \nthe Transmission Research Program and other PIER-funded electric grid research, \nled, administered, managed and/or conducted for the California Energy Commission\nby the California Institute for Energy and Environment of the University of California.\nSome of the research projects were not explicitly included, but still accounted for, \nbecause they were precursors to projects of continuing efforts included here. Many \nof the other excluded research efforts not explicitly described in detail here were of \nthe nature of research planning consisting of situational characterization, issue \ndefinition, technology solution identification, gap analysis and technology research \nroadmaps for the California electric grid. While these planning efforts usually did not\nresult in direct benefits to the electric grid, they did help in formulating the most \nvaluable portfolio of research projects, and making the research products used and \nuseful in a timely fashion to Californians.\nPublic interest energy research is situated at the nexus of three inextricably linked, \nyet competing desires for electric power systems: service quality, environmental \nimperatives, and economic objectives. At the intersection of these three goals, the \neffective integration of renewable resources throughout the electric grid has been a \ncentral, challenging theme for the 2003\u20132014 period of this particular portfolio of \nresearch projects. Work sponsored through PIER systematically sought to expand \nthe grid\u2019s technical hosting capacity for various types of renewable and distributed \nresources through a diverse range of approaches. It would be wrong, of course, to \ncredit PIER research with the entirety of newly connected renewables and DER \n101\nduring this period; nor could the most ambitious analyst assign an explicit \npercentage of due credit to PIER. Nevertheless, the authors feel confident in stating \nthat the remarkable progress on renewable and DER integration seen in California in\nthese recent years \u2013 progress that serves as an example to other states and nations\naround the world \u2013 would not have been possible without the contributions of PIER, \nat least not without some combination of electric service degradation and cost \nincreases that in all likelihood would have made the case of California less of a \nposter child and more of a cautionary tale. While the explicit charge of PIER is to \nserve the interests of California\u2019s electric ratepayers, in fact much more is at stake. \nIn the context of the present status of global climate negotiations, most notably \nwith respect to China, the imperative for success of the California experiment, and \nthe long-term public benefit even beyond our State\u2019s borders of every contribution \ntoward this success, cannot be overstated.\n102\nGLOSSARY\nAB Assembly Bill\nAC Alternating Current\nACE Area Control Error\nAGC Automatic Generation Control\nCAISO California Independent System Operator\nCEC California Energy Commission\nCPUC California Public Utilities Commission\nDC Direct Current\nDER Distributed Energy Resources\nDG Distributed Generation\nDOE (U.S.) Department of Energy\nED Economic Dispatch\nEIPP Eastern Interconnection Power Pool\nEMS Energy Management System\nEPACT Energy Policy Act (2005)\nERO Electric Reliability Organization\nEV Electric Vehicle\nFERC Federal Energy Regulatory Commission\nFIDVR Fault-induced Delayed Voltage Recovery\nGHG Greenhouse Gas\nGUI Graphical User Interface\nGW Gigawatt\nHVAC Heating, Ventilating and Air Conditioning\nIEEE Institute of Electrical and Electronics Engineers\n103\nIOU Investor-owned Utility\nISO Independent System Operator\nMW Megawatt\nNaS Sodium-sulfur\nNERC North American Electric Reliability Corporation\nOTC Once-through Cooling\nPAC Policy Advisory Committee\nPIER Public Interest Energy Research\nPMU Phasor Measurement Unit\nPOU Publicly Owned Utility\nPURPA Public Utility Regulatory Policies Act\nPV Photovoltaic(s)\nR&D Research and Development\nRMR Reliability Must Run\nROI Return on Investment\nRPS Renewable Portfolio Standard\nSB Senate Bill\nSCADA System Control and Data Acquisition\nT&D Transmission and Distribution\nTAC Technical Advisory Committee\nTRP Transmission Research Program\nUC Unit Commitment\nVAR Volt-Ampere Reactive\nWAEMS Wide-Area Energy Storage and Management System\nWECC Western Electricity Coordinating Council\n104\n",
      "id": 78451001,
      "identifiers": [
        {
          "identifier": "oai:escholarship.org:ark:/13030/qt9hz5h2sd",
          "type": "OAI_ID"
        },
        {
          "identifier": "oai:escholarship.org/ark:/13030/qt9hz5h2sd",
          "type": "OAI_ID"
        },
        {
          "identifier": "484236704",
          "type": "CORE_ID"
        },
        {
          "identifier": "288432726",
          "type": "CORE_ID"
        }
      ],
      "title": "An Assessment of PIER Electric Grid Research 2003-2014 White Paper",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:escholarship.org:ark:/13030/qt9hz5h2sd",
        "oai:escholarship.org/ark:/13030/qt9hz5h2sd"
      ],
      "publishedDate": "2015-01-01T00:00:00",
      "publisher": "eScholarship, University of California",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://escholarship.org/content/qt9hz5h2sd/qt9hz5h2sd.pdf?t=q752d4"
      ],
      "updatedDate": "2023-12-02T23:28:05",
      "yearPublished": 2015,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/288432726.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/288432726"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/288432726/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/288432726/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/78451001"
        }
      ]
    },
    {
      "acceptedDate": "2019-02-05T00:00:00",
      "arxivId": null,
      "authors": [
        {
          "name": "Aguero, Julio Romero"
        },
        {
          "name": "do Prado, Josue Campos"
        },
        {
          "name": "Qiao, Wei"
        },
        {
          "name": "Qu, Liyan"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/189485936",
        "https://api.core.ac.uk/v3/outputs/201227920",
        "https://api.core.ac.uk/v3/outputs/540185056",
        "https://api.core.ac.uk/v3/outputs/188144006"
      ],
      "createdDate": "2019-03-09T14:31:52",
      "dataProviders": [
        {
          "id": 2912,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/2912",
          "logo": "https://api.core.ac.uk/data-providers/2912/logo"
        },
        {
          "id": 22080,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/22080",
          "logo": "https://api.core.ac.uk/data-providers/22080/logo"
        },
        {
          "id": 179,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/179",
          "logo": "https://api.core.ac.uk/data-providers/179/logo"
        },
        {
          "id": 645,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/645",
          "logo": "https://api.core.ac.uk/data-providers/645/logo"
        }
      ],
      "depositedDate": "2019-02-03T00:00:00",
      "abstract": "The increasing adoption of distributed energy resources (DERs) and smart grid technologies (SGTs) by end-user retail customers is changing significantly both technical and economic operations in the distribution grid. The next-generation retail electricity market will promote decentralization, efficiency, and competitiveness by accommodating existing and new agents through new business models and transactive approaches in an advanced metering infrastructure (AMI). However, these changes will bring several technical challenges to be addressed in transmission and distribution systems. Considerable activities have been carried out worldwide to study the impacts of integrating DERs into the grid and in the wholesale electricity market. However, the big vision and framework of the next-generation retail market in the context of DERs is still unclear. This paper aims to present a brief review of the present retail electricity market, some recent developments, and a comprehensive vision of the next-generation retail electricity market by describing its expected characteristics, challenges, needs, and future research topics to be addressed. A framework of integrating retail and wholesale electricity markets is also presented and discussed. The proposed vision and framework particularly highlight the necessity of new business models and regulatory initiatives to establish decentralized markets for DERs at the retail level as well as advances in technology and infrastructure necessary to allow the widespread use of DERs in active and effective ways",
      "doi": "10.3390/en12030491",
      "downloadUrl": "https://core.ac.uk/download/188144006.pdf",
      "fieldOfStudy": null,
      "fullText": "University of Nebraska - Lincoln\nDigitalCommons@University of Nebraska - Lincoln\nFaculty Publications from the Department of\nElectrical and Computer Engineering Electrical & Computer Engineering, Department of\n2019\nThe Next-Generation Retail Electricity Market in\nthe Context of Distributed Energy Resources:\nVision and Integrating Framework\nJosue Campos do Prado\nUniversity of Nebraska - Lincoln, josue@huskers.unl.edu\nWei Qiao\nUniversity of Nebraska - Lincoln, wqiao@engr.unl.edu\nLiyan Qu\nUniversity of Nebraska-Lincoln, lqu2@unl.edu\nJulio Romero Aguero\nQuanta Technology, julio@quanta-technology.com\nFollow this and additional works at: http://digitalcommons.unl.edu/electricalengineeringfacpub\nPart of the Computer Engineering Commons, and the Electrical and Computer Engineering\nCommons\nThis Article is brought to you for free and open access by the Electrical & Computer Engineering, Department of at DigitalCommons@University of\nNebraska - Lincoln. It has been accepted for inclusion in Faculty Publications from the Department of Electrical and Computer Engineering by an\nauthorized administrator of DigitalCommons@University of Nebraska - Lincoln.\ndo Prado, Josue Campos; Qiao, Wei; Qu, Liyan; and Aguero, Julio Romero, \"The Next-Generation Retail Electricity Market in the\nContext of Distributed Energy Resources: Vision and Integrating Framework\" (2019). Faculty Publications from the Department of\nElectrical and Computer Engineering. 467.\nhttp://digitalcommons.unl.edu/electricalengineeringfacpub/467\nenergies\nConcept Paper\nThe Next-Generation Retail Electricity Market in the\nContext of Distributed Energy Resources: Vision and\nIntegrating Framework \u2020\nJosue Campos do Prado 1 , Wei Qiao 1,* , Liyan Qu 1 and Julio Romero Ag\u00fcero 2\n1 Department of Electrical and Computer Engineering, University of Nebraska-Lincoln, Lincoln,\nNE 68588-0511, USA; josue@huskers.unl.edu (J.C.d.P.); lqu2@unl.edu (L.Q.)\n2 Quanta Technology, Houston, TX 77056-6175, USA; julio@quanta-technology.com\n* Correspondence: wqiao3@unl.edu; Tel.: +1-402-472-9619\n\u2020 This paper is an extended version of our paper published in Do Prado, J.C.; Qiao, W. A Vision of the\nNext-Generation Retail Electricity Market in the Context of Distributed Energy Resources. In Proceedings of\nthe IEEE Power & Energy Society Innovative Smart Grid Technologies Conference, Washington, DC, USA,\n19\u201322 February 2018, pp. 1\u20135.\nReceived: 18 December 2018; Accepted: 31 January 2019; Published: 3 February 2019\n\u0001\u0002\u0003\u0001\u0004\u0005\u0006\u0007\b\u0001\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\nAbstract: The increasing adoption of distributed energy resources (DERs) and smart grid technologies\n(SGTs) by end-user retail customers is changing significantly both technical and economic operations\nin the distribution grid. The next-generation retail electricity market will promote decentralization,\nefficiency, and competitiveness by accommodating existing and new agents through new business\nmodels and transactive approaches in an advanced metering infrastructure (AMI). However, these\nchanges will bring several technical challenges to be addressed in transmission and distribution\nsystems. Considerable activities have been carried out worldwide to study the impacts of integrating\nDERs into the grid and in the wholesale electricity market. However, the big vision and framework of\nthe next-generation retail market in the context of DERs is still unclear. This paper aims to present a\nbrief review of the present retail electricity market, some recent developments, and a comprehensive\nvision of the next-generation retail electricity market by describing its expected characteristics,\nchallenges, needs, and future research topics to be addressed. A framework of integrating retail and\nwholesale electricity markets is also presented and discussed. The proposed vision and framework\nparticularly highlight the necessity of new business models and regulatory initiatives to establish\ndecentralized markets for DERs at the retail level as well as advances in technology and infrastructure\nnecessary to allow the widespread use of DERs in active and effective ways.\nKeywords: distributed energy resource; renewable energy; retail electricity market; smart grid\n1. Introduction\nThe traditional way of generating, transmitting, and distributing electricity has been changing\nsignificantly as generating units become more distributed, efficient, and closer to consumption\ncenters. The use of distributed energy resources (DERs), such as distributed photovoltaic (PV),\nenergy storage systems (ESSs), and demand response (DR), combined with innovative smart grid\ntechnologies (SGTs) has been growing every year. DERs are not the most cost-effective option from a\npower system perspective, but many investments have been made worldwide in developing more\naffordable, flexible, and efficient solutions that enable greater adoption of these technologies at\ncustomer level, thus improving power system efficiency, reliability, flexibility, and helping several\ncountries reach decarbonization targets [1]. However, market efficiency is necessary to make the smart\ngrid environment completely smart [2]. This includes business models designed to maximize the\nEnergies 2019, 12, 491; doi:10.3390/en12030491 www.mdpi.com/journal/energies\nEnergies 2019, 12, 491 2 of 24\nsocial welfare of all participants by monetizing energy products and services with the highest possible\nquality for the lowest possible price.\nMany states and countries have partially liberalized and decentralized their retail electricity\nmarkets by adopting retail choice programs that enable retail customers to choose electricity suppliers,\nservices, and tariff schemes according to their needs and preferences. Such a paradigm has encouraged\ninnovation and flexibility in both pricing and services offered to retail customers. In addition,\nmany liberalized and non-liberalized retail markets have implemented compensation programs for\ncustomer-side distributed generation (DG) and DR to encourage the adoption of behind-the-meter\nrenewable DG and peak load reduction, respectively. In the United States (U.S.), over 40 states adopted\ncompensation programs for customer-side DG, such as net metering [3], and the number of net-metered\ncustomers increased from fewer than 22,000 in 2005 to more than 1,500,000 in 2016 [4,5]. Utilities in the\nCalifornia Independent System Operator (CAISO) area reported 5.4 GW of net-metered distributed\nsolar capacity as of December of 2016 [6]. Moreover, some independent system operators (ISOs) and\nregional transmission organizations (RTOs) in the U.S. have been adopting DR programs for end-user\nretail customers through direct load control [7].\nEurope has also been experiencing significant growth in DERs in the last years. Residential\nPV installations are expected to reach 90 GW by 2021. Belgium currently has around 150 W of PV\nresidential capacity per capita, the highest in Europe [8]. In Australia, small-scale PV systems produced\n3.4% of the country\u2019s total electricity in 2017. More than 20% of the Australian houses are currently\nprovided with PV systems [9].\nAs advanced metering infrastructures (AMIs) become more affordable, accessible, and spread\nin the distribution grid, more entities will take advantage of DERs, transforming conventional loads\ninto smart loads, and conventional buildings into smart buildings and microgrids. Such technologies\nare provided with effective power management and control systems, and communication schemes\nthat promote energy efficiency and allow direct interaction with external agents and systems. Thus,\nconventional passive customers will become active agents in the retail electricity market, by providing\nDERs in efficient and effective ways. Such active agents are defined as DER agents and their main\ntechnical capabilities are described as follows [1]:\n1. DG: Small-scale production of electricity at distribution voltage levels. It can be based on variable\nrenewable sources (e.g., PV systems), or systems that can be dispatched at any time (e.g., small\ngas turbine generators).\n2. Load management (LM): Capability to receive and quickly respond to external signals to\nmanage real-time electricity consumption, perform load shifting and scheduling, etc., through\nsmart metering systems (SMSs), intelligent energy management systems (IEMSs), smart loads,\netc. [10\u201312].\n3. Energy storage systems (ESSs): Capability to import, store, and export electricity to the grid\nvia battery energy storage systems (BESSs), plug-in electric vehicles (PEVs) operating in the\nvehicle-to-grid (V2G) mode, and other energy storage technologies.\nThe management of DERs is performed through IEMSs and SMSs, whereby DER agents can\nreceive and send information, set preferences, and control energy production, consumption, and\nstorage in real-time. Figure 1 illustrates the concept of DER agents in the smart grid environment.\nThe increasing adoption of DERs and SGTs in the distribution grid has led researchers,\npolicy-makers, and other stakeholders to define the concept of transactive energy as a reliable,\naffordable, and sustainable system that promotes the dynamic balance of supply and demand and\nmaximizes the social welfare of all its agents [13]. Under this environment, all decisions have economic\nand/or engineering \u201cvalues,\u201d such as profit or performance, as key operational parameters [14].\nPower system flexibility from both supply and demand sides are becoming a necessity in several\ncountries facing fuel price uncertainties, growth in variable renewable energy production, and higher\nload variability [15]. The management of DERs for power system flexibility is still very limited, but\nEnergies 2019, 12, 491 3 of 24\nis expected to play a big role in the next years, opening opportunities for reforms in retail electricity\nmarkets worldwide.Energies 2018, 11, x FOR PEER REVIEW  3 of 25 \n \nFigure 1. Distributed energy resource (DER) agents in the smart grid environment. \nPower system flexibility from both supply and demand sides are becoming a necessity in \nseveral countries facing fuel price uncertainties, growth in variable renewable energy production, \nand higher load variability [15]. The management of DERs for power system flexibility is still very \nlimited, but is expected to play a big role in the next years, opening opportunities for reforms in \nretail electricity markets worldwide. \nAlthough the recent advances in DG, LM, and ESSs have been transforming the distribution \ngrid in many ways, it is evident that the conventional electric system framework, which includes \nthe physical infrastructure, system operations, and power market operations, does not fully take \nadvantage of the technical and economic benefits that all DERs can provide, and is not ready to \naccommodate and manage the dynamic flow of power and information among the existing and the \nemergent electricity market agents. \nIn the literature, several studies have proposed new methods to integrate DERs in the \nwholesale market [16\u201321] and in the retail market [22\u201327]. Reference [28] provided a comprehensive \nbibliographical survey of recent works related to the next-generation U.S. retail electricity market \nwith consumers and prosumers, which are end users with the ability to produce and consume \nelectricity. \nMost of those proposals, to be implemented successfully, involve important changes in the \nelectric system, such as new market business models, new technologies, and advanced transmission \nand distribution infrastructures. Some of those changes are discussed in [29,30], with great \nemphasis on implications for electric utilities. With the increasing penetration and participation of \nDER agents in the distribution grid, what are the expected technical and economic characteristics, \nchallenges, and needs of the next-generation retail electricity markets? How can DERs integrate \nretail and wholesale markets as well as transmission and distribution grids? To address these open \nquestions in a comprehensive manner and provide researchers and engineers with an overview of \nthe future characteristics, changes, challenges, and future research topics associated with increasing \nmarket integration of DERs, this paper expands the work in [1] by presenting an overview of the \npresent retail electricity market, some recent developments on transactive energy, a comprehensive \nvision of the next-generation retail electricity market, a framework of integrating retail and \nwholesale markets, and the main roles and responsibilities of retail market agents under the \nproposed vision and framework. In addition, this paper contributes to the energy policy research \narea by providing examples of regulatory initiatives in different jurisdictions and discussing \nimportant technical and economic aspects necessary to develop new policies for decentralized \nmarkets with DERs. Although the U.S. has taken the lead in implementing new retail market \nbusiness models with transactive energy mechanisms and most examples in this paper refer to the \nU.S., retail electricity market evolution with widespread DERs is a global trend. Thus, the proposed \nvision and framework can be applied to any retail electricity market without loss of generality. \nFigure 1. Distributed energy resource (DER) agents in the smart grid environment.\nAlthough the recent advances in DG, LM, and ESSs have been transforming the distribution\ngrid in many ways, it is evident that the conventional electric system framework, which includes the\nphysical infrastructure, system operations, and power market operations, does not fully take advantage\nof the technical and economic benefits that all DERs can provide, and is not ready to accommodate and\nmanage the dynamic flow of power and information among the existing and the emergent electricity\nmarket agents.\nIn the literature, several studies have proposed new methods to integrate DERs in the\nwholesale market [16\u201321] and in the retail market [22\u201327]. Reference [28] provided a comprehensive\nbibliographical survey of recent works related to the next-generation U.S. retail electricity market with\nconsumers and prosumers, which are end users with the ability to produce and consume electricity.\nMost of those proposals, to be implemented successfully, involve important changes in the electric\nsystem, such as new market business models, new technologies, and advanced transmission and\ndistribution infrastructures. Some of those changes are discussed in [29,30], with great emphasis on\nimplications for electric utilities. With the increasing penetration and participation of DER agents\nin the distribution grid, what are the expected technical and economic characteristics, challenges,\nand needs of the next-generation retail electricity markets? How can DERs integrate retail and\nwholesale markets as well as transmission and distribution grids? To address these open questions\nin a comprehensive manner and provide researchers and engineers with an overview of the future\ncharacteristics, changes, challenges, and future research topics associated with increasing market\nintegration of DERs, this paper expands the work in [1] by presenting an overview of the present retail\nelectricity market, some recent developments on transactive energy, a comprehensive vision of the\nnext-generation retail electricity market, a framework of integrating retail and wholesale markets, and\nthe main roles and responsibilities of retail market agents under the proposed vision and framework.\nIn addition, this paper contributes to the energy policy research area by providing examples of\nregulatory initiatives in different jurisdictions and discussing important technical and economic\naspects necessary to develop new policies for decentralized markets with DERs. Although the U.S. has\ntaken the lead in implementing new retail market business models with transactive energy mechanisms\nand most examples in this paper refer to the U.S., retail electricity market evolution with widespread\nDERs is a global trend. Thus, the proposed vision and framework can be applied to any retail electricity\nmarket without loss of generality.\nThe remainder of this paper is organized as follows. Section 2 briefly reviews the present retail\nelectricity market, its recent developments, and some transactive energy demonstration projects.\nEnergies 2019, 12, 491 4 of 24\nSection 3 presents a framework and the main characteristics of the next-generation retail electricity\nmarket in the context of DERs. Section 4 describes the challenges and needs that should be addressed as\nwell as potential solutions in the proposed vision and framework. The main roles and responsibilities\nof retail market agents are described in Section 5. A framework of integrating wholesale and retail\nmarkets is presented in Section 6. Finally, relevant conclusions are presented in Section 7.\n2. Present Retail Electricity Market and Recent Developments\nThe retail electricity market is the economic platform that facilitates the provision of electricity\nto retail customers. Historically, most retail customers worldwide were subjected to electricity rates\ndefined by electric utilities and regulated by governmental entities. However, the liberalization of\nsome retail electricity markets has promoted competition and diversification of services, enabling\ncustomers to choose from different services and suppliers. According to a study of the retail electricity\nin the U.S. [31], the effect of moving to a competitive retail electricity market was mixed across states,\nbut led to lower electricity prices in states with high customer participation, and higher prices in\nstates with little customer participation. In that study, customer participation was referred only to the\nability to switch electricity suppliers. Liberalization made the retail electricity market more efficient\nby lowering the markup of retail prices over wholesale costs. In addition, the development of DER\ntechnologies enabled new types of retail tariffs and mechanisms for the integration of DR and DG into\nthe distribution grid.\nCurrent DR programs adopted worldwide can be classified into price-based DR, in which\ncustomers control their energy consumption in response to pricing arrangements, and incentive-based\nDR, in which retail customers directly control or let grid operators control part of their loads in\nexchange for financial incentives. The present price-based DR programs in most retail markets include\ntime-of-use (TOU) pricing, real-time pricing (RTP), critical peak pricing (CPP), and increasing block\nprice (IBC). The present incentive-based DR programs include direct load control (DLC), emergency\ndemand response (EDR), and demand bidding/buyback (DB) [22]. Table 1 describes the main\ncharacteristics of these DR programs.\nDG is integrated into the present retail electricity market worldwide primarily through net\nmetering and feed-in tariff mechanisms. Both mechanisms credit small-scale DG producers, such\nas residential and commercial facilities with solar PV systems, for the electricity they add to the\ngrid to which they are connected. The term net metering refers to the value of the difference\nbetween the energy delivered and received at a retail customer, which is usually measured via a\nunidirectional meter that only measures electricity consumption. In feed-in tariff mechanisms, the\nrate utilities pay for the electricity exported to the grid might be different from the consumption\nrate. This requires a bidirectional meter that measures both electricity generation and consumption.\nIn many states and countries, retail customers are paid the full retail rate for the energy exported to\nthe grid. However, as the number of self-producers of energy increases every year, there has been\nincreasing discussions among electric utilities, regulatory commissions, industry stakeholders, and\nretail customers concerning DG compensation tariffs and the real value of DG for both the retail markets\nand distribution grids. On the one hand, some utilities argue that self-producing retail customers are\nnot paying for grid and consumer costs, thus shifting costs onto other retail customers [32]. On the\nother hand, a coalition of partners in the solar energy industry claims that net metering tariffs should\nnot be underestimated; otherwise, it would discourage customers from generating their own clean\nelectricity [33]. In 2014, Minnesota became the first state in the U.S. to adopt a \u201cvalue of solar\u201d policy,\nby defining solar energy tariffs based on all the costs avoided by utilities when using solar energy from\nretail customers [34]. Other states, such as Arizona, Maine, and Indiana are currently reviewing their\nregulation policies on net metering and defining new tariff schemes for DG.\nIn contrast to traditional market integration schemes for DERs, transactive energy approaches\nhave been receiving increasing attention from both industry and academia in the last few years due to\nthe need for greater integration of DERs into the electricity grids as well as new market mechanisms\nEnergies 2019, 12, 491 5 of 24\nto facilitate such integration. It should be noted that in this paper \u201celectricity grids\u201d include the\ncyber-physical infrastructure of distribution and transmission grids.\nTable 1. Main demand response (DR) programs in the present retail electricity market. TOU:\ntime-of-use; RTP: real-time pricing; CPP: critical peak pricing; IBC: increasing block price (IBC);\nDLC: direct load control; EDR: emergency demand response; DB: demand bidding/buyback.\nPrice-Based DR Incentive-Based DR\nDR\nProgram Characteristics\nDR\nProgram Characteristics\nTOU\nRetail rates depend on the time of the day (e.g.,\npeak and off-peak), season (e.g., summer and\nwinter), and day of a week (e.g., weekday,\nweekend, and holiday). Retail customers have\nfull knowledge on TOU rates before adjusting\ntheir consumption pattern.\nDLC\nGrid operators remotely\ncontrol customers\u2019 loads\nduring the periods of high\nelectricity prices or when the\ngrid reliability is threatened.\nRTP\nRetail rates reflect the real-time wholesale market\nprice changes at every hour or half-hour. Some\nRTP programs simply pass along the hourly\nwholesale market prices with no markup\nwhereas other programs define a retail rate based\non the wholesale market price variations.\nEDR\nEDR programs usually offer\nrebates or other incentives to\nretail customers for load\nreduction during critical\nevents. Retail rates are\ngenerally not changed.\nCPB\nRetail rates are significantly raised during times\nof critical events (e.g., periods of extremely high\nwholesale market prices and power system\nemergency conditions). CPP programs are\nusually limited to a fixed number of critical\nevents during a specific time period.\nDB\nLarge retail customers provide\nload curtailment at a price at\nwhich they are willing to be\ncurtailed.\nIBP\nRetail rates are divided into several increasing\ntiers or blocks. Retail customers are charged\nbased on the electricity consumption levels and\nthe prices for the corresponded blocks.\nSome demonstration projects in the U.S. analyzed some values of DERs in a transactive energy\nframework. Some of these projects include the Pacific Northwest Smart Grid Demonstration in\nthe Olympic Peninsula and the GridSMART Demonstration Project in Ohio. The former evaluated\ntechnologies and proposed a regional transactive coordinating system to optimize the energy dispatch\nand the demand management in an environment replete with intermittent energy sources and SGTs [35].\nThe latter integrated several customer-oriented SGTs and studied the impacts of different DR pricing\nmechanisms to the grid reliability and to customers\u2019 electricity bill [36]. Both projects involved several\nentities such as utilities, universities, and technology companies. They concluded that transactive\nmechanisms contributed to peak power demand and energy cost reductions under high customer\nengagement. Some other demonstration projects under development include the National Institute of\nStandards and Technology (NIST) Transactive Energy Challenge in the U.S. [37] and the Ecogrid 2.0 in\nDenmark [38]. Additionally, the Gridwise Architecture Council (GWAC) has been taking an important\nrole in studying transactive energy projects. The GWAC is an independent organization supported by\nthe U.S. Department of Energy that includes representatives from different sectors of the U.S. electric\nsystem [39].\nFurthermore, some U.S. states have been adopting transactive energy approaches in their planning\nand vision for the future. For instance, the Reforming the Energy Vision (REV) strategy intends to\nchange the way energy is produced, consumed, and transacted throughout the state of New York.\nThis program intends to reduce 40% of total carbon emissions, reduce 23% of the energy consumption\nin buildings, and generate 50% of the total electricity from renewable energy sources by 2030 through\nvarious approaches, including transactive energy initiatives that allow interactions between consumers\nEnergies 2019, 12, 491 6 of 24\nand self-producers of energy. The REV project intends to make market agents take full advantage\nof every type of energy resource [40]. Moreover, in California, environmental and energy policies\ncombined with increasing integration of DERs are forcing substantial changes in the local electricity\nmarket [41]. CAISO is currently implementing a new market mechanism to integrate DERs into its\nwholesale market through new market agents, called distributed energy resource providers (DERPs).\nSuch agents will be able to aggregate DERs at the retail level and provide energy and ancillary services\nin the wholesale market. This new mechanism will provide more trading options for retail market\nagents and enable more integration of DERs into the grid [42]. Other initiatives, such as the Distribution\nResource Plan (DRP) and the Integrated Distribution Energy Resources (IDER) efforts will explore\ntransactive energy mechanisms, among various alternatives, to support services provided by DERs\nand improve the reliability of the Californian distribution grids [43]. In the European Union (E.U.), the\nRenewable Energy Directive is currently establishing policies for the promotion and production of\nrenewable energy. This directive intends to ensure that at least 27% of the electricity consumption in\nE.U. is supplied by renewable energy sources by setting specific targets for each country. E.U. countries,\non the other hand, have been developing action plans that include investments and policies to facilitate\nmarket integration of DERs to meet those targets [44].\nFinally, there is a growing interest in the global industry in exploring the utilization of bulk\nelectricity market concepts to provide economic signals that can be used to compensate DER-driven\ntransactions. For instance, the introduction of distribution locational marginal pricing (DLMP) [45\u201349]\nhas received growing attention as an option to estimate the value of DER and evaluate the feasibility\nof non-wire alternatives (NWAs).\n3. Key Characteristics of the Next-Generation Retail Electricity Market in the Context of DERs\nThe recent retail market developments described in the previous section as well as the trends and\ntechnical studies for the market integration of DERs mentioned in Section 1 indicate that the current\nretail electricity market is evolving from a centralized and passive environment to a decentralized and\ninteractive platform, where market participants can interact with each other and provide technical\nservices to the electricity grid. This entails not only in new business models, but also in innovative\nregulatory paradigms and infrastructure upgrades. Based on such studies, trends, and developments,\nan expanded vision of the next-generation retail electricity market in the context of DERs is illustrated\nin Figure 2. This vision is formed by key characteristics as well as challenges and needs that will\nrequire future research and development [1].\nThe key characteristics of the proposed vision are described as follows:\n1. Operation optimization: Market agents will be able to minimize costs, maximize revenues,\nand optimize the grid operation through timely, cost-effective, and safe transactive energy\nmechanisms that will promote the effective, reliable, and efficient integration of DERs for\ncommercial and technical purposes. Furthermore, an efficient integration between retail and\nwholesale markets will allow DERs to be aggregated and effectively integrated into the wholesale\nmarket and the transmission system. The optimal management of DERs will facilitate the\nprovision of affordable and fast-response ancillary services to distribution and transmission\ngrids. The implementation of this paradigm would require high levels of real-time monitoring,\nprotection, automation, and control to keep track and process potentially millions of transactions.\nThese are the capabilities that are not currently available in distribution grids and would\nrequire large investments in enabling intelligent infrastructure (e.g., sensors, information\nsystems, etc.). The approval and recovery of investments of this magnitude typically involves\nthorough regulatory scrutiny. Therefore, this vision will need to be accompanied by regulatory\nmodernization and modern recovery mechanisms that should go beyond traditional approaches\nbased on cost of service.\nEnergies 2019, 12, 491 7 of 24\n2. Flexibility: A flexible retail electricity market will be ready to accommodate new technologies\nand market agents by enhancing and expanding its infrastructure. Market agents will\ncope with uncertainties, such as electricity demand, electricity prices, and renewable energy\ngeneration through effective forecasting techniques and comprehensive decision-making\nstrategies. In addition, a flexible retail electricity market will utilize its local resources to manage\nuncertainties, variations, and unforeseen events over various time horizons. Here it is important\nto emphasize that flexibility must be accompanied by robustness to handle the uncertainties\nderived from market complexity, which may be difficult to capture even through advanced\nforecasting techniques.\n3. Customer integration: A fully integrated retail electricity market will be designed to maximize\nthe social welfare of all market agents, accommodate a large number of diverse agents, and\nsatisfy their needs and preferences in a competitive environment. Market platforms should be\ndesigned to allow the active participation and interaction of all agents and avoid market power\nand conflicts of interest by considering the strengths and limitations of each agent. An integrated\nretail electricity market will also promote social engagement to facilitate the participation of\nagents from different socio-economic strata. This is a critical task, given that the proliferation\nof DER and the introduction of related concepts such as microgrids, may prompt end-users to\nconsider the possibility of defecting from the grid or to largely use it as a backup source [50].\nTherefore, a customer-focused market that has the capability to provide customized solutions to\nend users may help retain end users.\n4. Sustainability: A sustainable retail electricity market will maximize the use of clean and renewable\nenergy sources and promote energy efficiency initiatives through market mechanisms designed\nto reduce greenhouse gas emissions, mitigate load and network losses, and incentivize the use of\nenvironment-friendly technologies that will contribute to sustainability and energy efficiency.\nEnergies 2018, 11, x FOR PEER REVIEW  7 of 25 \nprovide technical services to the electricity grid. This entails not only in new business models, but \nalso in innovative regulatory paradigms and infrastructure upgrades. Based on such studies, \ntrends, and developments, an expanded vision of the next-generation retail electricity market in the \ncontext of DERs is illustrated in Figure 2. This vision is formed by key characteristics as well as \nchallenges and needs that will require future research and development [1]. \n \nFigure 2. Vision of the next-generation retail electricity market [1]. PEVs: plug-in electric vehicles; \nSMSs: smart metering systems; IEMs: intelligent energy management systems. \nThe key characteristics of the proposed vision are described as follows: \n1. Operation optimization: Market agents will be able to minimize costs, maximize revenues, and \noptimize the grid operation through timely, cost-effective, and safe transactive energy \nmechanisms that will promote the effective, reliable, and efficient integration of DERs for \ncommercial and technical purposes. Furthermore, an efficient integration between retail and \nwholesale markets will allow DERs to be aggregated and effectively integrated into the \nwholesale market and the transmission system. The optimal management of DERs will \nfacilitate the provision of affordable and fast-response ancillary services to distribution and \ntransmission grids. The implementation of this paradigm would require high levels of real-\ntime monitoring, protection, automation, and control to keep track and process potentially \nmillions of transactions. These are the capabilities that are not currently available in \ndistribution grids and would require large investments in enabling intelligent infrastructure \n(e.g., sensors, information systems, etc.). The approval and recovery of investments of this \nmagnitude typically involves thorough regulatory scrutiny. Therefore, this vision will need to \nbe accompanied by regulatory modernization and modern recovery mechanisms that should \ngo beyond traditional approaches based on cost of service. \n2. Flexibility: A flexible retail electricity market will be ready to accommodate new technologies \nand market agents by enhancing and expanding its infrastructure. Market agents will cope \nwith uncertainties, such as electricity demand, electricity prices, and renewable energy \ngeneration through effective forecasting techniques and comprehensive decision-making \nstrategies. In addition, a flexible retail electricity market will utilize its local resources to \nmanage uncertainties, variations, and unforeseen events over various time horizons. Here it is \nFigure 2. Vision of the next-generation retail electricity market [1]. PEVs: plug-in electric vehicles;\nSMSs: smart metering systems; IEMs: intelligent energy management systems.\nEnergies 2019, 12, 491 8 of 24\n4. Opportunities, Challenges, and Needs\nIn order to achieve the key characteristics described in Section 3, the present retail electricity\nmarket must be reformed not only to bring new opportunities for DERs integration but also to properly\naddress several challenges and needs. Such aspects are described as follows [1]:\n4.1. New Business Models\nAs the number of DER agents increase in the distribution grid, comprehensive business models\ndesigned to accommodate, integrate, and allow the dynamic interaction of all retail electricity market\nagents will be needed. Such business models include clear rules and plans describing the market\nparticipants, their roles and interactions, products and services, as well as strategies to generate\nrevenue, minimize costs, and maximize profits. The main elements and aspects of the new business\nmodels are described as follows:\n1. Regulatory Modernization: The next-generation retail electricity market will depend massively\non regulatory modernization in different jurisdictions. This includes market liberalization,\ndecentralization as well as policies and incentives aimed to reduce the current dependency on\ncentralized and pollutant power plants and incentivize the use and adoption of DERs. Today,\nin most countries, the concept of retail market liberalization and decentralization refers to the\ncapacity of consumers to have freedom and independence to choose electricity suppliers and\nservices according to their needs and preferences. Such a paradigm has promoted competition\nand cost reductions and increased innovation. However, in the context of DERs, liberalization and\ndecentralization also include the provision of DG, LM, and ESSs for important energy services in\na decentralized market framework. The increasing integration of DERs makes the retail market\nliberalization and decentralization even more challenging due to several technical and economic\ncomplexities, and uncertainties that are introduced. The extended process of retail electricity\nmarket liberalization and decentralization is not a simple event. It is a long-term process that,\nto be successful, requires coordinated planning among governmental entities and all other\ninvolved sectors and agents. Furthermore, regulatory changes along with plans for investments\nin infrastructure and technology necessary to ensure all the characteristics described in Section 3\nshould take into account all possible economic and social benefits. For instance, aspects such\nas innovation, expected societal benefits of renewable integration, resiliency improvement, and\ncustomer choice must need to be accounted for in project justification. In this regard, the\nRIIO model (Revenue = Incentives + Innovation + Outputs) implemented by Ofgem, the U.K.\nregulatory agency, represents an initial step in this direction [51].\n2. New Agents: The increasing adoption of SGTs and DERs has brought several DER agents in\nthe distribution grid. Such agents include smart buildings, microgrids, and PEVs. However,\ntheir current participation in the retail electricity market is very limited since they are still under\nprograms and tariffs imposed by electric utilities. Such programs and tariffs limit the active\nmarket participation and the provision of important energy services from DER agents, which\ncan provide technical and economic benefits to the grid and to other market agents. The studies\nin [22,52\u201354] illustrated how load serving entities (LSEs), such as utilities and competitive retailers,\ncan benefit from integrating DERs in their decision-making models and, thus, mitigate the impacts\nof wholesale market volatility on their procurement costs. However, the massive adoption\nof DERs will depend directly on governmental subsidies and tax breaks designed to reduce\ngreenhouse gas emissions and control the electricity demand growth. Such aspects are still big\nchallenges in countries with high dependency on centralized and nonrenewable generation and\nunclear or inexistent decarbonization targets. The increasing number of DER agents will give\nrise to new entities to operate the distribution grid and facilitate market mechanisms in the\nretail level. In most countries, the electricity market is categorized into wholesale and retail\nmarkets, and the power grid is divided into transmission and distribution grids with different\nEnergies 2019, 12, 491 9 of 24\nagents performing technical and economic operations. In the U.S., for example, both wholesale\nmarket and transmission grid operations are performed by ISOs/RTOs. Electric utilities, on\nthe other hand, coordinate both retail market and distribution grid operations. The concept of\ndistribution system operator (DSO) has been extensively discussed in the academic, industry,\nand regulation sectors [55]. The DSO is envisioned as an entity that can operate the distribution\ngrid, facilitate transactions involving DERs in a neutral retail market, and work cooperatively\nwith existing transmission grid and wholesale market operators [56\u201363]. This concept is different\nfrom some present European utilities also called DSOs, which mainly operate the distribution\ngrid and facilitate customer choice of load serving entities, with no complete interaction with\ntransmission service providers and wholesale market operators [57]. Two types of DSOs have\nbeen extensively discussed in the literature. The utility DSOs (UDSOs) are referred to as evolved\nelectric utilities, which will have expanded responsibilities and capabilities to provide new\nproducts and services to retail customers and provide new ways for DER owners to increase\nthe return on their investments [64,65]. The independent DSOs (IDSOs), on the other hand,\nare referred to as independent and regulated entities that are not affiliated with any other\nelectricity market participant [66], and are responsible for coordinating technical operations in the\ndistribution system and facilitating open access retail markets for DERs, similar to how ISO/RTOs\noperate the transmission grids and coordinate the wholesale market in the U.S. In the IDSO\nconcept, utilities continue to own and maintain the physical assets in the distribution grid [60].\nA complete discussion of the roles and responsibilities of the market agents in the next-generation\nretail electricity market is provided in Section 5.\n3. Transactive energy mechanisms: To promote liberalization and decentralization, and\naccommodate the increasing number of DER agents in the retail electricity markets, effective\ntransactive energy mechanisms should be developed to monetize the value of DERs. Examples of\ntransactive energy mechanisms include interactive bidding and offering platforms, and market\nclearing models capable to incorporate uncertainties from DG production, electricity demands,\nand wholesale market prices over different time horizons [67]. To ensure the real-time balancing\nof supply and demand, minimize the impacts of abrupt changes and unforeseen events in the\ndistribution grid, and ensure that DER agents can respond to such events promptly, the time\nframe of each transactive energy mechanisms should be determined properly. The profitability\nof flexible products and services via transactive energy mechanisms is a critical point that\nshould be studied carefully before implementing new retail market business models. Moreover,\nDSOs should be able to review, approve, deny, and modify a large number of transactions by\nconsidering their impacts on the distribution grid [68]. This will be possible with high speed\nsensing and processing capabilities. All transactive energy mechanisms should promote the\ninformation exchange among agents, facilitate the receipts and payments for energy services in\nreal-time, and ensure price transparency. Thus, the real-time cost of power and ancillary services\ncan be accessible to all market agents.\n4. Competitiveness: The increase in DER use and adoption will stimulate competition in two ways.\nFirst, the incentives, subsidies, and other regulatory programs aimed to promote local energy\nefficiency, flexibility, and sustainability will increase the competitiveness of DERs over centralized\nand non-renewable generation units. Without such regulatory programs, system operators are\nprone to use more centralized generation units since the widely use of DERs increases power\nsystem complexity and requires substantial infrastructure upgrades. Second, the creation of new\nbusiness models and transactive energy mechanisms will stimulate retail market competition\nand, thus, promote lower electricity prices and better services. However, to ensure the social\nwelfare maximization, the market rules and mechanisms should be clear, transparent, and fair to\nall market agents.\nEnergies 2019, 12, 491 10 of 24\n4.2. Innovative DER Technologies\nThe massive adoption of DERs in the distribution grid will rely on innovative technologies aimed\nto increase efficiency, resilience, and flexibility to both technical and market operations in affordable\nways. Existing technologies will be enhanced and expanded to provide additional functionalities.\nSome opportunities for enhancements and advances in DER technologies are described as follows:\n1. DG Systems: In the last few years, DG systems have become more efficient and affordable.\nPV systems are currently the most used DG systems worldwide. Grid-tied PV systems are\ndirectly connected to the grid at all times and do not use storage systems. On the other hand,\nhybrid PV systems can operate in grid-tied form, charge batteries during the periods of low\nelectricity prices, discharge batteries during the periods of high electricity prices, and even operate\nin the off-grid mode. Figure 3 shows the residential and commercial PV costs evolution from\n2010 to 2018 in the U.S. [69]. In 2016, the National Renewable Energy Laboratory (NREL) and the\nSwiss Center for Electronics and Microtechnology (CSEM) have jointly set a new world record for\nconverting non-concentrated sunlight into electricity with 29.8% efficiency using a dual-junction\nIII-V/Si solar cell [70]. However, the reduction in the size of solar modules and the adaptability\nand customization to different places and surfaces are examples of improvements required to\nsatisfy customer needs and preferences. Solar shingles and tiles currently in development by\nTesla [71] may be a potential solution for these issues if proven to be cost-effective and durable\nfor different environments. Moreover, other types of existing clean DG systems such as wind\nand hydrogen fuel cell need improvements in flexibility and affordability. The development of\ninnovative and clean DG system will promote a diversified portfolio of sustainable energy in\nthe distribution grid. Furthermore, the power electronics of DG systems should be designed to\nprovide high quality power supply, voltage regulation, and ancillary services in effective ways.\nParticularly, PV inverters should mitigate voltage rises, caused by reverse power flow from PV\nsystems, through effective control strategies [72].\n2. ESSs: Lithium-ion batteries are a good example of electrical energy storage technologies that\nhave been improved significantly in the last few years. However, not all technologies are widely\navailable and economically feasible. Cost, specific energy, specific power, safety, performance,\nand life span of ESSs still need improvements and should be considered carefully for ESSs to\nbecome widely adopted in the distribution grid and, thus, increase the flexibility of variable DG.\nThe next-generation retail electricity market will rely on efficient and affordable energy storage\ntechnologies to manage a large share of intermittent resources. Furthermore, other existing ESSs\nsuch as flywheels and supercapacitors may also be improved and adapted to DER agents in the\ndistribution grid.\n3. PEVs: The recent advances in technologic, affordable, and customer-oriented PEV models boosted\nPEV sales in the last few years. The total U.S. PEV sales increased from fewer than 20,000 in 2009\nto nearly 200,000 in 2017 [73]. PEVs can provide important DERs to the grid since they can act\nas loads and dispatchable ESSs. When not needed for transportation, PEVs can participate in\nDR programs and contribute to peak load reduction while being charged and can also operate\nin the vehicle-to-grid (V2G) mode, when charged, to support the electricity grid needs such as\nenergy dispatch, voltage regulation, and reactive power support [74,75]. In addition, PEVs can\nalso operate in the vehicle-to-building mode under a grid voltage [76], and exchange power\nwith charging stations and other PEVs. Some key factors that will allow PEVs to become\nlarge-scale DER providers include evolution of ESSs, advanced information and communication\ntechnologies, regulatory initiatives, as well as public and private incentives and investments\naimed to improve technical performance and grid interoperability with reduced costs [74,77].\nUpgrades on functionalities and grid interconnection schemes of existing PEV charging stations\nrepresent an initial step towards this end.\nEnergies 2019, 12, 491 11 of 24\n4. Microgrids: DER proliferation and growing requirements from end users regarding reliability,\nresiliency, power quality, and efficiency have prompted a growing interest in both utility and\ncustomer-owned microgrids as a means to take advantage of some of the key benefits of DERs.\nWhile DER technology, analysis, standards, and relevant technical aspects required for microgrid\ndeployment are evolving fast, existing regulatory frameworks are not ready to address the\nchallenges associated with microgrid implementation. Aspects such as DER compensation,\nperformance guarantees, liabilities, and participation of third-party providers in community or\nutility microgrids are areas that are still either undefined or not clearly defined, depending on\nthe jurisdiction. This can only be addressed with clear viability studies and pilot projects that\nrequire efforts and collaboration from different stakeholders. Figure 4 illustrates the potential\ncomplexity of this endeavor, where every DG is expected to be compensated according to the\nvalue and benefits it provides to the grid and transactions. Estimating these revenue streams\nrequires the ability to potentially process massive amounts of data to ensure that individual profit\nmaximization objectives do not trump the overall operational performance goals.\n5. IEMSs and SMSs: The coordination of energy production, consumption, storage, and the energy\nexchange with the grid is performed through IEMSs and SMSs, which allow DER agents to\nbe active agents in the retail electricity market. Future IEMSs and SMSs will be designed to\nminimize procurement costs, maximize revenues and energy efficiency actions while maintaining\nacceptable level of customers\u2019 comfort, and provide two-way flow of power and information that\nwill allow DER agents to interact directly with other market agents. Decision-making algorithms\nwill need to be designed and embedded in IEMSs and SMSs to satisfy customer preferences\nand provide services to the grid. Transactive control, also called market-based control, might\nbe a potential solution to allow IEMSs and SMSs interact more actively on market operations.\nTransactive control is a distributed control approach that uses market mechanisms to engage\ngenerating units, storage systems, and flexible loads to provide energy services to the grid. In this\napproach, DER agents and DSOs would only exchange the prices and the quantities of electricity\nto be purchased/sold during a certain period, thus preserving the preferences and the privacy\nof DER agents [78]. Some relevant transactive control approaches for commercial buildings,\nresidential buildings, and PEVs are presented in [78\u201382], respectively.\n6. Smart loads: Future low-voltage loads, such as electric vehicles, heating, ventilation, and air\nconditioning (HVAC) systems, lighting systems, and household appliances, should be designed\nto provide affordability, flexibility, energy efficiency, and easy communication with IEMSs, SMSs,\nand DSOs through adaptive and timely power control. Flexibility can be achieved through the\nprovision of different levels of comfort and user preferences in interactive ways.Energies 2018, 11, x FOR PEER REVIEW  11 of 26 \n  \n(a) (b) \nFigure 3. (a) U.S. residential photovoltaic (PV) cost evolution [69]; (b) U.S. commercial PV cost \nevolution [69]. \n2. ESSs: Lithium-ion batteries are a good example of electrical energy storage technologies that \nhave been improved significantly in the last few years. However, not all technologies are \nwidely available and economically feasible. Cost, specific energy, specific power, safety, \nperformance, and life span of ESSs still need improvements and should be considered carefully \nfor ESSs to become widely adopted in the distribution grid and, thus, increase the flexibility of \nvariable DG. The next-generation retail electricity market will rely on efficient and affordable \nenergy storage technologies to manage a large share of intermittent resources. Furthermore, \nother existing ESSs such as flywheels and supercapacitors may also be improved and adapted \nto DER agents in the distribution grid. \n3. PEVs: The recent advances in technologic, affordable, and customer-oriented PEV models \nboosted PEV sales in the last few years. The total U.S. PEV sales increased from fewer than \n20,000 in 2009 to nearly 200,000 in 2017 [73]. PEVs can provide important DERs to the grid \nsince they can act as loads and dispatchable ESSs. When not needed for transportation, PEVs \ncan participate in DR programs and contribute to peak load reduction while being charged and \ncan also operate in the vehicle-to-grid (V2G) mode, when charged, to support the electricity \ngrid needs such as energy dispatch, voltage regulation, and reactive power support [74,75]. In \naddition, PEVs can also operate in the vehicle-to-building mode under a grid voltage [76], and \nexchange power with charging stations and other PEVs. Some key factors that will allow PEVs \nto become large-scale DER providers include evolution of ESSs, advanced information and \ncommunication technologies, regulatory initiatives, as well as public and private incentives \nand investments aimed to improve technical performance and grid interoperability with \nreduced costs [74,77]. Upgrades on functionalities and grid interconnection schemes of existing \nPEV charging stations represent an initial step towards this end. \n4. Microgrids: DER proliferation and growing requirements from end users regarding reliability, \nresiliency, power quality, and efficiency have prompted a growing interest in both utility and \ncustomer-owned microgrids as a means to take advantage of some of the key benefits of DERs. \nWhile DER technology, analysis, standards, and relevant technical aspects required for \nmicrogrid deployment are evolving fast, existing regulatory frameworks are not ready to \naddress the challenges associated with microgrid implementation. Aspects such as DER \ncompensation, performance guarantees, liabilities, and participation of third-party providers \nin community or utility microgrids are areas that are still either undefined or not clearly \ndefined, depending on the jurisdiction. This can only be addressed with clear viability studies \nand pilot projects that require efforts and collaboration from different stakeholders. Figure 4 \nillustrates the potential complexity of this endeavor, where every DG is expected to be \ncompensated according to the value and benefits it provides to the grid and transactions. \nEstimating these revenue streams requires the ability to potentially process massive amounts of \nFigure 3. (a) U.S. residential photovoltaic (PV) cost evolution [69]; (b) U.S. commercial PV cost\nevolution [69].\nEnergies 2019, 12, 491 12 of 24\nEnergies 2018, 11, x FOR PEER REVIEW  12 of 25 \nmarket mechanisms to engage generating units, storage systems, and flexible loads to provide \nenergy services to the grid. In this approach, DER agents and DSOs would only exchange the \nprices and the quantities of electricity to be purchased/sold during a certain period, thus \npreserving the preferences and the privacy of DER agents [78]. Some relevant transactive \ncontrol approaches for commercial buildings, residential buildings, and PEVs are presented in \n[78\u201379], [80], and [81\u201382], respectively. \n6. Smart loads: Future low-voltage loads, such as electric vehicles, heating, ventilation, and air \nconditioning (HVAC) systems, lighting systems, and household appliances, should be \ndesigned to provide affordability, flexibility, energy efficiency, and easy communication with \nIEMSs, SMSs, and DSOs through adaptive and timely power control. Flexibility can be \nach ved through the provision of different levels of comfort and user preferences in \ninteractive ways. \n \nFigure 4. Potential microgrid conceptual design and applications. \n4.3. Grid Infrastructure and Operations \nPresently, a large amount of DERs are behind-the-meter assets that are \u201cinvisible\u201d to grid \noperators due to limited distribution system awareness. These DERs \u201cmask\u201d the load tracked by \nmeters, thus making load forecasting and power system operations even more challenging [83]. The \nexisting transmission and distribution grid infrastructures are not ready to accommodate the \nincreasing number of DERs and allow their transition from passive customers to active retail \nmarket agents. Several advances in grid infrastructure and operations will be needed in the \nproposed vision of the next-generation retail electricity market to ensure the efficiency, reliability, \nand resiliency of distribution grids and support the needs of transmission grids through energy \nservices coordinated by DSOs and transmission grid and wholesale market operators. Such \nadvances are summarized into five aspects as follows: \n1. Control and optimization: The complexities associated with grid integration of DERs, \ntransactive energy approaches, and the implementation of DSOs will challenge the existing \ncontrol and optimization architectures in the electricity market. In particular, future DSOs will \nneed to deal with a great number of DER agents and energy transactions in different buses of \nFigure 4. Potential microgrid conceptual design nd applications.\n4.3. Grid Infrastructure and Operations\nPresently, a large amount of DERs are behind-the-meter assets that are \u201cinvisible\u201d to grid operators\ndue to limited distribution system awareness. These DERs \u201cmask\u201d the load tracked by meters, thus\nmaking load forecasting and power system operations even more challenging [83]. The existing\ntransmission and distribution grid infrastructures are not ready to accommodate the increasing\nnumber of DERs and allow their transition from passive customers to active retail market agents.\nSeveral advances in grid infrastructure and operations will be needed in the proposed vision of the\nnext-generation retail electricity market to ensure the efficiency, reliability, and resiliency of distribution\ngrids and support the needs of transmission grids through energy services coordinated by DSOs and\ntransmission grid and wholesale market operators. Such advances are summarized into five aspects\nas follows:\n1. Control and optimization: The complexities associated with grid integration of DERs, transactive\nenergy approaches, and the implementation of DSOs will challenge the existing control and\noptimization architectures in the electricity market. In particular, future DSOs will need to\ndeal with a great number of DER agents and energy transactions in different buses of the\ndistribution grid by producing adaptive control actions. Some of the technical aspects that\nshould be considered in the decision-making strategies of DSOs include reactive supply and\nvoltage control (Volt/Var control), self-healing actions, and many power flow constraints [84].\nOn the market operations, DSOs should operate pricing mechanisms that reflect the real cost\nof electricity in each distribution node, such as market clearing mechanisms with DLMP that\nreflect the real-time value of DERs in the distribution grid. In general, all retail market agents\nshould be able to collect, store, and analyze large sets of data through advanced architectures for\ndata acquisition, transmission, storage, and processing. Big data analytics will play an important\nrole for both technical and market operations in the distribution grid [85,86]. An innovative\nsupervisory control and data acquisition (SCADA) system based on the Internet of Things (IoT)\nEnergies 2019, 12, 491 13 of 24\nmay be a potential solution to enable the observability and controllability of multiple DERs in the\ndistribution grid [64].\n2. Grid expansion planning: Transmission and distribution grid expansion planning analyzes the\nexpansion or reinforcement needs of an existing infrastructure to adequately serve system loads\nwith minimal cost and acceptable quality standards over a certain time horizon [87]. The massive\nand widespread penetration of DERs in the distribution grid will bring more uncertainties and\nchallenges to the transmission and distribution grid expansion planning strategies. The proper\nintegration of DERs along with the development of transactive energy mechanisms may help\ndefer investments on costly distribution and transmission grid assets. The REV strategy is a\npractical example of grid expansion planning considering DERs. This strategy focuses on the\nintegration of DERs and nontraditional approaches, also referred to as NWAs, into the planning\nof the distribution grid in the state of New York [88]. Moreover, new methodologies for increasing\nthe hosting capacity (i.e., the maximum amount of DERs that can be accommodated without\njeopardizing the system) will need to be developed. This can be addressed with technical studies\nand methodologies adaptable to different power system topologies and scenarios. Future grid\nexpansion planning mechanisms should take into account different DER penetration scenarios\nand ensure the long-term reliability of transmission and distribution grids.\n3. Forecasting: The uncertainties associated with the variability of short-term renewable energy\nproduction, energy consumption, energy storage levels, and electricity prices will challenge\ntechnical and market strategies in the distribution grid, thus requiring the development of\nadvanced and accurate forecasting techniques to improve the decision-making strategies of\nretail market agents and allow the management of risks caused by unforeseen events [89].\nNew computational intelligence approaches capable of considering a vast number of uncertainties\nmay be a potential solution towards this end.\n4. Communications: Transactive energy mechanisms should be able to handle the vast amount\nof data coming from DER agents dispersed in the distribution grid and real-time information\nfrom wholesale markets and transmission grids. This will require advanced communication\ninfrastructures as well as interconnectivity, interoperability, and scalability capabilities to allow\nreal-time information exchange among retail market agents in different points of the distribution\ngrid. Advanced wireless communication infrastructures with standard communication protocols\nwill be essential to ensure information collection, dissemination, processing, and security [90,91].\nEnergy Internet (EI) communication schemes may be a potential solution to allow effective\ncommunications and transactive energy mechanisms among market agents. EI, which is\nconsidered the evolution of smart grid, is an integrated grid of DERs, real-time monitoring,\ninformation sharing, and market transactions that provides energy packing and routing functions,\nsimilar to the Internet [92\u201394].\n5. Cybersecurity: As the communication networks become more interconnected and interoperable,\nthey become more vulnerable to deliberate attacks, such as those from disgruntled employees,\nespionage, and terrorists, as well as inadvertent compromises of the information systems due\nto natural disasters, equipment failures, and human errors. Such vulnerabilities might allow\nattackers to penetrate a network and destabilize the system in several ways [95]. In addition,\nin the event of an unauthorized disclosure and access to private and confidential data, market\nagents can orient their strategies to gain advantage illicitly and, thus, destabilize competitive\nenergy trading mechanisms. Prevention should be the main goal, but preparation to respond\nand recover quickly should also be carefully planned. This will require advanced monitoring,\nsensing, and control mechanisms as well as standardized authentication and authorization\nstrategies to ensure the system security and integrity [95]. Blockchain and smart contracts may\nbe a potential solution to facilitate auditable multiparty transactions based on prespecified rules\nbetween market agents and, thus, increase the trustworthiness, integrity, and resilience of energy\ntransactions [96]. Recently, the U.S. Department of Energy announced over $20 million awards\nEnergies 2019, 12, 491 14 of 24\nto national laboratories and partners to conduct cybersecurity projects for the energy sector.\nAmong such projects, the KISS (Keyless Infrastructure Security Solution) project, to be conducted\nby the Pacific Northwest National Laboratory, will develop blockchain cybersecurity technology\nfor DERs at the grid\u2019s edge [97].\n4.4. Distributed Grid Services\nThe next-generation retail electricity market will not only open economic transactions involving\nDERs, but also maximize the benefits of DERs to transmission and distribution grids through energy\nservices designed to enhance and support the grid reliability and resilience. The main challenges and\nneeds associated with the implementation of such services are described as follows:\n1. Congestion and Losses Management: Presently, most electricity markets worldwide do not\nconsider energy congestion and losses in distribution grids in the electricity price determination.\nHowever, the adoption of DLMP has been receiving increasing attention in the last few\nyears [49,98\u2013100] as a potential solution to price congestion and losses in the distribution grid.\nIn transmission grids, transmission LMPs (TLMPs) consider three components namely system\nenergy price, congestion cost, and marginal losses cost. The first component considers only\nthe optimal energy dispatch and, thus, ignores congestion and losses. The second component\nrepresents the prices of congestion, which are calculated on each bus of the system. Load generally\npays the congestion prices to generation. The third component represents the price of losses\ncaused by power injection or withdrawal and it is also calculated on each bus. In the distribution\ngrid, DLMPs can be decomposed into marginal costs for active power, reactive power, congestion,\nvoltage support, and losses while considering the real value of DERs on each node of the\ndistribution grid [49]. This will require powerful market clearing mechanisms capable of handling\na large amount of decision variables while considering the imbalances and nonlinearities of the\ndistribution grid.\n2. Markets for ancillary services: Ancillary services are essential energy services provided in\naddition to power generation to guarantee power system reliability, safety, and stability. In the\npresent electricity market framework, such services are provided by large synchronous generators\nand coordinated by system operators in transmission grids via wholesale market operations.\nFigure 5 shows the six ancillary services defined by the U.S. Federal Energy Regulatory\nCommission (FERC) through its orders 888 and 2000, issued in 1996 and 1999, respectively.\nSeveral studies have shown potential ancillary services that can be provided by DERs through\neffective active and reactive power control of inverter-based DG, prompt load control, and\nproper management of ESSs, respectively [101\u2013107]. However, the adoption of ancillary services\nprovided by DERs should be accompanied by transactive energy mechanisms that facilitate the\nprovision of those services locally to a distribution grid or aggregated to serve the needs of a\ntransmission grid. Volt/VAR control is an example of ancillary service that may be provided to a\nlocal distribution grid by inverter-based DG. Volt/VAR control is currently performed by using\ncapacitors in distribution lines and substations. Figure 6 illustrates a framework of integrating\nancillary services provided by DERs in distribution and transmission grids. In this framework,\nthe DSO coordinates ancillary services exclusively for the distribution grid, such as Volt/VAR\ncontrol, and also aggregates potential ancillary services to be integrated in the transmission\ngrid by the ISO/RTO, when prices are favorable. In addition, DERs can be aggregated by other\nmarket agents to provide ancillary services to the transmission grid through the wholesale market.\nHowever, the provision of ancillary services by DERs will depend on regulatory initiatives for\nDER integration and aggregation, new standards for DER interconnection and interoperability\nwith the electricity grid, and a cooperative work between DSOs and transmission grid and\nwholesale market operators. The IEEE 1547 has been recently revised to allow some new grid\nsupport functionalities of DERs [108]. The next-generation retail electricity market should\ntake advantage of the technical capabilities of DER agents and integrate effective transactive\nEnergies 2019, 12, 491 15 of 24\nmechanisms for ancillary services. Thus, distribution and transmission grids may benefit from\nemerging DER agents to become more efficient and reliable.\n3. Load management: The existing price-based and incentive-based DR programs described in\nSection 2 play an important role in the operations of several power systems worldwide, especially\nduring the periods of high wholesale market prices, peak load demands, or when system\nreliability is threatened [109]. However, such programs do not explore all functionalities and\ncapabilities provided by existing and emerging SGTs to allow real-time load management as\nwell as dynamic and effective interactions among DER agents and between DER agents and grid\noperators. Transactive energy mechanisms for load management will be extremely important\nin the next-generation retail electricity market as SGTs continue to evolve and DER agents have\ntheir capabilities expanded to become active market agents and directly participate in real-time\nload management programs in effective ways.\nEnergies 2018, 11, x FOR PEER REVIEW  15 of 25 \nservices exclusively for the distribution grid, such as Volt/VAR control, and also aggregates \npotential ancillary services to be integrated in the transmission grid by the ISO/RTO, when \nprices are favorable. In addition, DERs can be aggregated by other market agents to provide \nancillary services to the transmission grid through the wholesale market. However, the \nprovision of ancillary services by DERs will depend on regulatory initiatives for DER \nintegration and aggregation, new standards for DER interconnection and interoperability with \nthe electricity grid, and a cooperative work between DSOs and transmission grid and \nwholesale market operators. The IEEE 1547 has been recently revised to allow some new grid \nsupport functionalities of DERs [108]. The next-generation retail electricity market should take \nadvantage of the technical capabilities of DER agents and integrate effective transactive \nmechanisms for ancillary services. Thus, distribution and transmission grids may benefit from \nemerging DER agents to become more efficient and reliable. \n \nFigure 5. Ancillary services defined by the Federal Energy Regulatory Commission (FERC) in the \nU.S. \n \nFigure 6. A framework of integrating ancillary services provided by DER agents. DSO: distribution \nsystem operator; ISO: independent system operator. \n3. Load management: The existing price-based and incentive-based DR programs described in \nSection 2 play an important role in the operations of several power systems worldwide, \nespecially during the periods of high wholesale market prices, peak load demands, or when \nsystem reliability is threatened [109]. However, such programs do not explore all \nfunctionalities and capabilities provided by existing and emerging SGTs to allow real-time \nload management as well as dynamic and effective interactions among DER agents and \nbetween DER agents and grid operators. Transactive energy mechanisms for load management \nFigure 5. Ancillary services defined by the Federal Energy Regulatory Commission (FERC) in the U.S.\nEnergies 2018, 11, x FOR PEER REVIEW  15 of 25 \nservices exclusively for the distribution grid, such as Volt/VAR control, and also aggregates \npotential ancillary services to be integrated in the transmission grid by the ISO/RTO, when \nprices are favorable. In addition, DERs can be aggregated by other market agents to provide \nancillary services to the transmission grid through the wholesale market. However, the \nprovision of ancillary services by DERs will depend on regulatory initiatives for DER \nintegration and aggregation, new standards for DER interconnection and interoperability with \nthe electricity grid, and a cooperative work between DSOs and transmission grid and \nwholesale market operators. The IEEE 1547 has been recently revised to allow some new grid \nsupport functionalities of DERs [108]. The next-generation retail electricity market should take \nadvantage of the technical capabilities of DER agents and integrate effective transactive \nmechanisms for ancillary services. Thus, distribution and transmission grids may benefit from \nemerging DER agents to become more efficient and reliable. \n \nFigure 5. Ancillary services defined by the Federal Energy Regulatory Commission (FERC) in the \nU.S. \n \nFigure 6. A framework of integrating ancillary services provided by DER agents. DSO: distribution \nsystem operator; ISO: independent system operator. \n3. Load management: The existing price-based and incentive-based DR programs described in \nSection 2 play an important role in the operations of several power systems worldwide, \nespecially during the periods of high wholesale market prices, peak load demands, or when \nsystem reliability is threatened [109]. However, such programs do not explore all \nfunctionalities and capabilities provided by existing and emerging SGTs to allow real-time \nload management as well as dynamic and effective interactions among DER agents and \nbetween DER agents and grid operators. Transactive energy mechanisms for load management \nFigure 6. A framework of integrating ancillary services provided by DER agents. DSO: distribution\nsystem operator; ISO: independent system operator.\n5. Retail Market Agents: Main Roles and Responsibilities\nThe roles of retail market agents are changing dramatically as SGTs evolve and DERs spread in\nthe distribution grid [110]. The next-generation retail electricity market will acco modate new agents,\nwhich will play important roles in the effective operation of transactive energy mechanisms and the\nprovision of services to the electricity grids. The main roles and responsibilities of active market\nagents in the next-generation retail electricity market are briefly illustrated in Figure 7 and described\nEnergies 2019, 12, 491 16 of 24\nbelow. Hereinafter, without loss of generality, transmission grid and wholesale market operators are\nrepresented by a single entity, which is the case in the U.S., for illustrative purposes.\n1. DER agents: DER agents will play an important role in making the retail market more competitive,\nefficient, and sustainable. They will be able to interact and exchange energy with other market\nagents as well as provide DERs and important energy services to electricity grids through\ntransactive energy mechanisms.\n2. Load serving entities (LSEs): LSEs consist of competitive retailers and utilities. The main\ndifference between retailers and utilities is that utilities generally supply electricity to their\ncustomers and maintain power lines, transformers, substations, and other equipment in the\ndistribution grid whereas retailers only resell electricity to their customers, having no ownership\nover any assets in the distribution grid. LSEs will continue to ensure the supply of energy\nat competitive prices and high-quality services to passive and active market agents, promote\nincentives for energy efficiency and DG, and bill retail customers for energy consumption and\ndelivery charges.\n3. Aggregators: For the sake of generality, aggregators and LSEs are represented as separate\nentities in Figure 7 since DER aggregation can be of two types: LSE aggregation and third-party\naggregation. LSE aggregation refers to the capacity of LSEs to aggregate local DERs in its territory\nto support the needs of a local distribution grid or a transmission grid in cooperation with\nISOs/RTOs. On the other hand, third-party DER aggregation is performed by any entity other\nthan LSEs and their individual customers [111,112], such as third-party investors. Third-party\naggregation has been discussed extensively in the last few years as a way to make DERs\ncompetitive resources in the wholesale electricity market, but its implementation still faces\nregulatory barriers in several jurisdictions. The Regulatory Assistance Project (RAP) recently\npublished a comprehensive report to the Public Service Commission of the state of Arkansas that\nshows the advances, challenges, and needs required for the proper implementation of third-party\naggregators in that state [111]. In general, aggregators will actively participate in both retail\nand wholesale markets by aggregating DERs and trading those resources through effective and\ndynamic transactive energy mechanisms. Aggregators will work cooperatively with DER agents\nand ISOs/RTOs to ensure an effective integration of DERs in both the wholesale markets and\ntransmission grids [112].\n4. Distribution system operators (DSOs): DSOs will be responsible for balancing supply and demand\nat the distribution level and close the gap between retail and wholesale markets [13]. They will\nprovide new functionalities to coordinate the participation of DER agents in the electricity markets\n(as market operators) and optimize technical operations in distribution grids (as grid operators).\nFor UDSOs, a firewall separation between the DSO block and the merchant block of UDSOs\nneeds to be established to ensure a fair, nondiscriminatory, and competitive retail market and\navoid market power and eventual conflicts of interest especially in the cases that UDSOs own or\ninvest in DERs [64]. On the other hand, IDSOs should be nonprofit market facilitators with no\nownership of the distribution system assets. In both DSO concepts, regulated utilities continue\nto own and maintain the distribution grid assets and LSEs continue to retain billing function to\ntheir customers [60]. The implementation of DSOs, however, is a gradual process of technical\nand regulatory modernization towards the integration of transactive energy mechanisms in the\ndistribution grid. Figure 8 illustrates the roles and responsibilities of comprehensive DSOs in\nthe distribution grid and retail market operations. Working in the distribution grid operations,\nDSOs will be responsible for maintaining the safety and reliability of the distribution system\nthrough efficient protection and control mechanisms, coordinating ancillary services provided by\nDER agents, planning the distribution system expansion, and islanding their territory partially or\ntotally when black-start capacity from DERs is available in the event of a transmission system\ndisturbance [58,113]. Working in the retail market operations, DSOs will balance supply and\ndemand in the distribution grid, facilitate energy scheduling and settlements, coordinate the\nEnergies 2019, 12, 491 17 of 24\nexchange of power with the wholesale market, and ensure the integrity and transparency of all\ntransactions in the retail market [113]. The common responsibilities of DSOs in both grid and\nmarket operations include the forecasting, planning, and integration of DERs as well as the social\nwelfare maximization of all agents in their territory.\n5. ISOs/RTOs: ISOs/RTOs are primarily responsible for the control and operation of transmission\ngrids and wholesale markets, respectively. However, in the next-generation retail electricity\nmarket, such entities will work cooperatively with DSOs to ensure the transmission grid reliability\nby using DERs located in the distribution grid through transactive energy mechanisms. Note that\nin Figure 7, ISOs/RTOs are represented by the dotted box hierarchically above all other agents.\nA framework of integrating retail and wholesale markets that shows the interaction between\nISOs/RTOs and retail market agents is described in Section 6.\nEnergies 2018, 11, x FOR PEER REVIEW  16 of 25 \nwill be extremely important in the next-generation retail electricity market as SGTs continue to \nevolve and DER agents have their capabilities expanded to become active market agents and \ndirectly participate in real-time load management programs in effective ways. \n5. Retail Market Agents: Main Roles and Responsibilities \nThe roles of retail market agents are changing dramatically as SGTs evolve and DERs spread in \nthe distribution grid [110]. The next-generation retail electricity market will accommodate new \nagents, which will play important roles in the effective operation of transactive energy mechanisms \nand the provision of services to the electricity grids. The main roles and responsibilities of active \nmarket agents in the next-generation retail electricity market are briefly illustrated in Figure 7 and \ndescribed below. Hereinafter, without loss of generality, transmission grid and wholesale market \noperators are represented by a single entity, which is the case in the U.S., for illustrative purposes. \n \nFigure 7. Main roles and responsibilities of active retail market agents as well as the participation of \nISOs/RTOs in the retail market. LSEs: load serving entities. \n1. DER agents: DER agents will play an important role in making the retail market more \ncompetitive, efficient, and sustainable. They will be able to interact and exchange energy with \nother market agents as well as provide DERs and important energy services to electricity grids \nthrough transactive energy mechanisms. \n2. Load serving entities (LSEs): LSEs consist of competitive retailers and utilities. The main \ndifference between retailers and utilities is that utilities generally supply electricity to their \ncustomers and maintain power lines, transformers, substations, and other equipment in the \ndistribution grid whereas retailers only resell electricity to their customers, having no \nownership over any assets in the distribution grid. LSEs will continue to ensure the supply of \nenergy at competitive prices and high-quality services to passive and active market agents, \npromote incentives for energy efficiency and DG, and bill retail customers for energy \nconsumption and delivery charges. \n3. Aggregators: For the sake of generality, aggregators and LSEs are represented as separate \nentities in Figure 7 since DER aggregation can be of two types: LSE aggregation and third-\nparty aggregation. LSE aggregation refers to the capacity of LSEs to aggregate local DERs in its \nterritory to support the needs of a local distribution grid or a transmission grid in cooperation \nwith ISOs/RTOs. On the other hand, third-party DER aggregation is performed by any entity \nother than LSEs and their individual customers [111,112], such as third-party investors. Third-\nparty aggregation has been discussed extensively in the last few years as a way to make DERs \ncompetitive resources in the wholesale electricity market, but its implementation still faces \nregulatory barriers in several jurisdictions. The Regulatory Assistance Project (RAP) recently \npublished a comprehensive report to the Public Service Commission of the state of Arkansas \nFigure 7. Main roles and responsibilities of active retail market agents as well as the participation of\nISOs/RTOs in the retail market. LSEs: load serving entities.\nEnergies 2018, 11, x FOR PEER REVIEW  17 of 25 \nthat shows the advances, challenges, and needs required for the proper implementation of \nthird-party aggregators in that state [111]. In general, aggregators will actively participate in \nboth retail and wholesale markets by aggregating DERs and trading those resources through \neffective and dynamic transactive energy mechanisms. Aggregators will work cooperatively \nwith DER agents and ISOs/RTOs to ensure an effective integration of DERs in both the \nwholesale markets and transmission grids [112]. \n4. Distribution system operators (DSOs): DSOs will be responsible for balancing supply and \ndemand at the distribution level and close the gap between retail and wholesale markets [13]. \nThey will provide new functionalities to coordinate the participation of DER agents in the \nelectricity markets (as market operators) and optimize technical operations in distribution \ngrids (as grid operators). For UDSOs, a firewall separation between the DSO block and the \nmerchant block of UDSOs needs to be established to ensure a fair, nondiscriminatory, and \ncompetitive retail market and avoid market power and eventual conflicts of interest especially \nin the cases that UDSOs own or invest in DERs [64]. On the other hand, IDSOs should be \nnonprofit market facilitators with no ownership of the distribution system assets. In both DSO \nconcepts, regulated utilities continue to own and maintain the distribution grid assets and \nLSEs continue to retain billing function to their customers [60]. The implementation of DSOs, \nhowever, is a gradual process of technical and regulatory modernization towards the \nintegration of transactive energy mechanisms in the distribution grid. Figure 8 illustrates the \nroles and responsibilities of comprehensive DSOs in the distribution grid and retail market \noperations. Working in the distribution grid operations, DSOs will be responsible for \nmaintaining the safety and reliability of the distribution system through efficient protection \nand control mechanisms, coordinating ancillary services provided by DER agents, planning \nthe distribution system expansion, and islanding their territory partially or totally when black-\nstart capacity from DERs is available in the event of a transmission system disturbance \n[58,113]. Working in the retail market operations, DSOs will balance supply and demand in the \ndistribution grid, facilitate energy scheduling and settlements, coordinate the exchange of \npower with the wholesale market, and ensure the integrity and transparency of all transactions \nin the retail market [113]. The common responsibilities of DSOs in both grid and market \noperations include the forecasting, planning, and integration of DERs as well as the social \nwelfare maximization of all agents in their territory. \n \nFigure 8. Roles and responsibilities of comprehensive DSOs [58]. \n5. ISOs/RTOs: ISOs/RTOs are primarily responsible for the control and operation of transmission \ngrids and wholesale markets, respectively. However, in the next-generation retail electricity \nmarket, such entities will work cooperatively with DSOs to ensure the transmission grid \nreliability by using DERs located in the distribution grid through transactive energy \nmechanisms. Note that in Figure 7, ISOs/RTOs are represented by the dotted box hierarchically \nabove all other agents. A framework of integrating retail and wholesale arkets that shows the \ninteraction between ISOs/RTOs and retail market agents is described in Section 6. \n6. A Framework of Integrating Retail and Wholesale Elec ricity Markets \n[ ].\n6. A Framework of Integrating Retail and Wholesale Electricity Markets\nThe advances in technology, infrastructure, and the provision of en rgy services described in\nSection 4 will change not only the interactions mong retail market agents, but also the way in which\nwholesale and retail markets interact. An information exchange framew rk for the wholesale and\nthe next-ge eration retail electricity markets is illustrated in Figure 9a. The solid arrows indicate\nthe flows of information between agents in the prese t electricity market framework, whic remain\nunchanged. The hatched arrows indicate new two-w y flows of information among existing and\nemerging market agents. In this framework, DER agents can interact with DSOs, LSEs, aggregators,\nand other DER agents. In Figure 9a, the DSO and the LSEs are separated for the sake of generality.\nHowever, in the UDSO concept, they become a single entity. Moreover, aggregators are included\nEnergies 2019, 12, 491 18 of 24\nin both retail and wholesale markets as explained in Section 5. In such a framework, DSOs and\nISOs/RTOs may interact with each order and work coordinately for the provision of energy services to\nensure the efficiency, reliability, and resilience of the electricity grids. A coordinated work between\nDSOs and ISOs/RTOs is necessary to close the existing gaps between wholesale and retail markets as\nwell as between transmission and distribution grids, respectively [13]. Unlike the present electricity\nmarket framework in which energy production and DR are mostly centralized in large producers\nand consumers, the next-generation retail electricity market will integrate active DER agents in a\ndecentralized manner. Figure 9b illustrates the flows of energy among wholesale market agents and\nthe next-generation retail electricity market agents in a decentralized framework. Wholesale market\nparticipants and LSEs will continue to generate bulk power to be provided to retail market agents.\nHowever, a decentralized retail market will allow the exchange of energy among DER agents and the\nefficient provision of DERs to the wholesale market.\nEnergies 2018, 11, x FOR PEER REVIEW  18 of 25 \nThe advances in technology, infrastructure, and the provision of energy services described in \nSection 4 will change not only the interactions among retail market agents, but also the way in \nwhich wholesale and retail markets interact. An information exchange framework for the wholesale \nand the next-generation retail electricity markets is illustrated in Figure 9a. The solid arrows \nindicate the flows of information between agents in the present electricity market framework, \nwhich remain unchanged. The hatched arrows indicate new two-way flows of information among \nexisting and emerging market agents. In this framework, DER agents can interact with DSOs, LSEs, \naggregators, and other DER agents. In Figure 9a, the DSO and the LSEs are separated for the sake of \ngenerality. However, in the UDSO concept, they become a single entity. Moreover, aggregators are \nincluded in both retail and wholesale markets as explained in Section 5. In such a framework, DSOs \nand ISOs/RTOs may interact with each order and work coordinately for the provision of energy \nservices to ensure the efficiency, reliability, and resilience of the electricity grids. A coordinated \nwork between DSOs and ISOs/RTOs is necessary to close the existing gaps between wholesale and \nretail markets as well as between transmission and distribution grids, respectively [13]. Unlike the \npresent electricity market framework in which energy production and DR are mostly centralized in \nlarge producers and consumers, the next-generation retail electricity market will integrate active \nDER agents in a decentralized manner. Figure 9b illustrates the flows of energy among wholesale \nmarket agents a d the next-generation retail electricity m rket agents in a decentralized \nframework. Wholesale market participants and LSEs will con inu  to generate bulk power to be \nprovid d to r tail mark t agents. However, a decentralized retail market will allow the exchange of \nenergy am ng DER agents and the efficient provision of DERs to the wholesale market. \n \n(a) \n \n(b) \n  \nFigure 9. (a) Information exchange among retail and wholesale markets; (b) Energy flows among \nretail and wholesale market agents. \n7. Discussion and Conclusions \nThe retail electricity market worldwide is changing due to the increasing integration of DERs \nin the distribution grid, the development of innovative SGTs, and the necessity to ensure the \nFigure 9. (a) Information exchange among retail and wholesale markets; (b) Energy flows among retail\nand wholesale market agents.\n7. Discussion and Conclusions\nThe retail electricity market worldwide is changing due to the increasing integration of DERs in\nthe distribution grid, the development of innovative SGTs, and the necessity to ensure the reliability,\nresilience, and efficiency of transmission grids, and provide new services and functionalities to retail\nmarket agents. This paper aimed to fill an existing gap in the literature regarding the comprehensive\nvision of the next-generation retail electricity in the context of DERs and the integration of retail and\nwholesale electricity markets. In this paper, an overview of the present retail electricity market and\nsome recent developments on transactive energy were discussed. Then, a comprehensive vision of\nthe next-generation retail electricity market in the context of DERs has been presented. The proposed\nvision described the main technical and regulatory characteristics, challenges, opportunities, and\nneeds that will arise as passive customers provided with DERs become active agents in the electricity\nmarket. In addition, a framework of integrating retail and wholesale markets and the main roles\nand responsibilities of retail market agents under the proposed vision and framework have also\nbeen presented and discussed. In particular, this work highlighted the necessity of new regulatory\napproaches to establish new business models with decentralized markets for DERs and the expected\ntechnology advances and infrastructure upgrades required to allow a reliable and efficient integration\nof DERs. These two points are the big challenges to reach the proposed vision and framework since\nthey require concerted efforts and collaboration from different stakeholders. Government agencies,\nLSEs, energy policy makers, DER agents, and technology providers must agree on a common strategy\nto start the shift towards an efficient, flexible, sustainable, and decentralized retail electricity market.\nThrough this way, DER agents will have active participation in the electricity market, and DERs will\nbe used more efficiently in a competitive way. Therefore, more research, development, and practical\ninitiatives are needed to make this vision and framework partially or fully implementable to ensure\nEnergies 2019, 12, 491 19 of 24\nthe social welfare of market agents as well as to maximize the technical benefits of DERs to both\ndistribution and transmission grids.\nAuthor Contributions: J.C.d.P., W.Q., and L.Q. conceived and designed the vision and framework structure; J.R.A.\ncontributed with some regulatory aspects necessary to the implementation of the proposed vision and framework;\nJ.C.d.P. and J.R.A. wrote the paper; W.Q. edited and proofread the paper.\nFunding: This work was funded in part by the U.S. National Science Foundation under CAREER Award\nECCS-1554497 and in part by the Brazilian Council for Scientific and Technological Development (CNPq).\nConflicts of Interest: The authors declare no conflict of interest.\nAbbreviations\nAMI Advanced metering infrastructure\nBESS Battery energy storage system\nCAISO California Independent System Operator\nCPP Critical peak pricing\nDB Demand bidding/buyback\nDER Distributed energy resource\nDG Distributed generation\nDLMP Distribution locational marginal price\nDR Demand response\nDSO Distribution system operator\nEDR Emergency demand response\nESS Energy storage system\nE.U. European Union.\nIBC Increasing block price\nIDSO Independent System Operator\nIEMS Intelligent energy management system\nISO Independent system operator\nLM Load management\nLMP Locational marginal price\nLSE Load serving entity\nNWA Non-wire alternative\nSGT Smart grid technology\nPEV Plug-in electric vehicle\nPV Photovoltaic\nREV Reforming the energy vision\nRTO Regional transmission operator\nRTP Real-time pricing\nSMS Smart metering system\nTOU Time of use\nUDSO Utility distribution system operator\nU.S. United States\nV2G Vehicle-to-grid\nReferences\n1. Do Prado, J.C.; Qiao, W. A Vision of the Next-Generation Retail Electricity Market in the Context of\nDistributed Energy Resources. In Proceedings of the IEEE Power & Energy Society Innovative Smart Grid\nTechnologies Conference, Washington, DC, USA, 19\u201322 February 2018.\n2. Li, F.; Qiao, W.; Sun, H.; Wan, J.; Wang, J.; Xia, Y.; Xu, Z.; Zhang, P. Smart Transmission Grid: Vision and\nFramework. IEEE Trans. Smart Grid 2010, 1, 168\u2013177. [CrossRef]\n3. Net Metering by State. Solar Energy Industries Association (EIA). Available online: https://www.seia.org/\nresearch-resources/net-metering-state (accessed on 29 September 2018).\nEnergies 2019, 12, 491 20 of 24\n4. Heeter, J.; Gelman, R.; Bird, L. Status of Net Metering: Assessing the Potential to Reach Program Caps;\nTechnical Report; National Renewable Energy Laboratory (NREL): Golden, CO, USA, 2014.\n5. Electric Power Annual 2016. U.S. Energy Information Administration (EIA). Available online: https://www.\neia.gov/electricity/annual/ (accessed on 29 October 2018).\n6. Rising Solar Generation in California Coincides with Negative Wholesale Electricity Prices. U.S. Energy\nInformation Administration (EIA). Available online: https://www.eia.gov/todayinenergy/detail.php?id=\n30692 (accessed on 21 October 2018).\n7. PJM Demand Response. Available online: https://www.pjm.com/markets-and-operations/demand-\nresponse.aspx (accessed on 29 October 2018).\n8. 90 GW Residential Solar by 2021. HIS Markit. Available online: https://www.pveurope.eu/News/Markets-\nMoney/90-GW-residential-solar-by-2021 (accessed on 11 January 2019).\n9. Clean Energy Council. Available online: https://www.cleanenergycouncil.org.au/resources/technologies/\nsolar-energy (accessed on 11 January 2019).\n10. Aman, S.; Simmhan, Y.; Prasanna, V. Energy Management Systems: State of the Art and Emerging Trends.\nIEEE Commun. Mag. 2013, 51, 114\u2013119. [CrossRef]\n11. Sun, Q.; Li, H.; Ma, Z.; Wang, C.; Campillo, J.; Zhang, Q.; Wallin, F. A Comprehensive Review of Smart\nEnergy Meters in Intelligent Energy Networks. IEEE Internet Things J. 2016, 3, 464\u2013479. [CrossRef]\n12. Palensky, P.; Dietrich, D. Demand Side Management: Demand Response, Intelligent Energy Systems, and\nSmart Loads. IEEE Trans. Ind. Inform. 2011, 7, 381\u2013388. [CrossRef]\n13. Rahimi, F.A.; Ipakchi, A. Transactive Energy Techniques: Closing the Gap Between Wholesale and Retail\nMarkets. Electr. J. 2012, 25, 29\u201335. [CrossRef]\n14. GridWise Transactive Energy Framework Version 1.0. The GridWise Architecture Council. Available online:\nhttps://www.gridwiseac.org/pdfs/te_framework_report_pnnl-22946.pdf (accessed on 6 October 2018).\n15. Electric Power System Flexibility: Challenges and Opportunities. Electric Power Research Institute. Available\nonline: https://www.epri.com/#/pages/product/3002007374/?lang=en-US (accessed on 12 January 2019).\n16. Jim\u00e9nez-Est\u00e9vez, G.A.; Palma-Behnke, R.; Torres-Avila, R.; Vargas, L.S. A Competitive Market Integration\nModel for Distributed Generation. IEEE Trans. Power Syst. 2007, 22, 2161\u20132169. [CrossRef]\n17. Safdarian, A.; Fotuhi-Firuzabad, M.; Lehtonen, M.; Aminifar, F. Optimal Electricity Procurement in Smart\nGrid with Autonomous Distributed Energy Resources. IEEE Trans. Smart Grid 2015, 6, 2975\u20132984. [CrossRef]\n18. Goebel, C.; Jacobsen, H.A. Bringing Distributed Energy Storage to Market. IEEE Trans. Power Syst. 2016, 31,\n173\u2013186. [CrossRef]\n19. Parvania, M.; Fotuhi-Firuzabad, M.; Shahidehpour, M. Optimal Demand Response Aggregation in Wholesale\nElectricity Markets. IEEE Trans. Smart Grid 2013, 4, 1957\u20131965. [CrossRef]\n20. Vay\u00e1, M.G.; Andersson, G. Optimal Bidding Strategy for a Plug-in Electric Vehicle Aggregator in Day-Ahead\nElectricity Markets Under Uncertainty. IEEE Trans. Power Syst. 2015, 30, 2375\u20132385. [CrossRef]\n21. Vagropoulos, S.I.; Bakirtzis, A.G. Optimal Bidding Strategy for Electric Vehicle Aggregators in Electricity\nMarkets. IEEE Trans. Power Syst. 2013, 28, 4031\u20134041. [CrossRef]\n22. Do Prado, J.C.; Qiao, W. A Stochastic Decision-Making Model for an Electricity Retailer with Intermittent\nRenewable Energy and Short-Term Demand Response. IEEE Trans. Smart Grid 2018. [CrossRef]\n23. Golmohamadi, H.; Keypour, R.; Hassanpour, A.; Davoudi, M. Optimization of Green Energy Portfolio in the\nRetail Market Using Stochastic Programming. In Proceedings of the North American Power Symposium,\nCharlotte, NC, USA, 4\u20136 October 2015.\n24. Babar, M.; Nguyen, P.H.; Cuk, V.; Kamphuis, I.G. The Development of Demand Elasticity Model for\nDemand Response in the Retail Market. In Proceedings of the IEEE Eindhoven PowerTech, Eindhoven,\nThe Netherlands, 29 June\u20132 July 2015.\n25. Momber, I.; Wogrin, S.; San Rom\u00e1n, T.G. Retail Pricing: A Bilevel Program for PEV Aggregator Decisions\nUsing Indirect Load Control. IEEE Trans. Power Syst. 2016, 31, 464\u2013473. [CrossRef]\n26. Su, W.; Huang, A.Q. A Game Theoretic Framework for a Next-Generation Retail Electricity Market with\nHigh Penetration of Distributed Residential Electricity Suppliers. Appl. Energy 2014, 119, 341\u2013350. [CrossRef]\n27. Liang, Z.; Chen, T.; Su, W. Robust Distributed Energy Resources Management for Microgrid in a Retail\nElectricity Market. In Proceedings of the North American Power Symposium, Morgantown, WV, USA,\n17\u201319 September 2017.\nEnergies 2019, 12, 491 21 of 24\n28. Chen, T.; Alsafasfeh, Q.; Pourbabak, H.; Su, W. The Next-Generation U.S. Retail Electricity Market with\nCustomers and Prosumers\u2014A Bibliographical Survey. Energies 2017, 11, 8. [CrossRef]\n29. Sioshansi, F.P. Distributed Generation and its Implications for the Utility Industry, 1st ed.; Academic Press:\nSan Diego, CA, USA, 2014; Volume 1.\n30. Sioshansi, F.P. Future of Utilities\u2014Utilities of the Future, 1st ed.; Academic Press: San Diego, CA, USA, 2016;\nVolume 1.\n31. Swadley, A.; Y\u00fccel, M. Did Residential Electricity Rates Fall After Competition? A Dynamic Panel Analysis.\nEnergy Policy 2011, 39, 7702\u20137711. [CrossRef]\n32. 1.0 Primer on Rate Design for Residential Distributed Generation. Edison Electric Institute (EEI).\nAvailable online: http://www.eei.org/issuesandpolicy/generation/NetMetering/Documents/2016%\n20Feb%20NARUC%20Pimer%20on%20Rate%20Design.pdfa (accessed on 26 October 2018).\n33. Rate Design for a Distributed Grid. Solar Energy Industries Association (SEIA). Available online: https:\n//votesolar.org/files/5114/6920/9995/Rate_Design_for_Distributed_Grid_7_21_2016_v2.pdf (accessed on\n2 October 2018).\n34. Minnesota\u2019s Value of Solar: Can a Northern State\u2019s New Solar Policy Defuse Distributed Generation Battles?\nInstitute for Local Self-Reliance. Available online: https://ilsr.org/wp-content/uploads/2014/04/MN-\nValue-of-Solar-from-ILSR.pdf (accessed on 14 October 2018).\n35. Pacific Northwest Smart Grid Demonstration Project Technology Performance Report. Battelle Memorial\nInstitute. Available online: https://www.smartgrid.gov/document/Pacific_Northwest_Smart_Grid_\nTechnology_Performance.html (accessed on 28 October 2018).\n36. Widergren, S.E.; Subbarao, K.; Fuller, J.C.; Chassin, D.P.; Somani, A.; Marinovici, C.; Hammerstrom, J.L.\nAEP Ohio GridSMART Demonstration Project Real-Time Pricing Demonstration Analysis; Technical Report;\nPacific Northwest National Laboratory (PNNL): Richland, WA, USA, 2014.\n37. National Institute of Standards and Technology (NIST) Energy Modeling and Simulation Challenge for\nthe Smart Grid. Available online: https://www.nist.gov/engineering-laboratory/smart-grid/hot-topics/\ntransactive-energy-modeling-and-simulation-challenge (accessed on 16 October 2018).\n38. Ecogrid 2.0. Available online: http://www.ecogrid.dk/en/home_uk (accessed on 24 October 2018).\n39. The GridWise Architecture Council Mission & Structure. Available online: https://www.gridwiseac.org/\nabout/mission.aspx (accessed on 29 September 2018).\n40. Reforming the Energy Vision. New York State Department of Public Service. Available online: http://www3.\ndps.ny.gov/W/PSCWeb.nsf/All/CC4F2EFA3A23551585257DEA007DCFE2?OpenDocument (accessed on\n1 October 2018).\n41. De Martini, P. More than Smart: A Framework to Make the Distribution Grid More Open, Efficient, and Resilient;\nTechnical Report; Resnick Sustainability Institute: Pasadena, CA, USA, 2014.\n42. CAISO Distributed Energy Resource Provider. Available online: https://www.caiso.com/participate/\nPages/DistributedEnergyResourceProvider/Default.aspx (accessed on 27 October 2018).\n43. Sherick, R.; Yinger, R. Modernizing the California Grid: Preparing for a Future with High Penetrations of\nDistributed Energy Resources. IEEE Power Energy Mag. 2017, 15, 20\u201328. [CrossRef]\n44. Renewable Energy Directive. European Commission. Available online: https://ec.europa.eu/energy/en/\ntopics/renewable-energy/renewable-energy-directive (accessed on 13 January 2019).\n45. Tabors, R.D. Valuing Distributed Energy Resources (DER) via Distribution Locational Marginal Prices (DLMP);\n2016. Available online: https://www.energy.gov/sites/prod/files/2016/06/f32/4_Transactive%20Energy%\n20Panel%20-%20Richard%20Tabors%2C%20MIT%20Energy%20Initiative.pdf (accessed on 16 October 2018).\n46. Yang, R.; Zhang, Y. Three-Phase AC Optimal Power Flow Based Distribution Locational Marginal Price.\nIn Proceedings of the IEEE Power & Energy Society Innovative Smart Grid Technologies Conference,\nWashington, DC, USA, 23\u201326 April 2017.\n47. Li, R.; Wu, Q.; Oren, S.S. Distribution Locational Marginal Pricing for Optimal Electric Vehicle Charging\nManagement. IEEE Trans. Power Syst. 2014, 29, 203\u2013211. [CrossRef]\n48. Birk, M.E. Impact of Distributed Energy Resources on Locational Marginal Prices and Electricity Networks.\nMaster\u2019s Thesis, Massachusetts Institute of Technology, Cambridge, MA, USA, June 2016.\n49. Bai, L.; Wang, J.; Wang, C.; Chen, C.; Li, F. Distribution Locational Marginal Pricing (DLMP) for Congestion\nManagement and Voltage Support. IEEE Trans. Power Syst. 2018, 33, 4061\u20134073. [CrossRef]\nEnergies 2019, 12, 491 22 of 24\n50. Ag\u00fcero, J.R. What Does the Future Hold for Utilities? T&D World. Available online: https://www.tdworld.\ncom/distribution/what-does-future-hold-utilities (accessed on 9 October 2018).\n51. Network Regulation\u2014The RIIO Model. Available online: https://www.ofgem.gov.uk/network-regulation-\nriio-model (accessed on 20 October 2018).\n52. Safdarian, A.; Fotuhi-Firuzabad, M.; Lehtonen, M. Integration of Price-Based Demand Response in DisCos\u2019\nShort-Term Decision Model. IEEE Trans. Smart Grid 2014, 5, 2235\u20132245. [CrossRef]\n53. Palma-Behnke, R.; Vargas, L.S.; Jofr\u00e9, A. A Distribution Company Energy Acquisition Market Model with\nIntegration of Distributed Generation and Load Curtailment Options. IEEE Trans. Power Syst. 2005, 20,\n1718\u20131727. [CrossRef]\n54. Asimakopoulou, G.E.; Vlachos, A.G.; Hatziargyriou, N.D. Hierarchical Decision Making for Aggregated\nEnergy Management of Distributed Resources. IEEE Trans. Power Syst. 2015, 30, 3255\u20133264. [CrossRef]\n55. Do Prado, J.C.; Qiao, W.; Thomas, S. Moving Towards Distribution System Operators: Current Work and\nFuture Directions. In Proceedings of the IEEE Power & Energy Society Innovative Smart Grid Technologies\nConference, Washington, DC, USA, 18\u201321 February 2019. in press.\n56. Apostolopoulou, D.; Bahramirad, S.; Khodaei, A. The Interface of Power: Moving Toward Distribution\nSystem Operators. IEEE Power Energy Mag. 2016, 14, 46\u201351. [CrossRef]\n57. Ruester, S.; Schwenen, S.; Batle, C.; Perez-Arriaga, I. From Distribution Networks to Smart Distribution\nSystems: Rethinking the Regulation of European Electricity DSOs. Util. Policy 2014, 31, 229\u2013237. [CrossRef]\n58. Rahimi, F.; Mokhtari, S. A New Distribution System Operator Construct. Open Access Technology\nInternational (OATI). Available online: https://www.gridwiseac.org/pdfs/workshop_091014/a_new_\ndist_sys_optr_construct_paper.pdf (accessed on 12 October 2018).\n59. Covino, S.; Levitt, A.; Sotkiewicz, P. The Fully Integrated Grid: Wholesale and Retail, Transmission and\nDistribution. In Future of Utilities\u2014Utilities of the Future, 1st ed.; Sioshansi, P., Ed.; Academic Press: San Diego,\nCA, USA, 2016; Volume 1, pp. 363\u2013381.\n60. Tong, J.; Wellinghoff, J. Rooftop Parity: Solar for Everyone, Including Utilities. Public Util. Fortn. 2014, 152,\n18\u201323.\n61. Parhizi, S.; Khodaei, A. Investigating the Necessity of Distribution Markets in Accommodating High\nPenetration Microgrids. In Proceedings of the IEEE Power & Energy Society Transmission and Distribution\nConference and Exposition, Dallas, TX, USA, 3\u20135 May 2016.\n62. Parhizi, S.; Khodaei, A.; Bahramirad, S. Distribution Market Clearing and Settlement. In Proceedings of the\nIEEE Power & Energy Society General Meeting, Boston, MA, USA, 17\u201321 July 2016.\n63. Kristov, L.; De Martini, P. 21st Century Electric Distribution System Operations. Available online: http:\n//resnick.caltech.edu/docs/21st.pdf (accessed on 19 September 2018).\n64. Rahimi, F.; Mokhtari. Distribution Management System for the Grid of the Future: A Transactive System\nCompensating for the Rise in Distributed Energy Resources. IEEE Electrif. Mag. 2018, 6, 84\u201394. [CrossRef]\n65. Thomas, S. Evolution of the Distribution System & The Potential for Distribution-Level Markets: A Primer for\nState Utility Regulators; Technical Report; The National Association of Regulatory Utility Commissioners\n(NARUC): Washinton, DC, USA, 2018.\n66. De Martini, P.; Kristov, L.; Schwartz, L. Distribution Systems in a High Distributed Energy Resources Future.\nPlanning, Market Design, Operation and Oversight; Technical Report; Lawrence Berkeley National Laboratory:\nBerkeley, CA, USA, 2015.\n67. Conejo, A.J.; Morales, J.M.; Martinez, J.A. Tools for the Analysis and Design of Distributed Resources\u2014Part\nIII: Market Studies. IEEE Trans. Power Deliv. 2011, 26, 1663\u20131670. [CrossRef]\n68. Rahimi, F.; Albuyeh, F. Applying Lessons Learned from Transmission Open Access to Distribution and\nGrid-Edge Transactive Energy Systems. In Proceedings of the IEEE Power & Energy Society Innovative\nSmart Grid Technologies Conference, Minneapolis, MN, USA, 6\u20139 September 2016.\n69. Fu, R.; Feldman, D.; Margolis, R. U.S. Solar Photovoltaic System Cost Benchmark: Q1 2018; Technical Report;\nNational Renewable Energy Laboratory (NREL): Golden, CO, USA, 2018.\n70. Essig, S.; Steiner, M.A.; Alleb\u00e9, C.; Geisz, J.F.; Paviet-Salomon, B.; Ward, S.; Descoeudres, A.; LaSalvia, V.;\nBarraud, L.; Badel, N.; et al. Realization of GaInP/Si Dual-Junction Solar Cells with 29.8 Percent One-Sun\nEfficiency. IEEE J. Photovolt. 2016, 6, 1012\u20131019. [CrossRef]\n71. Tesla Solar Roof. Available online: https://www.tesla.com/solarroof (accessed on 14 January 2019).\nEnergies 2019, 12, 491 23 of 24\n72. Jahangiri, P.; Aliprantis, D.C. Distributed Volt/Var Control by PV Inverters. IEEE Trans. Power Syst. 2013, 28,\n3429\u20133439. [CrossRef]\n73. EV Volumes. Available online: http://www.ev-volumes.com (accessed on 7 October 2018).\n74. Liu, C.; Chau, K.T.; Wu, D.; Gao, S. Opportunities and Challenges of Vehicle-to-Home, Vehicle-to-Vehicle,\nand Vehicle-to-Grid Technologies. Proc. IEEE 2013, 101, 2409\u20132427. [CrossRef]\n75. Yilmaz, M.; Krein, P.T. Review of the Impact of Vehicle-to-Grid Technologies on Distribution Systems and\nUtility Interfaces. IEEE Trans. Power Electron. 2013, 28, 5673\u20135689. [CrossRef]\n76. Shin, H.; Baldick, R. Plug-in Electric Vehicle to Home (V2H) Operation Under a Grid Outage. IEEE Trans.\nSmart Grid 2017, 8, 2032\u20132041. [CrossRef]\n77. Dinger, A.; Martin, R.; Mosquet, X.; Rabl, M.; Rizoulis, D.; Russo, M.; Sticher, G. Batteries for Electric Cars:\nChallenges, Opportunities, and the Outlook to 2020. The Boston Consulting Group. Available online:\nhttps://www.bcg.com/documents/file36615.pdf (accessed on 13 October 2018).\n78. Hao, H.; Corbin, C.D.; Kalsi, K.; Pratt, R.G. Transactive Control of Commercial Buildings for Demand\nResponse. IEEE Trans. Power Syst. 2017, 32, 774\u2013783. [CrossRef]\n79. Katipamula, S.; Hatley, D.D.; Hammerstrom, D.J.; Chassin, D.P.; Pratt, R.G. Transactive Controls: Market-Based\nGridWise Controls for Building Systems; Technical Report; Pacific Northwest National Laboratory (PNNL):\nRichland, WA, USA, 2006.\n80. Li, S.; Zhang, W.; Lian, J.; Kalsi, K. Market-Based Coordination of Thermostatically Controlled Loads\u2014Part I:\nA Mechanism Design Formulation. IEEE Trans. Power Syst. 2016, 31, 1170\u20131178. [CrossRef]\n81. Galvan, E.; Mandal, P.; Velez-Reyes, M.; Kamalasadan, S. Transactive Control Mechanism for Efficient\nManagement of EVs Charging in Transactive Energy Environment. In Proceedings of the North American\nPower Symposium, Denver, CO, USA, 18\u201320 September 2016.\n82. Hu, J.; Yang, G.; Bindner, H.W. Network Constrained Transactive Control for Electric Vehicles Integration.\nIn Proceedings of the IEEE Power and Energy Society General Meeting, Denver, CO, USA, 26\u201330 July 2015.\n83. Shaker, H.; Zareipour, H.; Wood, D. Estimating Power Generation of Invisible Solar Sites Using Publicly\nAvailable Data. IEEE Trans. Smart Grid 2016, 7, 2456\u20132465. [CrossRef]\n84. Richardson, P. Integration of Distributed Energy Resources in Low Voltage Electricity Networks. Ph.D.\nDissertation, University College Dublin, Dublin, Ireland, January 2012.\n85. Morales, J.M.; Conejo, A.J.; Madsen, H.; Pinson, P.; Zuogo, M. Integrating Renewables in Electricity Markets,\n1st ed.; Springer: New York, NY, USA, 2014; Volume 205.\n86. Managing Big Data for Smart Grids and Smart Meters. IBM Software. Available online: http://www-935.\nibm.com/services/multimedia/Managing_big_data_for_smart_grids_and_smart_meters.pdf (accessed on\n20 October 2018).\n87. Garc\u00eda-Bertrand, R.; M\u00ednguez, R. Dynamic Robust Transmission Expansion Planning. IEEE Trans. Power Syst.\n2017, 32, 2618\u20132628. [CrossRef]\n88. Coddington, M.; Sciano, D.; Fuller, J. Change in Brooklyn and Queens: How New York\u2019s Reforming\nthe Energy Vision Program and Con Edison are Reshaping Electric Distribution Planning. IEEE Power\nEnergy Mag. 2017, 15, 40\u201347. [CrossRef]\n89. Hu, H.; Wen, Y.; Chua, T.S.; Li, X. Towards Scalable Systems for Big Data Analytics: A Technology Tutorial.\nIEEE Access 2014, 2, 652\u2013687. [CrossRef]\n90. Yan, Y.; Qian, Y.; Sharif, H.; Tipper, D. A Survey on Smart Grid Communication Infrastructures: Motivations,\nRequirements, and Challenges. IEEE Commun. Surv. Tutor. 2013, 15, 5\u201320. [CrossRef]\n91. Ma, R.; Chen, H.H.; Huang, Y.R.; Meng, W. Smart Grid Communication: Its Challenges and Opportunities.\nIEEE Trans. Smart Grid 2013, 4, 36\u201346. [CrossRef]\n92. Wang, K.; Yu, J.; Yu, Y.; Qian, Y.; Zend, D.; Guo, S.; Xiang, Y.; Wu, J. A Survey on Energy Internet: Architecture,\nApproach, and Emerging Technologies. IEEE Syst. J. 2018, 12, 2403\u20132416. [CrossRef]\n93. Wang, K.; Hu, X.; Li, H.; Li, P.; Zeng, D.; Guo, S. A Survey on Energy Internet Communications for\nSustainability. IEEE Trans. Sustain. Comput. 2017, 2, 231\u2013254. [CrossRef]\n94. Su, W.; Huang, A.Q. Proposing a Electricity Market Framework for the Energy Internet. In Proceedings of\nthe IEEE Power & Energy Society General Meeting, Vancouver, BC, Canada, 21\u201325 July 2013.\n95. Yan, Y.; Qian, Y.; Sharif, H.; Tipper, D. A Survey on Cyber Security for Smart Grid Communications.\nIEEE Commun. Surv. Tutor. 2012, 14, 998\u20131010. [CrossRef]\nEnergies 2019, 12, 491 24 of 24\n96. Mylrea, M.; Gourisetti, S.N.G. Blockchain for Smart Grid Resilience: Exchanging Distributed Energy at\nSpeed, Scale and Security. In Proceedings of the Resilience Week, Wilmington, DE, USA, 18\u201322 September\n2017.\n97. U.S. Department of Energy (DOE) Award Selections for the Development of Next Generation Cybersecurity\nTechnologies and Tools. Available online: https://www.energy.gov/sites/prod/files/2017/09/f36/CEDS%\n20Awards%20fact%20sheet%20September2017%20FINAL.pdf (accessed on 31 October 2018).\n98. Heydt, G.T. The Next Generation of Power Distribution Systems. IEEE Trans. Smart Grid 2010, 1, 225\u2013235.\n[CrossRef]\n99. Sahriatzadeh, P.; Nirbhavane, P.; Srivasatava, A.K. Locational Marginal Price for Distribution System\nConsidering Demand Response. In Proceedings of the North American Power Symposium, Champaign, IL,\nUSA, 9\u201311 September 2012.\n100. Papavasiliou, A. Analysis of Distribution Locational Marginal Prices. IEEE Trans. Smart Grid 2018, 9,\n4872\u20134882. [CrossRef]\n101. Olek, B.; Wierzbowaki, M. Locational Energy Balancing and Ancillary Services in Low-Voltage Networks\nwith Distributed Generation, Energy Storage, and Active Loads. IEEE Trans. Ind. Electron. 2015, 62, 2499\u20132508.\n[CrossRef]\n102. Rueda-Medina, A.C.; Padilha-Feltrin, A. Distributed Generators as Providers of Reactive Power Support\u2014A\nMarket Approach. IEEE Trans. Power Syst. 2013, 28, 490\u2013502. [CrossRef]\n103. Joos, G.; Ooi, B.T.; McGillis, D.; Galiana, F.D.; Marceau, R. The Potential of Distributed Generation to Provide\nAncillary Services. In Proceedings of the IEEE Power & Energy Society Summer Meeting, Seattle, WA, USA,\n16\u201320 July 2000.\n104. Dominguez-Garcia, A.D.; Hadjicostis, C.N. Coordination and Control of Distributed Energy Resources\nfor Provision of Ancillary Services. In Proceedings of the IEEE International Conference on Smart Grid\nCommunications, Gaithersburg, MD, USA, 4\u20136 October 2010.\n105. Calderaro, V.; Conio, G.; Galdi, V.; Massa, G.; Piccolo, A. Optimal Decentralized Voltage Control for\nDistribution Systems with Inverter-Based Distributed Generators. IEEE Trans. Power Syst. 2014, 29, 230\u2013241.\n[CrossRef]\n106. Kim, Y.J.; Blum, D.H.; Xu, N.; Su, L.; Norford, L.K. Technologies and Magnitude of Ancillary Services\nProvided by Commercial Buildings. Proc. IEEE 2016, 104, 758\u2013779. [CrossRef]\n107. Barr, J.; Majumder, R. Integration of Distributed Generation in the Volt/VAR Management System for Active\nDistribution Networks. IEEE Trans. Smart Grid 2015, 6, 576\u2013586. [CrossRef]\n108. IEEE Standard for Interconnection and Interoperability of Distributed Energy Resources with Associated\nElectric Power Systems Interfaces. IEEE Standard 1547-2018. Available online: https://standards.ieee.org/\nstandard/1547-2018.html (accessed on 17 October 2018).\n109. Albadi, M.H.; El-Saadany, E.F. Demand Response in Electricity Markets: An Overview. In Proceedings of the\n2007 IEEE Power & Energy Society General Meeting, Tampa, FL, USA, 24\u201328 June 2007.\n110. Su, W. The Role of customers in the U.S. Electricity Market: Past, Present and Future. Electr. J. 2014, 27,\n112\u2013125. [CrossRef]\n111. Migden-Ostrander, J.; Shenot, J.; Kadock, C.; Dupuy, M.; Linvill, C. Enabling Thrid-Party Aggregation\nof Distributed Energy Resources. Report to the Public Service Commission of Arkansas; Technical Report;\nThe Regulatory Assistance Project (RAP): Montpelier, VT, USA, 2018.\n112. Burger, S.; Chaves-\u00c1vila, J.P.; Batlle, C.; P\u00e9rez-Arriaga, I.J. The Value of Aggregators in Electricity Systems;\nTechnical Report; MIT Center for Energy and Environmental Policy Research: Cambridge, MA, USA, 2016.\n113. Kristov, L.; Hou, D.D. Rethinking the Transmission-distribution Interface in a Distributed Energy Future.\nIn Distributed Generation and its Implications for the Utility Industry, 1st ed.; Sioshansi, F.P., Ed.; Academic Press:\nSan Diego, CA, USA, 2014; Volume 1, pp. 359\u2013377.\n\u00a9 2019 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\narticle distributed under the terms and conditions of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n",
      "id": 54755010,
      "identifiers": [
        {
          "identifier": "201227920",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:digitalcommons.unl.edu:electricalengineeringfacpub-1465",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.3390/en12030491",
          "type": "DOI"
        },
        {
          "identifier": "oai:doaj.org/article:c049ea1d6599495089c4db687545fc2b",
          "type": "OAI_ID"
        },
        {
          "identifier": "540185056",
          "type": "CORE_ID"
        },
        {
          "identifier": "2912099761",
          "type": "MAG_ID"
        },
        {
          "identifier": "188144006",
          "type": "CORE_ID"
        },
        {
          "identifier": "189485936",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:mdpi.com:/1996-1073/12/3/491/",
          "type": "OAI_ID"
        }
      ],
      "title": "The Next-Generation Retail Electricity Market in the\nContext of Distributed Energy Resources: Vision and\nIntegrating Framework",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:doaj.org/article:c049ea1d6599495089c4db687545fc2b",
        "oai:digitalcommons.unl.edu:electricalengineeringfacpub-1465",
        "oai:mdpi.com:/1996-1073/12/3/491/"
      ],
      "publishedDate": "2019-01-01T08:00:00",
      "publisher": "DigitalCommons@University of Nebraska - Lincoln",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1465&context=electricalengineeringfacpub",
        "https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1465&amp;context=electricalengineeringfacpub"
      ],
      "updatedDate": "2023-02-11T01:31:15",
      "yearPublished": 2019,
      "journals": [
        {
          "title": "Energies",
          "identifiers": [
            "issn:1996-1073",
            "1996-1073"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/188144006.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/188144006"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/188144006/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/188144006/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/54755010"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "A Azmoodeh"
        },
        {
          "name": "A Bassi"
        },
        {
          "name": "A G Merkulov"
        },
        {
          "name": "A Khanna"
        },
        {
          "name": "A Salam"
        },
        {
          "name": "A Salam"
        },
        {
          "name": "A Schneider"
        },
        {
          "name": "B Leleux"
        },
        {
          "name": "B R Keeble"
        },
        {
          "name": "C Zhang"
        },
        {
          "name": "D Li"
        },
        {
          "name": "F Al-Turjman"
        },
        {
          "name": "F Cicirelli"
        },
        {
          "name": "G Beier"
        },
        {
          "name": "G Ding"
        },
        {
          "name": "G Elhayatmy"
        },
        {
          "name": "G Fortino"
        },
        {
          "name": "G Fortino"
        },
        {
          "name": "G Solmaz"
        },
        {
          "name": "H S Kim"
        },
        {
          "name": "I F Akyildiz"
        },
        {
          "name": "I F Akyildiz"
        },
        {
          "name": "I Hong"
        },
        {
          "name": "J Hopkins"
        },
        {
          "name": "J Zhang"
        },
        {
          "name": "K Liolis"
        },
        {
          "name": "L E Jackson"
        },
        {
          "name": "L Xu Da"
        },
        {
          "name": "M Bacco"
        },
        {
          "name": "M C Vuran"
        },
        {
          "name": "M J Tiusanen"
        },
        {
          "name": "M Maksimovic"
        },
        {
          "name": "M R Stead"
        },
        {
          "name": "M Yao"
        },
        {
          "name": "N R Council"
        },
        {
          "name": "N Zhu"
        },
        {
          "name": "P Godge"
        },
        {
          "name": "R Gravina"
        },
        {
          "name": "R Materese"
        },
        {
          "name": "R Varatharajan"
        },
        {
          "name": "S Basagni"
        },
        {
          "name": "S Berke"
        },
        {
          "name": "S Bluetooth"
        },
        {
          "name": "S Chandrasekharan"
        },
        {
          "name": "S Nandi"
        },
        {
          "name": "S Schneider"
        },
        {
          "name": "S Singh"
        },
        {
          "name": "V Dale"
        },
        {
          "name": "V N Swamy"
        },
        {
          "name": "X Dong"
        },
        {
          "name": "Xin Tan"
        },
        {
          "name": "Y Li"
        },
        {
          "name": "Y Liu"
        },
        {
          "name": "Y Simmhan"
        },
        {
          "name": "Y Wang"
        },
        {
          "name": "Z Zhang"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Abdul"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/471975349",
        "https://api.core.ac.uk/v3/outputs/286368292"
      ],
      "createdDate": "2020-01-23T23:04:39",
      "dataProviders": [
        {
          "id": 4786,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/4786",
          "logo": "https://api.core.ac.uk/data-providers/4786/logo"
        },
        {
          "id": 201,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/201",
          "logo": "https://api.core.ac.uk/data-providers/201/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "The two-third of the city-dwelling world population by 2050 poses numerous global challenges in the infrastructure and natural resource management domains (e.g., water and food scarcity, increasing global temperatures, and energy issues). The IoT with integrated sensing and communication capabilities has the strong potential for the robust, sustainable, and informed resource management in the urban and rural communities. In this chapter, the vital concepts of sustainable community development are discussed. The IoT and sustainability interactions are explained with emphasis on Sustainable Development Goals (SDGs) and communication technologies. Moreover, IoT opportunities and challenges are discussed in the context of sustainable community development",
      "doi": "10.1007/978-3-030-35291-2_1",
      "downloadUrl": "https://core.ac.uk/download/286368292.pdf",
      "fieldOfStudy": null,
      "fullText": "Purdue University Purdue e-Pubs Faculty Publications Department of Computer Information Technology 1-1-2020 Internet of Things for Sustainable Community Development: Introduction and Overview Abdul Salam Purdue University, salama@purdue.edu Follow this and additional works at: https://docs.lib.purdue.edu/cit_articles  Part of the Digital Communications and Networking Commons, Environmental Studies Commons, and the Sustainability Commons Salam, Abdul, \"Internet of Things for Sustainable Community Development: Introduction and Overview\" (2020). Faculty Publications. Paper 23. https://docs.lib.purdue.edu/cit_articles/23 This document has been made available through Purdue e-Pubs, a service of the Purdue University Libraries. Please contact epubs@purdue.edu for additional information. Chapter 1Internet of Things for SustainableCommunity Development: Introductionand OverviewAbstract The two-third of the city-dwelling world population by 2050 posesnumerous global challenges in the infrastructure and natural resource managementdomains (e.g., water and food scarcity, increasing global temperatures, and energyissues). The IoT with integrated sensing and communication capabilities has thestrong potential for the robust, sustainable, and informed resource management inthe urban and rural communities. In this chapter, the vital concepts of sustainablecommunity development are discussed. The IoT and sustainability interactions areexplained with emphasis on Sustainable Development Goals (SDGs) and commu-nication technologies. Moreover, IoT opportunitiesand challenges are discussed inthe context of sustainable community development.1.1 IntroductionThe sustainability is one of the vital factors in realization of the digital future.The Internet of Things (IoT) is envisaged as one of the enabling paradigms of thissustainable digital transformation and community development. In this book, thecommunity is referred as any geographical zones that function under some sortof structure and resources at its disposal to meet their current and future needs.The community sustainability depends on risk tolerance. The combined economicvalue of the industrial IoT along with public and consumer sector is likely to bemore than $15 trillion by 2030 [28, 67, 71]. Moreover, the convergence of the IoTwith other technologies (e.g., artificial intelligence (AI), technological revolution,blockchain, cluster and cloud computing) presents a tremendous potential forsustainable community development.1The accepted (peer-reviewed) version for self-archiving. https://doi.org/10.1007/978-3-030-35291-2_12 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .1.1.1 Global Efforts to Address SustainabilityA United Nations conference on the human environment was held in Stockholm,Sweden in 1992. It was the first conference to discuss environmentalissues. A reporttitled \u201cOur Common Future\u201d (also referred to as Brundtlandreport [38]) publishedby World Commission on Environmentand Development defined sustainability as:\u201cdevelopment that meets the needs of the present without compromising theability of future generations to meet their own needs\u201dThis reportplayed an importantrole in increasing the awareness of environmentalsustainable development. It identifiedmany issues and changed our thinkingtowardsthe sustainability. Accordingly, the United Nations started developing indicatorsand systems for sustainable development. Since then many conferences are held forsustainable development. The progress made these conferences is outlined below:\u2022 In 1983, the General Assembly (resolution 38/161) established a special com-mission to report on strategies for sustainable development, environment, andthe global problems by 2000. The commission was later renamed to WorldCommission on Environmentand Development.\u2022 Earth Summit, United Nations Conference on Environment and Development(UNCED), June 1992. Approximately, 100 heads of state met in this EarthSummit to discuss pressing problems in environmental protection and socio-economic sustainable development.\u2022 Barbados Programme of Action (BPOA). UN General Assembly resolution47/189. UN Global Conference on the Sustainable Development of SIDS,Barbados, 1994. A 14-point program identified priority areas recommendedactions.\u2022 A UN General Assembly review session was held to review progress ofsustainable development in New York, USA in 1997.\u2022 World Summit on Sustainable Development (WSSD). The Johannesburg summitwas held in 2002 to address challenges in improving human lives, naturalresources conservation, increasing water, sanitation, energy, food, shelter, andhealth.\u2022 Mauritius Strategy of Implementation (MSI 2005). It was held in Port Louis,Mauritius to review sustainability progress in 2005.\u2022 MSI+5. It was held in New York, USA in 2010 to review Mauritius Strategy ofImplementation.\u2022 The UN Conference on Sustainable Development (Rio+20) in Rio de Janeiro,Brazil, in June 2012. It was decided to develop a set of Sustainable DevelopmentGoals (SDGs) on top of the millennium development goals (MDGs).1.1 Introduction 3Fig. 1.1 The UN Sustainable Development Goals [41]1.1.2 Sustainable Development Goals (SDGs)In 2015, UN General Assembly set forth the Sustainable Development Goals(SDGs) in its resolution70/1 with 2030 [71] as the target year [66]. These goals havebeen developed with the communityinvolvement including academia, governments,and private sector. It encompasses three major sustainable community developmentdimensions (e.g., protection of the environment, social diversity and inclusions,and economic growth). The SDGs have become the widely accepted and adoptedstandard system to attain the aim of sustainable community development. Thesegoals are important in the entire IoT paradigm to increase the sustainability andsocial impact. The UN Sustainable Development Goals are shown in Fig. 1.1.The IoT with its ability to sense and communicate through interconnection ofthings and systems in different environments has the great benefit of achievingthese sustainable development goals. In the sustainability area, the IoT alongwith technology is going to be a huge game changer in the near future. It is acomprehensive, commercially viable, widely available and accepted technology toachieve these goals with many social and economic benefits at the regional andnational level to broader community.1.1.3 Sustainability IndicatorsThe indicators of sustainability are useful to describe minimum and contemporaryrequirements for sustainability. Accordingly, management policies and actions canbe evaluated to make a reliable forecast of future changes.4 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .\u201cindicators must provide information relevant to specific assessment ques-tions, which are developed to focus monitoring data on environmentalmanagement issues.\u201d\u2014Ev aluation Guidelines for Ecological Indicators [37].The sustainability indicatorsalone cannothelp to achieve sustainable goals. Moredetailed actions are required at appropriatelevels coupled with policy decisions. Forexample, surface water quality indicatorsonly provide informationabout issues onlyat a small spatial and temporal scale requiring extrapolation for decision making.Accordingly, the sustainable development guides policies considering all thesefactors. In the next section, the potential of the IoT as a comprehensive enablingparadigm to achieve SDGs is discussed.1.2 IoT as Enabling Paradigm for SustainabilityThe Internetof Things (IoT) for sustainable communitydevelopmentis envisaged todevelop the engineered systems that enable sustainability by protecting the naturaland environmental systems [14, 16]. Through interconnection of systems, sensingand communicationtechnologies, IoT for sustainability aims to provide a paradigmthat balance community\u2019s need to provide ecological and environmental protection,and maintains secure economic society.The strong relationship between the Internetof Things and sustainability cannotbe overemphasized [9, 25, 32, 35, 59, 60, 65, 67, 68, 72]. For example, a flood,sewerage, and storm overflow monitoring [53] Internet of Things solution basedon sensing and communications supports sustainable communities (SDG 11) byreducing water related disasters and economic losses. An IoT for condition basedmaintenance of smart grid supports infrastructure (SDG 9). A city-scale smartlighting IoT supports improvements in energy efficiency (SDG 7). The next-generation wireless IoT has the potential of advancements in multiple fronts toaccommodate the ever-increasing demands of commercial applications, scientificinfrastructures, governmentalagencies, and public, in general; for better and larger-scale connectivity (SDG 9). In the area of humanhealth (SDG 3), instead of a singlemajor technological breakthrough the community can rely on the culmination ofseveral key enabling IoT technologies. The wireless data harvesting IoT technolo-gies can provide managers and users real-time access to crop and soil moisture data,which supports effective water management decision making (SDG 2 and 12). Indigital forest management, the early warning system for drought stress can help toinitiate and prioritize actions (SDG 13). The forest soil moisture detection can guiderestoration decisions. These examples clearly show that sustainable communitydevelopment is the mainstream benefit of Internetof Things.1.4 Examples from Developing Countries 5In a study [28], the relationship between the Internetof Things and sustainabilityhas been explored. Particularly, the 640 different Internet of Things projectswere compared with the 17 SDGs in order to analyze the relationship betweensustainability and Internet of Things. It has been shown that 84% of the analyzedIoT projects exhibited strongerpotential to attain these goals. The five SDGs (SDG#3, 7, 9, 11, and 12) were emphasized by 75% of the projects. The IoT supportssustainable development in following areas:\u2022 Ecological Engineering. The IoT enables sustainable development in the areaecological engineering (e.g., rehabilitating and enhancementof ecological func-tions to natural systems and natural capital) [60].\u2022 Earth Systems Engineering. The sustainable development of IoT supports moni-toring of earth systems (e.g., greenhouse gas emissions). It has strong potential toguide adaption to varying climate, forestry, mining, energy systems, and relatedglobal scale concerns throughdevelopment of decision support systems [42].\u2022 Industrial Ecology. The IoT fosters advancements and innovations in the areaof industrial ecology, including evolution of life cycle assessment and economicmodels, and measurements for sustainable systems [84].\u2022 Environmental Sustainability and Green Engineering. The IoT paradigm hasgreat potential to advance the sustainability of infrastructures (e.g., water, recy-cling and reuse of drinking water, stormwater, waste water, climate assessment)[47]. Accordingly, the IoT guides innovations and growth strategies in distribu-tion and collection systems based on its sensing and monitoringparadigm.1.3 SDG Goals and Sustainable IoT SystemsThe examples of the sustainable IoT systems in developing and developed countriesare explained in the following.1.4 Examples from Developing CountriesIn developing and emerging countries the IoT paradigm has the strong potentials tomake big improvements in sustainability and human life [28]. With the increasingcoverage of wireless networks in developing countries, it has become easier toform IoT networks with interconnection of \u201cthings.\u201d The second/third generationwireless/cellular networking infrastructure in emerging countries surpasses thanelectricity, water, and sewage infrastructure. The adaption of modern technologysuch as technological innovations in the field of digital agriculture, health, envi-ronmental monitoring, energy systems, water resource monitoring, and livestock,is lacking due to lack on basic resources and supporting infrastructure requiredfor technology operation in developed countries. Consequently, the IoT monitoring6 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .systems are either in their infancy or do not exist. Scarce connectivity andspectrum availability are some of the other limiting factors. Therefore, there isneed of ubiquitous connectivity with energy efficient, low-cost wireless, machineto machine (M2M), and sensing technologies. Moreover, great potential exists forsustainable community development using IoT in various areas. The prospects fora variety of sustainable IoT use cases are very high. Higher level of efficiency canbe achieved by using meaningful IoT paradigm and implementation. Accordingly,SDGs can be monitoredfor achieving sustainability goals.There are many examples of IoT deployments aroundthe globe which highlightsustainable community development. In the following some examples from thedeveloping countries are presented [28].\u2022 SDG 10, and 16: Secure biometric cash is being provided to refugees in Jordanby using the retina scan connected to financial IoT\u2022 SDG 7,9, 11: Fire and smoke detection IoT with alarms is being used in highlydense urban settlements in Kenya and South Africa\u2022 In Indian Ocean, the buoy IoT supports an early warning tsunami monitoringsystem\u2022 In east Africa and India, the low income households are being powered by microsolar electricity off-grid IoT\u2022 Black carbon sensing IoT supports cooking stoves monitoring in Sudan\u2022 Public transportationconnected mini buses IoT in Kenya is being used to monitoracceleration, speed, and braking to control risky driving\u2022 SDG 12, 13, 14, 15: In East Timor, cloud based IoT supportsmotoringthe illegalfishing activity\u2022 Air pollution monitoring IoT to sense outdoorair pollution in Benin\u2022 Acoustics based sensing IoT are being used to monitorsee bird migrationpatternsand population count\u2022 In Africa, animal tracking IoT supports game parks management\u2022 In UAE, drone and groundcamera monitoringIoT is being used by national parkservice\u2022 In Indonesia, digital forestry IoT supports monitoringfor illegal logging activity\u2022 SDG 4: In South Africa, school attendance IoT has interconnected the students,faculty with the automated attendance system using biometric features\u2022 SDG 1,2, and 8: In Kenya, a weather monitoringIoT supports accurate weatherforecasting\u2022 In India, pumps are interconnectedusing irrigation IoT for mobile-based irriga-tion management\u2022 Agriculture IoT based on soil moisture sensing to tea crop in Sri Lanka andRwanda\u2022 Herd IoT in Namibia, Senegal, and Botswana, for animal tracking, keeping healthrecords, and theft control.\u2022 SDG 3 and 6: In Rwanda and Kenya, SMS and sensor-enabled water pumps tosupport villagers1.5 IoT Challenges for Sustainability 7\u2022 Cellular connected cool chain IoT is being used for refrigerated delivery ofvaccines\u2022 In west Africa, the medical IoT supports pulse, oxygen, and temperature,monitoring\u2022 River monitoringIoT to sense river depth and rate of flow in Honduras1.4.1 Examples from Advanced CountriesExamples of the sustainable IoT systems towards achieving SDG goals are dis-cussed below:\u2022 Internetof Things in Transportationand Logistics (IoTTL) [15]\u2022 Agricultural IoT (Ag-IoT) [77]\u2022 Internetof Battlefield Things [5]\u2022 Wearable IoT [75]\u2022 Internetof Body Things [20]\u2022 Internetof Things in Smart Lighting and Heating [13]\u2022 School Buses Transportationand Tracking IoT [26]\u2022 IoT of autonomousvehicle and unmannedaerial systems [18]\u2022 Payment facilitator [39]\u2022 Micro-Transit IoT [10]\u2022 Truck fleet IoT with charging stations [30]\u2022 Multi-model transportationand logistics IoT [30]\u2022 Garbage Monitoring IoT [29]\u2022 Waste and Storm overflow monitoringIoT [53]\u2022 Energy, Smart Meter, and Renewable Energy Systems IoT [45]\u2022 Urban parking IoT [4]\u2022 Mobility modeling and management IoT [63]\u2022 Traffic Counting IoT [62]\u2022 City utilities IoT [61]1.5 IoT Challenges for SustainabilitySince IoT market is still in infancy, there is need of comprehensive business modelsand proof-of-concept implementation.By employing the sustainability goals duringthe design phase of the IoT is required to attain its full potential and economicbenefit. Regulations, governmental incentives, monetary benefits, and tax credits,industry goodwill are some of the methods to encourage consideration of thesustainability goals at the system analysis and design of the IoT projects. Anefficient business model is vital for sustainable IoT development. Introduction ofaccreditation programs to certify sustainability goals of the IoT is needed.8 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .The management of huge amount of data being generated through connectedubiquitous IoT projects is a major challenge because of its competitive and ana-lytical value. The collection, ownership and storage of data, its usage and sharing,sensitivity and privacy are some of the contentious issues that need to be solved.The emergence of multitudeof IoT platform providers has caused fragmentationwhich is hindering the critically desired consensus for standarddevelopment in thearea of sensors, interfaces, and radios. The interoperability issues limit the choice ofavailable hardware for IoT projects and inter-system integration also suffers becauseof the closed standards.Collaboration among different stake holders particularly thestandardizationefforts can help to reduce the impact of fragmentation. Opening upthe data will also lead to development of cross-industry systems. These technicalpartnershipscan also be used to integrate different technologies together to providea unified front end.The lack of large-scale IoT infrastructure due to low interest from investmentsfrom public and private sector is also hindering sustainability goals. The utilizationof existing infrastructure, encouraging investors for IoT infrastructurethrough pol-icy incentive, simplified legal and regulatory frameworks will help in developmentof IoT infrastructures at a scale. Joint symposium of government, academia, andindustry leaders should be organized to discuss the sustainability promise of IoT inwater, energy, urban environment, and transportationareas.1.6 IoT DefinitionsIn this section, the IoT definitions as conceived by different standard bodies arepresented.1.6.1 Institute of Electrical and Electronics EngineersA network of items, each embedded with sensors which are connected to theInternet[1].1.6.2 International Telecommunication UnionThe International Telecommunication Union Telecommunication StandardizationSector (ITU-T) has defined IoT as a vision with technological and societal implica-tions:1.6 IoT Definitions 9Internet of things (IoT) is a global infrastructure for the information society,enabling advanced services by interconnecting (physical and virtual) thingsbased on existing and evolving inter-operable informationand communicationtechnologies [36].1According to this recommendation, the IoT, by using sensing and communica-tions capabilities, utilizes things to serve different types of application needs whileensuring security and privacy. The elements (terms) of the IoT paradigm are givenbelow [36]:\u2022 Device. A piece of equipmentwith the mandatory capabilities of communicationand the optional capabilities of sensing, actuation, data capture, data storage, anddata processing.\u2022 Things. An object of the physical world (physical things) or the informationworld (virtual thing).An infrastructureof interconnectedobjects, people, systems, and informationresources together with the intelligent services allow them to process infor-mation of the physical and the virtual world and react\u2014[79].21.6.3 Internet Engineering Task ForceThe Internet Engineering Task Force (IETF) excludes TCP/IP based Internet fromthe IoT domain because of private networks. To be considered an IoT it has tocontain both IP and other protocols. IETF defines IoT as:The Internetof Things is the network of physical objects or \u201cthings\u201d: embed-ded with electronics, software, sensors, and connectivity to enable objectsto exchange data with the manufacturer, operator, and/or other connecteddevices [34].31ITU-T Rec. Y.2060 (06/2012) Overview of the Internetof things.2IT4IT References Architecture\u2014ISO/IEC JTC1 WG10.3IETF.10 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .IETF definition of \u201cthings\u201d:In the vision of IoT, \u201cthings\u201d are very various such as computers, sensors,people, actuators, refrigerators, TVs, vehicles, mobile phones, clothes, food,medicines, books, etc. These things are classified as three scopes: people,machine (for example, sensor, actuator, etc.), and information (for example,clothes, food, medicine, books, etc.). These \u201cthings\u201d should be identified atleast by one unique way of identification for the capability of addressing andcommunicating with each other and verifying their identities. In here, if the\u201cthing\u201d is identified, we call it the \u201cobject.\u201d [34]1.6.4 National Institute of Standards and TechnologyThe National Institute of Standards and Technology (NIST) defines IoT as:Internet of Things (IoT)\u2014involves connecting smart devices and systemsin diverse sectors like transportation, energy, manufacturing and healthcarein fundamentally new ways. Smart Cities/Communities are increasinglyadopting CPS/IoT technologies to enhance the efficiency and sustainabilityof their operation and improve the quality of life [48].4Internetof Things Architecture (IoTIA) describes IoT in the following manner:It can be seen as an umbrella term for interconnected technologies, devices,objects, and services [8, 33].1.7 Architecture of IoT Paradigm for SustainabilityThe Internet of Things (IoT) for sustainability concept is based on the definingnetwork of things and people in various environmental and natural settings goalsto achieve sustainable goals. This pertains to application of IoT concepts to these4NIST.1.7 Architecture of IoT Paradigm for Sustainability 11settings using sensing and communicationtechnologies, systems and tools tailoredto various applications domains and for different use cases. The sensing elementsprovide the interface to physical world which and are linked throughcommunicationtechnologies.1.7.1 IoT ElementsThe Internetof Things for sustainability consists following elements:\u2022 Sustainability Things. It is integral part of the IoT paradigm with the ability tohave physical or virtual connection to the IoT system.\u2022 Sensors/Actuators. An instrument/equipment for environmental, climate,forestry, water, and energy sensing. It consists interface for networking andcommunications,and may have on-unitprocessing, data storage capabilities.\u2022 Networking and Communications. To support interconnection of sustainabilitythings and sensors/actuatorscomponents.\u2022 Sustainability IoT System. It consists of interconnection of different elementssuch as things, sensors, and communication components integrated together toperform certain unique functions,\u2022 Holistic Sustainability IoT Paradigm. It is the paradigm in which different IoTsystems work together in order to achieve sustainability goals for a particularenvironmentThese environmentsare shown in Fig. 1.2.1.7.2 IoT FunctionsThe proper functionality of these sustainability IoT components is vital to meetrequirements and achieve sustainability goals. A clear description of these sus-tainability goals coupled with requirement is need for integration into the holisticsustainability IoT paradigm for various applications. A detailed list of thesefunctions along with examples is given in the following.\u2022 In IoT, the sensing function is used to sense physical, logical, and biologicalproperties of different environments in the physical world in the analog anddigital domains. Accordingly, this data becomes as input to subsequent functionsof the IoT can be used by data collection, networking, data storage, processing,and decision making functions. Examples include cloud sensing, soil sensing,and water sensing. Different examples of sensing mechanisms in various sustain-ability IoT sensing phenomenaare discussed in detail in this book in subsequentchapters.\u2022 The data collection is a major function of the IoT in which data is gathered,combined, and processed for a particular environmentthat provides the ability tocombine and process some data of interest within a given IoT system.12 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .Fig. 1.2 The Internetof Things (IoT) for sustainable community development\u2022 The networking functionof the IoT is used to transportsensed data from differentlocations to storage location and cloud for subsequent decision making function.These could function in delay tolerant and delay sensitive fashion dependingon the latency requirement of a particular sustainability paradigm. In the IoTfor sustainability paradigm the networking tiers contain many layers includingsatellite, aerial, terrestrial, underwater, and underground networks. These net-work tier functions are discussed in the next section. The network interface cardsare used to implement the networking and communications functions in the IoTparadigm and provide connective between links. The Ethernet adapter (IEEE 802Standard), long-termevolution (LTE) Bluetooth, and ZigBee are some examplesof these networking interface cards.\u2022 The data storage and cloud function of the IoT are related to storing the data andinformationover the spatial and temporal variation. The examples of data storagefunctions include precipitation data, soil moisture data, hydrometer data, airtemperature, wind speed and direction, water flow in different water bodies,nutrientsand ion concentrations, and forest inventory.\u2022 The processing function of the IoT converts raw sensed data to the usefulinformation and provide it to decision making function, where it can be utilizedby managers and policy makers. The center pivot control algorithms of actuatorunits in the sensor-guided irrigation management systems are one example of the1.8 Networking for Sustainability IoT Paradigm 13processing function where data is fed from underground sensors in the field ofdigital agriculture. Feedback control is another example.\u2022 Decision making. In this IoT function, a decision is made based on the datacollection and processing and accordingly, appropriate actions are taken whichresults into corresponding changes in the physical world to achieve the desiredsustainability goal. Some of the examples these functions include flow controlbased on flow nutrientssensing, correct application of water treatmentbased oncontaminants sensing, proper irrigation based on soil moisture sensing, cardiactreatment based on hear conditions, and fertilizer application based on the cropneeds. It also includes functionality related to the humaninteractionwith the IoTsystems using graphical user interfaces, touch displays, and voice interfaces. Thecybersecurity, encryption, and authenticationare other functionalities.1.8 Networking for Sustainability IoT ParadigmThe IoT for sustainable development will be deployed at large scales by usingnetworking and advanced 5G/6G communicationarchitectures to serve a wide vari-ety of applications in different area. These communicationnetworks are discussedbelow.1.8.1 Five-Tier NetworkThe potential of current terrestrial networks is too less to support ubiquitous cover-age connectivity requirementof sustainable IoT in climate, water, ocean, and energyareas. Therefore, to supportthese IoT paradigms, a multi-dimensionalnetwork withcapability to integrate terrestrial and non-terrestrialsystems is required. A five-tiernetwork can support this integration and consists of five different tiers includingspace, ground, air, underwater, and underground. In Fig. 1.3, a design of multi-tiernetwork is shown [83]. The sixth generation (6G) networks will have this capabilityto integrate multiple tiers which are explained below.1.8.1.1 Terrestrial Network TierThe terrestrial networks are the main tool to provide wireless connectivity for mostof the sustainability IoT paradigms discussed in this book. Terrestrial networkswill have the capability to operate in low frequencies, microwave spectrum, mm-wave, and THz bands. To supporthigher data rated (e.g., Tb/s), such as sustainablewater and climate measurements, the THz band can be utilized. Energy-efficientmmWave communicationdevices based on a hybrid beamforming approachcan alsosupport real-time high-data rate communication needs. These networks will havehigh density deployments because of the higher attenuationin mm-wave and THz.14 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .Fig. 1.3 The multi-tier network design [83]. The (a) network architecture and (b) interface designand operation of large-dimensional and autonomous networks. GEO: geostationary Earth orbit;LEO: low-Earth orbit; MEO: medium-Earthorbit; CN: core networks; D2D: device to device; C-RAN: cloud radio access networks; D-RAN: distributed radio access networks; ORI: ocean radiointerface; SRI: satellite radio interface1.8 Networking for Sustainability IoT Paradigm 15Optical fiber is needed as backbone of these networks. The importanttechnologiesfor the terrestrial networks are shown below [82]:\u2022 The millimeter wave, Terahertz communications, full-duplex communication\u2022 MIMO, distributed antennaarrays, DMIMO\u2022 Interference cancellation, cognitive radio networks, NB-LPWAN\u2022 Underwater/underground, large-scale network design, sensor networks\u2022 Cellular networks, device-to-device, cyberphysical systems\u2022 vehicular networks, UAV connectivity, safe UAV operation, green cellularnetworks\u2022 Cyber threat defense, mobile computing, network estimation, content deliverynetworks\u2022 Statistical signal processing, multimedia networking, security, and privacy\u2022 Smart grid, cloud-fog platforms, software-defined networking, and mobile edgenetworkingMoreover, the conventional SDRs with novel mmWave radio can be used to cre-ate unique solutions by combine beam agility for highly directional communicationin mobile environments with ultra-low-power characteristics. The design of novellow-loss hybrid electronically scanned arrays (ESA) capable of beamforming atmillimeter wave (mmW) frequencies for next-generation high data-rate communi-cations systems will be central for sustainable IoT realization.1.8.1.2 Space-Based Wireless Network TierThe wireless coverage requirements of the IoT for sustainability can be sup-ported by space network by using satellites [6]. The future space network canutilize densely deployed low-medium-geostationaryEarth orbit satellites to provideconnectivity uncovered and undeserved area (e.g., IoT for sustainable digitalagriculture). In agriculture, the irrigation and water management community hasmeasured soil moisture to inform water management and irrigation decisions fordecades. Automatedtechnologies have largely replaced the use of hand-held/manualsoil moisture technologies because of difficulties associated with taking manual soilmoisture readings in productionfields in remote locations.In the last decade, wireless data harvesting technologies have developed thatprovide managers and users real-time access to soil moisture data, which, hasresulted in more effective water management decision making. Unfortunately,advanced automatedand wireless soil moisture measurementtechnologies still facepractical application challenges. One challenge is a lack of consistent and robustwireless service in rural communities that prevent immediate access to soil moisturedata. Another is the difficulty of installing soil moisture sensors early in the growingseason and removing them at season end. Currently, users must drive long distancesto install and remove sensors in different locations duringthe growing season, whichcreates problems in deploying advanced technologies in productionfields.16 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .Therefore, wireless underground soil moisture devices imbedded permanently inthe soil, coupled with robust, reliable, and continuous wireless network servicesthrough satellites in rural agricultural communities, will significantly contributeto the adoption of technology and sustainable practices in production fields. Forlong-range, high data rate satellite to field communications in sustainable digitalagriculture, the satellites with mm-wave communicationscan be deployed.1.8.1.3 Aerial Network TierThe recent advancements in technology have made possible to deploy air networksin low frequency bands, microwave spectrum, and mm-wave bands using aerial basestations mounted on unmanned aerial vehicles complemented by space networks.The aerial networks can enable IoT paradigms in the harsh areas where terrestrialnetworks are unable to provide coverage [12]. One application of aerial networks isin IoT for sustainable water where pollution level monitoringand advanced nutrientmeasurements are used in water bodies to assess water quality to assists regulatorsfor pollution policy making.Currently, the UAV potential in sustainability IoT is limited in part by theirability to navigate spaces precisely and in a cost-effective manner. The existingmechanisms to support localization are often hampered by cost (e.g., GPS-RTK),service gaps (cell towers), or crowded environments (e.g., GPS).1.8.1.4 Underwater Network TierThe underwater networks will enable sustainable IoT monitoring applicationsoceans, estuaries, rivers, lakes, streams, canals, and wetlands [7, 17, 64, 78]. Dueto different wave propagation characteristics in the water medium from over-the-air(OTA), the acoustics and laser propagation can be utilized to attain higher data ratesfor in underwater communicationand networking. It has applications in sustainableclimate IoT in tsunami and undersea earthquake monitoring.1.8.1.5 Underground Network TierIn a new type of wireless communications (wireless underground (UG) communi-cations) [2, 76], radios are buried underground and communication is conductedpartly through the earth. The underground communication (UG) solutions arein their infancy and depend on off-the-shelf radios, which are not designed forthe medium. For example, the maximum attainable communication ranges forunderground-to-underground links are limited to a few meters, which prohibitsthe establishment of multi-hop underground networks. On the other hand, UGradios can establish communication with aboveground devices at distances over200 m. While promising, these distances are still limited for some applications,1.9 Wireless Communicationsfor Sustainability IoT 17e.g., agricultural automation where large fields need monitoring with a limitednetwork architecture to mobile data harvesting components [19]. In addition, thedata rates attained by commercial off-the-shelf (COTS) solutions are limited to atens of kbps, which prohibits data-hungry applications, including real-time controland navigation components.To enhance wireless UG communication ranges, a novel theoretical frame-work for UG beamforming using adaptive antenna arrays to improve wirelessunderground communications performance [55] has been devised. A soil mois-ture adaptive beamforming (SMABF) algorithm was developed for planar arraystructures and simulations show, with different optimization approaches, rangecan be significantly improved. Similarly, multi-carrierunderground communicationthrough soil-adaptive sub-carrier and system bandwidth operation can significantlyimprove data rates [54, 57]. Currently, practical and large-scale evaluations ofthese techniques are cost prohibitive, limiting rapid commercialization for practicalapplications.Undergroundnetworks supportmany uniqueapplications in sustainability IoT byusing wireless UG communications (e.g., stormwater and wastewater monitoringIoT and agricultural IoT). Existing over-the-air (OTA) wireless communicationsolutions face significant challenges in meeting the unique requirements of Ag-IoTapplications. Therefore, these IoT paradigms for sustainability can use a diverseset of UG communication requirements and realistic scenarios to implement thecommunication range- and capacity-enhancing solutions in large scales. The inte-gration of UG communicationswith Ag-IoT will help conserve water resources andimprove crop yields [24, 27, 70, 74]; advances in Ag-IoT will benefit undergroundinfrastructure and landslide monitoring, pipeline assessment, underground mining,and border patrol [3, 19, 54, 56\u201358, 76].1.9 Wireless Communications for Sustainability IoTIn the following section, the key wireless communicationtechnologies and driversare discussed for the sustainability IoT.1.9.1 Key Drivers for Next-Generation Wireless Systemsin Sustainability IoT\u2022 The operation frequency in the spectrum is moving from the radio bands to sub-terahertz (THz) bands and visible spectrum (e.g., visible light communications).\u2022 The drive for automation and intelligence in wireless networks is relying onuse of advanced technologies such as artificial intelligence (AI) and machinelearning.18 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .\u2022 More robust and dynamic networking architectures to meet goals of sustainabledevelopment.\u2022 These innovations will also drive development in novel applications based onnetworking architectures.1.9.2 Wireless Requirements for Sustainability IoTThe wireless communications and networking requirements for sustainability IoTrequires innovation to increase data rates, capacity, connectivity, spectrum usage,energy efficiency, and mobility [23]. The key requirements are listed in thefollowing:\u2022 Peak Data Rates. The current peak data rates of 5G are around 10 gigabits persecond (Gbps), whereas to meet sustainability IoT demands, the data rates of 1Tb/s are required. This hundredtimes higher data rates demand than the currentcan be met by the next-generation technologies such as 6G, where the peak back-hual and front-hauldata rates of 10 Tb/S can be achieved.\u2022 Due to multitude of technologies operators vying for the scarce spectrum,spectrum efficient communications are vital for sustainability IoT. Particularity,in multi-tier networks, the same connectivity zones will be covered by multipleaccess network tiers, causing severe interference among tiers within in theparadigm. Therefore, advancement in interference mitigation, suppression, andcancellation techniques are required. Integration of licensed and unlicensedtechnologies (e.g., short-range Wi-Fi and long-range cellular) is also necessaryto connect all sustainability things in different IoT applications.\u2022 Application Specific Data Rates. For some scenarios, such hyper-spectral min-eralogy sensing techniques, application specific data rates of 1\u201310 10 Gb/s ratesare required.\u2022 Extreme energy efficient technology and devices are required to support pro-longed uninterrupted operation in some of the sustainability IoT scenariossuch as urban underground infrastructuremonitoring, storm and sewer overflowmonitoring, and underground soil sensing. For example, IoT devices can awakefrom the sleep mode for data reception after periods of longer durationto extendbattery life.\u2022 Latency and Mobility. To archive quality of service (QOS), an OTA latency of0.01\u20130.1 ms and extremely high mobility (621 miles/h) is required for sustain-ability IoT paradigm. More, low latency space-to-air and space-to-ground linksare needed.\u2022 Novel gateways, protocols, and standards are required to integrate differentnetwork tiers. One example of this link is interconnectionbetween IoT devicesin aerial networks and sensors in underground and underwater networks. Otherexamples include aerial to ground stations, space to aerial to ground. Things topeople interactiongateways can utilize computervision, always-on discovery and1.9 Wireless Communicationsfor Sustainability IoT 19awareness, and machine learning. Moreover, advancements in Things-to-Things(T2T) communicationtechnologies are needed.\u2022 Connectivity Density. For water climate monitoringIoT applications, a very highdensity of approximately 145 devices/mi2 and with subnetwork capacity of morethan 1 Gb per second per square mile. This will help to attain interoperabilityacross multiple sustainability paradigms.\u2022 Cybersecurity. It is discussed in detail in Chap. 10.1.9.3 Wireless Standard Applications to Sustainability IoT1.9.3.1 RF Wireless Modem ChipsetThe chipset with ability to supportmultiple wireless and cellular standardswill playcortical role to achieve the regional and local connectivity in different applicationsin sustainability IoT paradigm (e.g., health, security, and energy). In this regard,innovations are needed to produce cost-effective and scalable RF wireless modemchipset design [52]. Any such chipset will support multiple bands and modes withpower saving, battery life for up to a decade through advanced power savingwith Bluetooth, voice, and Wi-Fi interfaces with backward compatibility. Otherimportant wireless interfaces include GSM, LTE FDD and TDD, EDGE/EGPRS,DC-HSPA, LR-WPAN, and TD-SCDMA. AllJoyn Open Connectivity Foundation(OCF) is an open source framework inter- interface/device/application securecommunication protocol supports discovery of devices manufactured by differentvendors.1.9.4 Standardization for Sustainability IoT1.9.4.1 Long-Term Evolution (LTE) IoTThe long-termevolution (LTE) is an enabler for high performance and scalable sus-tainability IoT services can provide high data rate (Gigabit) [46]. It has high energyand power efficiency to address sustainability IoT needs. It combines improvedmachine type communication (eMTC Cat-M1) and the narrowband IoT (NB-IoT)for narrowband applications (Cat-NB1) and supports grant-free uplink, and multi-hop mesh. The low complexity, long range, and low power communications insustainability IoT can be supported by using NB-IoT and eMTC (e.g., agriculture,wearable, health, smart meters, and climate). The LTE Direct is a device-to-device(D2D) protocol that uses LTE user authentication, resource allocation and timingfeatures to provide neighbor discover, and connectivity to mobile nodes in the nodeproximity.20 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .1.9.4.2 802 Wi-Fi StandardsThe Wi-Fi has the great potential to provide connectivity to many IoT devices andthings to achieve sustainability. These 802.11 Wi-Fi standardswhich can be utilizedfor sustainability IoT are shown below [31]:\u2022 802.11ah for low power operation in the 902\u2013928 MHz frequency bands\u2022 802.11ac for 5 GHz spectrum unlicensed uses\u2022 802.11ad for WiGig networking\u2022 802.11ay for 60 GHz unlicensed uses\u2022 802.11ax for dense networking environmentMany important alliances include: HomePlug Alliance [49], Bluetooth SpecialInterest Group (Bluetooth SIG) [11], Open Connectivity Foundation (OCF) [43],the Thread Group [40], the Powerline technologies, and oneM2M. In a recent trailof high data rate communications, it has been shown that it is possible to achieve100 Gb/s in microwave spectrum using multiple-input, multiple-output (MIMO)for a communication range of approximately 1 mile. This trial has shown thefeasibility of better communications in microwave as compared to the millimeter(mm-wave) communications [81]. The important trial parameters are: 8 \u00d7 8 LOSMIMO, 2.5 GHz channel bandwidth in the 70 and 80 GHz (E band) with highspectrumefficiency of 55.19 b/s/Hz.Recently, an autonomousunmannedbroadbandsmart surface vessel was operated remotely using 4G network for water quality andpollutants sensing.1.9.4.3 5G and 6G Wireless CommunicationsCurrently, the 5G communications[22] are envisioned as big technology driver forthe Internetof Things particular for sustainable communitydevelopment(e.g., smartcities, public safety, transportation,smart energy usage, connected and autonomousvehicles, and health care). Through its better than 4G speeds, energy and spectrumefficiency, low latency and higher reliability, the 5G wireless networking the vitalto realize sustainability IoT and its real-time data-intensive communication needsin applications such real-time video streaming for police body cams and medicalimaging.Currently, there are many challenges in 5G. Although in 5G, the ultra-reliable,low latency communications (URLLC) [69] has the potential to support sustain-ability IoT applications, its performance suffers from the small packet size issuesthat is a limiting factor for higher data rates. More, the support for sensing,communications, things, and system convergence is limited in 5G and moreimprovements are needed in this area. Another needed feature in regard to IoTthe support for visualization the radio access network (vRAN) due to front-haulchallenges. Moreover, in 5G dynamic pricing models are needed based on capacityand usage. The limitations of slow data rates, convergence of IoT sensing, systems,1.9 Wireless Communicationsfor Sustainability IoT 21Fig. 1.4 The 6G application scenarios [83]. (a) The 6G application scenarios, (b) typical scenariosand (c) key capabilities of 6G networksand wireless communication,and open interfacing related issues can be solved withnovel networking architectures of 6G wireless communications which is discussednext (Fig. 1.4).The road-map to 6G wireless communicationshas already started to take shape.The requirements and trends are being defined with 6G enabling technologies forconnected intelligence and things. The prominent 6G goals and desirable featuresare listed below [83].\u2022 Support of extremely high data rates (in Tb/S) as comparedto current4G wirelesscommunications\u2022 High energy efficiency, energy harvesting, and wireless power transfer to supportIoT\u2022 The ultra-low latency in data and control planes in few microseconds22 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .\u2022 Support for a very wide spectrum in GHz and THz bands such as from 72 GHzto 141 GHz and 1000 GHz to 3000 GHz,\u2022 Convergence of space and ground based wireless networks to provide globalconnectivity and coverage\u2022 Intelligence built into the network through machine learning, enhanced mobilebroadband (eMBB) [44] ultra-reliable, low latency communications (URLLC)[69], and massive machine-type communications(mMTC) [50].1.9.5 Artificial Intelligence and WirelessThe artificial intelligence (AI) will play a key role in optimization and autonomousfunctionality of the network [80]. A list of AI algorithms in networking is shownin Fig. 1.5. The AI enabling technologies in wireless communicationsare discussedbelow:\u2022 Application of AI training methods specifically the machine learning in wirelesscommunicationswill bring innovation and performance improvements. This canbe achieved intelligence management and autonomousagent.\u2022 The neural networks based deep learning for data driven approaches in wireless.\u2022 AI applications to address network management, complexity, and QoS issues innext-generation wireless networks.1.9.6 Wireless Spectrum PaucityThe wireless spectrum scarcity is major challenge for heterogeneous wirelesssystems. The demand for wireless spectrum to meet the needs of sustainability IoTapplications is increasing which could be met the identification and allocation ofadditional spectrum. Spectrum sharing throughcognitive radios is anotherapproachto address the issue of dearth of spectrum where unlicensed users can use thespectrum when the primary user is not present in the licensed spectrum. The effortsof the United States Federal Communications Commission (FCC) to address thisissue through rulemaking are presented below [21, 73]:\u2022 Use of Spectrum Bands Above 24 GHz For Mobile Radio Services\u2022 Establishing a More Flexible Framework to Facilitate Satellite Operations in the27.5\u201328.35 GHz and 37.5\u201340 GHz Bands\u2022 Petition for Rulemaking of the Fixed Wireless Communications Coalition toCreate Service Rules for the 42\u201343.5 GHz Band\u2022 Petition for Rulemaking of the Fixed Wireless Communications Coalition toCreate Service Rules for the 42\u201343.5 GHz Band1.9 Wireless Communicationsfor Sustainability IoT 23Fig. 1.5 AI algorithms in networking [83]\u2022 Allocation and Designation of Spectrum for Fixed-Satellite Services in the37.5\u201338.5 GHz, 40.5\u201341.5 GHz, and 48.2\u201350.2 GHz Frequency Bands\u2022 Allocation of Spectrum to Upgrade Fixed and Mobile Allocations in the40.5\u201342.5 GHz Frequency Band\u2022 Allocation of Spectrum in the 46.9\u201347.0 GHz Frequency Band for WirelessServices\u2022 Allocation of Spectrum in the 37.0\u201338.0 GHz and 40.0\u201340.5 GHz for Govern-ment Operations24 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .1.9.7 Rural Broadband TelecommunicationsThe broadband infrastructure is vital for the proper functionality of sustainabilityIoT. In rural areas, there are many challenges being faced by the service providers(e.g., network extension to under covered areas, need of infrastructure upgrades tomeet increasing demand)[51]. Rural broadbandis importantto provide connectivityto agricultural users and things.1.9.8 Satellite CommunicationsThe satellite communicationsalso play an importantrole to provide connectivity tothe sustainability IoT paradigm things. A Global Low Power Wide Area Network(LPWAN) to support IoT devices around the world by combining the Inmarsat\u2019sglobal connectivity as backhaul connectivity and Actility\u2019 s LoRaWAN technology.Various applications are enabled by this network such cattle tracking systems forremote ranches, water and soil moisture monitoring in agriculture, and remoteoil facility monitoring in areas where cellular coverage does not exist. Other sus-tainability IoT applications that can benefit from satellite communications includesmart grid, underground and surface pipeline monitoring, vehicular fleet tracking,water resource management, disaster response, remote and critical infrastructuremonitoring,environmentalprotection,wind turbinemonitoring,and bordersecurity.1.10 Organization of the BookThe book covers the research and innovation ecosystem of the sustainable Internetof Things in the following major areas:\u2022 Climate change\u2022 Sustainable energy systems\u2022 Sustainable water\u2022 Human health\u2022 Sustainable mining\u2022 Decision agriculture\u2022 Storm and wastewater\u2022 Sustainable forestryWhile each of these areas will emphasize a core IoT research challenges andsolutions while leveraging their shared traits, interdependencies, and expertise toconverge on applications of IoT to sustainability challenges. In the following, wehighlight the above mentioned areas each with a collection of supporting conceptsthat are developed and explored in this book. Many of these areas emphasize crosscutting activities that support major cohesive goal of sustainability.1.10 Organization of the Book 25Chapter 2: Internet of Things for Environmental Sustainability and ClimateChange Our world is vulnerable to climate change risks such as glacier retreat,rising temperatures,more variable and intense weather events (e.g., floods, droughts,frosts), deteriorating mountain ecosystems, soil degradation, and increasing waterscarcity. However, there are big gaps in our understanding of changes in regionalclimate and how these changes will impact human and natural systems, making itdifficult to anticipate, plan, and adapt to the coming changes. The IoT paradigm inthis area can enhance our understanding of regional climate by using technologysolutions, while providing the dynamic climate elements based on IoT sensing andcommunications that is necessary to support climate change impacts assessmentsin each of the related areas (e.g., environmental quality and monitoring,sustainableenergy, agricultural systems, cultural preservation, and sustainable mining). In theIoT in Environmental Sustainability and Climate Change chapter, a framework forinformed creation, interpretation and use of climate change projections and forcontinued innovations in climate and environmental science driven by key societaland economic stakeholders is presented.Chapter 3: Internet of Things in Agricultural Innovation and Security Theagricultural Internetof Things (Ag-IoT) paradigm has tremendouspotential in trans-parent integration of underground soil sensing, farm machinery, and sensor-guidedirrigation systems with the complex social network of growers, agronomists, cropconsultants, and advisors. The aim of the IoT in agricultural innovation and securitychapter is to present agricultural IoT research and paradigm to promote sustainableproduction of safe, healthy, and profitable crop and animal agricultural products.The chapter covers the IoT platform to test optimized management strategies,engage farmer and industry groups, and investigate new and traditional technologydrivers that will enhance resilience of the farmers to the socio-environmentalchanges. A review of state-of-the-art communicationarchitectures, and underlyingsensing technology and communication mechanisms has been presented withcoverage of recent advances in the theory and applications of wireless undergroundcommunication. Major challenges in Ag-IoT design and implementation are alsodiscussed.Chapter 4: Internet of Things for Water Sustainability The water is a finiteresource. The issue of sustainable withdrawal of freshwater is a vital concernbeing faced by the community. There is a strong connection between the energyand water which is referred as energy-water nexus. The agriculture industry andmunicipalities are struggling to meet the demand of water supply. This situationis particularly exacerbated in the developing countries. The projected increasein world population requires more fresh water resources. New technologies arebeing developed to reduce water usage in the field of agriculture (e.g., sensorguided autonomousirrigation management systems). Agricultural water withdrawalis also impacting ground and surface water resources. Although the importance ofreduction in water usage cannot be overemphasized, major efforts for sustainable26 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .water are directed towards the novel technology development for cleaning andrecycling. Moreover, currently, energy technologies require abundant water forenergy production. Therefore, energy sustainability is inextricably linked to watersustainability. The water sustainability IoT has a strong potential to solve manychallenges in energy-water nexus. In this chapter, the architecture of IoT for watersustainability is presented. An in-depth coverage of sensing and communicationtechnologies and water systems is also provided.Chapter 5: Internet of Things for Sustainable Forestry Forests and grasslandsplay an importantrole in water and air purification, prevention of the soil erosion,and in provision of habitat to wildlife. Internet of Things has a tremendouspotential to play a vital role in the forest ecosystem management and stability. Theconservation of species and habitats, timber production, prevention of forest soildegradation forest fire prediction, mitigation, and control can be attained throughforest management using Internet of Things. Use and adoption of IoT in forestecosystem management are challenging due to many factors. Vast geographicalareas and limited resources in terms of budget and equipment are some of thelimiting factors. In digital forestry, IoT deployment offers effective operations,control, and forecasts for soil erosion, fires, and undesirable depositions. In thischapter, IoT sensing and communication applications are presented for digitalforestry systems. Different IoT systems for digital forest monitoring applicationsare discussed.Chapter 6: Internet of Things in Sustainable Energy Systems Our planet hasabundantrenewable and conventional energy resources but technological, capabilityand capacity gaps coupled with water-energy needs limit the benefits of theseresources to citizens. Through IoT technology solutions and state-of-the-art IoTsensing and communications approaches, the sustainable energy-related researchand innovation can bring a revolution in this area. Moreover, by the leveragingcurrent infrastructure, including renewable energy technologies, microgrids andpower to gas (P2G) hydrogen systems, the Internet of Things in sustainable energysystems can improve challenges in energy security to the communitywith a minimaltrade off to environment and culture. In this chapter, the IoT in sustainable energysystems approaches, methodologies, scenarios, and tools is presented with detaileddiscussion of different sensing and communicationstechniques. This IoT approachin energy systems is envisioned to enhance the bidirectional interchange of networkservices in grid by using Internet of Things in grid that will result in enhancedsystem resilience, reliable data flow, and connectivity optimization. Moreover, thesustainable energy IoT research challenges and innovation opportunities are alsodiscussed to address the complex energy needs of our community and promote astrong energy sector economy.Chapter 7: Internet of Things for Sustainable Human Health The sustainablehealth IoT has the strong potential to bring tremendous improvements in humanhealth and well-being through sensing, monitoring, of health impacts across thewhole spectrumof climate change. The sustainable health IoT enables developmentof a systems approach in the area of human health and ecosystem. It allows1.10 Organization of the Book 27integration of broader health sub-areas in a bigger archetype for improving sus-tainability in health in the realm of social, economic, and environmental sectors.This integration provides a powerful health IoT framework to sustainable healthand community goals in the wake of changing climate. In this chapter, a detaileddescription of climate related health impacts on human health is provided. Thesensing, communications, and monitoring technologies are discussed. The impactof key environmental and human health factors on the development of new IoTtechnologies is analyzed.Chapter 8: Internet of Things for Sustainable Mining The sustainable miningInternet of Things deals with the applications of IoT technology to the coupledneeds of sustainable recovery of metals and a healthy environment for a thrivingplanet. In this chapter, the IoT architecture and technology is presented to supportdevelopmentof a digital mining platform emphasizing the exploration of rock-fluid-environment interactions to develop extraction methods with maximum economicbenefit, while maintainingand preserving both water quantity and quality, soil, and,ultimately, human health. New perspectives are provided for IoT applications indeveloping new mineral resources, improved management of tailings, monitoringand mitigating contamination from mining, and tools to assess the environmentaland social impacts of mining including the demands on dwindling freshwaterresources. The cutting-edge technologies that could be leveraged to develop state-of-the-art sustainable mining IoT paradigm are also discussed.Chapter 9: Internet of Things in Water Management and Treatment The goalof the water security IoT chapter is to present a comprehensive and integratedIoT based approach to environmental quality and monitoring by generating newknowledge and innovative approaches that focus on sustainable resource man-agement. Mainly, this chapter focuses on IoT applications in sewer and stormwater management, and the human and environmental consequences of watercontaminantsand their treatment. The IoT applications using sensors for sewer andstorm water monitoringacross networked landscapes and water quality assessment,treatment,and sustainable management are presented. The studies of rate limitationsin biophysical and geochemical processes that support the ecosystem servicessupporting water quality are presented and the application of IoT solutions basedon these discoveries is discussed.Chapter 10: Internet of Things for Sustainability: Perspectives in Privacy,Cybersecurity, and Future Trends In the sustainability IoT, the cybersecurityrisks to things, sensors, and monitoring systems are distinct from the conventionalnetworking systems in many aspects. The interaction of sustainability IoT with thephysical world phenomena(e.g., weather, climate, water, and oceans) is mostly notfound in the modern information technology systems. Accordingly, the actuation,the ability of these devices to make changes in real world based on sensingand monitoring, requires special consideration in terms of privacy and security.Moreover, the energy efficiency, safety, power, performance requirements of thesedevice distinguish them from conventional computers systems. In this chapter, thecybersecurity approaches towards sustainability IoT are discussed in detail. The28 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .sustainability IoT risk categorization, risk mitigation goals, and implementationaspects are analyzed. The openness paradox and data dichotomy between privacyand sharing is analyzed. Accordingly, the IoT technology and security standarddevelopments activities are highlighted. The perspectives on opportunities andchallenges in IoT for sustainability are given. Finally, the chapter is concluded withsustainability IoT cybersecurity case studies.References1. 2413-2019 - IEEE approved draft standard for an architectural framework for the Internet ofThings (IoT). https://standards.ieee.org/project/2413.html2. Akyildiz, I. F., & Stuntebeck, E. P. (2006). Wireless underground sensor networks: Researchchallenges. Ad Hoc Networks Journal, 4, 669\u2013686.3. Akyildiz, I. F., Sun, Z., & Vuran, M. C. (2009). Signal propagation techniques for wirelessundergroundcommunicationnetworks. Physical Communication Journal, 2(3), 167\u2013183.4. Al-Turjman, F., & Malekloo, A. (2019). Smart parking in IoT-enabled cities: A survey.Sustainable Cities and Society, 49, 101608.5. Azmoodeh, A., Dehghantanha, A., & Choo, K. K. R. (2018). Robust malware detection forinternet of (battlefield) things devices using deep eigenspace learning. IEEE Transactions onSustainable Computing, 4(1), 88\u201395.6. Bacco, M., Boero, L., Cassara, P., Colucci, M., Gotta, A., Marchese, M., et al. (2019). IoTapplications and services in space information networks. IEEE Wireless Communications,26(2), 31\u201337.7. Basagni, S., Di Valerio, V., Gjanci, P., & Petrioli, C. (2017). Finding MARLIN: Exploitingmulti-modal communications for reliable and low-latency underwater networking. In IEEEINFOCOM 2017-IEEE Conference on Computer Communications (pp. 1\u20139). New York: IEEE.8. Bassi, A., Bauer, M., Fiedler, M., & Kranenburg, R.V. (2013). Enabling things to talk. Berlin:Springer.9. Beier, G., Niehoff, S., & Xue, B. (2018). More sustainability in industry through industrialinternetof things? Applied Sciences, 8(2), 219.10. Berke, S. (2019). The sustainable development of data-driven smart cities: Citizen-centeredurban governance and networked digital technologies. Geopolitics, History, and InternationalRelations, 11(2), 122\u2013127.11. Bluetooth, S. (2019). History of the Bluetooth special interest group.12. Chandrasekharan, S., Gomez, K., Al-Hourani, A., Kandeepan, S., Rasheed, T., Goratti, L.,et al. (2016). Designing and implementing future aerial communication networks. IEEECommunications Magazine, 54(5), 26\u201334.13. Cicirelli, F., Guerrieri, A., Mastroianni, C., Spezzano, G., & Vinci, A. (2019). The Internet ofThings for smart urban ecosystems. New York: Springer.14. Council, N. R. (2013). Sustainability for the nation: Resource connections and governancelinkages. Washington: National Academies Press.15. Da Xu, L., He, W., & Li, S. (2014). Internetof things in industries: A survey. IEEE Transactionson Industrial Informatics, 10(4), 2233\u20132243.16. Dale, V., Lowrance, R., Mulholland, P., & Robertson, G. (2010). Bioenergy sustainability atthe regional scale. Ecology and Society, 15(4), 23.17. Demirors, E., Shankar, B. G., Satagati, G. E., & Melodia, T. (2015). SEANet: A software-defined acoustic networking framework for reconfigurable underwater networking. In Pro-ceedings of the 10th International Conference on Underwater Networks & Systems (p. 11).New York: ACM.References 2918. Ding, G., Wu, Q., Zhang, L., Lin, Y., Tsiftsis, T. A., & Yao, Y.D. (2018). An amateur dronesurveillance system based on the cognitive internetof things. IEEE Communications Magazine,56(1), 29\u201335.19. Dong, X., Vuran, M. C., Irmak, S. (2013). Autonomous precision agriculture through inte-gration of wireless underground sensor networks with center pivot irrigation systems. Ad HocNetworks, 11(7), 1975\u20131987. http://dx.doi.org/10.1016/j.adhoc.2012.06.01220. Elhayatmy, G., Dey, N., & Ashour, A. S. (2018). Internet of things based wireless body areanetwork in healthcare. In Internet of things and big data analytics toward next-generationintelligence (pp. 3\u201320). New York: Springer.21. FCC spectrum. https://www.fcc.go v/tags/spectrum-022. Flynn, K. The mobile broadband standard. https://www.3gpp.org/news-events/3gpp-news/1929- nsa_nr_5g23. Fortino, G., Gravina, R., Li, W., Hassan, M. M., & Liotta, A. (2015). Enhancing internetand distributed computing systems with wireless sensor networks. International Journal ofDistributed Sensor Networks, 2015(11), 1\u20132.24. Fortino, G., Savaglio, C., Palau, C. E., de Puga, J. S., Ganzha, M., Paprzycki, M., et al.(2018). Towards multi-layer interoperability of heterogeneous IoT platforms: The INTER-IoTapproach. In Integration, interconnection, and interoperability of IoT systems (pp. 199\u2013232).New York: Springer.25. Garrity, J. (2015). Harnessing the internet of things for global development. Available at SSRN2588129.26. Godge, P., Gore, K., Gore, A., Jadhav, A., & Nawathe, A. (2019). Smart bus management andtracking system. International Journal of Latest Engineering Science, 2(2), 20\u201325.27. Gravina, R., Palau, C. E., Manso, M., Liotta, A., & Fortino, G. (2018). Integration, intercon-nection, and interoperability of IoT systems. New York: Springer.28. Harnessing the internet of things for global development. https://www.itu.int/en/action/broadband/Documents/Harnessing-IoT-Global-Development.pdf29. Hong, I., Park, S., Lee, B., Lee, J., Jeong, D., & Park, S. (2014). IoT-based smart garbagesystem for efficient food waste management. The Scientific World Journal, 2014, 13.30. Hopkins, J., & Hawking, P. (2018). Big data analytics and IoT in logistics: A case study. TheInternational Journal of Logistics Management, 29(2), 575\u2013591.31. IEEE 802.11. http://www.ieee802.org/11/32. Internet of things: Aligning the ecosystem towards sustainable adoption. https://es.weforum.org/projects/internet-of-things-aligning-the-ecosystem-towards-sustainable-adoption33. Internet of things architecture - iotforum.org. https://iotforum.org/wp-content/uploads/2014/09/D1.5-20130715- VERYFINAL.pdf34. Internet of things: Standards and guidance from the IETF. https://www.ietfjournal.org/internet-of-things-standards-and-guidance-from-the-ietf/35. IoT & sustainability: Practice, policy and promise. http://citris-uc.org/wp-content/uploads/2016/07/CITRIS_IoT-and-Sustainability-White-Paper.pdf36. ITU-T Rec. Y.2060 (06/2012) overview of the internet of things. https://www.itu.int/rec/T-REC-Y.2060- 201206- I37. Jackson, L. E., Kurtz, J., & Fisher, W. S. (2000). Evaluation Guidelines for EcologicalIndicators.38. Keeble, B. R. (1988). The Brundtland report: \u2018our common future\u2019. Medicine and War, 4(1),17\u201325.39. Khanna, A., & Tomar, R. (2016). IoT based interactive shopping ecosystem. In 2016 2ndInternational Conference on Next Generation Computing Technologies (NGCT) (pp. 40\u201345).New York: IEEE.40. Kim, H. S., Kumar, S., & Culler, D. E. (2019). Thread/OpenThread:A compromise in low-power wireless multihop network architecture for the internetof things. IEEE CommunicationsMagazine, 57(7), 55\u201361.41. Leleux, B., & van der Kaaij, J. (2019). Sustainable development goals. In Winning Sustainabil-ity Strategies (pp. 81\u2013102). New York: Springer.30 1 Internetof Things for Sustainable CommunityDevelopment: Introductionand. . .42. Li, D., Yao, Y., Shao, Z., & Wang, L. (2014). From digital earth to smart earth. Chinese ScienceBulletin, 59(8), 722\u2013733.43. Li, Y., Huang, X., & Wang, S. (2019). Multiple protocols interworking with open connectivityfoundationin fog networks. IEEE Access, 7, 60764\u201360773.44. Liolis, K., Geurtz, A., Sperber, R., Schulz, D., Watts, S., Poziopoulou, G., et al. (2019).Use cases and scenarios of 5G integrated satellite-terrestrial networks for enhanced mobilebroadband: The SaT5G approach. International Journal of Satellite Communications andNetworking, 37(2), 91\u2013112.45. Liu, Y., Yang, C., Jiang, L., Xie, S., & Zhang, Y. (2019). Intelligent edge computing for IoT-based energy management in smart cities. IEEE Network, 33(2), 111\u2013117.46. Long term evolution for machines: LTE-M. https://www.gsma.com/iot/long-term-evolution-machine-type-communication-lte-mtc-cat-m1/47. Maksimovic, M. (2018). Greening the future: Green internet of things (G-IoT) as a keytechnological enabler of sustainable development. In Internet of things and big data analyticstoward next-generation intelligence (pp. 283\u2013313). New York: Springer.48. Materese, R. (2019). Internetof things (IoT). https://www.nist.gov/topics/internet-things-iot49. Merkulov, A. G., & Shuvalov, V. P. (2019). The perspectives and practice of PLC HomePlugAV modems application in the network devices and industrial tools. In 2019 1st Global Power,Energy and Communication Conference (GPECOM) (pp. 46\u201349). New York: IEEE.50. Mikhaylov, K., Petrov, V., Gupta, R., Lema, M. A., Galinina, O., Andreev, S., et al.(2019). Energy efficiency of multi-radiomassive machine-type communication(MR-MMTC):Applications, challenges, and solutions. IEEE Communications Magazine, PP(99), 1\u20137.51. Nandi, S., Thota, S., Nag, A., Divyasukhananda, S., Goswami, P., Aravindakshan, A., et al.(2016). Computing for rural empowerment: Enabled by last-mile telecommunications. IEEECommunications Magazine, 54(6), 102\u2013109.52. Pang, H. Y., Agarwal, R., & Donaldson, T. A.: RF architecture utilizing a MIMO chipset fornear field proximity sensing and communication(2019). US Patent App. 10/211,889.53. Salam, A., & Shah, S. (2019). Urban underground infrastructure monitoring IoT: The pathloss analysis. In 2019 IEEE 5th World Forum on Internet of Things (WF-IoT) (WF-IoT 2019),Limerick.54. Salam, A., & Vuran, M. C. (2016). Impacts of soil type and moisture on the capacity of multi-carrier modulationin internetof undergroundthings. In Proceedings of the 25th ICCCN 2016,Waikoloa, HI.55. Salam, A., & Vuran, M. C. (2017). Smartundergroundantennaarrays: A soil moistureadaptivebeamforming approach. In Proceedings of the IEEE INFOCOM 2017, Atlanta.56. Salam, A., & Vuran, M. C. (2017). Wireless underground channel diversity reception withmultiple antennas for internet of underground things. In Proceedings of the IEEE ICC 2017,Paris.57. Salam, A., Vuran, M. C., & Irmak, S. (2016). Pulses in the sand: Impulse response analysis ofwireless undergroundchannel. In Proceedings of the IEEE INFOCOM 2016, San Francisco.58. Salam, A., Vuran, M. C., & Irmak, S. (2017). Towards internetof undergroundthings in smartlighting: A statistical model of wireless undergroundchannel. In Proceedings of the 14th IEEEInternational Conference on Networking, Sensing and Control (IEEE ICNSC), Calabria.59. Schneider, A. (2019). Internet of Things and Sustainability: A Comprehensive Framework.60. Schneider, S. (2019). The impacts of digital technologies on innovating for sustainability. InInnovation for sustainability (pp. 415\u2013433). New York: Springer.61. Simmhan, Y., Ravindra, P., Chaturvedi, S., Hegde, M., & Ballamajalu, R. (2018). Towardsa data-driven IoT software architecture for smart city utilities. Software: Practice andExperience, 48(7), 1390\u20131416.62. Singh, S., Singh, B., Singh, B., Das, A. (2019). Automaticvehicle countingfor IoT based smarttraffic management system for Indian urban settings. In 2019 4th International Conference onInternet of Things: Smart Innovation and Usages (IoT-SIU) (pp. 1\u20136). New York: IEEE.References 3163. Solmaz, G., Wu, F. J., Cirillo, F., Kovacs, E., Santana, J.R., Sanchez, L., et al. (2019).Toward understanding crowd mobility in smart cities through the internet of things. IEEECommunications Magazine, 57(4), 40\u201346.64. Song, W., Wang, Y., Huang, D., Liotta, A., & Perra, C. (2019). Enhancement of underwaterimages with statistical model of background light and optimization of transmission map.Preprint. arXiv:1906.08673.65. Stead, M. R., Coulton, P., Lindley, J. G., & Coulton, C. (2019). The little book of sustainabilityfor the internet of things.66. Sustainable development goals. https://www.undp.org/content/undp/en/home/sustainable-development-goals.html67. Sustainable development impact summit. https://www.weforum.org/events/sustainable-development-impact-summit-201968. Sustainability, smart cities, and the internet of things (2017). https://www.brookings.edu/events/sustainability-smart-cities-and-the-internet-of-things/69. Swamy, V. N., Rigge, P., Ranade, G., Nikolic\u0301, B., & Sahai, A. (2019). Wireless channeldynamics and robustness for ultra-reliable low-latency communications. IEEE Journal onSelected Areas in Communications, 37(4), 705\u2013720.70. Tan, X., Sun, Z., & Akyildiz, I. F. (2015). Wireless underground sensor networks: Mi-based communicationsystems for undergroundapplications. IEEE Antennas and PropagationMagazine, 57(4). https://doi.org/10.1109/MAP.2015.245391771. The 2030 agenda for sustainable development. https://sustainabledevelopment.un.org/content/documents/21252030AgendaforSustainableDevelopmentweb.pdf72. The effect of the internet of things on sustainability (2018). https://iot-analytics.com/effect-iot-sustainability/73. The voice of 5G and LTE for the Americas. https://www.5gamericas.org/74. Tiusanen, M. J. (2013). Soil scouts: Description and performance of single hop wirelessunderground sensor nodes. Ad Hoc Networks, 11(5), 1610\u20131618. http://dx.doi.org/10.1016/j.adhoc.2013.02.00275. Varatharajan, R., Manogaran, G., Priyan, M. K., & Sundarasekar, R. (2018). Wearable sensordevices for early detection of Alzheimer disease using dynamic time warping algorithm.Cluster Computing, 21(1), 681\u2013690.76. Vuran, M. C., & Akyildiz, I. F. (2010). Channel model and analysis for wireless undergroundsensor networks in soil medium. Physical Communication, 3(4), 245\u2013254. https://doi.org/10.1016/j.phycom.2010.07.00177. Vuran, M. C., Salam, A., Wong, R., & Irmak, S. (2018). Internet of underground things:Sensing and communications on the field for precision agriculture. In 2018 IEEE 4th WorldForum on Internet of Things (WF-IoT) (WF-IoT 2018), Singapore.78. Wang, Y., Song, W., Fortino, G., Qi, L. Z., Zhang, W., & Liotta, A. (2019). An experimental-based review of image enhancement and image restoration methods for underwater imaging.IEEE Access, 7, 140233\u2013140251. https://doi.org/10.1109/ACCESS.2019.293213079. Wg 10 (2019). https://jtc1info.org/sd_2-history_of_jtc1/jtc1-scs-and-groups/wg-10/80. Yao, M., Sohul, M., Marojevic, V., & Reed, J. H. (2019). Artificial intelligence defined 5Gradio access networks. IEEE Communications Magazine, 57(3), 14\u201320.81. Zhang, C., Zhang, W., Wang, W., Yang, L., & Zhang, W. (2019). Research challenges andopportunities of UAV millimeter-wave communications. IEEE Wireless Communications,26(1), 58\u201362.82. Zhang, J., Kang, K., Huang, Y., Shafi, M., & Molisch, A. F. (2019). Millimeter and THz wavefor 5G and beyond. China Communications, 16(2), iii\u2013vi.83. Zhang, Z., Xiao, Y., Ma, Z., Xiao, M., Ding, Z., Lei, X., et al. (2019). 6G wireless networks:Vision, requirements, architecture, and key technologies. IEEE Vehicular Technology Maga-zine, 14(3), 28\u201341.84. Zhu, N., & Zhao, H. (2018). IoT applications in the ecological industry chain from informationsecurity and smart city perspectives. Computers & Electrical Engineering, 65, 34\u201343.63. Salam A. (2020) Internet of Things for Sustainable Community Development: Introduction and Overview. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-2_164. Salam A. (2020) Internet of Things for Environmental Sustainability and Climate Change. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-2_265. Salam A. (2020) Internet of Things in Agricultural Innovation and Security. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-2_366. Salam A. (2020) Internet of Things for Water Sustainability. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-2_467. Salam A. (2020) Internet of Things for Sustainable Forestry. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-2_568. Salam A. (2020) Internet of Things in Sustainable Energy Systems. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-2_669. Salam A. (2020) Internet of Things for Sustainable Human Health. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham.  DOI: https://doi.org/10.1007/978-3-030-35291-2_770. Salam A. (2020) Internet of Things for Sustainable Mining. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham.  DOI: https://doi.org/10.1007/978-3-030-35291-2_871. Salam A. (2020) Internet of Things in Water Management and Treatment. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham.  10.1007/978-3-030-35291-2_972. Salam A. (2020) Internet of Things for Sustainability: Perspectives in Privacy, Cybersecurity, and Future Trends. In: Internet of Things for Sustainable Community Development. Internet of Things (Technology, Communications and Computing). Springer, Cham.  DOI: https://doi.org/10.1007/978-3-030-35291-2_10 73. Salam, A.; Hoang, A.D.; Meghna, A.; Martin, D.R.; Guzman, G.; Yoon, Y.H.; Carlson, J.; Kramer, J.; Yansi, K.; Kelly, M.; Skvarek, M.; Stankovic, M.; Le, N.D.K.; Wierzbicki, T.; Fan, X. The Future of Emerging IoT Paradigms: Architectures and Technologies. Preprints 2019, 2019120276 (doi: https://doi.org/10.20944/preprints201912.0276.v1).74. A. Konda, A. Rau, M. A. Stoller, J. M. Taylor, A. Salam, G. A. Pribil, C. Argyropoulos, and S. A. Morin, \u201cSoft microreactors for the deposition of conductive metallic traces on planar, embossed, and curved surfaces,\u201d Advanced Functional Materials, vol. 28, no. 40, p. 1803020. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.20180302075. A. Salam, M. C. Vuran, and S. Irmak, \u201cPulses in the sand: Impulse response analysis of wireless underground channel,\u201d in The 35th Annual IEEE International Conference on Computer Communications (INFOCOM 2016), San Fran- cisco, USA, Apr. 2016.76. A. Salam and M. C. Vuran, \u201cImpacts of soil type and moisture on the capacity of multi-carrier modulation in internet of underground things,\u201d in Proc. of the 25th ICCCN 2016, Waikoloa, Hawaii, USA, Aug 2016.77. A. Salam, M. C. Vuran, and S. Irmak, \u201cTowards internet of underground things in smart lighting: A statistical model of wireless underground channel,\u201d in Proc. 14th IEEE International Conference on Networking, Sensing and Control (IEEE ICNSC), Calabria, Italy, May 2017.78. A. Salam and M. C. Vuran, \u201cSmart underground antenna arrays: A soil moisture adaptive beamforming approach,\u201d in Proc. IEEE INFOCOM 2017, Atlanta, USA, May 2017.79. \u2014\u2014, \u201cWireless underground channel diversity reception with multiple antennas for internet of underground things,\u201d in Proc. IEEE ICC 2017, Paris, France, May 2017.80. \u2014\u2014, \u201cEM-Based Wireless Underground Sensor Networks,\u201d in Underground Sensing, S. Pamukcu and L. Cheng, Eds. Academic Press, 2018, pp. 247 \u2013 285.  63. A. Salam, M. C. Vuran, and S. Irmak, \u201cDi-sense: In situ real- time permittivity estimation and soil moisture sensing using wireless underground communications,\u201d Computer Networks, vol. 151, pp. 31 \u2013 41, 2019. [Online]. Available: http://www.sciencedirect.com/science/article/pii/ S138912861830314164. A. Salam and S. Shah, \u201cUrban underground infrastructure monitoring IoT: the path loss analysis,\u201d in 2019 IEEE 5th World Forum on Internet of Things (WF- IoT) (WF-IoT 2019), Limerick, Ireland, Apr. 2019.65. A. Salam, \u201cPulses in the sand: Long range and high data rate communication techniques for next generation wireless underground networks,\u201d ETD collection for University of Nebraska - Lincoln, no. AAI10826112, 2018. [Online]. Available: http://digitalcommons.unl.edu/dissertations/AAI1082611266. A. Salam and S. Shah, \u201cInternet of things in smart agriculture: Enabling technologies,\u201d in 2019 IEEE 5th World Forum on Internet of Things (WF-IoT) (WF-IoT 2019), Limerick, Ireland, Apr. 2019.67. A. Salam, M. C. Vuran, X. Dong, C. Argyropoulos, and S. Irmak, \u201cA theoretical model of underground dipole antennas for communications in internet of under- ground things,\u201d IEEE Transactions on Antennas and Propagation, 2019.68. A. Salam, \u201cUnderground soil sensing using subsurface radio wave propagation,\u201d in 5th Global Workshop on Proximal Soil Sensing, COLUMBIA, MO, May 2019.69. \u2014\u2014, Underground Environment Aware MIMO Design Using Transmit and Receive Beamforming in Internet of Underground Things. Cham: Springer International Publishing, 2019, pp. 1\u201315.70. A. Salam and U. Karabiyik, \u201cA cooperative overlay approach at the physical layer of cognitive radio for digital agriculture,\u201d in Third International Balkan Conference on Communications and Networking 2019 (BalkanCom\u201919), Skopje, Macedonia, the former Yugoslav Republic of, Jun. 2019.71. A. Salam, \u201cAn underground radio wave propagation prediction model for digital agriculture,\u201d Information, vol. 10, no. 4, 2019. [Online]. Available: http://www.mdpi.com/2078-2489/10/4/14772. S. Temel, M. C. Vuran, M. M. Lunar, Z. Zhao, A. Salam, R. K. Faller, and C. Stolle, \u201cVehicle-to-barrier communication during real-world vehicle crash tests,\u201d Computer Communications, vol. 127, pp. 172 \u2013 186, 2018. [Online]. Available: http://www.sciencedirect.com/science/article/pii/ S014036641730522473. M. C. Vuran, A. Salam, R. Wong, and S. Irmak, \u201cInternet of underground things: Sensing and communications on the field for precision agriculture,\u201d in 2018 IEEE 4th World Forum on Internet of Things (WF-IoT) (WF-IoT 2018), Singapore, Feb. 2018.74. \u2014\u2014, \u201cInternet of underground things in precision agriculture: Architecture and technology aspects,\u201d Ad Hoc Networks, 2018.75. A. Salam, \"A Path Loss Model for Through the Soil Wireless Communications in Digital Agriculture\", in Proc. 2019 IEEE International Symposium on Antennas and Propagation (IEEE APS 2019), Atlanta, GA, USA, July 2019. 76. A. Salam, \"A Comparison of Path Loss Variations in Soil using Planar and Dipole Antennas\", in Proc. 2019 IEEE International Symposium on Antennas and Propagation (IEEE APS 2019), Atlanta, GA, USA, July 2019.77. Salam A. (2020) Internet of Things for Sustainable Community Development. Springer, Cham. DOI: https://doi.org/10.1007/978-3-030-35291-278. A. Salam, \"Design of Subsurface Phased Array Antennas for Digital Agriculture Applications\", in Proc. 2019 IEEE International Symposium on Phased Array Systems and Technology  (IEEE Array 2019), Waltham, MA, USA, Oct 2019. 79. A. Salam,  \"Subsurface MIMO: A Beamforming Design in Internet of Underground Things for Digital Agriculture Applications\",  J. Sens. Actuator Netw., Volume 8, No. 3, August 2019.  doi: 10.3390/jsan8030041",
      "id": 19175188,
      "identifiers": [
        {
          "identifier": "oai:docs.lib.purdue.edu:cit_articles-1025",
          "type": "OAI_ID"
        },
        {
          "identifier": "471975349",
          "type": "CORE_ID"
        },
        {
          "identifier": "286368292",
          "type": "CORE_ID"
        },
        {
          "identifier": "10.1007/978-3-030-35291-2_1",
          "type": "DOI"
        }
      ],
      "title": "Internet of Things for Sustainable Community Development: Introduction and Overview",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:docs.lib.purdue.edu:cit_articles-1025"
      ],
      "publishedDate": "2020-01-01T08:00:00",
      "publisher": "'Purdue University (bepress)'",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1025&amp;context=cit_articles"
      ],
      "updatedDate": "2022-05-16T12:57:14",
      "yearPublished": 2020,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/286368292.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/286368292"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/286368292/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/286368292/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/19175188"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Baumg\u00e4rtner, Lars"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Freisleben, Bernd (Prof. Dr.)"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/226760451"
      ],
      "createdDate": "2019-09-04T01:36:37",
      "dataProviders": [
        {
          "id": 265,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/265",
          "logo": "https://api.core.ac.uk/data-providers/265/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "W\u00e4hrend Naturkatastrophen oder terroristischer Anschl\u00e4ge ist die bestehende Kommunikationsinfrastruktur h\u00e4ufig \u00fcberlastet oder f\u00e4llt komplett aus. In diesen Situationen k\u00f6nnen mobile Ger\u00e4te mithilfe von drahtloser ad-hoc- und unterbrechungstoleranter Vernetzung miteinander verbunden werden, um ein Notfall-Kommunikationssystem f\u00fcr Zivilisten und Rettungsdienste einzurichten. Falls verf\u00fcgbar, kann eine Verbindung zu Cloud-Diensten im Internet eine wertvolle Hilfe im Krisen- und Katastrophenmanagement sein. \r\nSolche Kommunikationssysteme bergen jedoch ernsthafte Sicherheitsrisiken, da Angreifer versuchen k\u00f6nnten, vertrauliche Daten zu stehlen, gef\u00e4lschte Benachrichtigungen von Notfalldiensten einzuspeisen oder Denial-of-Service (DoS) Angriffe durchzuf\u00fchren. Diese Dissertation schl\u00e4gt neue Ans\u00e4tze zur Kommunikation in Notfallnetzen von mobilen Ger\u00e4ten vor, die von der Kommunikation zwischen Mobilfunkger\u00e4ten bis zu Cloud-Diensten auf Servern im  Internet reichen. Durch die Nutzung dieser Ans\u00e4tze werden die Sicherheit der Ger\u00e4te-zu-Ger\u00e4te-Kommunikation, die Sicherheit von Notfall-Apps auf mobilen Ger\u00e4ten und die Sicherheit von Server-Systemen f\u00fcr Cloud-Dienste verbessert",
      "doi": "10.17192/z2019.0044",
      "downloadUrl": "https://core.ac.uk/download/226760451.pdf",
      "fieldOfStudy": null,
      "fullText": "Secure CommunicationinDisaster ScenariosDissertationzur Erlangung des Doktorgrades der Naturwissenschaften(Dr. rer. nat.)dem Fachbereich Mathematik und Informatikder Philipps-Universita\u00a8t Marburgvorgelegt vonDiplom-InformatikerLars Baumga\u00a8rtnergeboren in OffenbachMarburg, im September 2018Vom Fachbereich Mathematik und Informatik der Philipps-Universita\u00a8t Marburg(Hochschulkennziffer 1180) als Dissertation am 3. September 2018 angenommen.1. Gutachter: Prof. Dr. Bernd Freisleben, Philipps-Universita\u00a8t Marburg2. Gutachter: Prof. Dr. Matthias Hollick, Technische Universita\u00a8t DarmstadtTag der Einreichung am 3. September 2018.Tag der mu\u00a8ndlichen Pru\u00a8fung am 27. November 2018.Eidesstattliche Erkla\u00a8rungIch versichere, dass ich die vorliegende Arbeit selbsta\u00a8ndig, ohne unerlaubte Hilfeangefertigt und mich dabei keiner anderen als der von mir ausdru\u00a8cklich bezeichnetenQuellen und Hilfen bedient habe. Die Dissertation wurde in der jetzigen oder einera\u00a8hnlichen Form noch bei keiner anderen Hochschule eingereicht und hat noch keinensonstigen Pru\u00a8fungszwecken gedient.Marburg, denDatum UnterschriftvAbstractDuring disasters, existing telecommunication infrastructures are often congested oreven destroyed. In these situations, mobile devices can be interconnected using wirelessad hoc and disruption-tolerant networking to establish a backup emergency communi-cation system for civilians and emergency services. When available, a connection tocloud services in the Internet is a valuable aid in crisis and disaster management. How-ever, such communication systems entail serious security risks, since adversaries mayattempt to steal confidential data, fake notifications of emergency services, or performdenial-of-service (DoS) attacks. This thesis proposes novel emergency communicationapproaches for challenged networks of mobile devices, addressing issues ranging frommobile device communication to cloud services running on servers in the Internet.Using these approaches, the security of mobile device-to-device communication, thesecurity of emergency apps running on mobile devices, and the security of serversystems hosting cloud services are improved.viiDeutsche ZusammenfassungWa\u00a8hrend Naturkatastrophen oder terroristischer Anschla\u00a8ge ist die bestehende Kommu-nikationsinfrastruktur ha\u00a8ufig u\u00a8berlastet oder fa\u00a8llt komplett aus. In diesen Situationenko\u00a8nnen mobile Gera\u00a8te mithilfe von drahtloser ad-hoc- und unterbrechungstoleranterVernetzung miteinander verbunden werden, um ein Notfall-Kommunikationssystemfu\u00a8r Zivilisten und Rettungsdienste einzurichten. Falls verfu\u00a8gbar, kann eine Verbindungzu Cloud-Diensten im Internet eine wertvolle Hilfe im Krisen- und Katastrophen-management sein. Solche Kommunikationssysteme bergen jedoch ernsthafte Sicherheits-risiken, da Angreifer versuchen ko\u00a8nnten, vertrauliche Daten zu stehlen, gefa\u00a8lschteBenachrichtigungen von Notfalldiensten einzuspeisen oder Denial-of-Service (DoS)Angriffe durchzufu\u00a8hren. Diese Dissertation schla\u00a8gt neue Ansa\u00a8tze zur Kommunikationin Notfallnetzen von mobilen Gera\u00a8ten vor, die von der Kommunikation zwischen Mobil-funkgera\u00a8ten bis zu Cloud-Diensten auf Servern im Internet reichen. Durch die Nutzungdieser Ansa\u00a8tze werden die Sicherheit der Gera\u00a8te-zu-Gera\u00a8te-Kommunikation, die Sicher-heit von Notfall-Apps auf mobilen Gera\u00a8ten und die Sicherheit von Server-Systemen fu\u00a8rCloud-Dienste verbessert.ixAcknowledgmentsFirst of all, I would like to thank Prof. Dr. Bernd Freisleben for supervising me over thecourse of my dissertation, for his assistance, and the valuable discussions that helpedme to advance this thesis. I am grateful that he gave me the opportunity to work indifferent projects and let me follow different, exciting research topics.I would also like to thank Prof. Dr. Matthias Hollick at the Technische Universita\u00a8tDarmstadt for kindly taking the time to act as a reviewer of my thesis. Moreover, Iam thankful for the opportunity to benefit from the collaboration with colleagues andresearchers in the NICER project which would not have happened without him. Thisproject was very inspirational by not only providing technically challenging researchquestions, but also giving me a new form of motivation by having a humanitarian goaland working on something that is supposed to save and impact lives.During the work on this thesis, I was financially supported by the German Ministry ofResearch and Education (BMBF) in the ACCEPT project, the Hessische Landesoffensivezur Entwicklung wissenschaftlich-o\u00a8konomischer Exzellenz (LOEWE) in the LOEWE-Zentrum SYNMIKRO and in the LOEWE-Schwerpunkt NICER, as well as the GermanResearch Foundation (DFG) in the SFB 1053 (MAKI).Furthermore, I would like to thank my past and present colleagues and students atthe Distributed Systems Group in Marburg who were important for many researchprojects I was involved in (alphabetically): Prof. Dr. Ralph Ewerth, Prof. Dr. Sascha Fahl,Dr. Niels Fallenbeck, Pablo Graubner, Christina Heitzer, Jonas Ho\u00a8chst, Dr. Ernst Juhnke,Nikolaus Korfhage, Patrick Lampe, Matthias Leinweber, Prof. Dr. Dorian Minarolli, Prof.Dr. Afef Mdhaffar, Dr. Markus Mu\u00a8hling, Alvar Penning, Falk Schellenberg, Dr. MatthiasSchmidt, Nils Schmidt, Dr. Roland Schwarzkopf, Prof. Dr. Matthew Smith, MarkusSommer, Artur Sterz, and Christian Strack. Special thanks go to Mechthild Kessler formanaging almost everything in administration, so that one can completely focus onresearch. Without her, the Distributed Systems Group would be pretty thwarted.While being involved in different projects, I had interesting, inspirational and funcollaborations in Marburg and across universities with (alphabetically): Lars Almon, Dr.Thomas Fober, Prof. Dr. Kurt Geihs, Dr. Bastian Ho\u00dfbach, Prof. Dr. Stefan Katzenbeisser,Prof. Dr. Anja Klein, Dr. Stefan Kohlbrecher, Florian Kohnha\u00a8user, Christian Meurisch,Prof. Dr. Mira Mezini, Ragnar Mogk, Prof. Dr. Max Mu\u00a8hlha\u00a8user, Dr. Bjo\u00a8rn Richerzhagen,Prof. Dr. Guido Salvaneschi, Prof. Dr. Bernhard Seeger, Marc Seidemann, Prof. Dr. RalfSteinmetz, Prof. Dr. Paul Gardner-Stephen, Prof. Dr. Oskar von Stryk, Milan Stute. Forthese, I am very grateful.Finally, I want to thank my family for always being there for me. My parents Angelikaand Wolfgang Baumga\u00a8rtner supported me in all my activities from early childhoodon and encouraged my to pursue all my goals in life. They made me the curious,open-minded person I am today, for which I am deeply grateful. Last but not least, Ialso have to thank Eva, who always has my back and helped me through many difficulttimes, pushing me when I was unmotivated and providing a cozy place when needed.xiMy ContributionsAs already indicated in my acknowledgments, I am grateful to several persons whocooperated with me or who influenced my research in one way or another. Security,systems, and network research are often joint work. Therefore, pinning achievementsto a single individual is not always possible, since most developments are ongoingprocesses, involving contributions from different participants. Furthermore, studentsplay a vital role in implementing ideas or assisting with experimental evaluations.Since this thesis contains content from original publications, often in verbatim form, italso includes joint and sometimes practically indivisible contributions from colleagues.Therefore, I try to highlight my specific contributions as good as possible below.Chapter 3 presents solely my views and ideas for the research topics addressed inthis thesis.Chapter 4 includes several works that are joint efforts of different researchers in theLOEWE NICER project. Although many ideas and concepts are genuinely my work,several bachelor and master students were involved in the experimental evaluationsand parts of the implementations [1]\u2013[6]. This holds especially for Sections 4.3, 4.4,and 4.6 where student assistants contributed to realizing and evaluating my concepts.Sections 4.2, 4.5, and 4.7 are also based on students\u2019 master theses that I supervised,where I also made contributions to the design, implementation, and evaluation in thepublished version of these works. I developed the idea and the concept of the publicationon environmental monitoring [6] plus major parts of the implementation such as therf95modem firmware and the BLE LoRa integration. The Serval evaluation study [2]was my idea, and I also supervised the involved students. Pablo Graubner performedthe energy related evaluation in the announcement interval paper [3], while I developedthe underlying software (mesher) and the announcement algorithms, and a student wasinvolved in some implementation parts and the evaluation setup. Bringing differentaspects of emergency communication together in a joint publication [7] involved peoplefrom different backgrounds. My work focused on the overall architecture, as well as theintegration and evaluation of the DTN component for the mobile cloud in Section 4.8,and I also had the lead for producing the paper. Here, I developed different componentsof the mobile cloud, such as Serval shell integration, ServalDesktopApp, sdnatui, serval-socks-proxy etc. and evaluation helpers like core-automator. Through several jointdiscussions, novel concepts for secure mobile device communication were formulatedbetween Florian Kohnha\u00a8user, Milan Stute, Lars Almon, and me. This led to the SEDCOSpublication [8] in Section 4.9 where my contributions were mainly providing a systemmodel and input for the overall concept, plus integrating knowledge gained from myprevious work on various DTN systems, which was used in initial versions of the paper.For several publications [1]\u2013[3], [5], [6], I wrote the initial texts, while I wrote majorparts of the initial texts for other publications [4], [7].Chapter 5 focuses on joint work with other members of our research group inMarburg or with former members at other universities. In the Eve and Mallory paperxiii[9] presented in Section 5.2, my main contributions were performing manual app audits,writing automated tests, and developing proof-of-concept exploits such as the Zoner-AV hack featured in the paper. AndroLyze and Dynalize [10], [11] were joint effortsbetween Pablo Graubner, students, and me. While my focus was mostly on the staticapp analysis and distributed system design of AndroLyze (Section 5.3) plus assistingwith requirements and developing use cases for Dynalize (Section 5.4), Pablo Graubnerwas responsible for the architecture and cloud integration of Dynalize. AndroLyzewas also part of a bachelor thesis that I supervised. I designed and conducted theemergency app audit in Section 5.5, assisted by a student.Chapter 6 includes cooperations between different partners of the BMBF ACCEPTproject. In the mail server misuse paper [12], a bachelor student was involved in theevaluation of the results, and his bachelor thesis was also about the topic presented inSection 6.2. In the malware detection paper [13], I contributed the kernel introspectionand hooking parts described in Section 6.3. In the ACCEPT system [14], [15], I mainlytake credit for being involved in the overall architectural design and the design andimplementation of sensors on various layers (where my colleagues Christian Strack andMatthias Leinweber also made contributions), as well as in designing the use case anddeveloping the proof-of-concept implementation.xivContentsAbstract viiDeutsche Zusammenfassung ixAcknowledgments xiMy Contributions xiii1 Introduction 11.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41.3 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51.4 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61.5 Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Background 92.1 Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92.1.1 Mesh Networking . . . . . . . . . . . . . . . . . . . . . . . . . . . 92.1.2 Delay-/Disruption-Tolerant Networking . . . . . . . . . . . . . . 102.1.3 Serval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112.2 Mobile Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122.3 Emergency Communication . . . . . . . . . . . . . . . . . . . . . . . . . . 142.3.1 Federal Public Warning Systems . . . . . . . . . . . . . . . . . . . 142.3.2 Infrastructureless Communication . . . . . . . . . . . . . . . . . . 172.4 Cloud Computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192.5 Security . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202.5.1 Transport Layer Security . . . . . . . . . . . . . . . . . . . . . . . . 202.5.2 Man-in-the-Middle Attacks . . . . . . . . . . . . . . . . . . . . . . 203 Secure Emergency Communication 233.1 Emergency Communication . . . . . . . . . . . . . . . . . . . . . . . . . . 233.1.1 Internet Services . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233.1.2 Mobile Applications . . . . . . . . . . . . . . . . . . . . . . . . . . 243.1.3 Shortcomings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253.2 Design of a Secure Emergency Communication System . . . . . . . . . . 263.2.1 Disruption-tolerant Device-to-Device Emergency Communication 273.2.2 Security Vulnerability Analysis of Mobile Apps . . . . . . . . . . 283.2.3 Secure Cloud Systems . . . . . . . . . . . . . . . . . . . . . . . . . 294 Disruption-tolerant Device-to-Device Emergency Communication 314.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31xvContents4.2 MiniWorld - An Emulation-based Evaluation Environment . . . . . . . . 334.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334.2.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344.2.3 MiniWorld\u2019s Design . . . . . . . . . . . . . . . . . . . . . . . . . . . 354.2.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374.2.5 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 414.2.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 464.3 Serval - A Robust Communication Foundation . . . . . . . . . . . . . . . 484.3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 484.3.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 494.3.3 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 504.3.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584.4 Optimizing Epidemic Announcements . . . . . . . . . . . . . . . . . . . . 604.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 604.4.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 614.4.3 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 634.4.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 654.4.5 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 664.4.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 734.5 DTN-RPC - Offloading Work in Challenged Environments . . . . . . . . 754.5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 754.5.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 764.5.3 DTN-RPC\u2019s Design . . . . . . . . . . . . . . . . . . . . . . . . . . . 774.5.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 814.5.5 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 824.5.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 884.6 Environmental Monitoring Platforms for Disaster Scenarios . . . . . . . 894.6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 894.6.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 904.6.3 Sensor Platforms for Disaster Scenarios . . . . . . . . . . . . . . . 904.6.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 924.6.5 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 964.6.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1024.7 Applications for Disaster Response: SmartFace . . . . . . . . . . . . . . . 1034.7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034.7.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1034.7.3 SmartFace\u2019s Design . . . . . . . . . . . . . . . . . . . . . . . . . . . 1044.7.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1054.7.5 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 1064.7.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1134.8 Applications for Disaster Response: UV4EC . . . . . . . . . . . . . . . . 1144.8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1144.8.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1154.8.3 UV4EC\u2019s Design and Implementation . . . . . . . . . . . . . . . . 1164.8.4 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 1214.8.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126xviContents4.9 SEDCOS - Secure Disaster Communication . . . . . . . . . . . . . . . . . 1284.9.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1284.9.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1284.9.3 System Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1294.9.4 Secure Key Management . . . . . . . . . . . . . . . . . . . . . . . 1294.9.5 Resilient Communication . . . . . . . . . . . . . . . . . . . . . . . 1314.9.6 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 1334.9.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1344.10 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1355 Security Vulnerability Analysis of Mobile Apps 1375.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1375.2 TLS Usage in Android Apps . . . . . . . . . . . . . . . . . . . . . . . . . 1385.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1385.2.2 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1395.2.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1415.2.4 Evaluating Android SSL Usage . . . . . . . . . . . . . . . . . . . . 1425.2.5 MITMA Study . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1465.2.6 Limitations of our Analysis . . . . . . . . . . . . . . . . . . . . . . 1525.2.7 Trouble in Paradise . . . . . . . . . . . . . . . . . . . . . . . . . . . 1525.2.8 Countermeasures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1545.2.9 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1565.2.10 List of Apps With Broken SSL Usage . . . . . . . . . . . . . . . . 1575.3 AndroLyze: Static Mobile App Analysis . . . . . . . . . . . . . . . . . . . 1595.3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1595.3.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1595.3.3 AndroLyze\u2019s Design . . . . . . . . . . . . . . . . . . . . . . . . . . . 1615.3.4 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1655.3.5 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 1675.3.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1735.4 Dynalize: Dynamic Mobile App Analysis . . . . . . . . . . . . . . . . . . 1755.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1755.4.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1755.4.3 Dynalize\u2019s Design and Implementation . . . . . . . . . . . . . . . 1775.4.4 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 1815.4.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1855.5 Security Assessment of Emergency Apps . . . . . . . . . . . . . . . . . . 1865.5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1865.5.2 Popular Emergency Apps . . . . . . . . . . . . . . . . . . . . . . . 1865.5.3 Common Attack Surface . . . . . . . . . . . . . . . . . . . . . . . . 1875.5.4 Individual App Audits . . . . . . . . . . . . . . . . . . . . . . . . . 1885.5.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1985.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2006 Secure Cloud Systems 2016.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201xviiContents6.2 Assessment of Email Delivery Security . . . . . . . . . . . . . . . . . . . 2026.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2026.2.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2036.2.3 An Empirical Study of SMTP over TLS . . . . . . . . . . . . . . . 2056.2.4 Advice for Email Providers . . . . . . . . . . . . . . . . . . . . . . 2146.2.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2156.3 Hardening Server Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . 2176.3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2176.3.2 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . 2176.3.3 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2196.3.4 Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2206.3.5 Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2256.3.6 Experimental Evaluation . . . . . . . . . . . . . . . . . . . . . . . 2286.3.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2306.4 Reactive Realtime Cloud Infrastructure Monitoring . . . . . . . . . . . . 2316.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2316.4.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2326.4.3 Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2356.4.4 Example Anomaly Detection . . . . . . . . . . . . . . . . . . . . . 2376.4.5 Sensor Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . 2396.4.6 Analysis-VM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2436.4.7 Action Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . 2516.4.8 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2546.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2557 Conclusion 2577.1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2577.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258List of Figures 259List of Tables 263Bibliography 265Curriculum Vitae 287xviii1 Introduction1.1 MotivationThe unfortunate reality is that each year disasters and emergencies occur in manyplaces around the world. The chart shown in Figure 1.1 displays an increasing trendfor most types of natural disasters in the last decades, not even taking into account actsof terrorism or wars.Figure 1.1: Natural catastrophes since 1980.1Especially highly developed countries are in danger due to their high dependencyon electricity and communication. Without local food production or fuel, life dependson coordinated efforts and logistics. Apart from a lack of electrical power, anothercommon feature of these events is that partial or complete loss of communicationcapacity occurs.2 Even without the loss of communication capacity in a disaster, thereare significant challenges to providing effective information for those affected [16]. Theloss of means of communication serves to compound the difficulties and sufferingsfaced by those in the disaster area [17]. Furthermore, communication is needed to findmissing people, self-organize aid by civilians or report local issues and emergenciesto authorities. It is not only useful for person-to-person text messaging, but alsovital to coordinate semi-autonomous systems such as Unmanned Aerial and GroundVehicles (UAVs and UGVs). The use of drones and ground-based robots has manyadvantages and helps to protect the lives of professional responders. For example,in the Fukushima event, UGVs were sent into areas where radiation levels were too1Deutsche Welle: https://p.dw.com/p/152Y22https://www.drj.com/articles/online-exclusive/when-communications-infrastructure-fails-during-a-disaster.html11 IntroductionFigure 1.2: FEMA Top 10 Response Core Capabilities.4Figure 1.3: FEMA Top 10 Protection Core Capabilities.5high for human rescuers, which also shows that current systems easily reach theirlimits.3 Furthermore, infrastructureless wireless sensing is beneficial for environmentalmonitoring in various application scenarios, such as in a disaster where it is vital forthe operational planning of professional responders.A communication infrastructure is a critical key component to successful disasterresponse. This is also reflected in the National Preparedness Report of the US\u2019 FederalEmergency Management Agency (FEMA) where operational communication has thehighest priority of the 10 core capabilities (Fig. 1.2).Since communication plays a vital role, the integrity and security of such a system3https://singularityhub.com/2018/04/25/how-fukushima-changed-japanese-robotics-and-woke-up-the-industry/4Source: https://www.fema.gov/national-preparedness-report5Source: https://www.fema.gov/national-preparedness-report21.1 Motivationis of importance for professional responders as well as civilians involved. FEMA\u2019sNational Preparedness Report also lists cybersecurity as its top priority in its protectioncategory (Fig. 1.3), since many other operations and tasks heavily depend on networkedsystems. Therefore, there is a moral imperative to seek out means of finding ways torestore, or better, sustain secure communication during and following such adverseevents.31 Introduction1.2 Problem StatementTo deliver a viable solution to the problems discussed above, several steps are necessary.Since the challenges for networked devices during disasters are different from regularsetups, a controlled environment is needed for repeated tests, realistic developmentand evaluation of new approaches. Modern technology such as virtualization andemulation can be used to build simulations of larger scale with ease. This is thefoundation for any further developments regarding a secure emergency communicationsystem. Three different problem areas can be identified that are important for thisthesis. First, infrastructureless communication must be used to deliver relevant servicesin a secure and efficient manner between end user devices. Second, the applicationsrunning on mobile devices and providing emergency services to users are critical forthe security of the communication system. Third, more powerful backend systemsrunning on machines at a mobile command center or in the cloud must be considered.Each of these areas has specific problems and requirements as outlined below.1. Disruption-tolerant Device-to-Device Communication. The main challenge isto deliver services such as messaging or task offloading with remote procedurecalls in a secure yet accessible way for a disaster scenario where communicationinfrastructure failed. Therefore, one has to rely on battery-powered commodityhardware, such as mobile phones. This limits the radio link technologies to thosecapable of direct device-to-device communication, such as WiFi, Bluetooth, and(with additional hardware) LoRa, without relying on working cell towers. Further-more, the communication should ideally utilize disruption-tolerant-networking(DTN) and/or mesh networking to cope with the challenged network environ-ment where links and devices are prone to fail or move out of range. Existingalgorithms often either do not take these highly dynamic networks with oftendisrupted connections into account and/or neglect limited resources such asbattery or computing power.2. Security Vulnerability Analysis of Mobile Apps. Since emergency apps are themain interface for users on mobile devices, their security is vital for the wholesystem. For an in-depth analysis of the security level of any given or developedsolution, dynamic as well as static code analysis should be performed to assessattack surfaces and identify vulnerabilities. Having automated tests that can berepeated easily ensures that the security level can be kept even after adding newfeatures to an app.3. Secure Cloud Systems. Having services running on larger machines in thefog/edge of a network or virtualized in the cloud also means that they areexposed to possible attacks. Protecting core services such as email, which plays avital role for professional first responders, is important in maintaining the overallsecurity of rescue operations. Moreover, further steps must be taken to ensure thesecurity and integrity of such a system not only on the network level but alsoacross the whole setup.The aim of this thesis is to present approaches that provide solutions to the threeproblem areas outlined above.41.3 Contributions1.3 ContributionsThe main research contributions of this thesis are:Topic ContributionsEmergency Network EmulationA novel, flexible, distributed emulation environment forrealistically evaluating software in emergency scenariosis presented. The proposed approach utilizes full systememulation and can be integrated with external simulationsfor positional updates. The network back-end is flexible andcan mimic different wireless interfaces.DT-D2D CommunicationA novel communication system including a set of newapproaches to deliver a mobile cloud infrastructure withefficient data dissemination through dynamic announcementintervals and disruption-tolerant remote procedure callsis presented. These can power advanced apps such ason-device face recognition for supporting the search formissing persons, integrate UAVs for communication andrescue operations as well as faciliate various environmentalsensoring setups. These approaches are portable andplatform agnostic, covering mobile devices, computers andsmall embedded system. Furthermore, a large variety ofradio link technologies is covered (e.g. Bluetooth, WiFi, LoRa)by the developed solutions. Also, new solutions for increasedsecurity in the communication system are presented.Security Analysis of AppsA novel suite of tools for automated and repeatable staticas well as dynamic analysis of mobile Android apps ispresented. These tools can be deployed to repeatedly auditlarge sets of apps. The usefulness is shown through severalmass audits regarding the state of security in Android apps.Secure Cloud SystemsA novel approach for securing virtualized server systemsby integrating classic anti-virus solutions with live systemintrospection and dynamic sensors deployed across severallayers is presented. The use of a federated Complex EventProcessing (CEP) system in conjunction with a historic eventdatabase enables new ways to eliminate false positives anddetect various anomalies through minimal added logic withineach virtual machine.51 Introduction1.4 PublicationsDuring the work on this thesis, the following papers were published:1. L. Baumga\u00a8rtner, A. Penning, P. Lampe, B. Richerzhagen, R. Steinmetz, and B.Freisleben, \u201cEnvironmental Monitoring Using Low-Cost Hardware and Infras-tructureless Wireless Communication,\u201d in IEEE Global Humanitarian TechnologyConference (GHTC 2018), San Jose, USA: IEEE, 2018, accepted for publication2. R. Mogk, L. Baumga\u00a8rtner, G. Salvaneschi, B. Freisleben, and M. Mezini, \u201cFault-tolerant Distributed Reactive Programming,\u201d in 32nd European Conference on Object-Oriented Programming (ECOOP 2018), vol. 109, Amsterdam, The Netherlands:Schloss Dagstuhl\u2013Leibniz-Zentrum fu\u00a8r Informatik, 2018, 1:1\u20131:263. P. Graubner, P. Lampe, J. Ho\u00a8chst, L. Baumga\u00a8rtner, M. Mezini, and B. Freisleben,\u201cOpportunistic Named Functions in Disruption-tolerant Emergency Networks,\u201din ACM International Conference on Computing Frontiers 2018 (ACM CF\u201918), Ischia,Italy: ACM, 2018, pp. 129\u20131374. L. Baumga\u00a8rtner, S. Kohlbrecher, J. Euler, T. Ritter, M. Schmittner, C. Meurisch, M.Mu\u00a8hlha\u00a8user, M. Hollick, O. von Stryk, and B. Freisleben, \u201cEmergency Communi-cation in Challenged Environments via Unmanned Ground and Aerial Vehicles,\u201din IEEE Global Humanitarian Technology Conference (GHTC 2017), San Jose, USA:IEEE, 2017, pp. 1\u201395. C. Meurisch, J. Gedeon, A. Gogel, T. A. B. Nguyen, F. Kaup, F. Kohnha\u00a8user, L.Baumga\u00a8rtner, M. Schmittner, and M. Mu\u00a8hlha\u00a8user, \u201cTemporal Coverage Analysisof Router-based Cloudlets Using Human Mobility Patterns,\u201d in 2017 IEEE GlobalCommunications Conference: Selected Areas in Communications: Internet of Things(Globecom 2017 SAC IoT), Singapore, Singapore: IEEE, 2017, pp. 1\u201366. F. Kohnha\u00a8user, M. Schmittner, L. Baumga\u00a8rtner, L. Almon, S. Katzenbeisser, M.Hollick, and B. Freisleben, \u201cSEDCOS: A Secure Device-to-Device CommunicationSystem for Disaster Scenarios,\u201d in 42nd Annual IEEE Conference on Local ComputerNetworks (LCN 2017), Singapore, Singapore: IEEE, 2017, pp. 195\u20131987. J. Ho\u00a8chst, L. Baumga\u00a8rtner, M. Hollick, and B. Freisleben, \u201cUnsupervised TrafficFlow Classification Using a Neural Autoencoder,\u201d in 42nd Annual IEEE Conferenceon Local Computer Networks (LCN 2017), Singapore, Singapore: IEEE, 2017, pp. 523\u20135268. A. Sterz, L. Baumga\u00a8rtner, R. Mogk, M. Mezini, and B. Freisleben, \u201cDTN-RPC:Remote Procedure Calls for Disruption-Tolerant Networking,\u201d in IFIP Networking2017 Conference and Workshops (Networking 2017), Stockholm, Sweden: IFIP, 2017,pp. 1\u201399. N. Schmidt, L. Baumga\u00a8rtner, P. Lampe, K. Geihs, and B. Freisleben, \u201cMiniWorld:Resource-aware Distributed Network Emulation via Full Virtualization,\u201d in 22ndIEEE Symposium on Computers and Communication (ISCC 2017), Heraklion, Greece:IEEE, 2017, pp. 818\u201382510. P. Lampe, L. Baumga\u00a8rtner, R. Steinmetz, and B. Freisleben, \u201cSmartFace: EfficientFace Detection on Smartphones for Wireless On-demand Emergency Networks,\u201din 24th International Conference on Telecommunications (ICT 2017), Limassol, Cyprus:IEEE, 2017, pp. 1\u2013711. L. Baumga\u00a8rtner, P. Graubner, J. Ho\u00a8chst, A. Klein, and B. Freisleben, \u201cThe MoreYou Speak, the Less You Hear: On Dynamic Announcement Intervals in Wireless61.4 PublicationsOn-demand Networks,\u201d in 13th Conference on Wireless On-demand Network Systemsand Services (WONS 2017), Jackson Hole, USA: IEEE, 2017, pp. 33\u20134012. L. Baumga\u00a8rtner, P. Gardner-Stephen, P. Graubner, J. Lakeman, J. Ho\u00a8chst, P. Lampe,N. Schmidt, S. Schulz, A. Sterz, and B. Freisleben, \u201cAn Experimental Evaluation ofDelay-Tolerant Networking with Serval,\u201d in IEEE Global Humanitarian TechnologyConference (GHTC 2016), Seattle, USA: IEEE, 2016, pp. 1\u2013813. M. Leinweber, T. Fober, M. Strickert, L. Baumga\u00a8rtner, G. Klebe, B. Freisleben, andE. Hu\u00a8llermeier, \u201cCavSimBase: A Database for Large Scale Comparison of ProteinBinding Sites,\u201d IEEE Transactions on Knowledge and Data Engineering, vol. 28, no. 6,pp. 1423\u20131434, 201614. L. Baumga\u00a8rtner, J. Ho\u00a8chst, M. Leinweber, and B. Freisleben, \u201cHow to MisuseSMTP over TLS: A Study of the (In) Security of Email Server Communication,\u201d in2015 IEEE Trustcom/BigDataSE/ISPA, Helsinki, Finland: IEEE, 2015, pp. 287\u201329415. L. Baumga\u00a8rtner, C. Strack, B. Ho\u00dfbach, M. Seidemann, B. Seeger, and B. Freisleben,\u201cComplex Event Processing for Reactive Security Monitoring in Virtualized Com-puter Systems,\u201d in Proceedings of the 9th ACM International Conference on DistributedEvent-Based Systems, Oslo, Norway: ACM, 2015, pp. 22\u20133316. L. Baumga\u00a8rtner, P. Graubner, N. Schmidt, and B. Freisleben, \u201cAndroLyze: A Dis-tributed Framework for Efficient Android App Analysis,\u201d in IEEE 2nd InternationalConference on Mobile Services (MS 2015), New York City, USA: IEEE, 2015, pp. 73\u20138017. P. Graubner, L. Baumga\u00a8rtner, P. Heckmann, M. Mu\u00a8ller, and B. Freisleben, \u201cDy-nalize: Dynamic Analysis of Mobile Apps in a Platform-as-a-Service Cloud,\u201d inIEEE 8th International Conference on Cloud Computing (CLOUD 2015), New YorkCity, USA: IEEE, 2015, pp. 925\u201393218. M. Leinweber, L. Baumga\u00a8rtner, M. Mernberger, T. Fober, E. Hu\u00a8llermeier, G. Klebe,and B. Freisleben, \u201cGPU-based Cloud Computing for Comparing the Structure ofProtein Binding Sites,\u201d in 6th IEEE International Conference on Digital EcosystemsTechnologies (DEST 2012), Campione d\u2019Italia, Italy: IEEE, 2012, pp. 1\u2013619. S. Fahl, M. Harbach, T. Muders, L. Baumga\u00a8rtner, B. Freisleben, and M. Smith,\u201cWhy Eve and Mallory Love Android: An Analysis of Android SSL (In)Security,\u201din Proceedings of the 2012 ACM Conference on Computer and Communications Security(CCS), Raleigh, USA: ACM, 2012, pp. 50\u20136120. L. Baumga\u00a8rtner, P. Graubner, M. Leinweber, R. Schwarzkopf, M. Schmidt, B.Seeger, and B. Freisleben, \u201cMastering Security Anomalies in Virtualized Comput-ing Environments via Complex Event Processing,\u201d in Proceedings of the The FourthInternational Conference on Information, Process, and Knowledge Management (eKNOW2012), Valencia, Spain: IEEE, 2012, pp. 76\u20138121. M. Schmidt, L. Baumga\u00a8rtner, P. Graubner, D. Bo\u00a8ck, and B. Freisleben, \u201cMalwareDetection and Kernel Rootkit Prevention in Cloud Computing Environments,\u201din 19th Euromicro International Conference on Parallel, Distributed and Network-BasedProcessing (PDP 2011), Ayia Napa, Cyprus: IEEE, 2011, pp. 603\u201361071 Introduction1.5 OutlineThis thesis is organized as follows:Chapter 2 introduces topics fundamental for the research in this thesis. The top-ics covered include emergency communication in general, mesh and delay-tolerantnetworking technologies as well as cloud computing and security issues.Chapter 3 gives a more in-depth overview of the work presented in this thesis.The architecture of the proposed system as well as challenging areas covered in thefollowing chapters are explained.Chapter 4 includes research results obtained to provide optimized emergency com-munication services on mobile devices. Apart from algorithmic improvements to datadissemination and remote procedure calls, concrete applications such as mobile facedetection and its integration with unmanned vehicles are discussed.Chapter 5 presents work to improve the security of apps running on mobile devices.Audits on current mobile apps are performed as well as general frameworks for staticand dynamic analysis are presented.Chapter 6 discusses approaches for cloud service security in emergency scenarios.The technologies covered include email as well as realtime security monitoring forcloud computing and system hardening.Chapter 7 concludes the thesis and discusses possible areas of future work.82 BackgroundIn this chapter, fundamental issues relevant for the research presented in this thesisare discussed. General networking technologies such as mesh routing and delay-tolerant networking as well as relevant technologies regarding mobile devices andcloud computing are explained. Furthermore, an overview of security related topics isgiven.2.1 NetworkingIn the context of an emergency scenario, network infrastructure is not available or unableto function reliably. Due to the highly dynamic nature of the network, static routingbased on OSPF1, RIP2 or BGP3 is not suited to provide stable routes for applicationsto perform well. One alternative is to use mesh networking with algorithms that arespecifically tailored to provide the kind of dynamic routing that is needed in theseenvironments. The other alternative is to rely on Delay-/Disruption-Tolerant-Networking(DTN) where data dissemination happens in bundles rather than packets.2.1.1 Mesh NetworkingThe most common wireless mesh routing algorithms used in communities such asFreifunk4, GuiFi5, and Commotion Wireless6 are described below.OLSRThe Optimized Link State Routing protocol is formally described in RFC 36267. It is aproactive link-state routing mechanism working on the IP-layer and often deployed inwireless ad-hoc networks. It uses specific Hello and Topology Control (TC) messagesin conjunction with periodic broadcasts to build its routing tables. This information isused by each node to compute the next hop for all nodes. Due to its proactive natureand rather large routing tables that are disseminated, OLSR requires some bandwidthand CPU power to fully function. The main implementation runs as a userland routingdaemon on various platforms such as Linux, MacOS X, FreeBSD etc.1https://tools.ietf.org/html/rfc23282https://tools.ietf.org/html/rfc24533https://tools.ietf.org/html/rfc42714https://freifunk.net/5https://guifi.net/6https://www.commotionwireless.net/7https://tools.ietf.org/html/rfc362692 BackgroundFigure 2.1: IP vs DTN data flow.12B.A.T.M.A.N.Better Approach To Mobile Adhoc Networking (B.A.T.M.A.N.)8 is designed as a layer 2multi-hop routing algorithm for wireless ad-hoc networks. To eliminate the resourceintensive routing information calculation and dissemination of OLSR, each node onlyhas statistics about where it got data from and uses this for sending decisions ateach hop. Therefore, the node does not know the complete best route to a destinationbut only the best next hop node. To build up these statistics, the network is floodedperiodically with small Originator Messages (OGMs) that are forwarded and processedby the nodes. In case of multiple neighbors, a node chooses a next hop node by checkingthe OGM statistics for each neighbor, through which the most OGMs in the shortesttime were received from the target node. The main implementation is tightly coupledto the Linux kernel and runs as a loadable kernel module in Linux.2.1.2 Delay-/Disruption-Tolerant NetworkingDTN development is strongly driven by NASA9 and other space agencies to easecommunication between satellites, robots, spacecrafts etc. These devices only havelimited communication opportunities and often unstable links. Therefore, instead ofrelying on real-time routing and direct connections, data is passed in a store-and-forward fashion from node to node. Here, each device acts as a \u201ddata mule\u201d, physicallycarrying data around. A direct comparison of end-to-end communication with IPand incremental data dissemination using DTN is shown in Figure 2.1. For referencepurposes, the RFCs 483810 and 505011 provide specifications for a Bundle Protocol.There are different distribution strategies and routing algorithms specifically de-signed for DTNs. Some prominent replication-based candidates are summarized in thefollowing paragraphs.8https://www.open-mesh.org9https://www.nasa.gov/content/dtn10https://tools.ietf.org/html/rfc483811https://tools.ietf.org/html/rfc505012https://www.nasa.gov/sites/default/files/dtn_0.png102.1 NetworkingFileDistribution MeshMSVoiceMeshRhizome\u00a0DTN Mesh\u00a0DatagramProtocol\u00a0(MDP)Serval\u00a0Overlay\u00a0MeshUDP,\u00a0IP,\u00a0Ethernet/WiFi Packet\u00a0Radio ...Figure 2.2: The Serval technology stackEpidemic. Epidemic routing uses flooding as its basis, trying to synchronize all datato any new neighbor lacking a copy of it [24]. Even though many resources are wastedin this approach, it also is very robust when it comes to failing nodes and deliveryrates.PRoPHET. The Probabilistic Routing Protocol using History of Encounters andTransitivity (PRoPHET) protocol tries to conserve resources by exploiting the fact thathuman encounters, also in DTN \u201ddata mule\u201d context, are rarely purely random [25].This is achieved by keeping track of probabilities for successful delivery of bundlesthrough different nodes. Therefore, data synchronization is only triggered if a neighbournode has a higher probability of delivering the message. This protocol has also beenformalized as RFC 6693.132.1.3 ServalServal is centered around a suite of protocols and technologies designed to allow ad-hocinfrastructure-independent communications [26], [27], as illustrated in Fig. 2.2. Thegoal is to provide infrastructure-independent versions of many of the services thatare commonly used on smartphones in conjunction with the Internet and/or cellularnetworks, e.g., voice calls, short text messaging (SMS), voice mail, social media, as wellas file and image transfer.The Serval Mesh protocols purposely take a contrasting approach to that of us-ing IP (v4 or v6) as the basis for forming mobile ad-hoc communications networks(MANETs) [28]. The reason for this is that despite billions of dollars of research anddevelopment work, IP-based MANETs still struggle, and face a number of significantchallenges that limit their real-world use, e.g., address allocation, the need to main-tain a routing table, authenticity and integrity of communications, and the need forrelatively reliable and stable end-to-end connectivity for such systems. Instead, Servaluses 256-bit public cryptographic keys as the primary network identifier, the so-calledServal ID (SID), and also includes a rich security model that facilitates confidentiality,integrity and authenticity by design, and does not require a Trusted Third Party (TTP)to operate. It also includes a store-and-forward DTN protocol (Rhizome), allowingnetwork operation in the absence of end-to-end connectivity.13https://tools.ietf.org/html/rfc6693112 BackgroundRhizome and Delay Tolerant NetworkingRhizome is a simple bundle protocol that principally defines data units as bundles,consisting of an optional payload, together with a manifest that contains necessarymeta-data. Manifests have a hard size limit of 1 KB to improve efficiency, and must alsocontain a cryptographic public key that is used to protect the integrity and authenticityof the manifest itself. The manifest may also contain a cryptographic hash, indicatingthat it has an associated payload, together with other meta-data, such as mime-type,Rhizome service tag, file-name, and SID of the sender and/or recipient, as appropriate.While the Rhizome implementation includes several transports for Rhizome, includ-ing HTTP, packet radio and the Serval MDP protocol described below, the protocol ispurposely agnostic of the transport, to allow other transports to be added. The intentionof this is that any transport that is capable of carrying bytes of data can be used totransport Rhizome data.As a simple state-less flooding protocol, Rhizome requires no routing table, andnever requires that two parties have an end-to-end connection for them to communicate.That is, the Rhizome protocol is always focused on single-hop communications, withmulti-hop communications emerging as a natural consequence of bundles replicatingamong nodes.Rhizome is used as the basis for the SMS-like Mesh Messaging Service (MeshMS) [29],and file distribution, including software updates. It is also planned to implement atwitter-like micro-blogging service using Rhizome.MDP, MSP and Node DiscoveryIn addition to the Rhizome DTN protocol, Serval also includes a real-time packet-switched protocol, the Mesh Datagram Protocol (MDP) that is generally similar toUDP/IP, but uses SIDs instead of IP addresses, and includes encryption, authenticationand integrity features by default. The TCP-like Mesh Streaming Protocol (MSP) is lay-ered atop MDP to provide reliable data streaming. Various services can be implementedatop MDP and MSP, including the VoIP-like Voice over MDP Protocol (VoMP).MDP routing uses an OSLR- and BATMAN-inspired [30], [31] ad-hoc protocol forboth node discovery and maintaining a routing table, that facilitates multi-hop routingof packets. In order to reduce packet sizes, address abbreviation is used, so that onlythe minimum number of bytes of a SID is required to uniquely identify a node amongits direct, i.e., 1-hop neighbours. This reduces the header size in the common case to besmaller than that used for IPv6.2.2 Mobile DevicesMobile devices in general characterize networked appliances such as tablet computersand smartphones, in a broader sense also smart watches and notebooks. In this thesis,the focus will be on smartphones and tablets. Even though many vendors exist, themajority of devices either run Apple\u2019s iOS or Google\u2019s Android operating system.Due to its openness and easy accessibility, Android is often the platform of choice forresearchers. Some brief information about Google\u2019s system is given below.122.2 Mobile DevicesFigure 2.3: Contents of NINA APKAndroidAndroid is an operating system developed by Google specifically for smartphones,tablets and similar devices.14 At its core it uses a modified Linux kernel with a customuserland and user interface. While apps are generally written in Java, there is nostack-based Java Virtual Machine (JVM) involved, but a register-based one called DalvikVirtual Machine (Dalvik VM). Inter-process communication between apps can happenthrough explicit and implicit intents. Through this system, an app can subscribe toevents such a shared photo or contact information. Sending apps can either specify anexplicit application to handle the payload in the intent or just share the data such thatany application can respond to it. While UI code is written in the Java language, thereis also a native code interface to call binary libraries developed, for example, in C/C++.To ease development and debugging, Google provides a QEMU-based Android deviceemulator for all major desktop operating systems.APK - Android Application PackageAndroid apps are packaged as APKs, combining all necessary resources and code in oneZIP-compressed file ready for distribution. The basic layout of a typical application suchas the emergency warning application NINA is shown in Figure 2.3. While executablecode for the Dalvik VM can be found in .dex files, native libraries are organized under alib folder structured by target architecture, since one APK can be deployed on differentarchitectures (arm, mips, x64 etc). Assets and resources necessary have their predefinedlocations in the APK. Moreover, resources are also available in a precompiled formin resources.arsc. General information about an app are given in the binary XML filecalled AndroidManifest.xml. Here, version and author information as well as accessrights, public intents and referenced libraries are described. The META-INF containsmeta-information to ensure authenticity and integrity of the APK. Google requires eachapp to be signed by the developer prior to installation on any device.14https://www.android.com/132 Background2.3 Emergency CommunicationSeveral systems exist for emergency communication. There are specialized systemssuch as TETRA15 that are only for professionals and in many places also public sirens toalert the local population. The focus of this work is more on modern approaches usingcommodity devices. Here, one can distinguish between mobile device-based publicwarning systems that get centrally orchestrated by, e.g., the government (one-way),and general communication applications for anyone with a suitable device and appinstalled (two-way). Both approaches are described in more detail in the followingsubsections.2.3.1 Federal Public Warning SystemsPrior to omnipresent Internet access through mobile devices, governments relied mainlyon the use of public broadcast services such as television and radio as well as localsirens and speakers to inform the general population. Since the time spent with classicbroadcast services is declining16 and since especially younger people use the Internet,additional warning systems are needed. Due to the high smartphone penetration in thegeneral population17,18 of most countries, one favored approach is to use apps withpush notifications to deliver alerts. Some of the most common warning systems, mainlyfrom a German perspective, are presented below.DWD WarnWetterWarnWetter (Fig. 2.4) is a weather forecasting and warning app provided by the federalweather service of Germany, Deutscher Wetterdienst (DWD). It is available for Androidas well as iOS. Even though no source code is provided, the raw weather and warningdata is freely available through an official API and can be downloaded, for example, asa plaintext JSON file. The main features include general weather data, rain radar, hightide, flooding and avalanche information as well as alerts for the current location andsubscribed regions.BBK NINAThe Federal Office of Civil Protection and Disaster Assistance (Bundesamt fu\u00a8r Be-vo\u00a8lkerungsschutz und Katastrophenhilfe - BBK) has also developed an app to spreadpublic safety information to smartphones. NINA (Notfall-Information- und Nachrichten-App) enables a user to subscribe to various regions as well as the current position toreceive push alerts (Fig. 2.5. The warnings are from three different main categories: civilprotection, weather, and high tide information. The weather information is fed fromthe same source as the WarnWetter app. Besides the warnings, the app also includes15http : / / www . etsi . org / deliver / etsi _ en / 300300 _ 300399 / 30039202 / 03 . 02 . 01 _ 60 / en _30039202v030201p.pdf16http://www.businessinsider.de/tv-vs-internet-media-consumption-average%2Dchart-2017-617https://newzoo.com/insights/rankings/top-50-countries-by-smartphone%2Dpenetration-and-users/18http://www.pewglobal.org/2016/02/22/smartphone- ownership- and- internet%2Dusage-continues-to-climb-in-emerging-economies/142.3 Emergency Communication(a) Main overview (b) Weather radarFigure 2.4: DWD WarnWetter app in actionreading material regarding various disaster scenarios and general preparedness. Theapp is closed source, but the alert data is freely available as JSON files to be includedin other projects.KATWARNKATWARN (Fig. 2.6) is another system for public warnings similar to NINA. It wasdeveloped by Fraunhofer FOKUS and CombiRisk GmbH. A user can subscribe tovarious locations, areas or even special topics such as Oktoberfest for specific warnings.The backend also supports sending out warnings via SMS or email to users thatregistered for a location or topic and do not have a smartphone. KATWARN is alsoavailable internationally, for example, in Austria. Weather warnings are also issuedbut only for severe conditions, again sourced from the DWD. There is no sourcecode available and also no API or direct access to the current warnings. Dependingon a user\u2019s location and the corresponding districts and independent municipalities,warnings might get issued only over NINA or KATWARN or both. Therefore, bothapps are needed to be safe when traveling through the whole country. Also, due thecentral architecture deployed, KATWARN was overloaded during the Munich terroristattack in 2016.19Wireless Emergency and AMBER AlertsWireless Emergency Alerts (WEA) / Commercial Mobile Alert System (CMAS) is aUS-centric alert system designed for mobile phones utilizing the GSM infrastructureto deliver text messages via Cell Broadcast directly to cell phones.20 The system was19https://heise.de/-327721420https://www.fema.gov/pdf/emergency/ipaws/cmas_factsheet.pdf152 Background(a) Warnings overview (b) Detailed map view (c) Main menuFigure 2.5: BBK NINA in action(a) General map view (b) Alert detailsFigure 2.6: KATWARN in action162.3 Emergency Communicationdesigned to be used in the following use cases:\u2022 Alerts given out directly from the President of the United States of America.\u2022 Warnings for imminent threats such as terrorist attacks or extreme weather.\u2022 AMBER alerts - in case of local child abduction.Prominent use of the system was made during the Boston marathon bombing andby the National Weather Services for various extreme weathers like tornadoes, duststorms and flash floods. For the system to be effective, the cooperation of mobile serviceproviders as well as the cell phone manufacturers is required. Given that this is thecase and the cell network is still up, this system is highly effective in reaching people,and no preparation steps such as installing a specific app is required by the generalpopulation.Despite the limitations of the system, such as 90 character messages, no audio/videoattachments etc., it still poses a valuable tool to reach people in specific areas. Unfortu-nately, the system is not deployed in Germany or other European countries, Japan usesa similar system to issue earthquake warnings. Also, it fails if the central infrastructureis disrupted.2.3.2 Infrastructureless CommunicationBesides communication from professional responders and government officials to thegeneral public there is also the need for people to communicate with each other. Peopletend to self-organize help during disaster and therefore use social networks21 such asTwitter or Facebook. Often enough, Internet access is not or only partially availableduring disasters, which led to the development of messenger applications that com-municate also directly from device-to-device. These apps are not only popular duringdisasters, but also for communication in oppressive regimes or during demonstrationwhere free speech and communication might be restricted.BriarBriar22 is a rather new device-to-device messaging app. The focus of development wasto provide a secure and robust way for activists and journalists to communicate. BesidesBluetooth and Wi-Fi communication, it can also utilize the Tor network for increasedprivacy and security while exchanging messages over the Internet. Besides classicmessaging, group chats, forums, and blogs are supported by the app. The applicationand the protocol are completely open source, but the goal is only the integration ofopen platforms such as Android, leaving iOS users out. Therefore, Briar is not suitedas a general purpose communication tool for the majority of smartphone users.FireChatFireChat23 is a messaging app developed by the company Open Garden for decentral-ized communication without the need for Internet access. The app itself is available21https://blog.twitter.com/official/en_in/a/2016/twitter-for-crisis-and-disaster-relief-in.html22https://briarproject.org/23https://www.opengarden.com/firechat.html172 BackgroundFigure 2.7: FireChat room overviewFigure 2.8: Serval Mesh main viewfor Android as well as iOS platforms. It was especially popular during the Hong Kongprotests24 and various natural disasters. It features private one-on-one conversationsas well as public chat rooms (see Fig. 2.7). The core component MeshKit is, as the appitself, closed source.Serval MeshServal Mesh25 is an Android app (see Fig. 2.8) that uses Serval as its core to providemesh and DTN networking through an easy app interface. It enables a phone tocommunicate with peers through Bluetooth, WiFi and if supported by the mobiledevice also ad-hoc mesh routing. The app provides mainly the following services:\u2022 Voice calls\u2022 Text messaging\u2022 File sharingThe app26 and the underlying system27 are completely open source and develop-ment is very active even though Serval Mesh app is going to get replaced by a moremessaging-focused app called Serval Chat in the future. Features such as a publictwitter-like timeline missing from Serval Mesh are supposed to come with the newServal Chat app. Strong cryptography for end-to-end encryption is already built-in andusable in Serval Mesh. The app itself has been field tested during development by theNew Zealand Red Cross, among others. Various experimental ports exist, for example,for the iOS platform.24http://edition.cnn.com/2014/10/16/tech/mobile/tomorrow-transformed-firechat/25https://play.google.com/store/apps/details?id=org.servalproject26https://github.com/servalproject/batphone27https://github.com/servalproject/serval-dna182.4 Cloud ComputingCloud\u00a0ClientsSaaSPaaSIaaSWeb\u00a0browser,\u00a0mobile\u00a0app,\u00a0thin\u00a0client,\u00a0...CRM,\u00a0Email,\u00a0virtual\u00a0desktop,\u00a0communication,\u00a0...Database,\u00a0web\u00a0server,\u00a0development\u00a0tools,\u00a0...VMs,\u00a0server,\u00a0storage,\u00a0load\u00a0balancers,\u00a0network,\u00a0...InfrastructurePlatformApplicationFigure 2.9: Cloud services overview2.4 Cloud ComputingCloud computing is a paradigm where resources are shared and provisioned accordingto the current requirements. Often this means not owning hardware and not having iton premise but dynamically using the resources from specialized cloud providers as aservice. Through rapid provisioning and low management cost, companies can easilyscale when new events like Christmas business demand other resources.Many classic services used by companies as well as private persons, including storage,email, web-servers and databases, are migrated to cloud services with different paymentmodels. Instead of purchasing and maintaining own hardware, only the used servicesin terms of bandwidth, CPU power or storage are paid. The different services (Fig. 2.9)can be categorized, e.g., as Software as a Service (SaaS), Platform as a Service (PaaS), orInfrastructure as a Service (IaaS), the latter being the closest to classic dedicated serversproviding the most flexibility. A more technical look into IaaS is given in the followingsubsection.Infrastructure as a ServiceThe purpose of IaaS is to provide a computing infrastructure on demand similar toa hosted dedicated server. This is achieved by using either hypervisor based virtual-ization technologies like Xen28, KVM29, VirtualBox30, VMware ESXi31 or lightweight28https://www.xenproject.org/29https://www.linux-kvm.org30https://www.virtualbox.org31https://www.vmware.com/products/esxi-and-esx.html192 Backgroundvirtualization such as Linux containers32, DragonFly vkernel33 or FreeBSD jails34. Thelatter shares a kernel across all guest instances, preserving resources but less flexibilityand isolation for the guest user. Hypervisor-based solutions enable one to use guestOSes that are fundamentally different than the host, e.g., Windows machines runningon a Linux host, and provide increased security through better isolation.2.5 Security2.5.1 Transport Layer SecurityThe Secure Sockets Layer (SSL) and its successor, Transport Layer Security (TLS),are cryptographic protocols that were introduced to protect network communicationfrom eavesdropping and tampering. To establish a secure connection, a client mustsecurely gain access to the public key of the server. In most client/server setups,the server obtains an X.509 certificate that contains the server\u2019s public key and issigned by a Certificate Authority (CA). When the client connects to the server, thecertificate is transferred to the client. The client must then validate the certificate.35However, validation checks are not a central part of the SSL and X.509 standards.Recommendations are given, but the actual implementation is left to the applicationdeveloper.The basic validation checks include: a) does the subject (CN) of the certificate matchthe destination selected by the client?; b) is the signing CA a trusted CA?; c) is the signa-ture correct?; and d) is the certificate valid in terms of its time of expiry? Additionally,revocation of a certificate and its corresponding certificate chain should be checked, butdownloading Certificate Revocation Lists (CRLs) or using the Online Certificate StatusProtocol (OCSP)36 is often omitted. The open nature of the standard specification hasseveral pitfalls, both on a technical and a human level. Therefore, the evaluations in theremainder of this work are based on examining the four validation checks listed above.2.5.2 Man-in-the-Middle AttacksIn a Man-in-the-Middle attack (MITMA), the attacker is in a position to interceptmessages sent between communication partners. In a passive MITMA, the attacker canonly eavesdrop on the communication (attacker label: Eve), and in an active MITMA,the attacker can also tamper with the communication (attacker label: Mallory). MITMAsagainst mobile devices are somewhat easier to execute than against traditional desktopcomputers, since the use of mobile devices frequently occurs in changing and untrustedenvironments. Specifically, the use of open access points [32] and the evil twin attack[33] make MITMAs against mobile devices a serious threat.TLS is fundamentally capable of preventing both Eve and Mallory from executingtheir attacks. However, the cases described above open up attack vectors for bothEve and Mallory. Trivially, the mixed mode/no SSL case allows Eve to eavesdrop on32https://linuxcontainers.org/33https://www.dragonflybsd.org/docs/handbook/vkernel/34https://www.freebsd.org/doc/handbook/jails.html35https://tools.ietf.org/html/rfc528036https://tools.ietf.org/html/rfc2560202.5 Securitynon-protected communication. Furthermore, Mallory might act as a transparent proxy,delivering a certificate of its own to eavesdrop on the communication.SSL Stripping is another method by which a MITMA can be launched against anSSL connection, exploiting apps that use a mix of HTTP and HTTPS.37 SSL Strippingrelies on the fact that many SSL connections are established by clicking on a link in orbeing redirected from a non-SSL-protected site. During SSL Stripping, Mallory replaceshttps:// links in the non-protected sites with insecure http:// links. Thus, unless the usernotices that the links have been tampered with, Mallory can circumvent SSL protectionaltogether. This attack is mainly relevant to browser apps or apps using Android\u2019sWebView.37http : / / www . blackhat . com / presentations / bh - dc - 09 / Marlinspike / BlackHat - DC - 09 -Marlinspike-Defeating-SSL.pdf213 Secure Emergency CommunicationSecure communication during emergency scenarios is as complex as it is manifold,leading to complex systems with diverse requirements. At the one end, small, resourceconstrained devices such as smartphones, tablets and laptops are available to civiliansas well as to first responders. On the other end, large servers are relevant either inthe cloud or at specialized command and control centers in the field. Since manyother critical infrastructures and rescue operations heavily depend on ways of securecommunication, secure emergency communication plays a vital role.3.1 Emergency CommunicationIn general, there are two target groups that are relevant for emergency communication:professional responders and civilians. One issue refers to the question what happenson large, centralized systems that are connected via the Internet and provide variousessential services. Another issue is what happens on devices directly available to users,most commonly mobile devices such as smartphones. Both issues have their ownrequirements and challenges when used for emergency communication, as describedbelow.3.1.1 Internet ServicesInternetFigure 3.1: Typical services used during disaster response running in the Internet.A large variety of services exists in the Internet that are commonly used duringdisaster scenarios. Some of them are depicted in Figure 3.1. Several of them suchas email, Google, the World Wide Web itself or social networks such as Facebookand Twitter are also heavily used in everyday life. Yet, they also play a vital role indistributing information and connecting people during an emergency, as past events233 Secure Emergency Communicationhave shown.1,2 They are used by professional responders as well as civilians to self-organize help. Furthermore, there are services developed and deployed specificallyfor disaster scenarios, e.g., to coordinate rescue teams through disaster managementsoftware such as Project Sahana\u2019s EDEN3 or managing reports in Ushahidi4. Otheruseful cloud services for such scenarios include Google\u2019s Crisis Map or Facebook\u2019sSafety Check. For rapid deployment and scalability, many of these services rely on adynamic cloud infrastructure such as Amazon\u2019s EC2.3.1.2 Mobile ApplicationsFirst\u00a0RespondersCiviliansFigure 3.2: Mobile apps deployed on different devices.A similar picture can be seen when taking a look at common mobile devices used bycivilian and first responders (Fig. 3.2). Besides typical services that are also used oncomputers connected to the Internet, such as social networks (Twitter, Facebook etc.),the World Wide Web, or email, there are also apps more specific to smartphones, suchas messengers (e.g., WhatsApp, Threema, Telegram). While the previously mentionedapps are useful in non-disaster situations as well as during a disaster, there are manyapps such as Video-On-Demand (Netflix, Amazon Prime Video etc.), games and musicstreaming that have limited to no use during an emergency. There are a few appsspecifically designed for emergency scenarios to inform citizens and to cope with thefact that less and less people can be reached by classic broadcast services such as radioand television. In Germany, examples for these apps are NINA and KATWARN thatboth send push notifications via the Internet to participating mobile devices. While allthe previously mentioned apps on mobile devices rely on cellular networks or Internet1https://blog.twitter.com/official/en_in/a/2016/twitter-for-crisis-and-disaster-relief-in.html2https://www.fastcompany.com/40546380/facebooks-disaster-maps-helps-rescuers-know-where-theyre-needed-most3https://sahanafoundation.org/4https://www.ushahidi.com/243.1 Emergency Communicationaccess through WiFi, a few apps enable direct device-to-device communication forsimple services such as text messaging (Briar, Serval Mesh, FireChat). In recent years,mobile Internet usage has surpassed that of desktop systems.5 Having mobile, batterypowered devices readily available for the majority of people is a great advantage duringan emergency scenario.3.1.3 ShortcomingsOne common requirement for many existing emergency software solutions is that theyrequire a working communication infrastructure and a working Internet link. Whilemost of these applications work over reliable TCP links, they also assume connectionsto be stable and require quite some bandwidth even for loading a simple webpagesuch as Facebook. When disaster strikes like, for example, hurricane Irma in 2017, thiscan leave even parts of a high-tech country such as the USA for a few days withoutconnectivity. A small overview of a typical scenario can be seen in Figure 3.3.While mobile devices are mainly used for person-to-person communication, socialnetworks and taking footage with the built-in camera, back end services include stan-dard communication measures such as email as well as scenario specific applications.These cloud-based services might not be accessible when communication infrastructureis destroyed during disasters, as indicated by the red arrowed connections and yellowflashes in the figure. Also, emergency warning apps such as KATWARN or NINA willnot work anymore when the Internet connection is not available any longer. This isespecially problematic, since they were not only meant to warn people prior to a disas-ter, but also to inform them during the event. Even with working connectivity, such asystem might fail due to the sudden peak in user activity similar to a Denial-of-Serviceattack.6CiviliansFirst\u00a0RespondersInternetFigure 3.3: Problem overviewIn the past, the public was warned and informed using, e.g., radio broadcasts, butespecially young people are more focused on Internet-based media consumption and5http://bgr.com/2016/11/02/internet-usage-desktop-vs-mobile/6https://www.focus.de/5756395253 Secure Emergency Communicationmore and more mobile device vendors have removed the ability to use phones as FMreceivers.7 The lack of the Internet during a disaster also renders common applicationssuch as Skype, Twitter or WhatsApp useless. All dysfunctional apps are marked witha red \u2019x\u2019 in the figure. Only very few of the apps available on today\u2019s smartphoneswork truly offline or with local communication only. Notable examples are FireChatand Serval Mesh. If none of these are present on a smartphone, it is very limited in itsusefulness during a disaster.One of the few functions usually still working is the included camera for takingpictures or videos, but with very limited ways to share this data., e.g., via vendorspecific solutions for local data exchange such as AirDrop or Google\u2019s Files Go.3.2 Design of a Secure Emergency Communication SystemThe main challenge is to identify ways to re-enable communication with readily avail-able commodity hardware during a crisis. Typically, local routers can be used togetherwith mesh routing to form an independent communication infrastructure, e.g., Frei-Funk8 and GuiFi9. While this approach can also be beneficial in non-disaster situationsand provide stable services, it also relies on a sufficiently dense distribution of partic-ipating routers and a stable power supply. Mesh routing has the advantage that it istransparent to legacy applications, but often mobile devices lack capabilities to nativelyjoin an ad-hoc or pure 802.11s mesh network. Thus, such a network relies again on aform of maintained infrastructure.The alternative is to use device-to-device communication, relying on the built-in directcommunication capabilities of smartphones, tablets and notebooks. These technologiestypically include Bluetooth, WiFi and, WiFi direct, with special application supportfor disruption-tolerant-networking and new mechanisms for coping with delays anddisruptions. These technologies can provide a viable alternative. Furthermore, whenlooking at future technologies currently emerging, such as Lora, Bluetooth Mesh and802.11ah, all mainly used for Internet-of-Things (IoT) communication, more possibilitiesfor readily available emergency communication can be developed.Part of this thesis\u2019 research question is to find a communication solution integrat-ing these technologies with new approaches for secure and robust local and cloudcommunication.There are three key components (see Fig. 3.4) relevant for a general emergencycommunication system that is suitable for civilians and professional responders alike:\u2022 Disruption-Tolerant Device-To-Device Emergency Communication (green)\u2022 Security Vulnerability Analysis of Mobile Apps (blue)\u2022 Secure Cloud Systems (red)The foundation is a disruption-tolerant device-to-device emergency communicationsystem (indicated by green arrows in the figure) that handles various needs of usersand can cope with the challenges in disaster scenarios while maintaining a high level ofsecurity. Also, the state of apps deployed on mobile devices is relevant for the overallsecurity of the system and, therefore, must be analyzed for security vulnerabilities7http://fortune.com/2017/09/28/apple-fm-radio-hurricane/8http://freifunk.net/9http://guifi.net/263.2 Design of a Secure Emergency Communication SystemFigure 3.4: Secure communication during disaster scenarios(marked in blue in the figure). Finally, services running on servers in the edge/fog/mistcomputing infrastructure (provided, e.g., by professional responders) or the cloud mustbe secured against failures and attackers (marked in red in the figure).3.2.1 Disruption-tolerant Device-to-Device Emergency CommunicationThere are several key challenges that must be overcome to deliver a disruption-tolerantdevice-to-device emergency communication system that also works during a disasterscenario. These challenges are described briefly below.Test and Evaluation Environment. Since the goal of this thesis is to deliver a systemthat operates in various network setups, mobility and link properties, a virtual play-ground for disaster scenarios is needed. While there are different network simulatorsavailable, these lack the capabilities to include software as it is and therefore, omit anyside-effects caused by real world implementations of the software or the full systemstack (network, kernel, userland etc.). Yet, they often provide advanced mobility pat-terns and (at least for WiFi) realistic communication models. On the other hand, manyemulation environments are often limited in terms of mobility of the nodes or realisticsimulation of link properties. To thoroughly test an emergency communication system,a simulation-emulation system with full-system emulation, flexible movement patterns,and various radio links is vital.Basic Messaging and Data Exchange. The most basic and useful feature needed bypeople for organizing themselves during a crisis is some form of message exchangeand a way to share binary data. Since many solutions exist that try to solve theseproblems, we must first evaluate those that might also work in a disaster scenario.Only peer-to-peer protocols must be considered, since we cannot rely on infrastructureduring emergencies. Furthermore, not relying on TCP connections but using UDPinstead helps to deal with unreliable connections. Protocols that have DTN built inare especially suitable for these setups. Further desired properties include messageintegrity and confidentiality that are mandatory for such a scenario.Optimizations for Low-Bandwidth Links. Due to the fact that we heavily rely on low-bandwidth links (e.g., Bluetooth and LoRa) we have to minimize the produced traffic.273 Secure Emergency CommunicationExisting protocols often rely on flooding the network with local announcements, whichworks well with Ethernet or fast WiFi, but can easily overwhelm a small local networkwith only a few kilobits per second of bandwidth. Furthermore, some protocols suchas HTTP(S) are suitable as long as the infrastructure works and bandwidth is plentiful,but for slow links HTTP(S) is very verbose, and each request and response is very large.Finally, the payload data itself is subject to optimizations. Especially large binary blobssuch as image data can be optimized prior to sending either through compression orpreprocessing on the device itself.High-Level Task Offloading. Since resources such as battery power and computepower on mobile devices are considered to be very limited in a disaster scenario,alternatives must be found to handle more complex tasks. Usually, we can offload tasksby calling a remote procedure e.g., via SOAP or JSON-RPC, on a remote server andutilize its power. When we are limited to unreliable links and have highly mobile nodes,these approaches do not work. Therefore, a system is needed to deal with unknownremote-peers, disrupted connections, and delayed execution, and delayed delivery ofresults.On-Device Data Processing. By processing data on a mobile device, not only thebandwidth requirements can be reduced, but also improved quality of services regard-ing emergency services can be delivered. On of the most common tasks during andisaster is the localization of missing persons. Therefore, having the ability to processimage data on-device and detect human faces can easily be used to automate thesearch. Furthermore, having automated visual concept detection on-device can helpto reduce the number of unimportant images that should not be spread further inthe network. Since mobile devices such as smartphones or Raspberry Pis are severelylimited when it comes to battery life and CPU power, algorithms must be adopted tothis new environment. This also results in an overall higher processing speed, since ashorter runtime means that less power is consumed.Secure Communication System. Besides designing the communication system to berobust against network disruptions and to work in an infrastructureless manner, it isequally important to incorporate approaches for increased security of such a system.This includes attestation of new devices during a crisis and avoiding DTN-specificattacks on message buffer management. Confidentiality and message authenticity isvital during a crisis for professionals responder as well as civilians.Since mobile devices are key components in communication nowadays, researchtopics focusing on mobile communication infrastructures and application level servicescan be found in Chapter 4.3.2.2 Security Vulnerability Analysis of Mobile AppsFurthermore, the security aspects of data-at-rest and data-in-motion in emergencyscenarios are vital for mobile emergency communication. Therefore, several researchquestions have to be answered, as outlined below.283.2 Design of a Secure Emergency Communication SystemStatic Analysis of Mobile Apps. Repeatability and automation of security auditsmake it easy to evaluate larger sets of apps that might be relevant in an emergencyscenario. While static analysis usually is a manual process on the binary, assembler orsource level, the patterns of vulnerabilities found in binaries are often similar. Thesepatterns can be related to different network usage patterns, encryption functionality,or access to sensitive information. Moreover, static analysis is suited to quickly ensurethat certain mistakes are not (re-)introduced during development by reapplying theaudit script to newly produced binaries.Dynamic Analysis of Mobile Apps. There are some vulnerabilities that cannot bespotted with static analysis such as the ones nested in dynamically loaded code. Fora thorough security audit, it is mandatory to also inspect apps during runtime. Sincethis involves on-device deployment or emulation of a mobile device, the process ofautomating this on a large scale is very resource intensive and quite challenging.Therefore, it is beneficial to include cloud computing resources in the design of such asystem.Security of Common Emergency Apps. There already exist various apps for commu-nication and information spreading before, during and after disasters, as mentioned inChapter 2. Some of them are officially distributed by governments and are widely used.By applying static and dynamic analysis together with manual audits, potential short-comings and vulnerabilities can be identified. Having apps where one can suppresswarnings or distribute false information, an attacker can potentially worsen an alreadycritical situation or cause a disaster in the first place.The security analysis and approaches regarding mobile devices mentioned above arepresented in Chapter 5.3.2.3 Secure Cloud SystemsThe Internet provides vast resources for various services that are critical during disastersas well as everyday life. Especially due to dynamic deployments in the cloud one caneasily respond to disasters and quickly get necessary services for coordination of rescueefforts running.10 Here, it is important to understand key services and find ways toprotect infrastructure at risk.Email Delivery. One of the corner stones of Internet communication is the emailsystem based on SMTP. Its importance can also be seen as this is mentioned in the list of\u201dbasic internet communications activities like text messaging, SMS, status updates, basicweb access and email\u201d that was delivered by Google\u2019s Project Loon to the people ofPuerto Rico after being struck by a hurricane.11,12 By design, SMTP, responsible for thedelivery of email message, is a plain text protocol. To secure a message, there are manysolutions such as S/MIME or PGP/GPG that users can settle on. Factors often neglected10https://www.ushahidi.com/plans11https://www.fiercewireless.com/wireless/loon-working-at-t-to-get-basic-services-to-puerto-rico12https://blog.x.company/helping-out-in-peru-9e5a84839fd2293 Secure Emergency Communicationare leaking meta-data and insecure communication links. Transport-layer security isoptional but critical for the overall security of emergency communication. Therefore,an evaluation of how wide-spread encrypted SMTP is, what cryptographic key size isused, who issued a certificate and what encryption ciphers are used is needed for anmore in-depth understanding of the overall security of email communication.Infrastructure Protection. All services exposed via a network are potentially at riskfrom malware and malicious hackers. While 100% security will never be achieved, it isvital to make a system compromise as hard as possible. If it does happen, incidentsneed to be detected as soon as possible to trigger counter actions. The use of virtualizedsystems gives a defender a variety of new options to detect attacks and infected systems,ideally, with a minimal footprint in the virtual machine and all security critical logicseparated. Points to be considered are classic anti-virus protection against unknownbinaries, but also advanced monitoring of network traffic, system calls or loading ofkernel modules for yet unknown anomalies. By having minimally-invasive sensorsacross all layers of the host machine, kernel, userland and the application layer alsogives us the opportunity to cross-validate findings and eliminate false positives.New approaches regarding cloud and server security for communication systems arepresented in Chapter 6.304 Disruption-tolerant Device-to-DeviceEmergency Communication4.1 IntroductionThis chapter presents research conducted in this thesis regarding disruption-tolerantdevice-to-device emergency communication on mobile devices as well as applicationsand application services developed for this scenario.First, a realistic environment for the evaluation of possible mobile communicationsolutions is needed. Since pure model-based simulations often differ from real worldimplementations and large scale physical test-beds are as expensive as they are inflex-ible, a solution, called MiniWorld, based on full system virtualization is presented inSection 4.2.MiniWorld is used for the development and evaluation of novel DTN-based commu-nication solutions. The Serval Project appears to be a viable basis for mobile emergencycommunication. To verify its claims, an in-depth evaluation regarding an emergencyscenario is presented using MiniWorld in Section 4.3.During this evaluation, a major issue for improvement was identified regardingServal\u2019s energy and bandwidth requirements. So far, Serval uses fixed announcementintervals for peer discovery and database synchronization. Switching to dynamicallyadaptable announcement algorithms is much more efficient, as shown in Section 4.4.Since the resources on mobile devices are limited, offloading tasks makes sense,but existing classical remote procedure call (RPC) solutions are not applicable inthis uncertain environment. Therefore, a novel RPC system, called DTN-RPC, that isspecifically tailored to DTN and D2D communication. is presented in Section 4.5.Furthermore, with additional new components developed for embedded systems,DTN-RPC can be used for environmental monitoring in static and mobile setups, asshown in Section 4.6. By combining low-cost micro-controller units and long-rangeLoRa transceivers, it is possible to integrate smartphones in such infrastructurelessnetworks. Moreover, the possibility to perform on-device visual concept detection onsmartphone photos is also presented and optimized for energy efficiency on low-powerdevices such as the Raspberry Pi. Section 4.7 shows that on-device pre-processing ofdata, such as face detection, is invaluable especially for low bandwidth links.Using the above research, it is possible to deliver new applications and networkservices for disaster scenarios. One common task, often heavily relying on Internetcloud services, is the detection of a missing person\u2019s face on images. A completeon-device solution for efficient face detection is presented in Section 4.7.The real world usefulness of the developed system as a mix of mesh and DTN-based services in combination with unmanned autonomous ground and air vehicles isdemonstrated in Section 4.8.A flexible security infrastructure that is resilient to flooding attacks and that takes314 Disruption-tolerant Device-to-Device Emergency CommunicationFileDistribution MeshMSVoiceMeshRhizome\u00a0DTN Mesh\u00a0DatagramProtocol\u00a0(MDP)Serval\u00a0Overlay\u00a0MeshUDP,\u00a0IP,\u00a0Ethernet/WiFi Packet\u00a0Radio ...LoraSmartFacePeopleFinderDTN\u00adRPC GWProxyPre\u00ad/Content\u00ad/Post\u00adFilterAdaptive\u00a0CommunicationMesh\u00a0RoutingInformation\u00a0Centric\u00a0Networking Sensor\u00a0Managment Remote\u00a0ControlFigure 4.1: The DT D2D communication system developments highlighted in green.proper key/certificate management into account, is necessary for any emergency com-munication system. SEDCOS, presented in Section 4.9, is a novel solution specificallydesigned for emergency scenarios with these problems in mind.The various improvements and new developments in comparison to Serval aredepicted in Figure 4.1. Many of the developments required for the emergency commu-nication system described in this chapter are available as open source software. Duringthe course of this work, contributions have been made to Serval1 as well as CORE2,through patches, bug reports, and additional software3. Regarding the MiniWorld emu-lation environment, more information can be found on github.4 DTN-RPC5 and thefilters developed for integration and optimization purposes are also available.6,7 Vari-ous user directed developments are also available such as command line helpers andremote command execution services8, legacy TCP application integration9 as well asuser interfaces.10,11,12 To make the most out of the various LoRa transceivers embeddedon microcontrollers, a novel radio modem firmware was also developed. 131https://github.com/servalproject/serval-dna2https://github.com/coreemu/core3https://github.com/gh0st42/core-automator4https://github.com/miniworld-project/miniworld_core5https://github.com/umr-ds/DTN-RPC6https://github.com/umr-ds/serval-contentfilters7https://github.com/umr-ds/serval-dna/tree/nicer-filters8https://github.com/gh0st42/servalshellscripts9https://github.com/umr-ds/python-socks5-serval10https://github.com/umr-ds/serval-web11https://github.com/gh0st42/ServalDesktopApp12https://github.com/gh0st42/sdnatui13https://github.com/gh0st42/rf95modem324.2 MiniWorld - An Emulation-based Evaluation Environment4.2 MiniWorld - An Emulation-based Evaluation Environment4.2.1 IntroductionTo develop applications, algorithms, and protocols for future networks, four methodsare typically used: (a) mathematical modeling, (b) network simulation, (c) networkemulation, and (d) real world experiments. Mathematical modeling and network simu-lation are commonly used in the early stages of development, but are often criticizedfor inaccuracies in capturing realistic node behavior and medium characteristics [34],[35]. In contrast, real world testbeds can establish genuine environmental conditions,but are often limited in scope and induce a high management overhead.Network emulation offers a valuable compromise between network simulation andreal world experiments, since evaluations can be performed in real-time under realisticconditions and software can largely be reused when switching from emulation to realworld deployment [36], [37]. In particular, in virtualization-based network emulation,real code is run in an emulated network using operating system level virtualizationtechniques combined with careful resource isolation and monitoring [38]\u2013[40]. Thisapproach provides the topology flexibility, low cost, and repeatability of simulationwith the functional realism of real world testbeds.In this section, MiniWorld is presented, a novel distributed network emulation frame-work. It is based on virtual machines (VMs) running on the cores of a shared-memorymulti-core processor (centralized mode) or in a distributed system of connected multi-core processors (distributed mode). Its main properties that distinguish it from othernetwork emulators are:\u2022 MiniWorld\u2019s QEMU14/KVM-based15 full virtualization allows nearly every soft-ware and hardware to be emulated.\u2022 Three network backends for wired and (pseudo-)wireless communication areprovided to demonstrate the flexibility and modularity of MiniWorld.\u2022 Four mobility patterns and three distance-based link quality models are offeredto ease the development and evaluation of wireless networks.\u2022 A snapshot boot mode is presented for accelerated booting of identical environmentsand repeating emulations.\u2022 MiniWorld\u2019s emulations can be distributed across multiple computers via aresource-aware VM scheduler.\u2022 Connection tracking, differential network switching, address configuration andnetwork supervision features are provided automatically for every network back-end.Experimental results demonstrate the performance of MiniWorld with respect to VMboot times, network bandwidth, round trip times, and topology switching times, bothfor MiniWorld\u2019s centralized and distributed emulation mode.Parts of this section have been published in [1].14http://www.qemu-project.org15http://www.linux-kvm.org/334 Disruption-tolerant Device-to-Device Emergency Communication4.2.2 Related WorkSeveral network emulators have been developed [36], [37]. For example, CORE [38]is a popular network emulator based on container virtualization. Since all emulatednodes share the same operating system (OS) kernel, protocol stacks other than the onespresent in the kernel cannot be emulated. Further limitations are that router images,different OS and different kernels are not usable with CORE. In contrast, MiniWorldis designed for full system emulation and supports every OS and application thatruns under QEMU. CORE offers a distributed mode in Linux based on GRE tunnels(i.e., Gretap) to connect nodes living on different emulation servers. Nodes have to bemanually assigned to a specific emulation server. This is different in MiniWorld where ascheduler carries out the node assignment task according to resources of the emulationservers.Cloonix16 is an emulator using KVM, mainly for wired networks. Several Cloonixservers can be interconnected, but there are fixed links between the emulated nodes,and nodes are manually pinned to their hosting server, similar to CORE.DOCKEMU [39] uses Docker containers as its virtualization layer and utilizes Linuxbridges together with the ns-3 simulator17 to emulate PHY and MAC layers. MiniWorlduses the KVM instead of Docker containers as its virtualization layer, but adding Dockerto MiniWorld would increase performance for scenarios where full system virtualizationis not required.BAMNE [41] is a network emulator that leverages a patched version of VDE [42] to-gether with VirtualBox18. The emulator is tailored to perform tests with B.A.T.M.A.N.19.Unfortunately, no experiments that demonstrate the performance of BAMNE are pro-vided.Netkit [43] relies on full virtualization and container-based isolation. It is based onUML, a port of the Linux kernel designed to run as a user-space application. All nodesshare the same file system for reading, while they use a COW mechanism to create awrite-layer on a per-node basis. Netkit is built for educational purposes and lacks severalimportant features, such as link emulation or a wireless mode. MiniWorld utilizes theCOW approach in the same manner Netkit does.GNS320 is an open source emulator built to help people preparing for Cisco exams.GNS3 can only emulate Cisco routers, not switches [44]. Besides CORE and Cloonix, itis the only simulator with a distributed mode.NEMAN [45] is a network emulator for testing middleware and application layerprotocols. It relies on ns-221 scenario files for the description of mobility and topology.In contrast to MiniWorld, NEMAN requires application binaries to be modified. Fur-thermore, there is no virtualization layer, since processes simply bind to a tap device.Moreover, there is no link impairment and no high fidelity link emulation. Netem, aLinux kernel module [46], is used for link impairment by MiniWorld\u2019s Bridged LAN andBridged WiFi network backends. For high fidelity link emulation, MiniWorld could becombined with ns-3, similar to CORE or DOCKEMU.16http://cloonix.fr17https://www.nsnam.org18https://www.virtualbox.org19https://www.open-mesh.org/projects/open-mesh/wiki20https://www.gns3.com21http://nsnam.sourceforge.net/wiki/344.2 MiniWorld - An Emulation-based Evaluation EnvironmentMiniWorldEmulation ManagerImage StoreScenario ConfigAnalystAddress ConfigurationNetwork SupervisionMobility PatternNetwork BackendStart / StopStepNode VirtualizationVirtual NetworkFigure 4.2: MiniWorld\u2019s ArchitectureMininet [40] is an emulator for SDN and comes with open vSwitch [47]. It uses Linuxnetwork namespaces and process isolation for each emulated node [48]. SDN controllerscan run on the real network or inside the network namespaces, since Mininet ships witha VM with useful tools, e.g., Wireshark and dpctl, to control and view the flow tablesof an OpenFlow switch. In contrast, MiniWorld\u2019s Bridged LAN and Bridged WiFi networkbackends follow the CORE approach. CORE scenario files can be built with the COREUI and used by MiniWorld\u2019s CORE Mobility Pattern to switch between topologies.4.2.3 MiniWorld\u2019s DesignArchitectureThe architecture of MiniWorld is shown in Figure 4.2. To start an emulation, a networkanalyst needs a Scenario Config to setup a Virtual Network, and an OS image containingthe software to be evaluated from the Image Store. The analyst starts/stops an emulationand performs emulation steps by invoking the Emulation Manager. A step involvesthe Network Backend to change the topology of the Virtual Network and requires adistance matrix from the Mobility Pattern as the input for the static or event-drivenimpairment scenario that governs node connectivity and link quality. The NetworkBackend can operate either in user-space or in kernel-space and is responsible forcreating or switching the network topology according to the Link Quality Model andthe Mobility Pattern. Address Configuration to communicate via addresses and NetworkSupervision to monitor the network topology setup are optional components.MiniWorld needs to know when a VM has finished booting. This is accomplished byeither letting MiniWorld know for which string it has to wait (boot mode: Boot Prompt) orby simulating pressing enter and waiting for the shell prompt (boot mode: Shell Prompt).Furthermore, network nodes are started in parallel to improve performance. After all354 Disruption-tolerant Device-to-Device Emergency Communicationnodes have been started, the VMs are provisioned according to the shell commandssupplied in the Scenario Config. MiniWorld can be set up to switch the network topologyin configurable time steps (normally one second) automatically. Note that an analystcan also manually switch the network topology.Wireless InterfacesVirtual nodes can have multiple wireless interfaces to create separate network segments.Built-in interface types are: AP, Ad-hoc, Mesh, Bluetooth and WiFiDirect. Each node canhave multiple instances of an interface type. An Interface Filter decides which interfacesare connected to each other. The default Interface Filter allows only interfaces of the sametype and index to be interconnected. A Network Backend can define its own InterfaceFilter to change this behavior. A Management interface that is not affected by link qualityimpairments serves as a management/side channel that can be used in experimentsfor control information or SSH automation. A Management Node has to be provided bya Network Backend to support the management interface. To simulate crowded eventssuch as football games, there is a Hub interface that allows a Network Backend to set upa single broadcast domain.Link Quality ModelsA Link Quality Model controls the impairment applied to the virtual network (impair-ment scenario). Static impairments serve as default values. For each step and distancebetween two nodes, the Emulation Manager calls the Link Quality Model. First, the modeldetermines whether a connection will be established at all. Second, the link qualitybased on the distance is determined. Currently, three link quality models are available:(a) Fixed-Range where nodes are interconnected if their distance is less than 30 metersand the bandwidth is fixed, (b) WiFi Simple Linear decreases bandwidth and increasesdelay linearly with the distance, (c) WiFi Simple Exponential halves bandwidth anddoubles delay every 4 meters. To prevent link quality models from slowing down theconnection switching process, the link quality settings are pre-calculated (Link QualityCaching) for all rounded distances up to the maximum allowed connection range. Thisapproach is a trade-off between performance and granularity.Mobility PatternsCurrently, MiniWorld provides four mobility patterns: (a) Random Walk, (b) Move OnBig Streets, (c) Arma 3, (d) CORE Mobility. Patterns (a) and (b) are based on OSM22 dataand implement a Random Walk and a Move On Big Streets pattern. Pattern (c) is basedon the Arma 3 MilSim game23 where coordinates are extracted from the game for eachplayer to feed a Movement Director with node positions. Pattern (d) uses CORE scenariosexported to XML in order to have multiple topology files that can be switched after apredefined number of time steps. There are two connection modes: LAN and WiFi. TheLAN mode considers whether nodes are connected according to the XML files. In theWiFi mode, the distances between nodes are used to determine link qualities betweennodes. Pattern (d) can also be looped.22http://www.openstreetmap.org23https://arma3.com364.2 MiniWorld - An Emulation-based Evaluation EnvironmentNetwork BackendsCurrently, MiniWorld comes with three network backends to create virtual networks,add/remove connections, and adjust link quality: (a) VDE, (b) Bridged LAN, and (c)Bridged WiFi.VDE [42] is a user-space software-switch to emulate link properties, such as delay,packet loss, and duplicate packets. In MiniWorld\u2019s VDE network backend, each interfaceis connected to a different VDESwitch to create separate network segments. A Wirefilterfor each connection between two nodes is used to apply different link quality impair-ments. The VDE color patch24 is used to create a hop-to-hop network instead of a singlecollision domain where all nodes can see each other. Traffic is only forwarded betweenswitch ports if their color differs, effectively realizing a wireless mesh network.Bridged LAN and Bridged WiFi leverage technologies from the Linux kernel (i.e., Linuxbridges and Linux TC) to create a virtual network. Bridged LAN uses one interface torepresent a connection. In contrast, the Bridged WiFi multiplexes connections via asingle tap interface per MiniWorld interface. Thus, Bridged LAN is static and can beused to emulate wired networks, because the number of unique connections has to beknown beforehand to set up the number of NICs in the VM. In contrast, Bridged WiFi isdynamic and can be used to emulate wireless networks, since it does not matter howmany unique connections are going to exist.Distributed ModeFigure 4.3 illustrates MiniWorld\u2019s distributed mode, where a central Coordinator allowsany Linux computer (Emulation Server) to participate in an emulation. A user can interactwith any of these via an RPC interface to query information or execute commands onspecific nodes. Each Emulation Server operates independently for each simulation step,and virtual network nodes are hosted only on the Emulation Servers.There is a score-based node placement strategy which takes the resources of theEmulation Servers into account. The Coordinator computes the distance matrix anddistributes it among the Emulation Servers, hence the Emulation Servers are kept in syncwith each other. Globally necessary information is shared with each Emulation Serverbefore an emulation starts.An emulation step of either the RunLoop or the user creates a distance matrixthat is sent via ZeroMQ25, a networking library for message-passing with efficientone-to-many (Publish-Subscribe) and one-to-one (Request-Reply) communication. In thePublish-Subscribe pattern, the distance matrix is sent to any subscriber and filtered atan Emulation Server for relevant data. In the Request-Reply pattern, the distance matrixcan optionally be filtered at the Coordinator, since it has a separate connection to eachEmulation Server.4.2.4 ImplementationFigure 4.4 shows an overview of the implementation of MiniWorld26. Its functionality,indicated by the blue buttons on the left, is accessible by an RPC interface. All classes24http://www.open-mesh.org/attachments/download/152/vde2-2.3.2_colour.patch25http://zeromq.org26https://github.com/miniworld-project/miniworld_core374 Disruption-tolerant Device-to-Device Emergency CommunicationMiniWorldEmulation ServerCoordinatorRPC InterfaceEmulationManagerZeroMQ InterfaceRunLoopStepStepStepVirtual NetworkChange TopologyNetwork BackendEmulatiom ManagerNetwork ManagerVMVMVMRPC InterfaceZeroMQ InterfaceStepEmulation ServerVirtual NetworkChange TopologyNetwork BackendEmulation ManagerNetwork ManagerVMVMVMRPC InterfaceZeroMQ InterfaceStepTunnelsStepAnalystStepLegendZeroMQ SocketOptional RPC Control FlowVirtual NetworkFigure 4.3: MiniWorld\u2019s Distributed Architecturewith dashed line frames can be exchanged in a modular manner. The interplay of mostof the classes of the core of MiniWorld in the lower right part of Figure 4.4 have alreadybeen explained in Section 4.2.3. The implementation of the remaining classes is outlinedbelow.Each virtual network node is represented by a QEMU process. If the processor doesnot support VT, the dynamic translation capabilities of QEMU are leveraged. Internally,the QEMU class has a connection to the serial console of the VM. This gives MiniWorldcontrol over the VM without requiring any VM configuration. Moreover, this enablesMiniWorld to view the kernel and boot log. The boot process is finished if either theshell prompt (boot mode: Shell Prompt) or a user configured string has been read onthe serial console (boot mode: Boot Prompt). An additional UDS socket, connected tothe QEMU Monitor, is leveraged to interact with the QEMU process. The monitorconnection enables the creation of snapshots (Snapshot Boot Mode).Not relying on SSH for node provisioning enables MiniWorld to configure a VMwithout preconfigured network settings. Commands to be executed on all or only aspecific node are stored inside the Scenario Config. Moreover, commands can be executedby the user on each node.The NetworkManager keeps track of current connections and associated link impair-384.2 MiniWorld - An Emulation-based Evaluation EnvironmentMiniWorldMiniWorld Core Virtual NetworkVMVMVMNetwork ConfiguratorNetwork BackendEmulation ManagerNetwork ManagerConnection TrackingQEMUEmulationNodeUnix Domain SocketsInterfaceShellCommand-SerializerChange TopologyEmulation ManagementTopologySwitchingProcess ManagementShell-HelperLogWriterfilestackMobility & Link QualityMovement DirectorLinkQualityModelEvent SystemEventSystemEventProgessStoreRPC InterfaceStart / Stop ScenarioGet ConnectionsGet Link QualityExecute Command on NodeGet LogsStepLegendControl Flow AggregationI/O ExchangeableClassClassUsageGet DistancesGet ServerRunLoopFigure 4.4: MiniWorld Implementationments independent of the network backend implementation. Since connections aretracked, the EmulationManager only communicates with the Network Backend if a con-nection changes in terms of link state or impairment (Differential Network Switching).An optional Network Configurator gives each interface of a VM an IP address. Moreover,each Network Backend may decide to use a custom implementation. Note that even thevirtualization layer can be exchanged so that container virtualization may be added toMiniWorld.Virtual NodesNodes are virtualized with QEMU. MiniWorld does not rely on libvirt, instead it usesplain QEMU to leverage the full flexibility of the emulator. The QEMU command isbuilt from options declared in the Scenario Config. For each different node image, anQCOW2 overlay image is generated to make use of a COW mechanism. With the COWmechanism, a single image representing a common read-only layer is used by all nodeswith the same base image, hence node images are write-isolated from each other. Theboot times of VMs for full virtualization are higher than for lightweight virtualization.A special boot mode called Snapshot Boot Mode tries to reduce these times. Snapshots aretaken from the VMs. For this purpose, {savevm,loadvm} <snapshot name> commandsare sent to the QEMU Monitor. If an error occurs, a VM is booted normally.394 Disruption-tolerant Device-to-Device Emergency CommunicationNetwork BackendsVDE For each interface of the VDE network backend, a VDESwitch is started. Boththe VDESwitch and Wirefilter can be controlled via an Unix Domain Socket (UDS). TheVDESwitch interface is used to set the hub mode, manage VLAN, view switch portsand their links, set the color of each link and to set the number of ports. The WirefilterUDS interface is used to define the link quality in terms of loss and bandwidth, but itsupports more impairment options such as delay, duplicate packets, bandwidth, speed,noise, MTU, and more advanced modulation techniques using Markov chains.Bridged LAN and Bridged WiFi Bridged LAN determines for each node the maximumnumber of connections during a scenario. Then, the VMs are created with the necessarynumber of NICs. The representation of a connection with a single NIC creates point-to-point links. Hence, for each connection, the appropriate NICs are added to a bridge.Bridged WiFi allows any number of connections to be multiplexed over a single NIC,hence only one NIC per MiniWorld interface is used. Ebtables is the equivalent of iptablesto create firewalls, but operates on the link level instead. For each connection, ebtablerules based on the tap device names are used for filtering. Additionally, Linux trafficcontrol facilities are used to apply different link qualities based on the connections.For each interface in MiniWorld, one bridge is created. Moreover, frames received by abridge are redirected to the appropriate chain.Virtual Network Creation and Control To create and control a virtual network, Mini-World supports Brctl, Iproute2 and the Pyroute2 Python library that uses netlink socketsto interact directly with the kernel. In contrast to Iproute2, Brctl worked out of the boxon all tested machines, whereas some versions of Iproute2 do not support setting thehub mode of a bridge. Although Brctl does not offer a batch mode, it is included forsituations where ease of use is more important than performance. Either Brctl, Iproute2or Pyroute2 is used for creating a bridge, adding an interface to a bridge, changing thestate of an interface and for transforming a bridge into a hub. Brctl commands can onlybe executed sequentially, hence communication with the kernel produces overhead foreach command. Iproute2 and Pyroute2 are able to execute all commands at once (batchmode).Link Quality Models Link quality impairment is implemented using HTB, a classfulQDisc for bandwidth shaping. More advanced link emulation is offered by NetEm [46]that allows to simulate delay, packet reordering, loss and much more. Currently, onlythe delay is deployed in the NetEm capable link quality models. The delay dependsto 25% on the last delay. For the Bridged WiFi network backend, connection flowsare marked by ebtables. Since connections are multiplexed via a single NIC, for eachconnection a separate traffic class associated with the NIC is used to simulate differentlink quality impairments. Traffic is classified by a filter (via the flow ID) and thenredirected to the appropriate traffic class. For Bridged LAN, a single traffic class can beused without any filtering, since each connection is represented by a NIC.404.2 MiniWorld - An Emulation-based Evaluation EnvironmentDistributed ModeIn MiniWorld\u2019s distributed mode, nodes are interconnected on the link layer with GREby default. Both sides of a connection have to establish a tunnel. The tunnel is added toa bridge on both nodes.Scheduling To perform resource-aware placement of virtual nodes on EmulationServers, their resources are transformed into a score and shared with the Coordina-tor. This includes CPU (based on bogomips) and RAM. The NodePlacementScore works asfollows: nodes are placed on Emulation Servers based on the CPU score. RAM is onlyused to check that the amount of free memory is not exceeded on an Emulation Server.Otherwise, the number of VMs is reduced until the memory fits to the needs of theVMs. The RAM check is possible, since memory is limited for each VM.Bridged Backends The Bridged network backends use Iproute2 to set up GreTap tunnelssuch that nodes living on distinct Emulation Servers can be interconnected. Each tunnelrequires an ID for (de)multiplexing. To avoid distributed coordination of such IDs, apairing function is used to produce a unique ID from the two node IDs. Since GreTapdevices are represented by a NIC on both sides of a connection, tunnels can be handledthe same way as in the centralized mode.Communication The central Coordinator distributes the distance matrix either via theRequest-Reply or the Publish-Subscribe pattern among the Emulation Servers. After eachstep, Emulation Servers are synced via the Request-Reply pattern. All Emulation Serverssubscribe to an extra channel such that a reset can be triggered at any time. The channelis implemented using the Publish-Subscribe pattern.4.2.5 Experimental EvaluationThis section presents a performance evaluation of MiniWorld itself. In all experimentsin this section, the presented values are averages of 10 repeated measurements.Centralized ModeThe experiments in MiniWorld\u2019s centralized mode are performed on a shared-memorymulti-core computer. It has 16 physical CPU cores and 64 virtual cores, and 256 GiBof RAM. In the experiments, iproute2 version 4.2.027 and QEMU version 2.6.0 are used.The used VMs are: OpenWrt Barrier Braker (OpenWrtBB; size: 68 MiB) that has beencompiled manually, and Debian 8 (Debian8; size: 1,568 MiB) that has been installedfrom a netinstall image with the options SSH Server and Standard System Utilities. TheOpenWrtBB VM needs only 10 MiB of memory after boot, whereas the Debian8 VMrequires 78 MiB of RAM.VM Image Boot Times The boot times of QEMU VMs in MiniWorld are evaluatedbelow.27https://kernel.googlesource.com/pub/scm/linux/kernel/git/shemminger/iproute2414 Disruption-tolerant Device-to-Device Emergency Communication1 2 4 8 16 32 64 128 256 512#Nodes01248163264128Time (s)OpenWrt BB +RDDebian 8 +RDOpenWrt BBDebian 8Figure 4.5: Boot Times: OpenWrtBB vs. Debian8 (Shell Prompt)1 2 4 8 16 32 64 128 256 512#Nodes01248163264128Time (s)Snapshot BootReal BootFigure 4.6: Boot Times: Snapshot Boot vs. Real Boot (Debian8)Image Comparison Figure 4.5 shows the required boot times for both images, con-sidering that the Debian8 VM is equipped with 256 MiB of RAM instead of 32 MiBfor OpenWrtBB. OpenWrtBB is approximately twice as fast as Debian8. Since the ShellPrompt boot mode is used, the VMs may not boot fully, but offer a shell prompt. Theuse of a RD reduces the boot times only slightly. Moreover, doubling the number ofVMs by factor 64 (i.e., the number of virtual CPU cores) doubles the start times for eachimage. Therefore, MiniWorld scales linearly.Snapshot Boot VM snapshots can be used to improve VM boot times. Snapshots aretaken after the VM has been started the first time. Figure 4.6 shows the improvementsof the boot times achieved by Snapshot Boot. Even for 512 VMs, only a few seconds arerequired to restore the state of the VM (6.8 seconds). A full boot requires 143.3 seconds,hence the node start times are reduced by a factor of 21.Network Backends The three network backends are evaluated in terms of bandwidthand RTTs below. In addition, the topology switching times are measured.424.2 MiniWorld - An Emulation-based Evaluation EnvironmentVDEBridged LANBridged WiFiBackends3264128256512102420484096Bandwidth (Mbps)Figure 4.7: Network Backend Throughput0 50 100 150 200 2500.00.20.40.60.81.01.21.4VDE0 50 100 150 200 250Bridged LAN0 50 100 150 200 250Time (s)RTT (ms)Bridged WiFiAvg MinAvg StdAvg MeanAvg MaxRTT / Std RTTFigure 4.8: RTTs for the Network BackendsBandwidth To measure bandwidth, two VMs and iperf are used. All VMs are startedwith 1024 MiB RAM and the virtio-net-pci QEMU NIC Model. Moreover, each VM getsa single CPU core. The results are shown in Figure 4.7. The VDE network backendprovides an average bandwidth of 55.7 Mbps. The Bridged network backends differ onlyslightly from each other: Bridged LAN provides a bandwidth of 5848.5 Mbps, whileBridged WiFi offers 5867.6 Mbps of bandwidth, i.e., ebtables does not seem to reducebandwidth.Round Trip Times Figure 4.8 shows the results for the RTTs, gathered by the pingcommand over 240 seconds. All three subplots share the same x and y axis. The red lineshows the average maximum delays (Avg Max) for 10 trials. With slightly more than1.4 ms, the Avg Max (red line) is the highest for VDE. The Bridged network backendsprovide the same delay characteristics, since both use Linux bridges. The Avg Mean(yellow line) of both is less than 0.4 ms. The highest Avg Mean value results from theVDE network backend (approximately 0.8 ms), most likely since the number of ports isquite high for the VDESwitches by default (65537). To summarize, all network backendsprovide good RTTs values.Topology Switching Mobile nodes change their positions frequently, hence switchingbetween different topologies needs to be fast. The following experiment investigatestopology switching of the Bridged network backends, because VDE did not showsatisfactory results and thus cannot be used for wireless network emulation. Figure 4.9shows the results of switching between 4 topologies, each consisting of 128 nodes:434 Disruption-tolerant Device-to-Device Emergency CommunicationChain 128Cycle 128Wheel 128Grid 128Chain 128Topology012345Time (s)Differential Differential +NSFullFull +NSFigure 4.9: Topology Switching (Bridged WiFi)Chain 128, Cycle 128, Wheel 128, and Grid 128. The first two bars of each topologyshow the Differential Topology Switching capability, since only the differences betweentopologies are changed. For example, switching between Chain 128 and Cycle 128requires less than a second (red bar at Cycle 128) since the Step Time of the RunLoopis 1 second by default. Therefore, each step takes at least one second. The DifferentialTopology Switching feature is provided by the Network Manager and hence every networkbackend benefits from it automatically. The values of the green and blue lines havebeen created by defining the appropriate topology as the only one in the Scenario Config.Therefore, no Differential Topology Switching can be performed. In all topology switchingcases depicted in Figure 4.9, Differential Topology Switching is faster than Full TopologySwitching. The used network backend is the Bridged WiFi network backend. Moreover,Figure 4.9 illustrates that Network Supervision increases switching times since NICs needto be configured in terms of IP addresses, and the network connectivity needs to bechecked with the ping command. Since Network Checking (NC) is an important featureto ensure that a network topology has been switched correctly, the additional times canbe neglected.Distributed ModeIn the following experiments, the distributed mode of MiniWorld is evaluated using 6Emulation Servers and one Coordinator. Each of the 6 computers has a Core i7 processorwith 4 physical and 8 virtual cores. Hence, 8 QEMU processes are started in parallel.Moreover, it has 32 GiB of memory and a Gigabit Ethernet card.VM Boot Times To demonstrate MiniWorld\u2019s resource-aware virtual node placementon the 6 Emulation Servers, 300 OpenWrtBB nodes are started by n servers where n isincreased by 1 until all 6 servers take part in the distributed emulation. The boot times(Selectors Boot Prompt) are shown in Figure 4.10. The start of 300 virtual nodes with asingle Emulation Server takes 435.8 seconds. Doubling the number of servers reduces theboot times to 218.9 seconds (factor 2). With a total of 6 servers, the boot times could belowered to 81.5 seconds. Hence, the total boot times could be reduced by a factor of 5.3.444.2 MiniWorld - An Emulation-based Evaluation Environment1 2 3 4 5 6#Emulation Servers50100150200250300350400450Time (s)Figure 4.10: Distributed Mode: Boot Times (300 OpenWrtBB Nodes, 128 MB RAM, Selectors Boot Prompt)1 2 3 4 5 6#Emulation Servers0123456Time (s)Chain 300Cycle 300Wheel 300Grid 300Chain 300Figure 4.11: Distributed Mode: Differential Topology Switching (300 OpenWrtBB Nodes, Fixed-RangeModel, Bridged WiFi Network Backend, No Link Quality Impairment)Topology Switching The topology switching times of the distributed mode are shownin Figure 4.11. 6 servers are used to run 300 OpenWrtBB nodes with the Bridged WiFinetwork backend and the Fixed-Range model without any link impairments. Creatingthe Chain 300 topology is very fast, taking less than 2 seconds. Adding only a singleadditional link (Cycle 300) can be handled efficiently by any number of Emulation Servers.Switching to Wheel 300 takes the longest time. Figure 4.11 indicates that there is nearlyno communication overhead. Therefore, the topology switching times in the distributedmode are approximately as fast in the centralized mode, since the number of connectionsto switch stay the same. One disadvantage of the distributed mode is that the slowestEmulation Server dictates the time required for a single step, since Emulation Servers aresynced after each step.Tunnel Delays Tunnels introduce overhead, since frames need to be encapsulated bya PDU. For Gretap, each frame is wrapped into an IP packet. The following experimentexamines the overhead posed by tunnels on bandwidth and delay. A Chain 6 topologyis used, delay is measured with the ping command, and bandwidth is measured withiperf. A connection from node 1 to node 6 is established and data is recorded during454 Disruption-tolerant Device-to-Device Emergency CommunicationLocal Chain 6 Distributed Chain 6500.01000.01500.02000.0Bandwidth (Mbps)1.02.03.04.05.06.07.0RTT (s)Figure 4.12: Distributed Mode: Tunnel Overhead (6 OpenWrtBB Nodes, Fixed-Range Model, Bridged WiFiNetwork Backend, No Link Quality Impairment)240 seconds. Figure 4.12 shows the results. IP routing is set up along the Chain topology.For x = 1, all nodes are placed on one Emulation Server only. Hence, no tunnels areused at all. The examined average bandwidth is 1804.6 Mbps. The average delay is3.1 ms. If the Chain 6 topology is distributed among all clients (x = 6, one node perEmulation Server), the bandwidth reduces to 866.0 Mbps and the RTT increases to 5.7ms. The lowered bandwidth can be explained by routing the traffic through 5 nodesand 5 tunnels on 6 different Emulation Servers. Even in this worst-case scenario, thedistributed mode still provides sufficient bandwidth and good delay characteristics.4.2.6 ConclusionIn this section, MiniWorld, a novel distributed network emulation framework, waspresented. It relies on full virtualization using QEMU/KVM, offers three networkbackends for emulating both wired and wireless communication, and provides fourmobility patterns as well as three distance-based link quality models. A novel snapshotboot mode is offered for accelerated booting of identical environments and repeatingemulation runs. Connection tracking, address configuration, and network supervisionfeatures are provided for each network backend automatically. To decrease runtimes,MiniWorld supports distributed emulation across multiple computers, based on aresource-aware virtual machine scheduler. Experimental results have demonstrated464.2 MiniWorld - An Emulation-based Evaluation Environmentthe performance of MiniWorld with respect to VM boot times, network bandwidth,round trip times, and topology switching times, both for MiniWorld\u2019s centralized andthe distributed emulation mode.There are several areas for future work, such as (a) providing virtual WiFi deviceswithin QEMU instead of Ethernet devices as pseudo-wireless links, (b) developingmore sophisticated models for node mobility and link quality computation, e.g., byintegrating the ns-3 simulator to support high-fidelity link emulation and by adaptingthe link quality depending on the used wireless interfaces, (c) investigating whetherSDN switches are alternatives to Linux bridges, e.g., to provide event-driven andtrace-based link impairment scenarios, and (d) integrating the QEMU-based Androidemulator into MiniWorld, e.g., to use geographic coordinates to emulate node mobilityand to evaluate location-aware Android apps.474 Disruption-tolerant Device-to-Device Emergency Communication4.3 Serval - A Robust Communication Foundation4.3.1 IntroductionThe Serval Project\u2019s [26]\u2013[29] objective is to allow people to use mobile telephonehandsets to communicate anywhere, anytime [28]. The project seeks to achieve thisby creating protocols, writing software, including mobile apps, and creating comple-mentary hardware devices that, together, are able to replicate many of the functionsof a conventional cellular network to some degree (see Sec. 2.1.3). The goal is notthe replacement of cellular networks, but rather provisioning the best possible set offunctionality and quality of service that is feasible, without requiring any conventionalinfrastructure.Currently, pilots are being planned in the Pacific region and in Outback Australia overthe coming months. The pacific trials that are sponsored by the Pacific HumanitarianChallenge28 in particular will involve the provision of Serval technology to the generalpublic in regions that are particularly vulnerable to natural disasters. It is thereforeimperative that the behavior of the technology be sufficiently characterized, so thatinformed decisions can be made, and where any current deficiencies might exist, thatthey can be identified, and thus be scheduled for remediation.In this section, an in-depth experimental evaluation is presented of the delay-tolerantnetworking (DTN) aspects of the Serval software stack for various network setupsand usage patterns, including simulated long term use. The evaluation is based onthe simulation and emulation environment called MiniWorld (Sec 4.2) to provideinsights into the scenarios where Serval can be deployed with satisfactory qualityand performance characteristics, without requiring the expense and complication ofdeploying large and potentially costly physical test networks. Since battery capacityis limited on mobile phones, a closer look at the battery drain from using Serval overvarious communication links, such as WiFi and Bluetooth is taken. The contributions ofthis research are:\u2022 Evaluation using a hybrid simulation and emulation environment that allowsus to run real OpenWRT29 firmware images in an emulator, in contrast to meresimulations where only the DTN protocol can be tested.\u2022 Various network topologies, ranging from many 1-hop neighbors and a 64-hopchain to more realistic merging islands connection schemes are evaluated.\u2022 Several test cases mimicking common functionality, such as file distribution,messaging and peer discovery, and typical user behavior, such as rapid bulkinsertion of content, writing periodic text messages, and adding different types ofcontent every now and then, are considered.\u2022 Different file sizes are examined to reflect different patterns of mobile phoneusage, such as sharing text files (GPX data, ebooks, messages), images (map tiles,pictures), voice and video recordings (eye-witness video footage, voice memos,diaries).\u2022 All test data, scripts and topologies are freely available and can be adapted to testother software30.28http://pacifichumanitarianchallenge.org/29https://openwrt.org/30https://github.com/umr-ds/484.3 Serval - A Robust Communication FoundationParts of this section have been published in [2].4.3.2 Related WorkThere exists a wide range of related work addressing emergency communications needsand solutions, beyond what is possible to cover in this work [49]. Nonetheless, manyof the solutions in this space can be classified according to (1) the communicationsmedium/media and modulation(s); and (2) the architectural model(s) used by eachsolution.Communications media include WiFi, Bluetooth, WiMAX, GSM, TETRA digital radio,and various analog two-way and digital microwave, UHF, VHF and HF radio systems,as well as wired analog or digital systems, and satellite based systems, all availablefrom various commercial vendors.The architectural models can be often classified as either infrastructure-oriented,distributed (including peer-to-peer ad-hoc systems), or hybrid architectures of bothapproaches.Several systems support multiple transport modalities. WISECOM [50], for example,is an infrastructure-oriented system that seeks to provide a comprehensive approach topost-disaster communications, using satellite for global connectivity and a wide rangeof media and modulations. A significant challenge with such systems is their overallcomplexity, and their dependence on a sophisticated Internet-side infrastructure.Distinct from the transport media, considerable work has been done on designingnetwork protocols and frameworks for emergency communications using variousselections of the media and modulations listed above [51]\u2013[53]. A resulting problem inthis diversity is that interoperability can be a signifcant challenge and requires ongoingeffort to contain and improve this situation [54], [55].Mobile applications are also becoming more prominent in the emergency commu-nications space [26], due to the increasing capability of modern smartphones. Severalsystems also employ DTN principles to mitigate the challenges that arise when formingnetworks from end-user devices, and without adequate supporting infrastructure [56].Such systems are particularly relevant, due of their ability to operate when faced withthe failure of infrastructure, which is a common feature in disasters and emergencies[49].For example, FireChat31 is a DTN system for sending messages, but it lacks openness.Other DTN systems such as SPAN [57] and Briar32 only support specific target operatingsystems such as Android, and SPAN does not provide applications built on top of it.Furthermore, Forban33 can spread files opportunistically in a DTN manner, but lacksprotocol support for direct private file transfers, messaging or routing.Liu et al. [58] have developed a DTN based mobile microblogging app for censorshipresistant communication. Their focus is on the app\u2019s energy consumption in an 802.11ad-hoc network, ignoring other means of communication such as Bluetooth or WiFiin AP mode and limiting the system to specific rooted Android devices in ad-hocnetworking mode. Also, there is no support for sending large files, such as videos.Ntareme et al. [59] have presented an approach based on Android phones using a31https://www.opengarden.com/firechat.html32https://briarproject.org/33http://www.foo.be/forban/494 Disruption-tolerant Device-to-Device Emergency Communicationstore-and-forward architecture. Services such as email are transparently delivered viaDTN, but the solution requires special server software in addition to the Android app.Energy and bandwidth consumption were measured, but scalability and performancein different scenarios were not evaluated.Heimerl et al. [60] attempt to solve the problem of poor cellular coverage and poweroutages in rural areas by using low-cost GSM hardware and a system for reducedpower consumption. While this approach is interesting for feature phones and servicessuch as voice calls and text messages, it still requires infrastructure to function.4.3.3 Experimental EvaluationIn this subsection, the details of the evaluation setup are described including theselected network topologies and tasks. Afterwards, the results of our evaluation arepresented.Experimental SetupThe experimental setup for the in-depth evaluation of Serval, including the hard-/software environment used, the parameters measured, the network topologies chosen,and communication scenarios, is presented below.Simulation/Emulation Environment To evaluate the performance in a realistic man-ner, the MiniWorld network emulator presented in Section 4.2 is used. This gives us theopportunity to use the OpenWRT build chain for building router images that includeServal. OpenWRT is also used on real world routers such as TP-Link MR3020 or theMesh Extenders of the Serval Project. Having a full operating system with its ownnetwork stack running on each node gives a much better picture of real life performancethan pure protocol simulation.All tests are performed on a 64 core AMD Opteron 6376 CPU with 256 GB RAM,simulating up to 100 virtual nodes, each one with 512 MB RAM and 2 GB of storagespace. These quite limited values allow us to investigate how Serval performs on oldersmartphones like the original Samsung Galaxy S or similar, which are common indeveloping countries.Measurements Standard Unix tools are used to measure system properties, with ameasuring interval of one second. For memory consumption, CPU and I/O usagepidstat34 is used to monitor the statistics of the Serval process from within a node. Diskspace is measured with du and df, both from the GNU coreutils35. Network usage ismeasured on the MiniWorld bridge interfaces of the host system using a custom Pythontool36 based on libpcap37. Insertion points in time for the Rhizome store are deriveddirectly from Serval\u2019s log, while the general file count is logged using direct servaldcalls.34http://sebastien.godard.pagesperso-orange.fr35http://www.gnu.org/s/coreutils/36https://github.com/umr-ds/serval-tests/blob/master/netmon.py37http://www.tcpdump.org504.3 Serval - A Robust Communication FoundationTable 4.1: Network TopologiesName # Nodes DescriptionHub 48 All nodes connected to each otherChained 64 Pair-wise connectedIslands 100 Partitioned islands, merging over timeNetwork Topologies Several network topologies are studied, as shown in Table 4.1.The Hub topology connects 48 nodes with each other. It represents a scenario with ahigh number of direct neighbors all using bandwidth, flooding each other with statusinformation and new files, sharing the same transport channel. Typically, the numberof direct neighbors is limited by the radio range of WiFi or Bluetooth (i.e., often lessthan 48). Thus, Hub is challenging for Serval and also the radio link itself.The Chained topology consists of a chain of 64 nodes, thus the last node is 63 hopsaway from the first node. Typically, network connections over the Internet require lessthan 16 hops. In a delay-tolerant mobile mesh network, more hops might be needed formessages to reach their destination compared to static networks physically optimizedfor minimum hop numbers and maximum throughput.The Islands topology represents a partitioned network that slowly merges over time.At the beginning, there are 100 nodes in small islands with only a few neighbors.Between these small islands there are no links, but after a predefined time a few ofthem merge together, exchanging all their information that they have collected so far.Finally, there are two big islands where one node acts as a bridge between the two, andall accumulated data from one island has to pass through this node to propagate to theother island.All topologies are used in two configurations, one modeled after the common 802.11gstandard with a 54 Mbit/s limit on each link and one with no bandwidth limitations.Scenario Tests Based on these topologies, several tests were designed, as shown inTable 4.2.Idle (I) simply starts Serval and waits until all nodes have found each other. This testserves to evaluate how long the discovery phase takes in various network setups andhow much traffic Serval produces while idling.Mass Files (MF) pre-generates a number of files and inserts them at one specificnode. The goal is to evaluate whether Serval can handle a large number of files atonce. Propagation through the network is observed to reveal problems related to highbandwidth, storage and/or CPU usage.Mass Messages (MM) is designed to test the messaging subsystem of Serval by floodingthe network with text messages. A number of messages is sent at once to every singlenode in the network no matter if it is currently reachable or not.Periodic Files (PF) is designed to observe the long-term behavior of the system. Filesare added at random points in time by every node. A real world analogy is: peopletaking pictures occasionally and sharing them with everybody else.Periodic Private Files (PPF) is a special case of PF where files are not shared with thepublic but sent to a randomly chosen recipient.514 Disruption-tolerant Device-to-Device Emergency CommunicationTable 4.2: Scenario TestsName Short DescriptionIdle I Node discovery, no actions triggeredMass Files MF Insert bulk of file set at onceMass Messages MM Insert bulk of messages at oncePeriodic Files PF Periodic adding of filesPeriodic Private Files PPF Periodic adding of private filesPeriodic Messages PM Periodic sending of messagesCombined C All periodic tests togetherTable 4.3: Test File SetsName Sizes DescriptionSmall 64K, 256K, 512K Small pictures, map data, text filesMedium 1M, 5M, 10M Camera pictures, audio recordingsLarge 25M, 50M, 100M Recorded videoMixed all of the above -Periodic Messages (PM) is designed to evaluate the Serval messaging subsystem. Thesemessages are also directed to a specific recipient and are not meant for the public.Combined (C) is designed to run all periodic tests (PF, PPF, PM) at once. Similar toreal life situations, the nodes change their behavior and there is a competition for theresources in the network. Broadcasting files, sending files to \u201cfriends\u201d and writing textmessages all have different requirements.Data Sent Text messages consist of a fixed string plus a timestamp in millisecondswhen a message was sent. Since these messages are meant to mimic real world chat, thetotal string length is kept small (53 characters). According to a chat study of Battestiniet al. [61], text messages sent by males had an average length of 47 characters and forfemales 58 characters.Files have different file sizes representing different types of data, as shown in Table 4.3.The Small file set contains randomly generated files ranging from 64 KB to 512 KB; largetext files, ebooks, small pictures or other data such as map tiles typically have thesesizes. In the Medium file set we have files between 1 MB and 10 MB, which is nowadaysthe size of pictures taken with mobile phones or some audio recordings. Recordedvideo or software bundles are represented in the Large file set and are generated in therange from 25 MB to 100 MB. Finally, there is a Mixed file set where small, medium andlarge files are included.Test Execution All file related tests were performed with all four file sets, every testwas executed on all topologies with limited and unlimited bandwidth resulting in a524.3 Serval - A Robust Communication Foundationtotal of 114 tests. While some tests (e.g., MF) are count-based and terminate after everynode has received a specific number of files, other tests (e.g., PPF) are time-based -always running for the same duration. Each test was performed 5 times, resulting in atotal of 570 test runs.Experimental ResultsIn the following, various results regarding Serval\u2019s behavior during the experimentsare presented.Idle Behaviour To investigate the idle behavior of Serval, we looked at network traffic,CPU load and memory usage after the initial discovery phase, without triggeringfurther actions. In every scenario, whenever Serval is started, there are peaks in thenetwork load, in the Chained and Hub topologies at approximately 10 to 12 Mbit/s. Afterthis peak, Chained has a summed average network traffic of around 0.7 Mbit/s, whereasthe nodes in Hub produce 6 Mbit/s. This behavior is caused by Serval\u2019s informationdistribution strategy, because it announces status information, such as the list of filesin Rhizome, periodically via broadcasts. Since there are 47 neighbours for each node,traffic is relatively high in the Hub topology. Islands has extrema whenever partitionsmerge. The traffic during peaks grows with the number of nodes.CPU usage of the Serval process correlates with network load in our scenarios, butnever gets larger than two percent per node. Serval uses around 4 MB of memory in allscenarios.Moreover, the discovery time of each topology is different. For Hub, the averagetime of a full network discovery is approximately 5 seconds, since every node has adirect connection to all others. In contrast, the Chained topology takes about 20 seconds,because announcements have to be forwarded through all other nodes.In some experiments, Serval\u2019s address abbreviation (Sec. 2.1.3) mechanism causedconflicts under special circumstances, depending on the keys and when different nodesannounce themselves for the first time. If a node already has seen another node withthe same abbreviated address, it is ignored, potentially causing a partitioning of thenetwork. To circumvent such effects, we modified Serval to generate unique prefixesfor the desired node number in our tests.Hub Constraints For Hub, a single bridge interface was used to connect all nodes.Since each node is a single hop away from all other nodes and Serval uses broadcastpackets to announce meta-data (e.g., the files of a node), each node is flooding allneighbors with this information. Since the number of adjacent nodes affect the CPUconsumption of the respective node, in the Hub topology the CPU usage is alwayshigher than in the corresponding test in Chained or Islands, due to the high number ofdirect neighbors.Topology Characteristics Fig. 4.13 shows Mass Files tests with a Mixed file set indifferent topologies. It shows how transfer rate in Mbit/s, size of the Rhizome databaseand the CPU usage change over time. The transfer rate is stacked for all links. TheRhizome size is the stacked database sizes of all nodes.534 Disruption-tolerant Device-to-Device Emergency Communication(a) Chained limited (b) Hub limited (c) Islands limitedFigure 4.13: MF Mixed: Rhizome store size, network and CPU loadFig. 4.13a shows a limited (802.11g) Chained topology, in which five phases are visible,caused by the Rhizome prioritization based on file sizes. Small files are delivered firstand therefore can be distributed earlier by the following nodes. The bigger the filesget, the less total network utilization is achieved. Despite this effect, a constant stabledata flow is visible, and the Rhizome store grows constantly. The maximum CPU loadcorrelates with network usage, since the most active network nodes do have the highestCPU usage.In Fig. 4.13b, a limited Hub topology is shown. Though a constant 54 Mbit/s data flowis visible, the spikes exceeding 54 Mbit/s are measurement errors, caused by differingnetwork backend and traffic monitoring timers. With a constant network load causedby the file transfers, the disk usage also grows linearly as expected in this case, meaningthat the network load is not dominated by status and management information but realcontent distribution. Compared to Fig. 4.13a the average CPU usage is about 10 timeshigher, as explained in Sec. 4.3.3.For Islands, CPU usage increases every time the network changes. Looking at PeriodicFiles tests, the max. CPU load rises to 15% when large files are inserted, since theyhave to be redistributed among the other nodes. Fig. 4.13c shows the Mixed file setin MF, which peaks at around 7% CPU load. Since many of the files already exist onvarious nodes, every time new network connections are set up, the impact on the CPUis relatively low compared to Hub. In general, smaller files have a negligible impact onthe CPU.The Periodic File tests with small sizes do not show any unexpected behavior interms of CPU consumption in Chained, the CPU peaks at about 10%. When the files areencrypted as in PPF, the CPU utilization is slightly higher, at about 15%, due to CPUintensive cryptographic operations.The file size influences CPU utilization, which greatly impacts the inserting node.For instance, when sending Small files in Chained, there is no significant change of CPUutilization compared to idling, whereas file set Large utilizes the CPU up to 35%. Biggerfiles lead to more time consuming hashing, as it is required by the correspondingprotocol. Thus, every node receiving the file needs to compute a hash, verify andredistribute it, which also leads to a higher load.In terms of CPU usage, Islands is a combination of Chained and Hub. CPU usage doesnot exceed 50%, since the total number of neighbors per node is not as high as in Hub.544.3 Serval - A Robust Communication FoundationFigure 4.14: MM CPU usage over time. Left: unlimited Chained, right: unlimited Hub.In the message based tests, the measured CPU consumption correlates with thenumber of messages sent. For MM, the behavior differs depending on the topologyused. Fig. 4.14 shows the CPU usage per node of two experiments over time. UsingChained, the inserting node peaks at 30% CPU load compared to the receiving nodes,which consume about 15%. Using Hub, the load of the inserting node remains the same.In contrast, the receiving nodes constantly consume about 65% CPU. Hub suffers fromthe broadcast overhead (Section 4.3.3), but this does not fully explain the high load, asthe sending node is not affected. Further investigating this behavior, it can be trackedback to recurring hashing and encryption in Rhizome Journal syncing, which is thecore of MeshMS messaging.PM results differ from MM. For Chained, the CPU utilization is relatively low at about15% maximum. This correlates with the CPU load of the non-inserting nodes in MM.Since they are added periodically, the CPU overhead is negligible here. Hub behavesdifferently than in the file based tests or MM: The PF tests show that in every topologythe more files are injected in the network, the more CPU is needed to handle thebroadcast packets. Messages are not announced further after reaching their destinationand being acknowledged by the recipient. The obvious consequence should be that theCPU usage decreases. However, as indicated by Fig. 4.15, once the CPU peaks at about25%, it does not settle any more, but increases even further, although the network loaddecreases to the idle level and the Rhizome database size is at its maximum, whichindicates that all messages have arrived. This behavior cannot be transferred to Islands,where the inserting nodes peak at about 40% and all other nodes do not exceed 15%.For C tests, the general CPU usage is similar to other file based tests. The onlydifference is the fact that in Chained and Hub the CPU usage increases by 5% after about500 seconds and also correlates with the network load, similar to the behavior depictedin Fig. 4.15. This problem emerges when sending messages over a longer time period.Since Islands is not in the final state at the beginning of the test in terms of the linksbetween the nodes, this result can not be observed in this particular topology.Network Performance One goal was to test to what extent Serval is able to useavailable bandwidth. Chained was created to assess this.The cumulative transfer rate using Rhizome in this topology reached 500 Mbit/s to2 Gbit/s, depending on the file sets, with Large being the fastest. That is, up to 2 Gbit/sof traffic was being carried over the set of hops in the chain, with each seeing an554 Disruption-tolerant Device-to-Device Emergency Communication0 100 200 300 400 500 600 700 800 900time (s)0510152025transfer rate (Mbit/s)0246810121416rhizome size (MiB)020406080100) max avgmincpu usage (%) - (Figure 4.15: Hub limited PM: Rhizome store size, network & CPUaverage utilization of 32 Mbit/s. Tests that transfer large files over an unlimited networkshow that Serval is able to use even more bandwidth, since the highest measuredtransmission speed from one node to another can be up to 160 Mbit/s.Using Chained, the hop-to-hop transmission time can be modeled, since node n isable to receive a file just after node n\u2212 1 received it. Fig. 4.16 shows the hop-to-hoptransmission times of the Medium file set. The five files of each size are grouped into onebox plot, while the colors present five different runs of each experiment. The mediantransmission times for 1, 5 and 10 MB files are 0.54, 1.06 and 1.85 seconds, and only 0.27sec for 64 KB files. From these values, a simple correlation for the transmission timecan be derived: T(sizeMB) = 0.16 \u00b7 size + 0.26, which also holds for the Large set. Theformula indicates a net transmission rate of around 31 Mbit/s, with a 0.26 sec delay.The average speeds are lower, because files are exchanged node-by-node, and canonly be spread to node n + 1 after reaching node n, resulting in an effective end-to-endbandwidth, for a given bundle, inversely proportional to the number of hops. Thiscompares favorably with end-to-end ad-hoc wireless routing protocols, where theeffective end-to-end bandwidth drops by approximately half for each additional hop.Briefly considering the different topologies, the network utilization in Islands for filebased tests is generally about the same as in Chained, since each node has only a fewneighbors, in contrast to Hub, which is always able to saturate all links due to the highdegree of connection among nodes.Messages in Serval are effectively transported as small files, with a payload size of 53bytes in both PM and MM cases. The network load shows a behavior similar to smallfiles in the PF test, peaking at up to 40 Mbit/s at all topologies and regardless if thenetwork is limited or not.The network load for C tests in all topologies is similar to the file based tests,independent of bandwidth limitations. The only difference is the increase of the network564.3 Serval - A Robust Communication Foundation1m1m1m1m1m5m5m5m5m5m10m10m10m10m10mfilesize0.1110100time (s)Figure 4.16: Chained limited Medium file set: File-size-grouped hop-to-hop delivery periods of five runs.load after about 500s on Chained and Hub, as shown in Section 4.3.3.In Hub, small files take between 1 and 4 min to arrive on the last node in thelimited network links. This increases linearly, up to 20 min, with increasing file size.If the network is unlimited, transmission time reduces to between 18 sec and 9 min,depending on the file size. One difference between Hub and Chained is the runtime.Small files are transmitted faster in Hub, whereas Large files are faster in Chained. Thetime overhead for file announcements is relatively higher for Small. Even with a lowertotal bandwidth (Hub: 54 Mbit/s for 48 nodes vs. Chained: 54 Mbit/s pairwise), Hub canachieve faster transmission rates. The limitation of network speed does not influencethis behavior, only the overall transmission time increases.The transfer times of messages differ from topology to topology. While it takes about350 sec in Chained until all messages arrive at their destinations, it can take up to 900 secin Hub. This again shows that the high number of 1-hop neighbors in Hub is challengingfor Serval. The transmission time for messages in the C tests depends highly on theused file set, rather than on the topology and network speed. The reason is that thenetwork is saturated with big files, which leads to overall higher transmission times formessages.Energy Consumption The Idle test in Section 4.3.3 showed network peaks caused byRhizome status information announcements. Therefore, the energy consumption of theannouncements is evaluated: Two devices send announcements in different intervals.Fig. 4.17 shows the energy consumption for peer A using different announcementintervals at peer A and peer B. With a 0.5 sec or 1 sec interval, the consumed energyis 9% higher than in idle state. With a 2 sec interval, the consumed energy is only3% higher than in idle state. With a higher interval of 4 sec or 8 sec, only negligibledecreases in energy can be achieved.Furthermore, the power consumption during MM and MF tests were evaluated. Twopeers were connected via an 802.11n WiFi Access Point. Peer A inserts files and messagesinto Rhizome in the same manner as MM and MF tests. The power consumption ofpeer B, a Raspberry Pi 3, is then measured with the Odroid Smart Power measurementdevice, an external power meter. The aim of these experiments is to measure the energyoverhead for running Serval on a device, which allows conclusions about the powerdrain of Serval on battery-powered devices.Fig. 4.18 shows the power consumption during different Rhizome file set insertions574 Disruption-tolerant Device-to-Device Emergency CommunicationNo Peer 0.5 1 2 4 8Announcement Interval Peer B (s)14001450150015501600165017001750Energy Consumption Peer A (Ws) Announcement Interval Peer A (s)0.5 1 2 4 8Figure 4.17: Energy consumption of announcement intervalssimilar to MF. The file sizes are increased during the phases f1-f4. During f1, the filesizes are smaller than 1 MB, resulting in a negligible additional power consumption.The bigger the transmitted files are, the more power is consumed. The comparisonbetween receiving files and sending files shows an unexpected behaviour: In all phasesf1-f4, sending files is less expensive compared to receiving files, on the average between0.05 and 0.1 W (3-6%). This counter-intuitive result is caused by additional CPUconsumption of the Rhizome checksum calculation during reception. Compared to a1.53 W mean idle value of peer B, the power overhead introduced by Serval is between0.01 and 0.13 W (1-8%) during phases f1-f4.In another experiment, the power consumption during different message insertionssimilar to the Mass Messages test was measured. The results show a power consumptionpeak between 1.81 and 1.91 W during a short period of reception, followed by a phaseof negligible additional power consumption. During the reception of 100 messages, amean value of 1.69 W (10%) additional power consumption is measured.A better energy efficiency during message transmission could be achieved by usingBluetooth. It consumes a significant amount of energy during device discovery, but hasa lower power consumption during data transmission than WiFi. Due to the low energyefficiency (joule per bit) of Bluetooth compared to WiFi, it consumes significantly moreenergy for large data transmissions. During an experiment, we measured a 32 timesbetter energy efficiency of WiFi compared to Bluetooth for files between 512 KB and 16MB.4.3.4 ConclusionIn this section, an in-depth experimental evaluation of the delay-tolerant aspects ofServal for various network setups and usage patterns was presented. The resultsshow satisfactory performance of Serval when deployed in partitioned scenarios andextreme examples of network topologies. Furthermore, Serval\u2019s energy consumptionwas evaluated, having the limited battery capacity of mobile devices in mind.In particular, the experiments indicate that there is a sweet-spot for the trade-offbetween up-to-dateness and energy consumption regarding announcement intervals.Furthermore, Serval can handle a realistic number of files over a longer time period.In the Chained topology, neither the CPU load nor the used network bandwidth leadsto out of service situations. All tests with the Hub topology show that in a highlyused network the announcements consume a considerable portion of the available584.3 Serval - A Robust Communication FoundationFigure 4.18: Power consumption during different Rhizome file set insertions (f1-f4) similar to the MassMessages test.bandwidth. In emergency situations or in long-term setups this could have a negativeeffect depending on the number of people in direct communication range. The Combinedtests in our Islands topology demonstrate that Serval works flawlessly in adapting toheterogeneous environments where users have different requirements at the same timeand the topology changes over time.There are several areas for future work. Mobility simulations should be carriedout, preferably with real world movement patterns gathered from past events. Morepowerful hardware with higher numbers of nodes should be used to run the simulationsand emulations, to further investigate Serval\u2019s scalability properties, particularly inhighly-connected topologies, like Hub. The defect that has been exposed in the addressabbreviation code should be rectified. An evaluation of Serval\u2019s non-DTN relatedfeatures, such as voice calls, could further increase the attractiveness of Serval as asolution for emergency or off-grid communication.594 Disruption-tolerant Device-to-Device Emergency Communication4.4 Optimizing Epidemic Announcements4.4.1 IntroductionAs shown in the previous section, several network protocols rely on nodes broadcastingannouncements to other nodes. Examples include service discovery (Bonjour/ZeroConf,Samba), routing algorithms (RIP, OLSR), and peer-to-peer or delay-tolerant networking(DTN) systems (Forban38, Serval39). While the traffic generated by periodically sendingannouncements might be negligible in wired networks with high-speed links, band-width in wireless networks, such as 802.11, Bluetooth or various mobile ad hoc networks(MANETs), is precious and limited. For example, spontaneous smartphone networksbecome more and more important not only by providing pervasive wireless Internetaccess during large human crowd gatherings, but also during emergency situations orpost-disaster recovery [62].Group 1 Group 2 Group 3Figure 4.19: Drive-by store-and-forward data exchange.s=77mr=40mv=50 km/hFigure 4.20: Drive-by window of opportunity example.In an emergency communication scenario, the main goal is to spread messages andfiles produced at a disaster site fast among reachable nodes. Therefore, data is passedaround in an epidemic fashion to as many neighboring peers as possible. Typically,some nodes are more static, such as devices of people trapped in their houses or smallemergency camp sites forming islands, while other nodes are on the move (by bike,car, foot), which by passing through these islands act as carrier-pigeons to distributeinformation further (see Fig. 4.19). These islands have a higher density than typicalsensor networks. To make optimal use of the short time in case of a drive-by, it isimportant to find a peer for data exchange very fast. Since any peer can initiate datasynchronization, a special treatment of mobility is not necessary. Depending on theused wireless technology, a mobile phone might have an effective range of 14-80 metersto communicate with others. Thus, if we assume a WiFi radius of 40 meters and astatic node being 10 meters away from a street, a car driving on the street would be38http://www.foo.be/forban/39http://www.servalproject.org/604.4 Optimizing Epidemic Announcementsin the WiFi range for about 77 meters (see Fig. 4.20). The car passing by, assuming itmoves at about 50 km/h, would have just under 6 seconds for node discovery andexchange of data. This is plenty of time for transferring, for example, two 6 megapixelpictures and setting up connections via a standard 54 Mbps link. Therefore, for the fastmoving node, one of the more static peers is sufficient to start a data transfer. Sinceall information gets replicated in this scenario, the fast moving node does not needto know all possible neighbors. The static node can distribute the data further amongits neighbors. Discovering all direct peers as fast as possible is neither necessary norbeneficial for the static nodes. Under these assumptions, it is reasonable to use dynamicannouncement intervals instead of the typically used static announcement intervals.Furthermore, dynamic announcement intervals require not only less network resources,but also potentially save more battery capacity than static announcement intervals.In this section, several approaches are presented to realize dynamic announcementstrategies that facilitate fast reception from at least one other node while trying to keepthe overall communication overhead as low as possible. Experimental results in termsof performance properties and energy consumption are given to illustrate the benefitsof dynamic announcement intervals in wireless on-demand networks. In particular, thissection makes the following contributions:\u2022 Various strategies for realizing dynamic announcement intervals optimized fordifferent network setups are presented.\u2022 An experimental evaluation of all proposed strategies, including static and ran-dom announcement strategies, with respect to bandwidth usage, announcementdistribution and energy consumption is presented.\u2022 Test environments suited for various topologies, such as large stable networks,islands merging and networks splitting, are investigated.\u2022 The results are directly applicable to local peer-to-peer content distribution sys-tems in emergency scenarios, such as Forban and Serval.Parts of this section have been published in [3].4.4.2 Related WorkThere are several publications that investigated problems associated with static an-nouncement intervals in various protocols and application scenarios.Natsheh et al. [63] proposed a solution based on fuzzy logic to optimize hellomessages in dynamic ad-hoc routing. Their work focused on the mesh routing use case,and experiments with a maximum of 35 simulated nodes were presented. Furthermore,Khalaf et al. [64] investigated the broadcast storm problem in mobile ad hoc networks.The authors presented a probabilistic approach to improve the situation in a meshrouting scenario.Ahmed et al. [65] addressed the problem of beaconing in vehicular ad hoc networks(VANETs). Combinations of controlling a beacon\u2019s transmission power, transmissionrate, and contention window at the MAC layer were proposed to achieve efficient beaconcommunication in VANETs. Another approach devoted to improve the problems relatedto static beaconing intervals in ad hoc networks was presented by Tahar et al. [66]. Hesset al. [67] investigated peer discovery in mobile opportunistic networks by consideringthe mobility of nodes.614 Disruption-tolerant Device-to-Device Emergency CommunicationPeng [68] proposed an adaptive mobility-aware MAC protocol for wireless sensornetworks. Apart from optimizing the number of messages, the energy consumptionwas investigated. Lim et al. [69] presented an approach called RandomCast to improvethe energy efficiency of 802.11 ad hoc networks. In this approach, the sender can specifythe desired level of overhearing of neighboring traffic, trying to find a balance betweenenergy consumption and routing performance.Using perfect difference sets for neighbor discovery, Link et al. [70] presented an en-ergy efficient approach for wireless networks. The authors focused on sensor networksand DTNs with sporadic communication, whereas we focus on networks with highercommunication frequencies in local clusters.Peer-to-peer content distribution is another scenario where announcements arerelevant, and a trade-off must be made between central tracker-based peer discoveryand distributed peer discovery. Da\u00b4n et al. [71] presented a hybrid approach that usesindividual trackers and a gossip protocol to improve peer discovery. By hoppingbetween swarms and redistributing known peers, efficiency is increased.Liu et al. [58] developed a censor-ship resistant delay-tolerant network for messageexchange and evaluated it with respect to performance and energy consumption.To avoid energy draining broadcasting with fixed intervals, the authors adopted anapproach presented by Zheng et al. [72] based on asynchronous wake-ups for adhoc networks. Another delay-tolerant networking system designed specifically fordata synchronization in emergency situations was presented by Paul et al. [73]. Whileoptimizations are proposed to speed up file transfers and syncing, the actual peerdiscovery was realized by simple broadcasts with fixed announcement intervals.During an experimental evaluation of Serval as a delay-tolerant emergency com-munication platform, Baumga\u00a8rtner et al. [2] (see also Section 4.3) found that regularbroadcasts used for node discovery or announcements of routing and data storage infor-mation especially in networks with many direct peers require high network bandwidth.The study showed that around 2 seconds of announcement delay was the best trade-offbetween quick peer discovery and conserving energy with the stock implementationmade available by the Serval Project.By exploiting social network characteristics for assisting ad hoc peer discovery, Zhanget al. [74] attempted to find optimal beacon probing rates with constant intervals foreach group of users. As stated by Wang et al. [75], peer discovery itself can be as energyconsuming as making phone calls.Trifunovic et al. [76] presented a solution for opportunistic networks of stock mobiledevices using 802.11. Since ad hoc mode and Bluetooth pairing does not really workin practice on current mobile devices, open access points and intelligent switching ofclients between these access points were used.While most of the mentioned work is highly specific to the studied use cases, thegeneral picture is that adaptive or dynamic announcement intervals usually outperformstatic ones, not only with respect to network performance, but also regarding energyconsumption. In this scenario, a small dense clusters of nodes is considered, where afew nodes act as mobile bridges between these islands, in contrast to most sparse sensornetworks. Furthermore, most approaches focus on lower layer technologies, whereasthese algorithms here can be applied on the application layer without operating systemsupport.624.4 Optimizing Epidemic Announcements4.4.3 DesignDynamic Announcement IntervalsIn this section, several dynamic announcement strategies, the constraints associatedwith them, and quality properties to evaluate their performance are presented.Announcement StrategiesSeveral novel strategies for realizing dynamic announcement intervals have beendeveloped. Each strategy has access to the current announcement delay, the globalnumber of announcements seen at the last observation interval and the current numberof unique peers. The strategies are described in the following:Static The Static announcement strategy is the basic announcement approach usedby most current broadcast protocols. There is a fixed interval defined for every nodein which an announcement is sent. This also means that the generated global traffic isgrowing linearly with the node count. By default, this interval is set to a 2 second delayin our tests, which also is the recommended value for MANET NHDP [77].Random In the Random strategy, every node chooses a random announcement delay.This delay is a random number between a minimum and a maximum (as described inSection 4.4.3) for every observation interval. The distribution of the random numbers,depending on the network size, heavily influences the performance of this strategy, aswell as the duration of the observation interval.RandomSweet In this strategy, Random is extended. The announcement interval is onlyset randomly if the current global announcement rate is higher than one announcementper second or less than the minimum number of announcements per second (see Section4.4.3). Thus, if the network has reached a stable state, this strategy does not changeanything and sticks to the last randomized delay for each node. This stabilizes thenetwork if by chance optimal delay combinations are found, at least until nodes join orleave the network.Step After every observation interval, the Step strategy checks the global announce-ment count. If the count is higher than one announcement per second, the node\u2019sannouncement delay is increased by one second. If the count is lower than 0.5 an-nouncements per second, the node\u2019s announcement delay is decreased. This leads togradually narrowing down to a most suitable announcement delay over time.StepRand In this strategy, Step is extended by adding randomness to each step. Whilethe conditions remain the same as in Step, a random value between 0 and 0.5 secondsis added or subtracted to the announcement delay.MaxFirst MaxFirst is a rather defensive strategy: whenever a high global announce-ment rate is detected (more than one announcement per second), the node\u2019s announce-ment interval is set to the observation interval, i.e., the maximum possible announce-ment delay is tried first, hence the name. Then, if less than 0.5 global announcements634 Disruption-tolerant Device-to-Device Emergency Communicationper second are present, the strategy decreases the announcement delay by one secondper iteration, until the local minimum of 0.5 seconds is reached. Thus, a very low an-nouncement frequency is favored, which should be beneficial in larger or fast growingnetworks.MinFirst MinFirst reverses MaxFirst, and thus is an aggressive announcement strategy.Whenever less than 0.5 announcements per second are detected globally, the announce-ment delay is set to the local minimum of 0.5 seconds. Otherwise, the announcementdelay is increased by one second per iteration, until the observation interval is reached.This strategy supports scenarios where most of the time only very few peers are indirect vicinity of each other.Unsteady In the Unsteady strategy, each announcement delay is computed only onthe basis of the number of unique peers known by a node and not on the globalannouncement rate like in the other algorithms. The goal is to reach a global rate ofone announcement per second. Looking at the current peer count, an announcementinterval is computed to complement the announcement intervals of the other nodes.Using this method, the strategy should be able to adapt to new situations as fast asdefined by the observation interval.ConstraintsTo guarantee that a node can be discovered, an observation delay, with the same valuefor all nodes, is define. This is the time between re-evaluation and before anotherchange in the announcement frequency can happen. Each node has to announce itselfat least once per observation interval. All nodes must set the announcement delayafter the observation delay is over. This enables a better comparability between theannouncement strategies.The observation delay is set to 20 seconds in all experiments, since the baseline for staticannouncements is 2 seconds. Therefore, it is reasonable to re-evaluate the situation after10 standard announcements. The higher the delay, the longer it takes for the networkto adapt to new situations. A very short delay in conjunction with the premise thateach node should at least send one announcement per interval leads to higher loads,especially with higher node numbers. Thus, a delay of 20 seconds ensures that withinthis interval all peers in the direct neighborhood are discovered.Quality PropertiesTo evaluate and compare different strategies for dynamic announcement intervals,universally applicable quality properties must be defined. The main goal is to globallyhave one announcement per second at any given time, not less, but also not muchmore to conserve resources. This goal is motivated by the drive-by scenario describedin Section 4.4.1, in which 10% of the window of opportunity would be used for peerdiscovery under this assumption.Global Announcement Rate The Global Announcement Rate is measured by countingthe announcements per second. This parameter is the main optimization goal for thealgorithms, since it is directly correlated with the bandwidth used for peer discovery.644.4 Optimizing Epidemic AnnouncementsGlobal Announcement Gaps The Global Announcement Gaps are measured by the timeperiods between two announcements. The Global Announcement Gaps are important toobserve, since they reveal how long a new peer needs until it receives an announce-ment from the rest of the network. Although this value is roughly the inverse of theGlobal Announcement Rate, its distribution can reveal other aspects, as observed in ourexperiments.Adaptation Rate The Adaptation Rate represents the time needed for an announcementstrategy to adapt to a new situation. It describes the situation that all nodes are startedat the same time, and defines the moment when no significant change in the number ofannouncements is recognizable.4.4.4 ImplementationIn this section, implementation issues of the announcement strategies and the networkusing them are discussed.MesherTo investigate dynamic announcement intervals, a simple broadcast service was ex-tended to provide easily exchangeable announcement algorithms for peer discovery.Mesher40 is a simple local chat written in Google\u2019s Go language by me, and therefore iseasily extensible. It utilizes broadcast packets for neighbor discovery and for exchang-ing public chat messages. Mesher uses a static announcement interval of 2 secondsin its default configuration, and thus the network traffic is growing linearly with thenode count. Each announcement contains the elliptic curve public key of the sendingnode, the services provided by the node, 512 bytes random data to simulate databasestates and a cryptographic signature, resulting in 642 bytes per broadcast packet. Otherprotocols might use larger or smaller announcement packets, depending on the type ofstate that is broadcasted.Dynamic Interval ComputationTo evaluate various interval computation methods including dynamic changes, thecorresponding algorithms needed to be easily exchangeable. Therefore, the algorithmsare implemented using an embedded JavaScript engine, and an interface was defined tohand over useful information to access it in the main Go binary:\u2022 get_announce_count()\u2022 get_and_reset_announce_count()\u2022 get_peer_count()\u2022 get_announce_delay()After analyzing the provided values, the algorithms are able to set a new announcementinterval using set_announce_delay(Int).40https://github.com/gh0st42/mesher654 Disruption-tolerant Device-to-Device Emergency CommunicationAnnouncement Strategies in MesherFor all announcement strategies, the same template (see Listing 4.1) in JavaScript is usedwhere one specific function is responsible for computing any changes. Each strategygets the current announcement delay and the global number of announcements seen inthe last observation interval. This setup proved to be perfect for rapid prototyping ofnew algorithms without recompilation or modifications of the main binary.Listing 4.1: Basic layout of the announcement strategiesvar observation_interval = 20000;var total_count = 0;var min_delay = 500;set_announce_delay(2000);for (;;) {sleep(observation_interval );var cur_count = get_and_reset_announce_count ();var cur_delay = get_announce_delay ();// call scheduler and set new delay therescheduler(cur_count , cur_delay );}4.4.5 Experimental EvaluationIn this subsection, the announcement strategies described in Subsection 4.4.3 areevaluated using the network configurations described below in Subsection 4.4.5. Basedon the quality properties of Subsection 4.4.3, the strategies are compared to each other.To test the strategies, the centralized network configuration was evaluated withdifferent node counts. For each of the eight announcement strategies, the tests wereperformed using 2, 5, 10, 25, 50, 100 and 200 nodes, resulting in 56 configurations.These configurations were each executed using two nodes starting mechanisms: a) thebatch node start, in which all nodes were started randomly in the observation intervalwindow; b) the delayed node start, where a node was added every second, resulting ina linearly growing network.In addition, two dynamic network configurations were used: Split, where the centralnetwork was split in two halves, and Merge, where two equally sized networks werejoined. Summing up the different configurations, 224 independent experiments wereperformed.Evaluation SetupTo evaluate the announcement strategies, several setups were used, including emula-tions with many nodes as well as physical machines connected over various networklinks.664.4 Optimizing Epidemic AnnouncementsNetwork EmulationFor network emulation, the Common Open Research Emulator41 (CORE) was chosen,which is scriptable using Python and in this way allows versatile creation of experimentalconfigurations. This system uses Linux and lightweight virtualization to provide anetworking testbed for unmodified, regular Linux binaries. All announcement strategiesare evaluated under four different network scenarios described below:Centralized Network In the Centralized Network configuration, all nodes are connectedcentrally and hence are located in the same collision domain. This setup is similar toa classic network hub or a local ad hoc wireless network in the sense that each nodecan directly communicate with all of its adjacent peers. As long as the network is notoversaturated, every node gets the announcements of every other node.Growing Network In the Growing Network configuration, nodes are added periodicallyto the network. Ideally, the announcement strategies should adapt to the new situationfast and down-regulate their announcement counts. Each second, a new node joins thenetwork, and adaptation is required to maintain optimal resource usage.Merging Network In the Merging Network configuration, two equally sized CentralNetworks merge at a fixed point in time, doubling their size instantaneously. Using thisconfiguration, adaptation rates for abruptly changing network configurations can beobserved.Splitting Network In the Splitting Network configuration, the network is split in twohalves at a fixed point in time. By creating two independent networks, the announce-ment strategies need to react fast to satisfy the defined quality properties and avoidprolonged periods of silence between announcements.41http://www.nrl.navy.mil/itd/ncs/products/core674 Disruption-tolerant Device-to-Device Emergency Communication0 50 100 150 200 250time (s)02468101214announces / secondMaxFirst-n025MinFirst-n025Random-n025RandomSweet-n025Static-n025Step-n025StepRand-n025Unsteady-n025Figure 4.21: Announcements/second in a static network of 25 nodes.Physical TestbedTo evaluate the proposed announcement strategies under realistic conditions, a physicaltestbed was created. It consists of several Raspberry Pi 3 Model B42 single-board com-puters, running under the vendor-provided Debian-Linux-based Raspbian43 operatingsystem. This platform is comparable to mobile phones in terms of energy consumptionand therefore allows one to obtain realistic energy and power consumption measure-ments when evaluating the announcement strategies.Eight Raspberry Pis were setup up as network participants, as well as an additionalRaspberry Pi as a system under test (SUT). The energy consumption of the SUT wasmeasured using an Odroid Smart Power measurement device, an external power meter.The data points were logged at 5 Hz to another device, in order to prevent disruptionof the measurement.Basic CapabilitiesIn Fig. 4.21, the announcement rate for all strategies in a static network with 25 nodesis visualized. The strategies share the same observation interval, and therefore the first20 seconds are the same, since they also start with the same announcement interval of2 seconds. The Static strategy preserves this announcement interval, and the globallygenerated traffic remains the same for the whole experiment.Unsteady and MaxFirst show very low announcement rates in this network config-uration. Unsteady uses the node count (see Sec. 4.4.3) and computes its maximum42https://www.raspberrypi.org/products/raspberry-pi-3-model-b/43https://www.raspbian.org684.4 Optimizing Epidemic Announcements100101102announces / second(a) MaxFirst (b) MinFirst (c) Random (d) RandomSweet0 50 100 150 200 250time (s)100101102announces / second n002n005n010n025n050n100n200(e) Static0 50 100 150 200 250time (s)(f) Step0 50 100 150 200 250time (s)(g) StepRand0 50 100 150 200 250time (s)(h) UnsteadyFigure 4.22: Comparison: announcements produced by the proposed strategies in different static networkconfigurations.announcement delay, which in this case is greater than the observation delay and setsthis maximum. Because the observed announcement count is high, MaxFirst jumpsto the maximum possible announcement delay. Since the situation does not change,both algorithms stick to their decision in future observations. This similarity changesfor lower node counts. Considering Figure 4.22a, MaxFirst sets the same very low an-nouncement rates in the beginning, which leads to low global announcement rates andfinally to big gaps between each two announcements. Unsteady (Fig. 4.22h) compensatesthis problem and starts with higher announcement rates in smaller networks.MinFirst and Step also behave similarly, since the down steps are implemented thesame way. Both algorithms extend their announcement delay by 1 second, starting at adelay of 2 seconds. StepAndRand also is in the same group and only differs from Step byadding a random value with a maximum of 0.5 seconds. All three algorithms achievethe goal of a less saturated network and also approach the same minimum as MaxFirstand Unsteady.In this network configuration, RandomSweet as well as Random show a similar behavior.The announcement rate drops directly after the initial observation, but stays higherthan for the other strategies that achieve a low announce rate after around 200 seconds.To get similar results as, for example, MaxFirst, all nodes would need to pick a prettyhigh delay by chance, and the more nodes in the network, the more unlikely it is thatall nodes do this in the same observation interval.Bandwidth SavingsA major goal for using dynamic announce intervals is the reduction of bandwidth insuch protocols. Table 4.4 shows the announcement rates of the proposed strategiescompared to the static announcement strategy. For this table, the announcements sentby one node in the batch node start is used. This number also includes the observationdelay in which all strategies follow the static behavior.All non-static strategies converge for growing node counts. Step, StepRand andMinFirst use around a third of the number of announcements compared to Static.694 Disruption-tolerant Device-to-Device Emergency CommunicationTable 4.4: Announcements of the strategies compared.Name# Nodes2 5 10 25 50Static 291 732 1460 3658 7296Random 34,4% 47,0% 37,0% 37,9% 37,3%RandSweet 58,1% 41,7% 29,0% 35,6% 37,7%Step 101,7% 45,4% 35,2% 33,2% 33,4%StepRand 99,7% 42,5% 32,5% 30,1% 30,2%MaxFirst 99,0% 21,2% 17,1% 17,0% 17,1%MinFirst 84,9% 44,3% 34,7% 33,3% 33,5%Unsteady 188,7% 56,8% 32,5% 17,7% 17,1%MaxFirst and Unsteady take advantage of their fast adaptation rate and are able to savearound 80% of the announcements. This means that only one fifth of the bandwidth isused without sacrificing any comfort or usability of the protocol.Table 4.4 also shows that the proposed strategies benefit the most from their dynamicbehavior for networks with 2 to 10 nodes. After that, only minor improvements canbe achieved. The announcement rate of Static can be altered easily by hand and couldtherefore also reach the goal of a lower global announcement rate for big networks,but would then lose the ability to perform good in small networks without manualinteraction on each node.Unsteady uses more bandwidth than Static for a minimal network. This allows fastdiscovery of new peers in an existing network and addresses the real-world problemsdescribed in Figure 4.20. Random and RandomSweet have a lower total announcementcount in small networks. This shows that these strategies are inferior in terms ofdiscovery times. The remaining Step-based strategies show satisfactory results in smalland bigger networks in terms of bandwidth usage, but take a longer time to reach anoptimal resource usage.Adaptation RateUnsteady and MaxFirst have a very high adaptation rate, since they set their finalannouncement delay after the first observation interval for all static network configu-rations, as presented in Figure 4.22h. MaxFirst is able to achieve fast adaptation ratesfor big networks, while MinFirst is able to achieve this in small networks, as a result oftheir designs. A disadvantage of MaxFirst is shown in Figure 4.22a: For small networks,the announcement rate also drops to the minimum in the first place, so discovery maybe worsened.The adaptation rate of the Step-based algorithms depend on the number of nodes. Asoutlined in Figure 4.22f, in a network of 5 nodes around 70 seconds and in a networkof 10 nodes around 150 seconds are needed to fully adapt.In Figure 4.23, a splitting network configuration with 10 nodes is presented. The Step-based strategies reach their target announcement rate immediately. In RandomSweet andUnsteady, new announcement rates are visible after about 30 seconds. Both strategiesreach announcement rates as in the united, central network. This understanding onlyslightly differs in the merging network: The Step based algorithms need longer, while704.4 Optimizing Epidemic Announcements0 50 100 150 200 250time (s)0123456announces / secondsplitMaxFirst-n010MinFirst-n010Random-n010RandomSweet-n010Static-n010Step-n010StepRand-n010Unsteady-n010Figure 4.23: Splitting network configuration with 10 nodes.Unsteady and MaxFirst adapt in the observation interval.The observed adaptation rates are also valid for the merging network configuration:MaxFirst and Unsteady adapt in a 30-seconds window, while the Step strategies take alonger time. For the network of 5 nodes, the Step strategies also achieve an adaptationrate of around 40 seconds. Especially in small networks, this rate is important, sincethe announcement gaps are compensated quickly.Figure 4.24 shows a delayed start of 100 nodes, with one node starting per second.Compared to Static, the proposed algorithms are able to keep the announcement rateslow. Since every node announces using the default interval for the first 20 seconds,the announcement rate grows even in the very agile Unsteady and MaxFirst strategies.Immediately after all nodes are spawned, the algorithms are able to adapt to thesituation.Announcement GapsFigure 4.25 shows a violin plot of the global announcement gaps for a static networkwith 10 nodes. The mean gap correlates with the global announcement rate, and so doesthe variance. Having this in mind, the perceptions of Subsection 4.4.5 are backed bythis plot. Although MaxFirst does not have the highest announcement gap, it producesa relatively high percentage of longer gaps, while all other strategies only have a lownumber of outliers in this area. This is also the case for a network of 5 nodes. Yet largernetwork configurations do not show the same characteristics. This behavior can beascribed to the observations made in the previous section.What stands out is that compared to Static, all strategies perform worse with respectto the maximum announcement gap. This can be put in perspective by examiningthe upper quartile: For all algorithms except for MaxFirst, the upper quartiles of the714 Disruption-tolerant Device-to-Device Emergency Communication0 50 100 150 200 250 300time (s)0102030405060announces / secondMaxFirst-n100MinFirst-n100Random-n100RandomSweet-n100Static-n100Step-n100StepRand-n100Unsteady-n100Figure 4.24: A growing network with 100 nodes.announcement gaps are below 2 seconds.Energy ConsumptionThe initial assumption was that a reduced number of announcements would reducethe consumed energy proportionally. This assumption was evaluated in a wirelessnetwork of 9 ARM-based nodes as described in Section 4.4.5. In these experiments,each node acted as sender and receiver simultaneously. One node (system under test -SUT) was connected to an external power meter (ODROID SmartPower), which loggedthe power and energy consumption of the node at a 5 Hz rate. Additionally, everyexperiment was performed with two different network interface configurations, witha different idle power consumption each: ad hoc mode (Pidle=1.37 W) and managedmode (Pidle=1.45 W).To measure the higher end of the power consumption, two additional announcementstrategies sending announcements at a high rate are introduced: Static05 and Static01,with 2 and 10 announcements per second, respectively.To compute the energy consumed by the software, the average idle power is sub-tracted from the measured power in the given 300 seconds measurement interval:E :=\u222b 3000Pmeasured(t)dt\u2212 300 \u2217 Pidle (4.1)In the physical testbed with 9 nodes, the default Static strategy uses 1.99 mWh.Static05 and Static01 use 11.97 mWh and 32.52 mWh for their announcements, respec-tively. Based on these numbers, a correlation between the number of announcements(sent and received) and the consumed energy is found and presented in Table 4.5.724.4 Optimizing Epidemic AnnouncementsMaxFirstMinFirstRandomRandomSweet Static StepStepRandUnsteady0123456announce gaps (s)Figure 4.25: Announcement Gaps in a static network of 10 nodes.Table 4.5: Correlation of energy consumption and announcements in a physical testbed of 9 nodes.Name # Ann. E (mWh) rel. Ann. rel. E ratioStatic 1323 1.99 1.00 1.00 1.00Static05 5404 11.97 4.08 6,00 1.47Static01 29342 32.52 22.18 16.31 0.74MaxFirst 256 1.17 0.19 0.59 3.04MinFirst 473 1.26 0.36 0.63 3.04Random 434 1.34 0.33 0.67 2.04RandomSweet 342 0.73 0.26 0,37 1.42Step 495 1.20 0.37 0.60 1.61StepRand 460 1.12 0.35 0.56 1.61Unsteady 514 1.38 0.39 0.69 1.78While the correlation between the number of announcements and the energy con-sumption is reasonable for large numbers of announcements, this correlation is notsubstantial for lower numbers of announcements. The general trend seems to be correct(correlation coefficient r = 0.985), since all proposed strategies need less energy thanStatic. In contrast, there are examples in which this correlation seems to be vice versa,e.g., when comparing MaxFirst and RandomSweet.To summarize, the energy measurements of the experiments show that for highnumbers of announcements the energy consumption is increased. Side-effects of theprogramming language, as well as the relatively low energy impact of the announce-ments of Mesher disturb the energy measurements. Nevertheless, a general trend isclearly evident.4.4.6 ConclusionIn this section, it was shown that without relying on application-specific properties,optimizations for network protocols relying on announcements can be achieved. Eightdifferent announcement strategies were compared, including a standard static announce-ment strategy and a random announcement strategy. While a random announcementstrategy might preserve more bandwidth than a static announcement strategy, it hasnegative side-effects compared to the other proposed announcement strategies. By734 Disruption-tolerant Device-to-Device Emergency Communicationdynamically changing the announcement interval and depending on the number ofnodes involved, the bandwidth required for announcements could be reduced by morethan 80% compared to a static announcement strategy. Nevertheless, the requirementof fast discovery of at least one node is still met. The evaluation of the proposedannouncement strategies in terms of energy consumption show that announcementsdo effect battery lifetimes and are thus worth to be reduced.There are several areas for future work. For example, so far the algorithms onlyhave access to information like the number of announcements received in the lastobservation interval or the number of currently known peers. By giving the strategiesmore information, further optimizations might be possible. Furthermore, a dynamicobservation interval could be implemented, to allow even faster adaptation to newsituations.744.5 DTN-RPC - Offloading Work in Challenged Environments4.5 DTN-RPC - Offloading Work in Challenged Environments4.5.1 IntroductionThe possibility of calling a procedure on a remote computer has been introduced toprogram client-server interactions in a procedural manner. Remote Procedure Calls (RPCs)[78] have proven to be useful in many distributed computing scenarios to simplifyapplication programming by eliminating the need for explicitly having to code thedetails of remote interactions based on a request-response message-passing protocol.RPCs have been integrated into programming languages (e.g., Java RMI, Python RPyC,Distributed Ruby DRb-RPC, and Erlang RPC), dedicated applications (e.g., SAP RFC),and WWW protocols (e.g., XML-RPC, JSON-RPC, SOAP, Windows WCF, Google gRPC,Google Web Toolkit RPC).However, none of the existing RPC implementations are designed to work properlyfor Delay/Disruption-Tolerant Networking (DTN) [79], [80] where network connectivityis periodic, intermittent, prone to disruptions, and a direct connection to a remote servermight not exist. DTN scenarios with potentially large transmission delays as a result ofeither inadequate physical link properties or extended periods of network partitioningare common in natural disasters. For example, during the 2010 earthquake in Haiti,public and mobile telephone systems were destroyed or disturbed and could not berebuilt or repaired for days44. An inoperative cellular communication infrastructureduring the earthquake in New Zealand on November 14, 2016, created uncertaintyabout whether people were still in the affected areas45. Even in the absence of disasters,there are still regions, e.g., in India [81] and Australia [82], where no telecommunicationinfrastructure exists and where people cannot communicate using mobile devices.Whenever reliable end-to-end connectivity is not available, DTN can be used to sustaincommunications without requiring any conventional infrastructure.Calls RemoteProcedureSends takenpicture asresult*Route usedby callRoute forthe resultConnection disruptafter call *New connectionfor resultFigure 4.26: Calling a remote procedure in a DTN disaster scenario.Being able to use RPCs in these scenarios could provide great services for civiliansand professional first responders. For example, quadcopters could offer a procedurethat takes a picture with a mounted camera at a particular geographical location and44https://en.wikipedia.org/wiki/2010_Haiti_earthquake45https://www.bbc.com/news/world-asia-37970775754 Disruption-tolerant Device-to-Device Emergency Communicationreturns it over the network. Then, rescuers could request an overview image via anRPC to a quadcopter while performing other tasks until the file arrives over a DTNconnection using nodes of other rescue workers or citizens as relay nodes. This exampleis illustrated in Fig. 4.26, where the call takes the blue route, but the result arrives overthe red route due to the connection loss illustrated by the yellow lightning symbol. Thismight take longer, but without DTN the call could not be made at all.In this section, DTN-RPC is presented, a new approach to provide RPCs for DTNenvironments. DTN-RPC relies on (a) control and data channels to cope with potentiallyshort contact durations in DTN where it is impossible to transmit large amounts of data,(b) explicit and implicit modes for server addressing, (c) Non-DTN and DTN transportprotocols for calls and results, and (d) predicates that servers can check to decidewhether a procedure should be executed. The open-source implementation of DTN-RPC46 is based on Serval [2], [27]\u2013[29], an open-source, disruption-tolerant wirelessad-hoc networking system. The experimental results obtained within the networkemulation framework CORE indicate that the measured CPU and network overheadsfor DTN-RPC are reasonably low so that DTN-RPC can be executed on smartphones orrouters, and that the round-trip times and the number of successful RPCs are highlysatisfactory in dynamically changing network topologies with unreliable connectivity.Parts of this section have been published in [4].4.5.2 Related WorkTu and Stewart [83] present a Java RPC framework where small data is replicated andsent over a second TCP connection to the server or back to the client. At the destination,a listener collects all arriving data on all connections, reassembles the original data,and passes it to the corresponding handler.Stuedi et al. [84] increase the efficiency of RPCs in data centers by softening theuserland and kernel separation in the network stack and by using remote direct memoryaccess to minimize the overhead of network operations by performing them with lesscontext switches and zero-copy network I/O.Chen et al. [85] introduce memory regions where server and client exchange datato improve the efficiency of RPCs between virtual machines (VMs) on the same hostcomputer. The proposed framework has three components: (a) a notification channelthat informs the server about new calls and the client about arriving results, (b) acontrol channel that sends meta-data (e.g., the parameter count), and (c) a transferchannel that is responsible for transmitting data between server and client and puttingthe data in the predefined memory regions.Shyam et al. [86] propose solutions for situations where an RPC server is not available.The first solution is a heartbeat server that observes whether the RPC server is operative.The second solution is that every node sends a health check message to the RPC server.Since these messages are typically smaller than an RPC request and no computationstake place, the answer of the health check should arrive faster. If the answer doesnot arrive within a timeout that is smaller than the timeout for the RPC, the server isconsidered inoperative.Reinhardt et al. [87] address the problem of providing RPCs in wireless sensornetworks. In particular, the authors eliminate the need of conventional RPCs to send46https://github.com/umr-ds/DTN-RPC764.5 DTN-RPC - Offloading Work in Challenged Environmentspredefined data to predefined destinations, typically addressed by ports, by publishingdescriptions of new sensors that can be used by other sensors or nodes dynamically.Shi et al. [88] present a framework where mobile devices can offload jobs to othermobile devices. In scenarios where node mobility is high, only small tasks will beoffloaded; otherwise larger jobs will be offloaded, too. To increase the number ofoffloaded jobs, every job is split into smaller tasks. Additionally, every node has toannounce its capabilities, such as CPU capacity and available battery power. To offloada job, the framework compares the task requirements with the capabilities of the clientand tries to find a server that satisfies the requirements better than the client. If noserver is found, the job will be executed locally.Chen et al. [89] propose a solution for offloading computations to ad-hoc cloudlets. Ajob is offloaded via an ad-hoc communication channel that is closed after the procedurehas been called successfully. The result of the job can arrive (a) via an ad-hoc channel ifserver and client are in close proximity, (b) via a cellular network used when an ad-hocconnection is not possible, (c) via a WiFi access point, if available.Zhang et al. [90] propose a solution for cloudlets with intermittent connectivity whereparts of a job will be executed either locally or remotely. The decision which of bothoptions is chosen is based on a probability that includes the cost of executing a task.Two cost factors are calculated: (a) the cost when the phase is executed locally, where,e.g., energy consumption is important, (b) the cost when the phase is executed in acloudlet, where, e.g., available bandwidth is important. Based on this information, aMarkov chain can be constructed and the optimal path can be found.Lai et al. [91] propose an offloading algorithm for delay-tolerant mobile networks thatincreases the amount of offloaded data without increasing the transmission overhead ordelay. The transfer channel is chosen based on the contact duration between two nodesand the available transmission protocols. Therefore, every node logs which neighborsare available. Based on the available neighbors, on the size of the data that is offloaded,and the estimated waiting time, a priority is computed. With these factors, a utility iscalculated that denotes whether data should be offloaded using this particular channelor not.To summarize, several of the related works address problems of RPCs in traditionalnetworks, where links are either static or tasks are on the same machine, such as inVMs. Furthermore, direct memory access methods to reduce networking overheadcannot be used in a DTN environment, due to possibly untrustworthy nodes. Also,control mechanisms like heartbeats or duplicating data on multiple channels are nooptions for DTN. In the offloading approaches, the particular problems of RPCs inDTN are either not addressed or would require additional infrastructure, such as celltowers for 3G or LTE connectivity, or nodes with access to the Internet. DTN-RPC onthe other hand is designed to provide RPCs in DTN environments without requiringany additional infrastructure.4.5.3 DTN-RPC\u2019s DesignThis section presents the design of DTN-RPC.Fundamental ConsiderationsThere are several differences between RPCs in traditional networks and RPCs in DTN.774 Disruption-tolerant Device-to-Device Emergency CommunicationIn conventional RPC implementations, errors are handled, for example, if the con-nection between client and server is lost. In DTN, it is not certain whether a call evenreaches its destination. Thus, errors in DTN can only be handled in a few situations,since error reports could just not arrive and the client would not notice that the callwas not successful. The server, on the other hand, would have to spend computationaloverhead while trying to inform the client about the error. Furthermore, disruptionsand poor connection quality make it impossible to support real-time communication orto guarantee a predefined quality of service in DTN.Common RPCs are location transparent. For this purpose, stubs or proxy functionsexist to handle communication via the network. In DTN, a call will explicitly beexecuted remotely, and it is expected that there will be networking overhead whenexecuting a remote procedure.In several RPC implementations, the client has to register at the server before callinga procedure. Since in DTN the address of a server is typically not known, clientregistration is not possible.Traditional RPC servers either announce the procedures they offer or there existsa lookup service where clients can find information about which server offers whichprocedure. In DTN, server announcements might not reach or lookup services mightnot be available for clients when needed.Control and Data ChannelsDTN is often used in mobile mesh and ad-hoc networks where the network topologychanges frequently. This can lead to short contact durations between nodes where itis impossible to transmit large amounts of data. Due to this restriction, two separatecommunication channels are introduced in DTN-RPC: the control and the data channel.The control channel is responsible for transmitting meta-data, such as the procedurename and the parameters, from client to server, and possible results from server toclient. The control channel supports two modes to address remote servers, explicit andimplicit (any or all), as described below.Explicit If the address of a server is known and the server is reachable, DTN-RPCwill choose the explicit mode and will try to establish an end-to-end connection to thisspecific server.Implicit (any or all) If the address of a server is not known, but potential serversare reachable, both the any and all modes (summarized as the implicit mode) are usedto broadcast a call. In the any mode, the client waits for exactly one response. This ishelpful if it is known that servers exist that offer a particular procedure, but it does notmatter which server responds. The first arriving response will be accepted. In the allmode, the client will wait for as many answers as possible until its internal timeoutoccurs. This is useful in scenarios where the quality of the results varies with theexecuting machine (e.g., GPU support, different algorithms), where different answersshould be combined (e.g., to implement aggregate functions that return a value acrossall items in the results set), or is influenced by other factors such as geolocation (e.g.,sensor readings, taking a picture).784.5 DTN-RPC - Offloading Work in Challenged EnvironmentsClientStartTransparent Call AddressReachable Call viaNon-DTNBroadcast Non-DTNReachableCall viaDTNReceive ResultStopExplicitImplicitYesYesNoNoServerStartOffer ProcedureWait for CallEval. PredicatesExecuteReceiving  Proto.ReachableReturn viaNon-DTNReturn viaDTNYesNoDTNNon-DTNNoYesFigure 4.27: DTN-RPC flowchart for client and server.The payload of the control channel packets must not exceed the payload size of theunderlying transport protocol to keep the data on the network as small as possible.The data channel transports larger amounts of data from client to server and viceversa. It is used if a file is required as a parameter for a particular call. The transportof the payload in the data channel is always performed via DTN. The transport of themeta-data in the control channel is explained below.TransparencyIn both explicit and implicit addressing modes, the control channel of DTN-RPC supportsNon-DTN and DTN transport protocols and automatically switches between them forperforming a procedure call, as explained below.Non-DTN vs. DTN As illustrated in Fig. 4.27, if the server is reachable in the explicitmode, DTN-RPC will use a Non-DTN transport protocol to call the server. If the serveris not reachable, the call will be issued using a DTN protocol.After having called a remote procedure in the explicit mode, the client waits for theresponse using the same transport protocol that was used to call the procedure. If theconnection is interrupted, the client additionally waits for results that arrive via a DTNprotocol.794 Disruption-tolerant Device-to-Device Emergency CommunicationAfter having successfully executed a received call, the server checks whether theexplicit control channel on which the call was received via a Non-DTN protocol is stillavailable, as shown in Fig. 4.27. If the channel is not available anymore, the result willbe sent via a DTN protocol. The DTN-RPC server does not attempt to re-establish aNon-DTN connection, since it is unlikely that a reconnection is successful if one of thenodes has physically moved out of the network\u2019s reach. If the call was received via aDTN protocol, the server also uses a DTN protocol for its response.Since the implicit modes use broadcast addresses to call procedures, a differenttransport protocol has to be used than in the explicit mode, because reliable point-to-point transport protocols like TCP do no support broadcast packets. Since a serveravailability check in a broadcast scenario would imply communication between multiplenodes, which would add additional delays, a call just gets broadcasted without anyprior availability checks. If a timeout occurs and no result arrives, the call is performedvia a DTN protocol.Transparent DTN-RPC is designed to automatically select the most suitable trans-port protocol in any given scenario. In the transparent transport method, both clientand server are designed to make all the above dicussed decisions without any userinteraction.Offering and Executing CallsTo offer a remote procedure as shown in Fig. 4.27, two steps are required on the server:declaring and implementing a procedure. The first step of offering a remote procedureis that every procedure has to be declared as a prototype in an extra configuration file inorder to tell the server which procedures are available for execution. The implementationof a procedure, which is the second step, has to be provided as an external executablewritten in any programming language.The parameters of an incoming call are passed in the order they were received to theexternal program that then executes the procedure. After the procedure finishes, theresult is returned to the server that marshals the result and prepares the result to sendit back to the client.Typically, the computational resources and the battery lifetimes of nodes in DTNare limited. To avoid the execution of calls that would consume too many resourceswith respect to the current state of a server, a server can decide whether a remoteprocedure should be accepted or not. For this purpose, particular predicates can bedefined, such as thresholds for resource constraints (number of concurrent processes,remaining battery life etc.) or available (sensor) hardware like GPS. This is also shownin Fig. 4.27. The server checks whether defined predicates are satisfied. If at least onerequirement is not met, the procedure will not be executed.Furthermore, each call can provide its own requirements that also have to be checkedby the server. For example, some calls should only be executed on non-moving nodes,or require special sensor hardware or extensive resources, such as disk space or RAM.Therefore, there is a two-stage predicate check per server: the first one is the generalserver acceptance check, and the second one is call-specific and evaluated after havingpassed the first check.804.5 DTN-RPC - Offloading Work in Challenged Environments4.5.4 ImplementationThe implementation of DTN-RPC is based on the Serval Project [27]\u2013[29]. Serval iscentered around a suite of protocols designed to allow ad-hoc and infrastructure-independent communications. The Serval Mesh Protocols abstract from lower-layerprotocols, such as IP, UDP, WiFi, packet radio or others. Serval\u2019s real-time packet-switched protocol is the Mesh Datagram Protocol (MDP), which can be compared toUDP/IP, but uses SIDs (Subscriber ID, the public key of an asymmetric elliptic curvekey pair) instead of IP addresses, and includes encryption, authentication and integrityfeatures by default. To route packets, MDP uses a protocol inspired by OLSR 47 andB.A.T.M.A.N. [30] for both node discovery and maintaining a routing table, whichfacilitates multi-hop routing of packets. On top of MDP, the Mesh Streaming Protocol(MSP) provides reliable data streaming, similar to TCP. Finally, Rhizome is a simplestore-and-forward protocol defining files as bundles. Intended as the DTN protocol ofServal, Rhizome uses an epidemic routing protocol to transmit files hop-by-hop fromsource to destination. Rhizome is purposely agnostic of the transport protocols belowit, requires no routing table and focuses on single-hop communications, with multi-hopcommunications emerging as a natural consequence of bundles replicating among nodes.DTN-RPC uses MDP, MSP, and Rhizome to handle different situations and addressingmodes.As shown by the evaluation in Section 4.3 Serval is an elaborate and ready-to-usesoftware for DTN and mesh networks.For programmers, an API is offered that can be used to develop programs using theDTN-RPC library to execute procedures on remote devices in DTN environments.Calling a Remote Procedure TransparentlyTo call a remote procedure transparently, a single function is required that is part ofthe offered DTN-RPC API. This function has five parameters: the server address, thename of the called remote procedure, the number of parameters of the procedure, theparameters themselves and the execution requirements discussed in Section 4.5.3. Themode to be used is determined by the first parameter of this API function call.Explicit If the parameter is a valid address, the remote procedure will be calledexplicitly, i.e., the call will be issued via Serval\u2019s MSP, if the server is available. Arouting table is built in an ad-hoc manner. If the address of the server can be foundin this routing table, this particular server is reachable. While waiting for the result,the client checks periodically whether the connection is still alive. If the connectionterminates, the client starts a Rhizome DTN listener.Implicit The modes any and all are used if the address is the ANY address providedby Serval for any or the broadcast address for all. Since Serval\u2019s MSP supports point-to-point communication only, it is not possible to send data to the broadcast address.Therefore, any and all use Serval\u2019s MDP.Since a reachability test is not possible for broadcast packets, the procedure will becalled without any prior checks. Since delivery is uncertain, the client sends a call every47https://tools.ietf.org/html/rfc3626814 Disruption-tolerant Device-to-Device Emergency Communicationsecond until at least one server responds with an acknowledgement or a timeout occurs.If an acknowledgment arrives, the threshold for the timeout is increased. Only if thenew timeout occurs, the client will additionally start a Rhizome DTN listener and waitfor the result via DTN.The difference between the modes any and all is the number of results. In the firstcase, the client stops listening as soon as the first result arrives. In the second case, theclient waits for as many results as possible, but at least for one.Returning the Result TransparentlyWhile executing the called procedure, the server does not check periodically whetherthe client is still reachable. Instead, this check is done once when the response is readyto be sent. If the call arrived via MSP or MDP, but the connection is broken or the clientis not reachable, sending will fail and the server will send the result via Rhizome.4.5.5 Experimental EvaluationIn this section, an experimental evaluation of DTN-RPC for different network topologiesand in various configurations is presented. Due to the lack of comparable RPC imple-mentations that can handle disruptive networks, DTN-RPC is not compared againstother approaches. A comparison with widespread software solutions such as JSON-RPCor SOAP would be unfair, since they would fail each time the network connection islost.Test SetupThe evaluation of DTN-RPC is based on the open source network emulation frameworkCORE48. Compared to protocol simulations, CORE can run DTN-RPC without modi-fications in a more realistic Linux environment. All tests are performed on a 64-coreAMD Opteron 6376 CPU with 256 Gigabyte RAM, emulating up to 64 virtual nodes atthe same time.Measurements Standard Unix tools are used to measure system properties with atime resolution of one second. For CPU statistics, pidstat49 is used, and the Serval andDTN-RPC processes are monitored from within a node. Network usage is measuredfrom within the nodes on every network interface for Serval and DTN-RPC using acustom Python script based on libpcap50. To monitor the behavior of DTN-RPC, metricssuch as call times, round-trip times, and logging functions were implemented andintegrated into the binary.Network Topologies Three network topologies are considered, as shown in Table 4.6.48https://www.nrl.navy.mil/itd/ncs/products/core49http://sebastien.godard.pagesperso-orange.fr50http://www.tcpdump.org824.5 DTN-RPC - Offloading Work in Challenged EnvironmentsTable 4.6: TopologiesName # Nodes DescriptionHub 28 All nodes connected to each otherChained 32 Pair-wise connectedIslands 64 Partitioned islands with dynamic links in betweenHub The Hub topology connects 28 nodes with each other so that every nodeis one hop away from all other nodes. As shown previously in Section 4.3, the Hubtopology is challenging for Serval and thus also for DTN-RPC due to the high number ofdirect neighbors, all using bandwidth and flooding each other with status information.Therefore, the Hub topology helps to investigate whether DTN-RPC can handle RPCswhen the network is under heavy load.Chained The Chained topology consists of a chain of 32 nodes, 31 hops from thefirst to the last node. Typically, network connections over the Internet require less than16 hops. In a DTN mesh network, more hops might be needed for messages to reachtheir destination.Islands The Islands topology represents a partitioned, dynamic network with 64nodes. At the beginning, there are 4 islands each containing 16 nodes. The 16 nodesper island are connected randomly with each other, creating an ad-hoc mesh network.Then, four different behaviors can occur randomly every 60 seconds: two islands areconnected, two connected islands are disconnected, all islands are connected or allislands are disconnected resulting in the original state.Network Connections DTN-RPC adds a new layer of abstraction to the Serval net-working stack. Although Serval can cope with several degraded networking scenarios,DTN-RPC is only evaluated in situations where network connections are completelylost, because this is the most challenging situation in DTN. Network degradations andbandwidth limitations would only lead to higher delays, but not break DTN-RPC itself.Test Sets and Modes The remote procedure used in the tests implements a simpleecho service. It is called with three different test sets: (a) 0MB, where no file is used; (b)1MB, where a file of 1 megabyte is transmitted; (c) 100MB, where a file of 100 megabyteis sent.Additionally, all tests are executed in 10 different modes: explicit, any and all viaRhizome; explicit, any and all via MDP; explicit, any and all transparently and explicit viaMSP.Servers Since the successful execution of remote procedures in DTN depends on thenumber and distribution of servers, every test in Hub and Islands is executed twice,first with 5% of the nodes as servers and second with 50%. In Chained, the goal is todetermine how DTN-RPC performs if the call has to travel a long distance. Thus, onlyone server and one client at the opposite ends of the chain are needed.834 Disruption-tolerant Device-to-Device Emergency CommunicationIn each test setup, the procedure is called 30 times to get reliable results. Theacknowledgement from the server has to arrive within 30 seconds on the explicitchannel. After the acknowledgement, the client waits an additional 90 seconds for theresult. If within these 90 seconds no results arrived, the procedure is called via DTN,which has an additional 90 seconds to finish. After the client has received the result orall timeouts are reached, the next procedure will be called.Since our evaluation is concerned with the overhead and the performance of DTN-RPC, the possibility of DTN-RPC to perform predicate checks to decide whether aremote procedure should be accepted has been disabled in the experiments.Fundamental PropertiesIn Hub where each node is a single hop away from all other nodes and Serval usesbroadcast packets to announce meta-data, each node produces a flood of data thatis sent to all neighbors. Thus, both the CPU usage and the network load in Hub arealways higher than in the corresponding tests in Chained or Islands, due to the highnumber of direct neighbors. Furthermore, DTN-RPC does not only use the API, butalso the networking stack and the communication mechanisms provided by Serval.Thus, DTN-RPC cannot be measured separately, but only together with other Servaltraffic.Similar to the network usage, the CPU utilization has to be measured not only forDTN-RPC, but also for Serval running on a node. The evaluation of the CPU usageshows that the CPU consumption of DTN-RPC is negligible with about 1% in heavyload situations. However, the Serval process has a higher CPU usage, since Rhizomecomputes a hash for each file sent. The larger the file, the more time-consuming thehash computation becomes. DTN-RPC, on the other hand, is independent of file sizes,because it simply issues a call to the Rhizome API, which leads to the described 1%CPU utilization increase in the DTN-RPC process. Therefore, since the CPU utilizationis dominated by Rhizome, in the experiments below it is always based on the Servalprocess.Network PerformanceFor the 0MB tests in the Chained topology, the overall network load averages at about2 Mbit/s for each of the three transport protocols (MDP, MSP and Rhizome). This istrue for all three modes, explicit, any and all. Since DTN-RPC uses only a single packetfor calling the remote procedure and returning the result in 0MB, these packets getlost in the overall network load that is produced by Serval exchanging meta-data andtherefore not plotted in Fig. 4.28.During the 1MB and 100MB test sets, the network load increases up to 70 Mbit/sfor 1MB and up to 500 Mbit/s for 100MB, as indicated by the blue and red graph ofFig. 4.28a, in which the stacked bandwidth for all network interfaces together withthe CPU usage in a logarithmic scale for 5 calls with the 100MB test set and 30 callswith the 1MB test set is shown. In the 1MB and 100MB calls, a file always has to betransmitted via the Rhizome DTN for calling the remote procedure and receiving theresult. The difference between the 1MB and 100MB calls is due to the different file sizes.The Hub topology shows a similar behavior, as illustrated by Fig. 4.28b, wherethe stacked bandwidth for all network interfaces together with the CPU usage in a844.5 DTN-RPC - Offloading Work in Challenged Environments(a) Chained topology (b) Hub topologyFigure 4.28: Stacked bandwidth usage for 1MB and 100MB and maximum CPU usage for 1MB and 100MBin different topologies.logarithmic scale for 3 calls with the 100MB test set and 30 calls with the 1MB testset is shown. The main difference is that the Hub topology suffers from the problemsdiscussed in Sec. 4.5.5. The overall network usage for the 1MB test sets exceeds 1,000Mbit/s (blue graph) and 10,000 Mbit/s for the 100MB test sets (red graph).Comparing the bandwidth consumption to previous results in Section 4.3, DTN-RPCdoes not add any measurable network traffic to the traffic produced by Serval, and thuscan handle scenarios where the network has a high bandwidth usage well.CPU UsageAs shown in Figures 4.28a and 4.28b, CPU usage highly correlates with network usage.Since CPU usage in the 0MB tests does not exceed 1% after the initial discovery phase,it is not plotted in Figures 4.28a and 4.28b. For the 1MB tests, the maximum is at about2% up to 3% (red line) and up to 20% for the 100MB tests (black line) in the Chainedtopology.In the Hub topology, the behavior is comparable to the Chained topology, with thedifference that the CPU usage is generally higher. In the 1MB tests, the CPU usageincreases up to about 10% and for the 100MB tests up to 90% during the sending phase.This relatively high CPU consumption happens only while a hash of a file is computedand the file is inserted into the Rhizome store, and thus only during a relatively shorttime period. As already mentioned, the CPU usage of DTN-RPC does not exceed 1%.Round Trip TimesTo measure the round-trip times (RTTs), only the Chained and Hub topologies areconsidered, since the Islands topology would not give any credible results due to therandom merging and separation of the islands. RTT is only used to indicate the timethat is needed to transmit the payload through the network to be sure no additionaldelays are introduced by DTN-RPC. The execution of a procedure typically takes longerto finish than the implemented echo service.As shown in Fig. 4.29a, the 0MB tests in Chained called by MDP or MSP (i.e., Non-DTN) are executed within a second. As the files grow, the RTT increases.854 Disruption-tolerant Device-to-Device Emergency Communication(a) Chained topology (b) Hub topologyFigure 4.29: Round trip times in different topologies.In the DTN tests, the RTTs are similar, regardless of the file size. Due to the fact that inDTN the control channel as well as the data channel are transferred via Rhizome, bothserver and client have to wait for two files. Therefore, all tests take about 40 seconds.Transparent calls are slower than the calls via MDP or MSP for the 0MB and 1MB tests.Some of the calls are issued via MDP or MSP, while others are executed via Rhizome,as explained in Section 4.5.3. The illustrated RTTs are averaged over 30 calls, includingthe slower Rhizome calls. Furthermore, the time it takes to wait until the transportprotocol will be switched is also part of the RTT. Therefore, the transparent tests areslower than the corresponding explicit tests, but faster than the DTN tests. Since all100MB tests are issued using Rhizome and the switch time is included in the RTT, thetime it takes for finishing is higher than for MDP or MSP.As shown in Fig. 4.29b, the RTTs for tests in Hub do not differ much from the tests inChained. The only difference is that the 0MB and 1MB tests are faster in Hub, becauseall nodes are only one hop away from each other.To summarize, DTN-RPC can execute remote procedures satisfactorily fast. Thefallback method using Rhizome is slower, but still can get a result back to the clientwithin an acceptable time, even if the files are large.Transparency BehaviorIn this section, it is examined how DTN-RPC behaves in the dynamic Islands topologywith different numbers of available servers. The figures below show how many of atotal of 30 procedures are called using Non-DTN or DTN, respectively, in terms ofpercentage values. The left half of the pie charts represents outgoing calls and the righthalf incoming results.Since the Islands topology consists of 4 islands with 16 nodes that merge and separateover time, it is possible that not all results arrive within 210 seconds at the client (seeSec. 4.5.5) if the call was issued in explicit mode, especially in tests with only 5% servers.Additionally, as the file size increases, the transmission time increases too, and thenumber of successful calls decreases as expected, as indicated by Fig. 4.30a, Fig. 4.30c,and Fig 4.30e.864.5 DTN-RPC - Offloading Work in Challenged Environments5% Servers 50% ServersCalls (%) Results (%) Calls (%) Results (%)55.344.726.323.750 5248282052(a) Explicit 0MB tests.5% Servers 50% ServersCalls (%) Results (%) Calls (%) Results (%)946 494100 100(b) Implicit 0MB tests.(c) Explicit 1MB tests. (d) Implicit 1MB tests.(e) Explicit 100MB tests. (f) Implicit 100MB tests.Figure 4.30: Percentages of procedures called and results returned via Non-DTN and DTN for 100MB inthe Islands topology.Furthermore, it is evident that some of the results arrive via MDP or MSP (i.e.,Non-DTN), others only via Rhizome (i.e., DTN). There are two reasons. First, it ispossible that a call is issued successfully using MSP, but the route from the server to theclient gets lost because the islands have separated. Then, the result is sent via Rhizomeand arrives after the islands have merged again. Second, the client cannot establish aconnection to the server at all, because the islands are not connected. The procedurewill be called using Rhizome and the client will wait via Rhizome for the result. Evenif some results do not arrive in the explicit mode, the DTN protocol helps to improvethe number of successful calls, as shown in Fig. 4.30. 41.9% of the results in the explicittests with the 100MB test set with 50% of the nodes as servers arrive via Rhizome, andin 41.9% of the tests, no result arrives. In the implicit tests with the 100MB test set withonly 5% of the nodes as servers, 61.1% of the results arrive via Rhizome, and only 27.8%of the results do not arrive at all.Figures 4.30b, 4.30d and 4.30f show implicit tests in the Islands topology for threedifferent file sizes with different numbers of servers. It is evident that the implicit modeincreases the number of successful calls in every situation compared to the explicittests. Due to the dynamically changing Islands topology and the relatively short contact874 Disruption-tolerant Device-to-Device Emergency Communicationdurations, it is still possible that not all results arrive in 100MB. For the explicit calls,the more servers are available, the more results arrive.The number of missing results can be decreased if the contact duration is increased orthe waiting time for results is increased. Furthermore, more elaborate remote proceduresrequire a lot more time to finish than the simple echo service used in this evaluation.Therefore, the waiting time for results of up to 210 seconds in the experiments shouldbe increased in production environments, since it might be possible that a result arrivesafter hours at the client via DTN.To summarize, the transparent mode helps to improve the probability of receivingresults in dynamically changing network topologies like Islands. Furthermore, thetransparent mode can deliver results where a traditional RPC would not lead to anyresponse due missing network connections. Finally, if the waiting time for results isadequately large, the probability of receiving results increases, because when a DTNprotocol is used, results do not get lost, but simply are not transmitted via a directconnection to the receiving node. Therefore, given sufficient time, results will alwaysreach their destinations.4.5.6 ConclusionIn this section, DTN-RPC was presented, a new approach to provide RPCs for DTNenvironments. DTN-RPC relies on (a) control and data channels to cope with potentiallyshort contact durations in DTN where it is impossible to transmit large amounts ofdata, (b) explicit and implicit modes to address remote servers, (c) Non-DTN and DTNtransport protocols for issuing calls and receiving results, and (d) predicates that serverscheck to decide whether a procedure should be executed. The implementation of DTN-RPC is based on Serval, an open-source, disruption-tolerant wireless ad-hoc networkingsystem. The experimental results have indicated that the measured CPU and networkoverheads for DTN-RPC are reasonably low so that DTN-RPC can be executed onsmartphones or routers, and that the round-trip times and the number of successfulRPCs are highly satisfactory in dynamically changing network topologies with unstablelinks. Thus, DTN-RPC adds remote computing capabilities in the form of RPCs to DTN.These can, for example, greatly improve the tools available for professional respondersduring emergencies by utilizing low-power mobile devices that can offload tasks, suchas requests for aerial overview images or for face recognition based comparisons tosearch for missing people. Furthermore, CPU-intensive tasks such as reconstruction of3D models for replication of spare parts in the field [92] can be delegated off-the-gridto more powerful participants in the area.There are several areas for future work. First, DTN-RPC has been tested and evaluatedusing emulated networks. We plan to perform tests with smartphones to get a betterview on the real-world performance of DTN-RPC and a realistic evaluation of its energyconsumption. Second, since the Non-DTN transport protocols produced satisfactorilyresults in the Chained and Hub topologies, DTN-RPC should be evaluated withoutrelying on the strict differentiation between control and data channels. Finally, althoughit is relatively difficult to implement error handling and acknowledgment mechanisms,the evaluation has shown that this is not impossible. Thus, an acknowledgment systemshould be implemented for the any mode to inform other servers that the execution hasalready started.884.6 Environmental Monitoring Platforms for Disaster Scenarios4.6 Environmental Monitoring Platforms for Disaster Scenarios4.6.1 IntroductionEnvironmental monitoring without being able to rely on existing electricity and com-munication infrastructures is required in several use cases, such as biological andecological studies (e.g., animal tracking, air quality measurement), delivering Internetof Things (IoT) technology to farms51 in rural places, and emergency communication indisaster scenarios (e.g., tsunamis, earthquakes, nuclear meltdowns). In these situations,several constraints need to be considered when a technical solution for environmentalmonitoring is designed: lack of power supply, lack of communication infrastructures,harsh weather, low maintenance possibilities, weight restrictions for animal-attachedsensors, availability of scenario-specific sensors, and cost factors.There are several computing platforms readily available that can be extended toprovide stationary services as well as mobile, low power tracking devices. Furthermore,there are many affordable, off-the-shelf sensors that are potentially useful in suchscenarios, but proper information on how to integrate them and their specific require-ments, such as real world energy consumption, are often not easily accessible. Moreover,integrating the computing power, flexibility and mobility of smartphones and tabletsis an interesting option. Since satellite communication is expensive and limited, andcellular services are often not available in remote places or during a disaster, low-costlong-range (up to 16 km) radio technologies, such as LoRa, are quite useful. Althoughthey are mostly associated with IoT applications in an infrastructure-based LoRaWANmode, they can also be used for device-to-device communication and have the benefitof license-free frequency bands in any country of the world. Due to the low bandwidthof these radio transceivers, only small pieces of data can be transmitted, increasing theneed to preprocess data prior to long-range transmissions.In this section, a flexible and affordable sensor, computation, and communicationplatform for environmental monitoring that relies on low-cost hardware and infrastruc-tureless communication is presented. It uses delay-/disruption-tolerant networking(DTN) for non-time critical tasks over different wireless links, provides on-device dataprocessing capabilities based on machine learning methods, and integrates mobilesensor nodes, static devices, and smartphones. In particular, the following contributionsare made:\u2022 A novel sensor, computation, and communication platform for static and mobileenvironmental monitoring setups, and for users with mobile devices is presented.\u2022 A novel energy-efficient approach for on-device image classification is presented.\u2022 A novel approach to provide long range communication capabilities for Bluetooth-enabled devices is presented.\u2022 Experimental evaluations of (a) commonly available and affordable platforms, (b)the power consumption of several sensors, and (c) the real world communicationranges and power demands of various radio link technologies for environmentalmonitoring are presented.Parts of this section have been published in [6].51https://wazihub.com894 Disruption-tolerant Device-to-Device Emergency Communication4.6.2 Related WorkSeveral wireless sensor platforms for environmental monitoring were presented inthe literature, but they are often either based on specific technologies or tailored todedicated use cases. For example, the OpenSense project aims to bring community-driven environmental monitoring to life with an open platform and accessible results[93]. However, it is specifically designed for air pollution monitoring, relies on existingcommunication infrastructures and hardware specifically built for this use case. On theother hand, it integrates static sensor nodes as well as mobile nodes, and most recentlyalso wearables [94]. Similarly, Citi-Sense-MOB [95] and AirSenseEUR52 [96] work forair quality measurements in urban environments, but also rely on technologies suchas GRPS for data transmission, constant power supply (e.g., from the bus or car thesensor is mounted on), and custom/closed-source printed circuit boards (PCBs).Some custom-built platforms can be adopted to various scenarios. Problems asso-ciated with custom-built platforms are their cost and availability; sometimes they arespecifically tailored to a particular geographic region [97], [98].Llamas et al. [99] use Arduino and Raspberry Pi computers for building a reusableopen sensor platform. Their application is human gait identification. Long rangecommunication or infrastructureless operation are not considered.The senseBox project53 provides a sensor platform for citizen science projects [100].There is a strong focus on education and publicly available sensor data, but senseBoxlacks flexibility when used for more than just raw sensor data aggregation and alsorelies on existing communication infrastructures. Luftdaten54 [101] also uses cheapmicrocontroller units (MCUs) configured for air quality measurement in a citizenscience project, but also relies on existing communication infrastructures.The EU project WAZIUP tries to bring IoT technologies to developing countries [102].WAZIUP provides a low-cost communication infrastructure (LoRaWAN), while we tryto work without any infrastructure on a purely peer-to-peer basis. We incorporate DTNtechnologies and feature heterogeneous radio-link setups. Furthermore, conservingenergy plays a more vital role in our use cases, and we focus on providing a completesystem for remote sensing and communication.Some proposals use mobile devices or wearables as sensors, and some approachesprovide low-cost, long-range radios usable from smartphones, but they are often veryimpractical (a direct USB connection to a smartphone is required) or require operatingsystem modifications [103].4.6.3 Sensor Platforms for Disaster ScenariosStatic Sensor Platforms (SSPs) are the backbone of our environmental monitoringplatform. They have less restrictions on size or weight than Mobile Sensor Platforms(MSPs), and energy problems can be handled easier by adding solar panels, windturbines, or larger batteries. SSPs can be used for relaying packets, collecting sensordata on roof-tops, on trees (e.g., wildlife cameras), or on smart street lamps. MSPs, onthe other hand, are used to tag animals and, therefore, must be kept as light and smallas possible. Energy is a more valuable resource. Since humans with smartphones and52https://airsenseur.org/website/53https://www.sensebox.de54https://www.luftdaten.info904.6 Environmental Monitoring Platforms for Disaster Scenariostablets can also act as sensors, these must be integrated as well. Adding long-rangeinfrastructureless communication to mobile devices also has the benefit that it can beused in case of an emergency for sending messages to other participants. Finally, it isnecessary to preprocess the gathered sensor data to reduce the needed bandwidth fortransmission. This is challenging when using power-efficient devices as a basis for SSPs.The different sensor platforms are discussed in more detail below.Static Sensor PlatformsSSPs can easily utilize different energy sources, such as solar panels, car batteries, orelectrical wall outlets. Therefore, they can be built using regular single board computers(SBCs), such as Raspberry Pi 3 or Zero, since these platforms offer a compromisebetween computational power and low energy consumption. To also function as anetwork hub for mobile users and MSPs, different radio link technologies can beincorporated - Bluetooth, WiFi mesh, and for longer range, license-free, low-bandwidthcommunication via LoRa. Since energy consumption of SSPs is not as critical as inMSPs, SSPs can constantly listen on the different wireless interfaces and act as hubs orrelays for smaller mobile nodes passing by. For data dissemination, DTN technologiessuch as Serval55 can be used, since they perform well in infrastructureless environments[2]. A variety of sensors can be added, e.g.:\u2022 camera, night-vision camera, thermal camera\u2022 microphone\u2022 GPS/GLONASS\u2022 temperature, humidity, barometric pressure\u2022 air quality\u2022 rain- and soil-moisture sensorsUsually, these are connected directly through GPIO pins or various bus systems (e.g.,serial, SPI, i2c). Most SBCs directly provide these interfaces, only analog-digital pinsare often lacking, but can easily be added externally.Mobile Sensor PlatformsMSPs have more constraints than SSPs, since they must be as light and small as possibleto be attached to animals or additionally mounted on an Unmanned Ground or AerialVehicles (UGV/UAV) [7]. Apart from the weight of the total system, power consumptionis the main bottleneck. Due to these limitations, the choice of radio link technologiesand the types of sensors are quite restricted. MSPs are based on small MCUs, since theyrequire much less power and often provide deep sleep capabilities as well as variousI/O pins for digital and analog sensor inputs.Long-range Radio Links for Mobile DevicesIn remote areas, cellular coverage or WiFi access points for communication usingstandard smartphones are often not available. Building custom radio links into phonesis quite expensive and economically not interesting for large carriers. Therefore, adifferent approach with the following requirements is needed:55https://github.com/servalproject/serval-dna914 Disruption-tolerant Device-to-Device Emergency Communication1. it should work with any operating system,2. it should be compatible with any mobile phone,3. it should be license-free \u201dworldwide\u201d,4. it should provide infrastructureless long-range (>1 km) communication,5. it should be energy-efficient,6. it should be affordable.The best solution for items 1 and 2 is to rely on platform-agnostic standards such asBluetooth Low Energy (BLE) that can be used from Apple iOS and Google Android, oralmost any other operating system. To cover items 3 and 4, we use the LoRa standardthat in theory provides up to 16 km of range and is available in different frequencybands (433/868/915 MHz) for worldwide usage. LoRa also offers the LoRaWAN stan-dard as a higher layer with built-in encryption, but it also requires some infrastructure,making it unsuitable for our task. Energy efficiency (item 5) is partly achieved by usingBLE, but also by using small MCUs to handle communication. By finding a suitableMCU with built-in Bluetooth and LoRa chipsets, the price for such a smartphoneadd-on is also kept low. Alternatively, an SBCs equipped with a LoRa modem can bepaired using Bluetooth with a smartphone. Even though power consumption will behigher, this system has the benefit that software such as Serval can run directly on theSBC and expose only UI relevant functions via BLE, preserving smartphone energydue to lesser notifications and wake-ups.On-Device Data ProcessingSince long-range links over LoRa only provide a few kilobits per second of bandwidth,transmitting large amounts of data in its raw form is not feasible. Therefore, processingthe sensor data at least partially on the SSP to filter out unwanted content or alreadyproduce analysis results is favorable. In our use cases, we heavily rely on visualobject/concept detection in images to filter out relevant information. Our previouswork has shown how this approach can significantly reduce the amount of datanecessary to be transmitted [5]. To cope with the limited CPU power of most SBCs, weintegrate external hardware to accelerate the visual classification process. The challengeis to limit the power consumed by the accelerator device when it is currently not in use.4.6.4 ImplementationHere, the implementation details of the developed platforms are discussed.Static Sensor PlatformThe SSP can act as a relay for MSPs and mobile devices carried by users. Furthermore,it can be used without any sensors as a base station and uplink to the Internet (seeFig. 4.31). To provide these features, we focused on ARM-based SBCs, more specificallythe Raspberry Pi family. These devices are readily available worldwide, are proventechnology made specifically for tinkerers and well documented. There are severalcameras that can be directly attached, plus many (p)HATs with additional hardware andmany GPIO pins for direct sensor attachment. Depending on particular requirements(size, energy etc.), there are different models available, such as the Pi Zero W and the Pi3. Many wildlife cameras and weather stations have already been built on this proven924.6 Environmental Monitoring Platforms for Disaster ScenariosFigure 4.31: Base station for monitoring, relaying and processing.hardware platform, and Raspbian provides a solid and familiar Linux foundation. Wemodified a Raspbian OS Image to provide features specific to our SSP. It can easily setupa mesh network, provide Bluetooth debugging capabilities, open an access point, andstart services, such as GPS logging and serval-dna. Also, the energy consumption canbe optimized by deactivating unused features, such as the HDMI port of the Raspberry.All this can be configured through a simple text file on the small FAT32 partition onthe SD card56. This has the benefit that the default image can be written to a new SDcard and then can be configured from any computer with a simple text editor priorto actually booting the system. There is no need for Linux knowledge or extra driversto read the filesystem, all is kept in one file, in one place for ease of use. The singlebiggest feature missing in the Raspberry Pi family is proper power management anddeep sleep, but there are several after-market solutions57,58 offering this functionality.Another benefit of the newer Pi\u2019s (Zero W(H) and 3) is that Wi-Fi and Bluetooth arealready present. The only major interface left to be added for our system is a LoRatransceiver for long-range communication.LoRa Radio Modem There are several MCUs on the market using Cortex M0, AT-mega32u4, or ESP32 chips with onboard rfm95 transceiver modules. Using the Radio-Head library59, these can easily be used in the Arduino programming environmentto send packet data from device to device. We developed a firmware to expose thisfunctionality via an AT command set over the built-in USB-Serial, similar to the onefound in classic dial-up modems. Therefore, any device with an USB port can use sucha modem, and no special drivers are needed. The source of the modem firmware can be56https://github.com/buschfunkproject/heckenschere57https://spellfoundry.com/product/sleepy-pi-2/58http://www.uugear.com/witty-pi-realtime-clock-power-management-for-raspberry-pi/59http://www.airspayce.com/mikem/arduino/RadioHead/934 Disruption-tolerant Device-to-Device Emergency Communicationfound on github60. Furthermore, Serval, our DTN middleware, was made aware of thiscommunication channel by changing LBARD and writing a driver for our firmware61.Mobile Sensor PlatformSince the MSP should be as light and small as possible, we focused on MCUs with inte-grated Wi-Fi and/or LoRa transceivers. For convenience, performance and portability,all of our programming was done using the Arduino programming environment incontrast to ESP\u2019s IDF or MicroPython. Hence, only minimal changes were necessaryto switch from one MCU to another. To preserve battery power, the mobile sensorsare mostly kept in deep sleep until a timeout or external trigger wakes them up. Also,they are programmed as send-only devices, since relaying data would require constantlistening and would prevent deep sleep, thus draining the battery faster.Long-range Radio Links for Mobile DevicesSince newer SBCs, such as the Raspberry Pi 3 and Pi Zero W, provide Bluetoothcapabilities and can control devices with our radio modem firmware, such a setupcan easily be used as a bridge for smartphones. For a simple prototype, we usedthe bleno framework62 to expose system functionality via BLE. This is also useful fordebugging head-less systems. Therefore, we provide a simple echo service to broadcastany information via BLE63 from our customized Raspbian distribution. Despite theflexibility this setup provides, it consumes quite a lot of power and is rather large insize (Pi Zero + LoRa modem + battery pack + antenna).For a more lightweight solution, the radio modem firmware was enhanced to directlyuse BLE as a serial UART replacement. The packet size restrictions of LoRa and the BLEimplementation in most RF95-based chipsets are quite similar. There are ESP32-basedMCUs, such as the ones from Heltec and TTGO, that provide WiFi, Bluetooth and LoRaon a single board. The resulting system can be paired with any BLE capable (mobile)device, requires much less power, and for the 868/915 MHz bands, a rather shortantenna. A modified version of the firmware can also be found online64. This system israther small and comparable to commercial products, such as the GoTenna65, but moreopen and flexible. The BLE LoRa modem based on a TTGO ESP32 chip, including asmall 750 mAh LiPo, a custom 3D printed case, and a 868 MHz antenna is shown inFig. 4.32 right next to a Raspberry Pi 3 for a size reference.On-Device Data ProcessingFor data processing on SBCs, a solution with two execution options was imple-mented. The first one uses the device CPU itself, and the second one utilizes a Intel R\u20ddMovidiusTM Neural Compute Stick (NCS). If we use the compute stick, the CPU of theSBC can go to deep sleep and save energy. Visual object/concept detection is used for60https://github.com/gh0st42/rf95modem61https://github.com/gh0st42/lbard-ng62https://github.com/noble/bleno63https://github.com/buschfunkproject/bledebug64https://github.com/gh0st42/rf95modem/tree/ble_modem65https://www.gotenna.com944.6 Environmental Monitoring Platforms for Disaster ScenariosFigure 4.32: BLE LoRa modem with plain Raspberry Pi 3 for size comparison.image processing, and for this purpose we use two neural network models. The firstone is InceptionNet v3 [104] with 1001 different detectable classes, and the second oneis also an InceptionNet v3 model trained on the Open Images Dataset66 This neuralnetwork can detect 6012 different classes and is suitable for a more detailed analysis ofthe given images.These neural network models are executed either with Tensorflow 1.1.0 built for ARMCPUs or on the Movidius compute stick. Additionally, the neural networks have to beconverted with the Movidius compiler mvNCCompile to run the pretrained versions onthe compute stick.During our evaluation we found that the Intel Movidius NCS consumes an averagepower of 1955 mW when it is idle. On a Raspberry Pi, we can disable the entire USBsubsystem, but in this case the Ethernet and all other USB ports are also disabled. Sincevarious sensors and potential extra radio link interfaces might be connected over USB,this behavior is not desirable. Disabling only the specific port of the NCS to save energywhen no processing has to be done is more favorable. To achieve this, hub-ctrl67 isused to turn off the power of the compute stick in case it is currently not needed. Thispreserves a lot of energy, since the compute stick is expected to have more idle timesthan compute times. The possibility to have the compute stick as a backup without anenergy penalty and only activating it when really needed makes it even more useful.The visual object/concept detection software itself was written in Python 2.7 andoutputs the five main visual concepts for each given image for further processing ordiscarding of irrelevant images. Thus, the energy for transmitting irrelevant images canbe saved. Especially in a multi-hop scenario, a large amount of energy can be saved byapplying preprocessing functions to recorded image data [19].66https://storage.googleapis.com/openimages/web/index.html67https://github.com/codazoda/hub-ctrl.c954 Disruption-tolerant Device-to-Device Emergency Communication4.6.5 Experimental EvaluationSeveral experimental evaluations were performed regarding power consumption, trans-mission ranges, and execution times. The Monsoon Power Monitor was used for powermeasurements. All energy tests were repeated 2-3 times and ran for about one minuteeach, resulting in plenty of time to get a realistic power reading. Only the stress andcompute stick evaluations were not terminated by time but by the given task.Platform ComparisonsThe evaluation includes some Raspberry Pi SBCs as well as MCUs from differentvendors. They were tested for their idle power consumption and under full load. Otherchipset-specific features such as RAM, onboard networking capabilities etc. are alsolisted in Table 4.7.Table 4.7: Overview of SBC and MCU PlatformsProcessor RAM Network Idle - Power in mW Load - Power in mWMean Max Mean MaxPi 1 Model B+ 1x 700 MHz 512 MB 100 Mbit Eth. 931 1288 1043 1418Pi 3 Model B 4x 1200 MHz 1024 MB 100 Mbit Eth., WiFi,  4.1 1107 1845 2224 3285Pi Zero W 1x 1000 MHz 512 MB WiFi, 4.1 415 702 662 1057ESP32, TTGO 1x 240 MHz 520 KB WiFi, 4.2 366 427ESP8266, Feather Huzzah 1x 80 MHz 80 KB WiFi 426 1321Feather M0 1x 48 MHz 32 KB Optionally WiFi, LoRa 25 29Feather 32u4 1x 8 MHz 2 KB Optionally LoRa 24 27Waspmote 1x 14.74 MHz 8 KB 145 150When looking at the different Raspberry Pi models, it is evident that when idling,the Pi Zero W (415 mW) consumes less than half of what a Pi 1 (931 mW) needs andjust about a third of what the base Pi 3 Model B (1107 mW) needs. The newest Pi 3Model B+ was not tested, but due to its increased CPU power it is expected to consumeeven more power. Both Pi 1 and Pi 3 offer more USB ports onboard and Ethernet. ThePi 3 offers more processing power and cores than the relatively power-hungry Pi 1 thatprovides even less processing power than the Pi Zero W. Under load, the Pi Zero W stillconsumes less power than a Pi 1 idle. Due to its 4 cores and high clock speed, the Pi 3uses 2224 mW under load and peaks to 3285 mW at certain times. Thus, if saving poweris the priority, then the Pi Zero W is the best choice. If multiple CPU cores, onboardEthernet, and more USB ports are essential, then the Pi 3 Model B is the best candidate.For the MSP several MCU candidates were evaluated, as shown in the lower part ofthe table. Some of them like the ESP32 board from TTGO are much more powerful with240 MHz and 520 KB RAM compared to systems like the Waspmote with 14.74 MHzand 8 KB RAM. Not all systems provide deep sleep functionality by default. Eventhough the Waspmote or Feather M0 system consume less power than the ESP32, theyalso lack the radio link interfaces. Due to the flexibility through the included radiointerfaces, cost of the board and provided CPU/RAM as well as deep sleep capabilitiesand I/O pins, the MSPs were mainly built on ESP32 boards. Should RAM not bean issue and a single radio-link interface be sufficient, the Feather M0 or even thelow-power 32u4 are good alternatives with minimal power requirements.964.6 Environmental Monitoring Platforms for Disaster ScenariosEvaluation of Sensor RequirementsThe typical power requirements of different sensor types were measured, as shown inTable 4.8. The sensors range from simple temperature and particle sensors over GPSreceivers to complex optical systems such as (night vision) cameras.Table 4.8: Overview of different SensorsFunction Power in mWMean MaxMAX30105 Particle 19 145CCS811 VOC, TVOC, eCO2 52 186PIR PIR 51 55SIM28 GPS GPS 250 302BME280 Temp., Baro., Humidity 56 65MICS-2714 NO2 42 45MICS-5524 CO 41 60AMG8833 IR thermal 179 2248EnvirophatTemp., Baro., Color,Accel., Magnetometer180 1868Pi Camera NV Night Vision Camera 1173 2290Pi Camera v2.1 Camera 393 2231Most of these sensors consume an average power of about 50 mW or less. A notableexception is GPS with about 250 mW and the cameras with 393 mW / 1173 mW. Itis also noteworthy that the night vision camera draws 3 times as much power as theregular one. A simple 8x8 thermal imaging sensor, such as the AMG8833, on the otherhand, only consumes an average of 179 mW. When adding these sensors to an MSP orSSP, the maximum peaks must also be considered. These can go up to 2290 mW for theoptical sensors.Radio Link ComparisonsWe evaluated the power consumed by different MCUs with onboard radio transceivers,ranging from Wi-Fi to LoRa, as shown in Table 4.9. This table shows the powerconsumption from the MCUs with included radio transceivers. It is obvious that Wi-Ficommunication is at least twice as expensive as LoRa (TTGO ESP32), and in case of theFeather M0, about 10 times as expensive. There is also a bigger difference regardingLoRa power consumption when comparing both Feather devices (ca 46 mW) to theTTGO ESP32 (235 mW). Furthermore, sending via LoRa is much more expensive atroughly 528 to 816 mW. If more RAM and CPU power is needed or if more than oneradio transceiver with small physical dimensions is required, than the TTGO is the bestchoice. The Feather sticks are available only either with Wi-Fi or LoRa onboard.To evaluate the LoRa transceiver modules\u2019 communication range, we deployed oursensor box (Fig. 4.33) and measured the transmission range using one of our GPSmodules. We used ESP32 TTGO modules in various configurations. One chip wastuned to the 433 MHz band and equipped with a small wire antenna from the supplier.The next one was set to work in the 868 MHz band, also with the short vendor-supplied974 Disruption-tolerant Device-to-Device Emergency CommunicationFigure 4.33: Waterproof static sensor box deployed.Table 4.9: Power consumption of MCUs including radio transceiversPower in mWMean MaxESP32, TTGO, WiFi 591 1353ESP8266, Feather Huzzah, WiFi 405 2118Feather M0, WiFi 475 1577ESP32, TTGO, LoRa 235 816Feather M0, LoRa 45 528Feather 32u4, LoRa 47 568antenna. Finally, we set up another TTGO in the 868 MHz band but on a differentchannel with larger 3.5 dBi magnetic sucker antennas on both ends. The sendinginterval chosen for the fixed station was set to 7 seconds for each device.The city of Marburg is surrounded by many hills and forests, therefore, the sendingstation was deployed on a viewpoint near the university with line-of-sight to mostparts of the city. The receiving nodes were mounted on the dashboard of a car, and wedrove around the campus, through the city, up to the castle on the opposite side of thecity, and then along the valley, until we lost the signal. The route we took, includingreceived beacons, is shown in Fig. 4.34.The longest distance covered was almost 6.5 km with the 3.5 dBi sucker antenna. The433 MHz setup and the other 868 MHz node reached 1-2 km less, but with a muchhigher packet loss. Also, there was no more line-of-sight from either maximum distancepoints, it was blocked by hills, houses and trees. The 1.5-2 km distance to the downtownarea was covered by all three devices despite trees and houses in the way.The RSSI over distance is shown in Figure 4.35, where up to 2-3 km all devices stillreceived signals quite often. As expected, the 3.5 dBi antenna has the best receptionthroughout the test. This is especially clear for distances over 3 km where the duckantennas both fall short. The total number of received packets in percent can be seenin Fig. 4.36. The clear winner here, again, is the 3.5 dBi sucker antenna. Both stock984.6 Environmental Monitoring Platforms for Disaster ScenariosFigure 4.34: Communication range of different LoRa setups.antennas from TTGO perform very similar with reception rates between 10% and 15%during the test. Due to our constant movement and the diverse topographic areas, thesenumbers should be seen in relation to the sucker antenna, not as absolute numbers.Traffic might be responsible for remaining longer in areas where no reception waspossible, resulting in a higher overall packet loss rate.On-Device Data ProcessingFor on-device data processing, we used 1481 images for CPU and neural compute stickexecution. Each of these images is 3000 x 2000 pixels in size, since 6 mega-pixels are agood compromise between storage space and visual details. This dataset is described inour previous work [5]. For evaluation purposes, we built a Python tool to batch processthese images. First, the program loads the necessary libraries and the pretrained neuralnetwork, then the images are processed. The power consumption and time for the tasksis shown in Table 4.10.First, we compared the idle power consumption of the Pi 3 to one with an attachedneural compute stick. While the max peak is almost identical, the average power994 Disruption-tolerant Device-to-Device Emergency CommunicationFigure 4.35: RSSI vs. Distance Figure 4.36: Number of received packets in relationto packets sent.Table 4.10: Comparison of Concept Detection on Pi vs. Neural Compute StickIdle - Power in mW Starting - Power in mW Analysis - Power in mWMean Max Time Mean Max Time Mean Max Time per ImagePi 3b, 1K, CPU 1107 1845 59.29 sec. 2626 2895 19.66 sec. 2723 3537 13.27 sec.Pi 3b, 1K, Movidius 1955 2095 59.76 sec. 2372 2884 3.92 sec. 2760 3388 0.61 sec.Pi 3b, 6K, CPU 1107 1845 59.29 sec. 2659 3203 75.03 sec. 2871 3537 5.46 sec.Pi 3b, 6K, Movidius 1955 2095 59.76 sec. 2507 2879 12.64 sec. 3313 3667 0.82 sec.consumed is nearly double when a NCS is added. In the starting phase, the neuralnetwork is loaded either into RAM for the plain Pi 3 or onto the NCS. Both setups drawaround 2500 mW with a slight edge for the NCS setup. Taking runtime into account,the compute stick is clearly more efficient by loading the trained model 5-6 times faster.When performing the actual visual concept detection, the mean power is between 2723and 3313 mW and peaks at 3667 mW, with a slightly lower power demand by the CPUsetups. Given the much longer runtimes of the CPU version, 6x and 21x slower perimage, the NCS is still much more efficient, in terms of speed and energy. The maindrawback of the tested compute stick is its high power consumption when idle.This problem was solved by deactivating the specific USB port when the stick iscurrently not needed, reducing the power consumption overhead to zero.Setup CostSince we want to provide affordable solutions that can easily be customized to specificneeds, we also provide a short overview of the cost of our systems. All prices arein (rounded) Euro, taken in June 2018 from Amazon, Aliexpress etc. All our casesare custom printed on a 3D printer. We also did successful deployments with cheapwaterproof junction boxes from the local hardware store (<10 e).The cheapest system is our BLE LoRa Modem with a total system cost of about14 e (Table 4.11). A 750 mAh battery lasts roughly between half a day and a full day.This component can easily be swapped for a bigger battery or powerbank.1004.6 Environmental Monitoring Platforms for Disaster ScenariosTable 4.11: Cost of BLE LoRa ModemPart Estimate Price CommentTTGO LoRa SX1276 ESP32 9 e incl. antennaLiPo Battery 750mAh 3 e3D printed case 2 eTotal Price 14 eThe MSP example shown in Table 4.12 is usable for GPS tracking of larger animalsplus some added sensors for collecting weather data. In real world deployments with a750 mAh battery and gathering samples every 15 seconds, the power lasted for about 6days. With a reasonably lightweight and cheap 1500 mAh battery and a lower samplingrate, we can achieve runtimes over two weeks. The total cost for this setup is around46 e per device, mainly dominated by the price of the SD card for data logging and theGPS module.Table 4.12: Example configuration for a MSPPart Estimate Price CommentTTGO LoRa SX1276 ESP32 9 e incl. antennaLiPo Battery 1500mAh 3 e3D printed case 4 eUblox NEO GPS 12 e incl. antennaSD-Card Breakout 2 e32 GB SD Card 13 eReal Time Clock 1 eTemperature & Humidity Sensor 1 eGyro Sensor 1 eTotal Price 46 eIn Table 4.13, an SSP example, used for relaying data as well as actively gatheringsensor data and processing it on device, is shown. Depending on whether a computestick is used or not, the cost varies between 135 e and 201 e. The cost for a blankrelay-only system would be around 65 e. The rest is the cost of the added sensors andthe NCS. What this setup is lacking, is a power supply. Depending on the location ofdeployment, a battery system (20 e - 200 e) and/or a solar panel (50 e - 200 e) couldbe added if a direct power supply is not available.1014 Disruption-tolerant Device-to-Device Emergency CommunicationTable 4.13: Example configuration for a SSP (w/o power supply)Part Estimate Price CommentRaspberry Pi 3 32 eTTGO LoRa SX1276 ESP32 9 e incl. antenna3D printed case 10 eUblox NEO GPS 12 e incl. antenna32 GB SD Card 13 eReal Time Clock 1 eTemperature & Humidity Sensor 1 ePi Camera 20 e night vision opt.Movidius NCS 66 e optionallyThermal Imaging 32 eRain Sensor 1 eSoil Moisture 3 ePIR Motion Detector 1 eTotal Price 135 e / 201 e4.6.6 ConclusionIn this section, a flexible and affordable sensor, computation, and communicationplatform for environmental monitoring was presented. Solutions for static and mo-bile setups, and integrated mobile devices, such as smartphones, into long-rangeinfrastructureless radio networks were provided. Apart from evaluating typical powerrequirements of common hardware platforms and sensors, LoRa radio transceiverswere also included in the study and evaluated regarding their realistic communicationranges. Furthermore, to make optimal use of these long-range, low-bandwidth links,a solution to on-device preprocessing of image data using neural compute sticks wasprovided in an energy efficient and computationally fast way. Finally, the expected costsof the subsystems used in the evaluation were presented. The components developedfor the setups, such as the rf95 modem firmware, the BLE modem, Serval LBARDsupport, and the software customized for the Raspbian distribution, are all released asopen source software on github.In the future, the possibilities of direct device-to-device communication via cheapLoRa addons for smartphones should be used more extensively. This opens possibilitiesfor new apps on mobile devices, such as infrastructureless messaging, or using a phonefor sensing and remote control tasks. Furthermore, the usefulness of DTN softwaredirectly on the MCUs based on miniDTN should be explored. Finally, the integrationof energy harvesting solutions would also increase the flexibility of the system whendeployed in remote places.1024.7 Applications for Disaster Response: SmartFace4.7 Applications for Disaster Response: SmartFace4.7.1 IntroductionDuring many natural or man-made disasters, a common task is to find missing persons.For this purpose, Facebook and Google offer services such as Safety Check68 or PersonFinder69, respectively. However, both services require a working Internet connectionand thus cannot be used when telecommunication infrastructures of mobile phoneoperators fail. In such emergency situations, smartphones, tablets and/or batterypowered wireless routers can be used alternatively to spontaneously establish a disaster-response communications network to share data in a peer-to-peer fashion.To support the search for missing persons, photos taken by mobile device usersstaying inside a disaster area can be spread around using disruption-tolerant networking(DTN) [56]. Since CPU power, memory space, and battery capacity of mobile devices arelimited, the size of the photographic image data can be reduced by detecting persons\u2019faces in images and transmitting only the extracted faces. In many cases, faces onlymake up a small fraction of a complete photo, and only sharing these over a wirelesson-demand emergency network would significantly save resources.For desktop and server systems, several face detection libraries with different prop-erties in terms of recall and precision are available, but their resource requirementsdo not match with the resources of today\u2019s mobile devices, since the latter still onlyprovide a fraction of the computing power offered by a contemporary workstation.In this section, a novel approach, called SmartFace, to perform face detection insitu on smartphones or tablets in an efficient manner is presented. The approach isbased on a novel two-stage combination of state-of-the-art face detection algorithms,further enhanced by region of interest selection, color space/depth reduction, resolutionscaling, face size definition, image scaling, image cropping, and bounding box scaling.SmartFace improves the face detection rates within the same runtimes or obtains thesame face detection rates within faster runtimes compared to the individual facedetection algorithms used alone, and also reduces the amount of data that needs to bestored on disk and sent over the network. As a consequence, the battery life of mobiledevices is extended, too. The main contributions are:\u2022 A novel two-stage processing pipeline for resource-efficient face detection onmobile devices, with improved overall face detection rates and runtimes.\u2022 An experimental study of image preprocessing parameters to obtain algorithmagnostic speed gains.\u2022 Methods to reduce our original image data set by a factor of 133, indicatingsignificant savings of network bandwidth and disk storage resources.Parts of this section have been published in [5].4.7.2 Related WorkEmergency communication networks [49] typically rely on radio technologies, suchas Bluetooth, LoRaWAN, WiFi, TETRA digital radio or satellite links. They either68https://www.facebook.com/about/safetycheck/69https://google.org/personfinder/global/home.html1034 Disruption-tolerant Device-to-Device Emergency Communicationuse telecommunication infrastructures, are distributed (peer-to-peer, mobile ad-hocnetworks), or form hybrid architectures of both.Several approaches utilize commodity mobile devices to realize hop-to-hop DTN[28], [56], [57]. Due to their peer-to-peer nature, they are well suited for (post-)disasterscenarios. Projects such as FireChat70, Briar71, Serval72 and Forban73 transfer messagesand files between heterogeneous devices and share them locally through store-and-forward technology.Furthermore, several face detection algorithms have been proposed. Viola and Jones[105] offer an approach in OpenCV that accelerates face detection. The tradeoff is thatwith an increased detection rate, the false positive rate also increases.Felzenswalb et al. [106] present an object detection system for dlib. Since a slidingwindow over an entire image in different resolutions is used, the runtime increaseswith increasing image size. Therefore, small interesting regions within an image shouldbe selected before the algorithm is applied.Cheney et al. [107] perform a comparison of face detection algorithms. The authorsstate that often used test sets, such as Labeled Faces in the Wilf (LFW)[108] and YouTubeFaces [109], do not pose any challenges for current algorithms and should not be usedany more for benchmarking. Instead, they use the IARPA Janus Benchmark-A facechallenge (IJB-A)[110] that consists of over 5000 images and 20,000 video frames forbenchmarking, The main open source algorithms highlighted in their paper are fromDlib and OpenCV, the first one with good detection rates and the second one being oneof the fastest.The typical approach to perform face detection on mobile devices is to offload imagesto a server and run a face detection algorithm on the server [111], [112]. Using powerfulservers makes it much easier to achieve good face detection rates, but in an emergencyscenario such servers are often not available.Feng et al. [113] present a cascaded classifier approach that has also been testedon a Samsung S6 smartphone, resulting in a runtime of 34 ms for detecting faces ina 640 x 480 pixel photo. Compared to current 8 or 16 megapixel cameras in today\u2019ssmartphones, this size is very small, and no public code is available to verify the results.4.7.3 SmartFace\u2019s DesignThe goals of SmartFace are as follows:\u2022 Since the recognized faces have to be stored on mobile devices and transferredover wireless links, the size of the required data should be minimized. This alsomeans that the false positive rate of the used face detection approach should beas low as possible.\u2022 Since a data transfer can only happen after face detection has finished, the runtimeof the used face detection approach should be minimized. This also means that thefalse negative rate and the false positive rate of the used face detection approachcannot be minimized at the same time, but the false negative rate should be as low70http://opengarden.com/firechat71https://briarproject.org/72http://www.servalproject.org73http://www.foo.be/forban/1044.7 Applications for Disaster Response: SmartFaceresults resultsfirst detection stagesecond detection stageFigure 4.37: Basic two-stage face detectoras possible in accordance with the available computational resources on mobiledevices.To achieve these goals, the basic idea is to develop a two-stage processing pipelinein which the first stage is responsible for quickly selecting interesting regions in agiven image, and the second stage performs in-depth face detection and validationin the interesting region selected in the first stage (see Fig. 4.37). Thus, the first stageis optimized for speed, favoring high recall over high precision. The second stage isoptimized for quality, favoring high precision over high recall. By using adequate facedetection algorithms that support the competing objectives of each stage, overall speedand quality improvements can be achieved.This two-stage face detection approach can be flexibly configured to the preferencesof a particular usage scenario, e.g., (a) by reducing the runtimes to save battery power,(b) by improving the quality of the face detection results by running the algorithms fora longer time, or (c) by trying to get the best results in a fixed amount of time.There are several parameters that can change the runtime and the quality of theresults of a face detection algorithm without changing the algorithm itself. To supportthe goals of SmartFace, the following set of parameters and their values are considered:Color space: color / greyscale / black-and-whiteColor depth: 24-bit / 8-bit / 1-bitResolution: 100 \u2264 n \u2264 5000 in steps of 100 pixelsImage scaling: area, cubic, lanczos4, linear, nearest interpolationCropping: remove from each border 0%, 10%, 20%, 30% of the full imageFace size: min: 80 x 80 pixels; max: 1000 x 1000 pixelsBounding box scaling: 50 \u2264 n \u2264 500 in steps of 50Some of these parameters are relevant for operations in a preprocessing step, whileother parameters are applied to the first or second detection stages, respectively, asshown in Fig. 4.38. For example, having a larger bounding box in the second stagemight increase the number of results, but might overlap with nearby faces in thesame region. Here, duplicates have to be detected and eliminated. This is achieved byallowing bounding boxes to overlap to a certain degree after the second detection stage.4.7.4 ImplementationThe implementation of SmartFace is based on three main components. The first compo-nent handles the parameters and the preprocessing steps. The second component is afast face detection algorithm for the first stage of SmartFace to select regions of interest.The third component is a high-quality face detection algorithm for the second stage ofSmartFace to operate on the selected regions of interest.1054 Disruption-tolerant Device-to-Device Emergency Communicationpreprocessingfirst detection stage second detection stagecolorcolor depthresolutionmin face sizemax face sizeincrease bounding boxresultsimage sectionFigure 4.38: Two-stage face detector, preprocessing, and parametersFigure 4.39: SmartFace in actionOpenCV\u2019s Viola/Jones algorithm [105] is used in the first stage, since it is a commonout-of-the-box solution for face detection, in contrast to OpenCV\u2019s SURF that is alsosuitable for general object detection. It is comparatively fast [107], but has a relativelyhigh false positive rate (which is acceptable as a pre-filter), as shown in Fig. 4.39 by theblue bounding boxes in each image. Dlib is used in the second stage. It is slower thanthe Viola/Jones algorithm, but has a lower false positive rate and a higher precision[107]. The faces detected by dlib are shown by the yellow bounding boxes in Fig. 4.39.All parameters except the face sizes are independent of the used face detectionalgorithms. Therefore, the algorithms can be replaced by alternatives, still benefitingfrom the rest of the optimizations. The entire program flow is shown in Figure 4.40.To determine suitable parameters for the scenario, a parameter scan by creatinga test environment in Bash and using the created API to automatically iterate overthe parameter sets using the image test set is performed. The parameter scan is firstexecuted with dlib to match the results to the behavior of OpenCV. The results arepresented in Section 4.7.5.4.7.5 Experimental EvaluationTest EnvironmentThree different devices are used in the experimental evaluation, as shown in Table 4.14:(a) a workstation as a reference platform, (b) a high-end smartphone (OnePlus 3T), and(c) an older mid-range tablet (Nexus 7). The workstation operates under Ubuntu 16.04LTS, and both Android devices use the latest Android release 6.0.1.1064.7 Applications for Disaster Response: SmartFacepreprocessingOpenCVdlibmin face size max face sizebounding boxcolorcolor depthresolutionimage sectionresultfile path imagemodifytransformFigure 4.40: SmartFace implementationTable 4.14: Device SpecificationsDevice CPU RAM StorageWorkstation Quad-core (i7-2600 @3,4GHz) 8GB 256 GB SSDOnePlus 3T Quad-core (2x2,35 GHz & 2x1,6 GHz) 6GB 128 GB FlashNexus 7 Quad-core (4x1,5GHz) 2GB 32 GB FlashImage Test SetTo evaluate SmartFace on realistic images taken during emergency scenarios, an own testset by randomly was created by downloading images from the Internet (two examplesare shown in Figure 4.41) using one of the scenario specific search terms from thefollowing list: haiti earthquake, haiti earthquake people, haiti earthquake faces, earthquakefaces, earthquake people, disaster people, disaster faces, disaster management, flooding people,flooding faces, natural hazard people, natural hazard faces, tsunami people, tsunami faces, nightbushfire, bushfire people, firefighter disaster, explosion people, accident people, syrian civil war,crowd, crowd disasters, crowd control, crevices earthquake.A crawler for Google Images was developed and it downloaded the top 100 searchresults, finally obtaining a total of 2,400 images. Duplicates were removed prior to usage.The crawler downloads images with a resolution of 3000 x 2000 pixels. Thus, theseimages correspond to photos taken by a 6 megapixel camera. Current smartphones cantake photos with a higher resolution, but in a typical disaster scenario it is not realisticto assume that top-notch hardware is commonly available. Thus, 6 megapixel photosare quite realistic and much more sophisticated than commonly used face detectiontest sets, such as LFW where images have a resolution of 250 x 250 pixels, and a largeimage part is covered by a face.After removing duplicates, the test set consists of 1,481 images. This leads to 2.8 GBimage data that needs to be processed in the benchmarks. In addition, the faces for eachimage in our test set were manually labeled. It contains 2,419 faces to be detected. A list1074 Disruption-tolerant Device-to-Device Emergency CommunicationFigure 4.41: Examples from image test set0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)05001000150020002500runtime per image (ms)colorgreyscaleblack and white(a) Runtime0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)05001000150020002500detected facescolorgreyscaleblack and whitenumber of labeled faces(b) Detected faces0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)012345total runtime / detected facescolorgreyscaleblack and white(c) Runtime / facesFigure 4.42: Comparison of different color spaces and depths.with 2-D coordinates is stored for each image in the test set. These coordinates representa central point in the face, in many cases this is the tip of the nose. Furthermore, therule suggested by Cheney et al. [107] to only mark faces where both eyes can be seenwas followed.Parameter ScanTo evaluate the selected parameters, the results achieved with dlib are presented below;each preprocessing experiment is repeated 10 times. The results using OpenCV aresimilar.Color Space and Depth In this experiment, the 24-bit input image is reduced to an 8-bit greyscale image and to a 1-bit black-and-white image. As indicated by Fig. 4.42a, theruntimes for greyscale and black-and-white images are nearly identical, and both arefaster than for the fully colored image. This effect increases with increasing image size.Changing color space and depth also affects the detection rates, as shown in Fig. 4.42b.Using a greyscale image produces almost as good results as using the original image,but black-and-white yields significantly worse results. Fig. 4.42c shows the combinationof the first two graphs; lower numbers are better. Again, greyscale and full color imagesare similar in their score, with a slight edge for greyscale due to its runtime being fasterthan its decrease in detection rate.1084.7 Applications for Disaster Response: SmartFace0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)012345total runtime / detected facescolor areacolor cubiccolor lanczos4color linearcolor nearest(a) Color images0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)012345total runtime / detected facesgreyscale areagreyscale cubicgreyscale lanczos4greyscale lineargreyscale nearest(b) Grey scale imagesFigure 4.43: Number of detected faces per detection time for different resolutions.0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)05001000150020002500runtime per image (ms)10% cropped20% cropped30% croppedfull image(a) Runtime0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)05001000150020002500detected faces10% cropped20% cropped30% croppedfull imagenumber of labeled faces(b) Detected faces0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)012345total runtime / detected faces10% cropped20% cropped30% croppedfull image(c) Runtime / facesFigure 4.44: Comparison of cropped areas from grey scale images.Image Scaling These experiments are performed on the original and greyscale images;black-and-white is not considered due to the results from the color space tests. Althoughthe most common interpolation mechanisms for scaling images such as linear, area,cubic, nearest and lanczos4 produce slightly different images, they are all comparable interms of runtime and number of detected faces (see Fig. 4.43).Image Cropping The next parameter evaluated is cropping the greyscale image. Foreach image, 0%, 10%, 20% and 30% are cut off from each border, reducing the imagesize, but also reducing areas where possible faces could be detected. As expected,image cropping reduces runtimes, even more when an original image is upscaled,as shown in Fig. 4.44a. Cropping the image by 30% from each border significantlyreduces the number of detected faces, while cropping 10% decreases the detectionrate only slightly (see Fig. 4.44b). Combining both scores shows an interesting resultin Figure 4.44c where no single strategy wins. The behavior changes between 1,500and 2,000 pixels. Cropping around 10% gives the most reliable results independent ofimage size. However, since not many portrait photos can be expected in our emergencyscenario, one cannot assume that humans are always centered in the images, thereforecutting off the edges might miss important information.1094 Disruption-tolerant Device-to-Device Emergency CommunicationTable 4.15: Contingency table for dlibfaces detected undetectedlabeled faces 1,194 1,226 Recall (R): 0.49unlabeled areas 178 \u2014Precision (P): 0.87 F1-Score: 0.63Table 4.16: Contingency table for OpenCVfaces detected undetectedlabeled faces 1,967 502 Recall (R): 0.79unlabeled areas 6,106 \u2014Precision (P): 0.24 F1-Score: 0.37Face Detection ComparisonNext, the face detection quality of the dlib and OpenCV algorithms are compared. Tables4.15 and 4.16 show that dlib is superior with an overall F1 score of 0.63 compared to the0.37 of OpenCV. However, the recall value of 0.49 for dlib is much lower than the recallvalue for OpenCV with 0.79, whereas the precision of dlib with 0.87 clearly outperformsOpenCV with a precision of 0.24. This confirms that OpenCV is well suited for the firststage of SmartFace, while dlib is an ideal candidate for the second stage.Table 4.17 shows the results for combining both algorithms within SmartFace whereit was tried to run SmartFace as fast as possible to obtain roughly the same number ofdetected faces as dlib. In contrast, in Table 4.18 SmartFace was given the same amountof time as dlib, leading to a higher precision of 0.93 and also a higher recall of 0.70compared dlib. This also results in a higher F1 score of 0.80 compared to 0.63 of dlib.Table 4.17: Contingency table for SmartFace (faster runtime)faces detected undetectedlabeled faces 1,172 1,263 Recall (R): 0.49unlabeled areas 238 \u2014Precision (P): 0.83 F1-Score: 0.61Table 4.18: Contingency table for SmartFace (higher quality)face detected undetectedlabeled face 1,741 732 Recall (R): 0.70unlabeled area 129 \u2014Precision (P): 0.93 F1-Score: 0.80Compared to using color or greyscale images in dlib, SmartFace is up to two timesfaster depending on the image size, as shown in Figure 4.45a. The overall number ofdetected faces is only slightly smaller, particularly when compared to standard greyscale1104.7 Applications for Disaster Response: SmartFace0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)05001000150020002500runtime per image (ms)colorgreyscaleSmartFace (greyscale)(a) Runtime0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)05001000150020002500detected facescolorgreyscaleSmartFace (greyscale)number of labeled faces(b) Detected faces0 500 1000 1500 2000 2500 3000 3500 4000width (number of pixel)012345total runtime / detected facescolorgreyscaleSmartFace (greyscale)(c) Runtime / facesFigure 4.45: Overall benchmark80% dlib90% dlib95% dlib100% dlibdlib time maxoptimized timeoptimized detection0500100015002000number of detected faces and times (ms)dlib facesdlib runtime in msfacesruntime in msFigure 4.46: Best of all categoriesdlib vs SmartFaceoptimized time (i7)optimized detection (i7)optimized time (One Plus 3T)optimized detection (One Plus 3T)optimized time (Nexus 7)optimized detection (Nexus 7)010002000300040005000600070008000number of detected faces and times (ms)labeled facesruntime in msfacesFigure 4.47: Direct comparison of devices(Fig. 4.45b) images resulting in the best overall score, as indicated by Figure 4.45c.Figure 4.46 shows a comparison of the best parameter combinations. The two hori-zontal lines are the baselines of dlib for runtime and number of detected faces withoutpreprocessing, respectively. With an increased number of detected faces (80-100%), theruntime also increases for dlib with preprocessing. When reaching 100%, the runtimeis still slightly better than dlib without preprocessing. Giving dlib with preprocessingthe same amount of time as dlib without preprocessing results in a few more detectedfaces. On the other hand, SmartFace (i.e., the red/blue bars denoted by optimized timeand optimized detection) is almost twice as fast as dlib with preprocessing, when limitedto the same number of detected faces. If SmartFace gets the same amount of time as dlibwith preprocessing, the number of detected faces increases significantly.Device PerformanceA comparison (see Fig. 4.47) of SmartFace running on all three devices shows that thehigh-end OnePlus 3T is about 2-4 times slower than the i7 workstation. The slightlyoutdated mid-range tablet Nexus 7 is about twice as slow as the OnePlus 3T. All threedevices yield about the same high face detection rate, but the runtimes range between3 and 7 seconds for the mobile devices. For an emergency scenario with a DTN sharingphotos, these runtimes are sufficiently fast.The individual performance of the three devices is shown in Fig. 4.48. Across all1114 Disruption-tolerant Device-to-Device Emergency Communicationdlib OpenCV optimized time optimized faces0100020003000400050006000700080009000number of detected faces and times (ms)labeled facesruntime in mscorrect detected facesall detected faces(a) Computer i7dlib OpenCV optimized time optimized faces0100020003000400050006000700080009000number of detected faces and times (ms)labeled facesruntime in mscorrect detected facesall detected faces(b) OnePlus 3Tdlib OpenCV optimized time optimized faces0100020003000400050006000700080009000number of detected faces and times (ms)labeled facesruntime in mscorrect detected facesall detected faces(c) Nexus 7Figure 4.48: Individual device performanceTable 4.19: Transmission times for various link types100 Kb/s 2.1 Mb/s 54 Mb/s 150 Mb/s2.8 GB 3,734 Min 177.78 Min 6.91 Min 2.49 Min18 MB 24 Min 1.14 Min 0.044 Min 0.016 Mindevices, OpenCV is clearly the fastest algorithm, but with an unacceptably high falsepositive rate. Figure 4.48a shows that depending on whether SmartFace is optimizedfor time or detection rate, it clearly outperforms dlib. Even on the resource-constraintmobile devices, the number of detected faces is increased.Storage and Bandwidth SavingsThe complete full image test set is about 2.8 GB in size. When applying SmartFace, thisleads to 18 MB of face images for the runtime-optimized variant and around 24 MB forthe quality-optimized variant. Thus, SmartFace reduces the data roughly by a factor of133 to 0.75% of its original size. This indicates how much storage space and networkbandwidth can be saved when applying SmartFace prior to sharing data in a wirelesson-demand hop-to-hop emergency network.For illustration, Table 4.19 shows the transmission times of sending either the full2.8 GB or the reduced 18 MB data set over different wireless link types: (a) 100 Kb/s(e.g., LoRaWAN), (b) 2.1 Mb/s (e.g., Bluetooth), (c) 54 Mb/s (e.g., WiFi 802.11g), (d)150 Mb/s (e.g., WiFi 802.11n). Of course, the runtimes of SmartFace must be added tothe transmission time at the first node. Since for a single image they range from 665ms on the i7 over 3.4 s on the OnePlus 3T up to 7.3 s on the Nexus 7, the runtimes forwhole image test set are roughly 16 min, 84 min and 180 min, respectively. Therefore,there are different break-even points for the three devices. Fig. 4.49 shows that dueto its computational power, the i7 already pays off after 1-3 hops of transmissions formost link types; only for fast WiFi it takes about 8 hops to pay off, which is a quite lownumber in a scenario of DTN store-and-forward with epidemic routing. When lookingan the slowest links such as LoraWAN and Bluetooth transmitting 2.8 GB of data is notrealistic. Therefore, good compression or data reduction is a necessity. For both mobiledevices, the break-even point for the faster WiFi connections is 12 hops or higher. Sincethese are hop-to-hop transmissions instead of classic TCP/IP connections and data willeventually be passed to every participant in the area, quite high hop-counts are likely1124.7 Applications for Disaster Response: SmartFace0 2 4 6 8 10 12 14 16hops0100200300400500runtime (min)LoraWan full setBluetooth full setWiFi (54Mb/s) full setWiFi (150Mb/s) full setLoraWan prev face detectionBluetooth prev face detectionWiFi (54Mb/s) prev face detectionWiFi (150Mb/s) prev face detection(a) i70 2 4 6 8 10 12 14 16hops0100200300400500runtime (min)LoraWan full setBluetooth full setWiFi (54Mb/s) full setWiFi (150Mb/s) full setLoraWan prev face detectionBluetooth prev face detectionWiFi (54Mb/s) prev face detectionWiFi (150Mb/s) prev face detection(b) OnePlus 3T0 2 4 6 8 10 12 14 16hops0100200300400500runtime (min)LoraWan full setBluetooth full setWiFi (54Mb/s) full setWiFi (150Mb/s) full setLoraWan prev face detectionBluetooth prev face detectionWiFi (54Mb/s) prev face detectionWiFi (150Mb/s) prev face detection(c) Nexus 7Figure 4.49: Comparison of transmission and optimization times on various devices.in an emergency scenario. In reality, the impact of the runtimes on each mobile is muchless, since no mobile device would input 3 GB of data at once, but each device wouldprocess its own images. A photo taken every now and then, processed directly andthen shared epidemically does not have much influence on a single mobile device, butfor the whole network, the consumed bandwidth and storage resources are influencedin a significant manner, as stated above.4.7.6 ConclusionSmartFace is a novel approach to perform face detection on mobile devices in an efficientmanner for supporting the search for missing persons in wireless on-demand emergencynetworks. The approach relies on a two-stage combination of existing face detectionalgorithms, enhanced by region of interest selection, color space/depth reduction,resolution scaling, face size definition, image scaling, image cropping, and boundingbox scaling. Experimental results have shown that the proposed approach improvesboth the overall face detection rate and the overall runtime compared to each of theindividual face detection algorithms used alone, and also reduces the amount of datathat needs to be stored on disk and sent over the network.There are several areas for future work, such as (a) exploring the use of visualconcept detection algorithms as filters to determine whether humans are present inan image; the most computation-intensive parts of SmartFace can then be skipped ifno persons are present, (b) improving the runtimes of SmartFace on mobile devices byutilizing multiple CPU cores or GPUs, (c) applying SmartFace to non-scenario specificimage sets (e.g., LFW or FDDB) for a general evaluation of our optimizations, and(d) combining SmartFace\u2019s offline face detection capabilities with a decentralized on-device face recognition approach to find missing persons or family members by justparticipating in a DTN and relaying data.1134 Disruption-tolerant Device-to-Device Emergency Communication4.8 Applications for Disaster Response: UV4EC4.8.1 IntroductionRescue operations during and after disasters often expose rescue teams to high risks.Therefore, more and more unmanned vehicles (UVs) are used on the ground, in the airor in the water to support rescue operations. Typically, such UVs operate either in asemi-autonomous manner or are completely controlled by remote human operators.For example, in the ruins of Fukushima Daiichi remotely controlled robots were sent tohighly contaminated areas. Remote control requires a reliable communication infras-tructure to coordinate UVs and to increase their operation radius significantly. However,during the first hours of a disaster event, the existing communication infrastructuremight be severely damaged, disrupted or overloaded due to network congestion. Thus,re-establishing basic ways of communication during a disaster despite fragmented IPnetworks and totally or temporarily disrupted network links is a key step in successfuldisaster management and rescue operations.An emergency communication system should not only support UVs, but also humanrescuers and civilians who are still in the disaster area. Since connectivity cannotbe easily established in the entire affected area, it is more likely that small islandsof devices connected to each other will evolve, with limited bridges between theseislands. These islands can be formed by team members operating in the field, peopletrapped in houses or waiting in temporary shelters, and clusters of cooperating UVs.By using store-carry-forward technologies, humans or UVs can act as carrier pigeonsand deliver data between islands, thus spreading information in an epidemic fashion.This approach can be used for person-to-person communication, in a way similar toSMS and various messengers, or for sensor data such as images from smartphones ortemperature and Geiger counter readings from UVs that are shared with the public.Gathering this information and processing it in the rescuers\u2019 operations and controlcenter is helpful for situation analysis and coordination of rescue endeavors. In general,long distance, real-time unicast communication is not possible in such a scenario.The chances of establishing a successful multi-hop connection to a specific node areincreased by altering the objectives of UVs, such as drones, to incorporate air bridgesas part of their mission. In this case, a secure mesh routing algorithm is needed forreal-time communication in the emergency communication system.Here, a novel emergency communication system that relies on delay-/disruption-tolerant networking (DTN) for non-time critical tasks and direct mesh connections forprioritized tasks that need real-time feedback is presented. It is used for the distribu-tion of sensor data, human-to-human communication, as well as direct and indirectcontrol of unmanned ground vehicles (UGV) and unmanned aerial vehicles (UAV).To demonstrate the real-world applicability of the developed emergency communica-tion system, called UV4EC (Unmanned Vehicles for Emergency Communication), it isrunt on RoboCup Rescue proven [114] robots as well commodity mobile devices, andvarious drones, and support our operations and control center software for disastermanagement. Experimental results indicate that a combined DTN and mesh networkingapproach is a good compromise for providing emergency communication based onsemi-automatic and remotely controlled autonomous UVs. In particular, the followingcontributions are made:1144.8 Applications for Disaster Response: UV4EC\u2022 A novel hybrid DTN and mesh networking communication middleware fordisaster scenarios.\u2022 A novel approach to emergency communication where a semi-autonomous UGVestablishes UAV-based communication bridges between dynamically formingcommunication islands of mobile devices.\u2022 An operations and control center for commanders to get a more complete situationoverview of the disaster scenario and to control the rescue mission by sendinghigh-level commands to mobile rescuers or UVs.Parts of this section have been published in [7].4.8.2 Related WorkSeveral approaches that address emergency communications needs have been presentedin the literature [49]. Some of them require special hardware (e.g., radio-link technolo-gies or satellites), are engineered for specific tasks, or are not usable on consumer-gradehardware with commodity operating systems [50], [52], [53], [55], [60], [115]\u2013[117]. Sinceour focus is to enable as many people as possible to communicate in an emergencynetwork, our approach attempts to leverage commodity hardware and software, suchas WiFi-enabled mobile end-user devices, where possible.Other research has shown that DTNs and mesh networks are viable solutions inemergency scenarios [51], [56], [118], [119]. By leveraging ubiquitous mobile devices,such as smartphones or tablets, novel communication solutions have been proposed [57],[59], [120]\u2013[122] and evaluated [123]. Since both DTNs and mesh networks have distinctcapabilities, we incorporate a dual networking stack in UV4EC, which uses meshnetworking for real-time communication and DTN for data sharing and messaging.While the use of both UAV and UGV systems (and their combination) for search andrescue applications has received considerable attention from the research community[124], the combination of robots with both DTN and mesh networking has not beenstudied extensively. However, based on the experiences with real-world deployments[125], [126] and the associated communication difficulties, this appears to be a promisingdirection of research. While mesh-based approaches have been used successfully withUVs before [127], the body of research on the additional use of DTN with UVs is limitedto mainly theoretical results [128]\u2013[130].Collecting, analyzing, and visualizing emergency data at a central point (e.g., ina control center) to provide a situation overview for rescuers is crucial in disastermanagement [131]. However, many proposed control centers are stationary and relyon centralized approaches, assuming Internet connectivity to exchange data or tocontrol UGVs [132]. Only a few control centers have been designed for mobile use anddecentralized communication [133], [134]. For instance, the SENEKA project presents anadaptable and scalable ground control station integrated in a van for gathering sensordata from stationary sensors, mobile ad hoc networks and mobile sensor platforms [134].In addition to the data channel, it establishes a control channel to control UVs in the field.Inspired by this work, here a lightweight offline control center is presented, runningon a customary laptop for mobile use and relying on mesh networking and DTN fordecentralized communication while providing a similar range of functions as state-of-the-art approaches, namely data gathering, fusion and processing, providing visual1154 Disruption-tolerant Device-to-Device Emergency CommunicationFigure 4.50: Emergency communication scenariosituation overviews, as well as realtime and delay-tolerant control of semi-autonomousUAVs and UGVs.4.8.3 UV4EC\u2019s Design and ImplementationThe design of UV4EC supports unmanned vehicles and professional responders aswell as civilians in the affected area. All communication links can be volatile andconnectivity is expected to be lost. Given an opportunity to exchange data, each peerwill communicate with all of its neighbors for maximum data distribution, as indicatedin 4.50.Unmanned Ground VehiclesThe UGVs used in UV4EC employ ROS as a robotics middleware. ROS has becomethe de-facto standard in the robotics community in recent years. Based on a modularsoftware design, components for different tasks like navigation and perception can beexchanged and adjusted for use with different vehicle platforms. For UV4EC, we use atracked mobile robot based on the Taurob Tracker platform. To support multimodalsensing in disaster environments, the robot is equipped with a comprehensive sensorsuite consisting of (among others) a spinning 3D LIDAR, a thermal camera, a 30xoptical zoom camera, and a depth camera. The camera sensors are mounted on a sensorarm to provide flexibility in sensor positioning. The robot can perform autonomousexploration of unknown environments, using a Simultaneous Localization and Mapping(SLAM) approach to learn the environment and map and simultaneously localize objectswithin the environment [135]. The robot operator can select between teleoperation orautonomous operation at any time.Unmanned Aerial VehiclesSince the focus is on the communication aspects and to avoid the (administrative andorganizational) overhead of deploying real UAVs, multiple simulated UAVs based onthe Gazebo simulator are used. It allows us to simulate multiple UAVs with dynamics.The UAVs establish communication bridges between UGVs and the operations andcommand center (OCC) from time to time, i.e., the UAVs should position themselvesnear specific prescribed locations between UGVs and the OCC to enable communica-tion. The task of allocating and getting to these positions is solved cooperatively anddecentrally; necessary control inputs for each UAV are computed locally on board ofthe UAVs by applying a feedback and optimization-based vehicle controller [136], [137].This vehicle controller uses a mixed logical dynamical (MLD) approach to model themulti-vehicle system [138] consisting of every UAV within the communication radius.1164.8 Applications for Disaster Response: UV4ECBased on the MLD formulation, an optimal control problem is set up, in which thenumber of and distance to unoccupied bridge locations is minimized subject to vehicledynamics, allocation logic and constraints regarding collision avoidance. This optimalcontrol problem is solved over a limited time horizon in a model predictive controlfashion so that a mixed integer linear program has to be solved in every time step. Thefirst elements of the resulting control input sequence are applied by each individualUAV.Emergency CommunicationIn disaster scenarios, a number of communication services and applications are requiredto ensure effective disaster response. These applications include human-to-human(message-based) communication, sensor data sharing for situational reporting, and also\u201creal-time\u201d control channels for operating UGVs and UAVs from a remote location.Unfortunately, during a disaster, the local communication infrastructure, such as celltowers and Internet-connected WiFi hotspots that would normally be used to supportthese applications, might be unavailable either due to poor coverage at the disaster siteor because it has been destroyed by the disaster.Thus, the design decision to rely on decentralized ad-hoc communication technologiesto provide connectivity in such extreme environments. To enable a wide range ofapplications with different communication requirements, a dual networking stackconsisting of (i) a mobile cloud based on delay/disruption-tolerant networking that canbe used for messaging and information sharing applications, and (ii) a highly adaptiveend-to-end communication protocol based on wireless multi-hop routing that quicklyfinds and exploits communication bridges and can be used for control applicationswith \u201creal-time\u201d feedback is employed. The two components are presented in detailbelow.Mobile CloudIn a network consisting of many mobile and fast-moving nodes including UGVs andUAVs, the contact times between two nodes are typically short. When communicationlinks are only available for short periods and in the near vicinity, classical multi-hop routed network communication is hardly possible. As an alternative, store-carry-forward based DTN has been proposed especially for challenged environments such asspace communication and emergency communication. In DTN, nodes are considered as\u201cdata mules\u201d: they carry their own messages as well as messages from others. When twonodes meet, they exchange all messages they are carrying by replicating them. Usingthis approach, messages are spread in an epidemic fashion throughout the network,which increases the chances that a message eventually arrives at its destination. In DTN,delivery performance highly depends on node mobility. This makes it attractive for adisaster scenarios where mobile devices of civilians and professional disaster responsestaff as well as UGVs and UAVs are present and physically move around. Due to itsbest-effort service, DTN is suitable for applications such as text messaging, collectingsensor data, and transmitting geo-location updates.This research relies on the Serval Project74 to realize a DTN protocol for UV4EC.74http://www.servalproject.org1174 Disruption-tolerant Device-to-Device Emergency CommunicationServal provides basic messaging with built-in end-to-end encryption and a portableC code base for further extensions. To verify the viability of Serval in our disasterscenario, an in-depth performance analysis of the existing protocol and software wasconducted in Section 4.3. Based on the results, the protocol overhead was reduced bydynamically adjusting the neighbor announcement interval (Sec. 4.4) and transparentcomputation task offloading was implemented to preserve local resources (Sec. 4.5).To allow the integration of Serval in UV4EC, pre- and post-receive message filters aswell as content hooks that are triggered when manipulating the data store75,76 weredeveloped. Furthermore, more advanced features such as append-only sensor logs andfile updates for rapid prototyping and deployment in the field are supported.77 For non-mobile users, custom ways of interfacing with the Serval application are currently indevelopment, including a web interface78, standalone desktop application79, and a full-screen console application80. The final system enables any WiFi-enabled UNIX-basedsystem, such as smartphones running Linux, Android, or MacOS, to communicate witheach other. This includes one-to-one encrypted text messaging and file transfers, andpublicly shared information such as images or position logs. It can easily be ported andused by new specialized systems such as rescue robots, drones or static sensor nodes inaddition to the ones we are already using.Communication BridgesCertain applications, such as directly controlling a UGV or UAV, require real-time com-munication. This cannot be realized using the mobile cloud, since it does not providedelivery guarantees or feedback. Therefore, control messages might never or only verylately reach their destinations, which would render UGV/UAV control unreliable. Tosolve this problem, it is resorted to classical store-and-forward routing where messagesare forwarded from one node to the next node until it reaches its destination. If adestination is not reachable, for example, because the network is partitioned or thenode has moved out of range, messages should be dropped: in this case, there is noneed to buffer packets, since one is not interested in late deliveries. However, thesystem should be able to notify the user in a timely manner that communication wasunsuccessful or that an ongoing communication was interrupted.For UV4EC, SEMUD[139] is used that provides an end-to-end communication proto-col is employed. It supports on-demand route discovery and constantly adjusts its activerouting paths. This is important for a highly mobile network where topology changesare frequent. In other words, SEMUD maintains a stable route while there is activecommunication between two nodes, for example, between the operator\u2019s device and aUGV; and does not generate any traffic while end-to-end communication is inactive.This is in contrast to classical proactive routing protocols for mesh networks such asOLSR81. SEMUD achieves these goals by a combination of per-packet feedback, theintegration of routing with actual data transmission, the use of reliability as a distance75https://github.com/umr-ds/serval-contentfilters76https://github.com/umr-ds/serval-dna/tree/nicer-filters77https://github.com/gh0st42/servalshellscripts78https://github.com/umr-ds/serval-web79https://github.com/gh0st42/ServalDesktopApp80https://github.com/gh0st42/sdnatui81https://tools.ietf.org/html/rfc71811184.8 Applications for Disaster Response: UV4ECNICER OCCUI componentProcessing modulesLocal lightweight databaseContent-basedpub/sub systemNetwork managerData controllerFigure 4.51: Architecture of NICER OCCmetric, and lightweight cryptographic mechanisms. These features allow SEMUD to behighly adaptive to topology changes and resilient to a wide range of common attackson wireless routing protocols even in the case that a device is compromised or capturedby an adversary. Furthermore, a prototypical and portable C++ implementation of theprotocol is freely available82.Operations and Control CenterTo provide a more complete situation overview and coordinate rescue endeavors, auser-friendly operations and control center (termed NICER OCC) was developed, thatis commonly located outside of the affected region. It comprises (1) data gathering,fusion and processing, (2) visualization, and (3) coordination of mobile rescuers or semi-autonomous unmanned vehicles (UVs) with specific focus on high-level commands,namely exploring (e.g., mapping, taking photos) or performing critical tasks (e.g., closinga valve). To show the applicability for the outlined disaster scenario, a proof-of-conceptprototype that relies on the previously described communication network and can runon a customary laptop was implemented.Data Gathering, Fusion and Processing The NICER OCC strives to collect a compre-hensive picture about the situation and the interactions of mobile rescuers and UVsin the field. Pursuing a loosely coupled and event-driven architecture (cf. Fig. 4.51),the system or the data controller first gathers and fuses sensor data of multiple nodesfrom the decentralized ad-hoc communication network; and second, (a) persistentlystores them in a local lightweight database for historical views, as well as (b) publishesthem to a content-based pub/sub system for push updates to the subscribed modules,such as processing modules or the UI component. Subscribed processing modules can thenasynchronously analyze the data (e.g., image editing, object recognition) and publishthe results back to the pub/sub system, where other subscribers (e.g., the UI compo-nent) can use them. The computational workload (i.e., processing modules) can also be82https://seemoo.de/semud1194 Disruption-tolerant Device-to-Device Emergency Communication(a) Situation overview(outdoor map)(b) Detailed view within a building(indoor map)Figure 4.52: UI component of NICER OCCmoved to the network by integrating in-network processing approaches [140], which isespecially designed for such infrastructure-less scenarios. In urban environments, thesystem can also utilize upgraded home routers as DTN communication bridges andcomputing nodes [141].Visualization The UI component of the system provides a visual overview of thesituation by displaying the collected and processed sensor data (cf. Fig. 4.52). Modernlightweight web technologies are used to accelerate UI development, to provide aneasy to learn and use application, as well as to easily distribute and port the system(cross-platform compatibility) in infrastructure-less disaster scenarios.Figure 4.52a shows the offline (outdoor) map, which is supposed to provide an entiresituation overview for the commanders. It displays and updates all units in the field(e.g., UVs, mobile rescuers) who are at least equipped with communication technologyand location sensor, points of interest (POIs), and overlaid indoor maps. By clicking ona unit, a detail view on the right side of the map appears, representing all relevantcollected information (e.g., health status) and possible high-level commands (e.g., takea photo). The same is true for a POI, which geographically marks a situation thatthe commanders may find interesting, e.g., detected victims or damages. Receivingnew data (e.g., status or location updates) by listening on the pub/sub system, theUI component only updates the visual representation of the referenced unit or objectwithout refreshing the whole map.To provide a more detailed view for inaccessible buildings (e.g., a nuclear reactor)to the commanders, the NICER OCC can display and update indoor maps created vialaser scanning by on-site UGVs (cf. Fig. 4.52b). The indoor map view is based on theuser interface of the outdoor map to apply same interaction concepts.Coordination The NICER OCC also enables commanders to coordinate the units inthe field by sending high-level commands. Two types of commands to control semi-autonomous UAVs and UGVs are defined, namely (i) exploring (e.g., mapping, takingphotos), and (ii) performing critical tasks (e.g., closing a valve; handing special equipment,emergency rations or medical kits over to injured people). Internally, these commandsare encoded and sent via messages over the available network. For a high-prioritycommand or a direct control of an UV, the NICER OCC can easily request a so-calledcommunication bridge from the units in the field (cf. Section 4.8.3). The NICER OCC1204.8 Applications for Disaster Response: UV4ECFigure 4.53: Hector Tracker robot operating in a simulated disaster scenario.can also be extended by integrating civilians who use our mobile application forsmartphones (cf. [142]).4.8.4 Experimental EvaluationUV4EC is evaluated by performing real-world tests (4.8.4) and performing comprehen-sive simulation and emulation of various nodes in realistic setups (4.8.4) based on thegenerated data.Real World SetupTo provide a test scenario that can be transferred to real applications, real-world disasterscenarios is emulated by relying on well-established approaches for evaluating disasterresponse robots. This includes NIST standard test methods [143] that are used in theRoboCup Rescue competition. They are designed to provide reproducible test setupsrepresentative for the challenges encountered in real disasters. Figure 4.53 shows andimage of the robot operating in the scenario.To simulate the use of a robot for victim search in a disaster scenario, multiplepersons are placed in a simulated disaster zone, simulating trapped victims. The HectorTracker vehicle is then used to explore the environment and search for victims. Therobot can be controlled by teleoperation or can operate fully autonomously, and theused control paradigm can be changed at any time. Using onboard sensors, it generatesa map of the environment including geometric (point cloud) data and found victims orobjects of interest.Communication requirements for robot operation depend on the operation mode. Forfully autonomous control, neither up- or downlinks are required, but often desirable tomonitor the vehicle. For pure teleoperation, connectivity between robot and operator1214 Disruption-tolerant Device-to-Device Emergency Communication(a) RGB Image (b) Thermal ImageFigure 4.54: Robot sensor data for a \u201dvictim found\u201d eventstation must be established. The downlink (robot to operator) direction then requiresthe transmission of low latency image data.Independent of the operation mode, the robot\u2019s mission state needs to be commu-nicated as the main deliverable for responders. It mainly consists of robot pose, 3Denvironment map as well as event-based tracking of objects of interest, such as findinga trapped victim. Since all related computation tasks take place onboard the robot, allmission state related information can be communicated in a delay-tolerant manner.This motivates the use of image data for evaluating communication performance inSection 4.8.4. Figure 4.54 shows example camera imagery that is associated with a\u201dvictim found\u201d event onboard the robot when a victim has been automatically detected.Lab Test EnvironmentTo get a basic understanding of the performance of UV4EC, several experiments ina controlled simulated and emulated environment derived from scenarios faced inSection 4.8.4 were performed. The following results can be directly transferred to realworld deployments, due to the focus on emulation of systems instead of simulatedalgorithms.Test Environment All tests were performed on an i7-4771 CPU @ 3.50GHz, supporting8 threads, with 32 GB of RAM. The nodes were simulated using a combination of theCommon Open Research Emulator (CORE)83, Gazebo84 robot simulator and ROS85. Thesystem was designed with a static operations and command center node center1, a robotslowly moving in one direction until it gets stuck at a building entrance robot1 and threehighly mobile drones drone1-3 with various objectives. These drones either have fixedpoints of interest for their mission or circle around specific positions. Furthermore, theyperiodically seek contact to center1, and robot1. The setup is shown in Figure 4.55 wherean accident in the chemistry building of the university of Marburg is simulated. In the83https://www.nrl.navy.mil/itd/ncs/products/core84http://gazebosim.org/85http://www.ros.org/1224.8 Applications for Disaster Response: UV4ECFigure 4.55: Simulation setup with three drones, one ground robot and a command center operating onour university campussimulations, the area covered by all involved entities is about 250.000 m2. Each node hasa 802.11g WiFi interface in ad-hoc mode for direct mesh communication. Therefore, thebandwidth cannot exceed 54 Mbit/s and has a maximum simulated range of 80 meters.Each experiment was repeated 10 times and ran for about 260 seconds.Communication Opportunities For delay-tolerant communication, it is importanthow often peers get a chance to exchange their data with others. In the simulation,it was determined, using one second intervals, how many peers are currently incommunication range.Overall, there were over 800 total contact opportunities in the entire simulation acrossall nodes. The individual number of contacts per node is shown in Figure 4.56. Thenumber of opportunities over the runtime per node is depicted in Figure 4.57. It showsthat within this area of action and without any specific targets for the autonomousdrones regarding communication, there are plenty of opportunities to exchange data,even though the mobile drones have more opportunities than the rather static or remotenodes, such as center1 and robot1.Delivery Times Knowing that many opportunities exist for data exchange in thisscenario, one must still determine how fast responses to individual commands can beexpected in such circumstances.Two different tests were performed to analyze the delivery times. The first testinjects image data at robot1 and measures how long it takes for this data to arrive in1234 Disruption-tolerant Device-to-Device Emergency Communicationrobot1 drone1 drone2 drone3 center1 totalNode0100200300400500600700800Opportunitiesrobot1drone1drone2drone3center1totalFigure 4.56: Opportunities fordata exchange0 50 100 150 200 250Time [s]01234567Opportunitiesrobot1drone1drone2drone3center1totalFigure 4.57: Opportunities for dataexchange over timeimg0 img1 img2 img3 img4 img5 avgImage020406080100120140Transmission Time [s]Figure 4.58: File distribution times0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16Message01020304050Time [s]total avgdrone1drone2drone3avgFigure 4.59: Message distribution timesthe operations and control center (center1). In the second test, center1 wants a directconnection to robot1 and therefore sends the commands for an air-bridge to all threedrones. It is measured how long it takes for all drones to receive the command. Bothexperiments were repeated with different starting times and therefore different geo-spatial distributions of nodes.File distribution depends on the file size. In the experiments, 1080p images weresent as they are recorded by the physical robot. The transmission times are shown inFigure 4.58. Average file transmission time is about 60 seconds with the worst time ofabout 155 seconds. Without this image transmission, the average time goes down toabout 46 seconds. This can be explained with bad timing, no peers in range or movingout of range during transmission, and Serval needing some time to recover from failedtransmissions. The transmission always needs at least 2-3 hops to travel from robot1 tocenter1, considering that the area of action covered by an average transmission time of60 seconds is more than acceptable.When it comes to message delivery to the drones, the picture is similar. If messagesare sent faster than they can be delivered, they are transmitted together, arriving atthe same time even although they have been sent at different points in time. Thearrival times are shown in Figure 4.59. Since text messages are much smaller thanimages, the chances of a successful transmission even with only short contact periodsis much higher, resulting in an average transmission time of about 9 seconds in this1244.8 Applications for Disaster Response: UV4ECPacket Rate at DestinationTime [s]SEMUD OLSR01002003004005006000 5 10 15 20 25 30Bridge InactiveBridge ActiveFigure 4.60: Reaction to a newly established communication bridge of SEMUD and OLSRscenario. Considering the worst delivery rates recorded in the experiments, a messagestill reaches its destination in under one minute. Thus, even with the rather low numberof participants in the simulation, direct control can be triggered within a quite shortperiod of time.All these numbers are highly scenario specific, and by having humans with networkdevices also in the affected area, even better delivery rates can be achieved. Havingthe drones programmed with multiple objectives, one seeking opportunities for dataexchange, gives a powerful tool to dynamically adapt to the environment and the tasksat hand.Connection Establishment The responsiveness of the communication system to newlyestablished communication bridges, i. e., when drones have moved into positions toallow a multi-hop connection from the control center to a robot, was also evaluated.For the experiment, center1 generates UDP/IP traffic to robot1 using the iPerf86 tool.The incoming packets are recorded at robot1 over time using tcpdump and their arrivaltimes can be seen plotted in Figure 4.60. The figure also marks the point in time whenthe drones have aligned and the communication bridge has been established.One can see that SEMUD almost instantaneously is able to deliver messages to thedestination after the communication bridge has become active. This is due to SEMUD\u2019sdesign of integrated route discovery and data transmission: there is no explicit protocolthat needs to be run prior to actual data transmission, but data is piggybacked to everymessage that is sent, which keeps delay at a minimum. In addition, SEMUD essentiallyfollows a trial-and-error approach: every message is flooded through the network untilfeedback from the destination is received, in which case SEMUD switches to unicasttransmissions to reduce network load. In contrast, OLSR is significantly slower inexploiting the communication bridge: it needs approximately 17 seconds to find a path.This is due to the fixed interval at which OLSR exchanges routing information. Notethat this additional delay is not a one-time cost, but has be paid whenever the topologychanges. This is especially problematic when long-term continuous control of a movingrobot is required and more drones are added to maintain the bridge.86https://iperf.fr1254 Disruption-tolerant Device-to-Device Emergency CommunicationMessage Processing Besides the delivery time of messages through the network, itis also important that the system has low message processing times at the networkdevices to ensure fast responses. Therefore, the NICER OCC is evaluated by systemperformance tests with respect to the entire message life-cycle between the networkand the UI, i.e., from the arrival of the message at the OCC through to the visualizationof the contained sensor data in the UI or on the map, so that the commanders canperceive them.Both directions of message processing are considered, (a) reading sensor data fromthe network (including deserialization) and updating the UI, as well as (b) sending com-mands from the UI to the network (including serialization). As performance measures,latency and throughput are used. Latency is the time required to process one message.Throughput is the number of such messages processed per unit of time. It is importantto note that one message can contain multiple sensor data such as location updates.However, to analyze the different message types and make the tests comparable, thenumber of sensor data or commands is limited to one per message for the lab test.Table 4.20: Performance test of OCC w.r.t message processingMessage type Latency [ms] Throughput [1/s]Sensor data (location) 26.1\u00b1 1.3 53.8\u00b1 4.0Sensor data (image) 76.6\u00b1 2.5 12.5\u00b1 0.5Commands 69.1\u00b1 1.8 19.6\u00b1 0.3Table 4.20 shows the results of the performance tests. One can observe that messageswith different kinds of sensor data are processed differently: a message with locationdata needs about 26ms to be processed in the OCC while messages with image contentneed roughly three times more (\u223c76ms). This is also reflected in the throughputmeasurements. Considering the other direction, commands can be sent in about 70msfrom the UI to the network, which is more than sufficient to be able to smoothly controlthe rescue mission.All in all, the message processing of the operations and control center is negligiblecompared to the delivery times of the messages through the network. Thus, there isno lack of performance for the OCC; quite the contrary, the OCC supports situationoverviews with high-frequency updates in the magnitude of the human eye or screenrefresh rate.4.8.5 ConclusionIn this section, UV4EC was presented, a novel emergency communication systeminvolving unmanned vehicles. By combining a DTN-based mobile cloud infrastructurefor non-time-critical tasks with reactive mesh routing for real-time interaction, novelways of operating UGVs and UAVs are provided that also support humans in theaffected area. UGVs and UAVs are used to bridge communication gaps that otherwisewould significantly reduce their radius of operation. Also a lightweight operationsand control center that complements UV4EC to provide all relevant functionalities(i.e., data gathering and processing, providing visual situation overviews, and sendinghigh-level commands) to commanders for coordinating rescue missions was developed.1264.8 Applications for Disaster Response: UV4ECFurthermore, the viability of the approach by experimental evaluation and real worlddeployment was demonstrated.There are several areas of future work. For example, additional work should beinvested in developing further DTN-aware control mechanisms for various robotoperations. Furthermore, the coordination of the UAVs can be fine tuned and optimizedfor specific scenarios. Depending on the tasks at hand, data prioritization shouldbe considered at the UAV/UGV, DTN and/or routing levels for improved networkperformance. Finally, for low-priority tasks (e.g., analyzing local sensor data), it isplanned to move the computational workload from the control center to the network,i.e., the data should already be analyzed by the nodes in the network.1274 Disruption-tolerant Device-to-Device Emergency Communication4.9 SEDCOS - Secure Disaster Communication4.9.1 IntroductionCommunication technologies are integral to disaster relief operations. The solutions pre-sented in the previous sections leverage the ad hoc and disruption-tolerant networking(DTN) capabilities of mobile devices to create opportunistic communication networks.In DTNs, all devices store, carry, and forward data to form a dynamic, infrastructure-less, and self-organized network. Coverage is increased by adding more devices to thenetwork. In particular, the approach can be applied to mobile commodity devices, suchas smartphones, tablets, and laptops, which are ubiquitous and provide diverse adhoc communication capabilities (e. g., Wi-Fi and Bluetooth). In this way, people cancontinue using their personal devices to request or offer aid, obtain information fromemergency services, or contact relatives and friends.However, such opportunistic networks are susceptible to a wide range of security at-tacks due to their wireless, cooperative, decentralized, and resource-constrained nature.For instance, during wars or terror attacks, adversaries may subvert the communicationsystem to disrupt disaster relief operations by injecting false information or performingdenial-of-service (DoS) attacks. Furthermore, panicked people may spam the networkwith messages, unintentionally jeopardize availability.Thus, a practical emergency communication system must ensure confidentiality,authenticity, integrity, and availability, but these properties are difficult to achieveduring adverse events. Existing proposals either lack disaster functionality or providean insufficient level of security [144]\u2013[147]. High data availability and reliability arecrucial for emergency notifications and distress signals. Prior work has improvedreliability, but has not assessed secure prioritization mechanisms that work reliablyunder attack.In this section, SEDCOS, a secure device-to-device communication system for disasterscenarios, is presented. The main contributions are:\u2022 a secure communication substrate with message prioritization and a managementscheme that delivers messages reliably and is resilient against flooding DoSattacks, and\u2022 large-scale network simulations showing SEDCOS\u2019s effectiveness in maintaininghigh delivery rates under attack and revoking user certificates in the field.Parts of this section have been published in [8].4.9.2 Related WorkTypical security targets in opportunistic networks are authentication and integrity ofmessages [148], secure routing [149], and confidential as well as anonymous end-to-endcommunication [150]. Identity-based Cryptography (IBC) is a frequently suggestedsolution, since traditional public key cryptography is often regarded as unsuitablefor opportunistic networks due to the need of accessing public keys, certificates, andrevocation information from central online servers [151]. To eliminate central author-ities, fully decentralized trust-based concepts [152], [153], or approaches based onthreshold-cryptography [154] have been proposed. However, existing works do notaddress the unique challenges of disaster relief communication, such as a high delivery1284.9 SEDCOS - Secure Disaster Communicationrate (emergency messages), immobility of individual users (trapped victims), role-basedauthentication, or insider attackers. Denial-of-service attacks on unauthenticated DTNshave been evaluated, but contrary to previous findings [149], we show that authentica-tion is essential for reliable operation. Other works have attempted to hinder floodingattacks by setting explicit rate limits and trying to detect misbehaving nodes using acomplex distributed detection mechanism [155].4.9.3 System ModelStore, Carry, and ForwardInstead of relying on infrastructure, DTN-enabled devices exchange messages directlyusing WiFi and Bluetooth. DTNs exploit user mobility to increase coverage: devices actas \u201cdata mules\u201d that store their messages as well as messages from other users, carrythem, and finally forward them to the destination upon contact. This way, messagespropagate in an epidemic manner from device to device until they reach their destina-tions. DTN performance is typically worse than that of infrastructure networks but ispreferable to no communication at all. Nevertheless, devices with Internet connectivity(cellular or WiFi access points) can opportunistically act as \u201cwormholes\u201d used for rapidmessage distribution to isolated parts of the network.Communication ModelCommunication in an emergency scenario is either one-to-one (contact with friends orfamily), many-to-many (within task forces or departments), or one-to-many (emergencynotification broadcasts). Due to the inherent delay of DTN-based communication, onlysmall messages, such as text and prioritized distress messages (including additionalinformation, such as GPS location of the sender), serving a similar purpose as theclassic \u201c112\u201d emergency call, are allowed in SEDCOS. Compared to rich media (images,voice, video), information in text messages is more compact, thus, uses the limitedresources of DTNs more efficiently.Adversary ModelAn adversary Adv is considered who can mount network attacks and compromisenetwork entities. Specifically, Adv can eavesdrop, manipulate, forge, or drop messages.Furthermore, Adv can assume a limited number of entities, either by compromising orstealing devices or by registering multiple times in our system. Unlike the classic Dolev\u2013Yao adversary model, Adv controls only a part of the communication channel and aportion of all network entities. Moreover, Adv cannot break cryptographic primitives ortamper with the root authority (see 4.9.4).4.9.4 Secure Key ManagementEstablishing trust is important to satisfy the security requirements. For this purpose, acentralized trust model using a Public Key Infrastructure (PKI) is employed, as shownin 4.61. The PKI consists of multiple hierarchically organized certificate authorities(CAs), whose root is a dedicated authority named root authority (RA). The RA servesas a trust anchor, maintains the emergency communication software, and distributes1294 Disruption-tolerant Device-to-Device Emergency Communicationunprivileged users with seperate authorization level (   )EmergencyCommunicationSoftwareHigh Authorization Level Low Authorization LevelDistrictAuthority 1DistrictAuthority 2 TeamLeaderFirefighterPredefined User Group:Fire ServiceFire ServiceHeadquarterAuthoritynegotiatetermsissuecertificateAmbulanceHeadquarterAuthorityRootAuthority(RA)CitizenAuthorityNationalAuthority ANationalAuthority BissueidentitycertificateIdentityCertificateNetwork Identifier:    0x12345689Affiliation:    Fire ServiceAuthority:    District Authority 2Role:    Team LeaderAuthorization Level:    2 (        )revokecertificaterevokecertificateduringcrisisrevokecertificatebefore crisisnegotiatetermsFigure 4.61: Illustration of our secure key management. The authorization level decreases from left toright, except for citizens.the software if infrastructure access is still available. In an initialization phase, beforethe actual crisis, the RA establishes relationships to organizations or governmentsthat want to participate as authorities in the emergency communication system. Allauthorities initially undergo a rigorous audit by the RA, since their authenticity andtrustworthiness are crucial to the overall security. As part of the audit process, RA andauthority agree on user roles as well as preconfigured user groups that the authorityintroduces to the network. For instance, in 4.61, the fire service organization added theuser roles team leader and firefighter, and arranged a preconfigured user group fire service,so users can particularly address all firefighters when sending a message. Authoritiesmanage their own PKI and, hence, maintain one or multiple, potentially hierarchicallyorganized, CAs. The CAs\u2019 public keys are embedded in the emergency communicationsoftware. After this step, authorities can issue identity certificates. Furthermore, theoverall PKI contains at least one authority that issues identity certificates to unprivilegedusers, i.e., citizens. In 4.61, the fire service maintains several hierarchically organizedauthorities. On the lowest hierarchical CA level, CAs issue identity certificates to staffmembers.Identity certificates bind the public signing keys of users, which function as theirunique network identifiers (see 4.9.5), to user properties. A vital user property is theuser role, since it is important to assess the content of messages. For instance, citizensconsider medical information more reliable if they originate from physicians ratherthan firefighters. Another essential property is the authorization level that indicatesthe permission level and trustworthiness of a user. 4.61 shows the identity certificateof a firefighter team leader, and depicts the authorization level of entities by theirx-coordinate as well as stars in the certificate. In order to obtain an identity certificate,users must register with the CA and provide a proof of identity, e.g., using theiridentification card, phone number, or address. The identity proof is vital to hampermulti-registrations, where a single user obtains multiple identity certificates.Since an adversary may obtain identity certificates, compromise user devices, oreven infiltrate authorities, it is important that certificates can be revoked. SEDCOSimplements certificate revocations via certificate revocation lists (CRLs) that are broad-casted with high priority in the network. It is distinguished between two differententities: authorities and users. An authority A can revoke an entity E if A has a higherauthorization level than E , and there is a certificate chain (i.e., a chain of trust) betweenA and E . Upon the revocation of an authority, all certificates that the authority issuedin the past and will issue in the future are regarded as invalid, withdrawing its power.1304.9 SEDCOS - Secure Disaster CommunicationIn case a user identity certificate is revoked, the respective user becomes an uncertifiedand unprivileged user, hence, loses its user role, authorization level, and any messagetransmission privileges (see 4.9.5).4.9.5 Resilient CommunicationIn this subsection, first an overview of the communication protocol is given and thenthe design of the DoS-resistant buffer management is given.Protocol OverviewA short overview of the used message protocol is given in the following.Message Format and Types All SEDCOS messages have the same format and includethe following fields: message type, sender and receiver addresses, creation time andlifetime (together yielding the time-to-live (TTL)), sender signature, and the optionallyencrypted payload. It is emphasized that all header fields are immutable, that is, they arenot changed in transit, thus, allowing the signature to protect the entire message. Themessage type can be:\u2022 Certificate Revocation Lists;\u2022 Network control with subtypes for acknowledgments and the device-to-devicemessage exchange handshake;\u2022 Content sent by users.Acknowledgments are sent by the destination upon reception of a message.Message Authenticity and Confidentiality Each user possesses a unique EllipticCurve Digital Signature (ECDSA) signature key pair. The public part of the key servesas a unique addressable network identifier. Each outgoing message is signed usingthis key and can optionally be augmented with the identity certificate. Devices verifymessages at each hop by checking the message signature and, if available, the sender\u2019sidentity certificate; and discard them if any check fails. Hence, corrupted messages donot propagate in the network. To achieve data confidentiality, each user generates itsown Elliptic Curve Integrated Encryption Scheme (ECIES) encryption key pair duringinitialization. Consequently, sending or receiving confidential messages requires themessage payload to be encrypted with the public or decrypted with the private ECIESkey of the receiving user.Message Storage Each device reserves persistent memory for storing its own aswell as others\u2019 messages. This memory space is referred to as the buffer. Its capacity Cdepends on the device capabilities and can be adjusted by the user. Efficiently managingthe buffer is crucial for delivery reliability, as shown in 4.9.6.Message Exchange When two devices discover each other via Bluetooth or Wi-Fibeacon frames, they connect to exchange messages. Currently epidemic disseminationis used, i.e., nodes try to exchange all carried messages. This introduces redundancyin the network, which helps when single nodes \u201cdisappear\u201d (low battery or mobility).1314 Disruption-tolerant Device-to-Device Emergency CommunicationAlgorithm 1 Source-based Elastic Bucket InsertionRequire: msg, buckets, C1: s \u2190 source of msg2: if not buckets contains bucket for s then3: insert new empty bucket for msg in buckets;4: end if5: Bs \u2190 bucket from buckets for s;6: insert msg into Bs;7: while occupancy of buckets exceeds C do8: B\u02c6 \u2190 bucket from buckets with the highest occupancy;9: remove message with the lowest rank from B\u02c6;10: if B\u02c6 is empty then11: remove B\u02c6 from buckets;12: end if13: end whileHowever, due to limited buffer capacity and possibly short contact times (i. e., twocars passing each other), not all messages might be exchanged. Thus, messages areexchanged in the following order:\u2022 messages destined for B,\u2022 messages from privileged users (authorities),\u2022 all other messages.Source-based Elastic BucketsProper buffer management is essential to prevent resource starvation attacks suchas flooding. Malicious nodes can easily exploit trivial implementations such as FIFOqueues containing all messages to replace valid messages with bogus ones [156]. Tocounter such attacks, a novel buffer management strategy called Source-based ElasticBuckets (SEB) is employed that, by design, prevents valid messages from being purgedduring flooding attacks. The basic idea is that all messages from a source s are placedin an isolated bucket B such that messages from different sources cannot influenceone another. SEB is fair in the sense that each bucket has a guaranteed capacity ofCB = \u230aC/n\u230b where n is the number of currently allocated buckets (= number of sourcenodes currently carry messages from). The occupancy of a single source bucket OB issubject to OB \u2208 [0, C] and \u2211s OB \u2264 C. If s does not exhaust its guaranteed capacity(OB < CB) because it has not sent \u201cenough\u201d messages, free capacity (CB \u2212 OB) isshared by other buckets requiring it. However, when s sends a message at a laterpoint, overdrawn buckets (OB > CB) are emptied first. These elastic quotas allow fullexploitation of local buffer capacities while maintaining strict message separation ofdifferent source nodes. Algorithm 1 shows SEB\u2019s message insertion procedure: theunderlying idea is that SEB inserts new messages in the appropriate (source) bucketand then drops messages from the highest occupant bucket until the total occupancymeets C. Note that a node will always try to make space for its messages by droppingits messages last. This is to ensure that there is at least one copy of every message inthe network. However, if a device injects too many new messages (exceeding C), itsbuffer overflows, and SEB eventually has to drop own messages. Within each bucket,SEB prioritizes:1324.9 SEDCOS - Secure Disaster Communication\u2022 security control messages (revocation certificates),\u2022 network control messages (acknowledgments), and\u2022 messages with the longest remaining TTL.SEB\u2019s robustness relies on the fact that messages are source-authenticated and onthe relatively high costs of acquiring new identities in the system. Without the lattercosts, an attacker could assume multiple identities, flood the network with messagesand, thus, hijack a disproportional amount of buffer capacity.4.9.6 Experimental EvaluationIn this subsection, the impact of flooding attacks by several privileged devices (due totheft or compromise), and their eventual revocation from the system is evaluated.ScenarioThree different user classes are considered with a total of 1000 nodes: 850 citizens, 100authorities, and 50 attackers. Within each group, there are 5% cars (10\u201350 km/h), all oth-ers move at walking speed (1.8\u20134.5 km/h). Citizens can transmit low-priority messages,while authorities sent with high priority (interval: 15\u201325 s). SEB is compared to a classicFIFO queue, both using epidemic routing. The buffer capacity C is 5MB. The ONEsimulator v1.6.0 [157] as well as the default Helsinki map for the experiments is usedand the results are averaged over ten differently-seeded runs. Bluetooth communicationwith 2 Mbit/s and a range of 10m is assumed.Flooding Attack and RevocationNo Attack Attack RevocationDelivery ProbabilityTime [h]SEB-lowSEB-highFIFO-lowFIFO-high00.10.20.30.40.50.60.70.80.910 1 2 TC 4 5 6 7 8 TR 10 11 12(a) Delivery rate of valid mes-sages over time.Buffer OccupancyTime [h]bogushighlow00.10.20.30.40.50.60.70.80.910 1 2 TC 4 5 6 7 8 TR 10 11 12(b) Buffer occupancy withFIFOBuffer OccupancyTime [h]bogushighlow00.10.20.30.40.50.60.70.80.910 1 2 TC 4 5 6 7 8 TR 10 11 12(c) Buffer occupancy with SEBFigure 4.62: Flooding attack and revocation.The attack starts at TC = 3 h and the revocation certificate is issued at TR = 9 h.The impact of an attacker being able to compromise privileged devices is evaluated.In this case, the attacker is able to inject bogus high-priority messages into the network,thus, increasing their chances to remain in the nodes\u2019 buffers for a long time. In thisexperiment, two events occur: at TC = 3 h, the attackers start the flooding attackusing compromised devices; and after a reaction time of 6 h at TR = 9 h, an authorityissues and injects the revocation certificate into the network. When a node receivesthe revocation certificate, it drops all messages it carries from the revoked nodes andblacklists future messages by those nodes. Attackers ignore revocation certificates.1334 Disruption-tolerant Device-to-Device Emergency CommunicationBefore the attack Figure 4.62a shows the delivered benign messages (low and high)over time. In the beginning, SEB quickly starts to successfully deliver most messages.FIFO follows the same start-up behavior but is not able to keep up from the 30 minutesmark. After 30 minutes, buffers are filled up (Fig. 4.62b) and the lack of proper buffermanagement leads to poor delivery performance.During the attack At the start of the attack, SEB\u2019s delivery probability remains almostunaffected by the flooding attack even though buffers quickly fill up to 70 % with bogusmessages (Fig. 4.62c). The decrease in delivery probability is only about 10 % (Fig. 4.62a)demonstrating the effectiveness of the source-based elastic buckets: they assure thatbogus messages cannot overtake the entire buffer capacity. FIFO reacts less visibly tothe attack since the delivery probability is already low at TC (4.62a). Yet, the impact isapparent in 4.62b where bogus messages steadily take up more buffer capacity, leadingto continuously decreasing delivery probability.Aftermath FIFO does not recover from the attack after TR, since only a few nodesreceive the revocation certificate due to the lack of a prioritization mechanism. WithSEB, the revocation certificate propagates quickly throughout the network: half of thenodes are informed within 12 minutes while full network penetration is reached in lessthan one hour. The drop of bogus message buffer occupancy shortly after TR indicatesthe revocation certificate\u2019s effect (4.62c). As the certificate propagates in the network,buffer occupancy restores to a state similar to t < TC. Nevertheless, a small fraction ofbogus messages remains in the network since attackers ignore the revocation certificateand keep their messages in their buffers.4.9.7 ConclusionA secure and reliable communication system is essential for effective disaster response.SEDCOS, a system that enables secure and reliable disruption-tolerant emergencycommunication on commodity mobile devices, was presented. It is the first secureemergency communication system that enables the exclusion of adversaries whileproviding authentic and confidential group communication. Under DoS attacks, SED-COS increases the message delivery rate by a factor of 6 compared to a contemporaryDTN protocol. Finally, SEDCOS provides a timely revocation (less than one hour) forwithdrawing any power of an insider adversary.While the solutions described in this section proved to be effective, they have onlybeen evaluated in a simulator. In the future, integration into a real DTN middleware,as used in the previous sections, would be a valuable task. Furthermore, different waysof attestation, local and remote, for handing out identity certificates during a disastershould be investigated.1344.10 Summary4.10 SummaryIn Section 4.2, MiniWorld was presented, a novel distributed network emulator. It isbased on full virtualization using QEMU/KVM, offers three network backends foremulating both wired and wireless communication, and provides several mobilitypatterns as well as distance-based link quality models. A snapshot boot mode isoffered for accelerated booting of identical environments and repeating emulationruns. To decrease runtimes, MiniWorld supports distributed emulation across multiplecomputers, based on a resource-aware virtual machine (VM) scheduler. Experimentalresults demonstrate the performance of MiniWorld with respect to VM boot times,network bandwidth, round trip times, and topology switching times.An in-depth experimental evaluation of Serval for various network setups and usagepatterns, including simulated long term use was performed in Section 4.3. The focusof the evaluation was on the delay-tolerant aspects of Serval, providing insights intothe scenarios where Serval can be deployed with satisfactory quality and performancecharacteristics. Furthermore, since mobile phones have a limited battery capacity, acloser look is taken at the battery drain resulting from using Serval over differentcommunication links, such as WiFi and Bluetooth. Despite minor shortcomings, itwas shown that Serval is a flexible foundation for data and message dissemination invarious environments.Several approaches to realize dynamic announcement intervals that facilitate fastreception from at least one other node while trying to keep the overall communicationoverhead as low as possible were developed in Section 4.4. Experimental results interms of performance properties and energy consumption were presented to illustratethe benefits of dynamic announcement intervals in wireless on-demand networks.In Section 4.5, DTN-RPC, a new approach to provide RPCs for DTN environments,was presented. DTN-RPC relies on (a) control and data channels to cope with potentiallyshort contact durations in DTN where large amounts of data cannot be transmitted, (b)explicit and implicit modes to address remote servers, (c) Non-DTN and DTN transportprotocols for issuing calls and receiving results, and (d) predicates that servers check todecide whether a procedure should be executed. The implementation of DTN-RPC isbased on Serval. The experimental results indicate that the measured CPU and networkoverheads for DTN-RPC are reasonably low so that it can be executed on smartphonesor routers, and that the round-trip times and the number of successful RPCs are highlysatisfactory in dynamic networks with unstable links.In Section 4.6 a novel, low-cost yet flexible and powerful hardware/software platformfor sensing, computation, and infrastructureless wireless communication was presented.Since energy consumption is a key issue for autonomous operation, the power re-quirements of various computing platforms, sensors and radio link technologies wereinvestigated. Furthermore, several license-free radios (WiFi, Bluetooth, LoRa 433 MHzand 868 Mhz) were experimentally evaluated regarding their real-world communicationranges. To avoid wasting precious communication resources, machine learning andimage-based concept detection was applied on-device to remove irrelevant data priorto sending. Neural compute sticks were also evaluated to improve performance andoptimize their energy consumption in this specific scenario. The proposed hardware/software platform consists of small, low-power sensor nodes based on microcontrollers,larger single board computer relay nodes that can also preprocess data, and Bluetooth1354 Disruption-tolerant Device-to-Device Emergency CommunicationLow Energy enabled smartphone add-ons to give mobile devices access to long rangecommunication technology. Finally, a Linux distribution tailored to the specific needsin this application area is presented that makes deploying new relay nodes easy evenfor non-specialists.SmartFace, a novel approach to perform face detection locally on mobile devicesin an efficient manner, was presented in Section 4.7. The approach relies on a two-stage combination of existing face detection algorithms, enhanced by region of interestselection, color space/depth reduction, resolution scaling, face size definition, imagescaling, image cropping, and bounding box scaling. Experimental results indicate thatthe proposed approach improves both the overall face detection rate and the overallruntime compared to the individual face detection algorithms used alone. It alsoreduces the amount of data that needs to be stored on disk and sent over the network.UV4EV was presented in Section 4.8, a novel approach to emergency communicationwhere semi-autonomous UGVs and UAVs cooperate with humans to dynamically formcommunication islands and establish communication bridges between these islands.Humans typically form an island with their mobile devices if they are in physicalproximity; UGVs and UAVs extend an island\u2019s range by carrying data to a neighboringisland. The proposed approach uses delay/disruption-tolerant networking for non-timecritical tasks and direct mesh connections for prioritized tasks that require real-timefeedback. The developed communication platform runs on rescue robots, commoditymobile devices, and various drones, and supports our operations and control centersoftware for disaster management.SEDCOS, a secure device-to-device communication system for disaster scenarios, waspresented in Section 4.9. It mitigates flooding DoS attacks and offers role revocation fordetected adversaries to withdraw their permissions. The effectiveness of SEDCOS wasdemonstrated by large-scale network simulations.The research in this chapter shows that even in uncertain and challenged networkconditions, such as the ones found during emergency scenarios, common applicationsand services can be delivered through new ways. By relying on D2D communicationtogether with DTN, many of the challenges can be overcome.1365 Security Vulnerability Analysis of MobileApps5.1 IntroductionWhile the previous chapter focused on disruption-tolerant device-to-device emergencycommunication in general, this chapter provides an in-depth insight into the securityaspects of existing emergency apps and their communication. Most apps found onsmartphones use network resources, often through HTTP(S), or store valuable data,such as images, contacts, bank credentials, cryptographic identities and messages.Therefore, analyzing emergency apps for possible vulnerabilities is critical for secureemergency communication.One fundamental technology to secure data-in-motion is the use of SSL/TLS. InSection 5.2, a study of the use and implementation security state of SSL in Androidapps is presented.To ease the process of such audits, a flexible framework for distributed static analysis,called AndroLyze, is presented in Section 5.3. Furthermore, the use of cryptographicfunctions in about 40,000 APKs is investigated.In Section 5.4 Dynalize, a Platform-as-a-Service cloud for dynamic analysis of Androidapps, is proposed. It completes the flexible toolkit, together with AndroLyze, for large-scale analysis of mobile apps.The experience from the previous sections is used to give a security report on themost commonly used emergency communication apps currently available for Android.The results of this audit are presented in Section 5.5.AndroLyze1 as well as Dynalize2 have been published on github.1https://github.com/nachtmaar/androlyze2https://github.com/umr-ds/dynalize1375 Security Vulnerability Analysis of Mobile Apps5.2 TLS Usage in Android Apps5.2.1 IntroductionCurrently, Android is the most used smartphone operating system in the world, witha market share of 48%3 and over 400,000 applications (apps) available in the GooglePlay Market4, almost doubling the number of apps in only six months.5 Android appshave been installed over 10 billion times6 and cover a vast range of categories fromgames and entertainment to financial and business services. Unlike the \u201dwalled gardenapproach\u201d of Apple\u2019s App Store, Android software development and the Google PlayMarket are relatively open and unrestricted. This offers both developers and users moreflexibility and freedom, but also creates significant security challenges.The coarse permission system [158] and over-privileging of applications [159] can leadto exploitable applications. Consequently, several efforts have been made to investigateprivilege problems in Android apps [158], [160]\u2013[163]. Enck et al. introduced TaintDroid[164] to track privacy-related information flows to discover such (semi-)malicious apps.Bugiel et al. [162] showed that colluding malicious apps can facilitate informationleakage. Furthermore, Enck et al. analyzed 1,100 Android apps for malicious activityand detected widespread use of privacy-related information such as IMEI, IMSI, andICC-ID for \u201dcookie-esque\u201d tracking. However, no other malicious activities were found,in particular no exploitable vulnerabilities that could have lead to malicious control ofa smartphone were observed [165].In this section, instead of focusing on malicious apps, the potential security threatsposed by benign Android apps that legitimately process privacy-related user data, suchas log-in credentials, personal documents, contacts, financial data, messages, pictures orvideos is investigated. Many of these apps communicate over the Internet for legitimatereasons and thus request and require the INTERNET permission. It is then necessaryto trust that the app adequately protects sensitive data when transmitting it via theInternet.The most common approach to protect data during communication on the Androidplatform is to use the Secure Sockets Layer (SSL) or Transport Layer Security (TLS)protocols.7 To evaluate the state of SSL use in Android apps, 13,500 popular free appswere downloaded from Google\u2019s Play Market and their properties were studied withrespect to the usage of SSL. In particular, the apps\u2019 vulnerability against Man-in-the-Middle (MITM) attacks due to the inadequate or incorrect use of SSL was studied.For this purpose, MalloDroid was created, an Androguard8 extension that performsstatic code analysis to a) analyze the networking API calls and extract valid HTTP(S)URLs from the decompiled apps; b) check the validity of the SSL certificates of allextracted HTTPS hosts; and c) identify apps that contain API calls that differ from An-droid\u2019s default SSL usage, e. g., contain non-default trust managers, SSL socket factoriesor hostname verifiers with permissive verification strategies. Based on the results of the3https://bit.ly/L4c8Ky4https://bit.ly/xr7WET5https://bit.ly/rhJxf26https://bit.ly/H1qGta7Android supports both SSL and TLS; for brevity, it will be referred to both protocols as SSL. Theissues described in this work affect both SSL and TLS in the same way.8http://code.google.com/p/androguard/1385.2 TLS Usage in Android Appsstatic code analysis, 100 apps were selected for manual audits to investigate variousforms of SSL use and misuse: accepting all SSL certificates, allowing all hostnamesregardless of the certificate\u2019s Common Name (CN), neglecting precautions against SSLstripping, trusting all available Certificate Authorities (CAs), not using SSL pinning,and misinforming users about SSL usage.Furthermore, the visibility and awareness of SSL security in the context of Androidapps was studied. In Android, the user of an app has no guarantee that an app usesSSL and also gets no feedback from the Android operating system whether SSL isused during communication or not. It is entirely up to the app to use SSL and to(mis)inform the user about the security of the connection. However, even when appspresent warnings and security indicators, users need to see and interpret them correctly.The users\u2019 perceptions concerning these warnings and indicators were investigatedin an online survey. Finally, several countermeasures that could help to alleviate theproblems discovered in the course of this work are discussed.The results of the investigations can be summarized as follows:\u2022 1,074 apps contain SSL specific code that either accepts all certificates or allhostnames for a certificate and thus are potentially vulnerable to MITM attacks.\u2022 41 of the 100 apps selected for manual audit were vulnerable to MITM attacksdue to various forms of SSL misuse.\u2022 The cumulative install base of the apps with confirmed vulnerabilities againstMITM attacks lies between 39.5 and 185 million users, according to Google\u2019sPlay Market.9 This number includes 3 apps with install bases between 10 and 50million users each.\u2022 From these 41 apps, it was possible to \u2013 for example \u2013 capture credentials forAmerican Express, Diners Club, Paypal, bank accounts, Facebook, Twitter, Google,Yahoo, Microsoft Live ID, Box, WordPress, remote control servers, arbitrary emailaccounts, and IBM Sametime.\u2022 Virus signatures were injected into an anti-virus app to detect arbitrary apps as avirus or disable virus detection completely.\u2022 It was possible to remotely inject and execute code in an app created by avulnerable app building framework.\u2022 378 (50.1%) of the 754 Android users participating in the online survey did notjudge the security state of a browser session correctly.\u2022 419 (55.6%) of the 754 participants had not seen a certificate warning before andtypically rated the risk they were warned against as medium to low.Parts of this section have been published in [9].5.2.2 BackgroundThe focus of the investigation is the inadequate use of SSL in Android apps. In thissubsection, a brief overview of how SSL is used in Android is given and how MITMattacks can be launched against broken SSL connections in the context of this research.9Google\u2019s Play Market does not give a precise number of installs, instead giving a range. The actualnumber is likely to be larger, since alternative app markets for Android also contribute to the install base.1395 Security Vulnerability Analysis of Mobile AppsSSLThe Secure Sockets Layer (SSL) and its successor, Transport Layer Security (TLS),are cryptographic protocols that were introduced to protect network communicationfrom eavesdropping and tampering. To establish a secure connection, a client mustsecurely gain access to the public key of the server. In most client/server setups,the server obtains an X.509 certificate that contains the server\u2019s public key and issigned by a Certificate Authority (CA). When the client connects to the server, thecertificate is transferred to the client. The client must then validate the certificate.10However, validation checks are not a central part of the SSL and X.509 standards.Recommendations are given, but the actual implementation is left to the applicationdeveloper.The basic validation checks include: a) does the subject (CN) of the certificate matchthe destination selected by the client?; b) is the signing CA a trusted CA?; c) is the signa-ture correct?; and d) is the certificate valid in terms of its time of expiry? Additionally,revocation of a certificate and its corresponding certificate chain should be checked, butdownloading Certificate Revocation Lists (CRLs) or using the Online Certificate StatusProtocol (OCSP)11 is often omitted. The open nature of the standard specification hasseveral pitfalls, both on a technical and a human level. Therefore, the evaluations in theremainder of this work are based on examining the four validation checks listed above.Android & SSLThe Android 4.0 SDK offers several convenient ways to access the network. Thejava.net, javax.net, android.net and org.apache.http packages can be used tocreate (server) sockets or HTTP(S) connections. The org.webkit package providesaccess to web browser functionality. In general, Android allows apps to customize SSLusage \u2013 i. e., developers must ensure that they use SSL correctly for the intended usageand threat environment. Hence, the following (mis-) use cases can arise and can causean app to transmit sensitive information over a potentially broken SSL channel:Trusting all Certificates. The TrustManager interface can be implemented to trust allcertificates, irrespective of who signed them or even for what subject they wereissued.Allowing all Hostnames. It is possible to forgo checks of whether the certificate wasissued for this address or not, i. e., when accessing the server example.com, acertificate issued for some-other-domain.com is accepted.Trusting many CAs. This is not necessarily a flaw, but Android 4.0 trusts 134 CA rootcertificates per default. Due to the attacks on several CAs in 2011, the problem ofthe large number of trusted CAs is actively debated.12Mixed Mode/No SSL. App developers are free to mix secure and insecure connectionsin the same app or not use SSL at all. This is not directly a SSL issue, but it isrelevant to mention that there are no outward signs and no possibility for acommon app user to check whether a secure connection is being used. This opensthe door for attacks such as SSL Stripping [166], [167] or tools like Firesheep.1310https://tools.ietf.org/html/rfc528011https://tools.ietf.org/html/rfc256012https://bit.ly/g0dH3413https://codebutler.com/firesheep1405.2 TLS Usage in Android AppsOn the other hand, Android\u2019s flexibility in terms of SSL handling allows advancedfeatures to be implemented. One important example is SSL Pinning14, in which either a(smaller) custom list of trusted CAs or even a custom list of specific certificates is used.Android does not offer SSL pinning capabilities out of the box. However, it is possibleto create a custom trust manager to implement SSL pinning.15The use of an SSL channel, even under the conditions described above, is still moresecure than using only plain HTTP against a passive attacker. An active MITM attack isrequired for an attacker to subvert an SSL channel and is described below.MITM AttackIn a MITM attack (MITMA), the attacker is in a position to intercept messages sentbetween communication partners. In a passive MITMA, the attacker can only eavesdropon the communication (attacker label: Eve), and in an active MITMA, the attacker canalso tamper with the communication (attacker label: Mallory). MITMAs against mobiledevices are somewhat easier to execute than against traditional desktop computers,since the use of mobile devices frequently occurs in changing and untrusted environ-ments. Specifically, the use of open access points [32] and the evil twin attack [33] makeMITMAs against mobile devices a serious threat.SSL is fundamentally capable of preventing both Eve and Mallory from executingtheir attacks. However, the cases described above open up attack vectors for bothEve and Mallory. Trivially, the mixed mode/no SSL case allows Eve to eavesdrop onnon-protected communication.SSL Stripping is another method by which a MITMA can be launched against anSSL connection, exploiting apps that use a mix of HTTP and HTTPS. SSL Strippingrelies on the fact that many SSL connections are established by clicking on a link in orbeing redirected from a non-SSL-protected site. During SSL Stripping, Mallory replaceshttps:// links in the non protected sites with insecure http:// links. Thus, unless the usernotices that the links have been tampered with Mallory can circumvent SSL protectionaltogether. This attack is mainly relevant to browser apps or apps using Android\u2019sWebView.5.2.3 Related WorkSo far, there is no in-depth study of SSL usage and security on Android phones to date.Thus, the discussion of related work is divided into two parts: related work concerningAndroid security and a selection of SSL security work relevant for this research.Android SecurityThere have been several efforts to investigate Android permissions and unwanted ormalicious information flows, such as the work presented by Enck et al. [158], [164],Porter Felt et al. [159], [160], Davi et al. [161], Bugiel et al. [162], Nauman et al.[168]and Egners et al. [169]. These works have in common that they study how permissionscan be abused and how this abuse can be prevented. Their scope does not include thestudy of SSL issues, and the proposed countermeasures do not mitigate the threats14https://bit.ly/qugGtH15https://bit.ly/v55mxn1415 Security Vulnerability Analysis of Mobile Appspresented here. The vulnerabilities studied in this thesis are based on weaknesses inthe design and use of SSL and HTTPS in Android apps. Since the permissions used bythe apps during SSL connection establishment are legitimate and necessary, the currentpermissions-based countermeasures would not help.There are several good overviews of the Android security model and threat landscape,such as Vidas et al. [170], Shabatai [171] et al. and Enck et al. [165], [172]. These papersdo not discuss the vulnerability of SSL or HTTPS on Android. Enck et al. [165] doesmention that some apps use sockets directly, bearing the potential for vulnerabilities,but no malicious use was found (cf. [165], Finding 13). The investigation in this researchshows that there are several SSL-related vulnerabilities in Android apps, endangeringmillions of users.McDaniel et al. [173] and Zhou et al. [174] also mainly focus on malicious apps intheir work on the security issues associated with the app market model of softwaredeployment. The heuristics of DroidRanger [174] could be extended to detect thevulnerabilities uncovered in this work.SSL SecurityA good overview of current SSL problems can be found in Moxi Marlinspike\u2019s BlackHat talks [166], [167]. The talks cover issues of security indicators, Common Name (CN)mismatches and the large number of trusted CAs and intermediate CAs. Marlinspikealso introduces the SSL Stripping attack. The fact that many HTTPS connections areinitiated by clicking a link or via redirects is particularly relevant for mobile devices,since the MITMA needed for SSL Stripping is easier to execute against mobile devices[32], [33] and the visual indicators are hard to see on mobile devices.Shin et al. [175] study the problem of SSL Stripping for desktop browsers and presenta visual-security-cue-based approach to hinder SSL Stripping in this environment. Theyalso highlight the particular problem of this type of attack in the mobile environmentand suggest that it should be studied in more detail.Egelman et al. [176] and Sunshine et al. [177] both study the effectiveness of browserwarnings, showing that their effectiveness is limited and that there are significant us-ability issues. Although both of these studies were conducted in a desktop environment,the same caveats need to be considered for mobile devices. In this research, a first onlinesurvey was conducted to gauge the awareness and effectiveness of browser certificatewarnings and HTTPS visual security indicators on Android.5.2.4 Evaluating Android SSL UsageThe study of Android SSL security encompasses 13,500 popular free apps from Google\u2019sPlay Market.MalloDroid, an extension of the Androguard reverse engineering frame-work, was build to automatically perform the following steps of static code analysis:Permissions. MalloDroid checks which apps request the INTERNET permission, whichapps actually contain INTERNET permission-related API calls and which apps addi-tionally request and use privacy-related permissions (c.f. [159]).Networking API Calls. MalloDroid analyzes the use of HTTP transport and Non-HTTPtransport (e. g., direct socket connections).1425.2 TLS Usage in Android AppsHTTP vs. HTTPS. MalloDroid checks the validity of URLs found in apps and groupsthe apps into HTTP only, mixed mode (HTTP and HTTPS) and HTTPS only.HTTPS Available. MalloDroid tries to establish a secure connection to HTTP URLsfound in apps.Deployed Certificates. MalloDroid downloads and evaluates SSL certificates of hostsreferenced in apps.SSL Validation. MalloDroid examines apps with respect to inadequate SSL validation(e. g., apps containing code thats allows all hostnames or accepts all certificates).12,534 (92.84%) of the apps in the test set request the network permission android.permission.INTERNET. 11,938 (88.42%) apps actually perform networking related APIcalls. 6,907 (51,16%) of the apps in the sample use the INTERNET permission in additionto permissions to access privacy related information such as the users\u2019 calendars,contacts, browser histories, profile information, social streams, short messages or exactgeographic locations. This subset of apps has the potential to transfer privacy-relatedinformation via the Internet. This subset does not include apps such as banking,business, email, social networking or instant messaging apps that intrinsically containprivacy-relevant information without requiring additional permissions.It was found that 91.7% of all networking API calls are related to HTTP(S). Therefore,the decision was made to focus the further analysis on the usage of HTTP(S). To findout whether an app communicates via HTTP, HTTPS, or both, MalloDroid analyzesHTTP(S) specific API calls and extracts URLs from the decompiled apps.HTTP vs. HTTPSMalloDroid extracted 254,022 URLs. It can be configured to remove certain types ofURLs for specific analysis. For this study, the 58,617 URLs pointing to namespacedescriptors and images were removed, since these typically are not used to transmitsensitive user information. The remaining 195,405 URLs pointed to 25,975 unique hosts.29,685 of the URLs (15.2%) pointing to 1,725 unique hosts (6.6%) are HTTPS URLs.Then is was analyzed how many of the hosts referenced in HTTP URLs could also havebeen accessed using HTTPS.76,435 URLs (39.1%) pointing to 4,526 hosts (17.4%) allowed a valid HTTPS connectionto be established, using Android\u2019s default trust roots and validation behavior of currentbrowsers. This means that 9,934 (73.6%) of all 13,500 tested apps could have usedHTTPS instead of HTTP with minimal effort by adding a single character to the targetURLs. It was found that 6,214 (46.0%) of the apps contain HTTPS and HTTP URLssimultaneously and 5,810 (43.0%) do not contain HTTPS URLs at all. Only 111 apps(0.8%) exclusively contained HTTPS URLs.For a more detailed investigation, it was looked at the top 50 hosts, ranked bynumber of occurrences. This group mainly consists of advertising companies and socialnetworking sites. These two categories account for 37.9% of the total URLs found,and the hosts are contained in 9,815 (78.3%) of the apps that request the INTERNETpermission.Table 5.1 presents an overview of the top 10 hosts. The URLs pointing to the thesehosts suggest they are often used for Web Service API calls, authentication and fetch-ing/sending user or app information. Especially in the case of ad networks that1435 Security Vulnerability Analysis of Mobile Appscollect phone identifiers and geolocations [164] and social networks that transportuser-generated content, the contained information is potentially sensitive.Table 5.1: The top 10 hosts used in all extracted URLs and their SSL availability, total number of URLs andnumber of HTTPS URLs pointing to that host.Host has SSL # URLs # HTTPSmarket.android.com \u2713 6,254 3,217api.airpush.com \u2713 5,551 0a.admob.com \u2713 4,299 0ws.tapjoyads.com \u2713 3,410 3399api.twitter.com \u2713 3,220 768data.flurry.com \u2713 3,156 1,578data.mobclix.com \u2713 2,975 0ad.flurry.com \u2713 2,550 0twitter.com \u2713 2,410 129graph.facebook.com \u2713 2,141 1,94134 of the top 50 hosts offer all their API calls via HTTPS, but none is accessed exclu-sively via HTTPS. Of all the URLs pointing to the top 50 hosts, 22.1% used HTTPS, 61.0%could have used HTTPS by substituting http:// withhttps://, and 16.9% had to use HTTP because HTTPS was not available. The hostsfacebook.com and tapjoyads.com are positive examples, since the majority of theURLs found for these two hosts already use HTTPS.Deployed SSL CertificatesTo analyze the validity of the certificates used by HTTPS hosts, the SSL certificatesfor all HTTPS hosts extracted from our app test set were downloaded, yielding 1,887unique SSL certificates. Of these certificates, 162 (8.59%) failed the verification ofAndroid\u2019s default SSL certificate verification strategies, i. e., 668 apps contain HTTPSURLs pointing to hosts with certificates that could not be validated with the defaultstrategies. 42 (2.22%) of these certificates failed SSL verification because they wereself-signed, i. e., HTTPS links to self-signed certificates are included in 271 apps. 21(1.11%) of these certificates were already expired, i. e., 43 apps contain HTTPS links tohosts with expired SSL certificates.For hostname verification, two different strategies were applied that are also avail-able in Android: the BrowserCompatHostnameVerifier16 and the StrictHostnameVerifier17strategy. 112 (5.94%) certificates were found that did not pass strict hostname verifi-cation, of which 100 certificates also did not pass the browser compatible hostnameverification. Mapping these certificates to apps revealed that 332 apps contained HTTPSURLs with hostnames failing the BrowserCompatHostnameVerifier strategy.Overall, 142 authorities signed 1,887 certificates. For 45 (2.38%) certificates, no validcertification paths could be found, i. e., these certificates were signed by authorities notreachable via the default trust anchors. These certificates are used by 46 apps. All in all,16https://bit.ly/IKR9cD17https://bit.ly/Ixy9kr1445.2 TLS Usage in Android Apps394 apps include HTTPS URLs for hosts that have certificates that are either expired,self-signed, have mismatching CNs or are signed by non-default-trusted CAs.Custom SSL ValidationUsing MalloDroid, 1,074 apps (17.28% of all apps that contain HTTPS URLs) werefound that include code that either bypasses effective SSL verification completely byaccepting all certificates (790 apps) or that contain code that accepts all hostnames for acertificate as long as a trusted CA signed the certificate (284 apps).While an app developer wishing to accept all SSL certificates must implementthe TrustManager interface and/or extend the SSLSocketFactory class, allowing allhostnames only requires the use of the AllowAllHostnameVerifier class from theorg.apache.http.conn.ssl package that is included in 453 apps. Additionally, Mal-loDroid found a FakeHostnameVerifier, NaiveHostnameVerifier and AcceptAll-HostnameVerifier class that can be used in the same way.To understand how apps use \u2019customized\u2019 SSL implementations, it was searchedfor apps that contain non-default trust managers, SSL socket factories and hostnameverifiers differing from the BrowserCompatHostnameVerifier strategy. Here 86 customtrust managers and SSL socket factories were found in 878 apps. More critically, theanalysis also discovered 22 classes implementing the TrustManager interface and 16classes extending the SSLSocketFactory that accept all SSL certificates. Table 5.2 showswhich broken trust managers and SSL socket factories were found.Table 5.2: Trust Managers & Socket Factories that trust all certificates (suffixes omitted to fit the page)Trust Managers SSL Socket FactoriesAcceptAllTrustM AcceptAllSSLSocketFAllTrustM AllTrustingSSLSocketFDummyTrustM AllTrustSSLSocketFEasyX509TrustM AllSSLSocketFFakeTrustM DummySSLSocketFFakeX509TrustM EasySSLSocketFFullX509TrustM FakeSSLSocketFNaiveTrustM InsecureSSLSocketFNonValidatingTrustM NonValidatingSSLSocketFNullTrustM NaiveSslSocketFOpenTrustM SimpleSSLSocketFPermissiveX509TrustM SSLSocketFUntrustedCertSimpleTrustM SSLUntrustedSocketFSimpleX509TrustM TrustAllSSLSocketFTrivialTrustM TrustEveryoneSocketFTrustAllManager NaiveTrustManagerFTrustAllTrustM LazySSLSocketFTrustAnyCertTrustM UnsecureTrustManagerFUnsafeX509TrustMVoidTrustM1455 Security Vulnerability Analysis of Mobile AppsThis small number of critical classes affects a large number of apps. Many of thefound classes belong to libraries and frameworks that are used by many apps. 313apps contained calls to the NaiveTrustManager class that is provided by a crashreport library.18 In 90 apps, MalloDroid found the NonValidatingTrustManager classprovided by an SDK19 for developing mobile apps for different platforms with just asingle codebase. The PermissiveX509TrustManager20, found in a library for sendingdifferent kinds of push notifications to Android devices, is included in 76 apps. Finally,in 78 apps, MalloDroid found a SSLSocketFactory provided by a developer library21that accepts all certificates. The library is intended to support developers to writewell designed software and promotes itself as a library for super-easy and robustnetworking. Using any of the above Trust Managers or Socket Factories results in theapp trusting all certificates.5.2.5 MITMA StudyThe static code analysis presented above only shows the potential for security problems.The fact that code for insecure SSL is present in an app does not necessarily mean thatit is used or that sensitive information is passed along it. Even more detailed automatedcode analysis, such as control flow analysis, data flow analysis, structural analysis andsemantic analysis cannot guarantee that all uses are correctly identified [165]. Thus,the decision was made to conduct a more detailed manual study to find out whatsort of information is actually sent via these potentially broken SSL communicationchannels, by installing apps on a real phone and executing an active MITMA againstthe apps. For this part of the study, the search was narrowed down to apps from theFinance, Business, Communication, Social and Tools categories, where one can suspecta higher amount of privacy-related information and a higher motivation to protect theinformation. In this test set, there are 266 apps containing broken SSL or hostnameverifiers (Finance: 45, Social: 94, Communication: 49, Business: 60, Tools: 18). Theseapps were ranked based on their number of downloads and selected the top 100 appsfor manual auditing. Additionally, 10 high profile apps (large install base, popularservices) were cherry-picked that contained no SSL-related API calls but containedpotentially sensitive information, to see whether this information was actually sent inthe clear or if some protection mechanism other than SSL was involved.Test EnvironmentFor the manual app auditing process, a Samsung Galaxy Nexus smartphone withAndroid 4.0 Ice Cream Sandwich was used. The potentially vulnerable apps wereinstalled on the phone and a WiFi access point with a MITM SSL proxy was set up.Depending on the vulnerability to be examined, the SSL proxy was equipped eitherwith a self-signed certificate or with one that was signed by a trusted CA, but for anunrelated hostname.Of the 100 apps selected for manual audit, 41 apps proved to have exploitablevulnerabilities. It was possible to gather bank account information, payment credentials18Application Crash Report for Android (ACRA) library org.acra.util.NaiveTrustManager19Titanium Mobile ti.modules.titanium.network.NonValidatingTrustManager20Urban Airship library client.ssl.PermissiveX509TrustManager21Droid-Fu library com.github.droidfu.http.ssl.EasySSLSocketFactory1465.2 TLS Usage in Android Appsfor PayPal, American Express and others. Furthermore, Facebook, email and cloudstorage credentials and messages were leaked, access to IP cameras was gained andcontrol channels for apps and remote servers could be subverted. According to Google\u2019sPlay Market, the combined install base of the vulnerable apps in our test set of 100apps was between 39.5 and 185 million users at the time of writing. In the following,the findings are briefly discussed to illustrate the scope of the problem.Trusting All Certificates21 apps among the 100 selected apps fell into this category. The MITMA proxy wasgiven a self-signed certificate for the attack. The apps leaked information such as logincredentials, webcam access or banking data. One noteworthy contender was a genericonline banking app.22 The app uses separate classes for each bank containing differenttrust manager implementations. 24 of the 43 banks supported were not protectedfrom the MITMA. The app also leaks login credentials for American Express, DinersClub and Paypal. The Google Play Market reports an install base between 100,000 andhalf a million users. A further app in this category offers instant messaging for theWindows Live Messenger service23. The app has an install base of 10 to 50 million usersand is listed in the top 20 apps for the communication category in the Google PlayMarket (as of April 30th, 2012). Username and password are both sent via a brokenSSL channel and were sniffed during the attack. This effectively gives an attacker fullaccess to a Windows Live account that can be used for email, messaging or Microsoft\u2019sSkyDrive cloud storage. Also in this category, a browser24 with an install base between500,000 and one million users was found. The browser does not correctly handle SSL atall, i. e., it accepts an arbitrary certificate for every website the user visits and henceleaks whatever data the user enters. All three apps do not provide any SSL controlor configuration options for the user. None of the other apps in this category showedwarning messages to the user while the MITMA was being executed.Allowing All HostnamesThe second category of apps analyzed is the group of 20 apps that accepted certificatesirrespective of the subject name, i. e., if the app wants to connect to https://www.paypal.com, it would also accept a certificate issued to some-domain.com. A certificatefor an unrelated domain signed by startSSL25 was used for the attacks in this category.The apps leaked information such as credentials for different services, emails, textmessages, contact data, bitcoin miner api keys, premium content or access to onlinemeetings. A particularly interesting find was an anti-virus app that updated its virussignatures file via a broken SSL connection. Since it seems that the connection wasconsidered secure, no further validation of the signature files is performed by the app.Thus it was possible to feed a modified signature file to the anti-virus engine. First,an empty signature database was sent which was accepted, effectively turning off theanti-virus protection without informing the user. In a second attack, a virus signaturefor the anti-virus app itself was created and then sent it to the phone. This signature22com.liato.bankdroid23miyowa.android.microsoft.wlm24sui.m25https://www.startssl.com/1475 Security Vulnerability Analysis of Mobile Appswas accepted by the app, which then recognized itself as a virus and recommended todelete itself, which it also did. Figure 5.1 shows a screenshot of the result of this attack.This is a very stark reminder that defense in depth is an important security principle.Since the SSL connection was deemed secure, no further checks were performed todetermine whether the signature files were legitimate. The app has an install base of500,000 to one million users.26Figure 5.1: After injecting a virus signature database via a MITM attack over broken SSL, the AntiVirusapp recognized itself as a virus and recommended to delete the detected malware.A second example in this category is an app that offers \u201dSimple and Secure\u201d cloud-based data sharing.27 According to the website, the app is used by 82% of the FORTUNE500 companies to share documents. It has an install base between 1 and 5 million users.While the app offers simple sharing, it leaks the login credentials during the MITMA.One interesting finding in this app was that the login credentials were leaked from abroken SSL channel while up- and downloads of files were properly secured. However,using the login credentials obtained from the broken channel is sufficient to hijack anaccount and access the data anyway.A third example is a client app for a popular Web 2.0 site28 with an install base of500,000 to 1 million users. When using a Facebook or Google account for login, the appinitiates OAuth login sequences and leaks Facebook or Google login credentials.Also a very popular cross-platform messaging service was successfully attacked.29While the app has been criticized for sending messages as plaintext and thereforeenabling Eve to eavesdrop, the SSL protection that was intended to secure \u2019sensitive\u2019information such as registration credentials and the user\u2019s contact does not protect26appcom.zoner.android.antivirus \u2013 honored as the \u201dBest free anti-virus program for Android\u201d with adetection rate > 90% \u2013 http: // www. av-test. org/ en/ tests/ android/27com.box.android28com.yahoo.mobile.client.android.flickr29com.whatsapp1485.2 TLS Usage in Android Appsfrom Mallory. For instance, one is able to obtain all telephone numbers from a user\u2019saddress book using a MITMA. At the time of writing, the app had an install base of 10to 50 million users.SSL StrippingSSL Stripping (cf. Section 5.2.2) can occur if a browsing session begins using HTTP andswitches to HTTPS via a link or a redirect. This is commonly used to go to a securelogin page from an insecure landing page. The technique is mainly an issue for Androidbrowser apps, but it can also affect other apps using Android\u2019s webkit.WebView thatdo not start a browsing session with a HTTPS site. The webkit.WebView was found in11,038 apps. Two noteworthy candidates from this category concern a social networkingapp30 and an online portal app31 client app. Both apps use the webkit view to enhanceeither the social networking experience or surf the portal and have 1.5 to 6 millioninstalls. The two apps start the connection with a HTTP landing page, and one couldrewrite the HTTPS redirects to HTTP and thus catch the login credentials for Facebook,Yahoo and Google.One way to overcome this kind of vulnerability is to force the use of HTTPS, asproposed by the HTTP Strict Transport Security IETF Draft32, or using a tool suchas HTTPS-Everywhere.33 However, these options currently do not exist for Android.Android\u2019s default browser as well as available alternatives such as Chrome, Firefox,Opera or the Dolphin Browser do not provide HTTPS-Everywhere-like features out ofthe box, nor could any add-ons for such a feature be found.Lazy SSL UseAlthough the Android SDK does not support SSL pinning out of the box, Android appscan also take advantage of the fact that they can customize the way SSL validation isimplemented. Unlike general purpose web browsers that need to be able to connect toany number of sites as ordained by the user, many Android apps focus on a limitednumber of hosts picked by the app developer: for example, the PayPal app\u2019s maininteraction is with paypal.com and its sister sites. In such a case, it would be feasible toimplement SSL pinning, either selecting the small number of CAs actually used to signthe sites or even pin the precise certificates. This prevents rogue or compromised CAsfrom mounting MITM attacks against the app. To implement SSL pinning, an app canuse its own KeyStore of trusted root CA certificates or implement a TrustManager thatonly trusts specific public key fingerprints.To investigate the usage of SSL pinning, 20 high profile apps were cherry-picked thatwere not prone to the previous MITM attacks and manually audited. An own root CAcertificate was installed on the phone and a SSL MITM proxy set up that automaticallycreated CA-signed certificates for the hosts an app connects to. Then MITM attackswere executed against the apps. Table 5.3 shows the results. Only 2 of the apps makeuse of SSL pinning and thus were safe from the attack. All other apps trust all root30com.jmt.application.facebookthemes.activity31com.yahoo.mobile.client.android.yahoo32https://bit.ly/IJrVh533https://www.eff.org/https-everywhere1495 Security Vulnerability Analysis of Mobile AppsCA signatures, as long as they are part of Android\u2019s trust anchors, and thus werevulnerable to the executed attack.Table 5.3: Results of the SSL pinning analysis.App Installs SSL PinningAmazon MP3 10-50 millionChrome 0.5-1 millionDolphin Browser HD 10-50 millionDropbox 10-50 millionEbay 10-50 millionExpedia Bookings 0.5-1 millionFacebook Messenger 10-50 millionFacebook 100-500 millionFoursquare 5-10 millionGMail 100-500 millionGoogle Play Market All PhonesGoogle+ 10-50 millionHotmail 5-10 millionInstagram 5-10 millionOfficeSuite Pro 6 1-5 millionPayPal 1-5 millionTwitter 50-100 million \u2713Voxer Walkie Talkie 10-50 million \u2713Yahoo! Messenger 10-50 millionYahoo! Mail 10-50 millionMissing FeedbackWhen an app accesses the Internet and sends or receives data, the Android OS does notprovide any visual feedback to the user whether or not the underlying communicationchannel is secure. The apps are also not required to signal this themselves and there isnothing stopping an app from displaying wrong, misguided or simply no information.Several apps were found that provided SSL options in their settings or displayed visualsecurity indicators, however failed to establish secure SSL channels for different reasons.Banking apps34 were found in this category that could not be fully tested, sincebank accounts were required there. However, these apps stated that they were usingSSL-secured connections and displayed green visual security indicators, but sufferedfrom one of the MITMA vulnerabilities shown above. It was therefore possible tointercept login credentials, which would enable one to disable cards and gather accountinformation using the app.Several prominent mail apps were found that had issues with missing feedback.Both were dedicated apps for specific online services. The first app35 with an install34com.vrm.hessenland, com.vrm.mindenerland35com.yahoo.mobile.client.android.mail.apk1505.2 TLS Usage in Android Appsbase between 10 and 50 million users handled registration and login via a secure SSLconnection, but the default settings for sending and receiving email are set to HTTP.This can be changed by the user, but the user must be aware of the issue to do this andthere was no indication that the emails were not protected.An instant messaging app36, with an install base of 100,000 to 500,000 users, transferslogin credentials via a non-SSL protected channel. Although the user\u2019s password istransferred in encrypted form, it does not vary between log-ins, so Eve can record thepassword and could use it in a replay attack to hijack the user\u2019s account.Figure 5.2: A sample warning message that occurs in an app that is MITM attacked.A framework37 was found that provides a graphical app builder, allowing users to eas-ily create apps for Android and other mobile platforms. Apps created with this frame-work can load code from remote servers by using the dalvik.system.DexClassLoader.Downloading remote code is handled via plain HTTP. One app38 built with the frame-work was analyzed and it was possible to inject and execute arbitrary Java code, sincethe downloaded code is not verified before execution.During manual analysis, it was also found that 53 apps that were not vulnerable tothe MITM attacks did not display a meaningful warning messages to the user underattack. These apps simply refused to work and mostly stated that there were technicalor connectivity problems and advised the user to try to reconnect later. There was alsoan app39 that recommended an app-update to eliminate the network connection errors.Some apps simply crashed without any announcement. Figure 5.2 shows a confusingsample error message displayed during a MITMA.40An additional 6 apps not vulnerable to the MITM attacks did display certificaterelated warning messages, but did not indicate the potential presence of a MITMA. Theofficial Facebook app41 is not vulnerable to the MITM attacks described above and is apositive example for displaying a meaningful warning message. Even if the warningmessage contains tech-savvy wording, the user at least has the chance to realize that aMITM attack might be occuring (cf. Fig. 5.3).Interestingly \u2013 excluding browser apps \u2013 there was only one app that let the userchoose to continue in the presence of an SSL error.36cn.msn.messenger37http://ibuildapp.com/38com.appbuilder.u36633p9281139de.aboalarm.kuendigungsmaschine40com.yahoo.mobile.client.android.flickr41com.facebook.katana.apk1515 Security Vulnerability Analysis of Mobile AppsFigure 5.3: Facebook\u2019s SSL warning.A complete list of all apps found vulnerable to on MITM attack or another can befound at the end of this section (Sec 5.2.10).5.2.6 Limitations of our AnalysisThis study has the following limitations: a) During static code analysis, the studiedapplications were selected with a bias towards popular apps; b) The provided installbase numbers are only approximate values as provided by Google\u2019s Play Market; c) Only100 of the apps where MalloDroid found occurrences of broken SSL implementationswere manually audited. For the rest, the existence of the unsafe code does not meanthat these apps must be vulnerable to a MITM attack; d) Static code analysis mighthave failed in some apps, for instance if they were obfuscated. Hence, there might befurther vulnerable apps that were not classified as such; e) During manual audits, theapplications were selected with a bias towards popularity and assumed sensitivity ofdata they handle; f) It was not possible to test the entire workflow of all apps, e. g., itwas not possible to create a foreign bank account to see what happens after successfullylogging into the bank account.5.2.7 Trouble in ParadiseThe default Android browser uses sensible trust managers and host name verifiers.Also, unlike most special purpose apps, it displays a meaningful error message whenfaced with an incorrect certificate and allows the user to continue on to the site ifthe user wants to. Thus, it relies on the ability of the user to understand what thedisplayed warning messages mean and what the safest behavior is. There have beenmany studies of this issue conducted in the context of desktop browsing. Here, to thebest of knowledge, a first survey was conducted for this research to investigate theusers\u2019 perceptions when using secure connections in the Android browser.1525.2 TLS Usage in Android AppsOnline SurveyThe goal of the online survey was to explore whether or not the user can assess thesecurity of a connection in the Android browser. Goal was to test that a) a user candistinguish a HTTPS connection from a regular HTTP connection and b) how theuser perceives a SSL warning message. Previous work has addressed the effectivenessof warning dialogues in several scenarios, mostly for phishing on regular computers(e. g., [176], [177]). Recently, Porter Felt et al. [160] conducted a survey on the promptsinforming users of the requested permissions of Android apps during installation. Theonline survey in this research is based on a similar design, but studies SSL certificatewarnings and visual security indicators in Android\u2019s default browser.Participants were recruited through mailing lists of several universities, companiesand governmental agencies. The study invitation offered a chance to win a 600$ voucherfrom Amazon for participation in an online survey about Android smartphone usage.The survey could only be accessed directly from an Android phone. The survey wasserved via HTTPS for one half of the participants and via HTTP for the other. Afteraccessing a landing page, the participants were shown a typical Android certificatewarning message, mimicking the behavior of the Android browser. Subsequently, it wasasked whether the participants had seen this warning before, if they had completelyread its text and how much risk they felt they are warned against. Also of interest wasto know whether or not they believed to be using a secure connection and their reasonsfor this belief. Finally, demographic information on technical experience, Androidusage, previous experience with compromised credentials or accounts as well as age,gender and occupation was collected.Results754 participants completed the survey. The average age was 24 years (sd = 4.01), 88.3%were students while the rest mainly were employees. 61.9% of the participants didnot have an IT-related education or job (non-IT experts in the following) and 23.2%had previous experience with compromised credentials or accounts. Overall, the self-reported technical confidence was high: participants stated a mean value of 4.36 for ITexperts and 3.58 for non-experts on a scale from 1 (often asking for help) to 5 (oftenproviding help to others). 51.9% of IT experts and 32.8% of non-IT experts have beenusing an Android smartphone for more than a year and 57.1% of experts and 69.8% ofnon-experts had only 25 apps or less installed.Concerning connection security, it was found that 47.5% of non-IT experts believedto be using a secure connection, while the survey was served over HTTP. On top of that,even 34.7% of participants with prior IT education thought that they were using a securechannel when they were not. In both groups, 22.4% were unsure about the protectionof their connection. Only 58.9% of experts and 44.3% of non-experts correctly identifiedthat they were using a secure or insecure connection when prompted. The majority ofusers referred to the URL prefix as the reason for their beliefs and 66.5% of participantsthat were unsure said that they did not know how to judge the connection security.Those users that were wrongly assuming a secure connection stated that they use atrustworthy provider (47.7%), trust their phone (22.7%) or thought that the addresswas beginning with https:// even though it was not (21.6%) as a justification for theirbeliefs. Interestingly, participants that stated that they had suffered from compromised1535 Security Vulnerability Analysis of Mobile Appscredentials or online accounts before did significantly better in judging the connectionstate (\u03c72 = 85.36, d f = 6, p < 0.05).Concerning the warning message, the majority of participants stated that they hadnot seen such a certificate warning before (57.6% of non-IT experts and 52.3% of ITexperts) or were unsure (5.9%/9.2%). 24.0% of all participants only read the warningpartially and 4.5% did not read it at all. These numbers did not differ significantlybased on whether or not they had seen the warning before. The participants rated therisk they were warned against with 2.86 (sd = .94), with 1 being a very low risk and 5 avery high risk. The perceived risk did not differ significantly between IT-experts andother users.Overall, the results of our online survey show that assessing the security of a browsersession on Android\u2019s default browser was problematic for a large number of ourparticipants. While certificate handling is done correctly by the browser app and basicvisual security indicators are offered, the user\u2019s awareness for whether or not his datais effectively protected is frequently incomplete.LimitationsThe survey is limited in the following ways: Official mailing lists were used to distributethe invitation for the survey. While, on a technical level, this should not affect thetrustworthiness of the mail or the survey site - the emails were not digitally signed andthe survey was served with an URL that was not obviously linked to the university.Therefore, the emails could have been spoofed. Nonetheless, it is likely that a higherlevel of trust was induced in most participants, due to the fact that the survey wasadvertised as a university study (c.f. [178]). Therefore it was refrained from evaluatingthe users\u2019 reasons for accepting or rejecting a certificate in this concrete scenario.Participants were self-recruited from multiple sources, but mainly entries from univer-sity students for this first exploration were received. While a study by Sotirakopoulos etal. [179] found little differences between groups of students and the broader populationin the usable security context, a more varied sample of participants would improve thegeneral applicability of the results.5.2.8 CountermeasuresThere are several ways to minimize the problem of unencrypted traffic or SSL misuse.They can be categorized into three groups: (1) solutions integrated into the AndroidOS, (2) solutions integrated into app markets and (3) standalone solutions.1545.2 TLS Usage in Android AppsOS SolutionsEnforced Certificate Checking A radical solution to prevent the use of overly per-missive TrustManagers, SSLSocketFactorys and AllowAllHostnameVerifiers is todisallow custom SSL handling completely. This can be achieved by forcing developersto use the standard library implementations provided by Android\u2019s APIs. By limit-ing the way TrustManagers, SSLSocketFactorys and HostnameVerifiers can be used,most cases of faulty code and unintended security flaws could be avoided.HTTPS Everywhere A solution to improve a fair number of the vulnerabilities dis-covered in the test set would be an Android version of HTTPS-Everywhere, integratedinto the communication APIs. This would prevent most SSL Stripping attacks werefound in the test set.Improved Permissions and Policies Instead of simply having a general permissionfor Internet access, a more fine-grained policy model could allow for more control(cf. [159]). By introducing separate permissions for INTERNET SSL and INTERNET PLAIN,apps could indicate which type of connections are used. This would give users achance to avoid applications that do not use HTTPS at all. However, in mixed modecases or when SSL is used but used incorrectly, this method would not protect theuser without additional indicators/countermeasures. Furthermore, introducing policieslike GSM ONLY, NO OPEN WIFI or TRUSTED NETWORKS could help to protect apps fromsome MITM attacks. Despite the fact that cellular networks such as GSM/3G/4G donot provide absolute security, they still require considerably more effort to executean active MITMA. Apps could then specify which types of networks or even whichconnections specifically are allowed to be used. However, this countermeasure couldhave considerable usability and acceptance issues.Visual Security Feedback Reasonable feedback to the user about the security statusof the currently running application is undoubtedly a valuable countermeasure \u2013 atleast for some users. The operating system should provide visual feedback on whetheror not apps are communicating via a secure channel. Current mobile devices usuallyonly show the signal strength, the connection type and whether any transfers are inprogress at all. Finding an effective way to inform users about which apps are currentlycommunicating with the Internet and whether the communication is secure is nottrivial and should be studied carefully before a solution is propagated.MalloDroid Installation Protection MalloDroid could be integrated into app installers,such as Kirin [158], to perform static code analysis at install time. This analysis per-formed directly on a phone could warn of potentially unsafe applications. The userwould then have to decide if he wishes to install the app irrespective of the warning.App Market SolutionsSimilar to the MalloDroid installation protection, MalloDroid could be integrated intoapp markets. This form of automated checking of apps could either be used to rejectapps from entering the market or warnings could be added to the app\u2019s description.Both options have usability and acceptance issues that need to be studied.1555 Security Vulnerability Analysis of Mobile AppsStandalone Solution: The MalloDroid App & ServiceAll countermeasures mentioned above require modification of the Android OS andsupport from Vendors and/or app markets. Standalone solutions can be deployed moreeasily. Therefore, as a stop-gap measure, the MalloDroid tool is going to be offeredboth as a Web and Android app. This will at least allow interested users to check onapps before they install them. The Android app will also offer a convenience featurechecking all installed applications. MalloDroid can of course also be used as-is withAndroguard.5.2.9 ConclusionIn this research, an investigation of the current state of SSL/TLS usage in Androidand the security threats posed by benign Android apps that communicate over theInternet using SSL/TLS was presented. MalloDroid, a tool that uses static code analysisto detect apps that potentially use SSL/TLS inadequately or incorrectly and thusare potentially vulnerable to MITM attacks, was developed.The analysis of 13,500popular free apps from the Google Play Market has shown that 1,074 apps contain codebelonging to this category. These 1,074 apps represent 17.0% of the apps that containHTTPS URLs. To evaluate the real threat of such potential vulnerabilities, MITM attacksagainst 100 selected apps from that set have been mounted manually. This manual audithas revealed wide spread and serious vulnerabilities. The credentials for AmericanExpress, Diners Club, Paypal, Facebook, Twitter, Google, Yahoo, Microsoft Live ID, Box,WordPress, IBM Sametime, remote servers, bank accounts and email accounts havebeen captured. It was possible to successfully manipulate virus signatures downloadedvia the automatic update functionality of an anti-virus app to neutralize the protectionor even to remove arbitrary apps, including the anti-virus program itself. Furthermore,it was possible to remotely inject and execute code in an app created by a vulnerableapp building framework. The cumulative number of installs of apps with confirmedvulnerabilities against MITM attacks is between 39.5 and 185 million users, accordingto Google\u2019s Play Market.The results of the online survey with 754 participants showed that there is someconfusion among Android users as to which security indicators are indicative of asecure connection, and about half of the participants could not judge the security stateof a browser session correctly. Possible countermeasures were discussed that couldalleviate the problems of unencrypted traffic and SSL misuse. MalloDroid is offered asa first countermeasure to possibly identify potentially vulnerable apps.The findings of the investigation suggest several areas of future work. The intentionis to provide a MalloDroid Web App and Android App and will make it available toAndroid users. Moreover, there seems to be a need for more education and simplertools to enable easy and secure development of Android apps. But most importantly,research is needed to study which countermeasures offer the right combination ofusability for developers and users, security benefits and economic incentives to bedeployed on a large scale.1565.2 TLS Usage in Android Apps5.2.10 List of Apps With Broken SSL UsageThe following table gives an overview of the apps that we found vulnerable to MITMattacks. Either accepting all certificates (1) or allowing all hostnames (2) orbeing vulnerable for SSL Stripping (3).App Installs Vuln CommentBankdroid 100k-500k(1) Banking app. Leaks banks, Mastercard, Diners Cluband Paypal credentials.Bo\u00a8rse Mobil 10k-50k (1) Shows stock market information. Leaks login cre-dentials.CashBase 1k-5k (1) Wallet app, keeps track of spendings. Leaks logincredentials.Dolphin Browser HD 10m-50m (1) Web browser. Leaks credentials for Dolphin Con-nect.FriendScout24 10m-50m (1) Dating App. Leaks login credentials.IBM Sametime 10m-50m (1) IBM Sametime client. Leaks login credentials.IP Cam Viewer 100m-500m(1) App for viewing and controlling IP cameras.Leaks login credentials, gives Mallory access video-/audiostream.Last FM 1m-5m (1) App for sharing favorite music. Leaks data duringlogin process.Mamba 100k-500k(1) Dating app. Leaks account information.Messenger With You 10m-50m (1) MSN Messenger. Sends the credentials in an obfus-cated way.Mobli 100k-500k(1) Photo sharing app. Leaks credentials, contacts andGPS location.Pinger SMS Free 10k-50k (1) SMS app. Leaks login credentials.Pizza.de 100k-500k(1) Pizza ordering app. Leaks login credentials.SonicWALL MobileConnect5k-10k (1) Firewall administration, Establishes connection viabroken SSL.Total Recall 500k-1m (1) Call recorder. Checks premium status over brokenSSL.TouchDown Tablet 50k-100k (1) Exchange and Active Sync mail app. Leaks logincredentials.VR Banking 1k-5k (1) Banking application. Credentials and PIN are trans-mitted over broken SSL.VZ-Netzwerke 500k-1m (1) Social network client. Leaks data during login pro-cess.WordPress 1m-5m (1) Blogging tool. Leaks account information.World of Tanks Assis-tant100k-500k(1) Gaming asistant tool. Leaks credentials.xScope Browser 500k-1m (1) Browser, that accepts arbitrary certificates.AlwaysOnPC-HD:Office,Chrome10k-50k (2) Virtual PC app. Leaks login credentials.BILD 500k-1m (2) News app with premium features. Checks premiussubscription over broken SSL, allowing a MITM toobtain such a subscription.Box 1m-5m (2) Document sharing application for enterprises. Leakslogin credentials.1575 Security Vulnerability Analysis of Mobile AppsCisco WebEx Meetings 100k-500k(2) Cisco WebEx client. Leaks login credentials.DS file 100k-500k(2) Access remote files.Flickr 500k-1m (2) Flickr client. Leaks Facebook/Google credentialsduring login.Forfone 500k-1m (2) App for the SIP protocol and text messages. Leakslogin credentials and data.Formspring 100k-500k(2) Questionaires and photo sharing app. Leaks logincredentials.Hipster 10k-50k (2) Photo sharing and social network app. Leaks logincredentials.HootSuite 100k-500k(2) Social networking app for Facebook, Twitter, etc.Leaks login credentials.HP iLO Mobile 5k-10k (2) Control remote servers. Allows to shutdown servers.Leaks login credentials.MailDroid 500k-1m (2) MailDroid is a free IMAP/POP3/Exchange emailclient. It leaks login credentials as well as emailsthemselves.Miner Status 5k-10k (2) Bitcoin mining status app. Leaks the miner-API key.Monster 1m-5m (2) Job search app. Leaks login credentials.Moxier Mail Trial 100k-500k(2) Exchange Active Sync mailing app. Leaks login cre-dentials.Posterous Spaces 100k-500k(2) Photo and Video sharing app. Leaks login creden-tials.Privat24 50k-100k (2) Banking app. Leaks login credentials.TouchDown Phone 500k-1m (2) A free Exchange and ActiveSync client. Leaks logincredentials.WhatsApp Messenger 10m-50m (2) Messaging app. Leaks credentials during registra-tion.Zoner AntiVirus Free 100k-500k(2) Antivirus App. Loads signatures over broken SSL,allows the injection of arbitrary signatures.Facebook Themes 500k-1m (3) Color theming for the Facebook website. Leaks Face-book credentials.LetMeCU 100k-500k(3) Dating app. Leaks login credentials.QuickWindowsLiveHotmail100k-500k(3) Email app. Leaks login credentials.Yahoo! 1m-5m (3) Yahoo! news and services. Leaks login credentials.1585.3 AndroLyze: Static Mobile App Analysis5.3 AndroLyze: Static Mobile App Analysis5.3.1 IntroductionWith the rise of mobile applications (\u201cmobile apps\u201d) and the availability of app marketplaces, the security and privacy risks associated with mobile apps increase accordingly.Not only mobile malware is growing, but also the risk for private and corporate dataposed by badly written software as shown in the previous section. As a consequence,more and more security checks are developed [159] [9] [180] [181] [182] to analyzemobile apps. The focus is not solely on identifying malicious software, but also onspotting potential privacy breaches [183] and corporate data leaks [184] or indicatingbad programming issues such as energy bugs [185]. In the last years, researchers didnot only look at cherry picked applications from various market places, but also mass-analyzed apps ranging from a few hundred [159] over several thousand [9] up to overa million mobile apps [182].Performing mobile app analysis in an automated manner is interesting for theresearch community as well as for the corporate world. However, setting up an envi-ronment for different analyses is a tedious task, and conducting mass security scans ofapps is quite time-consuming.In this section, AndroLyze, a distributed framework to analyze large numbers ofapps in an efficient manner, is presented. AndroLyze combines several key features ina novel way that distinguish it from other work on mobile app analysis:\u2022 AndroLyze offers a utility library for standardized writing of static analysis scripts\u2022 AndroLyze provides unified logging and reporting functionality backed by adatabase\u2022 AndroLyze can handle large sets of mobile apps, including different versions ofan app\u2022 AndroLyze achieves efficiency through parallelization and distribution amongCPU cores, CPUs and servers\u2022 AndroLyze relies on optimized job scheduling to obtain faster analysis timesBy having a standardized way of writing and deploying scripts as well as a properlydefined output format, it is much easier to incorporate security checks into the devel-opment process or use the knowledge of various script sources to improve corporatesecurity by enriching black-/white-lists of mobile device management solutions. Todemonstrate the benefits of AndroLyze, the Top Free 500 Android apps of all categoriesin Google Play collected over three years are analyzed. The whole data set consists ofalmost 40,000 apps requiring about 227 GB of storage space.Parts of this section have been published in [10].5.3.2 Related WorkSeveral approaches in the literature rely on Android app analysis, ranging from thedetection of privacy leaks to misuse of cryptography and certificates as well as iden-tification of malicious software. However, very few publications address the issue ofmass-analysis of Android apps. Most approaches are \u201dhand-made\u201d and are only suit-able for a particular use case, and they do not provide version and result management.1595 Security Vulnerability Analysis of Mobile AppsA common basis for manual and automatic app audits has been developed by Desnoset al. [186]. This framework written in Python is called Androguard and offers featuressuch as disassembly, decompilation, control flow graphs and similarity search. The highnumber of features and the possibility to easily write scripts using them, combinedwith constant improvements over the years, added to Androguard\u2019s popularity.Viennot et al. [182] have conducted a study of Google Play and developed PlayDrone, acrawler of the Google Play store including a distributed analysis framework. DownloadedAPKs are decompiled with dex2jar and JD-Core and stored in Git repositories locatedon worker nodes as well as on ElasticSearch. The latter offers full text search and ananalysis engine for an app\u2019s source code. AndroLyze differs from PlayDrone in thefact that it offers a native decompiler and uses MongoDB, a NoSQL database for resultevaluation and storage. Furthermore, it achieves efficiency through parallelization andoptimized job scheduling, and can handle different versions of an app.Fahl et al. [9] have conducted a mass audit of APKs using a script based on Androguardnamed MalloDroid to identify security issues in the use of transport layer encryptionin apps. No special infrastructure used in the analysis is presented, and the system isspecifically tailored to perform SSL/TLS analysis. Cryptography related analysis hasbeen performed by Egele et al. [187] in their empirical study. Their static analysis toolcalled CryptoLint is also based on Androguard, and the number of APKs analyzed iscomparable to the work by Fahl et al. [9]. A similar approach has been taken by Felt et al.[159] for their static analysis tool Stowaway to analyze app permissions. Using Dedexerto disassemble the APKs, the output is analyzed and the results are manually stored.Further research on permission based problems with Android applications has beendone by Bartel et al. [188] by using static analysis to build call graphs, but focusing onthe Android framework itself and not on the apps. Fend et al. [189] use static analysisof applications to detect malware. By performing inter-component control flow analysisand static taint analysis, APKs from Google Play are analyzed. Static analysis is basedon SOOT42 for the task at hand. Kim et al. [183] have developed static tests to detectprivacy leaks in Android applications. The main component is a modified decompilerand an intermediate language for their analyzer. Another approach to static analysishas been presented by Payet et al. [190] by extending the Julia static analyzer to workwith the specific requirements and features of Android applications. Only tens of appshave been tested, and with a runtime of 7 minutes per app, speed can be an issue formass audits. Static analysis is also part of the work done by Schmidt et al. [191]. Fortheir collaborative malware detection function, calls made in the Android environmentare extracted for automatic classification and comparison with malware. All of thesepapers focus on their specific tests and have their own implementation to handle largeamounts of APKs. In contrast, AndroLyze provides a standardized way offering a singleplatform for all kinds of security checks regardless of the target and also with analysisspeed in mind to execute them as fast as possible.Grace et al. [181] have developed RiskRanker to detect apps exhibiting dangerousbehavior. Apart from offering this particular type of analysis, the authors focus onexecution speed to potentially handle large numbers of APKs. Nevertheless, RiskRankerdoes not provide a general purpose platform for other tests or a mixture of differentanalysis scripts.SAAF developed by Hoffmann et al. [192] is a general framework for static Android42https://sable.github.io/soot/1605.3 AndroLyze: Static Mobile App Analysisapp analysis. It can be used for manual and automated checks. While it aids developersin writing new security checks and provides fast execution times for single scripts, itdoes not provide support for effectively handling results and large numbers of APKsand scripts.An approach combining different solutions for Android malware detection has beenpresented by Maggi et al. [180]. Similar to Google\u2019s VirusTotal43, AndroTotal is a platformbased on virtual Android devices running different malware detection software andgiving users submitting samples feedback based on the results. The focus is solely on aninfrastructure for dynamic analysis including user-interaction automation. Integrationof different ready-to-run native anti-malware apps in the Android emulators is provided,but there is no support for third-party developers, and there is no scheduler optimizedfor fast results while conducting mass audits in place.Andrubis developed by Weichselbaum et al. [193] is a platform combining dynamicand static analysis. Static analysis is used to aid and fine-tune dynamic analysisand providing additional information about an app, such as permissions, activities,broadcast and receivers. While Andrubis has been designed for broad tests written fordynamic analysis on larger sets of APKs, the requirements for this hybrid approach arequite different from AndroLyze, and it lacks the unification and rapid writing of staticanalysis tasks AndroLyze provides.5.3.3 AndroLyze\u2019s DesignThis subsection presents the design and analysis approach taken by AndroLyze, asillustrated in Figure 5.4. The bottom part of Figure 5.4 shows that AndroLyze has adirect link to Google Play to download apps. Moreover, it shows an analyst with animport database carrying information about the APKs to be analyzed. Importing appsinto a local database enables certain filter and sorting capabilities, but AndroLyzecan also be used without using a local database. AndroLyze already comes with abuilt-in set of scripts, such as extracting permissions from the manifest, disassemblingor decompiling the APK. Additional analysis criteria require users to write customscripts based on the functionality of Androguard [186].The top part of Figure 5.4 illustrates the analysis approach. There are different modes:Depending on the number of applications, a user can start an analysis either locally(local mode) or on a cluster of nodes (distributed mode) to further improve performance.Both modes operate in a fully parallel manner, leveraging all available cores of the usedprocessor(s).The distributed mode shown in Figure 5.4 works as follows: Initially, the scripts aredeployed via SSH on the available nodes. Tasks are sent to a distributed job queueand processed by a pool of worker nodes. The APKs are either stored in the jobs orpredistributed and available in the APK cache. After a node has finished a job, it storesthe outcomes in the result database. Finally, an analyst can view and evaluate his orher findings either using AndroLyze directly, sending custom queries to the database, orby syncing all results and performing a local analysis or review.AndroLyze is designed to analyze large numbers of APKs in a short amount of time.More nodes can be added on the fly to further improve performance and reduce theanalysis time.43https://www.virustotal.com1615 Security Vulnerability Analysis of Mobile AppsAnalysts MachineAndroLyzeAnalystImportDBAPKCacheResultDBAPKCacheResultDBJob QueueResultAPKWorkerNodesScript + APK InformationFigure 5.4: Analysis approach of AndroLyzeIn the following, the design of AndroLyze is explained in more detail, describingthe script framework, the storage system and the parallel analysis engine. Finally, thereader is guided through a typical workflow using AndroLyze.Script FrameworkThe heart of AndroLyze is the script framework. User defined analysis features can beimplemented with Python scripts leveraging the power of Androguard [186].Script Requirements Scripts in AndroLyze can be written for different purposes, suchas collecting information from the Android manifest, accessing information gatheredby analyzing the disassembly, checking where and which permissions are used inthe code, creating the control flow graph or decompiling the application. These tasksdiffer in their demands they pose on Androguard. AndroLyze takes advantage of thisfact to improve performance by requiring script authors to signal their requirements toimplement certain analyses. Therefore, AndroLyze can scale down the requirements of allscripts to the lowest common denominator, resulting in the best analysis performance.The built-in scripts are written in a modular way, and functionality can be chainedtogether on demand.Logging Logging the results of an analysis in a structured fashion is important for anyevaluation study. The AndroLyze script framework comes with a set of functions to logcommon data types. Additionally, results can be summarized to groups of particular1625.3 AndroLyze: Static Mobile App Analysisinterest. Examining the manifest, for instance, might lead to a structure such as manifest\u2192 permissions \u2192 {permission1, ..., permissionn}.Very large and/or binary data is supported by the logging component. It is directlyconnected to the storage architecture, thus all results are kept in the result databaseand optionally in the file system of the analyst.AndroLyze does not enforce a static schema for results, but requires a script authorto register a basic structure such that a result can be rendered to hold initial defaultvalues. This offers the possibility to visualize results in the absence of any logging andmakes the comparison of app versions easier.Storage & AnalysisAndroLyze provides an import database that carries meta-information about the APKs,a result database for storing the results and an APK cache for the .apk files. One ofthe main design goals of the import database is to manage different versions of anapplication, either from different sources (e.g. Amazon Market or Google Play) or differentbuilds. This can be used for historic analysis, e.g., to see how long different bugs werepresent or to determine application trends on a broader scale, such as the adoption oftechnologies like HTML5-based frameworks or the use of encryption over the course ofseveral month or years. To collect these different versions, AndroLyze allows analysts toupdate the database by downloading newer versions, if present, directly from GooglePlay. Thus, evaluations can not only be performed on the most recent APKs, but alsoon earlier versions several years back.The analysis can be performed in two different modes, called local parallel anddistributed parallel. The local parallel mode offers the possibility to use AndroLyzewithout the need to install a distributed system. The distributed parallel mode enablesthe system to further improve performance by adding more nodes on demand.Both implement dynamic scheduling to utilize all available nodes, hence all cores/pro-cessors as long as possible. However, since the analysis time between jobs may differstrongly, long running jobs are scheduled first. Since most scripts analyze some pieceof code, the size of the classes.dex file is used as a simple metric for a job\u2019s runtime. Thisapproach is called Code Size Scheduling (CSS). With both dynamic scheduling and CSS,parallel execution can be performed as long as possible.The actual analysis process is as follows: A worker fetches a job from the task queue,performs an analysis and stores the outcomes in the result database. A job representsthe analysis of a single APK with a given set of scripts. An APK is either part of the jobor fetched from the APK cache if the applications have been imported beforehand. Inaddition to the analysis results, the system stores the identifiers of the analysis resultsin the job queue such that the analyst can view his or her findings directly after theanalysis has finished.WorkflowTo illustrate the approach in action, the reader is now guided through a typical workflowwhile using AndroLyze.Figure 5.5 summarizes the architecture and common steps required for an analysis.First, the analyst needs to obtain the APKs (s)he wants to inspect. The link to Google1635 Security Vulnerability Analysis of Mobile AppsAndroLyzeAnalysis environmentDetermine minimum script requirementsGet jobStore resultsProvide workAnalyze results6Start analysis5Load APK metaSynchronizeAnalyst Job QueueImportDBResultDBAPKCacheImport APKs13Download APKs2Create scriptDistributed mode4Deploy scriptsOptionalResultDBAPKCacheOptionalFigure 5.5: Typical workflow while using AndroLyzePlay44 offers the possibility to download single applications via the package name orto download the newest or most famous APKs from either a particular category or allcategories (Step 1). Importing the apps into a local database (Step 2) is not required,but enables an analyst to use our advanced scheduling and filtering functionality. Thenext step is to create a script (Step 3) suitable for AndroLyze, leveraging the power ofAndroguard in order to implement the needed analysis functionality. The more nodesone has, the faster the entire analysis is. Therefore, it is recommended to use thedistributed parallel mode for larger sets of applications. It assumes that all nodes havebeen started and that the scripts have been deployed (Step 4). The deployment processcan be handled through AndroLyze and requires an analyst to have SSH access on thenodes. After Steps 1-4, the actual analysis process can be triggered (Step 5). Initially, theAPK meta-information is loaded, either from the .apk files supplied by the analyst orfrom the import database. For an efficient analysis (Step 6), the minimum requirementsthat satisfy all scripts are determined and sent together with information about thescripts and the applications to the distributed job queue. The worker nodes in the poolfetch one job after the other, perform the analysis and store the outcomes in the resultdatabase. The results can be synchronized, concurrently to the analysis process, to thelocal hard disk drive of the initiator of an analysis. Finally, the findings can be furtherprocessed or evaluated.44The listing of the most famous or newest applications in a certain category is limited by n = 500 [182]1645.3 AndroLyze: Static Mobile App Analysis5.3.4 ImplementationIn this subsection, implementation details of AndroLyze, including the script framework,the storage and the analysis components, are described.Script FrameworkThere are two types of scripts, implemented as subclasses of either AndroScript orChainedScript. The first provides the analysis functionality for scripts, the latter en-ables the chaining of scripts to bundle their functionality. Depending on the scriptrequirements the analyst needs, the following analysis objects are provided:\u2022 DalvikVMFormat: Creates a disassembly and provides access to classes, fieldsand methods.\u2022 VMAnalysis: Analyzes the disassembly to check, for example, where whichpermissions are used or if reflection or dynamic code loading is used.\u2022 GVMAnalysis: Creates the control flow graph.\u2022 XREF: Detects cross-references between methods.\u2022 DREF: Detects cross-references between data fields.Through the definition of requirements, AndroLyze can query all scripts and determinethe minimum script requirements to provide the necessary analysis functionality.Without defining any requirements, it is only possible to access the raw .apk file or itscontents, such as the manifest file.Every script has access to the logging framework, allowing unified logging in astructured fashion. AndroLyze supports logging of all JSON serializable data types,such as booleans, integers, strings, lists and dictionaries. Internally, a dictionary keepsall reported results, extended by static information about the analyzed APK as wellas the script. Moreover, AndroLyze offers a custom storage interface for text files,graphs or other binary data. Statistics about the analysis time help to improve the scriptperformance.StorageThe storage implementation is divided into two parts: the import and the resultdatabase. Both are described below.Import Database Even if the analyst has many APKs, (s)he might be interested in asubset or a single application only. To provide filters, AndroLyze needs information fromthe application\u2019s manifest. The import mechanism extracts data such as the package nameand version number from the manifest. Moreover, it stores the size of the classes.dex file asa metric for the script runtime used for the improved job scheduling. Instead of relyingon Androguard to perform the import, a faster solution was developed that extracts onlythe manifest, thus preventing the extraction of the whole .zip file as Androguard doesit. The import process is fully parallelized and all operations are executed in-memoryafter the APK has been loaded. A SHA 256 message digest45 over the whole APK servesas a unique key in the database and enables management of different versions of asingle app. Therefore, AndroLyze can provide a security track record over many releases.45In the following, message digest or hash always refer to the usage of the SHA 256 algorithm1655 Security Vulnerability Analysis of Mobile AppsLabeling a data set in order to provide a better distinction between different APK setsis also allowed. Finally, the meta-information is stored in a local SQLite database so thatdifferent analysts can manage their databases independently of others.Result Storage In contrast to the local import database that is basically a flat file,MongoDB46, a schema-free NoSQL database for the distributed result storage, is used.Therefore, all users of AndroLyze share the same result database. Nevertheless, differentviews on the database can be used to distinguish between data sets.AndroLyze adds meta-information for an APK, such as package name, version name,build date and message digest, to the result. Additionally, information such as scriptname, hash, version number and the analysis date are added as script meta-information.This meta-information about the APK and script add fields to the result layout, allowingto formulate queries for the database without any knowledge of the actual results. Aresult is defined as the outcome of the analysis of a single APK using a single script.New results with the same script name and APK hash replace old ones47. In additionto the result storage in the database, AndroLyze can store the results formatted as JSONstrings on the local hard disk drive.GridFS To support the storage of files larger than the MongoDB limit of 16 MB,AndroLyze uses MongoDB\u2019s GridFS that splits BSON documents into binary chunks.Two collections, one for the chunks, the other for the meta-information, are used toreassemble the whole file. The method is used for storing large results and APKs48.AndroLyze does not decide on the fly to use GridFS for large results due to the fact thatstoring results in a binary format allows analysts to query only the meta-informationof the results.Key Escaping Reserved characters such as \u201d.\u201d and \u201d$\u201d need special treatment ifthey are used as keys in the result. This is important when using the package namein a query. AndroLyze escapes them with \u201d \u201d and \u201d $\u201d, respectively. Key escaping isonly necessary if queries are sent directly to MongoDB, since AndroLyze automaticallyhandles this while creating queries.AnalysisAlthough the local parallel and distributed parallel mode share the same conceptualdesign, they differ in their implementation details. Both modes use processes instead ofthreads, because, due to the Global Interpreter Lock, only one Python thread can executecode at once in the interpreter. On each node, as many processes as the CPU has cores(including multithreading) are spawned. Providing the Androguard analysis objects,such as the disassembly, implicates overhead that can be reduced by the definition ofscript requirements. This enables AndroLyze to use the minimum script requirementsneeded to perform an analysis. Due to the overhead involved, an APK is opened onlyonce and all scripts are run afterwards.46https://www.mongodb.org47The keys for the results are generated by hashing the script name and the APK message digest48We integrated the GooglePlayCrawler into AndroLyze to access the Play Store and download the APKs1665.3 AndroLyze: Static Mobile App AnalysisLocal Parallel Mode The local parallel mode uses a synchronized queue to distributethe work among the processes. The queue memorizes the path to the APK and themeta-information. After a successful analysis, the results are stored in MongoDB.Distributed Parallel Mode The Celery framework49 is used to implement a message-oriented middleware in combination with RabbitMQ50 as a distributed task queue.Celery acts as a message broker and provides worker instances to execute the actualanalysis jobs. Each process maintains a single Celery task instance that is kept aliveas long as Celery is started on the node. Therefore a persistent database connectioncan be kept for the result storage. To avoid idle times, a process reserves one task perprocess that is preloaded. Therefore, if the APK has been integrated into the message,it is already available when the process starts the analysis. The actual analysis processis as follows: Tasks are serialized with the Python Pickle module and sent to RabbitMQ.Celery workers retrieve a job and perform the analysis on the given APK with all scripts.Afterwards, the results are stored in MongoDB. The identifiers of each result are kept inRabbitMQ in a reserved queue only for the job results. The initiator of an analysis hasa callback handler registered for this queue so that (s)he can synchronize the resultsconcurrently to his or her local hard disk drive. All steps in the analysis process arefault tolerant. Thus, if a node fails, the job can be executed by any other node. Theconnection to RabbitMQ and MongoDB can be fully encrypted, using X.509 certificates.5.3.5 Experimental EvaluationIn this subsection, the performance of AndroLyze is evaluated. First, speed improvementsby import parallelization and by on-demand script requirements are demonstrated.Afterwards, the local parallel and distributed parallel modes are investigated as well asthe APK distribution strategies. Then, the overall performance of AndroLyze is illustratedby evaluating the analysis time of almost 40,000 applications (i.e., the Top Free 500APKs from all categories collected in three years: 2012, 2014 and 2015). Finally, theresults of a study on the use of cryptographic code in this set of APKs is presented.Test EnvironmentIn total, 7 computers are used in the experiments. Each has an Intel Core i7-4771processor, 32 GB RAM, a 240 GB SSD, and two hard disk drives with both 3 TB storage.They are connected via Gigabit Ethernet, and all except one computer host a KVMvirtualized machine (VM) that has only 16 GB RAM and a 128 GB HDD (no RAID),except for the job queue which has 512 GB of additional space.Table 5.5 shows the APK sets used in the experiments: the Top Free 4, 100 and 500applications51 available from all categories in Google Play. Furthermore, snapshots of theTop Free 500 applications of the years 2012, 2014, and 2015 were collected, and mergedin the set Top Free 500 Archive to demonstrate the versioning system and security trackcapabilities of AndroLyze.49http://www.celeryproject.org50http://www.rabbitmq.com51The shown numbers do not take duplicate apps (same hash) into account. Duplicates can occurbecause an app may be present in more than one category1675 Security Vulnerability Analysis of Mobile AppsTable 5.5: APK test setsSet # unique APKs Size in MBTop Free 4 102 1,159Top Free 100 2,519 22,315Top Free 500 12,689 91,764Top Free 500 Archive 39,725 226,798The used script sets shown in Table 5.6 start with scripts that extract informationfrom the manifest only. The next set adds partial SSL analysis capabilities from Mallo-Droid (Sec. 5.2). Bytecode has additional scripts listing the classes and fields using thedisassembly as well as creating a method call graph. In addition to Bytecode, Source codeperforms decompilation with the help of Androguard\u2019s DAD decompiler.Table 5.6: Script test setsSet Reqs. ScriptsManifest None Activities, BroadcastReceivers, ChainedApkInformation,ContentProviders, Files, Intents, Libs, Permissions, Services+SSL XREF Manifest, SSL+Bytecode XREF +SSL, AnalyzeFrameworks, ClassDetails, ClassListing,MethodCallGraph+Source code XREF +Bytecode, DecompileImportThe first experiment is performed on a single computer and inspects the performanceimprovements achieved by parallelizing the import and using the import code comparedto the standard Androguard import.Figure 5.6: Parallelization of APK importFigure 5.6 shows three curves: The orange (middle) curve is the import using An-droguard to open the APK and to extract the needed manifest information. The blue(bottom) curve points out the speed improvements over Androguard since only the1685.3 AndroLyze: Static Mobile App Analysismanifest needs to be extracted from the .zip file and all other processing of the APKcan be omitted at this stage. The green (top) curve shows the influence of concurrentlycopying the APKs to the local hard disk drive. For each run, the import database aswell as the import directory for the APKs were deleted. The database is created onthe SSD while the APKs are copied from and to the local hard disk drive. With onlyone process, the improved import mechanism is 2.03 times faster than Androguard.Even though the performance benefits decrease with more processes, there is still animprovement of 19.24% with 19 processes, which is the best value for the Androguardimport. Moreover, copying the APKs clearly reduces the import speed because the harddisk drive is involved, but even here there is a performance increase of 98.87% with 18processes compared to 1 process.ScriptsThe next experiment measures the impact of the analysis object provisioning time on thescript runtime. For this purpose, a scriptwas created for each available analysis object,signaling only the particular script requirement that is to be examined. The methodbody of the procedure responsible for the actual analysis was left empty. Nevertheless,meta-information about the script and APK is still logged and stored in the file systemas well as in MongoDB, because this is automatically done by AndroLyze. The networkis not involved in this test scenario, since only a single computer with a local MongoDBinstance in the local parallel mode is used.Figure 5.7: Relation between script requirements and runtimeThe results of this experiment shown in Figure 5.7 indicate that providing the analy-sis objects only on demand improves performance. Providing access to the manifestfor all 102 applications of the APK set Top Free 4 is very fast. As soon as the firstrequirement is needed, the runtime gets approximately 100 seconds longer (DalvikVM-Format, VMAnalysis and GVMAnalysis) because the disassembly etc. have to be created.Creating cross-references between methods (XREF) and fields (DREF) are the mosttime-consuming requirements.Local Parallel ModeTo evaluate the performance of the local parallel mode, the APK set Top Free 4 was usedand then analyzed with the script set Source code. The results in Figure 5.8 show that a1695 Security Vulnerability Analysis of Mobile Appsspeed-up of 3.19 is achieved using 4 processes instead of only 1 process, each of themassigned to a single CPU core of the used computer that is equipped with 4 CPU cores.Figure 5.8: Local parallel mode +Source codeFigure 5.9: Comparison of job scheduling strategiesFigure 5.9 shows the distribution of analysis tasks among the CPU cores using twodifferent scheduling strategies. The first scheduling strategy is based on the ascendingorder of the package names, while the second (CSS) uses the code size and schedulesjobs with a large code sizes first. Each job is represented by a different color and itsblock size in the chart corresponds to its runtime. The figure shows that the analysisof a particular job took very long, which is caused by the decompilation script. WithCSS, this long running job is scheduled earlier, resulting in a reduced analysis time(233.15 seconds). With improved scheduling, the speed-up of 3.19 shown in Figure 5.8is improved to 3.59.To validate the performance benefits of CSS, an experiment was carried out that usesthe same script set as the experiment before, but does not use the decompilation script,thus eliminating the long running process. The results in Figure 5.10 show again thatCSS exhibits a better performance. The speed-up is improved from 3.69 to 3.8.Distributed Parallel ModeTo evaluate the distributed parallel mode, the performance properties of both modesincluding CSS are compared. Using 4 computers (3 of them with a KVM VM each), thedistributed environment has been set up as follows: The result database is located on1705.3 AndroLyze: Static Mobile App AnalysisFigure 5.10: Local parallel mode +Bytecodethe computer without a VM, whereas the distributed message queue runs in a VM. Theanalyst initiates the analysis from the computer without a VM and integrates the APKslocated on the hard disk drive into the messages sent to RabbitMQ. The serialization ofthe APK data as well as the network is taken into account.Figure 5.11: Distributed parallel mode + SSL vs. local parallel mode +SSLFigure 5.11 shows the analysis of the data set Top Free 4 (left) and the analysis withthe set Top Free 100 (right). Both use the script set +SSL, and each physical machineruns 8 processes. The results for Top Free 4 indicate that AndroLyze is optimized fora large number of jobs. The speed-up between the local parallel and distributed parallelmode is only 2.17 and 2.41 with CSS. This result can be explained by the reservation oftasks. Each process reserves one task, hence in the worst case, a worker may be free forwork, but all other workers have reserved the remaining tasks. Another problem is thegranularity of the tasks, because in our scenario the last 31 jobs are executed by lessthan 32 processes (the total number of processes). The results for Top Free 100 showthat a speed-up of 3.26 and 3.31 with CSS could be obtained. In both cases (Top Free 4and Top Free 100), CSS improves the performance.APK DistributionThe next experiment investigates the data throughput of the proposed APK distributionstrategies. Figure 5.12 compares both APK distribution strategies (Send APK vs. SendAPK-ID) in the distributed parallel mode with the local sequential and local parallel1715 Security Vulnerability Analysis of Mobile Appsmode. The used test set Top Free 500 consists of 12,689 APKs with a total size of 91.8GB to measure the throughput of serializing the APKs and the distribution throughMongoDB. The script set Manifest for unzipping the APK and extracting the information,is used in this experiment.Figure 5.12: APK distributionThe result synchronization from MongoDB to the initiator of the analysis has beendisabled in this experiment because it puts more load on the database and may influenceits APK distribution. The results shown in Figure 5.12 indicate that the local parallelmode is faster than the distributed parallel mode, no matter which APK distributionstrategy is used. Integrating the APK into the message that is sent to RabbitMQ allowspreloading the message, because every process reserves one task. Prior importing ofthe APKs into MongoDB and only sending the identifier of the application forces theworker to fetch the APK from MongoDB before it can start the analysis. Moreover, theAPK has to be build together from all of its chunks52. The distribution via MongoDB is17 minutes and 26 seconds slower than the distribution via RabbitMQ.Nevertheless, the distributed parallel mode is valuable, since MongoDB\u2019s shardingfacilities can be used to distribute data records among several instances. Having enoughMongoDB nodes can circumvent the bottleneck that can occur while serializing andsending apps from the analysis initiator over the network. Furthermore, the cachingbehavior of MongoDB allows MongoDB to be used as an in-memory database. In theexperiment, MongoDB was stopped, all unused pages removed and then the servicewas started again to prevent this effect.Overall PerformanceNow follows a presentation of an overall performance evaluation of AndroLyze. Figure5.13 shows the results of executing a single script on the data set Top Free 500 Archiveon 7 computers, each running 8 Celery processes.The first script (left) does not need any analysis objects. Thus, job execution is muchfaster than loading the APK data from the hard disk drive and transferring it over thenetwork. Obviously, increased script requirements increase the runtime. ClassListing(i.e., list all classes) and ClassDetails (i.e., list all classes and additionally show fields andmethods) do not need any cross-references because they only access the disassembly.Creating cross-references, as needed by CodePermissions, WebView (i.e., list all methods52AndroLyze sets the chunk size as large as possible, preventing more chunks than necessary1725.3 AndroLyze: Static Mobile App AnalysisFigure 5.13: Performance of AndroLyzeusing the WebView class), SSL, CryptoStats (see Section 5.3.5) and MethodCallGraph,adds more than one hour to the analysis time. Most of the time is needed to decompileall apps with Androguard\u2019s DAD decompiler, which consumes 9 hours and 24 minutes.Since there is an overhead for opening the APKs and providing the analysis objects, ananalysis with all scripts where the objects are only provisioned once and shared, is 19hours and 35 minutes faster compared to running all scripts alone.AndroLyze@Work: Use of Cryptographic Code in AppsTo demonstrate the benefits of AndroLyze in a concrete analysis scenario, a study on theuse of cryptographic code in APKs in the data set Top Free 500 Archive was conducted.The script checks for explicit calls to the block cipher modes ECB (Electronic Codebook)and CBC (Cipher Block Chaining) as well as for the most preferred ciphers, which intotal took 3:29 hours to complete on 7 computers. The results are shown in Figure 5.14.They are in line with the results by Egele et al. [187], since many apps use cryptographicfunctions (65.65 %) somewhere in their code. Since there were snapshots of the TopFree 500 apps of all categories from different years, it was also analyzed which appschanged their cryptographic behavior, given they were still in Google\u2019s Top Free 500apps. Throughout the years, AES (Advanced Encryption Standard) has always been themost popular cipher, and the study shows that most developers still favor AES. Overall,many developers requested CBC mode (87.51 %) independent of the used cipher, andonly a fraction asked explicitly for ECB mode (still 20.35 %). Some apps use both modesin different areas of code, either for backward compability, as a fallback, for file formatcompability or for no apparent reason. For apps relying on ECB mode, the results showthat 134 apps removed the ECB mode in their latest version. It is evident that checkslike these and the ones performed by Egele et al. [187] should not only be performedonce, but should be incorporated in a unit test-like fashion into build or release cycles.Having a standardized infrastructure, script, APK and result management as offered byAndroLyze helps providing audit trails for app lifecycles and various checks developedin-house, for the research community or for commercial entities.5.3.6 ConclusionIn this section, a distributed framework called AndroLyze to support researchers in theprocess of conducting mass-audits of Android apps was presented. It was shown that1735 Security Vulnerability Analysis of Mobile AppsFigure 5.14: Crypto Statistics for Top Free 500 Archiveintelligent scheduling and APK management leads to faster results with potentiallymore useful information by incorporating past versions of apps. AndroLyze has beenevaluated using the Top 500 Free apps from all categories of Google Play collected overthree years, consisting of almost 40,000 apps requiring about 227 GB of storage space.There are several areas of future work. Currently, the analysis scripts are basedon Androguard, but AndroLyze can be used to easily plug-in other script backendsfor custom checks. Furthermore, the scheduling algorithms and script managementfacilities could also be used to optimize and streamline app runtime analysis. Finally,potential applications for AndroLyze include open repositories for static checks tobring the knowledge from the research community to app developers and into thedevelopment process of companies.1745.4 Dynalize: Dynamic Mobile App Analysis5.4 Dynalize: Dynamic Mobile App Analysis5.4.1 IntroductionIn the previous section, a framework for large scale static analysis of Android appswas presented. Unfortunately, not all app functionality can be identified in this way.Thus, certain bugs or vulnerabilities might be missed if relying solely on static analysis.This can be overcome by using dynamic analysis to observe runtime properties of amobile app that is executed on a physical or virtual device. This process if very resourceintensive, and it proves to be even more challenging to do automated tests for largerquantities of apps.There are several tools that examine the runtime properties of mobile apps in order toevaluate bugs [194], performance issues [195] or to detect malware [196]. Furthermore,there are generic frameworks such as PUMA [197] that provide support for dynamicapp analysis, but not with respect to scalability and dynamic resource provisioning.On the other hand, Device-as-a-Service (DaaS) providers such as Genymotion [198],Manymo [199] and Testdroid [200] assume that a human tester controls devices remotely.These approaches are aimed at supporting the development and evaluation of singleapps on a small number of virtual or physical devices in parallel.In this section, Dynalize, a novel Platform-as-a-Service (PaaS) cloud for dynamicanalysis of mobile apps, is proposed. Dynalize provides a scalable platform for dynamicapp analysis, allows developers to integrate existing tools with only slight modificationsand can be used to publish analysis results as Software-as-a-Service (SaaS) offerings.Therefore, Dynalize provides (i) a container management/job processing engine thatserves as a layer between Infrastructure-as-a-Service (IaaS) and PaaS, and (ii) a serviceplatform for the dynamic analysis of mobile apps.Dynalize has the following features:1. It runs virtual devices on top of IaaS instances, which provides scalability anddynamic resource provisioning.2. It makes use of containerization and container virtualization, which allows de-velopers to execute existing tools with heterogeneous dependencies regardinglibraries and programming languages.3. It provides a storage architecture for mobile apps, which can be used to distributeand process large amounts of data for thousands of apps in an efficient andcoordinated manner.4. It offers users (i) one-time and (ii) long-term provisioning, which enables users toeither (i) start and terminate IaaS instances on demand or (ii) keep IaaS instancesrunning in order to make use of local caches.5. It offers a web service frontend to users, which allows users to publish theirresults as a SaaS service.Parts of this section have been published in [11].5.4.2 Related WorkDynamic analysis has been used to analyze mobile apps with respect to privacy [201],security [196], [202], performance [195], energy consumption [203]\u2013[205] and bugs [194],[206]\u2013[209]. Several frameworks for large-scale dynamic analysis for mobile apps [197],1755 Security Vulnerability Analysis of Mobile Apps[210] and automatic test frameworks running in the cloud [211], [212] have emerged.Furthermore, on-demand physical and virtual devices for testing individual apps withdifferent operating system releases and configurations [198]\u2013[200] and clouds of devicesfor automatic tests [213]\u2013[215] have been developed.The problem of performing dynamic analysis of mobile apps has been solved differ-ently in the past. Approaches such as AppDoctor[207] and AndroidRipper[206] analyzemobile apps sequentially and accelerate virtual device startups with snapshots. Whilethis is practicable for a small number of apps, without parallelization, dynamic analysison a large-scale can take months or even years. For example, a measurement studyof the Google Play store by Viennot et al. [216] has covered roughly 1 million apps.Assuming an execution time of one minute per app, a sequential analysis of these appswould take about two years.Another approach is to perform dynamic analysis in parallel on a cluster of physical[197] or virtual devices [210]. For example, Andlantis[210] can analyze 3,000 Androidapps per hour for malware on a cluster of 200 servers. Nevertheless, it relies ondedicated resources and only supports malware analysis. In contrast, Dynalize providesa generic solution with dynamically provisioned resources, enabling the user to analyzemobile apps with respect to other targets than malware, such as performance, bugs orenergy consumption.Furthermore, cloud-based approaches have been proposed for large-scale dynamicanalysis. For example, Mahmood et al. [211] have deployed the Android emulatoron IaaS instances to perform a large number of analyses in parallel. Furthermore,Ravindranath et al. [194] have developed VanarSena, allowing app developers toupload a Windows Phone binary and obtain a bug report within a short amount of time.In contrast, Dynalize supports multiple platforms and custom emulators such as theopen source QEMU extension PANDA [217] that adds the ability to record and replayexecutions. More importantly, Dynalize provides caching and scheduling methods toenable the user to consider costs/performance trade-offs and to decide between one-time or long-term analyses. Furthermore, in contrast to previous cloud-based solutions,a layered file system has fast deployment times even if the program that performs thedynamic analysis changes or makes use of other libraries.More recently, container virtualization has attracted the interest of researchers (e.g.,REMnux53). Containers can be deployed faster, compared to IaaS instances, and can bearbitrarily assembled from multiple storage layers. Container virtualization can also bebeneficial for dynamic analysis: (i) Different virtual device emulators, programminglanguages and libraries can be easily composed to an execution environment for ananalysis. (ii) Virtual devices can be recreated fast in order to provide a clean executionenvironment for an analyzed app. Therefore, Dynalize adapts container virtualizationfor its platform solution.Several cloud providers already offer container virtualization services based on thedocker container engine54, such as the Amazon EC2 Container Service (ECS)55 andthe Google Container Engine56. A user can acquire a cluster of containers that canbe composed arbitrarily out of existing libraries, execution environments and \u2013 of53https://remnux.org/docs/containers/malware-analysis/54https://www.docker.com/55https://aws.amazon.com/ecs56https://cloud.google.com/container-engine1765.4 Dynalize: Dynamic Mobile App AnalysisDynalizeplatformIaaS instance #nContainerVirtual DeviceTaskLocal CacheDaemonLocalSchedulerScheduler NodeFrontendGlobalSchedulerDeviceSchedulerData ProviderService NodeFrontendServiceHandlerIaaS ProviderPresentersubmits jobdeploys analysissubmits appssubmits jobserviceuserplatformusersubmitstasksFigure 5.15: Dynalize platform architecture.course \u2013 virtual devices. For example, a developer performing dynamic app analysiscan start a cluster of IaaS instances and make use of a container cluster manager suchas Kubernetes57 to parallelize her dynamic analysis. But from a technical perspective,this approach is limited. Since these approaches leave the virtual server hosting thevirtual container unmodified, the local storage cannot be used as additional cache,which is not efficient if large numbers of applications should be analyzed. For example,the study of Viennot et al. [216] is based on a data volume of 5.3 TB. Even smaller datasets with a volume of a few GBs require that the data is distributed and processed inan efficient and coordinated manner. Therefore, in contrast to pure container services,Dynalize provides a novel storage solution: It employs app prefetching and caching onthe IaaS instance executing the Dynalize container, using a local cache daemon.5.4.3 Dynalize\u2019s Design and ImplementationDynalize consists of dynamically provisioned IaaS instances, a central Scheduler Nodeand a Service Node (see Figure 5.15). The components of Dynalize are described below.IaaS InstancesFigure 5.16 shows the layout of an IaaS instance provisioned by Dynalize to analyzemobile apps. On the left side, the relation between data provider, local cache daemonand the container is shown. On the right side, the relation between global scheduler,local scheduler and local cache daemon is illustrated. Basically, the global schedulerpartitions the total set of apps and sends a list of tasks to the local schedulers residingon the IaaS instances (see Section 5.4.3). An IaaS instance usually hosts two or more57https://github.com/GoogleCloudPlatform/kubernetes1775 Security Vulnerability Analysis of Mobile AppsIaaS instanceOutgoing Data CacheContainerVirtual DeviceEnvironment TaskLocal Cache DaemonIncoming Data CacheTask LayerEnvironment LayerVirtual Device LayerData ProviderLocal SchedulerGlobal SchedulerFigure 5.16: Layout of an IaaS instance used to analyze apps with Dynalize.containers that are created and coordinated by the local scheduler. When a list of tasksis received, the local scheduler triggers the local cache daemon to asynchronouslydownload these apps from the data provider. In the meantime, the containers arecreated and the virtual devices are started.Container Layout In general, container virtualization makes use of operating systemlevel virtualization: The host kernel is shared with several isolated process groups(in the remainder of the work referred to as containers or guests) that appear asseparate physical systems to guest processes. In contrast to full- and para-virtualizationsolutions, container virtualization is lightweight; it enables isolated environments foruser processes without additional virtualization overhead. The file system within acontainer is composed of several layers during creation time: Each layer representsa separate folder on the host\u2019s file system. During startup, these folders are overlaidtransparently and form a single coherent file system using a storage backend.During the development of Dynalize, three different storage backends were evaluated:Advanced Union File System (AUFS)58, LVM2 DevMapper59 and VFS60. AUFS is aunion file system that provides a file-level Copy-On-Write (COW) mechanism, whileDevMapper is the kernel part of the LVM2 logical volume system, implementing ablock-level COW. VFS does not provide COW support, instead a container\u2019s file systemis formed by making a deep copy of its layers. The main advantages of composing a filesystem consisting of layers are deployment time and reusability of the base layer. SinceAUFS gives the best results with respect to container startup times and throughput (seeSection 5.4.4), Dynalize makes use of AUFS.A Dynalize container consists of the following layers: (i) The virtual device layer, (ii)the environment layer and (iii) the task layer. The term task refers to the analysis of asingle app, while the term job refers to a list of apps to be analyzed. The virtual device58http://aufs.sourceforge.net/59http://sourceware.org/lvm260https://www.docker.com/1785.4 Dynalize: Dynamic Mobile App Analysislayer contains the emulation program for the virtual device and its virtual storage,i.e., its system image and a virtual SD card. This layer may contain emulators such asthe Android Emulator, but also software such as the open source QEMU extensionPANDA [217]. Dynalize virtual devices rely on full system emulation, since they areexecuted on the application layer, and hardware-acceleration is usually not supportedin an IaaS cloud. On the other hand, full system emulation supports the executionof both native ARM or x86 binaries, which is not the case with hardware-acceleratedx86-emulators. Furthermore, Dynalize offers different virtual device types, reflectingdifferent amounts of resources reserved for each virtual device. The environment layerconsists of programming languages, libraries and other dependencies for the executionenvironment of a dynamic analysis. It contains dependencies that are consistent for along period and not changed with every minor update of an analysis. Finally, the tasklayer contains the program that performs the dynamic analysis.This layered design ensures that Dynalize can use the snapshot capability providedby several IaaS providers. Even if a task changes slightly, only the task layer has to beretransmitted to the IaaS instances. Since the virtual device layer and the environmentlayer can grow very large (several GBs for system images, SD cards etc.), this containerlayout avoids the retransmission of large files within the virtual device and the envi-ronment layer. In contrast, if a new version of an analysis is deployed in Dynalize, it isretransmitted to and cached within each IaaS instance.Local Cache Daemon In contrast to cluster solutions such as Andlantis [210], datatransfer from and to the data provider is completely separated from the containers.By design, a data provider can be any storage service that supports downloads viaHTTP/HTTPS, such as Amazon S361 or GitHub62. All containers share a commonread-only directory residing on the host, in which prefetched apps are stored by thelocal cache daemon. Prefetching allows a significant reduction of startup time of ananalysis, since data transmission can be started before the container is created. Also, theincoming data cache allows the reuse of a previously fetched app. On the other hand,the outgoing data cache is a writable directory residing on the host, which is createdduring the container startup process. Each container has its own outgoing data cachedirectory, and when a task within a container signals the end of an analysis, the datawithin the cache is asynchronously transferred to the data provider while the containeris restarted for the next analysis.Scheduler NodeThe Scheduler Node provides a frontend to the user, enable her to deploy her analysisand to submit jobs (see Figure 5.17). The user can choose between (i) one-time and (ii)long-term jobs, enabling her to either (i) start and terminate IaaS instances on demandor (ii) keep IaaS instances running to make use of local caches. Furthermore, a jobconfiguration specifies a data provider as well as the type and number of virtual devicesused to process this job.61http://aws.amazon.com/s362https://github.com1795 Security Vulnerability Analysis of Mobile AppsFigure 5.17: Screenshot of the Dynalize interface.Device Scheduler IaaS instances are started and terminated by the device schedulerthat maps virtual devices onto IaaS instances. It is based on a multi-objective schedul-ing algorithm: Since IaaS instances are billed in a pay-as-you-go manner, the objectivefunction of the scheduling algorithm includes job execution time and execution costs.The search space includes different IaaS providers, each allowing their users to choosefrom a broad variety of instance types with different prices per hour. Primarily, instancetypes specify resources like the number of CPUs and the amount of RAM for a virtualserver. Secondarily, instance types also reflect different kinds of hardware, which areoptimized, for example, for I/O-intensive or CPU-intensive workloads. Therefore, themulti-objective scheduler models execution time as a function of performance parame-ters like average virtual device startup time and throughput. The device scheduler isimplemented as a variant of the Strength Pareto Evolutionary Algorithm (SPEA2) [218],has good convergence properties and is adaptable to different application areas.Global Scheduler The global scheduler is responsible for distributing tasks to theIaaS instances. First, the tasks are partitioned among the virtual devices. The task listfor each virtual device is sent to the corresponding local scheduler that initiates theapp download and the creation of the containers (see Section 5.4.3). After a task isfinished, the local scheduler notifies the global scheduler, which in turn keeps track ofthe on-going and finished tasks. In case of mixed instance types, the global schedulerreschedules tasks between the instances. In case of one-time jobs, instances can beterminated if no tasks can be rescheduled.Service NodeAs Figure 5.15 shows, both Scheduler Node and Service Node provide a frontend to theDynalize user. While the Scheduler Node frontend is used to configure the IaaS providerinterface, to submit jobs and to deploy analyses, the Service Node allows Dynalizeusers to make their work publicly available. For example, when an analysis has beensuccessfully performed on a large number of apps, the developer can automatically1805.4 Dynalize: Dynamic Mobile App Analysisgenerate both a job submission template for the Service Handler and a web pagetemplate for the Presenter. Both templates can be modified to ensure a cost-efficientexecution or a custom web page layout.Since the main work is done by the Scheduler Node, a service request is processed ina straightforward manner. The Presenter runs a web server, on which a service usercan upload apps to analyze. After an app is uploaded, the Service Handler submits ajob to the Scheduler Node, which is terminated after all apps are analyzed. When theScheduler Node signals job completion, results are uploaded to the cloud storage andmade available to the user on the web page of the Service Node. The service can beevaluated more detailed with the demo service deployment.635.4.4 Experimental EvaluationIn the following sections, a use case and a performance evaluation of Dynalize aredescribed.Use CaseAs a use case for Dynalize, it was investigated which Android apps potentially use mal-ware obfuscation techniques. Rastogi et al. [196] have shown that typical anti-malwaresolutions heavily depend on static signatures and therefore are ineffective againstsimple program transformations (transformation attacks). In particular, programs thatmake use of reflection (e.g., using the Java Reflection API) or code encryption can makeparts of an app binary unavailable for static analysis. On the other hand, dynamic anal-ysis can give hints on which apps use obfuscation techniques. For example, dynamicanalysis can easily detect whether native libraries are linked within a binary or not.Afterwards, these apps can be further investigated with other tools.For Dynalize, this is an interesting use case: (i) The execution of native binariesrequires full system emulation, which Dynalize provides. (ii) The analysis needs to beperformed on a representative set of applications, i.e., thousands of apps. In our usecase, we have analyzed about 6,000 free Android apps from the Google Play store, withan average size of 17.7 MB per app and a total size of 10 GB, for signs of obfuscation.While a sequential dynamic analysis of these 6,000 apps took about 148 hours (nearlyone week), Dynalize can offer a significant speedup due to parallelization. (iii) Anappropriate de-obfuscation technique for arbitrary apps requires a variety of tasks,such as scanning the application for native library use, dynamic library linking, useof the Java Relection API, system calls and anomalous network traffic. These can beimplemented using different libraries within the execution environment of Dynalize. (iv)The use case can give evidence about the significance of dynamic mobile app analysis; tomake appropriate assumptions about real-world mobile apps, a representative sampleof apps needs to be analyzed.The dynamic analysis in this use case has been implemented using Python 2.7, theAndroid Developer Tools, the Android Emulator, and the Android Debug Bridge. Mostof the data has been collected with the Linux strace tool that traces system calls andsignals. The Android Debug Bridge is used to install, start and trace an app on the63http://ds.mathematik.uni-marburg.de/dynalize1815 Security Vulnerability Analysis of Mobile Apps0\t \u00a0200\t \u00a0400\t \u00a0600\t \u00a0800\t \u00a01000\t \u00a0t2.small\t \u00a0(1)\t \u00a0t2.medium\t \u00a0(2)\t \u00a0m3.medium\t \u00a0(1)\t \u00a0m3.large\t \u00a0(2)\t \u00a0c4.large\t \u00a0(2)\t \u00a0r3.large\t \u00a0(2)\t \u00a0i2.xlarge\t \u00a0(4)\t \u00a0!me\t \u00a0(s)\t \u00a0one\t \u00a0 two\t \u00a0 four\t \u00a0 eight\t \u00a0(a) Virtual device startup time.0.0\t \u00a00.5\t \u00a01.0\t \u00a01.5\t \u00a02.0\t \u00a02.5\t \u00a0t2.small\t \u00a0t2.medium\t \u00a0m3.medium\t \u00a0m3.large\t \u00a0c4.large\t \u00a0r3.large\t \u00a0i2.xlarge\t \u00a0MB/s\t \u00a0(b) Container to virt. dev. throughput.Figure 5.18: Virtual device startup time and container to virtual device throughput for different AmazonEC2 instance types.virtual device. Each output is stored in a single file on the outgoing data cache on theIaaS instance.Dynalize has been used with 40 virtual devices in parallel on 20 c4.large AmazonEC2 instances, two virtual devices each. The data was previously uploaded to AmazonS3. The additional startup time introduced by the instance boot time is negligible (lessthan a minute). However, due to resource sharing between virtual devices, the analysisof an individual app is approximately 10% slower than with a single virtual device. Insummary, dynamic app analysis for the 6,000 apps was executed within 4,4 hours (3% ofthe time required for sequential analysis), with costs of 11.88 $ (90 instance hours). Theresults show that 906 apps (15.1%) use native libraries and 192 apps (3%) dynamicallyload other binaries. There is a high usage of the Java reflection API, since it is used by4,238 apps (71%). Another 3,483 apps (58%) make use of the Java cryptography API.Virtual Device PerformanceIaaS providers allow users to choose between several instance types. Scheduling virtualdevices on IaaS instances requires us to consider different IaaS instance types. Duringthe sequential execution of the use case, it was observed that the virtual device startuptook 22-47% of the total execution time. Furthermore, the throughput between virtualdevice and container is important. Therefore, both virtual device startup time andthroughput were evaluated for different IaaS instance types. They were measured withthe Android Emulator with 512 MB RAM and the Android Debug Bridge, running ontop of an Ubuntu 14.04 Linux distribution.The virtual device startup time for different Amazon EC2 instance types in regioneu-west-1 is shown in Figure 5.18a, while the costs for the used instance types is listedin Table 5.7. All virtual devices were started simultaneously, the values in bracketsreflect the number of vCPUs. Note that t2.small only provides 1 vCPU and 2 GBRAM, while m3.medium provides 1 vCPU and 3.75 GB RAM. The t2 and m3 instancetypes are generic instances, while c4 is optimized for data processing, r3 for RAMaccesses and i2 for storage. Furthermore, t2 instances are burstable: According toAmazon64, CPU performance of t2 instances is based on CPU credits. Initially, a t2instance earns credits for 30 minutes of 100% utilization, and every hour credits for64http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/t2-instances.html1825.4 Dynalize: Dynamic Mobile App AnalysisTable 5.7: Prices of the used instance typesInstance Type vCPUs RAM (GB) $/ht2.small 1 2 0.028t2.medium 2 4 0.056m3.medium 1 3.75 0.077m3.large 2 7.5 0.154c4.large 2 3.75 0.132r3.large 2 15 0.195i2.xlarge 4 30.5 0.9380\t \u00a010\t \u00a020\t \u00a030\t \u00a040\t \u00a050\t \u00a060\t \u00a070\t \u00a080\t \u00a090\t \u00a0100\t \u00a0AUFS\t \u00a0Output\t \u00a0 AUFS\t \u00a0Input\t \u00a0 DevMapper\t \u00a0Output\t \u00a0 DevMapper\t \u00a0Input\t \u00a0 VFS\t \u00a0Output\t \u00a0 VFS\t \u00a0Input\t \u00a0MB/s\t \u00a0t2.small\t \u00a0 t2.medium\t \u00a0 m3.medium\t \u00a0 m3.large\t \u00a0\t \u00a0 c4.large\t \u00a0 r3.large\t \u00a0 i2.xlarge\t \u00a0Figure 5.19: Container storage throughput for different EC2 instance types and storage backends.another 12 minutes are added. If an instance runs out of credits, it is reduced to 20%(t2.small) and 40% (t2.medium) of CPU usage.Since CPU performance is significant for full system emulation, Figure 5.18a showsthe best results with 1+ vCPU per virtual device. Nevertheless, the values are notlinearly scaled due to concurrent access on the device images (I/O). An interestingfact is that the best execution times were measured with both the low-end t2 and thehigh-end c4 instance types. This is due to t2\u2019s ability to burst CPU performance for ashort period of time. Therefore, this is a good choice for analyses of a small number ofapps. On the other hand, c4 instance types use a high-frequency Intel Xeon processorwith SSD-backed instance storage. Therefore, both one and two virtual devices can bestarted within a short period of time.Figure 5.18b depicts the throughput between the container and the virtual device fordifferent Amazon EC2 instance types. It was measured by transferring a 133 MB appvia the Android Debug Bridge from the analysis task to the emulated 2GB SD-cardstorage residing in the virtual device. The data is first passed through the ADB processrunning within the container and afterwards sent to a ADB server process within thevirtual device via a QEMU-specific channel. Hence, the throughput of the AndroidDevice Bridge makes heavy use of the CPU and involves several processes.As Figure 5.18b shows, the best results were achieved with high-end c4 and i4instance types. Due to the burst ability of t2, this low-end instance type also gives goodresults. The outlier for m3 indicates that the ADB throughput does not increase with alarger amount of RAM.1835 Security Vulnerability Analysis of Mobile Apps0\t \u00a020\t \u00a040\t \u00a060\t \u00a080\t \u00a0100\t \u00a0120\t \u00a0140\t \u00a0160\t \u00a0180\t \u00a0200\t \u00a0t2.medium\t \u00a0 m3.large\t \u00a0\t \u00a0 c4.large\t \u00a0 r3.large\t \u00a0 i2.xlarge\t \u00a0!me\t \u00a0(s)\t \u00a0AUFS\t \u00a0 DevMapper\t \u00a0 VFS\t \u00a0Figure 5.20: Container startup.Container Storage BackendsAs mentioned in Section 5.4.3, the container file system consists of multiple layers. Thiscan be realized with three storage backends: AUFS, LVM2 DevMapper and VFS.Figure 5.19 shows different backend throughputs measured with the bonnie++65 filesystem benchmark suite. It tests sequential input and sequential output on the blocklevel. Although the measurements with different Amazon EC2 instance types show ahigh variance, they indicate the following: (i) In general, read throughput per instancetype is better than write throughput. (ii) AUFS is better for instance types with moreCPU efficiency and more RAM, while DevMapper performs better for I/O optimizedinstance types. (iii) The best results are performed with VFS, which comes with nearlyzero overhead.Afterwards, the startup time for each container was evaluated. In this benchmark, aLinux ARM system image was booted with QEMU, measuring the interval betweenthe container was created and the guest kernel was booted. Figure 5.20 shows that theAUFS storage backend performed best with an average startup time of 8.09 seconds.The DevMapper backend needed 10.55 seconds on the average, whereas VFS performedworst with an average of 131.68 seconds. The long startup time is due to the deep copymechanism used by VFS: As Figure 5.21a depicts, Devmapper needed only slightlymore (3.5%) disk space compared to AUFS, but VFS needed 1934% additional storage(32.12 GB in total).The latter is also confirmed by Figure 5.21b that shows the average disk throughputof both sequential input and output. Since VFS cannot be used for its slow deploymenttimes, an interesting result is that AUFS is slightly better than DevMapper.DiscussionThe results of the experiments can be summarized as follows: (i) In contrast to asequential mobile app analysis, Dynalize offers parallel dynamic mobile app analysis toprocess mobile apps on a large scale in short time. Furthermore, Dynalize can be used65http://www.coker.com.au/bonnie++1845.4 Dynalize: Dynamic Mobile App Analysis0\t \u00a05\t \u00a010\t \u00a015\t \u00a020\t \u00a025\t \u00a030\t \u00a035\t \u00a040\t \u00a0AUFS\t \u00a0 DevMapper\t \u00a0 VFS\t \u00a0GB\t \u00a0Storage\t \u00a0before\t \u00a0boot\t \u00a0 Storage\t \u00a0a9er\t \u00a0boot\t \u00a0(a) Overhead of storage backends.0\t \u00a010\t \u00a020\t \u00a030\t \u00a040\t \u00a050\t \u00a060\t \u00a070\t \u00a080\t \u00a090\t \u00a0Output\t \u00a0(seq.)\t \u00a0 Input\t \u00a0(seq.)\t \u00a0MB/s\t \u00a0AUFS\t \u00a0 DevMapper\t \u00a0 VFS\t \u00a0(b) Average backend throughput.Figure 5.21: Average throughput and overhead of storage Backends.as an economical and flexible alternative to a dedicated cluster. (ii) The measurementswith different Amazon EC2 instance types indicate that the ability of t2 instance typesto burst CPU performance for a short period of time is useful for analyses of a smallnumber of apps, while high-end instance types like c4 can perform analysis efficientlywith a high number of virtual devices in parallel. (iii) While throughput and virtualdevice startup measurements show high variance for different instance types, the AUFSstorage backend proved to be the best of the three alternatives AUFS, DevMapper, andVFS.5.4.5 ConclusionIn this section, Dynalize has been presented, a Platform-as-a-Service (PaaS) cloud forthe dynamic analysis of mobile applications. It relies on container virtualization ontop of IaaS instances, enabling dynamic provisioning and fast deployment of dynamicanalyses. A platform architecture as well as a custom container layout and a novelstorage solution on the virtual server layer have been presented. A dynamic securityanalysis of about 6,000 Android applications has shown the cost- and runtime-efficiencyof a large-scale analysis for thousands of apps. Experiments focusing on containerstartup, virtual device to container throughput and different storage backends showedthe feasibility of our approach.Future work will address a deeper comparison between Dynalize and containervirtualization engines like Kubernetes. It will also address other storage backends, likebtrfs66 and overlayfs67. Furthermore, efforts will be made to improve the cost- andruntime-efficiency of Dynalize. For example, QEMU checkpoint/restore mechanismswill be evaluated as an alternative to full virtual device termination/restarts. Finally,it will be evaluated how Dynalize can be automatically customized to support newdevice emulators and the corresponding environment libraries.66https://btrfs.wiki.kernel.org/index.php/Main_Page67https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/Documentation/filesystems/overlayfs.txt1855 Security Vulnerability Analysis of Mobile Apps5.5 Security Assessment of Emergency Apps5.5.1 IntroductionSince the usage of traditional broadcast media, such as television and radio, is declining,apps running on mobile devices play a major role in reaching the masses with alertsand warnings. Digital distribution of information has many benefits, but also presentsnew opportunities for malicious people. The propagation of fake news or false alarmscan be used to trigger certain behavior, worsen an emergency situation, or cause anemergency situation in the first place. For example, a spoofed, fake alert can trigger amass panic and disrupt the public order. How vulnerable the Internet infrastructure iscan be seen by incidents like the temporary rerouting of Telegram traffic through Iran in2018.68 Sophisticated attackers such as federal authorities or governmental institutionseasily have access to legitimate certificate authorities and can attack network linksworld wide. Therefore, the focus of this section is on a security assessment of commondisaster warning apps and whether it is possible to spread false alarms, under whichcircumstances and for which attackers. Furthermore, apps have access to sensitive userinformation, including their location, which should also be protected. More troublesome,a warning app might just as easily be used to spy on citizens.5.5.2 Popular Emergency AppsThe security audit focuses on official and popular emergency warning apps, partiallyconsisting of national German and/or international apps, where the international appseither have a world-wide focus or focus just on the USA. A brief description of each ofthese apps is given below. All install base numbers are from July 2018.German Official AppsDWD WarnWetter The federal weather service (DWD) provides this app free ofcharge to issue weather forecasts and warnings to the general public. While the API foraccessing the weather and warning data is made public, the app itself is closed sourcesoftware. The install base on Android alone is over one million devices.BBK NINA Similarly, The Federal Office of Civil Protection and Disaster Assistance(BBK) has an app to distribute public alerts, including weather related warnings. Again,the data itself is openly available, but not the source of the app. According to theGoogle Play Store it is deployed on over one million mobile devices.KATWARN This app has a similar focus as NINA but lacks a public API. Due tothe federal system in Germany, some cities, counties or states rely either on NINA orKATWARN. It is installed on over one million Android devices.Sicher Reisen The German foreign ministry developed this app to inform and warncitizens abroad about various dangers and disaster scenarios. According to the devel-oper, it has been installed on over 400.000 devices so far.68https://www.theregister.co.uk/2018/08/01/bgp_route_leak_telegram_iran/1865.5 Security Assessment of Emergency AppsBIWAPP The Bu\u00a8rger Info & Warn App is a free app developed by Marktplatz.GmbH. Itcan be used by cities, municipalities and professional responders to publish all kindsof information and warnings. Besides weather warnings or larger disasters, it canalso publish topics including cancellation of school classes, accidents, or bomb alerts.Currently, it is installed on more than 100.000 Android devices.International App SelectionFEMA The US Federal Emergency Management Agency also has an app to informand warn the public about various dangers. Furthermore, it provides general adviceand information about the location to nearby emergency shelters. So far, it has beeninstalled on over half a million Android devices.Disaster Alert The Pacific Disaster Center developed an app to inform about activehazards world wide. These hazards can be of natural origin, such as earthquakes,tsunamis or wildfires, or man-made disasters. The app was downloaded over half amillion times from the Play Store.NOAA Weather Radar This is a commercial offering, providing US and internationalweather forecast services including various warnings. According to the Google PlayStore, this app was installed on over 10 million devices. This makes it the app with thelargest user base in this selection.5.5.3 Common Attack SurfaceWhile the audit was performed with semi-automatic scripts, utilizing static and dynamicanalysis, for various common vulnerabilities, they were also manually inspected toeliminate false positives and to search for additional security bugs. The most commonproblem areas that were looked at are briefly described in the following.Transport Layer Security As already shown in Section 5.2, many mistakes can bemade regarding transport layer security in mobile apps. While spreading public infor-mation is not reliant on encrypted links, as the content is public anyhow, it still helpsto protect the content from being tempered with while in transport. All apps rely onHTTP and therefore should use TLS to encrypt their links. Common mistakes hereinclude:\u2022 Accepting self-signed or invalid certificates\u2022 Accepting any valid certificate without hostname verification\u2022 Not pinning the expected certificateWithout implementing certificate pinning, a user is still vulnerable to any sophisti-cated attacker that can manage to install a malicious root certificate on a user\u2019s deviceor has access to any already trusted certificate authority, which can easily be achievedby governments in a cyber-war or long planned cyber-terrorist attacks.1875 Security Vulnerability Analysis of Mobile AppsIntegrity of Messages After successful delivery of alerts, there is still the possibilitythat someone unauthorized placed the false information on the server or somehowmanaged to change the message in transit. Therefore, message integrity is not only rele-vant for transmission, but also for further processing on the device. For this evaluation,it must be checked whether the published data is digitally signed, where the certificatecomes from, and whether the client verifies that the message comes from a legitimatesource.App vs. App - Intent Security Besides altering information on the server or whileit is transmitted over the network, modern mobile device operating systems such asAndroid provide various ways of Inter-Process Communication (IPC). Using intentsand receivers, an app can expose its functionality to other local apps on the device. Thisadditional attack surface might be used by a malicious app to trigger custom alerts in avulnerable app or impersonate the legitimate app.Privacy Leaks All of the mentioned apps have access to potentially sensitive infor-mation, such as camera images, GPS locations, contacts, or device resource usage.Protecting this data should always be a high priority. Therefore, we investigate whetherthis data is used locally or transmitted to a remote destination and under whichcircumstances this happens, e.g., due to crash reports, regular checks for warnings etc.5.5.4 Individual App AuditsAll apps were audited with the above four topics in mind. Therefore, a short summarymatrix for each app is provided, displaying the state of Transport Layer Security (\u00b5 TLSusage,  certificate pinning), Message Integrity, IPC Security and Privacy (\uf2a0 leaking data).For each category, an app can receive a score of up to 4 points if no issues were foundand countermeasures have been implemented in all categories or no attack surfaceis given. This results in a maximum score of 16 points that an app can achieve. If anexploitable vulnerability is found, screenshots with a false alarm are given, includingout-of-place strings such as \u201dMITM\u201d or the number \u201d23\u201d as an indicator for a successfulattack.1885.5 Security Assessment of Emergency AppsDWD WarnWetterSecurity Matrix: DWD WarnWetterTransport Layer Security: \u00b5  Message Integrity: \u00e9IPC Security: \u00cb Privacy: \u00cbOverall Score: 10The official German weather forecast and warning app fetches all its data via HTTPS. Itwas not possible to use a self-signed certificate, a broken one or a valid one for anotherhostname. But since no certificate pinning was used, any trusted authority can issuea valid certificate for a malicious server. Since the delivered data from DWD was notsigned and therefore cannot be validated, a Man-in-the-Middle attack is still possiblefor a sophisticated attacker, as shown in Figure 5.22. Here, an attacker can not onlyinject text based warnings, but also directly embed videos, e.g., as a weather reporterpresenting a false forecast or spreading a fake warning.Figure 5.22: Successful MITM attack on WarnWetter.Furthermore, the GPS location is used, but only locally, since all warnings are loadedfrom the server and filtered on the device for the ones relevant for the user. There isalso usage and debug code present that gathers various statistics, but there seems novalid code path to trigger this behavior. Thus, no major privacy issues were found withthis app.1895 Security Vulnerability Analysis of Mobile AppsBBK NINASecurity Matrix: BBK NINATransport Layer Security: \u00b5  Message Integrity: \u00e9IPC Security: \u00cb Privacy: \uf2a0Overall Score: 6Similarly to WarnWetter, NINA also relies on HTTPS to fetch its content. Trust managersand TLS code in general work as intended, but again, no certificate pinning and nosigning of the retrieved data can be found. This enables advanced attackers to performMITM attacks and inject their own alerts, as shown in Figure 5.23. Furthermore,hardcoded basic authentication credentials are stored in the app to communicate withone of the backend systems responsible for push notifications.Figure 5.23: Successful MITM attack on NINA.Privacy-wise, the whole warning database is downloaded and locally checked forrelevant alerts. Yet, Google Analytics is contacted by the app, which should not benecessary for the functionality of the app. There is a lot of tracking code in place, givingdetailed feedback about the device and app usage. It is possible to deactivate this codevia the settings, by default it is turned on. From a privacy standpoint, this should bethe other way around.1905.5 Security Assessment of Emergency AppsKATWARNSecurity Matrix: KATWARNTransport Layer Security: \u00b5  Message Integrity: \u00e9IPC Security: \u00cb Privacy: \uf2a0Overall Score: 8KATWARN takes a completely different approach than the previous two applications.Here, the warning database is not publicly available. Each user/device has to registerwith the service and subscribe to different alert topics (e.g., Oktoberfest, Dippemess)and/or regional areas. The app itself ships a certificate to verify the identity of theserver. This means that for any successful MITM attack to be carried out, the app itselfhas to be heavily modified. This server pinning is an effective security measurementagainst network based attacks, even though the system still lacks signed alert data.Relying on complex server-side software for data exchange, on the other hand, addsunnecessary complexity and, therefore, provides a larger attack surface to the overallsystem.Having each device uniquely register at the central server and requesting specificlocations regularly means that identifying individuals and tracking them is rathereasy. Although this is happening over an encrypted link, it is not necessary for theapplication to provide its functionality, as the previous apps have shown.1915 Security Vulnerability Analysis of Mobile AppsSicher ReisenSecurity Matrix: Sicher ReisenTransport Layer Security: \u00b5  Message Integrity: \u00e9IPC Security: \u00cb Privacy: \u00cbOverall Score: 10Attacking the app on the transport layer works in the same way as it does withWarnWetter and NINA. No certificate pinning is in place and the data is directlyrendered to the user, without any validation. It is possible to display any HTML textand external images, but not the execution of JavaScript. A successful attack is shownin Figure 5.24. Furthermore, hardcoded credentials together with basic authenticationare used for each request to the server.Figure 5.24: Successful MITM attack on Sicher Reisen.No external resources are contacted besides those relevant for the main service. Allissued warnings are downloaded and the relevant ones for the user\u2019s location arelocally selected, as it should be. Overall, the app leaves a good impression in terms ofprivacy.1925.5 Security Assessment of Emergency AppsBIWAPPSecurity Matrix: BIWAPPTransport Layer Security: \u00b5  Message Integrity: \u00e9IPC Security: \u00cb Privacy: (\u00cb)Overall Score: 8The app also uses TLS correctly, but lacks certificate pinning and signing of the receiveddata. Therefore, it can easily be tricked into displaying false information when a trustedcertificate authority is used for the attack (Fig. 5.25). A few informational pages areloaded via HTTP to display information about pages and the likes.Figure 5.25: Successful MITM attack on BIWAPP.While analyzing the HTTPS-based protocols, more possible attacks on the app and theserver infrastructure came to light. Since each user is identified by an easily guessable 6-digit number, an attacker can trigger test alarms for any or all users by brute-forcing thenumbers and sending a short POST request to the API server. The app downloads thecomplete alert database, with a current size about 1 MB, every time the app is started orthe main screen is refreshed. Clicking on the test notification also triggers this behavior.Depending on the state of the app, the whole database is then downloaded multipletimes for one test alarm. This can be used to deplete the bandwidth volume of theusers phone contract or put stress on the server, resulting possibly in a denial-of-serviceattack. Furthermore, these brute-forced user IDs can be used to get the subscriptionlist of any BIWAPP user, also revealing their current location if they did enable the1935 Security Vulnerability Analysis of Mobile Appsguardian feature. During analysis of the requests and corresponding results, it becameevident that some fail regularly due to syntax errors, producing stack traces in theserver responses. These might contain useful information for attackers going after theserver systems.The app itself logs verbosely to the device system log but does not transmit thisdata back home. Privacy only leaks due to the bad protocol decisions and the serverback-end security, where an attacker could gain the users location and subscribedinterests. Furthermore, one of the external about pages uses piwik69 to gather statistics,such as the user agent. This is only triggered if one explicitly clicks on the link in theabout section. Thus, for BIWAPP the privacy issues are mostly related to the servercomponent and bad protocol/API design, and not to the app code itself.69https://github.com/piwik1945.5 Security Assessment of Emergency AppsFEMASecurity Matrix: FEMATransport Layer Security: unlock  Message Integrity: \u00e9IPC Security: \u00cb Privacy: \uf2a0Overall Score: 4The FEMA app partially uses TLS with correct hostname verification but also lackscertificate pinning. Therefore, it is possible to alter some content such as the blognews (Fig. 5.26a). Furthermore, some data is loaded via plain HTTP, such as the leafletJavaScript library, which can easily be modified to display false data (Fig. 5.26b). Thisleaves the app wide open for easy manipulation, since not only text and images can bechanged, but JavaScript code can be directly executed.(a) Sophisticated attacker performingMITM attack.(b) Primitive attacker changing map codeduring app start.Figure 5.26: Different successful attacks on FEMA app.Regarding privacy, the user\u2019s location and a possible target shelter is leaked viaHTTP when activating this functionality. Also, a token is generated when launchingthe app for the first time. It is used for communication with the back-end server, butuser- or device-specific data does not seem to be involved. Furthermore, the Androidversion and platform are leaked by HTTP(S) links.1955 Security Vulnerability Analysis of Mobile AppsDisaster AlertSecurity Matrix: Disaster AlertTransport Layer Security: unlock  Message Integrity: \u00e9IPC Security: (\u00e9) Privacy: \uf2a0Overall Score: 2Contrary to most of the previously mentioned applications that were vulnerable toMITM attacks only with valid certificates, PDC\u2019s Disaster Alert even loads HTMLfrom unencrypted HTTP links. Besides static content, it is also possible to executeJavaScript code within the app. This makes injecting manipulated content very easy,even for unsophisticated attackers, as displayed in Figure 5.27. Furthermore, hardcodedcredentials are used for basic authentication in some API calls to the service. Mostof these calls are sent twice, once without credentials, thus failing, and once withcredentials. This behavior wastes precious resources in a disaster scenario. Moreover,the app also exposes complex IPC functionality locally that under specific circumstancesmight be used to an attacker\u2019s advantage.Figure 5.27: Successful MITM attack on Disaster Alert.Privacy-wise, transmitting data unencrypted is also problematic since anyone withaccess to the routing path or local WiFi can easily eavesdrop on the user. These insecuretransmissions happen for the main app code, but also for helper functions such asGoogle\u2019s geocode API. Google Analytics is used by the app when accessing the FAQwhich also happens over an unencrypted link. Furthermore, privacy related informationis sent to another analytics server via HTTP.1965.5 Security Assessment of Emergency AppsNOAA Weather RadarSecurity Matrix: NOAA Weather RadarTransport Layer Security: unlock  Message Integrity: \u00e9IPC Security: \u00cb Privacy: \uf2a0Overall Score: 4This app uses plain HTTP to load an overlay for its weather radar on the map view. Thiscan be used to replace the tiles with custom warning symbols, as shown in Figure 5.28.Weather warnings are also downloaded as a ZIP file over a plain text link. Manualinspection shown that the remote server is capable of communicating using HTTPS.Thus, it is really a bug in the app and could easily be fixed by simply switching theprotocol in the source code. On the other hand, certificate pinning is used for some ofthe embedded functionality and specific servers, mostly integrated code from socialand ad networks. Yet, the servers vital for the service itself are not pinned or do notuse TLS at all.Figure 5.28: Successful MITM attack on NOAA Weather Radar.The user\u2019s location is leaked via plain HTTP to the weather service provider. Also,the app contains code for various ad networks, potentially leaking information andbroadening the general attack surface.1975 Security Vulnerability Analysis of Mobile AppsTable 5.8: Audit summary grouped by attacker skill and general privacy issues.App Primitive Attacker Sophisticated Attacker PrivacyDWD WarnWetter \u00e9BBK NINA \u00e9 \u00e9KATWARN (\u00e9) \u00e9Sicher Reisen \u00e9BIWAPP \u00e9 (\u00e9)FEMA \u00e9 \u00e9 \u00e9Disaster Alert \u00e9 \u00e9 \u00e9NOAA Weather Radar \u00e9 \u00e9 \u00e95.5.5 ConclusionThe security audit of these common emergency warning apps has shown that there areseveral shortcomings regarding security as well as privacy. Here, an \u00e9 indicates that anapp fails to defend itself against the corresponding attacker, either with primitive skillsor sophisticated ones, or has privacy issues in general. While a primitive attacker mighttry to intercept traffic with a self-signed certificate or by spoofing an intent to triggera false alarm, most apps defend very well against these types of attacks. Given that ahighly sophisticated and dedicated attacker can gain access to a certificate authorityor manage to install own certificates in users trust stores, many applications displayvulnerabilities. Furthermore, even when the transport layer is properly secured usingcertificate pinning, the data itself could be altered by an sophisticated attacker. This canonly be prevented by digitally signing the data and verifying it at the end user\u2019s mobiledevice. Fortunately, most apps avoid security problems through improper protection oflocal IPC code. Only more or less harmless code is left exposed with a few exceptionsof apps that already have shown serious flaws for transport security. Regarding privacy,almost every app has issues where it leaks data to third parties, to the official appservers or to Google.Having strong transport layer security without signed data, e.g., KATWARN, can alsocause problems during a disaster. While the publicly available data from WarnWetterand NINA can easily be served from another server, if the system is under stress byusers or a denial-of-service attack, the KATWARN service requires more server-sidelogic and proper certificates, matching the one distributed with the app. Having a morecomplex API and the process of retrieving data from the server can easily be used forserver-side attacks by sophisticated attackers. Hence, this should be avoided if it isnot absolutely necessary. Of course, for data duplication to work, both, WarnWetterand NINA, should provide signature files for verification of their distributed data,which they currently lack. The importance of proper protocol design and remote serversecurity also becomes evident when looking at the flaws found in BIWAPP. Theselead to serious privacy issues and enable attackers to easily force massive resourceconsumption on clients, servers and network links, with minimal effort on the attackerside.Overall, one can conclude that the official German warning apps provide basicsecurity features, but fail to deliver proper security when facing more serious threats.1985.5 Security Assessment of Emergency AppsThe recent events of increased cyberwarfare, manipulation of votes and cyber terrorismin general have shown that there are major players easily capable of conducting suchattacks on a large scale. The international apps have similar problems, but additionallyalso fail at defending against primitive attacks in various circumstances.All vulnerabilities found during this audit have been disclosed to the vendors priorto releasing this thesis.1995 Security Vulnerability Analysis of Mobile Apps5.6 SummaryAn analysis of 13,500 popular free apps from Google\u2019s Play Market regarding thestate of SSL security and protection from Man-in-the-Middle attacks was presentedin Section 5.2. MalloDroid was introduced, a tool to detect potential vulnerabilityagainst MITM attacks. The analysis revealed that 1,074 (8.0 %) of the apps examinedcontain SSL/TLS code that is potentially vulnerable to MITM attacks. Various forms ofSSL/TLS misuse were discovered during a further manual audit of 100 selected appsthat allowed successful MITM attacks against 41 apps and gathered a large varietyof sensitive data. Furthermore, an online survey was conducted to evaluate users\u2019perceptions of certificate warnings and HTTPS visual security indicators in Android\u2019sbrowser, showing that half of the 754 participating users were not able to correctlyjudge whether their browser session was protected by SSL/TLS or not. The sectionis concluded by considering the implications of these findings and discussing severalcountermeasures with which these problems could be alleviated.In Section 5.3, AndroLyze, a distributed framework with unified logging and report-ing functionality to perform security checks on large numbers of applications in anefficient manner, was presented. AndroLyze provides optimized scheduling algorithmsfor distributing static code analysis tasks across several machines. Moreover, AndroLyzecan handle several versions of a single mobile application to generate a security trackrecord over many versions. To demonstrate the benefits of AndroLyze, the Top Free500 Android applications of all categories in Google Play collected over three yearswere analyzed. The resulting data set consists of almost 40,000 mobile applications andrequires about 227 GB of storage space.A Platform-as-a-Service cloud for the dynamic analysis of mobile applications,called Dynalize, was presented in Section 5.4. It allows researchers and developers toinvestigate mobile applications at runtime in a virtual device cloud and to publishthe performed analyses as web services. In contrast to existing approaches, it makesuse of container virtualization on top of Infrastructure-as-a-Service instances, enablingdynamic provisioning and fast deployment of dynamic analyses. A custom containerlayout and a novel storage solution on the virtual server layer ensures cost- and runtime-efficient large-scale analyses of thousands of apps. The applicability of Dynalize isdemonstrated by a security analysis of about 6,000 Android applications. Experimentson container startup, virtual device to container throughput and different storagebackends show the feasibility of the proposed approach.The results of an security audit of the most common emergency apps was presented inSection 5.5. Here, it was shown that, while most apps provide basic security mechanisms,they still fall short when facing a sophisticated attacker. Furthermore, many apps alsohave privacy issues, leaking data to third parties or the app provider.2006 Secure Cloud Systems6.1 IntroductionThe previous chapter has shown that various security issues exist with existing mobileapps. This was also true for emergency specific apps. Furthermore, the audit of theseapps has also revealed flawed protocol designs and bugs in the server APIs. To ensurethe overall security, the backend systems running in the cloud must also be protectedfrom attackers.One of the main methods of communication for civilians as well as governmentaland non-governmental organizations is still email, which also makes it a prioritywhen rebuilding or installing emergency infrastructure.1 Therefore, the security ofthe involved technologies such as SMTP are vital also during emergency scenarios.An in-depth analysis of the state of transport layer security of SMTP in the GermanIP-Space is given in Section 6.2.Malware and kernel rootkits pose great threats to server infrastructure. The use ofvirtual machines especially in large hosting environments opens new possibilities fordefense against these threats. In Section 6.3 a combined approach for live applicationtracing, signature based malware detection and kernel rootkit prevention is presented.This does not require any software installation in the virtual machine but only amodified kernel with the security critical code running \u201doutside\u201d the machine.A holistic concept to detect, analyze and handle security anomalies in virtualizedcomputing systems is presented in Section 6.4. The focus is on intrinsic securitymeasures for virtualized cloud services. This is achieved by utilizing fast, minimal-intrusive sensors across all layers and using a federated Complex Event Processing(CEP) engine to aggregate and correlate events to find genuine attack and eliminatefalse positive alarms.1https://www.heise.de/newsticker/meldung/Not-Internet-aus-dem-Ballon-3848035.html2016 Secure Cloud Systems6.2 Assessment of Email Delivery Security6.2.1 IntroductionTransport Layer Security (TLS) and its predecessor, Secure Sockets Layer (SSL), areapplication-layer protocols to encrypt data segments transferred on the underlyingtransport layer of the Internet Protocol Suite. The communicating entities use X.509certificates and thus rely on asymmetric cryptography to authenticate themselves and toexchange symmetric session keys to encrypt data flowing between the communicatingentities. The use of X.509 certificates requires certificate authorities (CA) and a publickey infrastructure (PKI) to verify the relation between a certificate and its owner, aswell as to generate, sign, and administer the validity of certificates.Several versions of TLS and SSL protocols are used in applications such as the WWW,electronic mail (email), and Voice-over-IP. The current version of TLS, TLS 1.2, wasdefined in RFC 5246 and released in August 2008, TLS 1.3 is currently available as adraft version. The most recent version of SSL, SSL 3.0, was released in 1996 (see RFC61012).DNS MX QueryMail TransferSMTP Port 25Mail SubmissionSMTP Port 587Mail RetrievalIMAP, HTTP, \u2026smtp.two.orgm.one.dealice@one.de bob@two.orguser-opaqueuser-influenceable Alice sends mail to Bob.Figure 6.1: Email transfer and TLS usage.Since email is a fundamental technology in everyday communication for governmentagencies, NGOs and civilians alike, its security is highly relevant during a disasterscenario.The focus of this research is the use of TLS in SMTP3,4, the Simple Mail TransferProtocol, responsible for the delivery of email. In Figure 6.1, the process of sending andreceiving email is outlined. Alice connects to her provider via SMTP on Mail Submission2https://tools.ietf.org/html/rfc61013https://tools.ietf.org/html/rfc8214https://tools.ietf.org/html/rfc53212026.2 Assessment of Email Delivery SecurityPort 587. Using StartTLS, she can encrypt the connection, as long as the email providerhas this option enabled. After authenticating herself, she submits her email for Bob toher provider\u2019s email server. Her provider then looks up the DNS MX record for Bob\u2019semail address. In the next step, Alice\u2019s provider connects to Bob\u2019s provider using theMail Transfer Port 25. Neither Alice nor Bob are able to review the connection propertiesthe providers are using for the email transfer. Finally, Bob connects to his providervia the provider\u2019s web page or protocols such as POP3 or IMAP, and retrieves theemail from his provider. Even if the email body may be encrypted by Alice using aclient-side end-to-end encryption protocol such as Pretty Good Privacy (PGP) [219],meta-data such as sender, receiver and subject names may be visible to others, if theserver-to-server connection is not encrypted properly. To secure the server-to-serverconnection, SMTP has been combined with TLS to encrypt email delivery and exchangebetween the participating entities 5. Usually, the end user has no influence on this partexcept for his/her own mail submission to his/her provider\u2019s email server.Recent revelations by Edward Snowden show that various government agenciesactively and passively gather as much information from communication in the Internetas they can. Furthermore, since many corporate processes are coordinated using emailwithin a company or with its costumers, the security of email is important for avoidingcorporate espionage. Although consumers often communicate via Facebook, Whatsappor Google Talk, email is typically used for banking, tax and online shopping relatedinformation that may be quite valuable for criminals, governments or other entities.In this section, the results of a study of the security properties of SMTP over TLSconducted within the German IP address space (about 100 million IP addresses) ispresented. A look at the involved cipher suites, the used certificates, CAs, and thegeneral availability of TLS within the detected SMTP servers is taken. Since most privateemail correspondence is managed by a few big email providers, the behavior of theirMail Transfer Agents (MTAs) when communicating with improperly secured emailservers is also analyzed. The results of the investigation lead to recommendations andbest practices to solve some of the identified security issues.Parts of this section have been published in [12].6.2.2 Related WorkThe security properties of the TLS/SSL landscape have been investigated in severalworks. The used certificates, the lengths of the private keys and the supported cryp-tographic functions bear significant security risks, as indicated by attacks such asPOODLE6, BEAST7 and LUCKY THIRTEEN [220].Lee et al. [221] have investigated cryptographic cipher suites, key lengths and supportfor the insecure version SSL 2.0 in TLS/SSL servers. Attacks on the RC4 stream cipher[222] and the MD5 hash function [223] have been presented in other publications. Intheir study on the certificate ecosystem used in the WWW, Eckersley and Burns [224]have shown that only around 40% of the investigated web servers had a valid certificatechain. In 2011, Holz et al. [225] have presented their analysis of the SSL landscape andthe use of X.509 PKIs based on active and passive gathering of certificates, indicating that5https://tools.ietf.org/html/rfc32076https://poodlebleed.com/ssl-poodle.pdf7http://www.hit.bme.hu/~buttyan/courses/EIT-SEC/abib/04-TLS/BEAST.pdf2036 Secure Cloud Systemsonly 18% of the provided certificates were accepted without warning when validatingthem with the Mozilla Root Store. Ristic and Small [226] have presented an overview ofSSL usage in the WWW. In 2013, a similar study has been published by Durumeric et al.[227] to analyze signing CAs, key lengths and cryptographic algorithms. In Section 5.2we have conducted a mass audit of mobile Android applications to identify securityissues in the use of TLS/SSL.Giesen et al. [228] have published an approach to increase the security of recentmechanisms for TLS renegotiation. This hardening prevents Man-in-the-Middle attacksin some instances and minimizes the attack surface of applications using TLS. Focusingon TLS certificate management, Szalachowski et al. [229] have presented a solution basedon the idea of publicly verifiable logs as made popular by Laurie et al.8 with CertificateTransparency for PKIs. The reference implementation for a HTTP environment aidsin securing the PKI landscape as a whole. Ryan\u2019s work [230] also enhances CertificateTransparency and integrates it with end-to-end email encryption in an attempt to makeit easier accessible for users and avoid some of the cumbersome quirks of PGP. Thisapproach helps to improve certificate management, removes several trust issues andincludes end-to-end encryption transport channel security. Even if certificate validationis performed accordingly, it still leaves an attack surface. A general overview of pastattacks on SSL in the context of the WWW and issues with the certificate trust modelhas been shown by Clark and Oorshot [231]. However, the authors have web browsersand HTTPS traffic in mind, and their solutions are tied to this use case.Huang et al. [232] have published a study to detect forged SSL certificates in thewild. They have analyzed over 3 million real-world SSL connections to Facebook. Eventhough the used detection mechanisms are limited, about 0.2% of the connectionswere detected using forged certificates. Validating certificates is an error-prone task,and various SSL libraries have different default behaviors. Automated tests have beenperformed by Brubaker et al. [233] to reveal major flaws in common libraries and howthey are used in software like web browsers, giving false or at least misleading feedbackto the user. Slow deployment rates of security fixes for SSL related code has beenidentified as a key problem by Bates et al. [234]. The proposed approach hooks SSLverification code to non-browser applications to give them increased security withouttampering with the actual source code. These extra validations impose a 20 ms overheadand work out-of-the-box with 94% of Ubuntu\u2019s most popular packages.None of the cited works is concerned with the use of TLS/SSL in SMTP servercommunications. However, email is still an integral part of today\u2019s business communica-tions. Recently, Facebook9 has published some interesting observations regarding theiremail system. For example, STARTTLS is adopted by 76% of the unique MX hostnamesthat Facebook is in contact with. Moreover, 58% of the notification emails sent aresuccessfully encrypted. The study concludes that general support for encryption isavailable, but proper certificates and certificate validation are missing.8https://tools.ietf.org/html/rfc69629https : / / www . facebook . com / notes / protect - the - graph / the - current - state - of - smtp -starttls-deployment/14530159016052232046.2 Assessment of Email Delivery Security6.2.3 An Empirical Study of SMTP over TLSThe study of the email TLS landscape is based on the German IPv4 address space. Inparticular, 116,824,576 IP addresses were scanned to investigate the TLS properties ofGerman SMTP servers. Using nmap10, it was first checked whether the relevant portswere open and then TLS versions, cipher suites, certificates, CAs, and email providerstrategies were analyzed.SMTP uses port 25 as its main port. Port 465 has been suggested for SMTP overTLS, called SMTPS (Simple Mail Transfer Protocol Secure)11, but was later revoked;nevertheless some email providers still use this port. Port 587 is used to transfer emailfrom the user to the provider\u2019s server.Nmap also performs a reverse Domain Name System (DNS) lookup to find thedomain names belonging to the referenced IP addresses. It is common to check thereverse DNS name when an email is sent to a server, thus the domain names should beset. These domain names are used later to check the validity of TLS certificates and tomake sure that the IP in question is under the authority of the domain owner; emailsfrom servers without valid reverse lookups should not be accepted.totalport 25port 465port 5870 175,000 350,000 525,000 700,000656,29544,47827,870188,765211,556238,827419,373TLS handshake successful TLS handshake failed totalFigure 6.2: SMTP and TLS usage among the scanned hosts.TLS UsageFrom the scanned hosts reached at the 116,824,576 IP addresses, 656,295 hosts offerSMTP services on at least one of the following ports: 25, 465 or 587. Figure 6.2 showsthat only 68.96% (419,373) of the 608,138 hosts that offer SMTP services on port 25perform a successful TLS handshake on this port. On the mail submission port 587,82.63% (211,556 of 256,034) complete a TLS handshake successfully. While on port 465,which has TLS enabled by default, a TLS handshake nevertheless fails in 10.45% of theattempts. It is likely that server administrators use this port for different services notrelated to SMTPS. The results presented below are either based on the 656,295 hoststhat offer SMTP services on at least one of the three ports or on the 869,756 services(see Fig. 6.3) with a successful TLS handshake on at least one of three ports.10https://nmap.org11https://tools.ietf.org/html/rfc32072056 Secure Cloud SystemstotalSSL 3.0TLS 1.0TLS 1.1TLS 1.20 225,000 450,000 675,000 900,000869,756349,100413,644864,020824,785Figure 6.3: SSL and TLS versions used in the scanned services.TLS/SSL VersionsTLS and SSL have a long history of organic growth, leading to a non-uniform useof their different versions. SSL 2.0 had certain design flaws, ultimately leading to aninsecure protocol. SSL 3.0 was considered secure, until the POODLE attack went publicin October 2014. The SMTP server scans took place in May 2014, five months before thePOODLE attack was released to the public. On these grounds, the collected data allowsus to observe the potential impact of the attack.In Figure 6.3, the TLS/SSL versions used in the scanned SMTP servers are visualized.While the insecure version SSL 2.0 is not used at all, SSL 3.0 is enabled in 94.83% ofthe servers. The most popular TLS version 1.0 is supported by 99.34% of the servers,whereas the versions TLS 1.1 and TLS 1.2 are supported by less than half of the servers.BEAST\u2019s target was TLS 1.0, so there is no reason to hold back the newer versions.POODLE is also a good argument to use TLS 1.2 instead of SSL 3.0 \u2013 SSL 3.0 is onlyused for the sake (or curse) of compatibility.TLS Cipher SuitesIn a TLS handshake, the client offers a list of supported cipher suites to the server,which then picks one to secure the connection. To obtain all cipher suites supportedby a server, the client has to iterate over the cipher suites and then tries to establish aconnection using the selected cipher suite. This functionality is provided by the nmapsssl-enum-cipher script12. Performing this test requires many connections to the testedservers and therefore creates quite some traffic in the network.If an attacker is able to influence the TLS handshake by selecting a cipher suitethat (s)he is able to break, this attack is called a cipher suite downgrade attack. Even ifbackward compatibility is a reason to offer potentially insecure cipher suites, they openup a huge attack vector. The cipher suite classification of the nmap ssl-enum-ciphersscript provides three categories of cipher suites, as described below.Broken Cipher Suites Broken cipher suites do not support protection against passiveor active eavesdropping. Therefore, all anonymous cipher suites with an unauthorizedDiffie-Hellman key exchange belong to this category. It is easy for an attacker to12https://nmap.org/nsedoc/scripts/ssl-enum-ciphers.html2066.2 Assessment of Email Delivery Securityintercept and modify the messages between client and server and decipher the data.Furthermore, cipher suites using no encryption at all or just authentication are alsoconsidered as broken.Weak Cipher Suites The category of weak cipher suites mainly consists of historicalcipher suites. Examples are the export ciphers that emerged as a consequence of theUS export rules on cryptographic systems before 1999, and cipher suites based on thelegacy Data Encryption Standard (DES). Weak cipher suites can be deciphered in abrute force manner by powerful hardware in less than a day13.Strong Cipher Suites All remaining cipher suites are strong cipher suites. Althoughthere are known weaknesses in RC4 [235] and MD5 [236], they are nevertheless usedwith some workarounds in many cases. With RFC 7465, attempts are made to removeRC4 completely [237].Another noteworthy property of cipher suites is Perfect Forward Secrecy [238]. Itensures that a session key derived from a set of long-term keys can not be compromisedif one of the long-term keys is compromised in the future. Thus, an attacker cannotdecipher past messages even with the server\u2019s private long-term key.totalwith strong cipherswith weak cipherswith broken ciphersonly strong cipherswith pfswith ecdh0 225.000 450.000 675.000 900.000869.756194.108741.284240.547430.621504.711869.278Figure 6.4: Use of cipher suites.Figure 6.4 illustrates the used cipher suites. Almost every server offers strong ciphersuites, but only 27.66% of the servers are hardened in the sense that they offer strongcipher suites only. It is remarkable that 85.28% of the servers offer Perfect ForwardSecrecy (pfs). A widely discussed issue is the use of Elliptic Curve Cryptography (ECC),since many of the ECC algorithms are suspected to have been constructed under theinfluence of US intelligence services14. In our data set, 22,32% of the servers supportECC ciphers (ecdh).In Table 6.1, the top ten most used weak and broken cipher suites are presented.Many servers accept weak cipher suites without the need to. Looking at the FREAKattack15 published in March 2015, more than half of the server\u2019 connections can bedowngraded to weak or broken cipher suites.13http://www.sciengines.com/company/news-a-events/74-des-in-1-day.html14https://www.wired.com/2007/11/securitymatters-1115/15https://freakattack.com2076 Secure Cloud SystemsTable 6.1: Shares of weak and broken cipher suites.Name Usage ShareDH anon AES 256 CBC SHA 426,848 49.08%DH anon 3DES EDE CBC SHA 426,835 49.08%DH anon AES 128 CBC SHA 426,779 49.07%DH anon RC4 128 MD5 424,526 48.81%RSA DES CBC SHA 416,324 47.87%RSA EXPORT RC4 40 MD5 410,627 47.21%RSA EXPORT RC2 CBC 40 MD5 409,893 47.13%RSA EXPORT DES40 CBC SHA 407,480 46.85%DHE RSA DES CBC SHA 382,903 44.02%DHE RSA EXPORT DES40 CBC SHA 368,247 42.34%TLS CertificatesThe nmap ssl-cert script16 was used to retrieve the certificates used by the servers. Thisscript tries to perform a TLS handshake with the given server/port and saves thePrivacy-enhanced Electronic Mail (PEM) certificate in the scan report. In addition, itparses the fields of the certificate and stores them in the report. The script also supportsthe STARTTLS command for an active SMTP session.The validity of a certificate is based on three major properties: issuance by a validCA, time period of validity and a matching Common Name (CN). In addition, weinvestigate other issues of certificates, such as multiple uses of the key pair or shortprivate keys. Lastly, all retrieved certificates are categorized using these properties.Multiple Use of Key Pairs X.509 certificates are uniquely identified by their fingerprintusing a MD5 or the Secure Hash Algorithm 1 (SHA1) sum; current practice is to usea SHA256 hash nowadays. Although 656,295 hosts offer SMTP services in the dataset, only 218,239 unique certificates were found. The reason is the presence of sharedhosters using a single wildcard certificate for their hosts. This may not be a problemunless any user is able to retrieve the corresponding private key.Another group of repeatedly used certificates are the certificates delivered with theservers\u2019 operating systems. Those are recognizable by their subject\u2019s CN, which oftencontains the operating system name, phrases like localhost or a domain ending in *.local.These configurations have to be considered insecure, because multiple users have accessto the private key and therefore can decipher the TLS connections of other users.Also private keys that are used multiple times in different certificates were found.At a first glance, this does not involve a decrease of security. However, if the privatekey is lost, one has to revoke not only one, but all certificates issued for this privatekey. There is no acceptable reason for a system administrator to use the same key formultiple certificates.Time Period of Validity To investigate the time of validity, the certificates werecategorized into four groups, as outlined in Table 6.2. A certificate has two timestamps,16https://nmap.org/nsedoc/scripts/ssl-cert.html2086.2 Assessment of Email Delivery SecurityTable 6.2: Time period of validity of the retrieved certificates.Type Count Sharenot yet valid 161 0.07 %expired 56,078 25.68 %valid 161,993 74.20 %never valid 99 0.05 %defining the time period during which the certificate is valid. 25.80% of the certificateswere not valid. It is suspected these are hosts that are not maintained anymore. Althoughexpired certificates may not be a security problem, they are an indicator that email istreated with a low priority. Expired certificates prevent secure communication withthese servers if strict certificate validation is turned on at the email sender\u2019s side. Thereare 99 certificates which were never valid, since the not-after date of use was lower thanor equal to the not-before date of use.Table 6.3: Self-signed, server and CA certificates.Type Count Share is ca is serverserver 79,832 36.58 % 0 1ca 705 0.32 % 1 0self-signed 137,694 63.09 % 1 1invalid 1 0.01 % 0 0Certificate Issuance Also it was analyzed who issued and signed the obtained certifi-cates. Table 6.3 shows that 63.09% of the certificates were self-signed certificates, i.e.,certificates that are signed by the same entity whose identity they certify, by signingwith their own private key. It was not looked into them in more detail, since thesignature is not meaningful in these certificates, and they clearly represent a securityissue.To build the chain of trust for the non-self-signed certificates, the Ubuntu 14.04 trustedroot certificates were used as a trust anchor. It were 24,641 certificates reachable bybuilding a trust chain with the root and the retrieved intermediate certificates. Thisset of certificates corresponds to 11.29% of the 218,239 found certificates and can beconsidered trustworthy according to the signature.Key Lengths Figure 6.5 shows the growth of key lengths in relation to the dates ofissuance of their certificates. It is apparent that the key lengths are growing steadily,using an average of more than 2,230 bits at the time of the scans. The average lowestkey length stems from 2007 with 1366 bits. It is remarkable that a 1023-bit RSA numberhas been factored in May 200717, and that key lengths will become an issue when morepowerful hardware becomes available.17http://phys.org/news98962171.html2096 Secure Cloud Systemslllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll2008 2010 2012 201414001600180020002200date of issue (2007\u221201 to 2014\u221205)average keylengthFigure 6.5: Change of the average key lengths overtime.valid1.89%valid (wildcard)9.34%expired 0.19%wrong CN5.99%untrusted5.47%untrusted, expired29.03%untrusted, wrong CN 0.84%wrong CN, expired 0.39%nothing correct12.51%no rDNS10.48%no SSL/TLS23.87%Figure 6.6: Categorization of services using the mainsecurity properties.Categorization To summarize the findings regarding certificates, the three main valid-ity properties to form eight disjoint categories of certificates are used. Since not everyserver has reverse DNS entries, it was not possible to get the names of 10.48% of theservers. 23.87% did not offer TLS. Figure 6.6 indicates that only 11.23% of all scannedemail services had valid certificates in all concerns. Considering the certificate subject\u2019sCN, the category of valid certificates can be split up further. A certificate is not onlyaccepted as valid, if the CN matches the domain name, but if it has a wildcard patternin the form of *.domain.tld matching the domain name (e.g., mail.domain.tld). Usingthis categorization, only 1.89% of the email services use a certificate only valid for thisspecific host.0 50 100 150110100100010000trusted root certificates# signed server certificatesFigure 6.7: Root certificates in relation to their signed server certificates.Certificate AuthoritiesA widely criticized problem of the TLS trust model are CAs. Over the last years, moreand more CAs are trusted by software vendors. Figure 6.7 outlines the obtained trusted2106.2 Assessment of Email Delivery SecurityTable 6.4: Top 10: Most popular CAs, measured by their issued certificates.Count Share Common Name1 7,085 28.58 % StartCom Certification Authority2 4,309 17.38 % AddTrust External CA Root3 4,278 17.26 % GeoTrust Global CA4 2,632 10.62 % thawte Primary Root CA5 2,079 8.39 % GlobalSign Root CA6 1,243 5.01 % DFN-Verein PCA Global - G017 640 2.58 % UTN-USERFirst-Hardware8 515 2.08 % COMODO Certification Authority9 285 1.15 % Go Daddy Root Certificate Authority10 279 1.13 % Deutsche Telekom Root CA 2root CAs in relation to their signed server certificates of our test set. The ten mostpopular CAs shown in Table 6.4 sign 94.16% of the server certificates. To have 99%coverage, one needs to trust the 23 most popular CAs. The idea that \u201dif a CA can signfor one domain, it can sign for any domain\u201d leads to a loss of security. Examples such asthe DigiNotar hack18 or the TurkTrust incident19 show that this is a problem of practicalrelevance. Since the default configuration remains unchanged in many settings, theoperating system and application vendors should act more responsibly in this respect.CA TopologiesTo check the validity of a certificate, a user builds a so called chain of trust. In addition toits own certificate, the server can deliver additional intermediate certificates. The clientthen builds a chain of trust as follows: The issuer of a non-root certificate is identifiedby the issuer\u2019s properties of this certificate, and the signature is obtained by using theissuer\u2019s public key. To get a valid chain of trust, the last certificate needs to be in the listof trusted root certificates of the client. If no path from the server certificate to any ofthe trusted root certificates can be found, the certificate is considered as untrusted. Thisis often the case when a private CA for in-house deployment or self-signed certificatesare used.Using OpenSSL20, a key-value database was built representing the graph of signaturesand the hierarchy of CAs. Two CAs showed peculiarities. First, StartSSL uses twoalmost identical root certificates, only differing in the date of issuance and the serialnumber. The trusted root certificate set as shipped by default with Ubuntu 14.04was used. Second, as shown in Figure 6.8, the Comodo CA uses more than just theCA and intermediate certificates. Comodo cross-certifies its root keys using the otherroot certificates. This results in multiple signed key pairs and therefore in multiplecertificates for every key. If one of those root certificates is revoked, there are signingchains starting at other root certificates available. Comodo enables a kind of fail-safestrategy for their customers. Even if one root certificate is removed from the set of18https://www.eff.org/deeplinks/2011/08/iranian-man-middle-attack-against-google19http://web.archive.org/web/20130926134541/http://turktrust.com.tr/en/kamuoyu-aciklamasi-en.2.html20https://www.openssl.org2116 Secure Cloud SystemsStartCom Certification AuthorityStartCom Certification AuthorityStartCom Class 1 Primary Intermediate Server CAAddTrust External CA RootUTN - DATACorp SGCGeoTrust Global CARapidSSL CAPositiveSSL CA 2thawte Primary Root CAThawte DV SSL CAStartCom Class 2 Primary Intermediate Server CAGlobalSign Root CADeutsche Telekom Root CA 2DFN-Verein PCA Global - G01The Go Daddy Group, Inc.  Secure Certification AuthorityCOMODO High-Assurance Secure Server CAAlphaSSL CA - G2GeoTrust DV SSL CAThawte SSL CAGlobalSign Domain Validation CA - G2GlobalSign Domain Validation CA - G2PositiveSSL CAGo Daddy Root Certificate Authority - G2Go Daddy Secure Certificate Authority - G2COMODO Certification Authority tifi ti  t itGeoTrust SSL CAEssentialSSL CAEssentialSSL CAVeriSign Class 3 Public Primary Certification Authority - G5COMODO RSA Certification AuthorityCOMODO RSA Domain Validation Secure Server CADigiCert High Assurance EV Root CAStarfield Technologies, Inc.Starfield Secure Certification AuthorityVeriSign Class 3 Secure Server CA - G3Baltimore CyberTrust RootGlobalSign Organization Validation CA - G2GlobalSign Organization Validation CA - G2DigiCert High Assurance CA-3AlphaSSL CA - SHA256 - G2Entrust.net Certification Authority (2048)Uni-FR CA - G02EquifaxCOMODO SSL CATeleSec ServerPass CA 1EuropeanSSL Server CAUSERTrust Legacy Secure Server CAGeoTrust SSL CA - G2DFN-Verein-GS-CA - G02GlobalSignGlobalSign Domain Validation CA - SHA256 - G2GlobalSign Domain Validation CA - SHA256 - G2Thawte Server CADigiCert Global Root CAGlobeSSL CAStarfield Root Certificate Authority - G2Starfield Secure Certificate Authority - G2MPG CADigiCert Secure Server CAVeriSign Class 3 International Server CA - G3GeoTrust Primary Certification AuthorityGlobalSign Domain Validation CARWTH Aachen CAEquifax Secure Global eBusiness CA-1Certum CATUD CA G01TeleSec ServerPass DE-1GlobalSign Organization Validation CA - SHA256 - G2FAU-CAFHWF-CARHRK-CA - G02TC TrustCenter Class 2 CA IICertum Level II CADigiCert SHA2 Secure Server CAThawte Premium Server CASwissSign Silver CA - G2TC TrustCenter Class 2 L1 CA XIEntrust Certification Authority - L1CGeoTrust Extended Validation SSL CA - G2Technische Universitaet Braunschweig CASwissSign Gold CA - G2Zertifizierungsstelle der TUMCOMODO Extended Validation Secure Server CASwissSign Server Silver CA 2008 - G2thawte Extended Validation SSL CATU Dresden CA - G02Universitaet Bremen CAUHH CA - G02Ruhr-Universitaet Bochum CAStartCom Class 3 Primary Intermediate Server CACA der Universitaet zu LuebeckTeleSec ServerPass DE-2StartCom Extended Validation Server CAGeoTrust Extended Validation SSL CAUni Marburg CA - G02Universitaet-Goettingen CASwissSign Server Gold CA 2008 - G2Alpha CACA der LUH (UH-CA) - G03Universitaet Stuttgart CA - G01COMODO RSA Organization Validation Secure Server CADigiCert SHA2 High Assurance Server CAUniversitaet Duisburg-Essen CA -G01Vodafone (Corporate Domain 2009)VeriSign, Inc.DFN-Verein CA ServicesGlobal-UNITUE-CA 01DOMENY.PL DV Certification AuthorityUNIVERSITAET LEIPZIG CAUni Kiel CA - G02VeriSign, Inc.VeriSign Class 3 Extended Validation SSL SGC CALMU-CAWebSpace-Forum Server CATU Clausthal CA - G02Freie Universitaet Berlin - FU-CA - G01GlobalSignUniversitaet Potsdam CA - G01Vodafone (Corporate Services 2009)Vodafone (Corporate Services 2009)UTN-USERFirst-HardwareGandi Standard SSL CAFigure 6.8: CA Topology of the Comodo CA.trusted certificates, the customers\u2019 servers have other intermediate certificates to build atrusted chain. Although cross-certification is legitimate according to the X.509 standard,it implies a less secure CA, if the private key is lost.Email Provider StrategiesFinally, the connections of the providers\u2019 email servers to other email servers wereinvestigated. For this purpose, email accounts at various free email providers popu-lar in Germany were registered and emails sent to prepared test email server. Thisrevealed the connection details of the providers\u2019 outgoing connections. For this partof the study, Google Mail21, web.de22, GMX23, Freenet24, Yahoo Mail25, MicrosoftOutlook.com/Hotmail/Live26, Apple iCloud Mail27 and T-Online28 were used.The idea of this investigation was to find situations that a potential attacker withaccess to the connection between two email servers can exploit to read email. Theattacker could just passively eavesdrop on the connection or actively perform a Man-in-the-Middle attack. To simulate an attacker that attempts to change cryptographicproperties, the servers\u2019 TLS properties were changed to test the behavior of the emailproviders. In particular, the following settings were examined:\u2022 Expired certificate (not security critical)21https://mail.google.com22https://www.web.de23https://www.gmx.de24https://email.freenet.de25https://mail.yahoo.com26https://login.live.com27https://www.icloud.com28https://email.t-online.de2126.2 Assessment of Email Delivery SecurityTable 6.5: Email provider strategies for connections to other email servers.Provider Untrusted Certificate 512-bit RSA Key Anonymous Ciphers Weak Ciphers No STARTTLSGoogle Mail encrypted no delivery no delivery no delivery unencryptedWeb.de encrypted encrypted unencrypted unencrypted unencryptedGMX encrypted encrypted unencrypted unencrypted unencryptedFreenet encrypted unencrypted encrypted unencrypted unencryptedYahoo encrypted encrypted unencrypted unencrypted unencryptedOutlook/Hotmail encrypted no delivery unencrypted unencrypted unencryptediCloud encrypted encrypted unencrypted unencrypted unencryptedT-Online encrypted unencrypted unencrypted unencrypted unencrypted\u2022 512-bit RSA key certificate\u2022 Certificate with wrong CN\u2022 Only anonymous ciphers (no certificate)\u2022 Only weak or broken ciphersDifferent security settings were found and thus more and less difficult situationsto attack the email providers. All providers forward email to servers with invalidcertificates and still communicate plaintext if a server does not support TLS at all. Withone exception (Google), one can trick the email providers to send their data withoutany encryption. The results of the experiments are summarized in Table 6.5.Invalid Certificates The main security properties of a certificate are a trusted issuer,the period of validity and the domain name matching the common name. All emailproviders ignored these features, completed the TLS handshake and submitted thedata. A Man-in-the-Middle could provide this kind of certificate without any effort andthus see the data. In this study multiple certificates were used to check these properties.None of the providers complained about the often changing certificates, implying thatcertificate pinning is not used at all or at least not automatically for new or uncommonservers.Default Cipher Suites All examined email providers use strong cipher suites intheir connections, with one exception. Freenet offered, in addition to several strongcipher suites, three cipher suites with an anonymous key exchange. The anonymouskey exchange methods do not use a certificate and therefore do not provide anyauthentication of the server. An attacker would love this situation, since his or her effortto read the email data is minimized.Short RSA Keys To examine the use of short cryptographic keys, a certificate witha 512-bit RSA key was created. The email providers acted in different ways: Web.de,GMX, Yahoo and iCloud accepted the certificate, completed the TLS handshake andtransmitted the email data. Google Mail and Microsoft Outlook/Hotmail rejected thecertificate and continued with multiple unsuccessful retries. Freenet and T-Onlinerejected the certificate and closed the connection. Immediately afterwards, they openedanother connection to transfer the email without using any encryption.2136 Secure Cloud SystemsWeak Cipher Suites The behavior of the email servers when a server only supportedweak ciphers was also checked. As mentioned above, the providers offer only strongciphers in their client hello message. Therefore, the TLS handshake could not becompleted. However, all providers except Google Mail reconnect after this failed TLShandhake and transfer the email without using encryption.No STARTTLS In the last test, the STARTTLS command on port 25 was completelydisabled . After the SMTP session is initiated, an email server offers a list of featuresit supports. STARTTLS is a means to encrypt the session after it is established. Alltested email providers continued with the non-encrypted transfer of an email when thisfeature was disabled. Therefore, an attacker only needs to modify the SMTP commandlist provided by the server. Modern routing and firewall hardware, e.g., as provided byCisco, has exactly this mechanism built in to inspect mail traffic29.Implications Considering the results presented above, an interesting situation hap-pens: If an attacker is able to inject a few TCP packets into the connection, the TLShandshake is aborted, and the email provider reconnects and transfers the email with-out any transport security. Google seems to use a non-secured TLS policy in the sensethat Google transfers email using TLS only, but does not insist on correct certificates.Over the last years, several methods to avoid downgrade attacks in web browsersand other applications have been developed. Initiatives such as the SSL Observatory30and tools such as HTTPS Everywhere31 try to protect users against leakage of theirprivate data. Email providers need to catch up and deploy similar security standards intheir infrastructures.6.2.4 Advice for Email ProvidersThe SMTP TLS landscape has major flaws across most email providers. In this subsec-tion, some advice is given to email providers for obtaining secure configurations fortheir servers. The advice is meant to harden a TLS server at the cost of compatibility,which we think is one reason for weak configurations. In addition to the relevant TLSfactors, measures to prevent simple downgrade attacks are suggested.The following recommendations can be given to network administrators and emailproviders to harden their TLS configurations:1. Update the TLS stack frequently.2. Use TLS 1.0 (or higher) instead of SSL 3.0 (or lower).3. Support strong cipher suites only.4. Perform smart TLS certificate checks.\u2022 Time of validity\u2022 CA issuance\u2022 Key lengths5. Accept/use TLS enabled email transfer only.29https://www.cisco.com/web/about/security/intelligence/asa_esmtp_starttls.html30https://www.eff.org/observatory31https://www.eff.org/de/https-everywhere2146.2 Assessment of Email Delivery SecurityThe first advice is that the TLS stack of the system needs to be updated frequently tokeep the system secure.The second advice is that currently only TLS 1.0 and the higher TLS versions can beconsidered secure, since SSL 3.0 is affected by the POODLE attack.The third advice is to support strong cipher suites only. Older cipher suites withMD5 hashing or 3DES encryption should not be used, since they are more likely to bebroken in the near future. As with security updates for software and the TLS stack,email providers should pay close attention to the effects of new attacks on the list ofsecure cipher suites and remove insecure cipher suites accordingly32.The fourth advice is to perform appropriate certificate checks regarding period ofvalidity, CA issuer and key lengths and use a certificate pinning mechanism to detectbogus certificates33. A list of the trusted certificates for every server must be maintained.When a TLS handshake is in progress, it can be checked whether the certificate haschanged without revocation or whether it has expired.The final advice is to either at least warn users and let them decide to use a potentiallyinsecure connection, as done in web browsers, or decline non-encrypted email transfer,rather than just transferring email without encryption. One possibility to achieve thiswould be to set a special email header in the Mail User Agent (MUA) indicating that anemail should only be delivered over encrypted links, with strictly validated peers orjust anybody and any connection. Email should only be delivered over links with anequal or higher security rating than the one provided in the header. Although thereis no guarantee that the server respects the user\u2019s wishes, if the big email providersfollowed this proposal and enough users set a flag for strict validation and encryption,smaller providers would be forced to use valid certificates and strong ciphers. Thus,unencrypted communication could possibly be eliminated after some time. It is alsorecommend to consider Ristic\u2019s TLS deployment best practices34 for more details onTLS configuration hardening.Furthermore, email providers are mostly left alone when it comes to tools for securingand testing their setups. Qualys provides a service for web server administrators tocheck their setup for common misconfigurations35. This kind of service would be ofgreat benefit for email providers. Standardized test infrastructures could also be utilizedby central instances like CERT, the German BSI or large websites with lots of emailtraffic, such as Facebook, Youtube or Github, to automatically generate emails to MTAowners in case of security concerns. This, of course, means that every entity mustsupport the common mailbox names as suggested by RFC 214236.6.2.5 ConclusionIn this section, an empirical study of the security properties of SMTP over TLS withinthe German IP address space was presented. It was shown that even though manyemail servers support strong cipher suites, weak or broken cipher suites are still present.Furthermore, only few certificates provided by the email servers are valid (about11%). The behavior of email providers differs significantly with respect to handling32https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/33https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning34https://www.ssllabs.com/downloads/SSL_TLS_Deployment_Best_Practices.pdf35https://www.ssllabs.com/36https://tools.ietf.org/html/rfc21422156 Secure Cloud Systemsvarious TLS configurations. Based on the results, practical advice on securing SMTPsetups to avoid some of the identified issues was given. Unfortunately, an ultimatesolution offering perfect security is simply not possible with the current PKI landscape.This topic is often discussed in the context of HTTP(S), but with email the problemsmay be even harder to fix, since decision making happens automatically without userinteraction.There are several areas for future work. For example, appropriate best practicesare needed to ensure transport layer security of email traffic. A simple plain-textfallback as used by many providers significantly reduces the protection level of SMTPcommunication. Furthermore, validation and verification of peers and their certificatesmust be simplified. Finally, staying up to date with broken, weak and strong ciphersuites is another challenging task, since there is no central entity giving advice forregular updates.2166.3 Hardening Server Systems6.3 Hardening Server Systems6.3.1 IntroductionExternal and internal intrusions are the most serious threats in computer systemsconnected to a network. Attackers exploit software bugs in core components on a targetsystem to gain superuser privileges, allowing the attacker to take control of the attackedsystem. The rise of Cloud Computing aggravates the stated problem. Cloud Computingrefers to both the on-demand provisioning of hardware resources in the data centers ofpublic providers such as with Amazon\u2019s Web Services, and the applications deliveredas services over the Internet, such as with Google\u2019s AppEngine. Offering access toremote compute resources is often referred as Infrastructure as a Service (IaaS). Theresources provided as IaaS are platform virtualized environments, i.e. customers haveaccess to their own virtual appliances running on shared physical resources.To retain the control of the attacked system persistently, the intruders typically installmalware in order to recover full control after reboot. The target system in this caseis the virtual machine offered by the Cloud Computing provider. This kind of attackis commonly discussed as a strong intrusion attack, while temporary attacks betweentwo operating system startups are referred as weak intrusion attacks [239]. The softwaretoolkits that are installed within a strong intrusion attack are commonly called rootkits.Usually, weak intrusion attacks are used to place a rootkit on the attacked system.These potential threats create the need for a new malware detection system. Providersneed ways to ensure the security of their infrastructure and the systems of theircustomers. Having a flexible Cloud infrastructure also opens new possibilities to scaleup and distribute malware detection software among several systems. Most end-hostsecurity solutions have a major, negative performance impact on the computer causedby huge signature-sets or complex detection algorithms. Cloud Computing can bebeneficial here to decrease the slowdown and offload it to dedicated machines.In this section, an approach that deals with malware detection and kernel rootkitprevention is presented. While the former deals with detecting malware traces duringruntime in a safe and non-intrusive manner, the latter prevents rootkits from beinginstalled in the operating system kernel. A Cloud-based intrusion detection systemto recognize running malware is designed to run on virtual machine instances with abackend Cloud to distribute malware scanning operations between several backends. Aflexible framework for a distributed security solution with a minimal overall resourcefootprint on the end host is presented. To detect well-known as well as yet unknownmalware, a traditional signature check is performed and the prerequisites for a livesystem-call tracer are presented. Furthermore, the solution introduces an integritycheck of authorized kernel modules to prevent rootkit installations via corruptedkernel modules. For this purpose, the operating system kernel is modified to load onlypreviously cryptographically authorized kernel modules.Parts of this section have been published in [13].6.3.2 Problem StatementA convenient way for an attacker to gain control over a compromised system is a rootkit.There are various types of rootkits available, e.g. application level rootkits that replacethe original binaries with a fake binary containing a trojan horse or library rootkits2176 Secure Cloud Systemsthat replace valid library functions with malicious ones. The focus of our work is thekernel rootkit. It replaces/adds functions or device drivers in the kernel space of anoperating systems. Kernel modules in general enable upgrades to specified parts ofa kernel to strengthen modularity of the operating system. There are two classes ofkernel modules: permanent kernel modules, which are loaded at boot time and cannotbe removed once they are running, and loadable kernel modules, which can be loadedand unloaded by the system at run time. Many kernel rootkits are designed as loadablemodules or device drivers, since this is the easiest way to add new functionality to thecore system. Thus, monitoring the loading process of kernel modules is indispensableto ensure that no malicious modules are loaded.There are various ways to disable dynamic kernel module loading:\u2022 In Linux it is possible to disable kernel module loading completely. While con-figuring a kernel, the administrator can set the MODULES option to NO and thusdisables the complete kernel loading and processing mechanism. While thiscompletely prevents kernel rootkits from loading, it also affects all legal modules.\u2022 The technique of multiple secure levels is used in various BSD derived Unixoperating systems. Any super user is able to increase the secure level. On theother hand, the only way to lower the secure level is via the init-process, aprototype user process that is only loaded during system startup, so the systemhas to be restarted. For example, FreeBSD [240], a widely used Unix branch, runswith four different levels of security.Thus, it is possible to disable dynamic module loading either by disabling modules orvia a higher secure level. In this case, one has to take the good with the bad: On the onehand, this avoids critical actions such as arbitrary changes of kernel memory throughuser programs (which, in fact, is performed by loading a kernel module). On the otherhand, the concepts are very restrictive and forces users to compile and install the wholekernel instead of linking a single file. This step makes a reboot of the modified systemnecessary and interrupts running applications. Actually, for several applications (e.g.all mission critical applications), this is not a suitable solution.While the previously stated problem applies to a greater extent to infrastructuralmachines, such as critical servers (e.g. DNS, DHCP), a Cloud provider should also beinterested in keeping the VMs of its customers safe. Most Cloud vendors provide VMswith full root access, meaning that a user can mostly do whatever (s)he wants, includingdestroying the whole machine. Since Cloud Computing is about pay-as-you-go, thisshould not harm the vendor. Nevertheless, if a user (intentionally or not) executesmalware, this could also affect the provider, e.g. a spam malware could abuse theoutgoing bandwidth to send mass-spam mails. Thus, while granting root permissionsto its customers, a provider still should be able to inspect the applications runninginside its customers\u2019 VMs. Furthermore, (s)he should be able to take countermeasuresif (s)he detects a security violation, such as running malware binaries. In the followingsection, we will present a Cloud based host intrusion detection system with a minimalresource footprint as well as hidden from the malware itself in the operating systemkernel.2186.3 Hardening Server Systems6.3.3 Related WorkKroah-Hartman [241] has proposed to sign executables with a fingerprint. It is stored inan additional section of the commonly used executable linkage format (ELF). Further-more, the technique of asymmetric cryptography is used to protect the fingerprint frommalware modifications: A private key is used to encrypt the fingerprint stored in theELF section, while the kernel linker decrypts the signature in order to compare it withthe signature of the loaded file. A general problem is the kernel-level implementationof an asymmetric cryptography algorithm. There is no such implementation in mostcurrent operating systems. This is the reason why for this research the symmetricSHA256 hash algorithm was chosen.A similar way of implementing a kernel rootkit prevention technique is used byCatuogno et al. [239]. They implemented a verification mechanism based on encryptedsignatures stored in an additional section of an executable as well. In contrast to Kroah-Hartman, they did not address dynamically loadable kernel modules but executablesin general. This is why they assumed that the support of dynamically loadable kernelmodules should be disabled. This is not an appropriate assumption for the security ofmost applications.In the NetBSD operating system, the Veriexec (verified execution) kernel subsys-tem allows users to monitor files and to prevent their removal, read/write accessor execution if necessary37. It implements four levels of strictness: A learning modefor configuration matters, intrusion detection and intrusion prevention mode, as wellas a lockdown mode. Contrary to Veriexec, the proposed solution is specialized toprotect the kernel from modifications by dynamically loaded modules. In this researcha comparable database and fingerprints are used, but in contrary to the NetBSD kernel,the obsolete lkm (loadable kernel modules) architecture is not used.King et al. [242] have classified three kinds of malicious services supported by vir-tual machine based rootkits (VMBR): Services not interacting with the target system(spam relays, DDoS zombies, phishing web servers), services observing data or events(keystrokes, network packets) using virtual machine introspection and services delib-erately modifying the execution of the target system. They successfully implementedall of these types combined with a countermeasure against the redpill virtual machinedetection mechanism through emulating an instruction, which is used to determine adifference between a real and a virtualized processor\u2019s interrupt descriptor table. Theintrusion detection approach from this research cannot defend an attacked system oncea VMBR is installed, nevertheless the proposed secure level mechanism is powerfulenough to protect an endangered system from a VMBR installation by locking e.g.shutdown scripts used for Subvirt installation by King et al.Garfinkel and Rosenblum [243] have described a virtual machine introspection basedon an architecture that leverages the isolation, inspection and interposition propertiesof VMMs. Virtual machine introspection (VMI) describes a family of techniques thatenables a VM service to understand and modify states and events within the guest.Beside this passive monitoring technique, active monitoring of virtual machine-basedIDSes has been implemented as well [244]. Although they are facing the gap betweenthe VMM\u2019s view of data/events and the guest software\u2019s view (which is called semanticgap), their modifications of the guest operating systems are detectable.37https://www.netbsd.org/docs/guide/en/chap-veriexec.html2196 Secure Cloud SystemsCloudAV [245] is a software stack developed by Oberheide et al. It is meant tocounter the problems single anti-virus solutions face nowadays with the increase ofdifferent malware and new exploit techniques. Instead of having just one AV solutionper host, CloudAV uses multiple, heterogeneous detection engines. This approach iscalled \u2019N-version protection\u2019.The Automatic Malware Signature Discovery System (AMSDS) [246] has been de-veloped by Yan and Wu. The fact that increasing numbers of zero-day malware takemore and more time to analyze and the need to write signatures for them indicatesthat it is necessary to provide automatic signature generators. Moreover, the increasingsize of signature databases and analysis techniques increase the processor and memoryfootprint on computers with installed anti-virus solutions. This can be countered byanti-virus software as a Cloud service, putting the workload of analysis and signaturemaintenance on dedicated machines. AMSDS has a small detection engine with a re-duced signature set. This set of signatures can match a great share of malicious softwarethrough special treatment and preprocessing of the binary. Only if the much smallerAMSDS signatures cannot detect a suspicious file, it is send to the Cloud anti-virusservice for scanning with traditional anti-virus solutions. The automatic signaturegeneration is very effective and space saving compared to classic signature generation.But these signatures can only detect binary executables loaded either from disk ornetwork. An already running binary such as a service infected through an exploit isnot covered by this approach.Laureano et al. [247] have implemented some kernel introspection mechanismsinto User-Mode-Linux. The authors gather information about the running system byinspecting the flow of the system calls made. Their IDS runs in two different modes:a mode for learning the regular behavior of a system and a so called monitor modewhere anything unusual generates an alarm and suspicious processes are denied accessto specific system calls. A similar system could easily be implemented within theframework presented here. Furthermore, in the proposed approach access to systemcall parameters is granted, enabling a more fine grained behavior analysis, whiletheir approach just reports the system calls. Ignoring the parameters might lead tosignificantly more false alarms, since it can make a huge difference wether an opensystem call accesses a password file or just a new temporary file.6.3.4 DesignIn the sequel, the proposed solution to the problems stated above is presented. Theproposal is based on the standard assumptions made in most other virtualizationsecurity architectures [243], [244]. The hypervisor is part of the trusted computing base(TSB). Since the focus is on infrastructural security, it is not dealt with attacks againstthe Virtual Machine Monitor.Malware DetectionContrary to a classic anti-virus setup, a Cloud specific design of a malware detectionengine should run in a distributed manner and display some special requirements toensure the security of the service provider\u2019s infrastructure as well as the customer\u2019ssecurity. The communication paths and different software modules of the proposeddesign are shown in Figure 6.9. Any program run by the user (1) is executed in a virtual2206.3 Hardening Server Systemsmachine in the Cloud. The kernel of this machine then passes all relevant informationto a KernelAgent (2). The KernelAgent gathers all information by the virtual machinesrunning on the Cloud resource and then relays them to the ScanProxy (3). The ScanProxyprovides a front-end to the Cloud security analyzer services. At this stage, the proxyhas to distribute the information to the different services, such as classic anti-virussoftware or behavior-based analysis solutions (4).Service ResourceScan ProxyBackend nBackend 2Backend 1(e.g. ClamAV) 4Cloud Resource nVirtual Machine nKernelVirtual Machine 2KernelVirtual Machine 1KernelCloud Resource 2Virtual Machine nKernelVirtual Machine 2KernelVirtual Machine 1KernelCloud Resource 1Kernel AgentVirtual Machine nKernelVirtual Machine 2KernelVirtual Machine 1Kernel213UserFigure 6.9: Malware scanner architectureThe kernel module is the primary sensor sitting directly in the running virtualizedkernel of the guest machine. To avoid any security issues through the kernel module,it has very limited functionality. Its main task is to function as a logging relay and tosubmit any interesting activities to the KernelAgent for further processing. Valuableinformation include process creation or termination, system calls by these processes andthe system call parameters as well as any binary files getting executed. This approachmakes it very easy for the Cloud provider to maintain the system. The only componentthat has to be changed is the kernel. Thereafter, all operating system (OS) images thatare provided by the customers can be booted using the modified kernel. Contrary toclassic anti-virus solutions, no installation within the OS image is necessary, whichmeans the additional security provided by the OS is completely transparent to thecustomer. Moreover, the customer has full control over his or her OS image. No matterwhat the customer does with the image, (s)he cannot break or deactivate the malware2216 Secure Cloud Systemsdetection system.The kernel modules should intercept any executable before it is running and submitit to its host agent. This is the way classic anti-virus hooks grab an executable beforeloading it into their scan engine. They check every executable through static analysis.Applying static binary analysis might not always be the best way to ensure security,especially when confronted with unknown, new malware. Nevertheless, it still shouldbe part of any malware detection solution. Using this approach, it is easy to takeadvantage of all the existing anti-virus software. A requirement for any executableanalysis is the binary image of the file itself, and for identification purposes, thefilename must also be transmitted.Process Life Cycle, System Calls Monitoring a process with respect to its systemcalls throughout its lifecycle can be a valuable source of information when lookingfor common patterns in malware behavior. By relaying this information live, not onlyencrypted executable images and obfuscation, but also in-memory injected malwarethrough an exploit can be analyzed. System calls make it easy to spot specific fileaccesses or socket operations, such as transmitting data back to an attacker. Therelevant information includes the system call, its parameters, return values and theprogram that made the call.KernelAgent This part collects all the data from the VM kernels running on the hostsystem. This information should then be relayed to the ScanProxy. Since there is noother logic involved in this piece of software other than the configuration of whathas to be sent to whom, there is almost no need to touch an installed system. Toincrease the performance, caching of messages and later on responses is implemented.This is especially interesting for classical executable image analysis. While starting-upseveral virtual machines, the same executable is run several times. These often calledbinaries include e.g. system services. Submitting and analyzing the executable at everyinitiation/run costs CPU time and also increases network traffic. This can slow downthe start-up time in a feedback based intrusion prevention system significantly.Since both groups of information (binary and system call related) have differentrequirements, splitting up the KernelAgent into two separate servers makes sense. One isa UDP-based system call forwarder, the other one should receive binaries and forwardthem. The binary executable relay must not save any executables to the hard disk.Otherwise, there is a chance of an infection happening on the host system in case ofmalware.ScanProxy This component gathers all available information from the hosts anddistributes it among the registered scan engines. For each incoming packet containing asystem call, one or more receiving scan engines can be used. The proxy then forwardsthe packet to the registered receivers. It could also act as a global log and cachingproxy for the complete Cloud. Every new scan engine being a system call analyzeror a classical anti-virus scanner can be enlisted here once or even several times forredundancy purposes. The proxy does not need to have much more logic than theabove to keep the system as easy to manage and immunized as much as possible. Morecode complexity means more space for failure through attacks.2226.3 Hardening Server SystemsScan Engine and Executable Analysis Considering the previously described frame-work, several possible scanning backends can be implemented. They can generally becategorized as process behavior based or executable binary based, such as a classicalanti-virus solution, e.g. ClamAV38. Every incoming executable has to be placed in aseparate container on the hard disk and then has to be analyzed. The received binariesmust not be executed, otherwise the security of the scanning computer can be com-promised in case of an infection. By registering several different anti-virus scannerswith wrappers, an increased level of security can be achieved. This helps to minimizethe vulnerability window that exists between the discovery of a new malware and therelease of the signatures by the anti-virus vendors for their products. To process eventssuch as systems calls, a backend like the software of Wagener et al. [248] can be usedwith minor modifications. The underlying concept of their approach is that even newmalware shares common behavioral similarities to already existing malware. By findingthese similarities in behavior graphs, even yet unknown malware can be automaticallydetected. While Wagener et al. perform system call analysis ahead-of-time in a secureexecution environment, modifications should easily be possible to enable on-the-flydetection.Kernel Rootkit PreventionInstead of disabling kernel module loading completely, the BSD secure level conceptis favored. It allows module loading before raising the secure level. The followingsubsection describes the process of kernel rootkit prevention by loading authorizedkernel modules only. It is distinguished between two modes, describing the state ofthe secure level. If the secure level is lower or equal than 0 (which is the default forsingle user mode), it is called insecure mode; if the secure level is set to 1 or higher(kernel memory is read-only, file system might be read only), it is called secure mode.Furthermore, adding a module to the internal list is called mark/unmark as authorized.To prevent kernel rootkits, it is distinguished between safe and unsafe kernel modules.In secure mode, it is only possible to (un-)load authorized kernel modules. It is notpossible to load other modules, especially any kind of malware. All authorized modulesare kept in a list that resides in read-only kernel memory. The latter is needed to preventthat an attacker could simply modify the list to mask a rootkit as an authorized module.Each list entry contains the following information:\u2022 A human-readable description of the kernel module\u2022 A unique cryptographic hash of the kernel module\u2022 Some internal kernel structures to indicate whether the kernel module is currentlyloadedThe implementation uses a generated SHA256 hash to provide a unique key for eachmodule. To authorize kernel modules, a userland program has been developed to addor remove kernel modules to the mentioned list through a system call. This systemcall refuses execution if it is called without root privileges. Optionally, all dependentmodules could be added as well. Any operations on the list can only be made while thesystem is in insecure mode. A convenient moment would be the initial system setup38https://www.clamav.net/2236 Secure Cloud Systemsbefore it is actually connected to an external network. While the system is running ininsecure mode, the userland program is able to mark/unmark modules as authorized.The list, where the marks are stored, uses transient storage, i.e. the list is initially emptyat system start-up time.not loaded &not authorizednot loaded, but authorizedloaded, butnot authorizedloaded &authorizedmark as authorizedmark as not authorizedmark as not authorizedmark as loadedmark as not loadedmark as not loadedmark as loadedInsecure ModeSecure Modemark as authorizedFigure 6.10: Authorized module loading state transition diagramFigure 6.10 shows the possible modifications of a list entry. By default, a moduleis not loaded and not authorized. In insecure mode, a user can mark a module asauthorized and thus is able to load it later when the system is in secure mode. Allkernel modules that are loaded during the boot process (e.g. the ACPI subsystem ordevice drivers) are not authorized. Consequently, they have to be authorized beforethe system is switched to secure more. Otherwise, they would work as expected, butunloading would not be possible (which might not be necessary, especially if it is acore component). Once the system is in secure mode, only authorized kernel modulescan be loaded.The main features of this process are encapsulated in the dynamic module loadingprocess to check whether a module is marked as authorized or not. To authorize amodule, an authorization function has to open the module file, hash its content andsearch for matching hashes in the list. If the authorized-flag of the corresponding listentry is set, the module is allowed to be loaded. The unloading process is handledby another function that checks if the module is already loaded. Consequently, we donot have to hash the module again. Every loaded module is equipped with a uniquepointer, representing the module. This pointer is used to find the correct module inthe list and to decide whether to unload or not. Finally, unloaded modules must bemarked as not loaded in the list.2246.3 Hardening Server Systems6.3.5 ImplementationLike the operating system kernel (which in this case is the DragonFly BSD kernel,version 2.5.0), the kernel part of the malware detection module and all parts of kernelrootkit prevention and have been written in ANSI C.Malware DetectionTo tap into the relevant parts of the kernel, some static hooks are installed. These hooksredirect or copy valuable information from kernel functions such as execve to an extrafunction that passes this information on to the KernelAgent.Process Related Information Getting all process related information requires theaddition of several hooks to the VM kernel. A hook is installed in the function thatadds new processes to the kernel\u2019s process list and assigns a new PID to them. Thelist is a linked-list used to keep a global list of all running processes. Another hookthat is called at the end of a process lifetime works in a similar fashion. This routine iscalled by the kernel\u2019s exit1 function to remove a process from the global list of runningprocesses and add it to the list of dead processes. This list is an in-kernel linked-listcontaining all processes in the ZOMBIE state. This means that they are about to beremoved from memory and are done executing.The system call hook is called from within the VM\u2019s syscall2 function. It is executedimmediately after the processing of the real system call. Getting called after the exe-cution of the system call has the advantage that some parameters that are passed onempty to the kernel and are filled during execution can get their content inspected.This is, for example, the case with the open system call that has a buffer as its parameterfor reading bytes from a file descriptor.The challenging part here is getting the parameters. They are passed to the systemcall function without providing any type-information, except a memory reference. Forthe kernel, there is no need to know this type-information, since the correspondingsystem call knows what type its parameters should have. As part of this approach,an extra file holds a list of all system calls and their parameter types. Additionally,the error code as returned by the actual system call is provided for analysis purposes.This has the advantage that the data flow can be recorded, such as the returned filedescriptor from an open call and later on any read system calls to this file descriptor.Executable Loader The binary loader hook is placed in the kern execve function ofthe VM, which is the actual place of execution and not the system calls\u2019 first entrypoint, sys execve. To avoid unnecessary calls to the logging hook, it is only calledafter exec check permissions has successfully returned. After this call, it is certain thatthe executable is valid and has the appropriate permissions. The logging takes placebefore the first page of the executable gets mapped into the memory and is executed.In a feedback-based Intrusion detection system it would still be possible to stop theexecution at this stage, should the binary be infected with malware. The whole binaryis then submitted to the KernelAgent using TCP.Communication from the VM to the Host System To keep the protocol overhead assmall as possible and be as responsive as necessary, a simple protocol is implemented2256 Secure Cloud Systemsby using UDP in the kernel. Approaches based on TCP would have brought up someadditional delays, which is a problem when monitoring realtime events such as systemcalls.KernelAgent The KernelAgent\u2019s main task is to collect the data from all virtual kernelsrunning on the machine and forward it to its ScanProxy. This part is implementedusing the Python scripting language. Whenever a new packet is received, a backgroundthread is started to process the received packet. This implies that it is parsed and thenthe whole packet is sent forward to the configured ScanProxy.ScanProxy This software module is similar to the KernelAgent on the receiving partand is also written in Python. Instead of one configured receiver for relaying, like inthe KernelAgent, there is a list of receivers. This list can be configured for each entryto relay only specific types of traffic (e.g. only NEWPROC, ENDPROC and SYSCALL) or anytraffic for a catchall or logging daemon. Due to this fine grained configurability, theincoming packets must be inspected and checked against the list of receivers to ensurethat every receiver obtains only events that have been subscribed for.For scanning executable files with an anti-virus software such as ClamAV, a TCPvariant of the ScanProxy has also been written. Just as within the UDP ScanProxy, a listof receivers/backends can be configured. All incoming binaries are relayed to them.The ScanProxy only keeps the executable\u2019s data in memory, nothing gets written tothe hard disk. This backend checks incoming binary files with ClamAV for knownviruses. Incoming files are received over TCP connections to ensure that the receivedbinaries are complete and in-order. As in the KernelAgent and the ScanProxy the nameof the executable is also submitted. Every received binary is saved in a temporaryquarantine folder, where it is scanned. After scanning is done, the file gets deleted toensure security of the backend system.Kernel Rootkit PreventionAll main communication between userland tools and kernel is handled by a newlyintroduced system call, e.g. add a new module to the internal list is done by sendingthe required information via the defined interface. As mentioned before, the internallist has to hold any information about a module. For example, a module can just beauthorized, not loaded, or it can be loaded but not authorized. Therefore, our listcontains one entry per module. The state is held in flags or implicitly by pointers beingnot empty.Every generated list entry holds a unique key. In this implementation, the generatedSHA256 hash is used to provide a unique key for each module. The longer the resultinghash value is, the more secure is the corresponding algorithm regarding brute forceattacks. Thus, SHA-256 is a good tradeoff in terms of security as well as memory usageand performance.The identifier is used to hold the human readable description of that entry. A linker filepointer points to the corresponding linker file kernel structure. This is a convenientway to map a loaded module to the generated hash without doing changes inside theexisting kernel structures. To prevent the list from being changed while system is insecure state, the functions responsible for mark-and-authorize a module are not callable2266.3 Hardening Server Systemsin that case. After switching to secure mode, only authorized modules can be loaded orunloaded - there is no way to authorize kernel modules retroactively.Usually a userland tool is used to load modules during runtime. This utility directlyuses the system call kern kldload, which basically implements dynamic module loading.After a basic permission check, the main module loading, depending on the binaryformat, is performed. Those formats are compiled into the kernel and cannot be changeddynamically. The common format is the Executable and Linking Format (ELF). Each ofthe functions above verifies the secure level at first and interrupts loading immediatelyif the system runs in secure mode. Figure 6.11 shows a flowchart of the module loadingprocess (changes drawn in dashed lines).KernelLoad Module (Kernel)Secure ModeSecure ModeSelect FormatExtract pathLoad Module (Linker)Load Module FileyesModule authorized?Access denied yesnononoyesMark as LoadedUserlandLoad ModulenoyesFigure 6.11: Module loading activityThe first task to authorize a module is to open a virtual node, identified by the givenfilename. A virtual node is an entry in the virtual file system (VFS), which is an abstractlayer on top of the physical file systems. The function has to open the virtual nodealready in this early stage of the loading process. Later on, one could reuse the provided,convenient functions to read a file from kernel, but from the security perspective thiswould be too late. Thus, the more complex way through the VFS layer has to be taken.As a consequence, the virtual node, pointing on the module file, is opened twice duringthe loading process. As this is not a time-critical job, it is negligible. If the virtual nodeis opened without errors, the module is read. Otherwise, the function aborts with anerror message. Since the read bytes can be added to the hash algorithm successively, thememory usage by reading data piecewise using the same buffer each time is reduced.This data can be used to generate the hash key. If the internal list contains the generatedhash key, the module is marked as to be loaded, otherwise it is not and the appropriate2276 Secure Cloud Systems00.10.20.30.4Host VM VM Tracer0.2620.2550.029 0.0830.040.035Time (in seconds)Sys User(a) Comparing host, VMand modified VM (tracer)speed0 100 200 300Trials0.60.811.21.41.61.822.2Time (in seconds)(b) Overall time to intercept abinary, transfer it and scanit with ClamAV00.050.10.150.20.250.358KB 685KB 1.2MB 2.4MB0.2280.1110.0620.002Transfer timesTime in seconds(c) Transfer times for vari-ous binariesFigure 6.12: Malware Detection Benchmarkspermission denied error is returned.Authorizing a module within the unloading process is less complex, because theused data structures by the unload process contain a file pointer that is also registeredin the internal list if the module is loaded. If the module is authorized, it is unloaded.Otherwise, unloading is not permitted.6.3.6 Experimental EvaluationThis subsection focuses on the performance and a qualitative evaluation of the de-veloped prototype malware detection and kernel rootkit prevention system. All testswere performed on two 2.53 GHz Intel Core2Duo CPU, 4 GB MB RAM runningDragonFlyBSD 2.5 connected with Gigabit ethernet.Malware DetectionSince the main modifications to the VM kernel happened in the process and systemcall handling code, measuring performance impact is best done by spawning severalprocesses and by performing rapid system calls, thus data or process intensive tasksare not relevant for the benchmark. A test case that queries the kernel for network,user and other arbitrary information is executed 50 times, and the average run-time iscalculated. The results of the benchmark are presented in Figure 6.12a. The lower bars,named sys, indicate the time spent executing system calls on behalf of the executedprogram. The upper bars, named user, represent the time spent doing calculations,iterations or generally spoken actions in userland. The diagram clearly shows that thehost operating system easily outperforms the virtualized kernels. Even though the timespent executing system calls is nearly identical between host and the VM kernel, thetime spent in userland is much more compared to the time when running on the hostdirectly. Enabling the tracer functionality of the VM kernel doubles the time spent inthe kernel, but the userland portion stays constant. Since the in-kernel time for systemcalls is so low compared to the total execution time (0.06 seconds), this impact on theperformance can be neglected.Figure 6.12b shows the measured time needed to intercept a 8 KB binary in a runningVM with the KernelAgent, transfer it over the network and scan it with the ClamAVengine. Over 350 trials were conducted to get a robust mean, which is 0.5 seconds.The oscillation of the graph is due to the fact that we could only measure with a wall2286.3 Hardening Server Systems200 400 600 800 1000 1200 1400 1600 1800 2000Number of kernel modules5101520253035Time (in seconds)Insecure modeSecure modeDefault mode(a) Module loading200 400 600 800 1000 1200 1400 1600 1800 2000Number of kernel modules510152025Time (in seconds)Insecure modeSecure modeDefault mode(b) Module unloadingFigure 6.13: Module (un)loading overhead measurementclock, which in this case works with Unix timestamps (seconds since the epoch). Themeasured overhead of 0.5 seconds before the actual execution starts is negligible inthe described Cloud environment, since most jobs will be long running computationaljobs. Furthermore, the use of caching techniques will even reduce the overhead, asevery (unchanged) binary is only scanned once. Figure 6.12c shows the times neededto transfer various binaries of different sizes over the developed middleware betweenKernelAgent and the ScanProxy. Multiple measurements with different binary sizesrepresenting different types of malware (the average file size of the standard systembinaries is about 1.2 MB) were conducted. For binary 1 (58 KB), the average time is0.001 seconds, for binary 2 (685 KB), the average time is 0.06 seconds, for binary 3 (1.2MB), the average time is 0.1 seconds, and for the biggest binary (2.4 MB), the averagetime is 0.2 seconds. Thus, the transfer time increases with the size of the binary.Kernel Rootkit PreventionTo measure the module loading overhead, a script was written that cascades module(un-)loading. Since the main overhead is due to hashing the modules, a proper averagemodule size had to be chosen to get realistic results. By examining the standard kerneldirectory, 64 kByte turned out to be the average size of the kernel modules. In orderto be a bit ahead, 100 KB sized kernel modules were created for testing. To be able tomeasure the correct time overhead, the modules were loaded between 250 and 2000times.As shown in Figure 6.13a, there is an overhead in every measurement. The modulehashing causes the overhead during every module load. Loading modules either insecure or insecure mode (with enabled kernel protection) takes more time than loadingmodules in the default mode (no protection and a stock kernel). This is due to thefact that the kernel rootkit prevention technique has to iterate over the internal listto validate a module. Thus, there is an additional linear effort. Nevertheless, moduleloading is not a time critical job and the average number of loaded modules should bemuch lower than in the tests. In the case of 250 loaded modules in the generic kernel,a module needs 0.016 seconds on the average to get loaded. In a kernel with rootkitprevention it takes 0.02 seconds on the average. This is more than 1.25 times longer,but still is not a large delay. If the system is running in secure mode, loading a module2296 Secure Cloud Systemswill consume more time, because there is one additional list iteration involved in theloading process. Generic kernels are not even able to load modules during secure mode.The measured overhead for module unloading is shown in 6.13b. Contrary to theloading process, the unloading process is less time consuming. There is no noteworthytime difference regardless which kernel mode is used.6.3.7 ConclusionIn this section, an approach for combined malware detection and rootkit prevention inCloud Computing environments was presented. All running binaries are intercepted bya small, in-kernel agent and submitted to one or more backend units where the actualclassification process happens. Furthermore, live-scanning of all binary system calls isperformed to detect yet unknown exploits or malware. Due to the in-kernel nature ofthe agent, it is completely transparent to the user as well as to malicious binaries tryingto detect any countermeasures. The distributed architecture allows a good utilizationof existing Cloud resources and the connection of different analysis engines.While the detection rate of malware and anti-virus scanners has steadily improvedwithin the last years, its still not a fool-proof solution against recent exploits like zero-day exploits. Many successful attacks lead to the installation of a kernel rootkit to gainpermanent control over the target machine including the possibility to get access atlater times and misuse the machines as an attack platform. Consequently, the proposedsolution is a modification of the in-kernel loading process. Only authorized and thustrusted kernel modules are allowed to load during runtime. Loading of unauthorizedmodules is no longer possible.There are several issues of future work. For example, the malware detection enginecurrently implemented provides a solid foundation for a flexible Cloud specific anti-malware solution. In a second step, it would be desirable to change the software stackfrom just a detection engine to a bidirectional intrusion response engine capable ofisolating and terminating malware binaries in real-time. For the rootkit preventionsolution it would be desirable to bring asymmetric cryptography into the variousoperating system kernels to be able to use signatures instead of cryptographic hashes.Finally, the possibility to manage the in-kernel black- and whitelists (or a central signingkey) could be realized by a central instance in the Cloud Computing environment. Forthis purpose, various parts of proposed infrastructure could be reused to achieve thisgoal.2306.4 Reactive Realtime Cloud Infrastructure Monitoring6.4 Reactive Realtime Cloud Infrastructure Monitoring6.4.1 IntroductionIn recent years, the number of security attacks performed on computer systems con-nected to the Internet has increased significantly. Several security monitoring solutionssuch as Intrusion Detection/Prevention (IDS/IPS) and Security Information and EventManagment (SIEM) systems have been developed as a response to the rising number ofthreats. To work effectively, these systems heavily rely on meaningful log data generatedby different components involved in the setup. Automatically parsing these humanreadable logs costs considerable amounts of time given the verbosity of the informationcollected. Furthermore, the more complex an attack is, the harder it gets to detect itusing simple signature-based approaches, since they typically support only simplecount-based rules or simple regular expression matching rules for particular attacks.Supporting more complex rules, on the other hand, usually suffers from keeping upwith high event rates and processing them in real time.In this section, a new approach to detect, analyze and handle security anomalies ispresented. The anomalies include both known and yet unknown security vulnerabilitieswith a particular focus on systems based on operating system virtualization, such asInfrastructure-as-a-Service Cloud computing systems. Hence, a novel SIEM systemespecially for virtualized computing resources is proposed.The proposed approach utilizes sensors deployed on different layers of a virtualizedcomputer system. Layers range from the hypervisor, also called virtual machine (VM)monitor, and the operating system of the VM (kernel and userland) to any kind ofapplication runtime environment, such as a web-application container, to continuouslyreport all relevant events. The combination of out-of-VM monitoring using VM intro-spection [244] and in-VM monitoring opens up opportunities to eliminate false positivesthrough double bookkeeping.To facilitate horizontal and vertical correlation and aggregation of monitored events,Complex Event Processing (CEP) is used. Continuous queries on event streams performcross-layer monitoring of events to detect security anomalies. These queries can triggerdifferent actions in any of the virtualization layers to repel attacks or isolate breachedcomponents. Therefore, attacks can be stopped before they are successful, or furtherbreaching of a compromised VM is prevented.The core functionality resides in a hardened, trusted VM responsible for analyzingsensor data. All sensor data is sent to this VM for further processing, and actions aretriggered by this VM if necessary. To increase the speed with which events are processedby queries, queries are distributed across multiple, different CEP engines optimizedfor specific query operators. Furthermore, a global event log called Event Store ismaintained, gathering all events and providing the possibility for offline learning andwhat-if analysis. Analysis results produced offline from the Event Store can then be fedinto the online query rules.Thus, the proposed approach is designed to provide security monitoring in a box,meaning that every physical server hosting multiple virtual machines has a dedicatedvirtual machine (VM) responsible for performing all tasks required for monitoringthis server. Therefore, monitoring a very large number of physical servers is possible,since each additional physical server gets an additional dedicated VM for security2316 Secure Cloud Systemsmonitoring. The particular focus of this design is on systems based on operating systemvirtualization, such as Infrastructure-as-a-Service Cloud computing systems. Hence, wepropose a novel SIEM system for virtualized computing resources.This research makes several contributions to advance the state-of-the-art:\u2022 A novel set of minimally intrusive sensors with a reduced attack surface enablinglive gathering of sensor data is presented.\u2022 A novel approach to optimize the performance of continuous queries by utilizinga federation of heterogenous CEP engines is presented.\u2022 A novel historical data store, optimized for fast event logging is presented. Itis designed for fast sequential writing and applies a bulk-loading technique foralmost no-cost index creation.\u2022 A novel query language for specifying complex monitoring rules compared toclassic IDS and SIEM solutions is presented.\u2022 A secure execution and deployment environment for sensor and action scripts ispresented.The research focuses explicitly and solely on the components of the infrastructurerequired for performing security monitoring and not on the improved security throughadvanced attack signatures or anomaly detecting queries. Some examples of queries todetect simple security incidents are presented in this work, but developing new attacksignatures or automatically generating queries based on past behavior are beyond thescope of this work.Parts of this section have been published in [14], [15].6.4.2 Related WorkCEP Engine. The main features of the CEP engine used in this system are that it is afederation of different CEP engines and that it utilizes a query index. While the former isused to optimize the performance of single queries, the latter is used to ensure scalabilitywith an increasing number of queries. Federations of data management systems arenot novel. Federal database systems [249] have been intensively studied in the past.However, the main focus of federated database systems is the integration of distributedand potentially heterogeneous databases and not performance optimizations. Thesame is true for MaxStream [250], the only existing federal stream processing systemwe are aware of. MaxStream extends SAP MaxDB, a federation engine for databasemanagement systems (DBMS), by the ability to also integrate data stream processingsystems (DSMS) and has a strong emphasis on the cooperation between DBMSs andDSMSs. Performance optimizations among a federation of different DSMSs are notstudied by MaxStream. The cyclops platform [251] is similar to the approach used inthis work, but focuses on federations consisting of different classes of data managementsystems rather than on federations consisting of different implementations of the sametype of data management system. In particular, Cyclops optimizes the performanceof continuous aggregation queries among a federation consisting of a centralizedstream processing system, a distributed stream processing system and a distributedbatch processing system. Based on the definition of the window, one system classis superior to the others from a performance point of view. For instance, when thewindow is a window that slides from event to event, a centralized stream processing2326.4 Reactive Realtime Cloud Infrastructure Monitoringsystem performs best. When the window jumps with big distances, a distributed batchprocessing system performs best. Similar to the approach from this research, Cyclopsselects a target system class via a classifier that has been created on basis of performancebenchmarks. However, Cyclops focuses only on continuous aggregation queries that arean atomic unit and not on complex queries consisting of several operators that can bedistributed. The latter problem has been studied by StreamCloud [252]. StreamCloudpartitions operator graphs into arbitrary subgraphs and distributes the resulting partsacross a distributed streaming infrastructure. The partitioning is based on a simplebut effective strategy. For each stateful operator, an operator graph is cut. Therefore,costly stateful operators can be optimally distributed with respect to load balancing,utilization of the infrastructure and performance. All relatively cheap stateless operatorsare then automatically distributed together with their associated stateful operatorsin order to reduce communication overhead. However, StreamCloud focuses only oninfrastructures consisting of a single type of streaming system and not on heterogeneousfederations.Recently, the BE-tree [253] was introduced for indexing sets of queries. The BE-tree isa dynamic query index being superior to all competitors proposed so far (e.g., Gryphon[254], k-index [255]). Therefore, the BE-tree for the Analysis-VM of the system wasreimplemented. However, the system does not need a fully dynamic query indexsince index updates are very infrequent in comparison to the event rates. Therefore, abulk-loading technique for BE-trees was developed to perform several optimizations tofurther increase the performance of BE-trees.Sensor and Actor Frameworks. The foundation of every decision or rule-basedsystem are the sensors that deliver the data being used. There is a variety of datasources developed for different purposes such as alerts, performance monitoring andintrusion detection. Alert-based systems such as Nagios39 are organized in a host-and service-based manner, meaning that attributes of the host and running servicesare monitored by running specified commands and using specified polling values.Typical events reported are the information whether or not a service is vital and howthis information was determined, as plaintext printed to stdout. Countermeasuresare not part of the system, since the main purpose is the notification of responsibleadministrators. Performance monitoring frameworks such as Ganglia40, Munin41 andScout42 place agents on the hosts to be monitored. Sensors are scripts in any languagethe system supports, executed by these agents. In contrast to the polling-based approach,intrusion detection systems collect data continuously. Snort43, a network intrusiondetection system, collects network packets and uses regular expressions to detectmalicious activity or specific attack patterns. Ossec44, a host-based intrusion detectionsystem, performs log file analysis, file system monitoring, root-kit detection (Unix)and registry integrity checking (Windows). While data is being collected by agents,the analysis is performed by a central manager using regular expressions. Ossec usespre-shared keys for encryption and zlib for compression of the data sent via UDPand can trigger single commands at monitored sites or the server. Despite the fact39http://www.nagios.org/40http://ganglia.info/41http://munin-monitoring.org/42https://scoutapp.com/43https://snort.org/44http://www.ossec.net/2336 Secure Cloud Systemsthat one could have utilized all of the mentioned frameworks with little effort in theproposed reactive security monitoring system, the solution proposed here already offersminimally invasive sensors on all layers of a virtualized computer system collecting livedata and event-based data, secure communication optimized for fast transmission andsignature-based deployment and execution of actions. Forget et al. [256] have proposeda design for a client/server infrastructure for monitoring client machines in whichthey describe how sensors should be designed to be able to collect data for long-termanalysis. In contrast to this research approach, data is written to a data server before itis analyzed, but the general design principles of sensors, namely being independent,minimally invasive and running in a least privileged manner, are similar what is donein this work. DACSA [257] presented by Gionta et al. is a decoupled architecturefor cloud security analysis performing out-of-VM analysis without interfering withthe guest system. To achieve this goal, the authors create copy-on-write snapshots ofrunning VMs and analyze the memory of these snapshots using forensic methods andthe ClamAV Anti-Virus software. Through this technique, the overhead for analysiscan be reduced at the cost of not being able to analyze real-time data. Srinivasan et al.[258] have proposed a system for fine-grained out-of-VM process execution monitoringby moving the process to an analysis VM and redirecting kernel level operations backto the guest system using two techniques called out-grafting and split-execution. Inthis way, it is possible to use userland analysis tools such as strace to analyze processesfrom another guest system. While this is useful for malware analysis where the toolsfor inspection have to be hidden, the goal in this work is to prevent that any harm getsdone.Stream Data Stores. Storing streams is a great challenge due to their huge dataamounts and high data rates. In contrast this work, recent systems are either based onrelational database systems or distributed key-value stores. Golab et al. have proposeda data warehouse solution called DataDepot [259] to store streaming data. The authorsuse a two-tier approach: at first, data is simply written to disk (i.e., into log files).Afterwards, an ETL query transforms streaming data from the raw data sources into arelational representation and loads them into the data warehouse. Apart from theseraw tables, DataDepot supports derived tables constructed via SQL queries and datapartitioning. In contrast to this approach, DataDepot uses a relational database asits underlying storage and achieves a throughput of only about 10 MB/s. Tidalrace[260], the successor of DataDepot, pursues a distributed storage approach and reachesdata rates of up to 500.000 records per second, which still does not compete with thecentralized approach in this research. LogKV [261] utilizes distributed key-value stores toprocess event log files. The authors assume a scenario where many different log sources(machines) with different event formats are connected to LogKV. A central coordinatornode maintains the meta-information about the log sources and is responsible for thedistribution of the incoming data to a set of worker nodes in the same data center.Every worker node is divided into two components. TimeRangeKV represents the finalstorage layout and manages all data belonging to its dedicated temporal partition. Sincea single machine may be overwhelmed with the incoming event data, several IngestKVinstances of multiple worker nodes first ingest incoming events to support high datathroughput. Afterwards, IngestKV shuffles the log data to the desired worker node withthe dedicated TimeRangeKV instance for its time partition. In their experiments, theauthors achieved a throughput of 28MB/s log ingestion bandwidth per worker node2346.4 Reactive Realtime Cloud Infrastructure Monitoringconsisting of an Intel Xeon X5675 system with 96GB memory and a 7200rpm SAS drive,which are connected via a 1GB/s network. Deri et al. [262] have presented a lightweightand fast time series database based on the embedded BerkeleyDB. The authors storetime series as BLOBs to reduce the number of transactions, and therefore to increasedata throughput. Similar to this work, the authors use a LZ based compression libraryfor loss-less data compression. In contrast to this research, the authors assume allstreams of the same database to have the same equidistant time intervals. LogBase [263]is a distributed, write-optimized store with transaction support. It uses a log-structureddata base, and like HBase45, it uses super-nodes that are responsible for a group ofadjacent nodes. LogBase stores all data in a single unordered data log that is locatedon a distributed file system. The log approach has append-only semantics. This offerssequential write performance on disks. In contrast to this work, LogBase is designedas a general-purpose database, also applicable for media data like photos. Due to thefact that LogBase is based on Hadoop46, it is not able to keep up with the real-timedemands of a storage for event systems. The authors use an index similar to Blink-trees,augmented with compound keys (key, timestamp) to index the data in an in-memorymulti-version index. In the proposal of Wang et al. [264], LogBase acts as storage layerfor a lightweight indexing approach. Similar to this approach, the authors utilize theassumption that successive observational values are similar. Therefore, they index (min,max) intervals for each disk page within B+-trees and interval trees to speed up queryperformance. These (min, max) values cover a small amount of space compared to theraw data and therefore are assumed to be kept in memory.6.4.3 ArchitectureThe goal of the proposed reactive security monitoring system is to detect attacksbased on the analysis of sensor data. Therefore, it is crucial to gather as much sensordata as possible.Theoretically, every event that occurs in one of the different layers of avirtualized system can be an indicator for an anomaly: for example, established networkconnections, creation or termination of processes or even user or process activitiesbeyond regular working hours.The decision about what is a normal or unknown system behavior cannot be madeby the sensors of a monitored environment. Instead, a CEP engine is responsible forprocessing all the informations sent by the sensors and is then able to decide whatcan be viewed as normal system behavior. Through dynamic deployment of furthersensors, it is possible to eliminate false positives and verify findings.Collecting large amounts of data leads to challenges regarding the transport, theanalysis and the storage of sensor data. In addition, transitions from knowledge derivedfrom data considered as normal to detection rules and appropriate actions have to beconsidered.The architecture of the proposed system (Fig. 6.14) consists of a secure and trustedvirtual machine (called Analysis-VM) where the main analysis component is located,sensors that reside in every layer of the virtualized computer system and actors thatexecute actions. More design details for all components are given below.45http://hbase.apache.org/46http://hadoop.apache.org/2356 Secure Cloud SystemsVMHardwareApplication     ContainerAktorSensorSensorActorActorSensorAnalysis-VM (Trusted)ModelbaseMatchmaker(Input)Matchmaker(Output)AktionenAktionAktionAktionCEP EngineEPAEPAEPAEinf\u00fcgen/L\u00f6schenvon EPAsVMApplication    ContainerActorSensor AktorSensorHypervisorShared ressources (CPU, RAM etc.)SHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADSHIFT10 : 9SYNCBLUEONLYRGBF3F4SAFEAREAMONOAPTCOMBF1F2ADDRESSDEGAUSS POWERINPUTMANUELCONTRASTMANUELBRIGHTMANUELCHROMAMANUELPHASEMENUUPENTERDOWNPOWERSTANDBYOVER LOADDedicated ressourcesccFigure 6.14: Sensors, Analysis-VM and actorsSensor FrameworkSensors are deployed on every layer of the virtualized computer system. As shownin Figure 6.14, there are sensors in the hypervisor, guest userland, guest kernel andapplication containers. Apart from getting as much information as possible, this alsoenables one to compare and correlate information coming from different layers. Forexample, if an intruder is spoofing specific information for userland processes, onecan compare this information with information coming from the guest kernel or thehypervisor. Depending on their location, the sensors differ in their implementationdetails, but all of them are designed to be minimally invasive in terms of resourceconsumption and performance penalties. Sensors are deployed without any extraanalyzer functionality to keep the performance impact and additional attack surfaceintroduced through them as minimal as possible. Consequently, communication withthe Analysis-VM is crucial. Every sensor has two communication channels to interactwith the Analysis-VM: one channel for the transmission of sensor data and the otherchannel for control messages. Control messages are used to manage sensors and relyon a custom wire protocol for control messages. In addition, the control channel is usedto reconfigure a sensor if necessary (e.g., to reduce the amount of data being sent).Matchmaker Event Store EPA EPA Action Action CEP Engine Action Framework Analysis-VM Figure 6.15: Analysis-VM2366.4 Reactive Realtime Cloud Infrastructure MonitoringAnalysis-VMThe Analysis-VM is the central instance of the monitoring system where sensor datais analyzed using CEP technology. This implies that the Analysis-VM is the maintarget of potential attackers. A successful breach could be used to compromise anomalydetection and sent harmful actions to actors, e.g., to shutdown sensors and/or VMs.For this reason, several approaches to improve security and consistency of the systemhave been combined to harden the Analysis-VM. Inside the Analysis-VM, Grsecurity47,AppArmor48 and Aide49 are combined to get PaX address space protection50, role-basedaccess control, file system integrity checks, kernel auditing and executable protection. Inaddition, the Snort intrusion detection system is used to detect malicious network traffic.Furthermore, the host is configured to use SELinux51 protection for QEMU/KVM52processes.Figure 6.15 illustrates the different components responsible for event processing andtriggering of actions. All events produced by the sensors are managed by a central hubcalled the Matchmaker that forwards them to the CEP Engine and to the Event Store.The latter is used as a historical database to store all events gathered from all sensorsand can be used for what-if analysis or for machine learning to produce new rules.Since the number of events per second highly depends on the number of monitoredVMs and number of deployed sensors, high throughput optimization is mandatory forthis component. Live analysis is performed in the CEP Engine where different EventProcessing Agents (EPAs) run continous queries on the event streams to monitor theincoming sensor data. Queries are formulated in a simple but powerful language. Thereaction time of the entire system depends on the runtime of the used CEP engine andhow fast and how many EPAs it can handle. These EPAs can then trigger differentActions in the Action Framework that decides whether an action should run out-of-VMor should be submitted to any specific VM for execution.Action FrameworkActors are deployed on all layers of the virtualized computer system (see Figure6.14) to execute actions. They share the minimally invasive design principle andcommunication capabilities, but differ in their function. In contrast to sensors, actorsreceive cryptographically signed actions. Thus, they provide an execution envionmentand the capability to check signatures for their validity. The actions should be asflexible as possible to enable administrators to model any countermeasure required fora particular security intrusion.6.4.4 Example Anomaly DetectionThe general lifecycle of the monitoring system is depicted in Figure 6.16. In this figurethe blue loop represents the sense-detect-react-cycle and the yellow loop shows theautomatic rule generation process. To illustrate this new approach an example is given47https://grsecurity.net/48http://apparmor.net49http://aide.sourceforge.net/50http://pax.grsecurity.net51http://selinuxproject.org/52http://www.linux-kvm.org/2376 Secure Cloud SystemsVMHardwareHypervisorSVMASAASCEP EngineEPAEPAEPAActionsActionActionActionActionActionActionModel DBHist. DBIntruderattacksensor datasecurity alertactioncountermeasurerecord dataderive newmodelsnew rulesFigure 6.16: Monitoring lifecyclein this subsection. An anomaly in double-entry accounting of the hypervisor andoperating system layers port list is associated with a network based backdoor.TCP BackdoorIn this scenario, an attacker has successfully installed a backdoor in a monitoredvirtual machine. He/she hides his/her presence through a rootkit, a modification ofthe operating system and its userland interfaces. Even though the backdoor is listeningon an arbitrary TCP port, the process belonging to it and the listening socket are notlisted by the operating system userland tools.Sensors The scenario including the sensors and corresponding actions is shown inFigure 6.17. To detect the backdoor, at least two different sensors are involved: Onesensor is running within the virtual machine and utilizes standard tools such as netstatto check for any listening sockets. Since the backdoor is well hidden, this sensor willnot report the security breach.The other sensor is inspecting the network state of the virtual machine from thehypervisor level. Since this sensor is running outside of the guest operating system, itis not affected by the backdoor\u2019s hiding features. On this level, an event is generatedfor the detection of a newly opened port in the virtual machine.Analysis With the help of the Model Database and the Historical Database, queries canbe generated to recognize normal or regular behavior. Therefore, an alarm should betriggered when a new open port is detected. Furthermore, by comparing both listeningsocket sensors, inside and outside of the virtual machine, it can be concluded that thisreally is a security related anomaly. A regular service installed in the virtual machineshould not be hidden within the system. The conflicting sensors information is a clearsign of an attack.2386.4 Reactive Realtime Cloud Infrastructure MonitoringFigure 6.17: Example: TCP backdoor detection.Action As a result of this attack, actions should be taken to eliminate the threat asmuch as possible. One such action could be to block all communication from and tothe backdoor\u2019s port on the hypervisor level. This prevents the attacker of extractinginformation or further using the infected machine. Another step that should be taken isto isolate and possibly terminate the processes involved in the infection. For forensicspurposes, taking a snapshot of the virtual machine and generating a dump is anotherpossibility.6.4.5 Sensor FrameworkIn contrast to existing monitoring frameworks, the reactive security monitoring systemin this work incorporates sensors from different layers of a virtualized computer systemwith their own environments. Thus, sensors have to be written in different languagesusing specific libraries and programming idioms. An overview of the implementedsensors is shown in Table 6.6. To ensure that every sensor has a minimal memoryfootprint, is minimally invasive in terms of performance and can be implementedfast without having to know details about the Analysis-VM and the control messages,dedicated libraries and a framework for sensor execution were created. These librariesare accessible from C/C++, Python and Java to be useful on as many different layers aspossible.To ensure that the communication channel for event transmission between the sensorsand the Analysis-VM offers maximum throughput and robust transfer, we considereddifferent protocols and serialization formats.JMS and AMQP are message broker protocols that require a dedicated broker andoffer point-to-point and routed communication. While broker-oriented protocols havebeneficial attributes such as guaranteed message transmission through persistent queues2396 Secure Cloud SystemsTable 6.6: Number of implemented sensorsLayer QuantityHypervisor 12Guest Kernel 8Guest Userland 39Application Container 14and easy bootstrapping, they are not optimized for high throughput. No parameterconfiguration leading to a sufficient throughput required was found.In contrast to broker-oriented protocols, socket-oriented protocols offer higherthroughput. UDP offers a very high throughput at the cost of possible packet loss,while TCP provides high throughput with reliable transmission. Since every event cancontain information that might signal a security anomaly, TCP has been selected as thecommunication protocol for event transmission.Human readable serialization formats such as XML and JSON, as well as binarymarshalling algorithms such as MessagePack53 and Google Protocol Buffers54 wereconsidered. While human readability in general creates an environment that is easierto debug, it enlarges the attack surface and has an impact on performance. GoogleProtocol Buffers offer smaller messages with faster transition than human-readableformats, but require a definition in the Interface Description Language, which makesthem a suboptimal solution for dynamic adoption of sensors. MessagePack is also fast,but more flexible and dynamic, and thus the serialization format of choice. In addition,MessagePack offers libraries for different languages and was easier to port to the Linuxkernel.Furthermore, attributes related to the activity of sensors can be configured. In general,it is distinguished between sensors with a polling-based sending scheme and eventdriven sensors. While the latter obviously only send data when a specific event occurs,the sending rate of polling-based sensors can be configured. Thus, instead of relyingon operating system log files, data is directly queried and watched for specific eventsto occur. In addition, the initial configuration of sensors including specific white- andblacklists can be altered within our framework.Application ContainerIn today\u2019s production systems, enterprise applications run on application servers likeGlassfish or Tomcat. To be able to get detailed information about the servers andthe applications running on them, an environment for sensors written in Java wasdeveloped for this research. A dispatch sensor gets deployed and waits for directionsdelivered in the form of actions from the Analysis-VM. These actions contain names ofsensors to be deployed and the Process Identification (PID) of a Java process to attachthem to. Therefore, one can directly monitor the JVM of a given process. Using btrace55,one is also able to trace internals of a process, such as class loading, JDBC operations,53http://msgpack.org/54https://github.com/google/protobuf/55https://kenai.com/projects/btrace2406.4 Reactive Realtime Cloud Infrastructure Monitoringexceptions, webservices, file handling or URLs.UserlandThe userland is very broad, and thus there are many possible requirements for sen-sors. For this reason, the scripting language Python was adopted with its inherentprototyping qualities and several third-party packages. Moreover, a sensor developedin Python cannot easily compromise the security of the system since it is immuneto memory corruption attacks such as buffer overflows or double frees. Furthermore,sensors within the framework are signed and only executed with a valid signature.This prevents malicious changes or the deployment of untrusted sensors.As mentioned above, it is distinguished between event-driven sensors like a syslogsensor or a sensor that monitors specific files and folders, and polling-based sensorslike a sensor for firewall rules or open network connections. Sensors can be full Pythonprograms that make use of third-party packages or shell commands that are wrappedwithin the environment, making the creation of sensors an easy task without limitationsin functionality. Using our Python sensor framework, a new sensor can be developedby writing less than 10 lines of code, which makes writing sensors for custom inhouseapplication monitoring a simple task.KernelTo create a communication channel to the Analysis-VM that uses the protocol (TCP)and serialization format (MessagePack) chosen, a kernel module that uses the Linuxkernel\u2019s own socket library and a port of the MessagePack serializer to run in kernelspace had to be written.Sensors in this environment are written in C and trace specific system calls. Forvarious reasons, there is no interface to trace system calls within the kernel. Since nearlyevery Linux distribution offers debug symbols for their kernels, the sys call table addresscan be determined using the kallsyms header. The addresses within this table can bereplaced by the address of a decorator function that triggers an event before redirectingthe call to the original system call. Since specific regions of the kernel are protected,this would trigger a general protection fault that can be suppressed temporarily.HypervisorHypervisor sensors can be grouped into sensors that leverage the libraries libvirt56and libvmi57 and sensors that monitor the host operating system and QEMU/KVMprocesses. Since these libraries offer Python bindings, and monitoring the host operatingsystem and specific processes is comparable to userland sensors, it was decided to usethe Python sensor framework. Using high-level libraries for VM administration andintrospection offers support for different hypervisors such as Xen, QEMU and KVMwhile keeping the code for the actual sensors small. In this research QEMU/KVM wasused as hypervisor, because in QEMU/KVM virtual machines are processes that can beeasily monitored, and the QEMU Monitor Protocol (QMP) can be leveraged to query56http://libvirt.org/57http://libvmi.com/2416 Secure Cloud SystemsTable 6.7: Hardware specification of the host systemsHostCPU Intel Core i7-4771 CPU @ 3.50GHzRAM 32 GBNIC Intel I217-LM Gigabit LANHDD LVM Raid 1 Seagate Barracuda ST3000OS Ubuntu 14.04 LTSKernel 3.13.0.39-genericTable 6.8: Hardware specification of the guest systemsGuest VM Analysis-VMRAM 4 GB 8 GBKernel 3.13.0.24 3.13.0-44CPU 2 CoresNIC VirtIO macvtap VEPAHDD VirtIOOS Ubuntu 14.04 LTSinformation regarding virtual hardware. Furthermore, the QMP can be used withinactions to dump memory or alter a VM.Experimental EvaluationIn this subsection, the environment is described in which the system was evaluatedand the experiments that were performed to demonstrate that the system holds up tothe claims made above. The evaluation platform uses a Gigabit network on multiplehosts with similar hardware specifications as shown in Table 6.7.To produce realistic measurements, the guest system with the Analysis-VM wasseparated from the monitored guest system, both with similar specifications as listed inTable 6.8, and placed them on separate hosts.Sensor Resource Usage To measure sensor resource usage, 28 of the userland polling-based sensors were configured to send events without any limitation. These sensorsare encapsulated in a single process with one thread per sensor. During runtime, thisprocess has been monitored using ps for 10 minutes. The results of this experimentare based on calculating the mean values of the percentual usage of CPU and RAM.The results listed in Figure 6.18 show the mean value of the percentual usage as theabscissa and the metric (CPU and RAM) as the ordinate. With values ranging from 1.9to 2.6 percent leading to 2.2 percent mean CPU usage and 0.4 to 0.5 percent leadingto 0.49 percent mean RAM usage, sensor resource usage is quite low, especially whenconsidering the fact that the sensors had no limitations in their sending behavior.Sensor Impact on Other Processes In this experiment, it was investigated how theactivity of sensors affects other processes running under top load. For this purpose,2426.4 Reactive Realtime Cloud Infrastructure Monitoring00.511.522.5CPU MEMPercentual Usage Sensor Resource Usage Figure 6.18: Resource usage of sensors!\"##$ !\"%#$ !&##$ !&%#$ !'##$ !'%#$()$(#)$*+,-$!\"#$%&'#()&*+),-.%+/&0).%#.1&2-%)&'-34$&!\"#$%&'#()&Figure 6.19: Comparison of sensor activityaffecting total build timethe build time of Octave58 3.8.2 was measured without any sensor activity and twodifferent sending modes with the Posix tool time. The results in Figure 6.19 show allthree measurements with the build time in seconds as the ordinate and the differentsensor setups grouped by user, system and idle time as the abscissa. There is nearlyno impact between the different times resulting in a minimum total time of 2,776.02seconds when no sensor is active and a maximum total time of 2,905.15 seconds whensensors send data every second, yielding a negligible delay of 4.65 percent.6.4.6 Analysis-VMThis subsection presents the main components of the Analysis-VM, consisting of afederated CEP engine and a fast Event Store.Federated CEP EngineThe analysis of the event streams coming from the sensors is performed in real-timeusing CEP technology. The use of CEP distinguishes the system from other securitymonitoring systems that use tailor-made event correlation engines. CEP engines usuallyprovide powerful, declarative query languages, while tailor-made event correlationengines must often be configured via dedicated GUIs (e.g., web forms), configurationfiles or even imperative code. Using a declarative query language, complex queries areeasier to express and, most importantly, allow for query optimization. Furthermore, CEPquery languages not only allow developers to compose multiple queries to workflows,but also to express powerful queries, such as pattern matching queries, over eventsequences (including correlations among the events of a pattern). However, tailor-madeevent correlation engines typically offer very good performance characteristics. Thehypothesis is that general-purpose CEP engines can also provide very good performancein this specific application domain. In order to shed light on this hypothesis, theperformance of the security monitoring system implemented with CEP technologyinside was investigated.In the Analysis-VM, not a single CEP engine is used alone, but a federation ofheterogenous CEP engines to exploit synergies between them with respect to function-ality, expressiveness, and performance. Therefore, a federation of four different CEPengines allows one to execute a query or part of a query in the CEP engine that is most58https://www.gnu.org/software/octave/2436 Secure Cloud Systemssuitable or performs best. In general, the federated CEP engine executes a query with asignificantly better performance than a single CEP engine.A serious issue with today\u2019s CEP engines is that there are absolutely no standards.Each individual CEP engine has its own query language in terms of syntax and, morecritically, in terms of semantics. Since in this work a federated CEP engine is used thatincorporates multiple heterogenous CEP engines, an own query language had to bedeveloped on top. All detection rules of the system are specified as queries in thisquery language that is based on SQL; Listing 6.1 gives an impression of the developedquery language. Then, a query compiler translates every query into an abstract operatorgraph (i.e., an event processing network (EPN)). Each operator is identical to a basicevent processing agent (EPA) that is supported. Currently, EPAs for event filtering,event aggregation, event correlation and event pattern matching are supported. Forexecution, another compiler translates each single EPA into the different native querylanguages of the CEP engines within the federation, while the query semantics arepreserved. This approach is similar to application virtual machines such as the JVM orthe CLR. Here, a program is compiled into platform-independent byte code. To executea program on a specific platform, another compilation process translates the byte codeinto native code specifically for the given platform.Before the abstract operator plan of a query is decomposed into sub-plans that arethen distributed across the CEP engines of the federation, it is transformed by a queryoptimizer into a semantically equivalent but more efficient abstract operator plan.With respect to the supported types of EPAs, the rule-based query optimizer adoptswell-known and powerful techniques from query compilers of database systems. Inparticular, filter EPAs are pushed down as close as possible to the event sources anda sub-graph consisting of multiple correlation EPAs (i.e., a multiway-correlation) isexchanged for a sub-graph containing the correlation EPAs in an optimal orderingaccording to a cost model.Federation Manager After a new query has been successfully rewritten by the queryoptimizer, its abstract operator plan must be mapped to the federation of CEP engines.Conceptually, there are three different and concurrent optimization targets that deter-mine an optimal mapping. First, the abstract operator plan should be distributed in away such that the load is balanced. Otherwise, a CEP engine of the federation mightget overloaded and become the bottleneck of the federation. Second, disjoint sub-plansof the abstract operator plan should be created and deployed so that every single EPAis executed by the best suited CEP engine of the federation from a performance pointof view. Otherwise, an EPA of the query might be executed sub-optimally and becomea bottleneck of the query. Third, sub-plans should be as large as possible. Otherwise,the communication overhead between the CEP engines becomes too high and decreasesthe overall performance of the system.In the proposed system, a so-called federation manager automatically decomposesabstract operator plans and deploys the resulting sub-plans to different CEP engines.Of course, it respects the three concurrent optimization targets and tries to always finda good compromise between them. Since load balancing is a problem that has beensolved in different environments, existing techniques were adopted to solve it in thiscontext in an appropriate manner. However, the distribution of an operator plan acrossa federation of heterogeneous CEP engines is a novel problem requiring an adequate2446.4 Reactive Realtime Cloud Infrastructure Monitoringsolution. First, the individual strengths and weaknesses of each CEP engine of thefederation had to be figured out. Therefore, comprehensive benchmarks (more than200 individual benchmarks in total) had to be done to reveal this information. Eachindividual benchmark executed a certain type of EPA having a specific configuration ofits parameters in all available CEP engines. For many of the benchmarks, the differentCEP engines performed quite differently. Then the results of all benchmarks weremanually evaluated and a classifier in the form of a decision tree was developed. Thisclassifier gets an EPA and its parameter configuration as its input and returns the CEPengine that is expected to perform best. The federation manager uses the classifier toassign each EPA of an abstract operator plan individually to a CEP engine. Whenevermultiple EPAs of the abstract operator plan that are directly connected with each otherare assigned to the same CEP engine, they are clustered into a sub-plan. Finally, theresulting sub-plans can be deployed to their assigned CEP engines. Each CEP enginethen executes autonomously all of its sub-plans. The federation manager as the masterCEP engine is in charge of forwarding every incoming event to all CEP engines of thefederation that execute at least one sub-plan that needs the event. All communicationbetween the CEP engines of the federation (i.e., sending the output event of one sub-plan to a following sup-plan being executed in another CEP engine) is also done viathe federation manager.Query Index One of the CEP engines of the federation has been developed newly forthis research and only supports event filtering (i.e., filter EPAs). Since the monitoringsystem must be able to execute workloads consisting of thousands of queries, anindex for the queries is necessary in order to achieve sufficiently high performance.Unfortunately, most CEP engines do not include a query index, and the CEP enginesthat have a query index have unsatisfactory performance with respect to our targetworkload. Therefore, an own query index in the form of an additional CEP engine isprovided.The developed query index called BE+-tree is based on the BE-tree [253], the state-of-the-art query index. However, the BE-tree is a general-purpose query index that canbe used in a variety of application domains including e-commerce, publish/subscribeand approximate string matching. The BE-tree achieves this wide applicability bysupporting both fast index lookups and fast index updates (i.e., insertion of newqueries) at the same time. In particular, the BE-tree is a dynamic tree-based indexstructure that handles insertions of new queries at runtime by local reorganizationthat is limited to only one path of the tree data structure. However, in the targetedapplications, insertions of new queries occur with very low frequency compared to thefrequency of new events.Therefore, a new functionality was added to the BE-tree that creates a tree fromscratch for a given query set. This gives two important advantages. First, a prioriknowledge about the queries can be exploited to build better trees in comparison to theone-by-one design of the original BE-tree. The many optimizations performed by theBE+-tree are beyond the scope of this work. Second, the overall creation time of theBE+-tree is substantially lower than for the BE-tree. Due to the fast creation time of theBE+-tree, one can build an entirely new BE+-tree on updates even for large query setsvery fast.2456 Secure Cloud SystemsExperimental Evaluation The Analysis-VM is supposed to support the executionof huge query workloads with high performance. Due to the used query index, thefederated CEP engine scales well with the total number of running queries, anddue to the federation manager that optimizes the performance across a federation ofheterogenous CEP engines, every single query is executed with high event throughputand low latency. The following experimental evaluation indicates that the federatedCEP engine in conjunction with a query index can master the challenging workloads ofthe security monitoring system.SELECT \u2217FROM (SELECT COUNT(\u2217) AS newConsFROM OpenConnections WINDOW(TIME 5 SECONDS)WHERE port=x AND vm=y)MATCH RECOGNIZE (PATTERN abcWITHIN 10 SECONDSDEFINE a AS newCons > z \u2217 1.5b AS newCons > a.newConsc AS newCons > b.newCons)Listing 6.1: Parametrized query of our workloadListing 6.1 shows a typical anomaly detection query with parameters x, y and z ofthe query workload. It is used to detect attacks against services running on a server.The stream OpenConnections contains one event for each open connection to a VM onthe server. Within each VM, a sensor periodically obtains all currently open connectionsand pushes one event for each open connection into OpenConnections. Each eventcomprises the name of the service, the identification of its process, the user it belongsto, the protocol of the connection, the identification of the VM (vm) on that the serviceis running, the port on which the service is running (port) and the IP address of theremote destination of the connection. The presented query is specifically for a serviceon port x at VM y. For the selected service, it counts the open connections within asliding time window of size five seconds. On the output stream of the aggregation,the query searches for a pattern that indicates an abnormal use of the service (e.g.,denial of service attack, brute force attack). However, the meaning of normal differsfrom service to service and, thus, is individual for every single service. The listedquery uses the popularity of a service as its normal behavior z. Popularity is simplymeasured in the usual form of the total number of new connections within a timewindow of size five seconds. Obviously, different services have different popularities(e.g., an SSH server has significantly less new connections within a fixed time framethan a web server running a web site). Therefore, there is exactly one query runningfor each active service. The corresponding normal value z for an active service (x, y)can be easily determined by analyzing its history recorded by the Event Store (see thenext subsection for details).To evaluate the performance of the federated CEP engine, the number of activeservices was varied so that one could arbitrarily increase the total number of runningqueries. The events that the sensors emitted matched a running query with a probabilityof one percent. Figure 6.20 shows the overall performance of the federated CEP enginefor 10,000 up to 80,000 monitored services and, thus, running queries. Note that eachsingle query consisted of three EPAs in total (one filter EPA, one aggregation EPAand one pattern matching EPA) so that the total number of running EPAs is three2466.4 Reactive Realtime Cloud Infrastructure Monitoring500000052000005400000560000058000006000000620000064000006600000680000010000 20000 30000 40000 50000 60000 70000 80000Events per Second Total Number of Running Queries BE+-TreeBE-TreeFigure 6.20: Performance of the federated CEP engine with a query index0100002000030000400005000060000700008000010000 20000 30000 40000 50000 60000 70000 80000Index Creation Time in Milliseconds Total Number of Running Queries BE+-TreeBE-TreeFigure 6.21: Query index creation timetimes as much as the number of running queries. The figure shows that the federatedCEP engine can handle more than 500,000 events per second in every case. Thanks tothe query index, the performance scaled well with the number of running queries. Ifthe number of running queries is increased, the performance decreases only slightly.Despite the fact that the filter expressions of the queries were quite simple, the BE+-tree still performed notably better than the BE-tree. For more complex queries, theperformance improvements of the BE+-tree compared to the original BE-tree can bemultiple factors. Figure 6.21 shows the creation times needed to create the queryindexes of the last experiment from scratch. The graphs illustrate the better creationperformance of the bulk loading implemented by the BE+-tree in comparison to thequery-by-query loading of the BE-tree. Even the creation of an index for huge queryworkloads of size 80,000 required only about one second in case of the BE+-tree, whilethe creation of the BE-tree needed more than one minute. Due to its fast recreationon occasional updates of the query workload and its better overall performance, theBE+-tree is prefered over the BE-tree in the Analysis-VM.2476 Secure Cloud SystemsEvent StoreApart from the real-time analysis of events, the Analysis-VM also supports offlineanalysis of historical data. Therefore, it is necessary to store all incoming events fora certain period of time (i.e., long-term storage). Due to the high data rates, existingstorage solutions do not meet the requirements that are imposed on a data store for CEPsystems. Traditional relational databases incur high transactional overhead, resultingin poor insertion performance. Key-value stores such as Cassandra59 typically cannotkeep up with the high data rates of CEP systems. The historical data store called EventStore is optimized for storing event stream data on a single machine, since it resides inthe hardened Analysis-VM.Design Principles The goal of the Event Store is to keep up with the event rates ofthe system while offering a reasonable (offline) query performance. For security andmonetary reasons, the decision was made to use local hard drives as the primarystorage medium. Thus, the Event Store is designed for sequential writing, aimed atstoring millions of events per second.The most common queries that need to be supported are time travel queries andtemporal aggregation queries. Time travel queries allow requests for specific points andranges in time, e.g., all ssh login attempts within the last hour. Temporal aggregationqueries give a comprehensive overview of the data, e.g., the average number of ssh loginsfor each day of the week during the last three months.The fastest way to store data on a disk is logging, i.e., to store each incoming eventconsecutively on disk and hence leverage its sequential write performance. The majordrawback of this approach is its obviously poor query performance due to the lack ofindexes. The opposite extreme would be to index each attribute of each stream in amulti-dimensional index, resulting in very poor insertion rates but very good queryperformance. The aim is to combine both: while high write performance is the mainfocus, the best possible query performance should also be supported.Main Components The Event Store can be logically separated into three components:store, event queues and workers. The store is the central component, handling streamregistration and event insertion. It keeps one event queue per stream, required fordecoupling event queues from workers. Each worker resides in a dedicated thread andis assigned to a physical storage device (i.e., a hard drive). A worker\u2019s task is to processevents of one or multiple dedicated event stream queues.Figure 6.22 shows an example of a logical processing graph for 7 streams, 3 workersand 2 disks. The distribution of streams to workers and the assignment of workers todisks depends on the characteristics of the registered streams. The main objectives are(a) to optimally parallelize serialization and compression (worker distribution) and (b)to fully utilize disk speed (disk assignment).Storage Layout Based on the awareness of the importance of the time dimension forquery execution, it was figured out that the problem of storing incoming events in anindexed fashion on disks can be solved by an efficient bulk-loading strategy for B+-trees.The key attribute for the index is represented by the timestamps of events. Since events59http://cassandra.apache.org/2486.4 Reactive Realtime Cloud Infrastructure MonitoringEvent Queue Event Queue Event Queue Event Queue Event Queue Event Queue Event Queue Store Worker Worker Worker Disk Disk Figure 6.22: Example of an Event Store topologyarrive from the Analysis-VM in temporal order, a sort-based build approach was used.It is also possible to tolerate out-of order arrival within a certain tolerance, but thiswould require an explicit sorting step before writing the events into the Event Store.For primary indexing, an augmented B+-tree is used. It is built in a bottom-upmanner and avoids the traversal of the tree\u2018s right flank for each event. When a leafnode is filled, its corresponding index entry is inserted into the parent level. Therefore,one only has to access the parent node once per child node, which also applies to allhigher levels of the tree. Due to the fact that one can hold the right flank in memory(only logbN buffer blocks for N events and block size b needed), primary index creationis very fast.To further improve write performance, the Event Store leverages data compressiontechniques. LZ460, an LZ-based, loss-less compression library, is used due to its fastcompression speed. In terms of compression, the optimal physical storage layout wouldbe a column layout. Unfortunately, a column layout leads to non-sequential I/Os, andthus causes a substantial performance loss. Thus, the storage layout is optimized forbetter compression rates using a hybrid approach [265]. The main idea is to store therelational events in a column-based fashion only within a single disk block.Query Processing To speed up query performance, another characteristic of eventdata is utilized. As observed by Wang et al. [264], it can be assumed that valuesoccurring within a small time interval are often very similar. This observation canbe leveraged to speed up queries. For every node in the B+-tree, the minimum andmaximum (minai ,maxai ) value of each (selected) attribute ai is stored for light-weightsecondary indexing. Since the number of attributes i is negligible compared to thenumber of entries stored in a single node, the performance impact is minimal. Duringquery processing, one can use these values for pruning. Additionally to the minimumand maximum values, each node stores the count of all underlying entries as well asthe sum of each attribute, which allows it to answer aggregation queries very fast inlogarithmic time.For full secondary indexing, a write-optimized indexing technique is used, namelycache-oblivious look-ahead arrays (COLA) [266]. Since full secondary indexing is costlycompared to the primary index, indexes are only created partially if the system load issufficiently low.60https://code.google.com/p/lz4/2496 Secure Cloud SystemsExperimental Evaluation To measure the write performance of the Event Store, twometrics are used: the number of events stored per second and the (gross) data rate whilestoring on disk. Additionally, the net data rate is used due to its physical limitationwhile writing on disk. Another limiting factor is CPU performance. As the EventStore has been implemented in Java, data serialization is a major performance issue.Furthermore, data compression also requires CPU time.The goal is to leverage the maximum net data rate (i.e., disk rate) with even highergross data rate (i.e., good compression ratios). For the experiments, events consisting of10 attributes of 8 byte each (80 bytes per event) were used.110100100010000CompressionPerformanceSerializationPerformanceCombinedPerformanceDisk SpeedMB/s Figure 6.23: Evaluation of system performance factorsIn the first experiment (see Figure 6.23; note the log scale), the key performancefactors in the Event Store (and Java) were evaluated. The results indicate that themaximum possible gross data rate for 8 KB blocks with compression (but withoutserialization) is about 2818 MB/s, which is far beyond the disk speed of 187.4 MB/s.The main bottleneck of the Event Store is the serialization process, which is due to theJava type system. Serialization of event data results in 461 MB/s (net=gross) data rate.Overall, the total gross data rate of the Event Store is about 201 MB/s, resulting in a netdata rate of 88 MB/s. Although the Event Store is CPU-bound for a single stream, itsgross data rate already surpasses the sequential write speed of the disk (187.4 MB/s)and reaches 2.64 million events per second. Note that the net data rate is about 47 % ofthe available disk speed.In the second experiment shown in Figure 6.24, the write performance of two (parallel)streams, on separate workers but on the same disk, were evaluated since the resultsof the first experiment suggest higher possible data rates. If one increases the numberof streams and therefore the degree of parallelization, compression can improve thegross data rate significantly, reaching 186 % of the physical disk speed (4.56 millionevents per second). Even two streams do not suffice to utilize full disk speed, since theconfiguration is still CPU-bound.The third experiment evaluated the maximum reachable gross data rate for more2506.4 Reactive Realtime Cloud Infrastructure Monitoring050100150200250300350400Single Stream Two Streams Disk SpeedMB/s Gross NetFigure 6.24: Comparison of net and gross data ratesthan two parallel streams. The Analysis-VM was extended to 8 cores and processedeach stream on a separate worker thread. In this scenario, it is assumed that at least 4physical disks are installed. Since the test system offered only one disk, the final writecommand to physical storage was omitted. Figure 6.25 shows the measured number ofevents per second. With 8 parallel streams, a gross data rate of 768.6 MB/s and 9.05million events per second is reached.For query evaluation purposes, the relation scan performance (Q1), the time travelperformance (Q2) as well as the temporal aggregation performance (Q3) was measuredon a data set with 20 million events (with 80 bytes per event). For the time travel andtemporal aggregation performance, a continuous fraction containing 20 % of the data,i.e., 4 million events,was queried and its query time was measured.Figure 6.26 shows the results of the query evaluation (note the log scale). An entirerelation scan of the stream (Q1) takes about 7.1 seconds, reaching a gross data rate of213 MB/s. The time travel query (Q2) using the index takes only about 1.3 seconds, lessthan a fifth of a relation scan. Finally, the temporal aggregation query (Q3) of the samepartition as in Q2 only takes 5 milliseconds.6.4.7 Action FrameworkThe proposed reactive security monitoring system can not only observe security intru-sions and malicious behavior, but also trigger countermeasures to prevent an attack orfurther system breaches. For this purpose, an action framework, as described below,was developed.Actions and ActorsThe action framework has been developed to perform actions, when the matchmakerfor EPAs triggers events. Since possible countermeasures should be both simple and2516 Secure Cloud Systems0100000020000003000000400000050000006000000700000080000009000000100000001 2 4 8Events per Second Number of Streams Figure 6.25: Increasing the number of streamsflexible, the decision was made to use Python that due to CPython and Jython61 couldbe easily integrated in the environment. An action consists of a signed Python scriptand an XML file that contains its required parameters and the layer on which the actionshould be executed. Similar to sensors, actions can be dynamically added and removedand can be executed on all layers of the virtualized computer system. In addition,every action sent to an actor for execution can be configured to use the communicationchannel used in the system. In this way, feedback whether or not the operation wassuccessful is provided, or another action based on the results of its execution can betriggered. Typical actions are: making memory dumps with a forensic analysis andperforming live migration (hypervisor level), creating firewall rules and killing processes(userland level), and altering JVM settings including restrictions (application containerlevel). Actors executing actions are only in charge of registering themselves, checkthe signature of incoming actions and provide an execution environment includingparameters relevant for the specific layer.Experimental EvaluationSELECT \u2217FROM TestStreamWHERE identifier = \"BenchmarkSensor\"Listing 6.2: Query used for benchmarkingTo demonstrate that the proposed reactive security monitoring system can be usedin a real world setting, the difference between the timestamp of the creation of anevent at a sensor and the timestamp at the execution of an action triggered due to that61http://www.jython.org/2526.4 Reactive Realtime Cloud Infrastructure Monitoring110100100010000Q1 Q2 Q3Milliseconds Figure 6.26: Query performance evaluation (overall query time) for queries Q1, Q2 and Q300.010.020.030.040.050.06Time (seconds) Actions Event-To-Action Time (1 Action/s) Figure 6.27: Time from event to action (single)00.511.522.5Time (seconds) Actions Event-To-Action Time  (~23,700 Actions/s) Figure 6.28: Time from event to action (bulk)event was measured. A sensor explicitly designed for this benchmark sends an eventcontaining an increasing identifier and the current timestamp of the guest machine.The experiment is based on a simple query shown in Listing 6.2 to redirect this eventto the action framework. An action that prints the current timestamp and expects thisID is used and sent to an userland actor where the timestamps are then compared,resulting in the complete event-to-action time for this workflow. The actor is placedon the same guest machine to avoid having to synchronize different clocks. Figure6.27 shows the measured results for an event-to-action time of one event and thus oneaction per second with a time series as the ordinate and the difference in timestamps asthe abscissa. The results indicate that the system has an average reaction time of 0.007seconds.Figure 6.28 shows the measurement series for an event-to-action time with no limi-tation in the sending rate, resulting in around 23,700 actions per second in which thetime from event to action is measured. Similar to the previous experiment, the figureshows a time series as the ordinate and the difference in timestamps as the abscissa.Since this experiment investigates a system at the boundaries of the virtual hardwarewith a triggering rate of over 23,000 actions per second, a mean value of 1.82 secondsfor the time from event creation to the resulting action is still within an acceptabletimeframe and indicates how well the system operates under heavy load.2536 Secure Cloud Systems6.4.8 ConclusionIn this section, a novel approach for reactive security monitoring in a virtualizedcomputer environment based on minimally-intrusive dynamic sensor deploymentvertically across virtualization layers and horizontally within a virtual machine waspresented. The sensor streams are analyzed using a federation of CEP engines anda query index to maximize the performance queries, and the results of the analysisare used to trigger appropriate actions in response to the detected security anomalies.Furthermore, a novel event store is utilized that supports fast event logging for offlineanalysis of collected historical data. Experiments have shown that the proposed systemcan execute tens of thousands of detection rules with high performance and low latency.There are several areas of future work. For example, the research has demonstratedthat the system can be used for reactive security monitoring with respect to performance,but not how it should be used. Thus, specifying appropriate sensors, CEP queries andactions for several types of potential attacks is a challenging task for future research.Furthermore, research on using machine learning techniques to automatically setparameters of CEP queries based on historical data collected in the Event Store isrequired. Finally, to increase the processing speed further and handle an even largernumber of events, multi-core architectures should be leveraged and certain CEP queriesshould be offloaded to General Purpose Graphic Processing Units (GPGPUs).2546.5 Summary6.5 SummaryIn Section 6.2, an empirical study of the security properties of email server communica-tion within the German IP address space range was presented. Instead of investigatingend-user security or end-to-end encryption, we focused on the connections betweenSMTP servers relying on transport layer security. An in-depth analysis was performedon the involved ciphers suites, the certificates used and certificate authorities, andthe behavior of email providers when communicating with improperly secured emailservers. Conclusions drawn from this analysis lead to several recommendations formitigating the security issues currently present in the email system as it is deployed inthe Internet.An approach for combined malware detection and kernel rootkit prevention invirtualized cloud computing environments was presented in Section 6.3. All runningbinaries in a virtual instance are intercepted and submitted to one or more anti-virus analysis engines. Besides a complete check against a signature database, liveintrospection of all system calls is performed to detect yet unknown exploits or malware.Furthermore, to prevent that an intruder retains persistent control over a runninginstance after a successful compromise, an in-kernel rootkit prevention approach isproposed. Only authorized and thus trusted kernel modules are allowed to be loadedduring runtime; loading of unauthorized modules is no longer possible. Finally, theperformance of the presented solutions was evaluated and showed its practicability.Finally, in Section 6.4, a new approach for reactive security monitoring in a virtualizedcomputing environment based on minimally-intrusive dynamic sensor deploymentvertically across virtualization layers and horizontally within a virtual machine instancewas presented. The sensor streams are analyzed using a novel federation of ComplexEvent Processing engines and an optimized query index to maximize the performanceof continuous queries, and the results of the analysis are used to trigger appropriateactions on different virtualization layers in response to detected security anomalies.Furthermore, a novel event store that supports fast event logging is utilized for offlineanalysis of collected historical data. Experiments show that the proposed system canexecute tens of thousands of complex detection rules and trigger actions efficiently andwith low latency.2557 Conclusion7.1 SummaryIn this thesis, existing technology used during disaster scenarios was evaluated, andshortcomings were identified regarding usability, feature-completeness, and security.Several novel approaches were developed to improve the usefulness of a decentralizedcommunication system suited specifically for challenged networks such as the onesfound during an emergency. Overall, several improvements were made and noveltechnologies were designed for secure emergency communication in course of thisthesis.MiniWorld, a novel, flexible distributed emulation environment was developed. Itenables us to evaluate software for emergency scenarios in a more realistic way. This isachieved by combining full system emulation with interchangeable network back-endsto simulate wireless properties such as the ones found with Bluetooth or WiFi linksand allows an orchestrated dynamic movement of nodes.Furthermore, the usefulness of DTN and Device-to-Device networks was improvedby novel approaches and algorithms for local announcements and data dissemination.Also, a first of its kind RPC system specifically tailored to challenged network conditionsin an emergency scenario, called DTN-RPC, was presented. These developments are thefoundation for novel applications such as mobile optimized on-device face recognitionwith D2D data distribution capabilities (SmartFace) and an integrated approach utilizingunmanned ground and aerial vehicles (uv4ec). Through the addition of microcontrollerunits and making long range radio transceivers available to mobile device, the systemcan be used in various scenarios including environmental monitoring. Moreover, stepswere taken to increase the security and robustness of the presented disruption-tolerantdevice-to-device emergency communication system.To increase the security of mobile apps, novel tools for large scale dynamic (Dynalize)and static (AndroLyze) analysis of Android apps were developed. The importance ofsuch tools is shown by audits of common emergency communication apps as well aslarge-scale tests for the use of SSL/TLS and various cryptographic functions in apps.Finally, a novel system for increased security and monitoring of virtualized serverssystems was developed. The combination of integrated classic anti-virus systems withlive introspection and dynamically deployed sensors across several layers enables newways to defend a system, with minimal footprint on each guest machine. A federatedCEP engine in conjunction with a historic event database helps identifying anomaliesand reducing false alarms.Overall, this thesis has presented several solutions to provide a secure and flexiblecommunication system to cope with the challenging network conditions during adisaster scenario, ranging from DTN D2D communication on mobile devices utilizingsecure communication channels to Internet connected virtualized cloud systems.2577 Conclusion7.2 Future WorkThere are several areas for future research regarding secure communication in emer-gency scenarios. Many points have already been highlighted in the individual conclu-sions of each section. Furthermore, future research may include general improvementsand extensions of the solutions presented in this thesis, which will be discussed in thefollowing.Disruption-Tolerant Device-to-Device Emergency CommunicationAlthough the solutions presented in this thesis can be used in various scenarios, thereis room for further optimizations, especially for low-bandwidth links, such as LoRa.Here, DTN distribution strategies and protocols can be further developed to reduce theamount of bandwidth needed. Also, the resource footprint of security related functions,such as signing and hashing, is challenging for embedded microcontrollers. In termsof implementation, the solutions are engineered mainly towards Linux, macOS, andAndroid. However, they should also be expanded to iOS and Windows for wider realworld adoption.Security Vulnerability Analysis of Mobile AppsWhile the dynamic and static security checks designed during the course of this thesishave already unveiled many vulnerabilities in existing emergency communication apps,some aspects should be investigated further. Automatic and intelligent combination ofboth analysis methods could be used to eliminate false positives, and integration ofthese security checks into software development tools could further improve mobileapp security.Secure Cloud SystemsThe VM introspection and monitoring systems presented in this thesis are heavilytailored towards KVM and the Linux kernel. For wider adoption, including support forother hypervisors and operating systems such as FreeBSD or Windows Server wouldbe helpful. Building upon this foundation and the amount of sensor data that can beacquired, the possibility of using machine learning techniques for anomaly detectionshould be investigated.258List of Figures1.1 Natural catastrophes since 1980 . . . . . . . . . . . . . . . . . . . . . . . . 11.2 FEMA Top 10 Response Core Capabilities . . . . . . . . . . . . . . . . . . 21.3 FEMA Top 10 Protection Core Capabilities . . . . . . . . . . . . . . . . . 22.1 IP vs DTN data flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102.2 The Serval technology stack . . . . . . . . . . . . . . . . . . . . . . . . . . 112.3 Contents of NINA APK . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132.4 DWD WarnWetter app in action . . . . . . . . . . . . . . . . . . . . . . . 152.5 BBK NINA in action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162.6 KATWARN in action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162.7 FireChat room overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182.8 Serval Mesh main view . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182.9 Cloud services overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193.1 Typical Internet services used during disasters . . . . . . . . . . . . . . . 233.2 Mobile apps deployed on different devices . . . . . . . . . . . . . . . . . 243.3 Thesis problem overview . . . . . . . . . . . . . . . . . . . . . . . . . . . 253.4 Secure communication during disaster scenarios . . . . . . . . . . . . . . 274.1 DT D2D communication system developments . . . . . . . . . . . . . . . 324.2 MiniWorld\u2019s Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . 354.3 MiniWorld\u2019s Distributed Architecture . . . . . . . . . . . . . . . . . . . . 384.4 MiniWorld Implementation . . . . . . . . . . . . . . . . . . . . . . . . . . 394.5 Boot Times: OpenWrtBB vs. Debian8 (Shell Prompt) . . . . . . . . . . . . 424.6 Boot Times: Snapshot Boot vs. Real Boot (Debian8) . . . . . . . . . . . . 424.7 Network Backend Throughput . . . . . . . . . . . . . . . . . . . . . . . . 434.8 RTTs for the Network Backends . . . . . . . . . . . . . . . . . . . . . . . 434.9 Topology Switching (Bridged WiFi) . . . . . . . . . . . . . . . . . . . . . . 444.10 Distributed Mode: Boot Times . . . . . . . . . . . . . . . . . . . . . . . . . 454.11 Distributed Mode: Differential Topology Switching . . . . . . . . . . . . 454.12 Distributed Mode: Tunnel Overhead . . . . . . . . . . . . . . . . . . . . . 464.13 MF Mixed: Rhizome store size, network and CPU load . . . . . . . . . . 544.14 Mass-Messages CPU Usage over Time . . . . . . . . . . . . . . . . . . . . 554.15 Hub limited PM: Rhizome store size, network & CPU . . . . . . . . . . . 564.16 Evaluation Scenario: Chained Limited Medium . . . . . . . . . . . . . . 574.17 Energy consumption of announcement intervals . . . . . . . . . . . . . . 584.18 Serval Power Consumption . . . . . . . . . . . . . . . . . . . . . . . . . . 594.19 Drive-by store-and-forward data exchange . . . . . . . . . . . . . . . . . 604.20 Drive-by window of opportunity example . . . . . . . . . . . . . . . . . 604.21 Announcements/second in a static network of 25 nodes . . . . . . . . . 684.22 Announcement Strategies Comparison . . . . . . . . . . . . . . . . . . . 69259List of Figures4.23 Splitting network configuration with 10 nodes . . . . . . . . . . . . . . . 714.24 A growing network with 100 nodes . . . . . . . . . . . . . . . . . . . . . 724.25 Announcement Gaps in a static network of 10 nodes . . . . . . . . . . . . 734.26 Calling a remote procedure in a DTN disaster scenario . . . . . . . . . . 754.27 DTN-RPC flowchart for client and server. . . . . . . . . . . . . . . . . . . 794.28 DTN-RPC Bandwidth and CPU Usage . . . . . . . . . . . . . . . . . . . . 854.29 Round trip times in different topologies . . . . . . . . . . . . . . . . . . . 864.30 DTN vs. Non-DTN for 100MB with Islands Topology . . . . . . . . . . . 874.31 Base station for monitoring, relaying and processing . . . . . . . . . . . 934.32 BLE LoRa modem with plain Raspberry Pi 3 for size comparison . . . . 954.33 Waterproof static sensor box deployed . . . . . . . . . . . . . . . . . . . . 984.34 Communication range of different LoRa setups . . . . . . . . . . . . . . 994.35 RSSI vs. Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1004.36 Number of received packets in relation to packets sent. . . . . . . . . . . 1004.37 Basic two-stage face detector . . . . . . . . . . . . . . . . . . . . . . . . . 1054.38 Two-stage face detector, preprocessing, and parameters . . . . . . . . . . 1064.39 SmartFace in action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1064.40 SmartFace implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . 1074.41 Examples from image test set . . . . . . . . . . . . . . . . . . . . . . . . . 1084.42 Comparison of different color spaces and depths . . . . . . . . . . . . . 1084.43 Face-Detection Performance for Different Resolutions . . . . . . . . . . . 1094.44 Comparison of cropped areas from grey scale images . . . . . . . . . . . 1094.45 Overall benchmark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1114.46 Best of all categories dlib vs SmartFace . . . . . . . . . . . . . . . . . . . . 1114.47 Direct comparison of devices . . . . . . . . . . . . . . . . . . . . . . . . . 1114.48 Individual device performance . . . . . . . . . . . . . . . . . . . . . . . . 1124.49 SmartFace Performance on Various Devices and Links . . . . . . . . . . . 1134.50 Emergency communication scenario . . . . . . . . . . . . . . . . . . . . . 1164.51 Architecture of NICER OCC . . . . . . . . . . . . . . . . . . . . . . . . . . 1194.52 UI component of NICER OCC . . . . . . . . . . . . . . . . . . . . . . . . . 1204.53 Hector Tracker Robot in Simulated Disaster . . . . . . . . . . . . . . . . . 1214.54 Robot sensor data for a \u201dvictim found\u201d event . . . . . . . . . . . . . . . . 1224.55 UAV/UGV Simulation Setup . . . . . . . . . . . . . . . . . . . . . . . . . 1234.56 Opportunities for data exchange . . . . . . . . . . . . . . . . . . . . . . . 1244.57 Opportunities for data exchange over time . . . . . . . . . . . . . . . . . 1244.58 File distribution times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1244.59 Message distribution times . . . . . . . . . . . . . . . . . . . . . . . . . . 1244.60 SEMUD vs OLSR Reaction Times . . . . . . . . . . . . . . . . . . . . . . . 1254.61 Secure Key Management Illustration . . . . . . . . . . . . . . . . . . . . . 1304.62 Flooding attack and revocation . . . . . . . . . . . . . . . . . . . . . . . . 1335.1 Insecure mobile AV solution compromised . . . . . . . . . . . . . . . . . 1485.2 Sample SSL Warning Message . . . . . . . . . . . . . . . . . . . . . . . . 1515.3 Facebook\u2019s SSL warning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1525.4 Analysis approach of AndroLyze . . . . . . . . . . . . . . . . . . . . . . . 1625.5 Typical workflow while using AndroLyze . . . . . . . . . . . . . . . . . . 1645.6 Parallelization of APK import . . . . . . . . . . . . . . . . . . . . . . . . . 168260List of Figures5.7 Relation between script requirements and runtime . . . . . . . . . . . . . 1695.8 Local parallel mode +Source code . . . . . . . . . . . . . . . . . . . . . . 1705.9 Comparison of job scheduling strategies . . . . . . . . . . . . . . . . . . . 1705.10 Local parallel mode +Bytecode . . . . . . . . . . . . . . . . . . . . . . . . 1715.11 Distributed parallel mode + SSL vs. local parallel mode +SSL . . . . . . 1715.12 APK distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1725.13 Performance of AndroLyze . . . . . . . . . . . . . . . . . . . . . . . . . . 1735.14 Crypto Statistics for Top Free 500 Archive . . . . . . . . . . . . . . . . . . 1745.15 Dynalize platform architecture . . . . . . . . . . . . . . . . . . . . . . . . 1775.16 Dynalize IaaS Layout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1785.17 Screenshot of the Dynalize interface . . . . . . . . . . . . . . . . . . . . . 1805.18 Virtual device start time and throughput on EC2 . . . . . . . . . . . . . . 1825.19 Storage throughput for different EC2 instance types . . . . . . . . . . . . 1835.20 Container startup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1845.21 Average throughput and overhead of storage Backends . . . . . . . . . . 1855.22 Successful MITM attack on WarnWetter . . . . . . . . . . . . . . . . . . . 1895.23 Successful MITM attack on NINA . . . . . . . . . . . . . . . . . . . . . . 1905.24 Successful MITM attack on Sicher Reisen . . . . . . . . . . . . . . . . . . 1925.25 Successful MITM attack on BIWAPP . . . . . . . . . . . . . . . . . . . . . 1935.26 Different successful attacks on FEMA app . . . . . . . . . . . . . . . . . . 1955.27 Successful MITM attack on Disaster Alert . . . . . . . . . . . . . . . . . . 1965.28 Successful MITM attack on NOAA Weather Radar . . . . . . . . . . . . 1976.1 Email transfer and TLS usage. . . . . . . . . . . . . . . . . . . . . . . . . . 2026.2 SMTP and TLS usage among the scanned hosts . . . . . . . . . . . . . . 2056.3 SSL and TLS versions used in the scanned services . . . . . . . . . . . . 2066.4 Use of cipher suites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2076.5 Change of the average key lengths over time. . . . . . . . . . . . . . . . . 2106.6 Categorization of services using the main security properties . . . . . . 2106.7 Root certificates in relation to their signed server certificates . . . . . . . 2106.8 CA Topology of the Comodo CA. . . . . . . . . . . . . . . . . . . . . . . . 2126.9 Malware scanner architecture . . . . . . . . . . . . . . . . . . . . . . . . . 2216.10 Authorized module loading state transition diagram . . . . . . . . . . . 2246.11 Module loading activity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2276.12 Malware Detection Benchmarks . . . . . . . . . . . . . . . . . . . . . . . . 2286.13 Module (un)loading overhead measurement . . . . . . . . . . . . . . . . 2296.14 Sensors, Analysis-VM and actors . . . . . . . . . . . . . . . . . . . . . . . 2366.15 Analysis-VM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2366.16 Monitoring lifecycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2386.17 Example: TCP backdoor detection. . . . . . . . . . . . . . . . . . . . . . . 2396.18 Resource usage of sensors . . . . . . . . . . . . . . . . . . . . . . . . . . . 2436.19 Comparison of sensor activity affecting total build time . . . . . . . . . . 2436.20 Performance of the federated CEP engine with a query index . . . . . . 2476.21 Query index creation time . . . . . . . . . . . . . . . . . . . . . . . . . . . 2476.22 Example of an Event Store topology . . . . . . . . . . . . . . . . . . . . . 2496.23 Evaluation of system performance factors . . . . . . . . . . . . . . . . . . 2506.24 Comparison of net and gross data rates . . . . . . . . . . . . . . . . . . . 251261List of Figures6.25 Increasing the number of streams . . . . . . . . . . . . . . . . . . . . . . . 2526.26 Query performance evaluation . . . . . . . . . . . . . . . . . . . . . . . . 2536.27 Time from event to action (single) . . . . . . . . . . . . . . . . . . . . . . 2536.28 Time from event to action (bulk) . . . . . . . . . . . . . . . . . . . . . . . 253262List of Tables4.1 Network Topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514.2 Scenario Tests . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 524.3 Test File Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 524.4 Announcements of the strategies compared. . . . . . . . . . . . . . . . . 704.5 Correlation of energy consumption and announcements . . . . . . . . . 734.6 Topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 834.7 Overview of SBC and MCU Platforms . . . . . . . . . . . . . . . . . . . . 964.8 Overview of different Sensors . . . . . . . . . . . . . . . . . . . . . . . . . 974.9 Power consumption of MCUs including radio transceivers . . . . . . . . 984.10 Comparison of Concept Detection on Pi vs. Neural Compute Stick . . . 1004.11 Cost of BLE LoRa Modem . . . . . . . . . . . . . . . . . . . . . . . . . . . 1014.12 Example configuration for a MSP . . . . . . . . . . . . . . . . . . . . . . . 1014.13 Example configuration for a SSP (w/o power supply) . . . . . . . . . . . 1024.14 Device Specifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1074.15 Contingency table for dlib . . . . . . . . . . . . . . . . . . . . . . . . . . . 1104.16 Contingency table for OpenCV . . . . . . . . . . . . . . . . . . . . . . . . 1104.17 Contingency table for SmartFace (faster runtime) . . . . . . . . . . . . . . 1104.18 Contingency table for SmartFace (higher quality) . . . . . . . . . . . . . . 1104.19 Transmission times for various link types . . . . . . . . . . . . . . . . . . 1124.20 Performance test of OCC w.r.t message processing . . . . . . . . . . . . . 1265.1 Top 10 hosts in all extracted URLs . . . . . . . . . . . . . . . . . . . . . . 1445.2 Trust Managers & Socket Factories that trust all certificates . . . . . . . 1455.3 Results of the SSL pinning analysis . . . . . . . . . . . . . . . . . . . . . . 1505.5 APK test sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1685.6 Script test sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1685.7 Prices of the used instance types . . . . . . . . . . . . . . . . . . . . . . . 1835.8 Emergency warning app audit results . . . . . . . . . . . . . . . . . . . . 1986.1 Shares of weak and broken cipher suites . . . . . . . . . . . . . . . . . . 2086.2 Time period of validity of the retrieved certificates . . . . . . . . . . . . . 2096.3 Self-signed, server and CA certificates . . . . . . . . . . . . . . . . . . . . 2096.4 Top 10: Most popular CAs . . . . . . . . . . . . . . . . . . . . . . . . . . . 2116.5 Email provider strategies for connections to other email servers . . . . . 2136.6 Number of implemented sensors . . . . . . . . . . . . . . . . . . . . . . . 2406.7 Hardware specification of the host systems . . . . . . . . . . . . . . . . . 2426.8 Hardware specification of the guest systems . . . . . . . . . . . . . . . . 242263Bibliography[1] N. Schmidt, L. Baumga\u00a8rtner, P. Lampe, K. Geihs, and B. Freisleben, \u201cMiniWorld:Resource-aware Distributed Network Emulation via Full Virtualization,\u201d in 22ndIEEE Symposium on Computers and Communication (ISCC 2017), Heraklion, Greece:IEEE, 2017, pp. 818\u2013825 (cit. on pp. xiii, 6, 33).[2] L. Baumga\u00a8rtner, P. Gardner-Stephen, P. Graubner, J. Lakeman, J. Ho\u00a8chst, P.Lampe, N. Schmidt, S. Schulz, A. Sterz, and B. Freisleben, \u201cAn ExperimentalEvaluation of Delay-Tolerant Networking with Serval,\u201d in IEEE Global Human-itarian Technology Conference (GHTC 2016), Seattle, USA: IEEE, 2016, pp. 1\u20138(cit. on pp. xiii, 7, 49, 62, 76, 91).[3] L. Baumga\u00a8rtner, P. Graubner, J. Ho\u00a8chst, A. Klein, and B. Freisleben, \u201cThe MoreYou Speak, the Less You Hear: On Dynamic Announcement Intervals in WirelessOn-demand Networks,\u201d in 13th Conference on Wireless On-demand Network Systemsand Services (WONS 2017), Jackson Hole, USA: IEEE, 2017, pp. 33\u201340 (cit. onpp. xiii, 6, 61).[4] A. Sterz, L. Baumga\u00a8rtner, R. Mogk, M. Mezini, and B. Freisleben, \u201cDTN-RPC:Remote Procedure Calls for Disruption-Tolerant Networking,\u201d in IFIP Networking2017 Conference and Workshops (Networking 2017), Stockholm, Sweden: IFIP, 2017,pp. 1\u20139 (cit. on pp. xiii, 6, 76).[5] P. Lampe, L. Baumga\u00a8rtner, R. Steinmetz, and B. Freisleben, \u201cSmartFace: Ef-ficient Face Detection on Smartphones for Wireless On-demand EmergencyNetworks,\u201d in 24th International Conference on Telecommunications (ICT 2017),Limassol, Cyprus: IEEE, 2017, pp. 1\u20137 (cit. on pp. xiii, 6, 92, 99, 103).[6] L. Baumga\u00a8rtner, A. Penning, P. Lampe, B. Richerzhagen, R. Steinmetz, and B.Freisleben, \u201cEnvironmental Monitoring Using Low-Cost Hardware and Infras-tructureless Wireless Communication,\u201d in IEEE Global Humanitarian TechnologyConference (GHTC 2018), San Jose, USA: IEEE, 2018, accepted for publication(cit. on pp. xiii, 6, 89).[7] L. Baumga\u00a8rtner, S. Kohlbrecher, J. Euler, T. Ritter, M. Schmittner, C. Meurisch,M. Mu\u00a8hlha\u00a8user, M. Hollick, O. von Stryk, and B. Freisleben, \u201cEmergency Com-munication in Challenged Environments via Unmanned Ground and AerialVehicles,\u201d in IEEE Global Humanitarian Technology Conference (GHTC 2017), SanJose, USA: IEEE, 2017, pp. 1\u20139 (cit. on pp. xiii, 6, 91, 115).[8] F. Kohnha\u00a8user, M. Schmittner, L. Baumga\u00a8rtner, L. Almon, S. Katzenbeisser, M.Hollick, and B. Freisleben, \u201cSEDCOS: A Secure Device-to-Device Communica-tion System for Disaster Scenarios,\u201d in 42nd Annual IEEE Conference on LocalComputer Networks (LCN 2017), Singapore, Singapore: IEEE, 2017, pp. 195\u2013198(cit. on pp. xiii, 6, 128).265Bibliography[9] S. Fahl, M. Harbach, T. Muders, L. Baumga\u00a8rtner, B. Freisleben, and M. Smith,\u201cWhy Eve and Mallory Love Android: An Analysis of Android SSL (In)Security,\u201din Proceedings of the 2012 ACM Conference on Computer and Communications Security(CCS), Raleigh, USA: ACM, 2012, pp. 50\u201361 (cit. on pp. xiv, 7, 139, 159, 160).[10] L. Baumga\u00a8rtner, P. Graubner, N. Schmidt, and B. Freisleben, \u201cAndroLyze: ADistributed Framework for Efficient Android App Analysis,\u201d in IEEE 2nd Inter-national Conference on Mobile Services (MS 2015), New York City, USA: IEEE, 2015,pp. 73\u201380 (cit. on pp. xiv, 7, 159).[11] P. Graubner, L. Baumga\u00a8rtner, P. Heckmann, M. Mu\u00a8ller, and B. Freisleben, \u201cDy-nalize: Dynamic Analysis of Mobile Apps in a Platform-as-a-Service Cloud,\u201d inIEEE 8th International Conference on Cloud Computing (CLOUD 2015), New YorkCity, USA: IEEE, 2015, pp. 925\u2013932 (cit. on pp. xiv, 7, 175).[12] L. Baumga\u00a8rtner, J. Ho\u00a8chst, M. Leinweber, and B. Freisleben, \u201cHow to MisuseSMTP over TLS: A Study of the (In) Security of Email Server Communication,\u201din 2015 IEEE Trustcom/BigDataSE/ISPA, Helsinki, Finland: IEEE, 2015, pp. 287\u2013294 (cit. on pp. xiv, 7, 203).[13] M. Schmidt, L. Baumga\u00a8rtner, P. Graubner, D. Bo\u00a8ck, and B. Freisleben, \u201cMalwareDetection and Kernel Rootkit Prevention in Cloud Computing Environments,\u201din 19th Euromicro International Conference on Parallel, Distributed and Network-BasedProcessing (PDP 2011), Ayia Napa, Cyprus: IEEE, 2011, pp. 603\u2013610 (cit. onpp. xiv, 7, 217).[14] L. Baumga\u00a8rtner, P. Graubner, M. Leinweber, R. Schwarzkopf, M. Schmidt,B. Seeger, and B. Freisleben, \u201cMastering Security Anomalies in VirtualizedComputing Environments via Complex Event Processing,\u201d in Proceedings ofthe The Fourth International Conference on Information, Process, and KnowledgeManagement (eKNOW 2012), Valencia, Spain: IEEE, 2012, pp. 76\u201381 (cit. onpp. xiv, 7, 232).[15] L. Baumga\u00a8rtner, C. Strack, B. Ho\u00dfbach, M. Seidemann, B. Seeger, and B. Freisleben,\u201cComplex Event Processing for Reactive Security Monitoring in VirtualizedComputer Systems,\u201d in Proceedings of the 9th ACM International Conference onDistributed Event-Based Systems, Oslo, Norway: ACM, 2015, pp. 22\u201333 (cit. onpp. xiv, 7, 232).[16] D. M. West and M. Orr, \u201cRace, Gender, and Communications in Natural Disas-ters,\u201d Policy Studies Journal, vol. 35, no. 4, pp. 569\u2013586, 2007 (cit. on p. 1).[17] L. Comfort and T. Haase, \u201cCommunication, Coherence, and Collective Action:The Impact of Katrina on Communications Infrastructure,\u201d Public Works Manage-ment & Policy, vol. 10, no. 4, pp. 328\u2013343, 2006 (cit. on p. 1).[18] R. Mogk, L. Baumga\u00a8rtner, G. Salvaneschi, B. Freisleben, and M. Mezini, \u201cFault-tolerant Distributed Reactive Programming,\u201d in 32nd European Conference onObject-Oriented Programming (ECOOP 2018), vol. 109, Amsterdam, The Nether-lands: Schloss Dagstuhl\u2013Leibniz-Zentrum fu\u00a8r Informatik, 2018, 1:1\u20131:26 (cit. onp. 6).266Bibliography[19] P. Graubner, P. Lampe, J. Ho\u00a8chst, L. Baumga\u00a8rtner, M. Mezini, and B. Freisleben,\u201cOpportunistic Named Functions in Disruption-tolerant Emergency Networks,\u201din ACM International Conference on Computing Frontiers 2018 (ACM CF\u201918), Ischia,Italy: ACM, 2018, pp. 129\u2013137 (cit. on pp. 6, 95).[20] C. Meurisch, J. Gedeon, A. Gogel, T. A. B. Nguyen, F. Kaup, F. Kohnha\u00a8user, L.Baumga\u00a8rtner, M. Schmittner, and M. Mu\u00a8hlha\u00a8user, \u201cTemporal Coverage Analysisof Router-based Cloudlets Using Human Mobility Patterns,\u201d in 2017 IEEE GlobalCommunications Conference: Selected Areas in Communications: Internet of Things(Globecom 2017 SAC IoT), Singapore, Singapore: IEEE, 2017, pp. 1\u20136 (cit. on p. 6).[21] J. Ho\u00a8chst, L. Baumga\u00a8rtner, M. Hollick, and B. Freisleben, \u201cUnsupervised TrafficFlow Classification Using a Neural Autoencoder,\u201d in 42nd Annual IEEE Confer-ence on Local Computer Networks (LCN 2017), Singapore, Singapore: IEEE, 2017,pp. 523\u2013526 (cit. on p. 6).[22] M. Leinweber, T. Fober, M. Strickert, L. Baumga\u00a8rtner, G. Klebe, B. Freisleben,and E. Hu\u00a8llermeier, \u201cCavSimBase: A Database for Large Scale Comparisonof Protein Binding Sites,\u201d IEEE Transactions on Knowledge and Data Engineering,vol. 28, no. 6, pp. 1423\u20131434, 2016 (cit. on p. 7).[23] M. Leinweber, L. Baumga\u00a8rtner, M. Mernberger, T. Fober, E. Hu\u00a8llermeier, G.Klebe, and B. Freisleben, \u201cGPU-based Cloud Computing for Comparing theStructure of Protein Binding Sites,\u201d in 6th IEEE International Conference on DigitalEcosystems Technologies (DEST 2012), Campione d\u2019Italia, Italy: IEEE, 2012, pp. 1\u20136(cit. on p. 7).[24] A. Vahdat and D. Becker, \u201cEpidemic Routing for Partially Connected Ad HocNetworks,\u201d Duke University, Tech. Rep., Jul. 2000 (cit. on p. 11).[25] A. Lindgren, A. Doria, and O. Schele\u00b4n, \u201cProbabilistic Routing in IntermittentlyConnected Networks,\u201d ACM SIGMOBILE mobile computing and communicationsreview, vol. 7, no. 3, pp. 19\u201320, 2003 (cit. on p. 11).[26] P. Gardner-Stephen, \u201cThe Serval Project: Practical Wireless Ad-Hoc MobileTelecommunications,\u201d Flinders University, Adelaide, South Australia, Tech. Rep.,Aug. 2011, pp. 1\u201329 (cit. on pp. 11, 48, 49).[27] P. Gardner-Stephen, R. Challans, J. Lakeman, A. Bettison, D. Gardner-Stephen,and M. Lloyd, \u201cThe Serval Mesh: A Platform for Resilient Communications inDisaster & Crisis,\u201d in IEEE Global Humanitarian Technology Conference (GHTC2013), IEEE, 2013, pp. 162\u2013166 (cit. on pp. 11, 48, 76, 81).[28] P. Gardner-Stephen, A. Bettison, R. Challans, and J. Lakeman, \u201cThe RationalBehind The Serval Network Layer For Resilient Communications,\u201d Journal ofComputer Science, vol. 9, no. 12, p. 1680, 2013 (cit. on pp. 11, 48, 76, 81, 104).[29] P. Gardner-Stephen, J. Lakeman, R. Challans, C. Wallis, A. Stulman, and Y.Haddad, \u201cMeshMS: Ad Hoc Data Transfer within a Mesh Network,\u201d InternationalJournal of Communications, Network and System Sciences, vol. 8, no. 5, pp. 496\u2013504,2012 (cit. on pp. 12, 48, 76, 81).267Bibliography[30] D. Johnson, N. Ntlatlapa, and C. Aichele, \u201cA Simple Pragmatic Approachto Mesh Routing Using B.A.T.M.A.N.,\u201d in 2nd IFIP International Symposiumon Wireless Communications and Information Technology in Developing Countries,Pretoria, South Africa, 2008 (cit. on pp. 12, 81).[31] P. Jacquet, P. Muhlethaler, T. Clausen, A. Laouiti, A. Qayyum, and L. Viennot,\u201cOptimized Link State Routing Protocol for Ad Hoc Networks,\u201d in IEEE Interna-tional Conference on Technology for the 21st Century, IEEE, 2001, pp. 62\u201368 (cit. onp. 12).[32] C. Jackson and A. Barth, \u201cForcehttps: Protecting High-security Web Sites FromNetwork Attacks,\u201d in Proceeding of the 17th International Conference on World WideWeb, ACM, 2008, pp. 525\u2013534 (cit. on pp. 20, 141, 142).[33] Y. Song, C. Yang, and G. Gu, \u201cWho is Peeping at Your Passwords at Starbucks? \u2013To Catch An Evil Twin Access Point,\u201d in IEEE/IFIP International Conference onDependable Systems and Networks, IEEE, 2010, pp. 323\u2013332 (cit. on pp. 20, 141,142).[34] E. Weinga\u00a8rtner, H. vom Lehn, and K. Wehrle, \u201cA Performance Comparison ofRecent Network Simulators,\u201d in IEEE International Conference on Communications(ICC 2009), IEEE, 2009, pp. 1\u20135 (cit. on p. 33).[35] L. Hogie, P. Bouvry, and F. Guinand, \u201cAn Overview of MANET Simulation,\u201dElectronic notes in Theoretical Computer Science, vol. 150, no. 1, pp. 81\u2013101, 2006(cit. on p. 33).[36] M. Kropff, T. Krop, M. Hollick, P. S. Mogre, and R. Steinmetz, \u201cA Survey onReal World and Emulation Testbeds for Mobile Ad Hoc Networks,\u201d in 2ndInternational Conference on Testbeds and Research Infrastructures for the Developmentof Networks and Communities, IEEE, 2006, pp. 448\u2013453 (cit. on pp. 33, 34).[37] K. N. Patel and R. h. Jhaveri, \u201cA Survey on Emulation Testbeds for MobileAd-hoc Networks,\u201d Procedia Computer Science, vol. 45, pp. 581\u2013591, 2015 (cit. onpp. 33, 34).[38] J. Ahrenholz, C. Danilov, T. R. Henderson, and J. H. Kim, \u201cCORE: A Real-timeNetwork Emulator,\u201d in IEEE Military Communications Conference (MILCOM 2008),IEEE, 2008, pp. 1\u20137 (cit. on pp. 33, 34).[39] M. To, M. Cano, and P. Biba, \u201cDOCKEMU\u2013A Network Emulation Tool,\u201d in IEEE29th International Conference on Advanced Information Networking and Applications(WAINA 2015), IEEE, 2015, pp. 593\u2013598 (cit. on pp. 33, 34).[40] N. Handigol, B. Heller, V. Jeyakumar, B. Lantz, and N. McKeown, \u201cReproducibleNetwork Experiments Using Container-based Emulation,\u201d in 8th InternationalConference on Emerging Networking Experiments and Technologies (CoNEXT 2012),Nice, France: ACM, 2012, pp. 253\u2013264 (cit. on pp. 33, 35).[41] J. D. Britos, S. Arias, N. Echa\u00b4niz, G. Iribarren, L. Aimaretto, and G. Hirschfeld,\u201cBATMAN Advanced Mesh Network Emulator,\u201d in XXI Congreso Argentino deCiencias de la Computacio\u00b4n, 2015, pp. 1\u20138 (cit. on p. 34).[42] R. Davoli, \u201cVDE: Virtual Distributed Ethernet,\u201d in International Conference onTestbeds and Research Infrastructures for the DEvelopment of NeTworks and COMmu-nities, IEEE, 2005, pp. 213\u2013220 (cit. on pp. 34, 37).268Bibliography[43] M. Pizzonia and M. Rimondini, \u201cNetkit: Easy Emulation of Complex Networkson Inexpensive Hardware,\u201d in 4th International Conference on Testbeds and ResearchInfrastructures for the Development of Networks & Communities, ICST, 2008, pp. 1\u20137(cit. on p. 34).[44] T. Li, W. E. Thain Jr, and T. Fallon, \u201cOn the Use of Virtualization for RouterNetwork Simulation,\u201d in American Society for Engineering Education, ASEE, 2010,pp. 9\u201316 (cit. on p. 34).[45] M. Puz\u02c7ar and T. Plagemann, \u201cNEMAN: A Network Emulator for Mobile Ad-hocNetworks,\u201d in 8th International Conference on Telecommunications, 2005, pp. 155\u2013161 (cit. on p. 34).[46] S. Hemminger, \u201cNetwork Emulation with NetEm,\u201d in Australia\u2019s 6th NationalLinux Conference, 2005, pp. 1\u20137 (cit. on pp. 34, 40).[47] B. Pfaff, J. Pettit, T. Koponen, E. Jackson, A. Zhou, J. Rajahalme, J. Gross, A. Wang,J. Stringer, P. Shelar, et al., \u201cThe Design and Implementation of Open vswitch,\u201d in12th USENIX Symposium on Networked Systems Design and Implementation (NSDI15), 2015, pp. 117\u2013130 (cit. on p. 35).[48] S.-Y. Wang, \u201cComparison of SDN OpenFlow Network Simulator and Emulators:EstiNet vs. Mininet,\u201d in IEEE Symposium on Computers and Communications (ISCC2014), IEEE, 2014, pp. 1\u20136 (cit. on p. 35).[49] P. D. Pradeep and B. A. Kumar, \u201cA Survey of Emergency Communication Net-work Architectures,\u201d International Journal of u-and e-Service, Science and Technology,vol. 8, no. 4, pp. 61\u201368, 2015 (cit. on pp. 49, 103, 115).[50] M. Berioli, N. Courville, and M. Werner, \u201cEmergency Communications overSatellite: the WISECOM Approach,\u201d in 16Th IST Mobile and Wireless Communica-tions Summit, IEEE, 2007, pp. 1\u20135 (cit. on pp. 49, 115).[51] A. S. Cacciapuoti, F. Calabrese, M. Caleffi, G. Di Lorenzo, and L. Paura, \u201cHuman-mobility Enabled Wireless Networks for Emergency Communications duringSpecial Events,\u201d Pervasive and Mobile Computing, vol. 9, no. 4, pp. 472\u2013483, 2013(cit. on pp. 49, 115).[52] W. Wang, W. Gao, X. Bai, T. Peng, G. Chuai, and W. Wang, \u201cA Frameworkof Wireless Emergency Communications Based on Relaying and CognitiveRadio,\u201d in IEEE 18th International Symposium on Personal, Indoor and Mobile RadioCommunications, IEEE, 2007, pp. 1\u20135 (cit. on pp. 49, 115).[53] M. Manic, D. Wijayasekara, K. Amarasinghe, J. Hewlett, K. Handy, C. Becker,B. Patterson, and R. Peterson, \u201cNext Generation Emergency CommunicationSystems via Software Defined Networks,\u201d in Third GENI Research and EducationalExperiment Workshop, IEEE, 2014, pp. 1\u20138 (cit. on pp. 49, 115).[54] V. Mayer-Scho\u00a8nberger, \u201cEmergency Communications: The Quest for Interoper-ability in the United States and Europe,\u201d John F. Kennedy School of Government,Harvard University, 2002 (cit. on p. 49).[55] T. Pecorella, L. S. Ronga, F. Chiti, S. Jayousi, and L. Franck, \u201cEmergency SatelliteCommunications: Research and Standardization Activities,\u201d IEEE Communica-tions Magazine, vol. 53, no. 5, pp. 170\u2013177, 2015 (cit. on pp. 49, 115).269Bibliography[56] H. Chenji and R. Stoleru, \u201cDelay-tolerant Networks (DTNs) for EmergencyCommunications,\u201d Advances in Delay-tolerant Networks (DTNs): Architecture andEnhanced Performance, p. 105, 2014 (cit. on pp. 49, 103, 104, 115).[57] J. Thomas, J. Robble, and N. Modly, \u201cOff-grid Communications with AndroidMeshing the Mobile World,\u201d in IEEE Conference on Technologies for HomelandSecurity (HST 2012), IEEE, 2012, pp. 401\u2013405 (cit. on pp. 49, 104, 115).[58] Y. Liu, D. R. Bild, D. Adrian, G. Singh, R. P. Dick, D. S. Wallach, and Z. M.Mao, \u201cPerformance and Energy Consumption Analysis of a Delay-tolerantNetwork for Censorship-resistant Communication,\u201d in Proceedings of the 16thACM International Symposium on Mobile Ad Hoc Networking and Computing, ACM,2015, pp. 257\u2013266 (cit. on pp. 49, 62).[59] H. Ntareme, M. Zennaro, and B. Pehrson, \u201cDelay Tolerant Network on Smart-phones: Applications for Communication Challenged Areas,\u201d in Proceedings ofthe 3rd Extreme Conference on Communication, ACM, 2011, pp. 14\u201321 (cit. on pp. 49,115).[60] K. Heimerl, K. Ali, J. Blumenstock, B. Gawalt, and E. Brewer, \u201cExpandingRural Cellular Networks with Virtual Coverage,\u201d in 10th USENIX Symposium onNetwork Systems Design & Implementation, 2013, pp. 283\u2013296 (cit. on pp. 50, 115).[61] A. Battestini, V. Setlur, and T. Sohn, \u201cA Large Scale Study of Text-messagingUse,\u201d in 12th International Conference on Human Computer Interaction with MobileDevices and Services, ACM, 2010, pp. 229\u2013238 (cit. on p. 52).[62] G. Aloi, M. Di Felice, V. Loscri, P. Pace, and G. Ruggeri, \u201cSpontaneous Smart-phone Networks as a User-centric Solution for the Future Internet,\u201d IEEE Com-munications Magazine, vol. 52, no. 12, pp. 26\u201333, 2014 (cit. on p. 60).[63] E. Natsheh, A. B. Jantan, S. Khatun, and S. Shamala, \u201cAdaptive Optimizing ofHello Messages in Wireless Ad-Hoc Networks,\u201d Int. Arab J. Inf. Technol., vol. 4,no. 3, pp. 191\u2013200, 2007 (cit. on p. 61).[64] M. B. Khalaf, A. Y. Al-Dubai, and W. Buchanan, \u201cA New Adaptive BroadcastingApproach for Mobile Ad Hoc Networks,\u201d in 6th Conference on Wireless Advanced(WiAD 2010), IEEE, 2010, pp. 1\u20136 (cit. on p. 61).[65] S. H. Ahmed, S. H. Bouk, and D. Kim, \u201cAdaptive Beaconing Schemes in VANETs:Hybrid Approach,\u201d in International Conference on Information Networking (ICOIN2015), IEEE, 2015, pp. 340\u2013345 (cit. on p. 61).[66] R. Tahar, A. Dhraief, A. Belghith, H. Mathkour, and R. Braham, \u201cAutonomousand Adaptive Beaconing Strategy for Multi-interfaced Wireless Mobile Nodes,\u201dWireless Communications and Mobile Computing, vol. 16, no. 12, pp. 1625\u20131641,2016 (cit. on p. 61).[67] A. Hess, E. Hyytia\u00a8, and J. Ott, \u201cEfficient Neighbor Discovery in Mobile Oppor-tunistic Networking Using Mobility Awareness,\u201d in Sixth International Conferenceon Communication Systems and Networks (COMSNETS 2014), IEEE, 2014, pp. 1\u20138(cit. on p. 61).[68] F. Peng, \u201cA Novel Adaptive Mobility-aware MAC Protocol in Wireless SensorNetworks,\u201d Wireless Personal Communications, vol. 81, no. 2, pp. 489\u2013501, 2015(cit. on p. 62).270Bibliography[69] S. Lim, C. Yu, and C. R. Das, \u201cRandomCast: An Energy-efficient CommunicationScheme for Mobile Ad Hoc Networks,\u201d IEEE Transactions on Mobile Computing,vol. 8, no. 8, pp. 1039\u20131051, 2009 (cit. on p. 62).[70] J. A. B. Link, C. Wollgarten, S. Schupp, and K. Wehrle, \u201cPerfect Difference Setsfor Neighbor Discovery: Energy Efficient and Fair,\u201d in Proceedings of the 3rdExtreme Conference on Communication: The Amazon Expedition, ACM, 2011, p. 5(cit. on p. 62).[71] G. Da\u00b4n, N. Carlsson, and I. Chatzidrossos, \u201cEfficient and Highly AvailablePeer Discovery: A Case for Independent Trackers and Gossiping,\u201d in IEEEInternational Conference on Peer-to-Peer Computing (P2P 2011), IEEE, 2011, pp. 290\u2013299 (cit. on p. 62).[72] R. Zheng, J. C. Hou, and L. Sha, \u201cAsynchronous Wakeup for Ad Hoc Networks,\u201din Proceedings of the 4th ACM International Symposium on Mobile Ad Hoc Networking& Computing, ACM, 2003, pp. 35\u201345 (cit. on p. 62).[73] P. S. Paul, B. C. Ghosh, K. De, S. Saha, S. Nandi, S. Saha, I. Bhattacharya, andS. Chakraborty, \u201cOn Design and Implementation of a Scalable and Reliable SyncSystem for Delay Tolerant Challenged Networks,\u201d in 8th International Conferenceon Communication Systems and Networks (COMSNETS 2016), IEEE, 2016, pp. 1\u20138(cit. on p. 62).[74] B. Zhang, Y. Li, D. Jin, P. Hui, and Z. Han, \u201cSocial-Aware Peer Discovery forD2D Communications Underlaying Cellular Networks,\u201d IEEE Transactions onWireless Communications, vol. 14, no. 5, pp. 2426\u20132439, 2015 (cit. on p. 62).[75] W. Wang, V. Srinivasan, and M. Motani, \u201cAdaptive Contact Probing Mechanismsfor Delay Tolerant Applications,\u201d in 13th Annual ACM International Conference onMobile Computing and Networking, ACM, 2007, pp. 230\u2013241 (cit. on p. 62).[76] S. Trifunovic, B. Distl, D. Schatzmann, and F. Legendre, \u201cWiFi-Opp: Ad-hoc-lessOpportunistic Networking,\u201d in 6th ACM Workshop on Challenged Networks, ACM,2011, pp. 37\u201342 (cit. on p. 62).[77] T. Clausen, C. Dearlove, and J. Dean, Rfc 6130: Mobile ad hoc network (manet)neighborhood discovery protocol (nhdp), ietf, 2011 (cit. on p. 63).[78] A. D. Birrell and B. J. Nelson, \u201cImplementing Remote Procedure Calls,\u201d ACMTransactions on Computer Systems (TOCS 1084), vol. 2, no. 1, pp. 39\u201359, Feb. 1984(cit. on p. 75).[79] K. Fall, \u201cA Delay-tolerant Network Architecture for Challenged Internets,\u201d in2003 ACM Conference on Applications, Technologies, Architectures, and Protocols forComputer Communications, Karlsruhe, Germany: ACM, 2003, pp. 27\u201334 (cit. onp. 75).[80] A. McMahon and S. Farrell, \u201cDelay- and Disruption-Tolerant Networking,\u201d IEEEInternet Computing, vol. 13, pp. 82\u201387, 2009 (cit. on p. 75).[81] M. Kawecki and R. O. Schoeneich, \u201cMobility-based Routing Algorithm in DelayTolerant Networks,\u201d EURASIP Journal on Wireless Communications and Networking,vol. 2016, no. 1, pp. 1\u20139, 2016 (cit. on p. 75).271Bibliography[82] P. Gardner-Stephen and S. Palaniswamy, \u201cServal Mesh Software - WiFi MultiModel Management,\u201d in Proceedings of the 1st International Conference on WirelessTechnologies for Humanitarian Relief, Amritapuri, Kollam, Kerala, India: ACM,2011, pp. 71\u201377 (cit. on p. 75).[83] J. Tu and C. Stewart, \u201cReplication for Predictability in a Java RPC Framework,\u201din IEEE International Conference on Autonomic Computing (ICAC 2015), IEEE, 2015,pp. 163\u2013164 (cit. on p. 76).[84] P. Stuedi, A. Trivedi, B. Metzler, and J. Pfefferle, \u201cDaRPC: Data Center RPC,\u201din ACM Symposium on Cloud Computing (SOCC 2014), Seattle, WA, USA: ACM,2014, 15:1\u201315:13 (cit. on p. 76).[85] H. Chen, L. Shi, J. Sun, K. Li, and L. He, \u201cA Fast RPC System for VirtualMachines,\u201d IEEE Transactions on Parallel and Distributed Systems, vol. 24, no. 7,pp. 1267\u20131276, 2013 (cit. on p. 76).[86] N. Shyam, C. Harmer, and K. Beck, Managing Remote Procedure Calls When aServer is Unavailable, US Patent App. 12/610,049, May 2011 (cit. on p. 76).[87] A. Reinhardt, P. S. Mogre, and R. Steinmetz, \u201cLightweight Remote ProcedureCalls for Wireless Sensor and Actuator Networks,\u201d in IEEE International Confer-ence on Pervasive Computing and Communications Workshops, IEEE, 2011, pp. 172\u2013177 (cit. on p. 76).[88] C. Shi, V. Lakafosis, M. H. Ammar, and E. W. Zegura, \u201cSerendipity: EnablingRemote Computing Among Intermittently Connected Mobile Devices,\u201d in 13thACM International Symposium on Mobile Ad Hoc Networking and Computing (Mobi-Hoc 2012), Hilton Head, USA: ACM, 2012, pp. 145\u2013154 (cit. on p. 77).[89] M. Chen, Y. Hao, Y. Li, C.-F. Lai, and D. Wu, \u201cOn the Computation Offloadingat Ad Hoc Cloudlet: Architecture and Service Modes,\u201d IEEE CommunicationsMagazine, vol. 53, no. 6, pp. 18\u201324, 2015 (cit. on p. 77).[90] Y. Zhang, D. Niyato, and P. Wang, \u201cOffloading in Mobile Cloudlet Systems withIntermittent Connectivity,\u201d IEEE Transactions on Mobile Computing, vol. 14, no. 12,pp. 2516\u20132529, Dec. 2015, issn: 1536-1233 (cit. on p. 77).[91] Y. Lai, X. Gao, M. Liao, J. Xie, Z. Lin, and H. Zhang, \u201cData Gathering andOffloading in Delay Tolerant Mobile Networks,\u201d Wireless Networks, vol. 22, no. 3,pp. 959\u2013973, 2016 (cit. on p. 77).[92] J. Scho\u00a8ning and G. Heidemann, \u201cImage Based Spare Parts Reconstruction forRepairing Vital Infrastructure after Disasters,\u201d in IEEE Global HumanitarianTechnology Conference (GHTC \u201916), Seattle, USA: IEEE, 2016, pp. 225\u2013232 (cit. onp. 88).[93] K. Aberer, S. Sathe, D. Chakraborty, A. Martinoli, G. Barrenetxea, B. Faltings, andL. Thiele, \u201cOpenSense: Open Community Driven Sensing of the Environment,\u201din ACM SIGSPATIAL Int. Workshop on GeoStreaming, ACM, 2010, pp. 39\u201342 (cit.on p. 90).[94] B. Maag, Z. Zhou, and L. Thiele, \u201cW-Air: Enabling Personal Air PollutionMonitoring on Wearables,\u201d Proceedings of ACM on Interactive, Mobile, Wearableand Ubiquitous Technologies, vol. 2, no. 1, p. 24, 2018 (cit. on p. 90).272Bibliography[95] N. Castell, M. Kobernus, H.-Y. Liu, P. Schneider, W. Lahoz, A. J. Berre, andJ. Noll, \u201cMobile Technologies and Services for Environmental Monitoring: TheCiti-Sense-MOB Approach,\u201d Urban Climate, vol. 14, pp. 370\u2013382, 2015 (cit. onp. 90).[96] M. Gerboles, L. Spinelle, A. Kotsev, M. Signorini, and L. Srl, \u201cAirSensEUR:An Open-Designed Multi-Sensor Platform for Air Quality Monitoring,\u201d in 4thScientific Meeting EuNetAir, 2015, pp. 3\u20135 (cit. on p. 90).[97] P. Sikka, P. Corke, L. Overs, P. Valencia, and T. Wark, \u201cFleck-a Platform for Real-world Outdoor Sensor Networks,\u201d in 3rd International Conference on IntelligentSensors, Sensor Networks and Information, IEEE, 2007, pp. 709\u2013714 (cit. on p. 90).[98] M. T. Lazarescu, \u201cDesign and Field Test of a WSN Platform Prototype for Long-term Environmental Monitoring,\u201d Sensors, vol. 15, no. 4, pp. 9481\u20139518, 2015(cit. on p. 90).[99] C. Llamas, M. A. Gonza\u00b4lez, C. Herna\u00b4ndez, and J. Vegas, \u201cOpen Source HardwareBased Sensor Platform Suitable for Human Gait Identification,\u201d Pervasive andMobile Computing, vol. 38, pp. 154\u2013165, 2017 (cit. on p. 90).[100] J. A. Wirwahn and T. Bartoschek, \u201cUsability Engineering For Successful OpenCitizen Science,\u201d in Free and Open Source Software for Geospatial (FOSS4G) Confer-ence Proceedings, vol. 15, 2015, p. 54 (cit. on p. 90).[101] N. Fro\u00a8schle, \u201cEngineering of New Participation Instruments Exemplified byElectromobility, Particulate Matter and Clean Air Policy-Making,\u201d HMD Praxisder Wirtschaftsinformatik, vol. 54, no. 4, pp. 502\u2013517, 2017 (cit. on p. 90).[102] C. Pham, A. Rahim, and P. Cousin, \u201cWAZIUP: A Low-Cost Infrastructurefor Deploying IoT in Developing Countries,\u201d in International Conference on e-Infrastructure and e-Services for Developing Countries, Springer, 2016, pp. 135\u2013144(cit. on p. 90).[103] Y. Mao, J. Wang, B. Sheng, and F. Wu, \u201cBuilding Smartphone Ad-hoc Networkswith Long-range Radios,\u201d in 34th International Conference on Computing andCommunications, IEEE, 2015, pp. 1\u20138 (cit. on p. 90).[104] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, \u201cRethinking theInception Architecture for Computer Vision,\u201d in Proceedings of the IEEE conferenceon computer vision and pattern recognition, IEEE, 2016, pp. 2818\u20132826 (cit. on p. 95).[105] P. Viola and M. J. Jones, \u201cRobust Real-time Face Detection,\u201d International Journalof Computer Vision, vol. 57, no. 2, pp. 137\u2013154, 2004 (cit. on pp. 104, 106).[106] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan, \u201cObjectDetection with Discriminatively Trained Part-based Models,\u201d IEEE Transactionson Pattern Analysis and Machine Intelligence, vol. 32, no. 9, pp. 1627\u20131645, 2010(cit. on p. 104).[107] J. Cheney, B. Klein, A. K. Jain, and B. F. Klare, \u201cUnconstrained Face Detection:State of the Art Baseline and Challenges,\u201d in International Conference on Biometrics(ICB 2015), IEEE, 2015, pp. 229\u2013236 (cit. on pp. 104, 106, 108).273Bibliography[108] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller, \u201cLabeled Faces inthe Wild: A Database for Studying Face Recognition in Unconstrained Envi-ronments,\u201d University of Massachusetts, Amherst, Tech. Rep., 2007 (cit. onp. 104).[109] L. Wolf, T. Hassner, and I. Maoz, \u201cFace Recognition in Unconstrained Videoswith Matched Background Similarity,\u201d in IEEE Conference on Computer Vision andPattern Recognition, IEEE, 2011, pp. 529\u2013534 (cit. on p. 104).[110] B. F. Klare, B. Klein, E. Taborsky, A. Blanton, J. Cheney, K. Allen, P. Grother, A.Mah, and A. K. Jain, \u201cPushing the Frontiers of Unconstrained Face Detection andRecognition: ARPA Janus Benchmark A,\u201d in Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, IEEE, 2015, pp. 1931\u20131939 (cit. onp. 104).[111] K. Imaizumi and V. G. Moshnyaga, \u201cNetwork-based Face Recognition on MobileDevices,\u201d in IEEE 3rd International Conference on Consumer Electronics, IEEE, 2013,pp. 406\u2013409 (cit. on p. 104).[112] T. Soyata, R. Muraleedharan, C. Funai, M. Kwon, and W. Heinzelman, \u201cCloud-vision: Real-time Face Recognition Using a Mobile-cloudlet-cloud AccelerationArchitecture,\u201d in IEEE Symposium on Computers and Communications (ISCC 2012),IEEE, 2012, pp. 59\u201366 (cit. on p. 104).[113] H. Feng, B. Wang, C. Zhang, B. Yu, W. Hwang, J.-J. Han, C. Choi, and H.Wang, \u201cA Fast Multi-view Face Detector for Mobile Phone,\u201d in IEEE InternationalConference on Image Processing (ICIP 2016), IEEE, 2016, pp. 3219\u20133223 (cit. onp. 104).[114] H. L. Akin, N. Ito, A. Jacoff, A. Kleiner, J. Pellenz, and A. Visser, \u201cRobocupRescue Robot and Simulation Leagues,\u201d AI magazine, vol. 34, no. 1, p. 78, 2012(cit. on p. 114).[115] D. Fan, B. Li, and M. Chen, \u201cDesign of Global Emergency Mobile Communi-cation System Based on TDRSS,\u201d in 6th International Conference on ElectronicsInformation and Emergency Communication (ICEIEC 2016), IEEE, 2016, pp. 322\u2013325(cit. on p. 115).[116] K. Igarashi, K. Umeno, M. Okada, and M. Kikuchi, \u201cStudy on Emergency Mes-sage Communication System for Ensuring Safety in Antarctica under ExtremelySevere Environments,\u201d in International Conference on Smart Green Technology inElectrical and Information Systems (ICSGTEIS 2016), IEEE, 2016, pp. 116\u2013119 (cit.on p. 115).[117] K. Heimerl and T. S. Parikh, \u201cHow Users Understand Cellular Infrastructure,\u201dUniversity of California, Berkeley, Tech. Rep., Apr. 2012 (cit. on p. 115).[118] C. Ko\u00a8bel, W. B. Garcia, and J. Habermann, \u201cA Survey on Wireless Mesh Net-work Applications in Rural Areas and Emerging Countries,\u201d in IEEE GlobalHumanitarian Technology Conference (GHTC 2013), IEEE, 2013, pp. 389\u2013394 (cit. onp. 115).274Bibliography[119] D. Reina, J. Coca, M. Askalani, S. Toral, F. Barrero, E. Asimakopoulou, S. Sotiri-adis, and N. Bessis, \u201cA Survey on Ad Hoc Networks for Disaster Scenarios,\u201d inInternational Conference on Intelligent Networking and Collaborative Systems (INCoS2014), IEEE, 2014, pp. 433\u2013438 (cit. on p. 115).[120] Briar, https://briarproject.org/, (Accessed on 06/25/2016) (cit. on p. 115).[121] Firechat, http://opengarden.com/about-firechat, (Accessed on 06/25/2016)(cit. on p. 115).[122] Z. Lu, G. Cao, and T. La Porta, \u201cNetworking Smartphones for Disaster Recov-ery,\u201d in IEEE International Conference on Pervasive Computing and Communications(PerCom 2016), IEEE, 2016, pp. 1\u20139 (cit. on p. 115).[123] H. Nishiyama, M. Ito, and N. Kato, \u201cRelay-by-smartphone: Realizing MultihopDevice-to-Device Communications,\u201d IEEE Communication Magazine, vol. 52, no. 4,pp. 56\u201365, Apr. 2014 (cit. on p. 115).[124] R. Murphy, S. Tadokoro, D. Nardi, A. Joacoff, P. Fiorini, H. Choset, and A.Erkmen, Search and Rescue Robotics, Fundamental Problems and Open Issues inHandbook of Robotics, eds. Siciliano, Bruno; Khatib, Oussama, 2008 (cit. on p. 115).[125] R. R. Murphy, \u201cTrial by fire [rescue robots],\u201d IEEE Robotics & Automation Maga-zine, vol. 11, no. 3, pp. 50\u201361, 2004 (cit. on p. 115).[126] T. Yoshida, K. Nagatani, S. Tadokoro, T. Nishimura, and E. Koyanagi, \u201cImprove-ments to the Rescue Robot Quince Toward Future Indoor Surveillance Missionsin the Fukushima Daiichi Nuclear Power Plant,\u201d in Field and Service Robotics,Springer, 2014, pp. 19\u201332 (cit. on p. 115).[127] A. Hart, N. Pezeshkian, and H. Nguyen, \u201cMesh Networking Optimized forRobotic Teleoperation,\u201d Space and Naval Warfare Systems Center San Diegom,CA, Tech. Rep., 2012 (cit. on p. 115).[128] C. Luo, P. Ward, S. Cameron, G. Parr, and S. McClean, \u201cCommunication Provi-sion for a Team of Remotely Searching UAVs: A Mobile Relay Approach,\u201d in2012 IEEE Globecom Workshops, IEEE, 2012, pp. 1544\u20131549 (cit. on p. 115).[129] E. F. Flushing, M. Kudelski, L. M. Gambardella, and G. A. Di Caro, \u201cConnectivity-aware Planning of Search and Rescue Missions,\u201d in IEEE International Symposiumon Safety, Security, and Rescue Robotics (SSRR 2013), IEEE, 2013, pp. 1\u20138 (cit. onp. 115).[130] J. A. Dias, J. N. Isento, V. N. Soares, and J. J. Rodrigues, \u201cImpact of Schedulingand Dropping Policies on the Performance of Vehicular Delay-tolerant Net-works,\u201d in IEEE International Conference on Communications (ICC 2011), IEEE,2011, pp. 1\u20135 (cit. on p. 115).[131] M. Frassl, M. Lichtenstern, M. Khider, and M. Angermann, \u201cDeveloping a Sys-tem for Information Management in Disaster Relief-Methodology and Require-ments,\u201d in 7th International Conference on Information Systems for Crisis ResponseAnd Management (ISCRAM\u201910), vol. 1, 2010 (cit. on p. 115).[132] A. M. Khaleghi, D. Xu, S. Minaeian, M. Li, Y. Yuan, J. Liu, Y.-J. Son, C. Vo, A.Mousavian, and J.-M. Lien, \u201cA Comparative Study of Control Architectures inUAV/UGV-based Surveillance System,\u201d in IIE Annual Conference. Proceedings,Institute of Industrial Engineers-Publisher, 2014, p. 3455 (cit. on p. 115).275Bibliography[133] H.-B. Kuntze, C. W. Frey, I. Tchouchenkov, B. Staehle, E. Rome, K. Pfeiffer, A.Wenzel, and J. Wo\u00a8llenstein, \u201cSENEKA-Sensor Network with Mobile Robots forDisaster Management,\u201d in IEEE Conference on Technologies for Homeland Security(HST\u201912), IEEE, 2012, pp. 406\u2013410 (cit. on p. 115).[134] H.-B. Kuntze, C. Frey, T. Emter, J. Petereit, I. Tchouchenkov, T. Mueller, M. Tittel,R. Worst, K. Pfeiffer, M. Walter, et al., \u201cSituation Responsive Networking ofMobile Robots for Disaster Management,\u201d in Proceedings of ISR/Robotik 2014; 41stInternational Symposium on Robotics, VDE, 2014, pp. 1\u20138 (cit. on p. 115).[135] S. Kohlbrecher, J. Meyer, T. Graber, K. Petersen, O. von Stryk, and U. Klingauf,\u201cHector Open Source Modules for Autonomous Mapping and Navigation withRescue Robots,\u201d in Proceedings of 17th RoboCup International Symposium, 2013(cit. on p. 116).[136] J. Kuhn, C. Reinl, and O. von Stryk, \u201cPredictive Control for Multi-Robot Ob-servation of Multiple Moving Targets Based on Discrete-Continuous LinearModels,\u201d in Proceedings of the 18th IFAC World Congress, 2011, pp. 257\u2013262 (cit. onp. 116).[137] T. Ritter, J. Euler, S. Ulbrich, and O. von Stryk, \u201cDecentralized Dynamic Data-driven Monitoring of Atmospheric Dispersion Processes,\u201d Procedia ComputerScience, vol. 80, pp. 919\u2013930, 2016 (cit. on p. 116).[138] A. Bemporad and M. Morari, \u201cControl of Systems Integrating Logic, Dynamics,and Constraints,\u201d Automatica, vol. 35, pp. 407\u2013427, 1999 (cit. on p. 116).[139] M. Schmittner, A. Asadi, and M. Hollick, \u201cSEMUD: Secure Multi-hop Device-to-Device Communication for 5G Public Safety Networks,\u201d in IFIP NetworkingConference (Networking\u201917), Stockholm, Sweden, 2017 (cit. on p. 118).[140] T. A. B. Nguyen, C. Meurisch, S. Niemczyk, D. Bo\u00a8hnstedt, K. Geihs, M. Mu\u00a8hlha\u00a8user,and R. Steinmetz, \u201cAdaptive Task-Oriented Message Template for In-NetworkProcessing,\u201d in International Conference on Networked Systems (NetSys\u201917), IEEE,2017, pp. 1\u20138 (cit. on p. 120).[141] C. Meurisch, T. A. B. Nguyen, J. Gedeon, F. Kohnha\u00a8user, M. Schmittner, S. Niem-czyk, S. Wullkotte, and M. Mu\u00a8hlha\u00a8user, \u201cUpgrading Wireless Home Routers asEmergency Cloudlet and Secure DTN Communication Bridge,\u201d in 26th Interna-tional Conference on Computer Communications and Networks (ICCCN\u201917): Posters,IEEE, 2017 (cit. on p. 120).[142] C. Meurisch, T. A. B. Nguyen, S. Wullkotte, S. Niemczyk, Kohnha\u00a8user, andM. Mu\u00a8hlha\u00a8user, \u201cNICER911: Ad-hoc Communication and Emergency ServicesUsing Networking Smartphones and Wireless Home Routers,\u201d in 18th Inter-national Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc\u201917):Poster, ACM, 2017 (cit. on p. 121).[143] A. Jacoff, R. Sheh, A.-M. Virts, T. Kimura, J. Pellenz, S. Schwertfeger, and J.Suthakorn, \u201cUsing Competitions to Advance the Development of Standard TestMethods for Response Robots,\u201d in Proceedings of the Workshop on PerformanceMetrics for Intelligent Systems, ACM, 2012, pp. 182\u2013189 (cit. on p. 121).276Bibliography[144] T. Hossmann, P. Carta, D. Schatzmann, F. Legendre, P. Gunningberg, and C.Rohner, \u201cTwitter in Disaster Mode: Security Architecture,\u201d in ACM SpecialWorkshop on Internet and Disasters, ACM, 2011, p. 7 (cit. on p. 128).[145] E. A. Panaousis, T. A. Ramrekha, C. Politis, and G. P. Millar, \u201cSecure Decen-tralised Ubiquitous Networking for Emergency Communications,\u201d in Interna-tional Conference on Telecommunications and Multimedia (TEMU 2012), IEEE, 2012,pp. 233\u2013238 (cit. on p. 128).[146] M. Puzar, T. Plagemann, and Y. Roudier, \u201cSecurity and Privacy Issues in Middle-ware for Emergency and Rescue Applications,\u201d in Second International Conferenceon Pervasive Computing Technologies for Healthcare (PervasiveHealth 2008), IEEE,2008, pp. 89\u201392 (cit. on p. 128).[147] S. G. Weber, Y. Kalev, S. Ries, and M. Mu\u00a8hlha\u00a8user, \u201cMundoMessage: EnablingTrustworthy Ubiquitous Emergency Communication,\u201d in Proceedings of the 5thInternational Conference on Ubiquitous Information Management and Communication,ACM, 2011, p. 29 (cit. on p. 128).[148] H. Zhu, X. Lin, R. Lu, X. Shen, D. Xing, and Z. Cao, \u201cAn Opportunistic BatchBundle Authentication Scheme for Energy Constrained DTNs,\u201d in IEEE INFO-COM, 2010 (cit. on p. 128).[149] J. Burgess, G. D. Bissias, M. D. Corner, and B. N. Levine, \u201cSurviving Attacks onDisruption-tolerant Networks Without Authentication,\u201d in Proceedings of the 8thACM international symposium on Mobile ad hoc networking and computing (MobiHoc2007), ACM, 2007, pp. 61\u201370 (cit. on pp. 128, 129).[150] A. Kate, G. M. Zaverucha, and U. Hengartner, \u201cAnonymity and Security inDelay Tolerant Networks,\u201d in IEEE SecureComm, IEEE, 2007, pp. 504\u2013513 (cit. onp. 128).[151] D. Ma and G. Tsudik, \u201cSecurity and Privacy in Emerging Wireless Networks[Invited Paper],\u201d IEEE Wireless Communications, 2010 (cit. on p. 128).[152] R. Chen, F. Bao, M. Chang, and J.-H. Cho, \u201cDynamic Trust Management for DelayTolerant Networks and Its Application to Secure Routing,\u201d IEEE Transactions onParallel and Distributed Systems, vol. 25, no. 5, pp. 1200\u20131210, 2014 (cit. on p. 128).[153] H. Zhu, S. Du, Z. Gao, M. Dong, and Z. Cao, \u201cA probabilistic Misbehavior Detec-tion Scheme Toward Efficient Trust Establishment in Delay-tolerant Networks,\u201dIEEE Transactions on Parallel and Distributed Systems, vol. 25, no. 1, pp. 22\u201332,2014 (cit. on p. 128).[154] J. Luo, J.-P. Hubaux, and P. T. Eugster, \u201cDictate: Distributed Certification Au-thority with Probabilistic Freshness for Ad Hoc Networks,\u201d IEEE Transactions onDependable and Secure Computing, vol. 2, no. 4, pp. 311\u2013323, 2005 (cit. on p. 128).[155] Q. Li, W. Gao, S. Zhu, and G. Cao, \u201cTo Lie or to Comply: Defending AgainstFlood Attacks in Disruption Tolerant Networks,\u201d IEEE Transactions on Dependableand Secure Computing, vol. 10, no. 3, pp. 168\u2013182, 2013 (cit. on p. 129).[156] F. C. Lee, W. Goh, and C. K. Yeo, \u201cA Queuing Mechanism to Alleviate FloodingAttacks in Probabilistic Delay Tolerant Networks,\u201d in Sixth Advanced InternationalConference on Telecommunications (AICT 2010), IEEE, 2010, pp. 329\u2013334 (cit. onp. 132).277Bibliography[157] A. Kera\u00a8nen, J. Ott, and T. Ka\u00a8rkka\u00a8inen, \u201cThe ONE Simulator for DTN ProtocolEvaluation,\u201d in Proceedings of the 2nd international conference on simulation toolsand techniques (ICST SIMUTools), 2009, p. 55 (cit. on p. 133).[158] W. Enck, M. Ongtang, and P. McDaniel, \u201cOn Lightweight Mobile Phone Appli-cation Certification,\u201d in Proceedings of the 16th ACM Conference on Computer andCommunications Security, ACM, 2009, pp. 235\u2013245 (cit. on pp. 138, 141, 155).[159] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner, \u201cAndroid PermissionsDemystified,\u201d in Proceedings of the 18th ACM Conference on Computer and Com-munications Security, ACM, 2011, pp. 627\u2013638 (cit. on pp. 138, 141, 142, 155, 159,160).[160] A. Porter Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner, \u201cAndroidPermissions: User Attention, Comprehension, and Behavior,\u201d UC Berkeley, Tech.Rep., 2012 (cit. on pp. 138, 141, 153).[161] L. Davi, A. Dmitrienko, A. Sadeghi, and M. Winandy, \u201cPrivilege Escalation At-tacks on Android,\u201d in Proceedings of the 13th International Conference on InformationSecurity, Springer, 2011, pp. 346\u2013360 (cit. on pp. 138, 141).[162] S. Bugiel, L. Davi, A. Dmitrienko, T. Fischer, A. Sadeghi, and B. Shastry, \u201cTo-wards Taming Privilege-Escalation Attacks on Android,\u201d in Proceedings of the19th Network and Distributed System Security Symposium (NDSS), vol. 17, 2012,p. 19 (cit. on pp. 138, 141).[163] G. Portokalidis, P. Homburg, K. Anagnostakis, and H. Bos, \u201cParanoid Android:Versatile Protection for Smartphones,\u201d in Proceedings of the 26th Annual ComputerSecurity Applications Conference, ACM, Dec. 2010, pp. 347\u2013356 (cit. on p. 138).[164] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N.Sheth, \u201cTaintDroid: An Information-flow Tracking System For Realtime PrivacyMonitoring on Smartphones,\u201d in Proceedings of the 9th USENIX Conference onOperating Systems Design and Implementation, USENIX Association, 2010 (cit. onpp. 138, 141, 144).[165] W. Enck, D. Octeau, P. McDaniel, and S. Chaudhuri, \u201cA Study of AndroidApplication Security,\u201d in Proceedings of the 20th USENIX Conference on Security,2011 (cit. on pp. 138, 142, 146).[166] M. Marlinspike, \u201cMore Tricks For Defeating SSL In Practice,\u201d in Black Hat USA,2009 (cit. on pp. 140, 142).[167] \u2014\u2014, \u201cNew Tricks for Defeating SSL in Practice,\u201d in Black Hat Europe, 2009(cit. on pp. 140, 142).[168] M. Nauman, S. Khan, and X. Zhang, \u201cApex: Extending Android PermissionModel And Enforcement With User-defined Runtime Constraints,\u201d in Proceedingsof the 5th ACM Symposium on Information, Computer and Communications Security,ACM, 2010 (cit. on p. 141).[169] A. Egners, B. Marschollek, and U. Meyer, \u201cMessing with Android\u2019s PermissionModel,\u201d in Proceedings of the IEEE TrustCom, IEEE, 2012, pp. 1\u201322 (cit. on p. 141).[170] T. Vidas, D. Votipka, and N. Christin, \u201cAll Your Droid Are Belong To Us: ASurvey Of Current Android Attacks,\u201d in Proceedings of the 5th USENIX Workshopon Offensive Technologies, 2011, pp. 10\u201310 (cit. on p. 142).278Bibliography[171] A. Shabtai, Y. Fledel, U. Kanonov, Y. Elovici, S. Dolev, and C. Glezer, \u201cGoogleAndroid: A Comprehensive Security Assessment,\u201d Security & Privacy, IEEE,vol. 8, no. 2, pp. 35\u201344, 2010 (cit. on p. 142).[172] W. Enck, M. Ongtang, and P. McDaniel, \u201cUnderstanding Android Security,\u201d inProceedings of the IEEE International Conference on Security & Privacy, IEEE, 2009,pp. 50\u201357 (cit. on p. 142).[173] P. McDaniel and W. Enck, \u201cNot So Great Expectations: Why Application MarketsHaven\u2019t Failed Security,\u201d IEEE Security & Privacy, vol. 8, no. 5, pp. 76\u201378, 2010(cit. on p. 142).[174] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, \u201cHey, You, Get Off of My Market:Detecting Malicious Apps in Official and Alternative Android Markets,\u201d inProceedings of the 19th Annual Network and Distributed System Security Symposium(NDSS 2012), 2012 (cit. on p. 142).[175] D. Shin and R. Lopes, \u201cAn Empirical Study of Visual Security Cues to PreventThe SSLstripping Attack,\u201d in Proceedings of the 27th Annual Computer SecurityApplications Conference, ACM, 2011, pp. 287\u2013296, isbn: 1450306721 (cit. on p. 142).[176] S. Egelman, L. Cranor, and J. Hong, \u201cYou\u2019ve Been Warned: An Empirical Studyof the Effectiveness of Web Browser Phishing Warnings,\u201d in Proceedings of the26th Annual SIGCHI Conference on Human Factors in Computing Systems, ACM,2008, pp. 1065\u20131074 (cit. on pp. 142, 153).[177] J. Sunshine, S. Egelman, H. Almuhimedi, N. Atri, and L. Cranor, \u201cCrying Wolf:An Empirical Study of SSL Warning Effectiveness,\u201d in Proceedings of the 18thUSENIX Security Symposium, 2009, pp. 399\u2013416 (cit. on pp. 142, 153).[178] A. Sotirakopoulos and K. Hawkey, \u201c\u201dI Did it Because I Trusted You\u201d: ChallengesWith The Study Environment Biasing Participant Behaviours,\u201d in Proceedings ofthe 6th Symposium on Usable Privacy and Security, 2010 (cit. on p. 154).[179] A. Sotirakopoulos, K. Hawkey, and K. Beznosov, \u201cOn the Challenges in UsableSecurity Lab Studies: Lessons Learned From Replicating a Study on SSL Warn-ings,\u201d in Proceedings of the 7th Symposium on Usable Privacy and Security, Jul. 2011(cit. on p. 154).[180] F. Maggi, A. Valdi, and S. Zanero, \u201cAndrototal: A Flexible, Scalable Toolbox andService for Testing Mobile Malware Detectors,\u201d in Proceedings of the Third ACMWorkshop on Security and Privacy in Smartphones & Mobile Devices, ACM, 2013,pp. 49\u201354 (cit. on pp. 159, 161).[181] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang, \u201cRiskranker: Scalable andAccurate Zero-day Android Malware Detection,\u201d in Proceedings of the 10th In-ternational Conference on Mobile Systems, Applications, and Services, ACM, 2012,pp. 281\u2013294 (cit. on pp. 159, 160).[182] N. Viennot, E. Garcia, and J. Nieh, \u201cA Measurement Study of Google Play,\u201d inThe 2014 ACM International Conference on Measurement and Modeling of ComputerSystems, ACM, 2014, pp. 221\u2013233 (cit. on pp. 159, 160, 164).[183] J. Kim, Y. Yoon, K. Yi, J. Shin, and S. Center, \u201cScanDal: Static Analyzer forDetecting Privacy Leaks in Android Applications,\u201d in Proceedings of the 2012Workshop on Security Technologies, IEEE, 2012 (cit. on pp. 159, 160).279Bibliography[184] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and A. N.Sheth, \u201cTaintDroid: An Information Flow Tracking System for Real-time PrivacyMonitoring on Smartphones,\u201d ACM Transactions on Computer Systems (TOCS2014), vol. 57, no. 3, pp. 99\u2013106, 2014 (cit. on p. 159).[185] A. Jindal, A. Pathak, Y. C. Hu, and S. Midkiff, \u201cOn Death, Taxes, and SleepDisorder Bugs in Smartphones (HotPower 2013),\u201d in Proceedings of the Workshopon Power-Aware Computing and Systems, Farmington, Pennsylvania: ACM, 2013,pp. 1\u20135 (cit. on p. 159).[186] A. Desnos and G. Gueguen, \u201cAndroid: From Reversing to Decompilation,\u201d inProceedings of Black Hat Abu Dhabi, 2011. [Online]. Available: https://github.com/androguard/androguard (cit. on pp. 160\u2013162).[187] M. Egele, D. Brumley, Y. Fratantonio, and C. Kruegel, \u201cAn Empirical Studyof Cryptographic Misuse in Android Applications,\u201d in Proceedings of the 2013ACM SIGSAC Conference on Computer & Communications Security, ACM, 2013,pp. 73\u201384 (cit. on pp. 160, 173).[188] A. Bartel, J. Klein, M. Monperrus, and Y. le Traon, \u201cStatic Analysis for ExtractingPermission Checks of a Large Scale Framework: The Challenges and Solutionsfor Analyzing Android,\u201d IEEE Transactions on Software Engineering, vol. 40, no. 6,pp. 617\u2013632, Jun. 2014 (cit. on p. 160).[189] Y. Feng, S. Anand, I. Dillig, and A. Aiken, \u201cApposcopy: Semantics-based De-tection of Android Malware Through Static Analysis,\u201d in 2014 Proceedings of the22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineer-ing (FSE), Hong Kong, China: ACM, 2014, pp. 576\u2013587 (cit. on p. 160).[190] E\u00b4. Payet and F. Spoto, \u201cStatic Analysis of Android Programs,\u201d Information andSoftware Technology, vol. 54, no. 11, pp. 1192\u20131201, 2012 (cit. on p. 160).[191] A.-D. Schmidt, R. Bye, H.-G. Schmidt, J. Clausen, O. Kiraz, K. A. Yuksel, S. A.Camtepe, and S. Albayrak, \u201cStatic Analysis of Executables for Collaborative Mal-ware Detection on Android,\u201d in IEEE International Conference on Communications,IEEE, 2009, pp. 1\u20135 (cit. on p. 160).[192] J. Hoffmann, M. Ussath, T. Holz, and M. Spreitzenbarth, \u201cSlicing Droids: Pro-gram Slicing for Smali Code,\u201d in Proceedings of the 28th Annual ACM Symposiumon Applied Computing, ACM, 2013, pp. 1844\u20131851 (cit. on p. 160).[193] L. Weichselbaum, M. Neugschwandtner, M. Lindorfer, Y. Fratantonio, V. van derVeen, and C. Platzer, \u201cAndrubis: Android Malware Under The MagnifyingGlass,\u201d Vienna University of Technology, Tech. Rep. TRISECLAB-0414-001, 2014(cit. on p. 161).[194] L. Ravindranath, S. Nath, J. Padhye, and H. Balakrishnan, \u201cAutomatic andScalable Fault Detection for Mobile Applications,\u201d in 2014 Proceedings of the12th Annual International Conference on Mobile Systems, Applications, and Services(MobiSys), Bretton Woods, New Hampshire, USA: ACM, 2014, pp. 190\u2013203 (cit.on pp. 175, 176).280Bibliography[195] L. Ravindranath, J. Padhye, S. Agarwal, R. Mahajan, I. Obermiller, and S. Shayan-deh, \u201cAppInsight: Mobile App Performance Monitoring in the Wild,\u201d in 2012Proceedings of the 10th USENIX Conference on Operating Systems Design and Imple-mentation (OSDI), Hollywood, CA, USA, 2012, pp. 107\u2013120 (cit. on p. 175).[196] V. Rastogi, Y. Chen, and X. Jiang, \u201cDroidChameleon: Evaluating Android Anti-malware Against Transformation Attacks,\u201d in Proceedings of the 8th ACM SIGSACSymposium on Information, Computer and Communications Security, Hangzhou,China: ACM, 2013, pp. 329\u2013334 (cit. on pp. 175, 181).[197] S. Hao, B. Liu, S. Nath, W. G. Halfond, and R. Govindan, \u201cPUMA: ProgrammableUI-Automation for Large Scale Dynamic Analysis of Mobile Apps,\u201d in Proceed-ings of the 12th Annual International Conference on Mobile Systems, Applications, andServices, ACM, 2014, pp. 204\u2013217 (cit. on pp. 175, 176).[198] Genymobile. (2015). Genymotion, [Online]. Available: http://www.genymotion.com (visited on 02/19/2015) (cit. on pp. 175, 176).[199] Manymo LLC. (2015). Manymo, [Online]. Available: https://www.manymo.com(visited on 02/19/2015) (cit. on pp. 175, 176).[200] Bitbar. (2015). Testdroid, [Online]. Available: http://testdroid.com (visited on02/19/2015) (cit. on pp. 175, 176).[201] W. Enck, P. Gilbert, S. Han, V. Tendulkar, B.-G. Chun, L. P. Cox, J. Jung, P. Mc-Daniel, and A. N. Sheth, \u201cTaintDroid: An Information-Flow Tracking System forRealtime Privacy Monitoring on Smartphones,\u201d ACM Transactions on ComputerSystems (TOCS 2014), vol. 32, no. 2, 5:1\u20135:29, 2014 (cit. on p. 175).[202] D. Wu and R. Chang, \u201cAnalyzing Android Browser Apps for file:// Vulnerabili-ties,\u201d in Information Security, vol. 8783, Springer International Publishing, 2014,pp. 345\u2013363 (cit. on p. 175).[203] A. Pathak, Y. C. Hu, and M. Zhang, \u201cWhere is the Energy Spent Inside my App?Fine Grained Energy Accounting on Smartphones with Eprof,\u201d in Proceedingsof the 7th ACM European Conference on Computer Systems, ACM, 2012, pp. 29\u201342(cit. on p. 175).[204] R. Mittal, A. Kansal, and R. Chandra, \u201cEmpowering Developers to EstimateApp Energy Consumption,\u201d in 2012 Proceedings of the 18th Annual InternationalConference on Mobile Computing and Networking (Mobicom), Istanbul, Turkey: ACM,2012, pp. 317\u2013328 (cit. on p. 175).[205] S. Hao, D. Li, W. G. J. Halfond, and R. Govindan, \u201cEstimating Mobile Applica-tion Energy Consumption Using Program Analysis,\u201d in Proceedings of the 2013International Conference on Software Engineering (ICSE), San Francisco, CA, USA:IEEE, 2013, pp. 92\u2013101 (cit. on p. 175).[206] D. Amalfitano, A. R. Fasolino, P. Tramontana, S. De Carmine, and A. M. Memon,\u201cUsing GUI Ripping for Automated Testing of Android Applications,\u201d in Pro-ceedings of the 27th IEEE/ACM International Conference on Automated SoftwareEngineering, Essen, Germany: ACM, 2012, pp. 258\u2013261 (cit. on pp. 175, 176).281Bibliography[207] G. Hu, X. Yuan, Y. Tang, and J. Yang, \u201cEfficiently, Effectively Detecting MobileApp Bugs with AppDoctor,\u201d in Proceedings of the Ninth European Conference onComputer Systems (EuroSys 2014), Amsterdam, The Netherlands: ACM, 2014,18:1\u201318:15 (cit. on pp. 175, 176).[208] A. Machiry, R. Tahiliani, and M. Naik, \u201cDynodroid: An Input Generation Systemfor Android Apps,\u201d in Proceedings of the 2013 9th Joint Meeting on Foundations ofSoftware Engineering, Saint Petersburg, Russia: ACM, 2013, pp. 224\u2013234 (cit. onp. 175).[209] C.-J. M. Liang, N. Lane, N. Brouwers, L. Zhang, B. Karlsson, R. Chandra, andF. Zhao, \u201cContextual Fuzzing: Automated Mobile App Testing Under DynamicDevice and Environment Conditions,\u201d Microsoft Research, 2013 (cit. on p. 175).[210] M. Bierma, E. Gustafson, J. Erickson, D. Fritz, and Y. R. Choe, \u201cAndlantis: Large-scale Android Dynamic Analysis,\u201d in Proceedings of the 3rd IEEE Mobile SecurityTechnologies Workshop (MoST 2014), IEEE, 2014 (cit. on pp. 175, 176, 179).[211] R. Mahmood, N. Esfahani, T. Kacem, N. Mirzaei, S. Malek, and A. Stavrou, \u201cAWhitebox Approach for Automated Security Testing of Android Applicationson the Cloud,\u201d in 7th International Workshop on Automation of Software Test (AST2012), IEEE, 2012, pp. 22\u201328 (cit. on p. 176).[212] O. Starov and S. Vilkomir, \u201cIntegrated TaaS Platform for Mobile Development:Architecture Solutions,\u201d in 8th International Workshop on Automation of SoftwareTest (AST 2013), IEEE, 2013, pp. 1\u20137 (cit. on p. 176).[213] Perfecto Mobile. (2015). Perfecto Mobile, [Online]. Available: http://www.perfectomobile.com (visited on 02/19/2015) (cit. on p. 176).[214] Keynote. (2015). Mobile Testing, [Online]. Available: http://www.keynote.com/solutions/testing/%5Clinebreak%20mobile-testing (visited on 02/19/2015)(cit. on p. 176).[215] Apkudo. (2015). Apkudo, [Online]. Available: http://www.apkudo.com (visitedon 02/19/2015) (cit. on p. 176).[216] N. Viennot, E. Garcia, and J. Nieh, \u201cA Measurement Study of Google Play,\u201d inACM International Conference on Measurement and Modeling of Computer Systems,ACM, 2014, pp. 221\u2013233 (cit. on pp. 176, 177).[217] B. F. Dolan-Gavitt, J. Hodosh, P. Hulin, T. Leek, and R. Whelan, \u201cRepeatableReverse Engineering for the Greater Good with PANDA,\u201d Technical Report:CUCS-023-14, 2014 (cit. on pp. 176, 179).[218] E. Zitzler, M. Laumanns, L. Thiele, E. Zitzler, E. Zitzler, L. Thiele, and L. Thiele,\u201cSPEA2: Improving the Strength Pareto Evolutionary Algorithm,\u201d TechnicalReport 103, 2001 (cit. on p. 180).[219] S. Garfinkel, PGP: Pretty Good Privacy. O\u2019Reilly Media, 1995 (cit. on p. 203).[220] N. J. Al Fardan and K. G. Paterson, \u201cLucky Thirteen: Breaking the TLS andDTLS Record Protocols,\u201d in IEEE Symposium on Security and Privacy, IEEE, 2013,pp. 526\u2013540 (cit. on p. 203).282Bibliography[221] H. K. Lee, T. Malkin, and E. Nahum, \u201cCryptographic Strength of SSL/TLSServers: Current and Recent Practices,\u201d in 7th ACM SIGCOMM Conference onInternet Measurement, ACM, 2007, pp. 83\u201392 (cit. on p. 203).[222] A. Klein, \u201cAttacks on the RC4 Stream Cipher,\u201d Designs, Codes and Cryptography,vol. 48, no. 3, pp. 269\u2013286, 2008 (cit. on p. 203).[223] M. Stevens, A. Sotirov, J. Appelbaum, A. Lenstra, D. Molnar, D. A. Osvik, andB. De Weger, \u201cShort Chosen-prefix Collisions for MD5 and the Creation of aRogue CA Certificate,\u201d in Advances in Cryptology-CRYPTO 2009, Springer, 2009,pp. 55\u201369 (cit. on p. 203).[224] P. Eckersley and J. Burns, \u201cIs the SSLiverse a Safe Place?\u201d In Chaos CommunicationCongress, https://lb1.eff.org/files/ccc2010.pdf, 2010 (cit. on p. 203).[225] R. Holz, L. Braun, N. Kammenhuber, and G. Carle, \u201cThe SSL Landscape: AThorough Analysis of the X.509 PKI Using Active and Passive Measurements,\u201din ACM SIGCOMM Conference on Internet Measurement, ACM, 2011, pp. 427\u2013444(cit. on p. 203).[226] I. Ristic and M. Small, \u201cA Study of What Really Breaks SSL,\u201d Hack in the Box,vol. http://blog.ivanristic.com/Qualys_SSL_Labs-A_Study_of_Really_Breaks_SSL-HITB_Amsterdam_2011.pdf, May 2011 (cit. on p. 204).[227] Z. Durumeric, J. Kasten, M. Bailey, and J. A. Halderman, \u201cAnalysis of the HTTPSCertificate Ecosystem,\u201d in 2013 Conference on Internet Measurement, ACM, 2013,pp. 291\u2013304 (cit. on p. 204).[228] F. Giesen, F. Kohlar, and D. Stebila, \u201cOn the Security of TLS Renegotiation,\u201d inACM Conference on Computer & Communications Security, ACM, 2013, pp. 387\u2013398(cit. on p. 204).[229] P. Szalachowski, S. Matsumoto, and A. Perrig, \u201cPoliCert: Secure and FlexibleTLS Certificate Management,\u201d in ACM SIGSAC Conference on Computer andCommunications Security, ACM, 2014, pp. 406\u2013417 (cit. on p. 204).[230] M. D. Ryan, \u201cEnhanced Certificate Transparency and End-to-end EncryptedMail,\u201d Proceedings of NDSS 2014, The Internet Society, 2014 (cit. on p. 204).[231] J. Clark and P. C. van Oorschot, \u201cSoK: SSL and HTTPS: Revisiting Past Chal-lenges and Evaluating Certificate Trust Model Enhancements,\u201d in IEEE Sympo-sium on Security and Privacy, IEEE, 2013, pp. 511\u2013525 (cit. on p. 204).[232] L. S. Huang, A. Rice, E. Ellingsen, and C. Jackson, \u201cAnalyzing Forged SSLCertificates in the Wild,\u201d in IEEE Symposium on Security and Privacy, IEEE, 2014,pp. 83\u201397 (cit. on p. 204).[233] C. Brubaker, S. Jana, B. Ray, S. Khurshid, and V. Shmatikov, \u201cUsing Frankencertsfor Automated Adversarial Testing of Certificate Validation in SSL/TLS Imple-mentations,\u201d in IEEE Symposium on Security and Privacy, IEEE, 2014, pp. 114\u2013129(cit. on p. 204).[234] A. Bates, J. Pletcher, T. Nichols, B. Hollembaek, D. Tian, K. R. Butler, and A.Alkhelaifi, \u201cSecuring SSL Certificate Verification through Dynamic Linking,\u201d inACM SIGSAC Conference on Computer and Communications Security, ACM, 2014,pp. 394\u2013405 (cit. on p. 204).283Bibliography[235] S. Fluhrer, I. Mantin, and A. Shamir, \u201cWeaknesses in the Key Scheduling Algo-rithm of RC4,\u201d in Selected Areas in Cryptography, Springer, 2001, pp. 1\u201324 (cit. onp. 207).[236] X. Wang and H. Yu, \u201cHow to Break MD5 and Other Hash Functions,\u201d in Advancesin Cryptology\u2013EUROCRYPT, Springer, 2005, pp. 19\u201335 (cit. on p. 207).[237] A. Popov, \u201cProhibiting rc4 cipher suites,\u201d Computer Science, vol. 2355, pp. 152\u2013164, 2015 (cit. on p. 207).[238] W. Diffie, P. C. Van Oorschot, and M. J. Wiener, \u201cAuthentication and Authenti-cated Key Exchanges,\u201d Design, Codes and Cryptography, vol. 2, no. 2, pp. 107\u2013125,1992 (cit. on p. 207).[239] L. Catuogno and I. Visconti, \u201cAn Architecture for Kernel-Level Verification ofExecutables at Run Time,\u201d Computer Journal, vol. 47, no. 5, pp. 511\u2013526, 117 2004(cit. on pp. 217, 219).[240] M. McKusick and G. Neville-Neil, The Design and Implementation of the FreeBSDOperating System. Addison-Wesley Publishing Company, Reading, MA, 2005(cit. on p. 218).[241] G. Kroah-Hartman, \u201cSigned Kernel Modules,\u201d Linux Journal, pp. 301\u2013308, 1172004 (cit. on p. 219).[242] S. T. King, P. M. Chen, Y.-m. Wang, C. Verbowski, H. J. Wang, and J. R. Lorch,\u201cSubvirt: Implementing Malware with Virtual Machines,\u201d in In IEEE Symposiumon Security and Privacy, IEEE, 2006, pp. 314\u2013327 (cit. on p. 219).[243] T. Garfinkel, B. Pfaff, J. Chow, M. Rosenblum, and D. Boneh, \u201cTerra: a Vir-tual Machine-based Platform for Trusted Computing,\u201d ACM SIGOPS OperatingSystems Review, vol. 37, no. 5, pp. 193\u2013206, 2003 (cit. on pp. 219, 220).[244] T. Garfinkel and M. Rosenblum, \u201cA Virtual Machine Introspection Based Archi-tecture for Intrusion Detection,\u201d in In Proceedings of the Network and DistributedSystems Security Symposium (NDSS 2003), 2003, pp. 191\u2013206 (cit. on pp. 219, 220,231).[245] J. Oberheide, E. Cooke, and F. Jahanian, \u201cCloudAV: N-Version Antivirus in theNetwork Cloud,\u201d in Proceedings of the 17th USENIX Security Symposium, San Jose,USA, 2008 (cit. on p. 220).[246] W. Yan and E. Wu, \u201cToward Automatic Discovery of Malware Signature forAnti-Virus Cloud Computing,\u201d Advanced Threats Research Trend Micro Inc., 2009(cit. on p. 220).[247] M. Laureano, C. Maziero, and E. Jamhour, \u201cIntrusion Detection in VirtualMachine Environments,\u201d in Proceedings of the 30th Euromicro Conference, IEEE,2004, pp. 520\u2013525 (cit. on p. 220).[248] G. Wagener, R. State, and A. Dulaunoy, \u201cMalware Behaviour Analysis,\u201d Journalin Computer Virology, vol. 4, pp. 279\u2013287, 2008 (cit. on p. 223).[249] A. P. Sheth and J. A. Larson, \u201cFederated Database Systems for Managing Dis-tributed, Heterogeneous, and Autonomous Databases,\u201d ACM Computing Surveys(CSUR 1990), vol. 22, no. 3, pp. 183\u2013236, 1990 (cit. on p. 232).284Bibliography[250] I. Botan, Y. Cho, R. Derakhshan, N. Dindar, A. Gupta, L. Haas, K. Kim, C.Lee, G. Mundada, M.-C. Shan, N. Tatbul, Y. Yan, B. Yun, and J. Zhang, \u201cADemonstration of the MaxStream Federated Stream Processing System,\u201d inIEEE 26th International Conference on Data Engineering (ICDE 2010), IEEE, 2010,pp. 1093\u20131096 (cit. on p. 232).[251] Y. H. Harold Lim and S. Babu, \u201cHow to Fit when No One Size Fits,\u201d in Proceedingsof the Biennial Conference on Innovative Data Systems Research (CIDR 2013), 2013(cit. on p. 232).[252] V. Gulisano, R. Jimenez-Peris, M. Patino-Martinez, C. Soriente, and P. Valduriez,\u201cStreamCloud: An Elastic and Scalable Data Streaming System,\u201d IEEE Transac-tions on Parallel and Distributed Systems (TPDS 2012), vol. 23, no. 12, pp. 2351\u20132365, 2012 (cit. on p. 233).[253] M. Sadoghi and H.-A. Jacobsen, \u201cAnalysis and Optimization for Boolean Ex-pression Indexing,\u201d ACM Transactions on Database Systems (TODS 2013), vol. 38,no. 2, 8:1\u20138:47, 2013 (cit. on pp. 233, 245).[254] M. K. Aguilera, R. E. Strom, D. C. Sturman, M. Astley, and T. D. Chandra,\u201cMatching Events in a Content-based Subscription System,\u201d in Proceedings of theSymposium on Principles of Distributed Computing, ACM, 1999, pp. 53\u201361 (cit. onp. 233).[255] S. E. Whang, H. Garcia-Molina, C. Brower, J. Shanmugasundaram, S. Vassilvitskii,E. Vee, and R. Yerneni, \u201cIndexing Boolean Expressions,\u201d Proceedings of the VLDBEndowment, vol. 2, no. 1, pp. 37\u201348, 2009 (cit. on p. 233).[256] A. Forget, S. Komanduri, A. Acquisti, N. Christin, L. F. Cranor, and R. Telang,\u201cBuilding the Security Behavior Observatory: An Infrastructure for Long-termMonitoring of Client Machines,\u201d in Proceedings of the Symposium and Bootcamp onthe Science of Security (HotSos 2014), Raleigh, USA: ACM, 2014, 24:1\u201324:2 (cit. onp. 234).[257] J. Gionta, A. Azab, W. Enck, P. Ning, and X. Zhang, \u201cDACSA: A DecoupledArchitecture for Cloud Security Analysis,\u201d in 7th Workshop on Cyber SecurityExperimentation and Test (CSET 2014), 2014 (cit. on p. 234).[258] D. Srinivasan, Z. Wang, X. Jiang, and D. Xu, \u201cProcess Out-grafting: An Efficient\u201dout-of-VM\u201dApproach for Fine-grained Process Execution Monitoring,\u201d in Pro-ceedings of the Conference on Computer and Communications Security (CCS 2011),ACM, 2011, pp. 363\u2013374 (cit. on p. 234).[259] L. Golab, T. Johnson, J. S. Seidel, and V. Shkapenyuk, \u201cStream Warehousingwith DataDepot,\u201d in Proceedings of the International Conference on Management ofdata (SIGMOD 2009), ACM, 2009, pp. 847\u2013854 (cit. on p. 234).[260] T. Johnson and V. Shkapenyuk, \u201cData Stream Warehousing in Tidalrace,\u201d inProceedings of the Biennial Conference on Innovative Data Systems Research (CIDR2015), 2015 (cit. on p. 234).[261] Z. Cao, S. Chen, F. Li, M. Wang, and X. S. Wang, \u201cLogKV: Exploiting Key-ValueStores for Log Processing,\u201d in Proceedings of the Biennial Conference on InnovativeData Systems Research (CIDR 2013), 2013 (cit. on p. 234).285Bibliography[262] L. Deri, S. Mainardi, and F. Fusco, \u201cTsdb: A Compressed Database for TimeSeries,\u201d in Traffic Monitoring and Analysis, vol. 7189, 2012, pp. 143\u2013156 (cit. onp. 235).[263] H. T. Vo, S. Wang, D. Agrawal, G. Chen, and B. C. Ooi, \u201cLogBase: A Scalable Log-structured Database System in the Cloud,\u201d Proceedings of the VLDB Endowment,vol. 5, no. 10, pp. 1004\u20131015, 2012 (cit. on p. 235).[264] S. Wang, D. Maier, and B. C. Ooi, \u201cLightweight Indexing of Observational Datain Log-Structured Storage,\u201d in Proceedings of the VLDB Endowment, 2014, pp. 529\u2013540 (cit. on pp. 235, 249).[265] A. Ailamaki, D. J. DeWitt, M. D. Hill, and M. Skounakis, \u201cWeaving Relations forCache Performance,\u201d in Proceedings of the International Conference on Very LargeData Bases (VLDB), 2001, pp. 169\u2013180 (cit. on p. 249).[266] M. A. Bender, M. Farach-Colton, J. T. Fineman, Y. R. Fogel, B. C. Kuszmaul, andJ. Nelson, \u201cCache-oblivious Streaming B-trees,\u201d in Proceedings of the Symposiumon Parallel Algorithms and Architectures, ACM, 2007, pp. 81\u201392 (cit. on p. 249).286Curriculum VitaeDiese Seite entha\u00a8lt perso\u00a8nliche Daten. Sie ist deshalb nicht Bestandteil der Online-Vero\u00a8ffentlichung.287",
      "id": 19067252,
      "identifiers": [
        {
          "identifier": "10.17192/z2019.0044",
          "type": "DOI"
        },
        {
          "identifier": "226760451",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:archiv.ub.uni-marburg.de:urn:nbn:de:hebis:04-z2019-0044",
          "type": "OAI_ID"
        }
      ],
      "title": "Secure Communication in Disaster Scenarios",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:archiv.ub.uni-marburg.de:urn:nbn:de:hebis:04-z2019-0044"
      ],
      "publishedDate": "2018-01-01T00:00:00",
      "publisher": "Philipps-Universit\u00e4t Marburg",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://archiv.ub.uni-marburg.de/diss/z2019/0044/pdf/dlb.pdf"
      ],
      "updatedDate": "2022-05-16T13:46:42",
      "yearPublished": 2018,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/226760451.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/226760451"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/226760451/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/226760451/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/19067252"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Pfrommer, Julius"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Beyerer, J."
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/653804052",
        "https://api.core.ac.uk/v3/outputs/425276032"
      ],
      "createdDate": "2021-05-03T03:32:52",
      "dataProviders": [
        {
          "id": 5475,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/5475",
          "logo": "https://api.core.ac.uk/data-providers/5475/logo"
        },
        {
          "id": 11156,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/11156",
          "logo": "https://api.core.ac.uk/data-providers/11156/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "F\u00fcr automatisierte Produktionsanlagen gibt es einen fundamentalen Tradeoff\n\t\t\t\t\t\tzwischen Effizienz und Flexibilit\u00e4t. In den meisten F\u00e4llen sind die Abl\u00e4ufe\n\t\t\t\t\t\tnicht nur durch den physischen Aufbau der Produktionsanlage, sondern auch durch\n\t\t\t\t\t\tdie spezielle zugeschnittene Programmierung der Anlagensteuerung fest\n\t\t\t\t\t\tvorgegeben. \u00c4nderungen m\u00fcssen aufw\u00e4ndig in einer Vielzahl von Systemen\n\t\t\t\t\t\tnachgezogen werden. Das macht die Herstellung kleiner St\u00fcckzahlen unrentabel.\n\t\t\t\t\t\tIn dieser Dissertation wird ein Ansatz entwickelt, um eine automatische\n\t\t\t\t\t\tAnpassung des Verhaltens von Produktionsanlagen an wechselnde Auftr\u00e4ge und\n\t\t\t\t\t\tRahmenbedingungen zu erreichen. Dabei kommt das Prinzip der Selbstorganisation\n\t\t\t\t\t\tdurch verteilte Planung zum Einsatz. Die aufeinander aufbauenden Ergebnisse der\n\t\t\t\t\t\tDissertation sind wie folgt:\n\t\t\t\t\t\t1. Es wird ein Modell von Produktionsanlagen entwickelt, dass nahtlos von der\n\t\t\t\t\t\t   detaillierten Betrachtung physikalischer Produktionsprozesse bis hin zu\n\t\t\t\t\t\t   Lieferbeziehungen zwischen Unternehmen skaliert. Im Vergleich zu\n\t\t\t\t\t\t   existierenden Modellen von Produktionsanlagen werden weniger limitierende\n\t\t\t\t\t\t   Annahmen gestellt. In diesem Sinne ist der Modellierungsansatz ein Kandidat\n\t\t\t\t\t\t   f\u00fcr eine h\u00e4ufig geforderte \"Theorie der Produktion\".\n\t\t\t\t\t\t2. F\u00fcr die so modellierten Szenarien wird ein Algorithmus zur Optimierung der\n\t\t\t\t\t\t   nebenl\u00e4ufigen Abl\u00e4ufe entwickelt. Der Algorithmus verbindet Techniken f\u00fcr die\n\t\t\t\t\t\t   kombinatorische und die kontinuierliche Optimierung: Je nach Detailgrad und\n\t\t\t\t\t\t   Ausgestaltung des modellierten Szenarios kann der identische Algorithmus\n\t\t\t\t\t\t   kombinatorische Fertigungsfeinplanung (Scheduling) vornehmen, weltweite\n\t\t\t\t\t\t   Lieferbeziehungen unter Einbezug von Unsicherheiten und Risiko optimieren und\n\t\t\t\t\t\t   physikalische Prozesse pr\u00e4diktiv regeln. Daf\u00fcr werden Techniken der\n\t\t\t\t\t\t   Monte-Carlo Baumsuche (die auch bei Deepminds Alpha Go zum Einsatz kommen)\n\t\t\t\t\t\t   weiterentwickelt. Durch Ausnutzung zus\u00e4tzlicher Struktur in den Modellen\n\t\t\t\t\t\t   skaliert der Ansatz auch auf gro\u00dfe Szenarien.\n\t\t\t\t\t\t3. Der Planungsalgorithmus wird auf die verteilte Optimierung durch unabh\u00e4ngige\n\t\t\t\t\t\t   Agenten \u00fcbertragen. Daf\u00fcr wird die sogenannte \"Nutzen-Propagation\" als\n\t\t\t\t\t\t   Koordinations-Mechanismus entwickelt. Diese ist von der Belief-Propagation\n\t\t\t\t\t\t   zur Inferenz in Probabilistischen Graphischen Modellen inspiriert. Jeder\n\t\t\t\t\t\t   teilnehmende Agent hat einen lokalen Handlungsraum, in dem er den\n\t\t\t\t\t\t   Systemzustand beobachten und handelnd eingreifen kann. Die Agenten sind an\n\t\t\t\t\t\t   der Maximierung der Gesamtwohlfahrt \u00fcber alle Agenten hinweg interessiert.\n\t\t\t\t\t\t   Die daf\u00fcr notwendige Kooperation entsteht \u00fcber den Austausch von Nachrichten\n\t\t\t\t\t\t   zwischen benachbarten Agenten. Die Nachrichten beschreiben den erwarteten\n\t\t\t\t\t\t   Nutzen f\u00fcr ein angenommenes Verhalten im Handlungsraum beider Agenten.\n\t\t\t\t\t\t4. Es wird eine Beschreibung der wiederverwendbaren F\u00e4higkeiten von Maschinen\n\t\t\t\t\t\t   und Anlagen auf Basis formaler Beschreibungslogiken entwickelt. Ausgehend von\n\t\t\t\t\t\t   den beschriebenen F\u00e4higkeiten, sowie der vorliegenden Auftr\u00e4ge mit ihren\n\t\t\t\t\t\t   notwendigen Produktionsschritten, werden ausf\u00fchrbare Aktionen abgeleitet. Die\n\t\t\t\t\t\t   ausf\u00fchrbaren Aktionen, mit wohldefinierten Vorbedingungen und Effekten,\n\t\t\t\t\t\t   kapseln ben\u00f6tigte Parametrierungen, programmierte Abl\u00e4ufe und die\n\t\t\t\t\t\t   Synchronisation von Maschinen zur Laufzeit.\n\t\t\t\t\t\tDie Ergebnisse zusammenfassend werden Grundlagen f\u00fcr flexible automatisierte\n\t\t\t\t\t\tProduktionssysteme geschaffen -- in einer Werkshalle, aber auch \u00fcber Standorte\n\t\t\t\t\t\tund Organisationen verteilt -- welche die ihnen innewohnenden Freiheitsgrade\n\t\t\t\t\t\tdurch Planung zur Laufzeit und agentenbasierte Koordination gezielt einsetzen\n\t\t\t\t\t\tk\u00f6nnen. Der Bezug zur Praxis wird durch Anwendungsbeispiele hergestellt. Die\n\t\t\t\t\t\tMachbarkeit des Ansatzes wurde mit realen Maschinen im Rahmen des EU-Projekts\n\t\t\t\t\tSkillPro und in einer Simulationsumgebung mit weiteren Szenarien demonstriert",
      "doi": "10.5445/ir/1000131731",
      "downloadUrl": "https://core.ac.uk/download/425276032.pdf",
      "fieldOfStudy": null,
      "fullText": "Distributed Planning for\nSelf-Organizing Production Systems\nZur Erlangung des akademischen Grades\nDoktor der Ingenieurwissenschaften\nvon der KIT-Fakult\u00e4t f\u00fcr Informatik\ndes Karlsruher Instituts f\u00fcr Technologie (KIT)\ngenehmigte\nDissertation\nvon\nDipl.-Wirt.-Ing. Julius Pfrommer\naus Ostfildern\nTag der m\u00fcndlichen Pr\u00fcfung: 22. Juli 2019\nReferent: Prof. Dr.-Ing. habil. J\u00fcrgen Beyerer\nKorreferent: Prof. Dr.-Ing. Michael Weyrich\n\nKurzfassung\nF\u00fcr automatisierte Produktionsanlagen gibt es einen fundamentalen Tradeoff\nzwischen Effizienz und Flexibilit\u00e4t. In den meisten F\u00e4llen sind die Abl\u00e4ufe\nnicht nur durch den physischen Aufbau der Produktionsanlage, sondern auch\ndurch die spezielle zugeschnittene Programmierung der Anlagensteuerung fest\nvorgegeben. \u00c4nderungen m\u00fcssen aufw\u00e4ndig in einer Vielzahl von Systemen\nnachgezogen werden. Das macht die Herstellung kleiner St\u00fcckzahlen unrentabel.\nIn dieser Dissertation wird ein Ansatz entwickelt, um eine automatische\nAnpassung des Verhaltens von Produktionsanlagen an wechselnde Auftr\u00e4ge und\nRahmenbedingungen zu erreichen. Dabei kommt das Prinzip der Selbstorga-\nnisation durch verteilte Planung zum Einsatz. Die aufeinander aufbauenden\nErgebnisse der Dissertation sind wie folgt:\n1. Es wird ein Modell von Produktionsanlagen entwickelt, dass nahtlos von\nder detaillierten Betrachtung physikalischer Produktionsprozesse bis hin\nzu Lieferbeziehungen zwischen Unternehmen skaliert. Im Vergleich zu\nexistierenden Modellen von Produktionsanlagen werden weniger limitie-\nrende Annahmen gestellt. In diesem Sinne ist der Modellierungsansatz\nein Kandidat f\u00fcr eine h\u00e4ufig geforderte \u201cTheorie der Produktion\u201d.\n2. F\u00fcr die so modellierten Szenarien wird ein Algorithmus zur Optimierung\nder nebenl\u00e4ufigen Abl\u00e4ufe entwickelt. Der Algorithmus verbindet Tech-\nniken f\u00fcr die kombinatorische und die kontinuierliche Optimierung: Je\nnach Detailgrad und Ausgestaltung des modellierten Szenarios kann der\nidentische Algorithmus kombinatorische Fertigungsfeinplanung (Sche-\nduling) vornehmen, weltweite Lieferbeziehungen unter Einbezug von\nUnsicherheiten und Risiko optimieren und physikalische Prozesse pr\u00e4-\ndiktiv regeln. Daf\u00fcr werden Techniken der Monte-Carlo Baumsuche (die\nauch bei Deepminds Alpha Go zum Einsatz kommen) weiterentwickelt.\nDurch Ausnutzung zus\u00e4tzlicher Struktur in den Modellen skaliert der\nAnsatz auch auf gro\u00dfe Szenarien.\nii\n3. Der Planungsalgorithmus wird auf die verteilte Optimierung durch un-\nabh\u00e4ngige Agenten \u00fcbertragen. Daf\u00fcr wird die sogenannte \u201cNutzen-\nPropagation\u201d als Koordinations-Mechanismus entwickelt. Diese ist von\nder Belief-Propagation zur Inferenz in Probabilistischen Graphischen\nModellen inspiriert. Jeder teilnehmende Agent hat einen lokalen Hand-\nlungsraum, in dem er den Systemzustand beobachten und handelnd ein-\ngreifen kann. Die Agenten sind an der Maximierung der Gesamtwohlfahrt\n\u00fcber alle Agenten hinweg interessiert. Die daf\u00fcr notwendige Kooperation\nentsteht \u00fcber den Austausch von Nachrichten zwischen benachbarten\nAgenten. Die Nachrichten beschreiben den erwarteten Nutzen f\u00fcr ein\nangenommenes Verhalten im Handlungsraum beider Agenten.\n4. Es wird eine Beschreibung der wiederverwendbaren F\u00e4higkeiten von Ma-\nschinen und Anlagen auf Basis formaler Beschreibungslogiken entwickelt.\nAusgehend von den beschriebenen F\u00e4higkeiten, sowie der vorliegenden\nAuftr\u00e4ge mit ihren notwendigen Produktionsschritten, werden ausf\u00fchrbare\nAktionen abgeleitet. Die ausf\u00fchrbaren Aktionen, mit wohldefinierten\nVorbedingungen und Effekten, kapseln ben\u00f6tigte Parametrierungen, pro-\ngrammierte Abl\u00e4ufe und die Synchronisation von Maschinen zur Laufzeit.\nDie Ergebnisse zusammenfassend werden Grundlagen f\u00fcr flexible automa-\ntisierte Produktionssysteme geschaffen \u2013 in einer Werkshalle, aber auch \u00fcber\nStandorte und Organisationen verteilt \u2013 welche die ihnen innewohnenden Frei-\nheitsgrade durch Planung zur Laufzeit und agentenbasierte Koordination gezielt\neinsetzen k\u00f6nnen. Der Bezug zur Praxis wird durch Anwendungsbeispiele\nhergestellt. Die Machbarkeit des Ansatzes wurde mit realen Maschinen im Rah-\nmen des EU-Projekts SkillPro und in einer Simulationsumgebung mit weiteren\nSzenarien demonstriert.\nAbstract\nThere is a fundamental tradeoff between automation and flexibility in production\nsystems. Large lot sizes can be produced efficiently with automated production\nsystems. Many machines and equipment, like a 5-axis CNC mill, are in principle\ncapable of producing many different kinds of parts. Similarly, (intra-) logistics\nsystems exist for the automated transport and warehousing. Integrating these\nflexible components to an overall production system that is equally flexible has\nbeen prevented by the limits of automation technology in dealing with the ensuing\ncomplexity. Most production processes are rigid not only by way of the physical\nlayout of machines and their integration, but also by the custom programming\nof the control logic for the integration of components to a production systems.\nChanges are time- and resource-expensive. This makes the production of small\nlot sizes of customized products economically challenging.\nThis thesis develops solutions for the automated adaptation of production\nsystems based on self-organisation and distributed planning. The main results\nare the following:\n1. A model of production systems that scales seamlessly from detailed\nphysical process dynamics up to more abstract descriptions of entire\nsupply chains. Compared to existing models of production systems, the\nproposed approach requires less limiting assumptions and also includes\na treatment of concurrency\u2014many productions on many machines in\nparallel and their interaction. In the sense, the proposed model is a\ncandidate for a \u201ctheory of production\u201d.\n2. Based on the model, an algorithm for the optimization of concurrent\nproduction scenarios is proposed. The algorithm combines techniques\nfor combinatorial and continuous optimization. Depending on the level\nfidelity of of the model, the same algorithm can solve combinatorial\nscheduling problems, minimize risk in global supply-chains and control\nphysical production processes. For this, the technique of Monte-Carlo\niv\nTree Search is extended. By exploiting algebraic structure in the models,\nthe approach can be scaled to large scenarios.\n3. The algorithm is further extended to decentralized optimization by in-\ndependent agents. For the coordination between agents, the technique\nof \u201cutility propagation\u201d is developed. Utility propagation is inspired by\nbelief propagation, a well-known technique for inference in probabilistic\ngraphical models. Every agent has a local scope of visibility where can\nfurther influence the actions taking place. For the coordination, it is\nexpected that the scope of the different agents is overlapping. The agents\nare further expected to cooperate, i.e. they are interested to maximize the\noverall welfare that is generated. The coordination between agents is based\non the exchange of messages between neighboring agents. The messages\ndescribe the expected generated welfare conditional to the actions that are\nin the scope of both the sending and the receiving agent.\n4. A formal description of reusable skills of production resources (machines\nand tools) in production systems is developed. By combining the modeled\nskills with a description of the production steps, executable actions are\ngenerated that are described by preconditions and effects. Internally, the\nactions encapsulate all required program logic for the automation and\nthe runtime-synchronization between different machines and tools that\nparticipate in the action.\nIn summary, the results of this work enable future production systems that are\nboth efficient and adaptive. For this the components of the production system\nare enabled to use the degrees of freedom that are available to them. By the use\nof self-organization for the coordination, components of the overall system can\nreact to changes in the system topology and external conditions. The approach\nwas tested in application scenarios\u2014in simulation and in physical production\nsystems. For example as part of the EU-project SkillPro.\nAcknowledgments\nLet me first thank Prof. Dr.-Ing. habil. J\u00fcrgen Beyerer for his mentorship,\nguidance and shared passion for agent-based and distributed systems throughout\nthe development of this thesis. The time at the IES chair and the interactions were\nformative and invaluable. Furthermore I want to thank Prof. Dr.-Ing. Michael\nWeyrich for the discussions and his role as a reviewer of this dissertation.\nFraunhofer IOSB, and particularly the ILT department led by Thomas Usl\u00e4nder,\nwas a great environment to conduct both scientific research leading up this thesis\nand to pursue high-impact engineering projects in the automation environment.\nThe colleagues at IOSB and especially my former group leaders Miriam\nSchleipen and Ljiljana Stojanovic taught me the ropes of the craft of applied\nresearch. This was an experience from which I still profit immensely, now that I\nam also in the position of group leader at Fraunhofer IOSB.\nBesides the results on distributed planning for production control, a \u201cbyprod-\nuct\u201d of this thesis was that it enabled me to contribute to the open62541 open\nsource implementation of the OPC UA standard for industrial communication.\nThis background ensures a clear technological path from the theoretical work\nto the application scenarios. The open62541 development team proved very\ninspirational and productive, so let me thank Florian Palm and Sten Gr\u00fcner,\nProf. Leon Urbas, Chris Iatrou, Stefan Profanter, and Andreas Ebner.\nAnother thank you goes to Joseph Warrington and Georg Schildbach for their\nguidance during my first steps into research during my time at the Automatic\nControl Laboratory at ETH Zurich.\nMost importantly, this thesis would not have been possible without the\nencouragement and support of my family. Ce th\u00e8se n\u2019aurait pas \u00e9t\u00e9 possible\nsans tout ton soutien, Ingrid!\nKarlsruhe, July 2019 Julius Pfrommer\n\nTable of Contents\nKurzfassung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i\nAbstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii\nAcknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . v\nTable of Contents . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\nList of Figures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ix\nList of Tables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xi\nList of Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii\nList of Acronyms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xvii\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 Production and Logistics in a Global Economy . . . . . . . . 1\n1.2 The Structure of Automated Production Systems . . . . . . . . 4\n1.3 Approaches for Flexible Production Systems . . . . . . . . . . 11\n1.4 The Missing Hierarchy of Production Theories . . . . . . . . 16\n1.5 Scientific Contributions and Thesis Organization . . . . . . . 18\n2 A Model of Concurrent Production Systems . . . . . . . . . . . . 25\n2.1 State, Actions and Action Sequences . . . . . . . . . . . . . . 25\n2.2 Parameterized Actions . . . . . . . . . . . . . . . . . . . . . 34\n2.3 Uncertainty and Observations . . . . . . . . . . . . . . . . . . 36\n2.4 Reward and Policies . . . . . . . . . . . . . . . . . . . . . . . 39\nviii Table of Contents\n3 Simulation-Based Planning for Concurrent Production Systems 43\n3.1 Tree Search with Backtracking . . . . . . . . . . . . . . . . . 44\n3.1.1 Background: Trace Theory . . . . . . . . . . . . . . . 44\n3.1.2 Tree-Search with Trace-Based Pruning . . . . . . . . 46\n3.1.3 Evaluation . . . . . . . . . . . . . . . . . . . . . . . 52\n3.2 Planning for Discrete Action Sequences . . . . . . . . . . . . 56\n3.2.1 Background: Monte-Carlo Tree Search . . . . . . . . 57\n3.2.2 Monte-Carlo Tree Search for Discrete Action Sequences 60\n3.2.3 Evaluation . . . . . . . . . . . . . . . . . . . . . . . 62\n3.3 Planning with Uncertainty and Continuous Action Parameters 64\n3.3.1 Background: MCTS under Uncertainty . . . . . . . . 64\n3.3.2 Background: Optimistic Optimization . . . . . . . . . 66\n3.3.3 Planning for Parameterized Action Sequences . . . . . 70\n3.3.4 Evaluation . . . . . . . . . . . . . . . . . . . . . . . 76\n3.4 Planning with Linear Actions . . . . . . . . . . . . . . . . . . 80\n3.4.1 Linear Actions and Action Repetition . . . . . . . . . 80\n3.4.2 MILP Relaxation of the Planning Problem . . . . . . . 84\n3.4.3 Evaluation . . . . . . . . . . . . . . . . . . . . . . . 88\n4 Distributed Planning for Self-Organizing Production Systems . . 91\n4.1 Background: The Generalized Distributive Law . . . . . . . . 92\n4.2 A Model of Distributed Concurrent Production Systems . . . . 96\n4.3 Distributed Planning for Deterministic Action Sequences . . . 102\n4.4 Distributed Planning under Uncertainty . . . . . . . . . . . . 109\n4.5 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n5 Modeling of Production Skills . . . . . . . . . . . . . . . . . . . . 125\n5.1 Background: Skill Models for Production . . . . . . . . . . . 126\n5.2 Background: Description Logics . . . . . . . . . . . . . . . . 128\n5.3 The PPRS Model for Production Skills . . . . . . . . . . . . . 130\n5.4 Assisted Generation of Executable Actions . . . . . . . . . . . 136\n6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\nBibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\nList of Figures\n1.1 The automation hierarchy in discrete manufacturing . . . . . . . . 5\n1.2 Typical automation ontrol hierarchy of a chemical plant. . . . . . . 6\n1.3 Example for a PLC program in ladder logic . . . . . . . . . . . . 7\n1.4 Classes of manufacturing changeability . . . . . . . . . . . . . . 12\n1.5 Decomposition of the automation hierarchy with distributed services 13\n1.6 PROSA reference architecture . . . . . . . . . . . . . . . . . . . 15\n1.7 The model hierarchy in optics . . . . . . . . . . . . . . . . . . . 17\n1.8 Recommended reading order . . . . . . . . . . . . . . . . . . . . 19\n2.1 IRB140 robotic manipulator with inverse kinematics control. . . . 26\n2.2 Minimal scenario for discrete manufacturing . . . . . . . . . . . . 30\n2.3 Sequence tree for Example 2.2. . . . . . . . . . . . . . . . . . . 32\n2.4 P&ID Diagram. . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.1 Dependence Graph and Hasse Diagram . . . . . . . . . . . . . . 46\n3.2 Sequence tree from Example 2.3 before (left) and after the pruning\nof equivalent sequences (right). . . . . . . . . . . . . . . . . . . . 47\n3.3 Outline of a Monte-Carlo Tree Search. . . . . . . . . . . . . . . . 59\n3.4 JSP benchmarks for Monte-Carlo Tree Search . . . . . . . . . . . 63\n3.5 Optimistic Optimization. . . . . . . . . . . . . . . . . . . . . . . 66\n3.6 Example functions that are locally smooth around the optimized for\na semi-metric `. . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n3.7 Partially Observable Hybrid Tree. . . . . . . . . . . . . . . . . . 72\n3.8 The inverted pendulum problem. . . . . . . . . . . . . . . . . . . 76\n3.9 Swingup of an inverted pendulum . . . . . . . . . . . . . . . . . 78\n3.10 Expected reward for different numbers of ordered pencil casings. . 79\n3.11 Convergence speed of the optimization for the order quantity under\nuncertainty example. . . . . . . . . . . . . . . . . . . . . . . . . 79\n3.12 Supply chain example . . . . . . . . . . . . . . . . . . . . . . . . 89\nx List of Figures\n4.1 Factor graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n4.2 Minimal Production Scenario with Agents . . . . . . . . . . . . . 97\n4.3 Conditioned sequence trees of two agents. . . . . . . . . . . . . . 103\n4.4 Autonomous driving example without coordination. . . . . . . . . 123\n4.5 Autonomous driving example with coordination. . . . . . . . . . 124\n5.1 Outline of the relations between the PCM concepts. . . . . . . . . 131\n5.2 Excerpt from a hierarchy of production processes based on DIN 8580.133\n5.3 Architecture of the SkillPro project [Pfr+15b] . . . . . . . . . . . 138\nList of Tables\n2.1 Evolution of the system state for the sequence produce, put, produce, take.\nThe component state s is simplified and describes only the number\nof products currently at the component. All actions are assumed to\nhave a duration of five time units. . . . . . . . . . . . . . . . . . . 33\n3.1 Example JSP problems. . . . . . . . . . . . . . . . . . . . . . . . 53\n3.2 Benchmarking of pruning techniques for DFS and Branch & Bound. 55\n4.1 Reward generated by the actions in the supply-chain example. . . . 116\n5.1 Syntax and Semantics of the EL+\u22a5 Description Logic. . . . . . . . 130\n\nList of Symbols\nGeneral Notation\na, . . . , z Scalar (including tuples) and function mapping to a scalar\nA, . . . , Z Set\nA, . . . ,Z Graph represented by a tuple (V,E) with nodes V and\nedges E \u2286 V \u00d7 V\na, . . . , z Vector or function mapping to a vector. Column vectors\nare constructed as a = (a1, a2, . . . )>.\nA, . . . ,Z Matrix. Constructed as A = [a11 a12; a21 a22] or from\ncolumn vectors as A = [ab].\n0,1 Zero and one column vectors. The size is clear from the\ncontext or explicitly mentioned.\n\u03bdi Basis-vector with zeros and a single one-entry at index i\nGeneral Sets\nZ Set of integers\nN Set of natural numbers (without zero)\nN0 Set of natural numbers (including zero)\nR Set of real numbers\nR+ Set of real positive numbers (including zero)\nxiv List of Tables\nProbability\nP, E Probability, Expectation\nN (\u00b5, \u03c3) Normal distribution with mean \u00b5 and standard deviation\n\u03c3\nU(X) Uniform distribution on the support of set X\n\u223c Distributed according to\na, . . . , z Random variable (scalar)\na, . . . , z Random variable (vectorial)\nProduction System Model\n\u03c1, P Product type, Set of product types\np \u2208 N|P |0 Collection of products, represented by a vector with the\nnumber of products for each product type\nc, C System component, Set of components\ns, S Component state, Set of component states\n\u03c3,\u03a3 Time-indexed resource state, Set of time-indexed resource\nstates\na,A Action, Set of actions\nCa Set of components that participate in the action a\n\u03a3a Feasible initial states for the action a\n\u03b8,\u0398a,\u0398 Action parameter, Parameter space of action a, Parameter\nspace across all actions\no,O Observation, Set of observations\nr : \u03a3\u00d7A\u00d7\u0398\u00d7\n\u03a3\u2192 R\nReward function\nList of Tables xv\nDistributed Production System Model\ni, I Agent, Set of agents\nj \u2208 N(i) Neighbours of agent i\nai \u2208 Ai Action where agent i participates projected to the scope\nof agent i\nCa,i Set of components that participate in action a that are\nalso in the scope of agent i\n\u03a3a,i Feasible initial states for the action a for the components\nthat are in the scope of agent i\nTrace Theory\n[w] The trace of equivalent action sequences generated by the\naction sequence w\nw ' v Action sequences w and v are equivalent\na \u22a5 b Actions a and b are independent\nwk \u227a wl Partial order relation between the elements with indices\nk and l of the sequence w\n\u03c4 Permutation of sequence element indices\nPlanning\nw \u2208 A\u2217 Action sequence with elements wk\n\u03b5 Empty action sequence\nW,W\u03c3 Set of action sequences; Set of possible action sequences\nstarting at state \u03c3.\nWi,W\n\u03c3\ni Set of action sequences for agent i; Set of possible action\nsequences for agent i starting at state \u03c3i.\nxvi List of Tables\nWi |vij Set of possible action sequences for agent i starting at\nstate \u03c3i that project to the sequence vij for the shared\nscope of the agents i and j\nh History of (parameterized) actions and observations. The\nelements are (ak, ok) or (ak, \u03b8k, ok) respectively.\nH Set of possible histories with (parameterized) actions and\nobservations\nhi,hij History projected to the scope of agent i; History projected\nto shared scope of the neighboring agents i and j\nHi Set of possible histories with (parameterized) actions and\nobservations for agent i\n\u03c0 : \u03a3\u2192 A\u00d7\u0398 Policy for observable settings. Maps from the current\nstate to the next action.\n\u03c0 : H \u2192 A\u00d7\u0398 Policy for partially-observable settings. Maps from ob-\nserved histories to the next action.\nv, q V-value and Q-value for the expected reward under opti-\nmal decision making\nmi\u2192j Message send from agent i to a neighbor j \u2208 N(i)\nMiscellaneous\n1[\u03c8] Indicator function (one if \u03c8 is true, zero otherwise)\nn[k],n[k], N [k] Access to a hash-map under the key k. The shown\nnotation is for a scalar, vector or set value respectively.\nIf no value was stored for k prior, n returns a (scalar or\nvectorial) zero or the empty set.\n\u0017 Element-wise comparison of two column-vectors\nList of Acronyms\nAMS Automated Manufacturing System\nB&B Branch and Bound\nBP Belief Propagation\nDL Description Logics\nERP Enterprise Resource Planning\nEWO Enterprise-Wide Optimization\nFMS Flexible Manufacturing System\nGDL Generalized Distributive Law\nJSP Job-Shop Problem\nLNF Lexicographical Normal Form\nMARL Multi-Agent Reinforcement Learning\nMCTS Monte-Carlo Tree Search\nMDP Markov Decision Process\nMES Manufacturing Execution System\nMILP Mixed-Integer Linear Program\nMPC Model Predictive Control\nODE Ordinary Differential Equation\nOEM Original Equipment Manufacturer\nOO Optimistic Optimization\nOPC UA OPC Unified Architecture\nxviii List of Tables\nPOMDP Partially-Observable Markov Decision Process\nPGM Probabilistic Graphical Models\nPLC Programmable Logic Controller\nRL Reinforcement Learning\nSC Situation Calculus\nSCADA Supervisory Control and Data Akquisition\nTT Trace Theory\n1 Introduction\nThere has been a great deal of talk, much of it well founded,\nthat the effect of science on economics and on the economy\nhas not only been very large but that something like a\nsecond industrial revolution is impending. Illustrating this\nare the enormous advances in communications \u2013 physical\nand informational \u2013, advances in automatization and in\nthe domain of information and control, and finally, atomic\nenergy.\nJohn von Neumann [Neu55]\n1.1 Production and Logistics in a Global Economy\nAfter introducing the assembly line for the production of the Model T automobile\nin 1908, Henry Ford sought to make his company self-sufficient. For the supply\nof raw material, his Ford Motor Company bought 700,000 acres of forest,\nrubber plantations, iron and coal mines, and so on. The Ford River Rouge\nComplex near Detroit was designed to transform the incoming raw material\ninto fully assembled cars. The manufacturing operations performed at River\nRouge included coal coking, steel forging, sheet metal stamping, engine casting,\nlumber milling, tire making, the production of sheet glass from molten sand, and\nmany more. All leading up to the final production step: the final car assembly\nin Ford\u2019s assembly line [Bri03]. Since Ford\u2019s only product at the time was\nthe Model T, all production processes were highly specialized to maximize\nefficiency and reduce costs. This made the Model T the most affordable car at the\ntime. Ford\u2019s competitor Chevrolet had a different approach. They used generic\nmanufacturing equipment that could produce parts for several models at the\nsame time. This also enabled frequent updates of the car models. Innovations\nof the 1920s, such as motors with electric starters that require no hand crank, let\nthe Model T appear increasingly outdated. In 1927, Ford finally introduced a\n2 1 Introduction\nsuccessor: the Model A. However, since the production processes were tailored\ntowards the Model T, the changeover proved difficult. The River Rouge site\ncame to standstill for a duration of six months until production could be slowly\nresumed [Hou85]. In the following years, Ford gave up the model of the highly\nintegrated manufacturing site. Today, like all automotive companies, Ford\noperates a range of production sites that are specialized on a range of parts (e.g.\nthe internal combustion engine) that is used for several car models. And also\nthe final assembly lines can switch between car models to adjust to changing\ncustomer demands. All production sites are connected with logistics networks\nand rely heavily on external material and component suppliers.\nFord\u2019s change from an integration manufacturing site to a network of intercon-\nnected production sites is exemplary for the evolution of many manufacturing\nindustries. Initially, customized craft production is replaced by mass production,\nresulting in large efficiency gains and opening up new markets. When the\nmarkets are divided up, companies diversify their product portfolio to cater for\nindividual customer groups. This leads to smaller order sizes, reducing the effi-\nciency of the mass production approach. New methods have been developed to\nenable customization without loosing all the efficiency gains of mass production.\nAmong the most popular ones are Lean Production [Ohn88] (also known as the\nToyota Production System) and the Just in Sequence (JIS) inventory strategy\n[WS11]. They enable production sites to reduce the minimum order size that is\nstill economical to produce. Sometimes lot sizes are reduced to the absolute\nminimum: a single customized product.\nWhile automotive brands rely on a network of suppliers, these relationships\nare relatively stable. Building up the capacity to produce a specific part in\nhigh quantities in the expected quality takes time and investments in automated\nprocesses. This only makes economical sense when years of high demand are\nexpected. For many retail goods, a similar division of labour happens in a\ncomplex supply-chain. But, these relationships can be established and dissolved\nliterally overnight. Cheap long-range shipping, the reduction of tariffs and easy\ncommunication has enabled world-wide supply chains. We will take the example\nof global supply chains in the apparel industry [Ger99]. The supply-chain\nfor a cotton shirt comprises the provider of raw cotton, spinning of the yarn,\ncolor dyeing of the yarn, weaving of the textile, cutting and sewing to make\n1.1 Production and Logistics in a Global Economy 3\nthe shirt, design printing and stitching of brand logos. All of these production\nsteps are typically executed by different companies in different countries. And\nthe supply-chain is dynamically reconfigured for individual orders based on\navailability and price. A shirt bought today may have taken a wholly different\nway around the world than the same shirt bought a week earlier in the same store\n[Chr00]. Many apparel retailers even forego central warehousing for their stores.\nInstead, products are delivered directly from the last link in the supply chain\nto the store. So the retailers do not bind capital in stock for the entire season.\nAnd they can react within weeks to data showing good or bad sales of a specific\nproduct [CM15]. On the downside, most western apparel brands do not control\ntheir supply-chain and rely on sourcing agents from overseas.\nThe biggest sourcing agent is Li&Fung Limited. Operating out of Hong\nKong, Li&Fung self-describes it\u2019s core business as \u201cmanaging the supply chain\nfor high volume, time sensitive goods\u201d [FFW07]. Li&Fung owns no factory,\nwarehouse or inventory and can still source nearly any retail good. Its database\ncontains factories throughout Asia with their support for different manufacturing\nprocesses, available capacity and logistics options, as well as the availability and\nprices of raw material commodity components. Orchestrating the supply chain\nis a profitable business. In 2015, Li&Fung achieved a turnover of $18.8 billion\nand a healthy $2.2 billion profit [Lim15]. The leverage the sourcing agent has\nover the supply chain is seen increasingly critical by companies who rely on\ntheir services. In 2015, Wal-Mart announced a plan to reduce their reliance\nspecifically on Li&Fung. Relying too much on a single provider had become a\nstrategic weakness for the world\u2019s biggest retailer [WS15].\nSo why are dynamic reconfigurations of the supply-chain possible for the\napparel industry, but not for automotive? In the apparel supply-chain, suppliers\nprovide generic access to manufacturing processes that can be used for many\ndifferent customers with little changeover costs and fast production ramp-up.\n\u2022 Standardized commodity goods enable a high degree of automation. For\nexample, the objective of textile plants is to run their power looms with\nas little downtime as possible. The automated equipment allows the\nconfiguration of different product types. For example, a Jacquard loom\ncan configure different weaving patterns. The difference between product\ntypes can be entirely handled by the automated production system.\n4 1 Introduction\n\u2022 On the other end of the spectrum, cutting and sewing of apparel is highly\ndependent on human labour. Lot-sizes are generally smaller and the type\nof product can change drastically between orders (e.g. switching from\njeans to dress shirts). Handling of pliable textile material is difficult for\nautomated equipment and requires custom machines and long changeover\ntimes. This makes automated equipment ineconomical as long as cheap\nhuman labour is available in overseas countries.\nGlobalization and the decentralization of supply chains lead to increased\nrequirements for flexibility in production [Abe+06]. In practice, however,\nflexibility in production is a conflicting goal with efficiency. Automated\nsystems provide the increased efficiency required for mass production. But they\nrequire considerable investment for the initial setup and the changeover between\nproducts. In recent years, many countries with a large industrial base have\nset up research programmes to renew industrial production with the increased\nuse of information processing and communication technology. Among these\nprogrammes are \u201cIndustrie 4.0\u201d in Germany [KWH13], \u201cMade in China 2025\u201d\n[Ken15] in China and \u201cIndustrie du Futur\u201d [FD16] in France. A major part of\nthese efforts is the creation of new automation technology that improves on the\ntradeoff between efficiency and flexibility in production.\n1.2 The Structure of Automated Production Systems\nThe vast majority of control systems for production systems is organized as\na hierarchy. This is true both for discrete manufacturing and continuous\nproduction processes (e.g. chemicals, pharmaceuticals, beverages). Figure 1.1\nshows the automation pyramid, a frame of reference for the hierarchical design\nof most automated systems in discrete manufacturing. Figure 1.2 depicts the\ntypical automation hierarchy from the process industry (e.g. chemicals and\npharmaceuticals). Decisions are made hierarchically and data is aggregated\nmore and more as it is forwarded to the upper levels of the automation hierarchy.\nHierarchical control follows the principle of subsidiarity, where upper levels\nmake high-level decisions that are gradually refined as they are forwarded down\nthe automation hierarchy. Subsidiarity is a necessary consequence of the fact\nthat information is aggregated when it moves up the automation hierarchy.\n1.2 The Structure of Automated Production Systems 5\nEnterprise Level\nPlant Management Level\nOperations Level\nControl Level\nField Level\nC\non\ntr\nol\n D\nec\nis\nio\nns\nD\nat\na \nA\nkq\nui\nsi\ntio\nn\nProcess Level\nERP\nMES\nSCADA\nPLC\nI/O-Signals\nManufacturing Process\nFigure 1.1: The automation hierarchy in discrete manufacturing. The IEC\n62264 / ISA-95 standard does not include the enterprise level. It was added here\nto include interfaces to systems outside the shopfloor.\nThe models used for decision making in the upper levels are more and more\ncoarse and abstract away low-level details. But the low-level details have to\nbe considered eventually. The lower levels in the automation hierarchy takes\ndecisions from one level above and \u201cfill the gaps\u201d.\nIn many systems, the control levels are tightly coupled. Changes to a\ncomponent of a production system usually requires changes in many adjacent\nsystems both vertically and horizontally. The subsystems are interwoven and\nimplicit assumptions about adjacent systems are represented only in custom\ncontrol code. This makes modifications to automated systems costly and\ntime-intensive. Reducing this effort is the focus of an entire research community.\nThe remainder of this section gives an overview on the most important\nplanning and optimization methods for decision-making on the different levels\nof the automation hierarchy. Whilst it is not possible to provide a complete\nenumeration, the examples from this chapter will set the frame for the modeling\nand planning techniques that are introduced later on.\nThe Control Level\nModern control theory and their implementation on computers can be traced back\nto work done at MIT in the 1940s. There, Norbert Wiener first coined the term\n6 1 Introduction\nSupervisory Control\n(Minutes)\nRegulatory Control\n(Seconds)\nC\non\ntr\nol\nLa\nye\nr\nLocal Optimization\n(Hour)\nSite-wide Optimization\n(Day)\nScheduling\n(Weeks)\nFigure 1.2: Typical automation hierarchy of a chemical plant [Sko04].\n\u201ccybernetics\u201d as the conjunction of control and communication [Wie48]. At the\nsame time, project Whirlwind, conducted at Jay Forrester\u2019s Servomechanisms\nLaboratory, developed digital \u201cfeedback control\u201d for numerically controlled\n(NC) manufacturing processes [Rei91]. Both modern Programmable Logic\nControllers (PLCs) and the application of feedback control methods on digital\ncomputers are descendant from this work in a direct lineage. The fundamental\ndifference between the two lies in the type of decisions they have to make.\nProgrammable Logic Controllers (PLC) generally are driven by a state machine\nwith discrete transitions or events. Feedback (optimal) control is mostly\nconcerned with physical systems with continuous dynamics.\nProgrammable Logic Controllers Programmable Logic Controllers [Joh87;\nWal12] (PLC) are directly interfaced with a physical process via sensors\nand actuators. In the automation of discrete manufacturing, PLC couple\nthe physical system with digital control and communication. This coupling\nrequires custom program code to accomodate for the specific details of the\n1.2 The Structure of Automated Production Systems 7\nFigure 1.3: Example for a PLC program in ladder logic\nphysical system and its intended functionality. As the control level often deals\nwith safety-critical functionality, hard bounds on realtime reactiveness have\nto be guaranteed. The IEC-61131 languages [Com93] are standard for PLC\nprogramming and mandate a programming style that is idiomatic to industrial\ncontrollers. Figure 1.3 shows an example for one of the IEC-61131 languages,\nladder logic, which is directly descendent from the analog circuits that were\noriginally used for industrial control before the PLC.\nThe logic coded into a PLC is mostly reactive. Sensor inputs are read and\ntranslated into actuation commands. This loop is repeated at a fast pace\n(many hundred Hertz) for realtime operations. Lengthy planning procedures\ndo not usually fit into the constraints of the control loop in a PLC. The\nIEC-61499 standard is intended as a modernization of IEC-61131 [Vya11]. It\nadds an event-based control flow to the strictly cyclic operations of previous\nPLC generations. But even with IC-61499, PLC-based control is mostly\nreactive. Computationally expensive planning is generally not performed in a\nsafety-critical control environment.\nAutomated production systems typically are integrated from components\nthat come with their own control hardware. The integration requires com-\nmunication between individual controllers and custom control software to\nreact to cyclically transmitted status messages and events. On the control\nlevel, traditional fieldbuses are still common today [Zur14]. Fieldbuses\n8 1 Introduction\nare even mandatory to use if safety-critical functionality relies on digital\ncommunication between controllers or between a PLCs and field devices with\nsensors and actuators. The programming of PLCs is often finished on-site as\npart of the integration of system components. As many automation systems\nare custom solutions, code reuse for PLCs is difficult even if systems are built\nfrom standard components. This leads to a tight coupling that also increases\nthe time required to make changes in an existing system.\nFeedback Control The canonical definition of an optimal control problem is as\nfollows [Lib11]:\nx\u0307 = f(t,x,u), x(t0) = x0 (1.1)\nThe system dynamics is described by an ordinary differential equation (ODE)\nf . The system state at time t is x(t) \u2208 Rn and its evolution depends on\nthe control input u(t) \u2208 Rm. The initial condition is given by x0. A cost\nfunctional for the state evolution assigns costs to the state and control effort\nbetween times t0 and tf and an additional terminal cost on the final state\nx(tf ).\nC(u) =\n\u222b tf\nt0\nL(t,x(t),u(t))dt+K(tf , xf ) (1.2)\nThe problem of optimal control is to compute u\u2217 = arg minu C(u). In\nthis general framework, computing u\u2217 is a variational problem as u is a\n(vectorial) function over time [Lue69]. A popular approach is to discretize\nthe time domain T = {t0, t1, . . . , tf} so that u\u2217 problem of finding the\nsequence of u that minimizes C. Applying the resulting u blindly until tf is\ncalled open-loop control. Repeating the optimization after every time period\nwith updated state information is called Model Predictive Control (MPC) or\nReceding Horizon Control [ML99; Mac02].\nTraditionally, feedback control has be implemented as analog electrical\ncircuits. But these are restricted to relatively simplistic solutions, such as\nPID controllers [Ben93]. With the increase in computational power available\nin control devices, Model Predictive Control (MPC) has become possible\nfor many application. Here, the control problem is stated as an optimization\nproblem that is solved repetitively at a high frequency to incorporate sensor\nmeasurements for \u201cfeedback\u201d control. Optimal control as an optimization\n1.2 The Structure of Automated Production Systems 9\nproblem originates from the association of dynamical system with control\ninput with\nThe Operations Level\nSupervisory Control and Data Acquisition On the operations level, decisions\nare being made with respect to a horizon of minutes or hours. So-called\nSCADA systems (Supervisory Control and Data Acquisition) collect data from\nthe control level, aggregate it and present it to a higher-level decision making\nsystem or a human operator. Some aspects of the lower-level control layer,\nsuch as reactions to safety critical conditions are typically abstracted away.\nSCADA systems are often interfaced directly with the PLC that control the\nprocess. So the possible choices of communication technology are reduced to\nthe capabilities of the PLC. In addition to classical fieldbuses, Ethernet-based\nprotocols are making inroads into factories. The most popular protocol for\nnon-realtime communication on the shopfloor today is OPC UA [MLD09].\nPerformance and Quality Control The supervision of the process performance\nand resulting product quality is performed on the operations level [Jel06].\nThe performance and quality of production processes is generally varying\nover time. The reasons for this are the following: a) an inherent stochasticity\nof the process, b) changes to the input material and semi-finished goods, c)\neffects from changing ambient conditions, such as temperature and humidity,\nd) gradual degradation of the equipment and tools and their maintenance, and\ne) the evolution of the dynamic system state. To illustrate e), take the example\nof a stamping press. The evolution of the dynamic system state could refer\nto an increase in the tool temperature during long uninterrupted production\nruns, or a buildup of residual oil from the metal coating in the stamp tool.\nIt is often up to a skilled process expert to adjust the process parameters at\nruntime to ensure the required performance.\nThe Plant Management Level\nOn the plant management level, an entire shopfloor is considered. Typically the\nplanning horizon is between several hours and several days of operation [She03].\n10 1 Introduction\nScheduling Scheduling theory [Pin08] is concerned with the distribution of\nproduction steps to machines in order to maximize the overall efficiency and\nto reduce costs. The field was active since the early 1960s [GT60] and many\nimportant breakthroughs have been made. Scheduling functionality is often\nsold under names such as Manufacturing Resource Planning (MRP, [Wig81])\nor Advanced Planning and Scheduling (APS). Traditionally, due to the long\nruntime of schedule optimization, updates were being computed at night. If\nthe original plan is disrupted by an unforeseen event, such as a delay or a\nmachine breakdown, the scheduling procedure is restarted or the original plan\nis repaired with appropriate heuristics. Repairing or iterative refinement of\nplans has a long history [HL05]. Modern systems can also perform a full\nrescheduling even during a running shift [VHL03; Dim15].\nMaterial Handling Material handling with uncertain arrival and processing\ntimes is usually modeled using stochastic processes and queuing theory\n[Gro08; Fur18]. Based on such a stochastic queuing system model the\nsystem behaviour can be described. One approach is to compute a steady\nstate occupancy of the queues, for example based on the landmark BCMP\ntheorem [Bas+75]. The discipline of queuing theory is concerned not only\nwith computing steady state occupancy, but also to apply queuing algorithms\n/ network schedulers for customer routing such that the network throughput is\noptimized.\nThe Enterprise Level\nEnterprise Resource Planning Enterprise Resource Planning (ERP) describes\na class of software systems to assist enterprise-wide management [Jac+07].\nThe ERP products with the highest market share are SAP ERP (previously\nSAP/R3) and the Oracle E-Business Suite [Gar18]. In many aspects, ERP\nfunctionality mirrors tasks performed at the plant management level. But the\ntimeframes are generally much longer and several production and warehousing\nsites are jointly considered. Enterprise-wide optimization (EWO) aims at\noptimizing the operations of supply, manufacturing and distribution activities\nof a company to reduce overall costs and inventories [Gro05].\n1.3 Approaches for Flexible Production Systems 11\nSupply-Chain Management Supply-Chain Management (SCM) [Ali05; GF08]\nis concerned with production scenarios that include several layers of suppliers.\nSCM is most common in industries where suppliers are not delivering\nspecialized parts instead of commodity products. The integration with\nsuppliers is often very tight. This enables the reduction of buffer storage at\nthe production site by the use of just-in-time and just-in-sequence delivery.\nThe so-called bullwhip effect [LPW97] describes how small fluctuations in\ncustomer demand lead to large fluctuations in demands at suppliers that are\nseveral tiers removed. A big motivator for digitalisation and information\nsharing in the supply-chain is the reduction of the bullwhip effect by enabling\nbetter forecasts for the suppliers.\n1.3 Approaches for Flexible Production Systems\nThis section discusses approaches to render automated production system\nflexible. The possibility of flexible production is one of the driving motivations\nfor Industrie 4.0 [Wey+14]. This thesis has a scope on automated production.\nOrganizational methods that focus on the human element in production, such as\nLean Manufacturing [Ohn88], are therefore not considered in depth. Several\nauthors have developed frameworks to characterize flexibility in production\nsystems [Bro+84; BS88; GG89; SS90; Ger93; DT98; Wie+07]\nThe scientific literature uses specific terms to describe flexibility in a produc-\ntion context. See Figure 1.4 for a common nomenclature by Wiendahl [Wie+07].\nEven though specific terms exist, the term flexibility is deliberately used with\nits colloquial meaning in this thesis: The models and planning algorithms\ndeveloped in this thesis apply to all level in the automation hierarchy. The\nspecific terms for flexibility from the scientific literature are mostly tied to one\nlevel of the automation hierarchy. We aim to avoid misunderstandings by the\nspecific terms outside of their commonly understood definition.\nService-Oriented Production Systems The principle of service-orientation is\nused in computer science to develop system architectures where components are\nloosely coupled [Mac+06]. A specific service provider can be exchanged as long\nas the interfaces for interaction remain identical and the underlying functionality\n12 1 Introduction\nStation Cell Segment Site Network\nFeature\nWorkpiece\nSubproduct\nProduct\nProduct\nPortfolio\nChange-\nover-\nability\nReconfigurability\nFlexibility\nTransformability\nAgility\nProduction Level\nPr\nod\nuc\ntL\nev\nel\nFigure 1.4: Classes of manufacturing changeability from [Wie+07].\nis still provided. Discovery mechanisms are used to find and select appropriate\nservice providers. In the context of Industrie 4.0, service-orientation is regarded\nas an enabler for future control system architectures that dissolve the classical\nautomation hierarchy. See Figure 1.5 for a popular depiction. The DIN SPEC\n16593-1 standard [DIN18] defines a reference model with basic principles for\nservice-based architectures in the context of Industrie 4.0. This is the common\nbasis for technical realisations to the vision from Figure 1.5.\nA range of research projects has translated service-orientation to production\ncontrol. The authors from the SOCRADES project [JS05; De +08; C\u00e2n+11]\nand Shen et al. [She+07] develop a service-oriented manufacturing system\narchitecture where semantic technologies are used to match possible providers\nof functionality in a manufacturing system. Loskyll et al. [Los+11; Los+12]\nexpand the concept of semantic service discovery to the parameterization and\norchestration of services. For this, they develop a domain-specific ontology for\nthe use in semantic reasoning tools. Puttonen et al. [PLM13] describe a set\nof specialized web services for composing and invoking semantically enriched\nautomated procedures in a manufacturing setting. They also present an algorithm\n1.3 Approaches for Flexible Production Systems 13\nFigure 1.5: Decomposition of the automation hierarchy with distributed services\n[Mes13; Mon14].\nto identify the steps required to reach a predefined goal state. D\u00fcrkop et al.\n[D\u00fcr+14] discuss the use of service-oriented architectures in reconfigurable\nmanufacturing systems (see Figure 1.4 and the technical challenges that need to\nbe overcome. [SZW17] use model-based approach for the service development\nand a modular architecture to reduce the complexity of service-based production\nsystems. [LV15] combine service-oriented manufacturing control with a multi-\nagent architecture. The Smart Factory Web testbed in the Industrial Internet\nConsortium (IIC) uses web services for planning and control in global supply\nchains [Jun+17].\nAgent-Based Production Systems An even more radical departure from\nthe classical automation hierarchy is investigated with agent-based distributed\ncontrol of production systems. Agent-based systems in manufacturing and\nlogistics are the topic of a dedicated research community that has been active\nsince the 1980s [DP87; LS92]. The survey papers [MVK06; LK08; Lei09;\nLMV13; LK15] give an account on the history of agent-based control and\nan overview on the focus of current work. Notably, the IEEE-IES Technical\nCommittee on Industrial Agents (TC-IA1 brings together researchers on an\ninternational level.\n1https://tcia.ieee-ies.org/\n14 1 Introduction\nSoftware frameworks have been developed to assist the development of\nagent-based systems. For example the well-known JADE project [BCG07].\nThe frameworks for software agents, however, do not provide abstractions\nspecifically for the production domain and are used for the development of\ndistributed software systems in general.\nThe core challenge of agent-based control is the coordination of individual\ndecision making across agents. The remainder of this paragraph discusses the\nmost common approaches. A common coordination mechanisms for agent-\nbased control is negotiation [ZR89]. The Contract Net Protocol (CNP) [Smi80]\nreplaces the market with a negotiation scheme in order to decompose and\ndistribute tasks between agents. The CNP has been applied for agent-based\nmanufacturing systems in a range of research projects and industrial installations\n[Par87; LL94; SKB97; Oue+99]. While the CNP is mostly used for greedy\ndecision making, other authors have integrated scheduling theory with agent-\nbased control [SWH06; Agn+14; Bad11] Other coordination mechanisms are\nnature-inspired and derived from the behavior of animals [XL08].\nHolonic production control is a special case of agent-based control. The term\nholon, originally coined in [Koe68], refers to systems made up from components\nthat encapsulates both physical assets and virtual functionality [GLK98; Fis99;\nMB00]. The key idea is that the system components are themselves holons. This\ngoes beyond the usual system-of-systems approach, as holons are self-similar in\nthe sense that the structure and functionality of the constituent parts is governed\nby the same principles as their parent. Taken to its extreme, this self-similarity in\nmanufacturing systems has led to the concept of the fractal factory [War93]. The\nPROSA project has proposed a architecture reference architecture for holonic\nmanufacturing systems [Van+98]. See Figure 1.6 for the building blocks defined\nby PROSA.\nWhat is currently lacking in the field of agent-based and holonic manufacturing\ncontrol are widely used benchmark scenarios to quantitatively compare the\nproposed coordination mechanisms. Compared to other scientific fields, this\nhas led to many competing approaches without a clear winner and uncertainty\non how well the different approaches can cope with aspects outside of their\noriginal scope. For example if unforeseen events are introduced in a stochastic\nenvironment. For practitioners, this has led to an overwhelming range of choices.\n1.3 Approaches for Flexible Production Systems 15\nOrder\nHolon\nProduct\nHolon\nResource\nHolon\nProduct\nknowledge\nProcess\nexecution\nknowledge\nProcess\nknowledge\nFigure 1.6: Building blocks of a holonic manufacturing system according to\nthe PROSA reference architecture [Van+98].\nFor researchers, years of effort have so far not amalgamated into a unified theory\nof agent-based production control.\nPlug and Produce\nThe idea of Plug & Produce is derived from plug-and-play functionality known\nfrom the USB interface for computer hardware. There, well-known device\nclasses with standardized functionality remove the need for custom software\ndrivers for the hardware integration. Arai et al. [Ara+00] first translated plug-\nan-play to the production domain and coined the term Plug & Produce. Onori\net al. [Ono+12] use the concept for a self-configuring assembly system at the\nshop-floor level.\nThe integration of machines and equipment with Plug & Produce encompasses\nthe following aspects: First of all, basic connectivity is established for an\nexisting (industrial) communication infrastructure [D\u00fcr+12; Rei+10]. Second,\nthe new component announces its presence to a central controller or directly\nto the adjacent components with a discovery mechanism [Pro+17]. Third,\nin production, there exists a wide range of machines and equipment. This\nheterogeneity cannot be reduced to a small number of devices classes. A way to\nenable Plug & Work scenarios in the face of device heterogeneity is the use of\nself-descriptions languages for the integration [OHN14; Sch+15a]. The fourth\n16 1 Introduction\nand most challenging aspect is the functional integration. Lepuschitz et al.\n[Lep+11] show reconfiguration of manufacturing resources based on distributed\nIEC 61499 function blocks and a semantic description of the manufacturing\nsetting and the expected behavior.\nMany of the published Plug & Produce implementations use a dedicated\ninterconnector module that acts as a facade for manufacturing equipment and\nprovides a uniform interface and that generates low-level commands for the\nunderlying device [NWS07; Dor+17].\nOne approach for the functional integration in Plug & Produce is the modeling\nof the skills of technical equipment. For this, see the review of the state of the\nart in Chapter 5.\n1.4 The Missing Hierarchy of Production Theories\nScientists and engineers use models on a level of abstraction that is the most\nuseful for the phenomena under investigation [Gie04]. It often occurs that a\nmore accurate model is available in principle. But working with an increased\nlevel of accuracy would overburden the analysis with unnecessary complexity.\nFor example, an electrical engineer laying out the power grid of a city will not\nuse Maxwell\u2019s Equation for a power-flow study. Many technical fields have\narranged these model approaches (theories) in a hierarchy. This hierarchy has\nevolved over time and \u2013 in the natural sciences \u2013 its development is closely\nrelated to the process of scientific discovery [Kuh62; Car84]. As an example,\nFigure 1.7 shows how the model hierarchy established in the field of optics . If\nsome phenomena cannot be explained one can resort to a more detailed (and\ncomputationally or analytically more expensive) model until the first principles\nfrom Maxwell\u2019s Equations and quantum physics are reached [MW59].\nDifferent academic fields have produced \u201cTheories of Production\u201d. For\nexample economics [Sch34; Dan66; She71], business administration [Sch86;\nF\u00e4r88] and production management [Dyc06]. Around the year 2000, prominent\nauthors have called for a unified theory of production that provides a common\nfoundation that integrates existing results [Dyc03; Sch04; WNH10]. Recent\nyears have seen a range of proposals to fulfill this need [NW10; Sch+11;\nSch+15b]. The authors of [Sch+17] provide a comprehensive review and\n1.4 The Missing Hierarchy of Production Theories 17\nRe\nfle\ncti\non\nRe\nfra\ncti\non\nCo\nlo\nr\nDi\nffr\nac\ntio\nn\nPo\nlar\niza\ntio\nn\nKe\nrr\nEff\nec\nt\nFa\nra\nda\ny E\nffe\nct\nCo\nhe\nre\nnc\ne L\nen\ngt\nhs\nRay Optics X X X\nHuygen\u2019s Waves X X X X\nTransverse Waves X X X X X X X\nMaxwell\u2019s Equations X X X X X X X\nQuantum Mechanics X X X X X X X X\nFigure 1.7: The model hierarchy in optics. (Reproduced from http://www.\nargmin.net/2018/01/25/optics.)\nclassification of such production theories. But the cited work remains mostly\nconceptual and does not model the detailed control of automated systems on the\nlower levels of the control hierarchy.\nBy contrasting the model hierarchies in other academic fields with the control\nhierarchy in automation, one could aim for a high-fidelity model at the bottom\nlayers that is abstracted more and more as we go up in the control hierarchy.\nWhile that is the case, we want to stress that the underlying modeling principles\nshould stay the same for all levels of the control hierarchy.\nThe work on a theory of production is not only of academic interest and also\nrelevant to practitioners that have to cope with the increasing complexity of\nproduction systems. Currently, each layer of the control hierarchy works with\ndedicated system models that are tailored for the tasks at hand. But the models\nare so task-specific that they become mutually incompatible. This is problematic\nat vertical as well as horizontal interfaces of the control hierarchy. Assumptions\nabout the behavior of adjacent components are implicit in the custom rules for\nthe interaction between subsystems and encoded in custom control program\ncode. The lack of a common core to translate between subsystems leads to\n18 1 Introduction\nconstant manual effort for system integrators and the loss of flexibility due to\nthe task-specific hard coupling of components.\n1.5 Scientific Contributions and Thesis Organization\nThe original title at the very beginning of the work leading to this thesis was\n\u201cAgent-based production control using the paradigm of self-organisation in the\ncontext of Industrie 4.0\u201d. The path to the final thesis led through scientific fields\nthat are not directly associated with that original title. For example Probabilistic\nGraphical Models, Convex Optimisation, Description Logics, Reinforcement\nLearning, and many more. Some of these detours did not pay off as intended.\nBut many did. While not always visible, the thesis has stayed true to the original\ntopic and the results and techniques from different fields finally tie to together\ninto one body of work.\nThe thesis is organized into six chapters. See Figure 1.8 for an overview\nand recommended reading order. The scientific contributions are closely\nrelated to the thesis structure. In general, prior results are summarized in\ndedicated \u201cbackground\u201d sections. Beyond the background sections, all results\nwith an explicit reference to the literature were developed as part of the thesis\ndevelopment. It follows a summary of the key developments.\nChapter 2: A Model of Concurrent Production Systems A novel model\nrepresentation for production systems is introduced. The goal of the model is to\nprovide a uniform representation of both discrete and continuous production\nprocesses on all levels of the automation hierarchy. To achieve this, the model\ncombines the following aspects:\n\u2022 Seamless scaling from the dynamics of cyber-physical components within\nmachines and equipment up to the orchestration of global supply chains.\n\u2022 Integration of discrete manufacturing (where individual work-pieces are\nconsidered) and process manufacturing (for the production of chemicals,\nbeverages).\n\u2022 Representation of concurrency, i.e. parallelism and the synchronization\nof operations across multiple system components.\n1.5 Scientific Contributions and Thesis Organization 19\n1. Introduction\n2. A Model of\nConcurrent\nProduction Systems\n3. Simulation-Based\nPlanning for Concurrent\nProduction Systems\n4. Distributed Planning\nfor Self-Organizing\nProduction Systems\n5. Modeling of\nProduction\nSkills\n6. Conclusion and Outlook\nFigure 1.8: Structure and recommended reading order of the thesis.\n\u2022 Representation of both deterministic and stochastic scenarios.\nThe following four chapters aim to show that the model representation not\nonly presents a common core for higher-level models but is practical to use in\nflexible production systems. For this, a tailored planning algorithm is developed,\nfurther scaling of planning is achieved by exploiting additional model structure,\nthe planning algorithm is extended to distributed planning by independent agents,\nand finally models of the skills of machines and equipment are used as high-level\nabstraction from which executable low-level representations are derived for\nruntime control.\nChapter 3: Simulation-Based Planning for Concurrent Production Systems\nThe production system model implies a planning problem: maximizing the\nexpected reward that is generated. Existing planning algorithms from the\nproduction domain do not apply to the model from Chapter 2. They make\nlimiting assumptions on the planning problem structure that no longer apply. To\nsolve the planning problem, an algorithm based on Monte-Carlo Tree Search\n(MCTS) is developed.\n20 1 Introduction\n\u2022 Combines MCTS for discrete decision making with Optimistic Optimiza-\ntion (OO) for decision-making on continuous domains.\n\u2022 Requires only forward-simulation (rollout) of the planning scenario.\n\u2022 Additional knowledge about the planning problem can be integrated via\nso-called Rollout Policies. A large class of planning problems is identified\nwhere a relaxation of the planning problem can be solved as a Mixed\nInteger Linear Program (MILP). The solution to the MILP is then used\nfor the Rollout Policy.\n\u2022 The algorithm is shown to solve a wide range of standard benchmark\nproblems after casting them into the model of Chapter 2. The range of\nbenchmark problems considered includes combinatorial decision-making\nin the Jopshop Scheduling Problem (JSP) and optimal control for the\nswing-up of an inverted pendulum.\n\u2022 A large class of models is identified that can be relaxed to a Mixed-Integer\nLinear Program (MILP). This leads to a large improvements for planning\nin scenarios where actions are repeated many times in a row.\nChapter 4: Distributed Planning for Self-Organizing Production Systems\nThe planning complexity depends on the number of individual components that\npartake in the system. By reducing the planning scope to a subset of the system\ncomponents, it is much easier to explore the solution space and converge to good\nsolutions. We develop an algorithm that combines Monte-Carlo Tree Search\nwith Message Passing approaches known from Belief Propagation. Thereby, the\nsystem can be compartmentalized into individual agents who are coordinating\ntheir actions. The agent coordination mechanism is shown to improve the\nplanning solution quality compared to uncoordinated individual planning. The\nsame implementation of our novel planning algorithm can be used the solve\nhitherto separate planning and optimization concerns from all levels of the\nautomation hierarchy.\n\u2022 Combines MCTS with Message-Passing algorithms originally developed\nfor Belief Propagation in Probabilistic Graphical Models.\n1.5 Scientific Contributions and Thesis Organization 21\n\u2022 The agents need to simulate only a small portion of the overall system.\n\u2022 The considered benchmark problems include distributed supply chain\norchestration by independent agents and the distributed maneuver planning\nof autonomous vehicles.\nChapter 5: Modeling of Production Skills In order to achieve flexibility\nin automation with runtime planning, an accurate system model is required.\nIt can be quite resource-intensive to keep the physical system and its model\nrepresentation synchronized. Especially if new manufacturing operations are\nfrequently introduced in a flexible production environment. To reduce this effort,\nhigher-level descriptions are developed from which low-level representations for\nruntime control are generated. We introduce a formal model for the technical\nskills of components in an automated system based on semantic modeling and\ndeductive inference based on second-order logic.\nThe modeled skills are used to generate executable action-representations for\nspecific operations. The generation of executable actions take in as input the\ncapabilities of the system components, the topological layout of the system and\na description of the requested operation. The capability model is therefore used\nas a high-level descriptive language that can be compiled to executable actions\nfor the participating system components. The generated action representations\ncontain all preconditions and effects required for detailed planning.\nAlready published results that were created in preparation for this thesis are:\n\u2022 Julius Pfrommer, Miriam Schleipen, and J\u00fcrgen Beyerer. \u201cF\u00e4higkeiten\nadaptiver Produktionsanlagen\u201d. In: atp-edition 55 (11) (2013)\n\u2022 Julius Pfrommer, Miriam Schleipen, and J\u00fcrgen Beyerer. \u201cPPRS: Pro-\nduction skills and their relation to product, process, and resource\u201d. In:\nProceedings of the 2013 IEEE 18th Conference on Emerging Technologies\n& Factory Automation (ETFA). IEEE. Cagliari, Italy, 2013\n22 1 Introduction\n\u2022 Julius Pfrommer, Denis Stogl, Kiril Aleksandrov, Viktor Schubert, and\nBj\u00f6rn Hein. \u201cModelling and Orchestration of Service-Based Manu-\nfacturing Systems via Skills\u201d. In: Emerging Technologies & Factory\nAutomation (ETFA), 2014 IEEE 19th Conference on. Barcelona, Spain,\nSept. 2014\n\u2022 Julius Pfrommer, Denis Stogl, Kiril Aleksandrov, Stefan Escaida Navarro,\nBj\u00f6rn Hein, and J\u00fcrgen Beyerer. \u201cPlug & produce by modelling skills and\nservice-oriented orchestration of reconfigurable manufacturing systems\u201d.\nIn: at-Automatisierungstechnik 63.10 (2015), pp. 790\u2013800\n\u2022 Selma Azaiez, Michael Boc, Loic Cudennec, Max Da Silva Simoes, Jens\nHaupert, Selma Kchir, Xenia Klinge, Wael Labidi, Karima Nahhal, Julius\nPfrommer, Miriam Schleipen, Christian Schulz, and Thibaud Tortech.\n\u201cTowards Flexibility in Future Industrial Manufacturing: A Global Frame-\nwork for Self-organization of Production Cells\u201d. In: Procedia Computer\nScience 83 (2016), pp. 1268\u20131273\n\u2022 Julius Pfrommer, Sten Gr\u00fcner, Thomas Goldschmidt, and Dirk Schulz.\n\u201cA common core for information modeling in the Industrial Internet of\nThings\u201d. In: at-Automatisierungstechnik 64.9 (2016), pp. 729\u2013741\n\u2022 Sten Gr\u00fcner, Julius Pfrommer, and Florian Palm. \u201cRESTful Industrial\nCommunication With OPC UA\u201d. in: IEEE Transactions on Industrial\nInformatics 12.5 (2016), pp. 1832\u20131841\n\u2022 Julius Pfrommer, Miriam Schleipen, Selma Azaiez, Michael Boc, and Xe-\nnia Kling. \u201cDeploying software functionality to manufacturing resources\nsafely at runtime\u201d. In: Emerging Technologies and Factory Automation\n(ETFA), 2016 IEEE 21st International Conference on. Berlin, Germany:\nIEEE, Sept. 2016, pp. 1\u20137\n\u2022 Julius Pfrommer. \u201cGraphical Partially Observable Monte-Carlo Planning\u201d.\nIn: Workshop on Learning, Inference and Control of Multi-Agent Systems,\nConference on Neural Information Processing Systems (NIPS). Dec. 2016\nThe following publications are our technical reports or publications in adjacent\nfields. They contributed to the thesis indirectly by using similar techniques or\n1.5 Scientific Contributions and Thesis Organization 23\nby working on implementation technologies in industrial automation (e.g. using\ntechnologies such as OPC UA and AutomationML) that are relevant for bringing\nthe results of this thesis into practice.\n\u2022 Julius Pfrommer. Towards Graphical Partially Observable Monte-Carlo\nPlanning. Tech. rep. 2016, pp. 113\u2013125\n\u2022 Julius Pfrommer. Distributed Constraint Optimization over Constrained\nCommunication Topologies. Tech. rep. 2015, pp. 77\u201387\n\u2022 Julius Pfrommer. Information and Control in Cyber-Physical Production\nSystems. Tech. rep. 2014, pp. 61\u201374\n\u2022 Julius Pfrommer, Clemens Zimmerling, Jinzhao Liu, Luise K\u00e4rger, Frank\nHenning, and J\u00fcrgen Beyerer. \u201cOptimisation of manufacturing process\nparameters using deep neural networks as surrogate models\u201d. In: Proceed-\nings of the 51st CIRP Conference on Manufacturing Systems. Stockholm:\nCIRP, 2018\n\u2022 Julius Pfrommer. \u201cSemantic Interoperability at Big-Data Scale with the\nopen62541 OPC UA Implementation\u201d. In: 2nd International Workshop\non Interoperability and Open-Source Solutions for the Internet of Things\n(InterOSS-IoT). Stuttgart, Germany, Nov. 2016\n\u2022 Julius Pfrommer, Sten Gr\u00fcner, and Florian Palm. \u201cHybrid OPC UA\nand DDS: Combining architectural styles for the industrial internet\u201d. In:\nFactory Communication Systems (WFCS), 2016 IEEE World Conference\non. Aveiro, Portugal: IEEE, May 2016, pp. 1\u20137\n\u2022 Thomas Usl\u00e4nder, Julius Pfrommer, and Miriam Schleipen. \u201cDas Internet\nder Dinge in der Automation - Anforderungen und Technologien\u201d. In: 5.\nJahreskolloquium \"Kommunikation in der Automation\" (KommA 2014).\nLemgo, 2014\n\u2022 Julius Pfrommer, Miriam Schleipen, Thomas Usl\u00e4nder, Ulrich Epple,\nRoland Heidel, Leon Urbas, Olaf Sauer, and J\u00fcrgen Beyerer. \u201cBegrif-\nflichkeiten um Industrie 4.0 \u2013 Ordnung im Sprachwirrwarr\u201d. In: Tagungs-\nband zu Entwurf komplexer Automatisierungssysteme (EKA) 2014. Ed. by\nUlrich Jumar and Christian Diedrich. Magdeburg, May 2014\n24 1 Introduction\n\u2022 Julius Pfrommer, Joseph Warrington, Georg Schildbach, and Manfred\nMorari. \u201cDynamic vehicle redistribution and online price incentives\nin shared mobility systems\u201d. In: IEEE Transactions on Intelligent\nTransportation Systems 15.4 (2014), pp. 1567\u20131578\n2 A Model of Concurrent Production Systems\nThe value of [Lagrange\u2019s book \u201cM\u00e9canique Analytique\u201d]\nconsists in the exposition of a general method by which every\nmechanical question may be stated in a single algebraic\nequation. The entire history of any mechanical system, as\nfor example, the solar system, may thus be condensed into a\nsingle sentence.\nRobert S. Woodward [Woo95]\nThe chapter introduces a model for production systems that combines contin-\nuous and discrete system dynamics with concurrency, i.e. parallel operations\nand the synchronization of system components. The model is intended as the\nbasis for a \u201ctheory of production systems\u201d. For this, the model needs to able to\nrepresent the system dynamics on all levels of the control hierarchy. Examples\nfrom different levels of the control hierarchy are used for demonstration and to\nsubstantiate this claim. The core postulate of this chapter is the following:\nThe same set of modeling principles can represent the re-\nlevant properties of production systems on all levels of the\ncontrol hierarchy.\n2.1 State, Actions and Action Sequences\nDefinition 2.1. A system is a set of components c \u2208 C.\nExamples for components on a manufacturing shopfloor are machines and\nlogistics equipment, such as forklifts. Depending on the level of abstraction of\nthe model, components can also represent parts inside a machine, as well as\nentire production plants and warehouses. Assume for now that components do\nnot contain other components in a hierarchy.\n26 2 A Model of Concurrent Production Systems\nDefinition 2.2. Each component c has a state s \u2208 Sc. The set Sc contains all\npossible states of the component c.\nThe global state space S = \u00d7c\u2208CSc is the cartesian product of the possible\nstates for every component. A global state is a vector s \u2208 S with elements sc.\nThe state space of a subset of the components Q \u2286 C is SQ = \u00d7c\u2208QSc. The\nprojection \u03a0Q(s) = (sc : c \u2208 Q) extracts the state of the components Q from\nthe global state. In general, a subscript denoting a set of components indicates\nprojection and sQ = \u03a0Q(s). The inverse projection is \u03a0\u22121Q (sQ) = {u \u2208 S :\n\u03a0Q(u) = sQ }.\nExample 2.1. Consider the ABB IRB140 robotic manipulator from\nFigure 2.1. The green sphere represents the Tool Center Point (TCP). The\nTCP has six degrees of freedom (three each for translation and rotation).\nBut some positions are not reachable due to the physical constraints of the\nmanipulator. The constraints are encoded in the set of reachable positions\n\u03a8 \u2282 R6. In addition, the IRB140 can be fitted with different tools. In this\nexample, the possible tools are \u03a5 = {gripper, welder, drill, none}.\nThe overall state space of the manipulator is Sirb140 = \u03a8\u00d7\u03a5.\nFigure 2.1: IRB140 robotic manipulator with inverse kinematics\ncontrol. The simulation environment V-Rep and the model of\nthe IRB140 robotic manipulator is courtesy of Coppelia Robotics\n(http://www.coppeliarobotics.com/).\nMany manufacturing operations define trajectories where the manipulator\nstarts and finishes at fixed locations. As an alternative to modeling a\n2.1 State, Actions and Action Sequences 27\ncontinuous state space, one can limit the possible positions to a discrete set\nof predefined positions. A continuous configuration space for the position\nis however better suited to model the physical movement dynamics of\nthe robot.\nComponents can change their state over time. The following nomenclature\nis taken from [Fuj98]: Physical time refers to time in the physical system that\nis represented by the model. Simulation time refers to a time representation,\nfor example a real value that corresponds to a physical clock by scaling and an\nepoch-date for the origin. Wallclock time refers to the time when the simulation\nis executed. In distributed systems, it is generally impossible to assign an\nabsolute order to events [Lam78]. We make the simplifying assumption that\nclocks are synchronized to absolute precision. So the physical time of the\nsystem components is always identical. In the model representation, however,\nthe simulation time can differ between components. That is, components can\nevolve their state independently from one another until synchronization forces\ntheir simulation time to coincide again. If not stated otherwise, time refers to\nsimulation time in the remainder of the text.\nDefinition 2.3. The time-indexed state of a component c is\n\u03c3 = (s, t) \u2208 \u03a3c, \u03a3c = Sc \u00d7 R . (2.1)\nIt indicates the state of the component s at time t. The time t represents the\noffset from some epoch-date in seconds.\nThe time-indexed state of the entire system is \u03c3 \u2208 \u03a3 for \u03a3 = \u00d7c\u2208C\u03a3c. In the\ncontext of a system state \u03c3, the time-indexed state of a component c is referred\nto as \u03c3c = (sc, tc). Again, subscript-based notation for projection refers to the\ndefinitions from the surrounding context: \u03a3Q denotes the joint time-indexed\nstate-space for a subset of the components Q \u2286 C and \u03c3Q = \u03a0Q(\u03c3) is the\nprojection of a global time-indexed state into \u03a3Q.\nComponents change their time-indexed state by executing actions. In the\nmodel, actions skip the time-indexed state ahead to the time after the execution.\nComponents have no well-defined state during the execution of an action. If the\n28 2 A Model of Concurrent Production Systems\nmodel is linked to a physical instance of the system, then the relation between\nsimulation time and physical time is as follows. If the time tc of some component\nc is earlier or equal to the physical time, then the component has been idle since\ntc and is immediately available. If tc is later than the physical time, then the\ncomponent is occupied with the execution of one or more actions until tc.\nDefinition 2.4. Actions are possible state transitions, represented as a tuple\na =\n(\nCa, \u03a3\u0304a, ea, da\n)\n. (2.2)\nThe tuple describes the action via its participating components, preconditions\nand effects. It consists of\n\u2022 the participating components Ca \u2286 C,\n\u2022 the feasible initial time-indexed states of the participating components\n\u03a3\u0304a \u2286 \u03a3Ca = (\u00d7c\u2208Ca\u03a3c),\n\u2022 the action effect ea : \u03a3\u0304a \u2192 SCa , where ea,c is the effect for just the\nparticipating component c \u2208 Ca, and\n\u2022 the action duration da : \u03a3\u0304a \u2192 R+.\nThe set of feasible time-indexed initial states \u03a3\u0304a encodes the preconditions\nof the action a for the participating components. The shorthand notation for\nthe state of the participating components is \u03c3a = \u03a0Ca(\u03c3). The feasible global\ninitial states for the action a are \u03a3a = {\u03c3 \u2208 \u03a3 : \u03c3a \u2208 \u03a3\u0304a}. Every action is an\noperator on the time-indexed global state a : \u03a3a \u2192 \u03a3.\nFrom the initial global state \u03c3 it follows that the earliest possible starting\ntime is tstarta (\u03c3a) = maxc\u2208Ca tc for the action a. Let \u03c3\u2032 = a(\u03c3) denote the\nglobal state following the execution. The new global time-indexed state is then\ncomprised of elements\n\u03c3\u2032c =\n\uf8f1\uf8f2\uf8f3\n(\nea,c(\u03c3a), tstarta (\u03c3a) + da(\u03c3a)\n)\n, if c \u2208 Ca\n\u03c3c, else .\n(2.3)\nEquation 2.3 defines the operational semantics of all actions. It implies the\nMarkov assumption: The outcome of an action depends only on the previous\n2.1 State, Actions and Action Sequences 29\nsystem state. Components that are not participating in an action do not partake\nin the preconditions and their state is left unchanged as well.\nEquation 2.3 defines how components with different simulation times are\nsynchronized: The participating component with the highest simulation time\ndefines the starting time of the action. The other participating components idle\nuntil they join the execution.1 The feasible initial states \u03a3a can also encode\npreconditions for the component timing. Consider a physical system whose\ndynamics is described by a differential equation. Such systems typically cannot\nidle without any effect on their state. To adequately cover components that\ncannot idle in the sense of Equation 2.3, the preconditions of \u03a3a can require\nidentical simulation times for all participating components \u2200\u03c3a \u2208 \u03a3a,\u2200(c, c\u2032) \u2208\nCa\u00d7Ca, tc = tc\u2032 . Alternatively, as the effect function ea takes the time-indexed\nstate of all participating components as input, the state evolution of the individual\ncomponents up until the starting time of a can be modeled as part of the effect\nfunction.\nIn discrete manufacturing, the major concern is the movement and transfor-\nmation of products within the system. Many modeling approaches represent\nproducts as objects with individual lifecycles [Sal+10] or even as independent\nagents who negotiate and make independent decisions [KBT17]. To model\nproducts as individual objects, they could be represented as system components\nc. But, in this text, we follow a different approach that enables algorithmic\nimprovements for planning later on.\nLet \u03c1 \u2208 P denote the set of different product types. A product type not\nonly represents marketable output, but also raw material and semi-finished\nwork-pieces that occur between production steps. Products are not considered\nindividually. So products of the same product type are indistinguishable. Instead\nof representing each component individually, it suffices to track the number of\nproducts of each product type present at every component. A product is always\ncontained in some component. Take for example a workpiece mounted inside a\nmachine, a crate of material sitting on a forklift, or a finished product stored in a\nhigh bay warehouse. The following definition is a special case of Definition 2.2\nfor the component state.\n1This corresponds to the use of the popular Max-Plus algebra to describe the time-evolution of\ndiscrete event systems [Bac+92].\n30 2 A Model of Concurrent Production Systems\nDefinition 2.5. Some components can physically contain products. In that case,\nthe component state decomposes into the component configuration \u03be \u2208 \u039ec and\na vector p for the number of contained products for each product type.\ns = (\u03be,p) \u2208 Sc, Sc \u2286\n(\n\u039ec \u00d7 N|P |0\n)\n.\nFor convenience, we denote a vector with just a single product of type \u03c1 as\nthe basis-vector \u03bd\u03c1. The number of products of type \u03c1 in component c is (pc)\u03c1.\nA component c with no contained products has pc = 0, where 0 denotes the\nnull-vector of appropriate dimensionality.\nExample 2.2. This example introduces a minimal manufacturing sce-\nnario that will be used throughout this text. The scenario, shown in\nFigure 2.2, is comprised of a machine tool (mt) that mills piston rods out\nof steel bars, a lattice box (box) and a robotic manipulator that packages\nthe piston rods for transport (manip).\nproduce put take package\nFigure 2.2: Minimal scenario for discrete manufacturing\nFour actions have been defined for the scenario. The actions produce\nand package have only one participating components, the machine tool\nand the manipulator respectively. The actions put and take require the\nparticipation of two components to model the transition of a product\nbetween them. We do not consider single piston rods, but only orders of\n100 parts with the product type order. Every component can only hold\na single order-product at once. Therefore, once the machine tool has\ncompleted an order, the parts need to be put into the lattice box before\nthe next order can be produced. The manipulator then has to take the\n2.1 State, Actions and Action Sequences 31\nparts of the previous order out of the lattice box before the machine tool\ncan put in the next. Products \u201cappear\u201d and \u201cdisappear\u201d when they leave\nthe scope of the modeled system.\nThe complete definition of the action put is as follows:\n\u2022 Cput = {mt, box}\n\u2022 \u03a3\u0304put = {\u03c3put \u2208 \u03a3Cput : pmt = \u03bdorder, pbox = 0}\n\u2022 eput(\u03c3put) = ((\u03bemt,0), (\u03bebox,\u03bdorder))\n\u2022 dput(\u03c3put) = (5s, 5s)\nActions can be chained to form action sequences. The set of actions A is\nthe alphabet for the free monoid (Kleene Star, [HU79]) A\u2217 which contains all\nwords (sequences) of finite length. The empty sequence is written as \u03b5. The\nsequence elements wk are indexed according to their position in the sequence\nw = w1w2 . . . w|w|.\nDefinition 2.6. An action sequence w \u2208 A\u2217 is itself an action resulting from\nthe composition of the constituent actions.\nFor a valid initial state \u03c3 \u2208 \u03a3w (defined in the next paragraph), the resulting\nstate after the execution of w is w(\u03c3) = (w|w| \u25e6 \u00b7 \u00b7 \u00b7 \u25e6 w1)(\u03c3) according to the\ndynamics of action execution from Equation (2.3). The multiplication notation\nfor sequences is preferred to the \u25e6-notation for function composition to keep\nthe notation light, to write the sequence elements in-order, and because we will\ntake on an algebraic perspective on composition later on. Note that, due to the\nway concurrency is represented with the time-indexing of component states, an\naction at a later sequence index may actually start at an earlier simulation time\nthan one of its predecessors in the sequence. But this is possible only if the two\nactions do not share participating components.\nThe subsequence of the first k elements is w:k =\n\u220fk\nl=1 w\nl. The subsequence\nstarting at the kth element is wk: =\n\u220f|w|\nl=k w\nl. The domain of w as an operator\nis \u03a3w =\n{\n\u03c3 \u2208 \u03a3 : \u2200k \u2208 {1, . . . , |w|}, w:k\u22121(\u03c3) \u2208 \u03a3wk\n}\n. This ensures that\nthe preconditions of all actions are satisfied when the sequence is executed in\n32 2 A Model of Concurrent Production Systems\norder. The composition of action operators to a sequence is always possible.\nBut the resulting sequence might be infeasible with an empty domain \u03a3w = \u2205.\nThe set of all action sequences, from now on denoted as W = A\u2217, implies\na tree-graph. In the context of an initial system state \u03c3, infeasible sequences\nare removed from the tree. The feasible sequences starting at \u03c3 are W\u03c3 =\n{w \u2208 A\u2217 : \u03c3 \u2208 \u03a3w}. Obviously, the pruned tree is a subset W\u03c3 \u2286 W and\nis still a tree since for every sequence w \u2208 W\u03c3 all subsequences of the first\nk \u2208 {0, . . . , |w|} elements are also contained w:k \u2208W\u03c3 . After the first action\na has been executed, the system states becomes a(\u03c3) and the sequence tree\nbecomes a(W ) = {w : aw \u2208W}.\nExample 2.3. This example extends the minimal manufacturing scenario\nfrom Example 2.2. Assume an initial system state\u03c3 where no component\ncontains any products. The four defined actions with their preconditions\nand effects yield a sequence tree W\u03c3 of feasible sequences. All feasible\nsequences up to five actions are shown in Figure 2.3.\n\u03b5\nproduce\nput\ntake\nproduce\npackage\n...\nput\n...\npackage\nproduce\n...\nproduce\ntake\npackage\n...\nput\n...\nFigure 2.3: Sequence tree for Example 2.2.\nNote that the order of the actions in the sequence do not require that\nthe start times of the actions have the same ordering. Consider the\n2.1 State, Actions and Action Sequences 33\naction sequence (produce put produce take). The last two actions\nproduce and take can start at the same time. It is even possible that an\naction occurs later in a sequence but starts before a preceding action in\nterms of absolute time.\nk Machine Tool Box Robot\n0 (s = 0, t = 0) (s = 0, t = 0) (s = 0, t = 0)\ufe38 \ufe37\ufe37 \ufe38\nproduce\n\ufe37 \ufe38\ufe38 \ufe37\n1 (s = 1, t = 5) (s = 0, t = 0) (s = 0, t = 0)\ufe38 \ufe37\ufe37 \ufe38\nput\n\ufe37 \ufe38\ufe38 \ufe37\n2 (s = 0, t = 10) (s = 1, t = 10) (s = 0, t = 0)\ufe38 \ufe37\ufe37 \ufe38\nproduce\n\ufe37 \ufe38\ufe38 \ufe37\n3 (s = 1, t = 15) (s = 1, t = 10) (s = 0, t = 0)\ufe38 \ufe37\ufe37 \ufe38\ntake\n\ufe37 \ufe38\ufe38 \ufe37\n4 (s = 1, t = 15) (s = 0, t = 15) (s = 1, t = 15)\nTable 2.1: Evolution of the system state for the sequence\nproduce, put, produce, take. The component state s is simplified\nand describes only the number of products currently at the component.\nAll actions are assumed to have a duration of five time units.\n34 2 A Model of Concurrent Production Systems\nAction sequences can be the result of a planning procedure that are executed\nonly once for the current situation. But sequences can also be used as reusable\nmacro-actions. Many manufacturing systems are organized in lines, within\nwhich work-pieces undergo a fixed sequence of actions. In Example 2.3, the\nsequence (produce put take package) could be such a macro action. System\nparts with little flexibility can thus be modeled with comparatively few macro-\nactions. These can be integrated seamlessly with more fine-grained actions\nwhere more behavioral flexibility is required.\n2.2 Parameterized Actions\nThe action definition from Section 2.1 has been accompanied by examples from\ndiscrete manufacturing. In the process industry (e.g. chemicals, pharmaceuticals,\nfood and beverages), many decisions have to be made on a continuous domain.\nIn principle, the set of actions A could represent continuous decisions with\nan uncountably infinite set of actions. But then we could no longer maintain\nexplicit representations of every action in computer-based simulations. Instead,\nwe allow actions to be parameterized.\nDefinition 2.7. The preconditions, effects and durations of a parameterized\naction a depend on the choice of action parameter \u03b8 \u2208 \u0398a.\na\u03b8 = (Ca, \u03a3\u0304\u03b8a, e\u03b8a, d\u03b8a) (2.4)\nThere are no particular restrictions on possible parameter spaces \u0398a. Of\ncourse, parameters can also be vectorial or sets, even though we use scalar\nnotation for parameters in general. Actions a that do not define parameters\nhave \u0398a = \u2205. In that case, the parameter can be omitted in the notation. The\nfollowing list gives examples for parameters on different scales of measure and\nsizes of the parameter space.\nNominal and Ordinal Parameters In the simplest case, parameterized actions\nsimply group actions that, in some sense, belong together. For example the\naction paint with categorical parameters \u0398paint = {blue, green}. There\ncan also be a natural order among the parameters on an ordinal scale, such as\n{cold, warm, hot}.\n2.2 Parameterized Actions 35\nDiscrete Parameters Discrete parameters (on an interval or ratio scale) can\nindicate for example the number of repetitions of an action. When 5,000\nparts of a certain product are needed, this can then be achieved by an action\nsequence with appropriate parameters in much less than 5,000 sequence\nentries.\nContinuous Parameters Process control (in the sense of control theory [Lib11])\nusually makes decisions about continuous control values at every considered\npoint in time. An example for this is setting a continuous voltage for an\nelectric motor.\nVectorial Parameters An action can take a vector or some other structured\nmathematical object for its parameter. We continue to write action parameters\nas a scalar \u03b8, even though it may be vectorial.\nExample 2.4. Take the example of a storage tank in a process control\nsetting. The tank can be filled with liquid and drained afterward. The\nfill level is controlled by a pump and a valve at the bottom of the tank.\nFigure 2.4: Piping and instrumentation diagram (P&ID) of a storage tank.\n(Reproduced with permission from https://commons.wikimedia.\norg/wiki/File:Pump_with_tank_pid_en.svg.)\nConsider the action drain acting on the tank. Let v \u2208 [0, 1] be\nthe control value for the valve and \u03c4 the duration of the action with\n\u03b8drain = (v, \u03c4). The valve is closed for v = 0 and fully open for v = 1.\nIn addition, the liquid flow depends on the pressure at the valve and\n36 2 A Model of Concurrent Production Systems\nhence the fill level described by the state of the tank stank \u2208 R+. The\nflow of the (incompressible) fluid out of the tank can then be described\nby a differential equation s\u0307tank = g(stank, v) according to Bernoulli\u2019s\nprinciple [Ber38] and stank(t0) is known from the initial state \u03c3drain.\nThe effect of the action drain on the tank is\ne\n(v,\u03c4)\ndrain(\u03c3drain)tank = stank(t0) +\n\u222b t0+\u03c4\nt=t0\ng(stank(t), v)dt .\nWith the introduction of parametric actions, problems from control theory\ncan be represented in the model. In Model Predictive Control (MPC) [ML99],\na dynamical system is approximated by discretizing the time domain. The\nproblem of optimal control is then posed as an explicit optimization problem that\nselects control values for every time period. By taking the (continuous) control\ndecisions as action parameters, optimal control problems can be represented\nwith a single action that encompasses all system components. Control with\nmixed discrete-continuous control values can be represented by either a more\ncomplex parameter-space \u0398 or by representing discrete choices with different\nactions. But only with several actions can aspects of concurrency be represented,\nwhere the system components are synchronized via joint participation in an\naction and evolve their state independently otherwise.\nSo far, the model presented in this chapter unifies the treatment of discrete\nevents, concurrency and continuous system dynamics.\n2.3 Uncertainty and Observations\nUntil now, it was implicitly assumed that actions are deterministic. But\nvirtually no production system actually is. There is always an interaction with a\nstochastic environment, from logistics influenced by weather conditions to the\nhuman operator returning late from a break. In addition, even fully automated\nmanufacturing processes are inherently stochastic. This is illustrated by the\nfact that very few production processes achieve zero-defects production.2 It\n2The most common reasons for delays and unforeseen events are, according to [VHL03], machine\nfailure, urgent job arrival, job cancellation, due date change, shortage or delay in the arrival of\n2.3 Uncertainty and Observations 37\nis desirable to represent this uncertainty also in the model used for control or\nplanning. With an explicit representation of the uncertainty in the evolution of\nthe system state, plans of higher quality can be achieved by optimizing for the\nexpected reward. In general, uncertainty in the model is represented by belief\ndistributions over the system state and actions with probabilistic outcomes.\nThis section uses the notation of [Hem66]: Underlined symbols denote\nrandom variables whose realizations follow some probability distribution. The\nsame symbol may occur underlined and non-underlined. Here, this can be the\ndistinction between a random variable and a sampled realization of the random\nvariable. Another case is the distinction between an action used as an identifier\nand the same action used to sample stochastic state transitions.\nThe system state following an initial state \u03c3 and an action with uncertainty a is\nin effect the realization of a random variable \u03c3\u2032 \u223c \u03c3\u2032 = a(\u03c3). The probability\n(density) of the possible outcomes \u03c3\u2032 \u2208 \u03a3 is P(\u03c3\u2032 = \u03c3\u2032). We allow the\napplication of uncertain states with a belief distribution to actions The resulting\nstate has a belief distributionP(a(\u03c3) = \u03c3\u2032) =\n\u222b\n\u03a3 [P(a(\u03bd) = \u03c3\n\u2032)P(\u03c3 = \u03bd)] d\u03bd.\nWe do not consider the case where a is not applicable to the realization of the\ninitial state \u03c3.\nBy Equation 2.3, non-participating components c /\u2208 Ca are not affected by\nthe action execution. Actions with uncertainty are not exempt from this rule. All\nstate transitions where a non-participating component changes its timed-indexed\nstate via execution of an action a must have zero probability.\n\u2200\u03c3 \u2208 \u03a3a, \u2200\u03c3\u2032 \u2208 \u03a3, \u2200c /\u2208 Ca : \u03c3c 6= \u03c3\u2032c \u21d2 P(a(\u03c3) = \u03c3\u2032) = 0 (2.5)\nIf the state following the execution of an action with uncertainty is not\nimmediately and fully knowable, we have to indirectly infer probabilities over the\nresulting state via incomplete or noisy observations. This is called the partially\nobservable setting [KLC98]. With partial observability, the components c \u2208 C\neach generate observations oc \u2208 Oc. An action results in observations from the\nparticipating components Oa = (\u00d7c\u2208COc). With a slight abuse of notation,\nthe next state and the observations are both drawn by sampling the action\nmaterial, change in job priority, rework or quality problems, over- or underestimation of process\ntime, and operator absenteeism.\n38 2 A Model of Concurrent Production Systems\n(\u03c3\u2032, oa) \u223c a(\u03c3). The distribution of observations conditionally depends on the\naction and the state transition P(oa |\u03c3, a,\u03c3\u2032).\nObviously, for every action a, the observations oa are conditionally indepen-\ndent of the state of components that do not participate in a. Otherwise, if an\nobservation was conditionally dependent on the state of a non-participating\ncomponent, then the observation could depend on the outcome of an action\nthat occurs earlier in the action sequence but actually has a later starting time\nin simulation. This cannot be possible. Therefore, given the state of the\nparticipating components \u03c3a, the resulting state of the participating components\nand the observations are conditionally independent of the non-participating\ncomponents.\n(\u03c3\u2032a, oa |\u03c3a) \u22a5 \u03c3C\\Ca (2.6)\nNow we extend the treatment of uncertainty to action sequences. We write\n\u0398 = \u222aa\u2208A\u0398a for the set of possible action parameters and O = \u222aa\u2208AOa\nfor the set of possible observations. The action-subscript for parameters and\nobservations is dropped when the relation is clear from context.\nDefinition 2.8. A history h is a sequence of episodes hk. Each episode\nconsists of the selected action and action parameters, as well as the generated\nobservation.\nh = a1\u03b81o1\ufe38 \ufe37\ufe37 \ufe38\nh1\na2\u03b82o2\ufe38 \ufe37\ufe37 \ufe38\nh2\n. . . a|h|\u03b8|h|o|h|\ufe38 \ufe37\ufe37 \ufe38\nh|h|\nThe set of possible histories H \u2282 (A\u00d7\u0398\u00d7O)\u2217 implies a tree-graph. The\nhistories in H have finite length. Either because the scenario is done when a\nspecific state is reached or by a cutoff at a maximum history depth. A history h\ncan be appended with the next action a, parameters \u03b8 and observation o to form\nh\u2032 = ha\u03b8o. In the case of a partially observable system, the current system\nstate can only be inferred with uncertainty. Every history yields a probability\ndistribution for the belief over the final system state that is conditioned on the\nobservations. Recall that a\u0303 denotes the already parameterized actions.\n\u03c3\u2032 \u223c h(\u03c3), h(\u03c3) = P\n((\na1 \u03b8\n1\n\u00b7 \u00b7 \u00b7 a|h| \u03b8\n|h|)\n(\u03c3)\n\u2223\u2223\u2223 o1, . . . , o|h|) (2.7)\nThe computation of the belief distribution for the resulting state can be performed\nwith iterative Bayes updates [Jay03] for the intermediary system state between\n2.4 Reward and Policies 39\nactions. The state belief distribution following from an uncertain initial state\nis h(\u03c3). In general, this computation cannot be performed with the available\ncomputational resources. The planning algorithms from the later chapters\ntherefore rely on samples from forward simulations of the system only.\n2.4 Reward and Policies\nSo far, only the dynamics of actions and action sequences were discussed. Now\nwe begin to express preferences between action sequences.\nDefinition 2.9. Executing action a with parameters \u03b8 inducing a transition of\nthe system state from \u03c3 to \u03c3\u2032 generates a reward r(\u03c3, a, \u03b8,\u03c3\u2032). The reward\nfunction is\nr : \u03a3\u00d7A\u00d7\u0398\u00d7 \u03a3\u2192 R . (2.8)\nWith the reward function, each state defines a planning problem with the\ngoal to maximize the future (expected) reward. This is known as the decision-\ntheoretic planning problem [De 70; BDH99]. The following hierarchy of\nplanning problems is distinguished in the literature [LaV06]:\n1. Deterministic sequential decision making in deterministic systems is\nsimply known as the planning problem. It results in a fixed sequence of\nactions.\n2. Sequential decision making under uncertainty with full observability is\nknown as the Markov Decision Problem (MDP, [Put94]).\n3. The partially observable stochastic case is known as Partially-Observable\nMarkov Decision Problem (POMDP) in the literature [SS73; KLC98].\nThe decision maker does not have access to a full description of the system\nstate. He can only indirectly infer a belief distribution over the system\nstate based on incomplete or noisy observations.\nThe application of decision-theoretic planning for the (feedback) control of\ndynamical systems is discussed in [DW91; Ber+95; BG01]. See [LP12] for an\napplication of MDP solvers to model manufacturing scenarios under uncertainty.\nAlgorithms for solving decision-theoretic planning problems belong to two\ndistinct groups, online planning algorithms and policy constructing algorithms.\n40 2 A Model of Concurrent Production Systems\nOnline planning algorithms are executed for the selection of the next action\n[Ros+08; SV10] at runtime. Policy constructing algorithms are executed ahead\nof time. They compute a fixed policy function that takes the current system state\n(or observed history) to the next action [KHL08].\nDefinition 2.10. A policy is a mechanism to select the next action during runtime.\nIn fully observable settings, policies are represented as functions \u03c0 : \u03a3\u2192 A\nthat map from the current system state to the next action. The policy function\nbecomes \u03c0 : \u03a3\u2192 A\u00d7\u0398 in settings with parameterized actions.\nIn POMDP, policies \u03c0 : H \u2192 A or \u03c0 : H \u2192 A\u00d7\u0398 map from the observed\nhistory to the next action. Internally, the POMDP policy may decide the next\naction and parameters based on a belief distribution over the current system\nstate conditioned on the observed history P(\u03c3 \u2208 \u03a3 |h \u2208 H).\nFor simplicity of the exposition, consider fully observable settings without\nparameterized actions. For a fixed policy \u03c0 and a discount rate \u03b3 \u2208 [0, 1), the\nvalue of an initial state \u03c30 is the expected discounted reward.3\nv\u03c0(\u03c30) = E\n[ \u221e\u2211\nk=0\n\u03b3kr(\u03c3k, ak,\u03c3k+1)\n\u2223\u2223\u2223 ak = \u03c0(\u03c3k), \u03c3k+1 \u223c ak(\u03c3k)]\n(2.9)\nAs an alternative to the discount factor, we can limit the number of considered\nperiods. The optimal value of a state v is the expected reward resulting from\noptimal action selection in every step. Based on Bellman\u2019s principle of optimality\n[Bel57], the V-value can be written as a recursive formula.\nv(\u03c3) = max\na\u2208A\nE\n\u03c3\u2032\u223ca(\u03c3)\n[r(\u03c3, a,\u03c3\u2032) + \u03b3v(\u03c3\u2032)] (2.10)\nThe corresponding Q-value is the expected reward for selecting action a in state\n\u03c3 and optimal decision making thereafter.\nq(\u03c3, a) = E\n\u03c3\u2032\u223ca(\u03c3)\n[r(\u03c3, a,\u03c3\u2032) + \u03b3v(\u03c3\u2032)] (2.11)\n3The V-value and Q-value are longstanding terms in the literature. As both are scalar values we\ndenote them as v and q in the mathematical notation.\n2.4 Reward and Policies 41\nSelecting a value according to maxa\u2208A q(\u03c3, a) is the optimal policy. But\ncomputing the optimal policy is generally computationally intractable. The\nremainder of this thesis is concerned with ways of rendering optimization and\nplanning in the framework introduced in this chapter computationally feasible.\nThis is achieved a) with tailored planning algorithms, b) so-called rollout policies\nthat exploit known structure in the planning problem and c) the decomposition\nof the planning problem into a coupled set of smaller problems that are jointly\noptimized by cooperating agents.\n\n3 Simulation-Based Planning for Concurrent\nProduction Systems\nProgramming, or program planning, may be defined as the\nconstruction of a schedule of actions by means of which an\neconomy, organisation, or other complex of activities may\nmove from one defined state to another, or from a defined\nstate toward some specifically defined objective.\nMarshal K. Wood and George B. Dantzig [WD51]\nThe model from Chapter 2 is generic and can be used to represent many\ntypes of systems. Very little constraints are imposed on the system dynamics\nthat can be represented. This chapter develops an algorithm for sequential\ndecision making that does not make additional limiting assumptions. But this\nrichness with respect to possible system dynamics is a drawback when it comes\nto planning. Most planning algorithms impose a much more limited model\nstructure they exploit to reduce the computational effort. The core postulate of\nthis chapter is the following:\nThe same algorithm can be used for planning and runtime\ncontrol on all levels of the control hierarchy \u2013 ranging from\ncontinuous dynamics of a physical system to global supply-\nchain operations \u2013 and for both continuous and discrete\nproduction.\nThis chapter develops a planning algorithm for the full model from Chapter 2\nwithout additional assumptions. In the first two sections, two techniques are\nused to reduce the number of action sequences that are visited for planning\n44 3 Simulation-Based Planning for Concurrent Production Systems\nwith action sequences in deterministic scenarios. In Section 3.1 the search\ntree is explicitly pruned by removing equivalent action sequences (this will\nhave a precise definition). Section 3.2 further speeds up planning by implicitly\npruning less promising parts of the search tree via Monte-Carlo Tree Search\n(MCTS). Section 3.3 extends planning to the full model with parametric actions\nand uncertainty with partial observability. In order to scale to larger scenarios,\nSection 3.4 develops a custom rollout policy that uses a relaxation of the planning\nproblem to a Mixed-Integer Linear Program (MILP).\n3.1 Tree Search with Backtracking\nThe model from Chapter 2 can represent concurrency, i.e. parallelism and the\nsynchronization of system components. A consequence of the model is that\nmany action sequences are equivalent with respect to their overall preconditions\nand effects.\nExample 3.1. Take the scenario from Example 2.2 with the modifi-\ncation that the robotic manipulator initially contains a product. The\nactions produce and package do not share a participating compo-\nnent as Cproduce = {mt} and Cpackage = {manip}. It is easy to see\nthat the sequence (produce package) is equivalent to the sequence\n(package produce) in terms of their preconditions and effects. In that\nsense, the two actions are independent from each other.\nThis notion of action sequence equivalence is made rigorous based on\nestablished results from Trace Theory (TT) [CF69; Maz77]. The theoretical\nprerequisites are summarized in the following. Full proofs can be found in\n[DM97a]. Some elementary definitions from Group Theory [DF04] are assumed\nas known.\n3.1.1 Background: Trace Theory\nPrevious nomenclature from Chapter 2 applies to TT by taking A as a set of\nletters of action-identifiers that are concatenated to words corresponding to\naction sequences. Let A be a finite alphabet of letters and A\u2217 the set of all\n3.1 Tree Search with Backtracking 45\nfinite-length words over A. The composition of letters forms a free monoid with\ngenerating set A and the empty word, denoted \u03b5, as the unit element. Some\nletters commute and are said to be mutually independent. This is captured\nin the set of independence relations Z \u2286 A \u00d7 A. Independence relations are\nsymmetric (a, b) \u2208 Z \u21d2 (b, a) \u2208 Z and irreflexive \u2200a \u2208 A, (a, a) /\u2208 Z. We\nalso write a \u22a5Z b to denote independence between a and b. From Z follows\nan equivalence relation between words 'Z : two words w and v from A\u2217 are\nequivalent according to 'Z if v is a permutation of w that can be reached\nby successive reordering of adjacent elements that commute according to Z.\nIn algebraic terms, the trace monoid M(A,Z) is the quotient of A\u2217 by the\ncongruence 'Z . Its elements, called traces, are pairwise disjoint subsets of A\u2217.\nEach trace contains the words that are mutually equivalent according to 'Z .\nLet [w]Z denote the trace generated from the word w. We can now rephrase\nequivalency as w and v generating the same trace w 'Z v \u21d4 [w]Z = [v]Z .\nWhen it is clear from context which independence relations apply, we simply\nwrite [w] for the trace and w ' v to denote equivalence.\nThe independence relations define a partial order between some of the letters\nin a word. This partial order is a \u201cmust appear before\u201d binary relation \u227a.\nwk \u227a wl \u21d4 k < l \u2227 \u00ac(wk \u22a5 wl) (3.1)\nThe transformation between equivalent words w ' v is described by a permuta-\ntion of the element indices \u03c4 . The partial order of the word elements is invariant\nto this permutation and therefore\n\u2200k, l \u2208 {1, . . . , |w|}, wk \u227a wl \u21d2 v\u03c4(k) \u227a v\u03c4(l) . (3.2)\nThe partial order yields the same dependence graph and Hasse diagram for every\nword from the same trace.1 The dependence graph G = (V,E) is a directed\nacyclic graph with nodes V = {w1, . . . , w|w|} and edges E = {(w, v) \u2208 V 2 :\nw \u227a v}. The Hasse diagram G\u2032 = (V,E\u2032) is the dependence graph with\nredundancies removed E\u2032 = {(w, v) \u2208 E : @u, w \u227a u \u227a v}. See Figure 3.1\nfor an example.\n1Graphs being equal refers to the existence of an isomorphism between the graphs that takes\nnode labels into account.\n46 3 Simulation-Based Planning for Concurrent Production Systems\na b a\nc\nd\ne\na b a\nc\nd\ne\nFigure 3.1: The Dependence Graph (left) and Hasse Diagram\n(right) for the trace [abcaed] according to the trace monoid M(A,Z)\nover the alphabet A = {a, b, c, d, e} and independencies Z =\n{(a, c), (c, a), (b, d), (d, b), (d, e), (e, d)}.\nBesides their dependence graph and Hasse diagram, traces are uniquely\nrepresented by a word in a normal form. That is, exactly one word from every\ntrace is in the normal form. There exist several normal forms with this property.\nWe consider the Lexicographical Normal Form (LNF): Assume a total ordering\nof the letters A and a resulting lexicographical ordering over words. Longer\nwords have a larger order than smaller words regardless of their elements. For\ntwo words w,v of the same length, w < v if wk < vk for the smallest index k\nwhere wk 6= vk. A word is in LNF if it has the smallest lexicographical order\namong all words of the trace.\n3.1.2 Tree-Search with Trace-Based Pruning\nWith the prerequisites in place, we now take a look back at Chapter 2. Remember\nthat action sequences are operators on the system state with defined preconditions\n(the operator domain) and effects.\nDefinition 3.1. Two action sequences w and v are equivalent w ' v if they\nhave the same domain of initial states \u03a3w = \u03a3v and yield identical results\n\u2200\u03c3 \u2208 \u03a3w, w(\u03c3) = v(\u03c3).\nThe independence of actions is defined based on the possibility to commute\nthem if they occur in adjacent positions in any action sequence.\nDefinition 3.2. Two actions a and b are independent a \u22a5 b if commuting them\nyields an equivalent sequence \u2200w,v \u2208 A\u2217, wabv ' wbav \u21d4 a \u22a5 b.\nIt is generally intractable to show the equivalence of two action sequences\nby enumerating the set of valid initial system states and the effect of the action\n3.1 Tree Search with Backtracking 47\nsequence on those states. For some action pairs however, independence can be\nshown without evaluating the preconditions and effects:\nProposition 3.3. Any two actionsa, b that do not share a participating component\nare independent.\nCa \u2229 Cb = \u2205\u21d2 a \u22a5 b (3.3)\nProof. For all action sequences w,v there must be wabv equivalent to wbav.\nThis follows directly from the operational semantics of actions defined in\nEquation 2.3.\nExample 3.2. Figure 3.2 shows which sequences from Example 2.3 are\nequivalent and can be pruned. Only the sequences up to a length of five\nare shown. The initial lexicographic ordering of the actions for the LNF\nis produce < put < take < package.\n\u03b5\nproduce\nput\ntake\nproduce\npackage\n...\nput\n...\npackage\nproduce\n...\nproduce\ntake\npackage\n...\nput\n...\n\u03b5\nproduce\nput\ntake\npackage\nproduce\ntake\npackage\n...\nput\n...\nFigure 3.2: Sequence tree from Example 2.3 before (left) and after the\npruning of equivalent sequences (right).\nSome sequences may additionally be equivalent due to some lucky alignment\nof the action effects. Such additional equivalencies are not considered in this\ntext. Now that the independence of any two actions is easily computed, we use\nthis information to speed up the search for the best action sequence. Only one\n48 3 Simulation-Based Planning for Concurrent Production Systems\nAlgorithm 1 Is the action sequence wa in LNF given that w is in LNF?\n1: procedure TestLNF(w, a)\n2: for k = |w|, . . . , 1 do\n3: if Cwk \u2229 Ca 6= \u2205 then\n4: return true\n5: else if wk > a then\n6: return false\n7: return true\nsequence from each trace is considered. The sequences from the same trace are\nequivalent also with respect to the reward that they generate. To consider only\none sequence per trace, we evaluate only the action sequences in LNF.\nProposition 3.4. If a word w is not in LNF, no word wu starting with the prefix\nw is in LNF.\nProof. If w is not in LNF, then a word v ' w must exist so that v < w. For\nall u \u2208 A\u2217 there is vu ' wu and vu < wu.\nFrom Proposition 3.4, we know that a sequence wa can only be in LNF if w\nis in LNF. During a depth-first traversal of the search tree, entire subtrees can\nthus be pruned away. If the action sequence w leading to the current position in\nthe search tree is known to be in LNF, the candidate sequence wa can be tested\nfor LNF very fast. The test is performed by Algorithm 1. It has a worst-case\nruntime that is linear in the sequence length. In practice the algorithm performs\nmuch faster as a breaking condition is usually found within the first few elements\nof the sequence.\nProposition 3.5. If the action sequence w is in LNF, then for all a \u2208 A\nAlgorithm 1 returns true if and only if the sequence wa is also in LNF.\nProof. For a sequence v, denote withZ(v, k) = {l : l < k \u2227 \u2200m \u2208 {l, . . . , k\u2212\n1}, vk \u22a5 vm} the indices of the contiguous elements before vk that all commute\nwith vk. In the following we show that an action-sequence v is in Lexicographical\nNormal Form (LNF) if and only if\n\u2200k \u2208 {1, . . . , |v|}, \u2200l \u2208 Z(v, k), vl < vk . (3.4)\n3.1 Tree Search with Backtracking 49\nAlgorithm 2 For an LNF sequence w, find the LNF equivalent to wa.\n1: procedure AppendLNF(w, a)\n2: for k = |w|, . . . , 1 do\n3: if TestLNF(w:k, a) then\n4: return w:kawk+1:\n5: return aw\n1: procedure LNF(w)\n2: v \u2190 \u03b5\n3: for k = 1, . . . , |w| do\n4: v \u2190 AppendLNF(v, wk)\n5: return v\nFirst, we show that (3.4) must be satisfied for every sequence v in LNF.\nAssume v is in LNF and does not hold condition (3.4). Then there exists a\ncombination of indices l < k where vl > vk and \u2200m \u2208 {l, k \u2212 1}, vm ' vk.\nThe decomposition v = uvlqvkz can be rearranged as y = uvkvlqz with\npossibly empty subsequence u, q and z. This contradicts v being in LNF since\nv ' y and y < v.\nSecond, we show that condition (3.4) is sufficient for v to be in LNF. Assume\nv satisfies (3.4) and is not in LNF. Then there must exist an equivalent sequence\ny ' v in LNF. Equivalent sequences are permutations and |y| = |v|. So for\ny to have a smaller order, there must be an index l where y and v first differ\ny:l\u22121 = v:l\u22121 and vl < yl. Due to y ' v, action vl must appear in v at an\nindex greater than l and v can be decomposed as v = uvlqylz, with possibly\nempty subsequences u, q and z, where yl commutes with vl and all elements of\nq. This contradicts (3.4).\nSince Equation 3.4 only refers to the preceding elements in the action sequence\nand w is known to be in LNF, it suffices to test (3.4) for the new element.\nProposition 3.6. For any action a and LNF action sequence w, Algorithm 2\nreturns an action sequence that is in LNF and equivalent to wa.\nProof. When the condition in line 3 of Algorithm 2 is not true, then a commutes\nwith wk and a < wk. Therefore, once the condition in line 3 is true, w:ka\nis in LNF and the LNF-order of the sequence cannot be improved by moving\nan element from wk+1: before a. Since w is in LNF, no permutation of\nthe sub-sequence wk+1: has reduced LNF-order. Therefore w:kawk+1: is in\nLNF.\nA trivial approach to search for good sequences is to cast the search space\nas a tree structure and to enumerate the solutions at the leaf nodes of the tree.\n50 3 Simulation-Based Planning for Concurrent Production Systems\nAlgorithm 3 Depth-First Search\n1: vmax \u2190 \u2212\u221e, wmax \u2190 \u03b5\n2: procedure DFS(\u03c9, v,w)\n3: if |w| = kmax then\n4: if v > vmax then\n5: vmax \u2190 v\n6: wmax \u2190 w\n7: return\n8: for a \u2208 A : \u03c9 \u2208 \u03a3a do\n9: \u03c9\u2032 \u2190 a(\u03c9)\n10: v\u2032 \u2190 v + r(\u03c9, a,\u03c9\u2032)\n11: DFS(\u03c9\u2032, v\u2032,wa)\n12: end for\n13: DFS(\u03c3, 0, \u03b5)\n14: return wmax\nAlgorithm 4 Pruned Depth-First Search\n1: vmax \u2190 \u2212\u221e, wmax \u2190 \u03b5\n2: procedure DFSLNF(\u03c9, v,w)\n3: if |w| = kmax then\n4: if v > vmax then\n5: vmax \u2190 v\n6: wmax \u2190 w\n7: return\n8: for a \u2208 A : \u03c9 \u2208 \u03a3a \u2227\nTestLNF(w, a) do\n9: \u03c9\u2032 \u2190 a(\u03c9)\n10: v\u2032 \u2190 v + r(\u03c9, a,\u03c9\u2032)\n11: DFSLNF(\u03c9\u2032, v\u2032,wa)\n12: end for\n13: DFSLNF(\u03c3, 0, \u03b5)\n14: return wmax\nAlgorithm 5 Branch & Bound\n1: vmax \u2190 \u2212\u221e, wmax \u2190 \u03b5\n2: procedure B&B(\u03c9, v,w)\n3: if |w| = kmax then\n4: if v > vmax then\n5: vmax \u2190 v\n6: wmax \u2190 w\n7: return\n8: for a \u2208 A : \u03c9 \u2208 \u03a3a do\n9: \u03c9\u2032 \u2190 a(\u03c9)\n10: v\u2032 \u2190 v + r(\u03c9, a,\u03c9\u2032)\n11: if v\u2032+\u03b2(\u03c9\u2032,wa) > vmax then\n12: B&B(\u03c9\u2032, v\u2032,wa)\n13: end for\n14: B&B(\u03c3, 0, \u03b5)\n15: return wmax\nAlgorithm 6 Pruned Branch & Bound\n1: vmax \u2190 \u2212\u221e, wmax \u2190 \u03b5\n2: procedure B&BLNF(\u03c9, v,w)\n3: if |w| = kmax then\n4: if v > vmax then\n5: vmax \u2190 v\n6: wmax \u2190 w\n7: return\n8: for a \u2208 A : \u03c9 \u2208 \u03a3a \u2227\nTestLNF(w, a) do\n9: \u03c9\u2032 \u2190 a(\u03c9)\n10: v\u2032 \u2190 v + r(\u03c9, a,\u03c9\u2032)\n11: if v\u2032+\u03b2(\u03c9\u2032,wa) > vmax then\n12: B&BLNF(\u03c9\u2032, v\u2032,wa)\n13: end for\n14: B&BLNF(\u03c3, 0, \u03b5)\n15: return wmax\n3.1 Tree Search with Backtracking 51\nEvery node in the tree represents a (partial) action sequence. Depth-first search\ncompletely enumerates the solutions at the leaf nodes without having to hold\nthe entire tree in memory. Algorithm 3, called DFS for depth-first search, walks\nover the tree in recursive fashion. The algorithm backtracks to a prior partial\naction sequence once all solutions starting at the current position in the tree have\nbeen enumerated. The tree of depth kmax contains up to\n\u2211kmax\nk=0 |A|k nodes\nand |A|kmax leaf nodes. Enumerating all possible combinations is intractable\nfor all but the most trivial scenarios. Usually the branching factor of the tree\nis reduced because not all actions from A are applicable in the intermediary\nsystem states. But the problem of combinatorial explosion of the search space\nremains. Proposition 3.4 can be used to test at every node whether the entire\nsubtree starting at the node is not in LNF and can be skipped (pruned). Since\nevery trace contains exactly one sequence in LNF, it is ensured that traversing\nthe tree without the pruned branches still visits every trace once. Algorithm 4,\ncalled DFSLNF, extends DFS with the pruning of sequences that are not in LNF.\nNote that only line 10 of Algorithm 4 has changed compared to DFS.\nAnother technique to speed up tree search is Branch & Bound [Lit+63].\nBranch & Bound is a well-known technique for combinatorial optimization in\nthe presence of so-called admissible heuristics [Pea84]. A heuristic is called\nadmissible if it overestimates the performance that can still result from a partial\nsolution. Here, we express the admissible heuristics as a function \u03b2(\u03c3,w)\nwith the current system state \u03c3 and the current partial action sequence w as\narguments. If the admissible heuristics show that the best performance starting\nfrom the current partial solution is worse than the best solution that was already\nencountered, then the entire subtree behind the current partial solution can\nbe pruned. Branch & Bound is implemented in Algorithm 5. In Algorithm 6,\nBranch & Bound is combined with trace-based pruning. Again, only line 10 is\nchanged to prune out sequences that are not in LNF. The commonality between\nDFS and Branch & Bound is the use of backtracking to return to a previous\npartial solution either when all nodes in a subtree have been visited or when the\nsolutions that remain in the subtree are known to be suboptimal.\n52 3 Simulation-Based Planning for Concurrent Production Systems\n3.1.3 Evaluation\nThe effect of the pruning techniques for tree search methods is evaluated based\non the Jobshop Scheduling Problem (JSP) [Pin08]. Scheduling is one of the\nmost important planning problems on the shopfloor. It is also computationally\nchallenging. The jobs j \u2208 J have to be processed on the machines M . Every\njob consists of operations o \u2208 Oj = {1, 2, . . . , |M |}. The operations need to\nbe processed in-order for every job and are each assigned to a specific machine\nmj,o \u2208M . The operation duration is dj,o. The goal is to find a schedule that\nassigns operations to machines in order to minimize the finishing time of the\nlast job. See Table 3.1c for a benchmark JSP from the literature. There are\n(|J |!)|M | possible schedules for a JSP with |J | jobs and |M | machines where\nevery jobs needs to visit every machine once [JM98]. So a JSP with |J | = 20\nand |M | = 10 has 7.2651 \u00d7 10183 possible solutions. Compare this to the\nmass of the observable universe currently estimated to the equivalent of 1080\nhydrogen atoms. Even though the number of possible solutions is huge, current\nsolution techniques can compute near-optimal solutions for JSP with hundreds\nof machines and jobs. Many benchmark scheduling problems have even been\nsolved with certified optimaltiy. However, the worst-case analysis of the JSP\nshows that it is NP-hard for instances where |J | \u2265 3 and |M | \u2265 3 [GJS76].\nTherefore, unless P = NP, all algorithms for solving the JSP are either heuristic\nor require a long running time for some (synthetic) JSP problems.\nWe cast the JSP in the model from Chapter 2 in terms of actions with\npreconditions and effects. Every machine and every job in a JSP is represented\nas a component in the system model C = Cmachines \u222a Cjobs. The operations\nfor each job are represented as actions where both one machine and one job\nparticipate. The time-indexed state of the machine components is trivial. It only\nconsists of the time when the machine is available next. The state of the job\ncomponents is the number of operations that were already performed for the\njob. The precondition of every action is that the associated operation is next\nin line for the job. The action effect simply increases the number of finished\noperations for the job by one. The duration of each action (operation in the\nJSP) is deterministic. The cost generated by an action is the increase in the\nmaximum timestamp of the components. So the cost of the entire sequence is\n3.1 Tree Search with Backtracking 53\nJob Operations (m, p)\n1 (0, 5), (1, 10), (2, 5)\n2 (1, 10), (0, 5), (2, 5)\n3 (2, 5), (1, 10), (0, 5)\n(a) Minimal 3\u00d7 3 JSP.\nJob Operations (m, p)\n1 (0, 5), (1, 10), (2, 5), (3, 10)\n2 (1, 10), (3, 5), (2, 5), (0, 5)\n3 (1, 5), (0, 10), (2, 5), (3, 5)\n4 (3, 5), (2, 10), (0, 5), (1, 10)\n(b) Minimal 4\u00d7 4 JSP.\nJob Operations (m, p)\n1 (2,1), (0,3), (1,6), (3,7), (5,3), (4,6)\n2 (1,8), (2,5), (4,10), (5,10), (0,10), (3,4)\n3 (2,5), (3,4), (5,8), (0,9), (1,1), (4,7)\n4 (1,5), (0,5), (2,5), (3,3), (4,8), (5,9)\n5 (2,9), (1,3), (4,5), (5,4), (0,3), (3,1)\n6 (1,3), (3,3), (5,9), (0,1), (4,4), (2,1)\n(c) The 6\u00d7 6 benchmark JSP ft06 from [FT63].\nTable 3.1: Example JSP problems.\nthe makespan of the solution.\nr(\u03c3, a,\u03c3\u2032) =\n(\nmax\nc\u2208C\ntc\n)\n\u2212\n(\nmax\nc\u2208C\nt\u2032c\n)\n(3.5)\nHere, tc refers to the simulation time of component c in the system state \u03c3 and\nt\u2032c refers to the simulation time of the component in the system state \u03c3\u2032.\nGiven a partial schedule as an action sequencew, the following trivial heuristic\ncomputes an upper bound for the reward that can be generated following the\nexecution of w. For every component (representing a job or a machine), the\nremaining operations for the component are summed up and added to its current\n54 3 Simulation-Based Planning for Concurrent Production Systems\ntime.\n\u03b2JSP (\u03c3,w) = \u2212max\nc\u2208C\n(\ntc +\n\u2211\na\u2208A:a/\u2208w,\nc\u2208Ca\nda\n)\n(3.6)\nThe ft06 benchmark problem from Table 3.1c illustrates the importance of\noptimisation. An unoptimized solution can require more than 150 seconds to\ncomplete all jobs. The optimal solution requires just 55s. Finding the optimal\nsolution for larger problems is not possible without the help of computers.\nIn addition to the ft06 benchmark, two additional minimal problems are\nconsidered. See Table 3.1 for their exact definition. The minimal examples\nare too small to be of any practical value. But they give an indication of how\nfast the problem complexity increases. A sequence of 9 unique elements has\n9! = 362, 880 permutations. The minimal 3\u00d7 3 JSP depicted in Table 3.1 also\ndefines 9 actions. But the full scenario tree for the JSP has only 1,680 leaf nodes\ncorresponding to valid schedules. By additionally pruning branches that are not\nin the LNF only 63 leaf nodes remain. Using the makespan lower bound from\nEquation 3.6, nodes can be pruned where the lower bound is equal or worse to\nthe best solution encountered so far. With the Branch & Bound pruning, only\n3 leaf nodes are actually visited. However, more nodes were visited overall\ncompared to trace-based pruning for full depth-first search. This indicates that\nmostly branches close to the leaves were pruned with Branch & Bound only.\nBy combining trace pruning with Branch & Bound, only 65 nodes are visited\noverall. This is a decrease in the search running time by a factor of more than\n50 compared to Branch & Bound search without pruning.\nOn the 4 \u00d7 4 JSP depicted in Table 3.1 an even smaller fraction of the\nscenario-tree is visited by combining trace-based and makespan-based pruning.\nHowever, the number of visited nodes still grows fast with the size of the JSP.\nOn the ft06 6\u00d7 6 JSP, 682,508 nodes are expanded with both bound and trace\npruning enabled. Our implementation is capable of visiting over 1,000,000\nnodes per second during Branch & Bound search (on a Lenovo T480 laptop\ncomputer). However, with only either trace-based pruning or Branch & Bound\nenabled, we could not solve ft06 in over a day of computation. A 10 \u00d7 10\nJSP could not be solved within several days of compute time even with both\ntrace-based and bound-based are activated. In summary, trace-based pruning\n3.1 Tree Search with Backtracking 55\nDFS B&B DFSLNF B&BLNF\nVisited Nodes 3,568 405 348 65\nVisited Leaf\nNodes 1,680 3 63 3\nTrace-Pruned\nBranches 0 0 191 41\nBound-Pruned\nBranches 0 376 0 35\n(a) Visited nodes for the minimal 3\u00d7 3 JSP\nDFS B&B DFSLNF B&BLNF\nVisited Nodes 128,385,941 115,042 105,666 826\nVisited Leaf\nNodes 63,063,000 9 11,143 9\nTrace-Pruned\nBranches 0 0 93,074 1,131\nBound-Pruned\nBranches 0 206,025 0 643\n(b) Visited nodes for the minimal 4\u00d7 4 JSP\nDFS B&B DFSLNF B&BLNF\nVisited Nodes ? ? ? 682,508\nVisited Leaf\nNodes ? ? ? 43\nTrace-Pruned\nBranches 0 0 ? 2,051,681\nBound-Pruned\nBranches 0 ? 0 750,063\n(c) Visited nodes for the ft06 6\u00d7 6 JSP\nTable 3.2: Benchmarking of pruning techniques for DFS and Branch & Bound.\nQuestionmarks indicate that an optimization did not terminate after two weeks\nof computation. So the numbers are outstanding.\n56 3 Simulation-Based Planning for Concurrent Production Systems\nreduces the number of visited action sequences to a small fraction. For the 4\u00d7 4\nJSP, the number of action sequences (visited leaf nodes) was reduced by a factor\nof more than 5,600. The improvements are comparatively increasing with the\nlength of the action sequences.\nWe have shown that LNF pruning leads to a dramatic reduction of the search\nspace. The reduction is already on many orders of magnitude for the comparably\nsmall benchmark problems that were considered. However, even with trace-\nbased pruning, naive tree search does not scale up to scenarios of relevant size.\nIn practice, genetic algorithms are often used to solve combinatorial problems.\nModern heuristic solvers find good solutions for JSP with thousands of jobs\n[Dim15]. But these solvers exploit the specific structure of the JSP. Handling of\ncomplex action preconditions is near-impossible for genetic algorithms. The\ngenetic crossing and mutation of two partial solutions will almost always lead to\nan infeasible action sequence where the preconditions of an action are not met.\nRepairing an infeasible plan is usually quite difficult. For example if a single\nproduct is missing to finish an order of many hundred products.\n3.2 Planning for Discrete Action Sequences\nThe algorithms from Section 3.1 use backtracking to return to previous partial\nsolutions. This requires either that the system state is fully known so that it can\nbe stored in a computer (to return to previous states) or that action sequences\ncan be deterministically repeated. For experiments carried out in the physical\nworld, neither of these assumptions is true. In this section, we further speed up\nplanning by \u201cimplicitly pruning\u201d less promising branches with Monte-Carlo Tree\nSearch (MCTS). Many recent breakthroughs in Artificial Intelligence were made\npossible by MCTS. This includes the AlphaGo system [Sil+17] which is able to\nplay the game of Go with superhuman performance. In short, MCTS enables\nplanning in scenarios with many combinatorial variations where backtracking\ntree search is not able to cover any significant portion of the search space.\nIn addition, MCTS uses only forward-simulation without backtracking. This\nreduces the coupling between the planning algorithm and the simulator to the\npoint where real-world simulations could be used to generate samples for the\nplanning algorithm.\n3.2 Planning for Discrete Action Sequences 57\n3.2.1 Background: Monte-Carlo Tree Search\nIn MCTS [Bro+12; Mun+14], a scenario tree is explored by iterative playouts. A\nplayout is essentially one run of the scenario with sequential decision making in a\nseries of steps. Every playout starts at the root of the sequence tree and evolves by\n\u201cforward simulation\u201d. In contrast to Branch & Bound, there is no backtracking to\nprevious states within a playout. Historically, MCTS evolved from research on\nthe multi-armed bandit problem: The multi-armed bandit problem is an idealized\nversion of a slot machine. The following short exposition follows [Mun+14]\nand adapts the notation to the conventions of this text. Consider a multi-armed\nbandit in a casino where they player can choose a different arm during kmax\nrounds (this will be extended to sequential decision making later on). The reward\nof the different arms a \u2208 A is random according to the distribution Pa with a\nsupport on [0, 1]. But the player is initially unaware of the reward distribution\nfor every arm. In each round k, the player chooses a bandit ak \u2208 A and collects\na reward rk \u223c Pak . The rewards generated at the other arm are not observed.\nThe goal is to find a strategy that maximizes the expected sum of payouts during\nthe k rounds. This leads to the so-called Exploration/Exploitation Tradeoff :\nThe player could select a bandit with high expected reward. But this might get\nhim stuck at a bandit with suboptimal expected reward. So the player wants to\nexplore other options without loosing too much in the process. The expected\nreward of the different arms a \u2208 A is \u00b5a = E[Pa]. The expected reward of\nthe best arm (there can be several best arms) is \u00b5\u2217 = maxa\u2208A \u00b5a. Possible\nstrategies for repeated play are analyzed with respect to their expected regret.\nThe cumulative regret after k rounds compares the actual reward r with the\nexpected reward of choosing the arm with highest expected reward every time.\nbk = k\u00b5\u2217 \u2212\nk\u2211\nl=1\nrl\nThe expected cumulative regret is therefore\nE[bk] = k\u00b5\u2217 \u2212\nk\u2211\nl=1\nE[rl] =\n\u2211\na\u2208A\nE[na(k)](\u00b5\u2217 \u2212 \u00b5a) ,\n58 3 Simulation-Based Planning for Concurrent Production Systems\nwhere na(k) denotes the number of draws from a after the first k rounds.\nAn important tool for bounding the expected cumulative regret is the Chernoff-\nHoeffding inequality. Let (y\ni\n)i=1,...,n i.i.d. samples of a probability distribution\nwith support [0, 1] and mean \u00b5. The empirical mean estimator \u00b5\u0302 = 1n\n\u2211n\ni=1 yi\nis a function of the y\ni\nand therefore a random variable as well. The Chernoff-\nHoeffding inequality gives probability bounds for the distance between the true\nand the estimated mean.\nP\n(\n\u00b5\u0302\u2212 \u00b5 \u2265 \u03b5\n)\n\u2264 e\u22122n\u03b5\n2\nand P\n(\n\u00b5\u0302\u2212 \u00b5 \u2264 \u2212\u03b5\n)\n\u2264 e\u22122n\u03b5\n2\nThe bound is independent of the underlying distribution of the yi. So it can be\napplied even when the distribution of the y\ni\nis not known!\nThere exists a variety of approaches for selecting the next draw in the\nmulti-armed bandit setting. Auer et al. [ACF02] proposed the so-called Upper\nConfidence Bound (UCB) algorithm. Let \u00b5\u0302a,k denote the mean return of arm a\nsampled during the first k rounds. UCB always selects the next arm as follows:\nak = arg max\nb\u2208A\n\u00b5\u0302b,k\u22121 +\n\u221a\n3 log k\n2nb(k \u2212 1)\nSelecting the best arm according to the UCB gives an upper bound for the\nexpected cumulative regret by application of the Chernoff-Hoeffding inequality.\nE[bk] \u2264 6\n\u2211\na\u2208A,\n\u00b5\u2217>\u00b5a\nlog k\n\u00b5\u2217 \u2212 \u00b5a\n+ |A|(\u03c0\n2\n3 + 1) ,\nThe expected cumulative regret grows at most logarithmically in k.\nThe algorithm of Auer et al. [ACF02] selects actions from a flat list of\noptions. Monte-Carlo Tree Search (MCTS) is a family of algorithms that uses\nthe same principle of iterative exploration for planning in sequential decision\nsettings. A popular variation of MCTS, called Upper Confidence on Trees\n(UCT) [KS06], uses the UCB decision rule for every action choice during a\nplayout. See Figure 3.3 for an overview. Algorithm 7 shows UCT (but with\nsome modifications compared to [KS06] that will be explained in the following).\nMCTS can be seen as \u201csimulation-based\u201d planning, as no backtracking is used.\n3.2 Planning for Discrete Action Sequences 59\nFigure 3.3: Outline of a Monte-Carlo Tree Search. Reproduced from [Cha+08].\nInstead, the results from the last simulation are incorporated into statistics about\nthe expected reward for the possible next actions at the current position in the\nscenario tree. The updated empirical reward statistics is used for decision-making\nin the following playouts.\nThe assumption that the reward in every step is in the range [0, 1] is not\nrequired for UCT to converge to optimal decisions in the limit. On the downside,\nthere is currently no good characterization of the convergence speed achieved by\nUCT that doesn\u2019t make strong assumptions on the underlying scenario. It is only\nknown that for a large enough number of plays, every branch of the scenario tree\nis visited. Since only a small subset of the tree is explored in practice before\nthe algorithm is terminated, MCTS struggles with scenarios where the reward\nis \u201cunevenly distributed\u201d. That is, if a big reward can be found after a long\nsequence of actions where small changes to the action sequence lead to much\nworse results, it is then not very likely that the reward is encountered at all and\nMCTS will not assign a correct value estimation for the choices. A workaround\nfor this is Reward Shaping [NHR99] where the reward is distributed such that it\nmay be encountered early on in the action sequences.\nUCT may require tuning of the parameter \u03b1 which regulates the importance\nof the upper confidence bias. Setting \u03b1 corresponds to making a choice for the\nExploration/Exploitation tradeoff between the two extremes \u201calways explore\u201d\nand \u201calways exploit\u201d. Note that UCB was developed for action selection in\nstochastic scenarios with unknown reward distributions for the different actions.\n60 3 Simulation-Based Planning for Concurrent Production Systems\nAlgorithm 7 The Upper Confidence on Trees (UCT) algorithm [KS06].\n1: procedure UCT(\u03c30)\n2: q[ \u00b7 ]\u2190 0\n3: n[ \u00b7 ]\u2190 0\n4: while enough time do\n5: Play(\u03c30, \u03b5)\n6: return arg max\na\u2208A\nq[a]\n1: procedure Rollout(\u03c3)\n2: if done(\u03c3) then\n3: return 0\n4: a\u2190 \u03c0A(\u03c3)\n5: (\u03c3\u2032, r)\u2190 a(\u03c3)\n6: return r +\nRollout(\u03c3\u2032)\n1: procedure Play(\u03c3,w)\n2: if done(\u03c3) then\n3: return 0\n4: B \u2190 {b \u2208 A : n[wb] = 0}\n5: if B 6= \u2205 then\n6: a\u2190 \u03c0B(\u03c3)\n7: (\u03c3\u2032, r)\u2190 a(\u03c3)\n8: r \u2190 r + Rollout(\u03c3\u2032)\n9: else\n10: a\u2190 arg max\nb\u2208A,\u03c3\u2208\u03a3b\n[\nq[wb] +\n\u03b1\n\u221a\nlogn[w]+1\nn[wb]\n]\n11: (\u03c3\u2032, r)\u2190 a(\u03c3)\n12: r \u2190 r + Play(\u03c3\u2032,wa)\n13: n[wa]\u2190 n[wa] + 1\n14: q[wa]\u2190 q[wa] + r\u2212q[wa]n[wa]\n15: return v\nHere we apply the same principle to tree-search for deterministic scenarios.\nThere is an informal argument for this. Many rollout policies are stochastic,\nsimilar to the uniform sampling policy described above. So the rollout takes\nsamples from the reward distribution that is implied by applying the current\nrollout policy to the subsequent steps. When nodes are visited several times,\nthe underlying distribution for the policy changes. So past experience does not\nnecessarily match the samples taken later on. Nevertheless, the UCB-based\nselection rule shows good performance in practice.\n3.2.2 Monte-Carlo Tree Search for Discrete Action Sequences\nWe introduce a modification of UCT called UCTLNF. See Algorithm 8 for\ndetails. UCTLNF is inspired from UCT but deviates in a few key aspects. First,\nthe original UCT algorithm gradually builds up a tree structure where the nodes\ncorrespond to partial action sequences. But only one new node is added with\nevery play. Once the edge of the current tree is reached, the remaining steps are\n\u201crolled out\u201d and only the sum of rewards for the rollout is considered. UCTLNF\ndoes not use rollouts and adds nodes for all selected actions in the sequence.\n3.2 Planning for Discrete Action Sequences 61\nAlgorithm 8 UCT for Deterministic Actions with Trace-Based Pruning\n1: procedure UCTLNF(\u03c30)\n2: n[ \u00b7 ]\u2190 0, q[ \u00b7 ]\u2190 0\n3: while enough time do\n4: Y \u2190 PlayLNF(\u03c30)\n5: UpdateLNF(Y )\n6: return arg max\na\u2208A\nq[a]\n1: procedure UpdateLNF(Y )\n2: z[ \u00b7 ]\u2190 0\n3: for (w, r) \u2208 Y do\n4: for k = |w| . . . , 1 do\n5: g \u2190 w:k\n6: if z[g] > 0 then\n7: break\n8: n[g]\u2190 n[g] + 1, z[g]\u2190 1\n9: q[g]\u2190 rk+ max\na\u2208A,\nn[ga]>0\nq[LNF(ga)]\n1: procedure PlayLNF(\u03c3)\n2: w \u2190 \u03b5, r \u2190 \u03b5, Y \u2190 \u2205\n3: while \u00acdone(\u03c3) do\n4: B \u2190 {b \u2208 A : n[wb] = 0}\n5: if B 6= \u2205 then\n6: a\u2190 \u03c0B(\u03c3)\n7: else\n8: a\u2190 arg max\nb\u2208A, \u03c3\u2208\u03a3b\n[\nq[LNF(wb)] + \u03b1\n\u221a\nlogn[w]+1\nn[LNF(wb)]\n]\n9: (\u03c3, v)\u2190 a(\u03c3)\n10: Y \u2190 Y \u222a {(wa, rv), LNF(wa, rv)}\n11: (w, r)\u2190 LNF(wa, rv)\n12: return Y\nSecond, the original UCT stores a statistics about the average reward that was\nachieved after selecting a node (action). Instead, we perform a maximization\nin every step of the Update procedure. Therefore, the value estimation of\nevery node is the maximum reward that can be achieved by following the best\nknown sequence of actions after selecting the node (action). Third, we do not\nonly update a single sequence for every play. Instead, when we arrive at a\nsequence that is not in LNF, then we permute the sequence to the equivalent LNF\nsequence. But we store the original sequence and the LNF sequence and run the\nUpdate procedure on both of them. All three modifications to the original UCT\nalgorithm are interrelated. This is explained next.\nThe easiest way to restrict the search to sequences in LNF only is to simply\nremove actions leading to non-LNF sequences at the current node in the search\ntree. But when choosing one action at a time, this often leads to dead-ends\n62 3 Simulation-Based Planning for Concurrent Production Systems\nwhere no action can be chosen without breaking the LNF constraint. Since we\ndo not want to backtrack to previous system states during a playout, virtually\nno playout would complete. Therefore we use the LNF algorithm to repair\nthe action sequence as we go along. However, simply permuting the sequence\nto LNF after every action selection is not compatible with the UCT approach\neither: Soon, some nodes are always selected because they have a very low\nvisit count. But as the sequence is permuted to LNF, this nodes continue to\nnot have their visit count n increased. Suppose an example with three actions\na < b < c that all commute and where every action can be chosen only once in\nevery sequence. The sequence starting with the action c would always become\nthe LNF sequences ac or bc after the second action choice. So the node for the\nfirst action c is nevery updated. But the UCT algorithm will always choose c\nfirst as long as the counter n[c] is not increased. This is solved by updating all\nsequences that were encountered in the current playout, regardless of whether\nthey are in LNF or not. The counter z for the node updates within the current\nplayout ensures that no node is updated twice for one playout. Note that we use\nthe algorithm LNF in a slightly different fashion. Giving the action sequence\nw and the reward history r as input, both are permuted to yield an LNF action\nsequence where the index of actions still matches the index of the corresponding\nreward.\n3.2.3 Evaluation\nWe evaluate the algorithms UCT and UCTLNF on the benchmark Jobshop\nScheduling Problems (JSP): The ft06 benchmark with 6 jobs on 6 machines\nfrom [FT63] and the abz5 benchmark with 10 jobs on 10 machines from\n[ABZ88]. However, we change the classical JSP in one important aspect:\nInstead of optimizing the makespan, the time when the last job finishes, we\ntarget the sum of the finishing times (the tardiness if the job is immediately due)\nfor all jobs. The reason for the change is to ensure that the immediate reward of\nactions depends on a small number of participating components Ca only. When\noptimizing the makespan, it is of course possible to return the negative increase\nof the maximum simulation time for all components. But then the actions would\nhave all components C as participants. We prefer to have only a small subset of\nthe components participating in each action, so that the trace-based equivalence\n3.2 Planning for Discrete Action Sequences 63\n0 20000 40000 60000\nNumber of Simulations\n500\n450\n400\n350\n300\n250\nRe\nwa\nrd\nalpha: 10\nalpha: 100\nalpha: 1000\n(a) Benchmark of UCT with the JSP\nexample ft06.\n0 20000 40000 60000\nNumber of Simulations\n500\n450\n400\n350\n300\n250\nRe\nwa\nrd\nalpha: 10\nalpha: 100\nalpha: 1000\n(b) Benchmark of UCTLNF with the\nJSP example ft06.\n0 5000 10000 15000\nNumber of Simulations\n25000\n22500\n20000\n17500\n15000\n12500\nRe\nwa\nrd\nalpha: 10\nalpha: 100\nalpha: 1000\nalpha: 10000\n(c) Benchmark of UCT with the JSP\nexample abz5.\n0 5000 10000 15000\nNumber of Simulations\n25000\n22500\n20000\n17500\n15000\n12500\nRe\nwa\nrd\nalpha: 10\nalpha: 100\nalpha: 1000\nalpha: 10000\n(d) Benchmark of UCTLNF with the\nJSP example abz5.\nFigure 3.4: JSP benchmarks for Monte-Carlo Tree Search. Every benchmark\nwas run 10 times. The lines give the average empirical reward. The standard\nerror is indicated by tick marks and the variance is shown in a lighter shade.\nof action sequences as defined in Section 3.1.2 can be used to prune the sequence\ntree. The rollout policy \u03c0 is set to select randomly among the possible choices\nwith a uniform distribution.\nAs can be seen in Figure 3.4, MCTS makes big improvements to the best-\nknown solution early on. Depending on the exploration parameter \u03b1, the\nalgorithm then \u201cconverges\u201d towards a reward value that is no longer improved\nupon even with very long running times. This is not a true convergence however,\nsince we know that all branches of the search tree are explored eventually with the\nUCB rule. The more complex abz5 example shows an interesting phenomenon\nwhere higher \u03b1 lead to better results. But it takes longer until \u201cconvergence\u201d\nis reached. This insight makes sense with regards to the UCB action selection.\nOnce all actions at a given node have been explored several times, the UCB rule\nwill predominantly choose actions with a known high reward. So the observed\n64 3 Simulation-Based Planning for Concurrent Production Systems\nconvergence is explained by a shift from exploration to exploitation in the action\nselections. Pruning sequences that are not in LNF speeds up the convergence to\nsome final best reward. This was expected as the pruning effectively reduces the\nsize of the search tree.\n3.3 Planning with Uncertainty and Continuous Action\nParameters\nAs defined in Section 2.2, parameterized actions a take parameters from the set\n\u0398a. But the algorithms from the previous sections 3.1 and 3.2 can only handle\ndiscrete choices of deterministic actions. If the set of parameters is finite, we can\nsimply extend the tree-search techniques to search over the joint space of actions\nand their parameters. This is however not possible if the action parameters are\nuncountable. For example if a parameter is defined on a continuous domain.\nFurthermore, while the UCB rule for bandit problems is defined for decision\nmaking in stochastic unknown environments, UCT assumes deterministic actions.\nThis section deals with the extension of the simulation-based planning approach\nto actions a that can be both stochastic and have parameters on a continuous\nparameter space.\n3.3.1 Background: MCTS under Uncertainty\nFor MDP, where the outcome depends not only on decision-making, but also on\nthe response from the stochastic system model, it has been known for some time\nthat a randomly sampled subset of the scenario tree that covers only a vanishing\nfraction of the full scenario is enough to compute near-optimal actions from any\nstate [KMN02]. If \u03b5 is the admissible error for the estimation of the V-value of\nthe current state (see Section 2.4), then the number of sample playouts grows\nexponentially in \u03b5. It does however not depend on the size and complexity of\nthe state representation. With the advent of MCTS, sampling based methods\nhave also been used for sequential decision-making under uncertainty [KS06].\nThe POMCP algorithm (Partially Observable Monte-Carlo Planning) extends\nMCTS to scenarios with partial observability (POMDP) [SV10]. The authors\n[SV10] write with regards to the performance of their invention POMCP:\n3.3 Planning with Uncertainty and Continuous Action Parameters 65\nAlgorithm 9 Partially Observable Monte-Carlo Planning\n1: procedure POMCP(\u03c30)\n2: q[ \u00b7 ]\u2190 0\n3: n[ \u00b7 ]\u2190 0\n4: while enough time do\n5: \u03c3 \u223c \u03c30\n6: Play(\u03c3, \u03b5)\n7: return arg maxa\u2208A q[a]\n1: procedure Rollout(\u03c3,h)\n2: if done(\u03c3) then\n3: return 0\n4: a\u2190 \u03c0A(h)\n5: (\u03c3\u2032, o) \u223c a(\u03c3)\n6: v \u2190 r(\u03c3, a,\u03c3\u2032)\n7: return v +\nRollout(\u03c3\u2032,hao)\n1: procedure Play(\u03c3,h)\n2: if done(\u03c3) then\n3: return 0\n4: B \u2190 {b \u2208 A : n[hb] = 0}\n5: if B 6= \u2205 then\n6: a\u2190 \u03c0B(h)\n7: (\u03c3\u2032, o, r) \u223c a(\u03c3)\n8: r \u2190 r + Rollout(\u03c3\u2032,hao)\n9: else\n10: a\u2190 arg max\nb\u2208A\n[\nq[hb] +\n\u03b1\n\u221a\nlogn[h]+1\nn[hb]\n]\n11: (\u03c3\u2032, o, r) \u223c a(\u03c3)\n12: r \u2190 r + Play(\u03c3\u2032,hao)\n13: n[h]\u2190 n[h] + 1\n14: n[ha]\u2190 n[ha] + 1\n15: q[ha]\u2190 q[ha] + r\u2212q[ha]n[ha]\n16: return r\n[On a benchmark problem], POMCP achieved the same performance\nwith 4 seconds of online computation to the state-of-the-art solver\nSARSOP with 1000 seconds of offline computation.\nWhile the current system state \u03c3 is known to the simulator used to sample state\ntransitions, the decision-making only relies on the observations resulting from\nthe actions and the reward statistics that were collected prior. See Algorithm 9\nfor details. The search tree now not only consists of nodes representing actions,\nbut is a bipartite graph of actions and the resulting observations. The rollout\npolicy \u03c0 takes the full history of actions and observations as input. A trivial\nrollout policy is to sample uniformly from the previously unexplored actions.\nThis policy is a popular choice as it does not depend on prior knowledge and\nassumptions about the scenario and the state representation.\n66 3 Simulation-Based Planning for Concurrent Production Systems\n(1, 1) (1, 2)\n(3, 1)\n(2, 2)\n(2, 3)\n(3, 2)\n(3, 3)\n(a) The unit cube split into cells.\n(0, 1)\n(1, 2)(1, 1) (1, 3)\n(2, 2)(2, 1) (2, 3)\n(3, 2)(3, 1) (3, 3)\n(b) Tree hierarchy of cells.\nFigure 3.5: Example for Optimistic Optimization on the unit cube. The unit\ncube is split into cells based on a hierarchical partitioning of the domain. Every\ncell has an index (~, i) that also represents a node in the partitioning tree: ~ is\nthe height of the tree at that node (the number of splits) and i is the index within\nthe set of cells of height ~. The initial node (0, 1) represents the entire domain,\nhere depicted as the unit cube. Leaf nodes are marked gray in the partitioning\ntree.\n3.3.2 Background: Optimistic Optimization\nOptimization of functions on a continuous domain has a long history. Very\nefficient solvers exist today for the optimization of convex functions where\ngradient information is available [BV04]. Gradient-free global optimization\nof non-convex functions remains challenging. Classical solution techniques\nare the Dividing Rectangles (DIRECT) algorithm [JPS93] as well as heuristic\ngenetic algorithms [SP97]. While the latter provides no lower bounds for\nperformance, the convergence speed of DIRECT depends on an upper bound of\nthe function\u2019s gradient known as the Lipschitz bound. In recent years, the ideas\nfor optimization in discrete bandit settings and MCTS have been translated to\noptimization of continuous functions. The resulting techniques are known as\nOptimistic Optimization (OO). See [Mun+14] for a comprehensive account.\nSuppose we want to maximize some function f : X \u2192 R over the domain X .\nx\u2217 = arg max\nx\u2208X\nf(x) (3.7)\n3.3 Planning with Uncertainty and Continuous Action Parameters 67\nIf we can make assumptions of convexity, then a range of established methods\nand commercial tools can be used to solve the optimization problem [BV04].\nOO does not require an assumption of convexity. The basic idea is to iteratively\ndissect X into disjoint cells of decreasing size that cover the entire function\ndomain (Figure 3.5a). The hierarchy of cells forms a tree structure (Figure 3.5b).\nAn \u201coptimistic\u201d upper bound is computed for every cell. This upper bound\nguides the continuing selection and splitting of the cells. The breakthrough\nof recent work is to not require a Lipschitz bound for f to compute the upper\nbound. Instead, the function is assumed to be smooth around the optimizer with\nrespect to a semi-metric.2 This is a much weaker assumption.\nAlgorithm 10 Deterministic Optimistic Optimization (DOO) for the optimization\nof an unknown function f : X \u2192 R. This formulation is for the special case\nwhere the search domain is the n-dimensional unit cube X = [0, 1]n and cells\nare split into three children.\n1: procedure DOO(f )\n2: L\u2190 {(0, 1)} . Set of leaf nodes\n3: x[0, 1]\u2190 1 12\n4: while enough time do\n5: (~, i)\u2190 arg max(d\u0304,j)\u2208L [f(x[d\u0304, j]) + \u03b4(d\u0304)]\n6: Split(~, i)\n7: return arg max(~,i)\u2208L f(x[~, i])\n1: procedure Split(~, i)\n2: v \u2190 max {g : x[~ + 1, j] 6= \u2205} . Highest node index at depth ~ + 1\n3: d\u2190 mod(~, n) + 1 . The dimension to split at depth ~\n4: o\u2190 \u03bdd\n( 1\n3\n)b~/nc+1\n. New distance along the split dimension\n5: L\u2190 L \\ {(~, i)} . Remove the cell from the leaves\n6: for j \u2208 {1, . . . , 3} do . Add new leaf nodes\n7: L\u2190 L \u222a {(~ + 1, v + j)}\n8: x[~ + 1, v + j]\u2190 x[~, i] + (j \u2212 2)o\nDeterministic Optimistic Optimization The first considered OO algorithm is\nDeterministic Optimistic Optimization (DOO). Algorithm 10 shows a simplified\n2A semi-metric has `(x,y) = `(y,x) and `(x,y) = 0 \u21d2 x = y. Different from a regular\nnorm, the triangle inequality (a consequence of the Cauchy-Schwarz inequality) is not required to\nhold.\n68 3 Simulation-Based Planning for Concurrent Production Systems\nversion of DOO. It assumes the domain of f is the n-dimensional unit cube and\ncells are split into three children. In every iteration, the cell with the highest\nupper bound is selected and split into 3 children. The cells are denoted as (~, i)\nwhere ~ is the depth of the tree and i is an index for the cells at the same depth.3\nThe set L contains the leaf nodes of the current search tree (cf. Figure 3.5b).\nThe midpoint of the visited cells (~, i) is stored as x[~, i]. The upper bound\nof each cell is computed from an evaluation at the midpoint and the bias \u03b4(~)\nthat depends on the depth-position of the cell. The choice of \u03b4 depends on the\ntarget function f and semi-metric `. More detail on that can be found in the next\nparagraph. Along which dimension to split is determined from the tree-depth ~\nat which the cell is situated.\nExample 3.3. Figure 3.6 shows the graph of two example functions\nwe seek to maximize on the domain X = [0, 1]. Notably, the Garland\nfunction is not differentiable at some points on the domain and has no\nLipschitz constant. The function is also not differentiable at the optimizer\n\u03c0/6. But there exists a semi-metric for which the Garland function is\nlocally smooth around the optimizer.\n0.0 0.2 0.4 0.6 0.8 1.0\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n0.2\n(a) Sine and quadratic: f1(x) =\n0.25 sin(50x) \u00b7 sin(10x) \u2212 (x \u2212\n0.75)2 with a scaled Euclidean met-\nric fitted to the optimizer.\n0.0 0.2 0.4 0.6 0.8 1.0\n0.4\n0.2\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\n(b) Garland function: f2(x) = 4x\n(1\u2212x)( 34 +\n1\n4 (1\u2212\n\u221a\n| sin(60x)|))\nand the semi-metric `(x, y) =\n\u03b2\u2016x\u2212y\u20161/2 fitted to the optimizer.\nFigure 3.6: Example functions that are locally smooth around the\noptimized for a semi-metric `.\n3Symbols with a crossing bar as in ~ are used to denote height-indices in a tree.\n3.3 Planning with Uncertainty and Continuous Action Parameters 69\nTo show convergence of DOO, the following assumptions are made for f and\nits domain [Mun+14].\n1. There exists a semi-metric ` : X\u00d7X \u2192 R+ for which f is locally smooth\naround the optimizer: Denote the maximum value of f on its domain\nwith f\u2217 = f(x\u2217). The function is locally smooth around the optimizer if\nf(x\u2217)\u2212 f(x) \u2264 `(x,x\u2217) for all x \u2208 X .\n2. The domain of each cell is X~,i \u2286 X . The midpoint of the cell is\nx~,i. The cell diameter \u03b4(~) decreases with increasing depth ~ and\nsupx\u2208X~,i`(x,x~,i) \u2264 \u03b4(~). So the value of the midpoint and the cell\ndiameter give an upper-bound for the best solution the cell can contain\noverall.\n3. The cells are well-shaped in the sense that there exists a \u00b5 > 0 such that\nfor any depth ~ \u2265 0 all cells (~, i) of that depth fully contain an `-ball\nwith radius \u00b5\u03b4(~) centered in x~,i. So all cells have a positive volume.\nFor every region (~, i) containing the optimizer x\u2217 \u2208 X~,i, we have f(x~,i) +\n\u03b4(~) \u2265 f(x~,i) + `(x~,i,x\u2217) \u2265 f\u2217. Since the leaf nodes always cover the\nentire function domain, cells with x~,i + \u03b4(~) < f\u2217 are never expanded as they\nare dominated by the leaf node containing the optimizer. So the cells potentially\nexpanded at depth ~ are I~ = {(~, i) : f(x~,i) + \u03b4(~) \u2265 f\u2217}.\n(Stochastic) Simultaneous Optimistic Optimization DOO requires no global\nLipschitz bound of the target function. But it requires knowledge of a semi-\nmetric ` that is smooth around the optimizer. The ` is not known in many\ncases. The Simultaneous Optimistic Optimization (SOO) algorithm [Mun11]\nadopts ideas from the DIRECT algorithm [JPS93] to achieve nearly the same\nconvergence results as DOO even without knowledge of `. SOO still assumes\nthe existence of a such a semi-metric `. But it suffices to show the existence of\nany such semi-metric for the convergence analysis without actually using it in the\nalgorithm. In many cases, the function f itself can be used to construct a suitable\nsemi-metric! Take any norm \u2016 \u00b7 \u2016 for the function domain X . The semi-metric\n`(x,y) for points x, y on X is constructed as follows. With \u03b7 = \u2016x\u2212 y\u2016 the\ndistance on the domain norm, the distance on ` is the difference between the\n70 3 Simulation-Based Planning for Concurrent Production Systems\noptimizer and the worst point in the \u03b7-ball around the optimizer:\n\u02dc\u0300(\u03b7) = sup\n\u2016x\u2212x\u2217\u2016\u2264\u03b7\n(f\u2217 \u2212 f(x)), `(x,y) = \u02dc\u0300(\u2016x\u2212 y\u2016) (3.8)\nWe forego full convergence proofs at this point and refer to the original paper\n[Mun11]. Stochastic SOO (StoSOO) [VCM13] extends SOO to the optimization\nof stochastic functions. Cells are split only after \u03ba evaluations. The mean of\nthe sampled values at the cell midpoint is used for the evaluation. The authors\nof [VCM13] provide a convergence bound for the expected regret on the order\nof O(log2(\u03b9)/\n\u221a\n\u03b9) where \u03b9 is the number of samples taken from the stochastic\nfunction f . The tuning parameter \u03b7 controls how much emphasis the algorithm\nis putting on exploration, i.e. the tradeoff between exploration and exploitation.\nAlgorithm 11 shows a simplified version of StoSoo for the n-dimensional unit\ncube where cells are split into three child cells after \u03ba evaluations. We will now\nexplain the major changes compared to DOO. First, the visited nodes are split\ninto leaf nodes L and internal nodes N . The internal nodes have been sampled\n\u03ba times and are no longer evaluated. Second, since we do know the semi-metric\n` (and hence the cell diameter \u03b4), an upper confidence bias is added to the cell\nevaluation for the selection. Third, the algorithm iterates over the depth-level\n~ of the cells. One cell is selected at every level (if there is an improvement\ncompared to the previous levels) and the cell is either sampled again or split.\n3.3.3 Planning for Parameterized Action Sequences\nTo integrate StoSOO with MCTS, we introduce so-called hybrid trees. Hybrid\ntrees contain nodes for actions and parameters. Hybrid trees are bipartite as a\nparameter selection must follow an action selection and vice versa. Partially-\nobservable hybrid trees (POHT) use three types of nodes: actions, parameters\nand the resulting observations. See Figure 3.7 for an example. Note that hybrid\ntrees not only grow at the leaf nodes. The paramter-nodes represent a cell in\nthe parameter space \u0398a of the associated action a. As the cells of a continuous\ndomain can be partitioned indefinitely often, a hybrid tree can grow new branches\nat the parameter-nodes during planning.\nFor planning in POHT, we want to combine OO with MCTS. The upper\nconfidence bound is used to select discrete actions and OO is used to select and\n3.3 Planning with Uncertainty and Continuous Action Parameters 71\niteratively refine the choice of action parameters. The StoSOO algorithm samples\nfrom the stochastic target function f several times within the SplitStoSOO\nprocedure. This prevents its unmodified use for simulation-based planning \u2013\nwithout backtracking \u2013 in sequential decision-making settings. Instead, we want\nevery call to the OO subproblem to return exactly one parameter combination \u03b8\nto continue the playout with the following steps in the scenario. The accumulated\nreward is then used to update the statistics for the involved branches of the\nscenario tree.\nAlgorithm 11 Stochastic Simultaneous Optimistic Optimization (StoSOO) on\nthe [0, 1]n cube. Cells are split after having been sampled \u03ba times.\n1: procedure StoSOO(f, \u03ba, \u03b9, \u03b7)\n2: L\u2190 {(0, 1)}, x[0, 1]\u2190 1 12\n3: q[0, 1] \u223c f(x[0, 1]), n[0, 1]\u2190 1\n4: while less than \u03b9 samples taken do\n5: qmax \u2190 \u2212\u221e\n6: for ~ = 0, . . . ,min(depth(L), ~max) do\n7: i\u2190 arg maxj:(~,j)\u2208L q[~, j] +\n\u221a\nlog(\u03b92/\u03b7)\n2n[~,j]\n8: r \u2190 q[~, i] +\n\u221a\nlog(\u03b92/\u03b7)\n2n[~,i]\n9: if r \u2265 qmax then\n10: qmax \u2190 r\n11: if n[~, i] < \u03ba then\n12: SampleStoSOO(~, i)\n13: else\n14: SplitStoSOO(~, i)\n15: return arg max(~,i),n[~,i]>0 q[~, i]\n1: procedure SampleStoSOO(~, i)\n2: y \u223c f(x[~, i])\n3: n[~, i]\u2190 n[~, i] + 1\n4: q[~, i]\u2190 q[~, i] + y\u2212q[~,i]n[~,i]\n1: procedure SplitStoSOO(~, i)\n2: v \u2190 max{l : x[~ + 1, l] 6= \u2205}\n3: d\u2190 mod(~, n) + 1\n4: o\u2190 \u03bdd\n( 1\n3\n)b~/nc+1\n5: for j \u2208 {1, . . . , 3} do\n6: L\u2190 L \u222a {(~ + 1, v + j)}\n7: x[~+1, v+j]\u2190 x[~, i]+(j\u22122)o\n8: SampleStoSOO(~ + 1, v + j)\n9: L\u2190 L \\ {(~, i)}\n72 3 Simulation-Based Planning for Concurrent Production Systems\n\u03b5\na1a2 a3\n\u03b80,1\n\u03b81,2\u03b81,1 \u03b81,3\n\u03b82,1\no1\na2 a1a3\no2\na3\no1\na2\no3\na3\nFigure 3.7: Partially Observable Hybrid Tree. The rectangle encompassing\nseveral circular nodes denotes a subtree for the optimisation of an action\nparameter with optimistic optimization. The tree is not fully explored for better\nvisual representation.\nPrevious authors have used OO for sequential decision-making with a contin-\nuous action-space [MWL11; Bus+13; BPM18]. The TrailBlazer algorithm\nof [GVM16] combines discrete action selection with continuous search. But it\nuses backtracking to return to a previous position in the scenario tree. In this\nthesis, we want to avoid storing the system state for backtracking search. So the\nalgorithms can just as well be performed with playouts in physical experiments\nonly.\nWe now develop the novel Partially Observable Hybrid Tree Planning (PO-\nHTP) algorithm that combines MCTS \u2013 and in particular the approach for\npartially-observable planning from to the POMCP algorithm \u2013 with Optimistic\nOptimization for parameter selection on continuous domains. See Algorithm 12\nfor the full details. In every step for sequential decision making, the algorithm is\npresented with the choice of several discrete actions that are each parameterized\nfrom a continuous domain. If there is only one action, POHTP reduces to\nStoSOO as a special case. On the other hand, if the actions have no parameters,\nPOHTP reduces to a variation of POMCP. The difference to the original POMCP\n3.3 Planning with Uncertainty and Continuous Action Parameters 73\nis the update mechanism that maximizes over possible choices to compute the\nV-value estimate (instead of taking the empirical reward from the previous\nplays), full playouts and a switch between exploitation and exploration within\neach playout that is explained in the next paragraph.\nIn contrast to POMCP, no rollouts are used that aggregate the reward beyond\nthe previously constructed tree. Instead, the full history of every playout is\nrecorded and used to update the value estimates for the nodes in a second\nUpdate procedure. Furthermore, the upper confidence bound is not used for\ndecision-making at every step. Instead, the algorithm initially takes optimal\ndecisions (for the current value estimates) and switches to an explorative regime\nat the depth d of the decision tree. In the StoSOO algorithm, the dimension\nalong which to split the current cell is determined by the depth in the search tree.\nThe important ingredient of StoSOO to achieve fast convergence is to select cells\nfrom a specific depth in each iteration. Similar to StoSOO, POHTP for every\niteration selects a depth at which the \u201cexploration\u201d (splitting in StoSOO) begins.\nThe depth d for this switch of the action-selection regime is iterated together\nwith number of performed playouts. Every action contributes one level to the\ndepth of the decision tree. The parameters of the action a contribute according\nto the depth in the embedded tree for the parameter selection L[ha] for the\naction a after an observed history h. The depth of the parameter-selection tree\ndepth(L[ha]) is the number of times the smallest cell represented in the tree\nhas been split.\nThe POHTP procedure initializes the algorithm and then iterates over a series\nof playouts. Importantly, the exploration depth for decision-making d is cut\noff at the maximum decision-making depth at log2 of the number of playout\niterations.\nThe Play procedure simulates steps until the current scenario is \u201cdone\u201d. If\na node in the search has not been encountered before, the policy \u03c0 is used to\nselect action and action-parameters. Otherwise, the action is selected via a UCB\nevaluation and the parameter is selected via OO.\nThe Update procedure stores the empirical mean reward that is directly\ngenerated by an action-parameter combination as e[ha\u03b8]. The Q-value associated\nwith the action-parameter combination additionaly takes the expected following\nreward into account. This is again the empirical mean over the observations\n74 3 Simulation-Based Planning for Concurrent Production Systems\nAlgorithm 12 Partially Observable Hybrid Tree Planning (POHTP)\n1: procedure POHTP(\u03c30)\n2:\nn[ \u00b7 ]\u2190 0, q[ \u00b7 ]\u2190 0, e[ \u00b7 ]\u2190 0,\nL[ \u00b7 ]\u2190 {(0, 1)},\nx[ \u00b7 ; 0, 1]\u2190 1 12 , d\u0304\u2190 1\n3: while enough time do\n4: (h, r)\u2190 Play(\u03c30)\n5: Update(h, r)\n6: d\u0304\u2190 d\u0304 + 1\n7: if d\u0304 > log2(n[\u03b5]) then\n8: d\u0304\u2190 1\n9: return arg max\n(a,\u03b8):n[a\u03b8]>0\nq[a\u03b8]\n1: procedure Param(ha, d\u0304)\n2: if d\u0304 > depth(L[ha]) then\n3: return arg max\n\u03b8:\u2203(l\u0304,i)\u2208L[ha],\nx[ha;l\u0304,i]=\u03b8\nq[ha\u03b8]\n4: else if d\u0304 < 1 then\n5: G\u2190 L[ha]\n6: else\n7: G\u2190 L[ha; d]\n8: (~, i)\u2190 arg max\n(l\u0304,j)\u2208G,\nx[ha;l\u0304,j]=\u03b8\n[\nq[ha\u03b8] +\n\u03b1\n\u221a\nlog n[ha]+1\nn[ha\u03b8]\n]\n9: \u03b8 \u2190 x[ha; ~, i]\n10: if n[ha\u03b8] < \u03ba \u2227 ~ = ~max then\n11: return \u03b8\n12: u[ha; ~, i]\u2190 u[ha; ~, i] + 1\n13: \u00b5\u2190 u[ha; ~, i]\n14: n\u2190 dim(\u0398a)\n15: \u03b4 \u2190 mod(~, n) + 1\n16: \u03be \u2190 |L[ha; ~ + 1]|+ 1\n17: x[ha; ~ + 1, \u03be]\u2190 \u03b8 +\n(\u00b5\u2212 2)\u03bd\u03b4\n(\n1\n3\n)b~/nc+1\n18: L[ha]\u2190 L[ha] \u222a {(~ + 1, \u03be)}\n19: if \u00b5 = 3 then\n20: L[ha]\u2190 L[ha] \\ {(~, i)}\n21: return x[ha; ~ + 1, \u03be]\n1: procedure Update(h)\n2: for k = |h|, . . . , 1 do\n3: g = h:k\u22121\n4: (a, \u03b8,o, r)\u2190 hk\n5: n[ga\u03b8]\u2190 n[ga\u03b8] + 1\n6: e[ga\u03b8]\u2190 r\u2212e[ga\u03b8]\nn[ga\u03b8]\n7: q[ga\u03b8]\u2190 e[ga\u03b8] +\u2211\no\u2208O\nq[ga\u03b8o]n[ga\u03b8o]\nn[ga\u03b8]\n8: n[ga]\u2190 n[ga] + 1\n9: q[ga]\u2190 max\n\u03c6\u2208\u0398a,\nn[ga\u03c6]>0\nq[ga\u03c6]\n10: n[g]\u2190 n[ga] + 1\n11: q[g]\u2190 max\nb\u2208A,\nn[gb]>0\nq[gb]\n1: procedure Play(\u03c3, d\u0304)\n2: h\u2190 \u03b5\n3: while \u00acdone(\u03c3) do\n4: B \u2190 {b \u2208 A : n[hb] = 0}\n5: if d\u0304 > 1 \u2227 n[h] > 0 then\n6: a\u2190 arg max\nb\u2208A,n[hb]>0\nq[hb]\n7: d\u0304\u2190 d\u0304\u2212 1\n8: \u03b8 \u2190 Param(ha, d\u0304)\n9: else if B 6= \u2205 then\n10: (a, \u03b8)\u2190 \u03c0B(\u03c3)\n11: d\u0304\u2190 d\u0304\u2212 1\n12: else\n13:\na\u2190 arg max\nb\u2208A\n[\nq[hb] +\n\u03b1\n\u221a\nlog n[h]+1\nn[hb]\n]\n14: d\u0304\u2190 d\u0304\u2212 1\n15: \u03b8 \u2190 Param(ha, d\u0304)\n16: d\u0304\u2190 d\u0304\u2212 depth(L[ha])\n17: (\u03c3\u2032,o, r) \u223c a\u03b8(\u03c3)\n18: h\u2190 ha\u03b8or, \u03c3 \u2190 \u03c3\u2032\n19: return h\n3.3 Planning with Uncertainty and Continuous Action Parameters 75\nfollowing the action-parameter combinations. The Q-value for the action and\nthe observation maximize over the respective choices.\nSo the periods in the observed history are hk = (ak\u03b8kok). Updating the\nparameterization-nodes is very similar to the updating of action-nodes in POMCP.\nThe considered statistic simply keeps count of how often the node was visited and\nthe empirical reward generated in the ensuing subtree. Since action parameters\nare now selected as well, the rollout policy \u03c0(s,A) for choosing an action also\nreturns a matching parameterization. Choosing a good rollout policy is crucial\nsince the optimization of parameterized actions leads to a large number of\nbranches and the search encounters a previously unknown part of the scenario\ntree in most iterations.\nThe Param procedure returns exactly one parameter combination for the\ncurrent selected action a. Again, if d is higher than the depth of L[ha], then\nthe best leaf node is returned. Other Param is in the explorative regime. If d\nis smaller than one, then the upper confidence bound is used to select the best\nparameter among all parameters in the tree. If instead d points to a depth-level\ninside L[ha], then a node at this depth is selected. Note that a level can become\nempty when all nodes in the level have been split. If L[ha] contains the indices\nof the leaf cells, then L[ha; d] denotes the first level containing leaf cells above\nor at depth d.\nL[ha; d] = {(c, i) \u2208 L[ha] : c \u2265 d, @e \u2208 {d, . . . , c\u2212 1},\u2203(e, j) \u2208 L[ha]}\nIf the thus selected parameter has been sampled less than \u03ba times, it will be\nreturned. Otherwise the selected cell in the parameter space is split. And the\ncurrent cell is removed from the list of leaf cells.\nThe POHTP algorithm can be combined with the pruning of equivalent\nsequences according to Section 3.1.2. Now the equivalence applies not only\nto action sequences, but to histories where every step consists of an action, an\naction parameter and the resulting observation. Entire steps can be commuted if\nthe respective actions are independent. Note that no problem-specific structure\nis exploited in the POHTP algorithm developed in this chapter.\n76 3 Simulation-Based Planning for Concurrent Production Systems\n\u03b2\nx\nFigure 3.8: The inverted pendulum problem. The goal is to perform a swing-up\nof the pendulum to an angle \u03b2 = 0 and to keep the pendulum in the upright\nposition.\n3.3.4 Evaluation\nSwingup of an inverted pendulum\nPlanning for parameterized actions is evaluated for an inverted pendulum\ndisplayed in Figure 3.8. The inverted pendulum is one of the canonical problems\nin the literature on optimal control [Lib11]. A pendulum is attached to a cart\nthat is free to move in the horizontal plane. The goal is to perform a swing-up to\nbring the pendulum into an upright position \u2013 and keep it there \u2013 by the precise\napplication of an accelerating force to the cart.\nThe full problem definition is as follows. Assume a single system component\npend for the pendulum and a single action acc with a parameter \u0398acc =\n[\u22122N, 2N ] for the force applied to accelerate the cart. The cart and the pendulum\nare approximated by point-masses mc and mp of 1kg each. The length of the\npendulum l is one meter. The angle of the pendulum \u03b2 gives the difference from\nthe upright position. The position of the cartx is in meters from the point of origin.\nThe initial state of the pendulum is s0pend = (\u03b2 = 0.5, \u03b2\u0307 = 0, x = 0, x\u0307 = 0).\nThe state evolution of the pendulum is described by two coupled differential\n3.3 Planning with Uncertainty and Continuous Action Parameters 77\nequations for the cart position x and the pendulum angle \u03b2 [FYK92]:\nx\u0307 = \u2212mpg sin(\u03b2) +mpl sin(\u03b2)\u03b2\u0307\n2 + u\nmc +mp sin2(\u03b2)\n\u03b2\u0307 = (mp +mc)g sin(\u03b2)\u2212mpl sin(\u03b2) cos(\u03b2)\u03b2\u0307\n2 \u2212 cos(\u03b2)u\nl(mc +mp sin2(\u03b2)\n(3.9)\nThe simulation time is discretized into periods of 0.2s. The effect of the action\nacc is the (numerical) solution to the forward simulation of Equation (3.9) for\nthe control value u given by the action parameter. The reward returned by acc\nis a cost term associated with the resulting pendulum state s\u2032 and the energy\nexpenditure for the control.\nracc(u, s\u2032) = 2\u2016\u03b2\u2032\u2016+ x+ u2 (3.10)\nBy \u2016 \u00b7 \u2016 we denote the angular distance from the upright position.\nThe control (acceleration) applied in each period is the result of POHTP\nwith 512 playouts over a horizon of 15 steps with a 0.2s time discretization.\nEven though the step length is discretized, the simulation uses the Runge-Kutta\nmethod for precise forward-simulation of the underlying differential equation.\nAfter the 512 playouts, the acceleration parameters with the best Q-value is\nselected and applied. The optimization is then repeated for the resulting system\nstate. This resembles optimal control based on MPC [ML99]. But as we directly\noptimize on the model from Section 2, we make less limiting assumptions than\ntraditional MPC based on convex optimization.\nAs can be seen in Figure 3.9, the POHTP algorithm achieves the swing-up and\nbalancing of the inverted pendulum. Note that the angle plateaus at multiples of\n2\u03c0 due to the use of the angular distance in the cost function. Adapting the cost\nfunction with a higher penalty for the angle leads to a more speedy swingup.\nBut at a greater cost for the control energy u.\nOptimal Order Quantity under Uncertainty\nThe scenario is concerned with the operations of a pencil factory. A customer\ngives the order for 50,000 pencils with his company logo on the casing. The\ncustomer is willing to pay $2 for each pencil. No payment is made if the order is\n78 3 Simulation-Based Planning for Concurrent Production Systems\n0 0.5 1 1.5 2 2.5 3 3.5 4\n\u22125\n0\n5\nA\nng\nle\n\u03b2\n0 0.5 1 1.5 2 2.5 3 3.5 4\n0\n0.2\n0.4\n0.6\nPo\nsi\ntio\nn\nx\n0 0.5 1 1.5 2 2.5 3 3.5 4\n\u221240\n\u221220\n0\n20\n40\nTime in seconds\nC\non\ntro\nlu\nFigure 3.9: Swingup of an inverted pendulum. The initial of the pendulum is at\n160 degrees (\u03b8 = 160180\u03c0). The upper time series show the penalization for |\u03b8|.\nThe lower time series show the penalization of | atan2(sin(\u03b8), cos(\u03b8))| where\n\u201cloopovers\u201d, e.g. angles at a multiple of 2\u03c0 are not penalized.\nincomplete or arrives too late. The plastic pencil casings with the logo printing\nare bought from a supplier that demands $0.5 for each casing. The production\ncosts in our factory are $1. So, in theory, the pencils are sold to the customer with\na margin of $0.5 each. However, some pencils do not make it through quality\ncontrol. Every pencil has a 10% chance of being sorted out by an inline quality\ncontrol system that verfies every single product. Due to the time constraints, it\nis not possible to reorder additional pen casings at the supplier once production\nhas started. The question now is: how many pencil casings should be ordered at\nthe supplier initially in order to maximize the expected earnings?\nIn order to compare the results of our tree-search planning, we implemented\na simple \u201cbrute-force\u201d solution technique: Monte-Carlo simulations for all\npossible solutions in the relevant range. The simulation model is as follows.\nAssume that n pencil casings have been delivered by the supplier. Start to\nproduce pencils until either 50.000 pencils are done or more than n\u2212 50.000\ncasings were discarded due to quality problems (otherwise, we would continue\n3.3 Planning with Uncertainty and Continuous Action Parameters 79\n55000 55200 55400 55600 55800 56000\nNumber of Ordered Casings\n100000\n80000\n60000\n40000\n20000\n0\n20000\n40000\nAv\ner\nag\ne \nEa\nrn\nin\ngs\n in\n $\nFigure 3.10: Expected reward for different numbers of ordered pencil casings.\nThe average was computed over 100 simulation runs each. The shaded area\nindicates the empirical standard deviation.\nlosing money during production without being able to complete the order\neventually). Figure 3.10 shows the results of the Monte-Carlo simulation in\nthe range between 55.000 and 56.000 ordered pencil casings. The results show\na phase transition between virtually all samples not completing the order to\nvirtuall all samples completing the order. In the transition range, only some\norders are completed and this number differs between simulations. Therefore,\nthe standard deviation for the reward is much bigger in the transition range.\nAccording to the Monte-Carlo simulations, the optimal order quantity is 55.750,\nresulting in an expected reward of $1,6575. With less ordered pencil cases,\nthere is a high likelihood of the order not completing. Every additional pencil\ncase incurs higher cost than the additional likelihood of completing the order\njustifies.\n101 102 103\nNumber of Simulations\n20000\n10000\n0\n10000\nEx\npe\nct\ned\n R\new\nar\nd \nin\n $\nFigure 3.11: Convergence speed of the optimization for the order quantity under\nuncertainty example.\n80 3 Simulation-Based Planning for Concurrent Production Systems\nFigure 3.11 shows the empirical reward of the best paramater after a certain\nnumber of plays.\n3.4 Planning with Linear Actions\nMost manufacturing systems perform repetitive tasks. While lot sizes have\ngenerally become smaller, most products are still produced in bulk. When many\nproduct instances are considered individually, the action sequences can become\nvery long. This section identifies a large class of actions where reasoning and\nplanning for action repetition is simplified.\nExample 3.4. Consider a stamping press that takes in raw material from\nan aluminum coil. The action stamp puts the produced work-pieces of\ntype p1 into a lattice box adjacent to the press. Every execution of stamp\nincreases the number of parts in the lattice box by one and reduces the\nlength of the remaining aluminum coil by 2.5cm. Suppose that 20m\nof coil are loaded initially. How often can stamp be repeated and how\nmany additional parts will be in the lattice box afterward? The answer is\nof course trivial. But how can this type of reasoning be made accessible\nto a planning algorithm that operates on the actions from Definition 2.4?\n3.4.1 Linear Actions and Action Repetition\nReasoning about the effects of the action stamp in Example 3.4 is easy and\nintuitive. The action has a fixed effect and repeating the action n times multiplies\nthe effect by n. We can compute the maximum number of repetitions of\nstamp that are possible starting from the described initial state. It is implicit\nto Example 3.4, that if the action stamp can be repeated n times, any number\nof repetitions between zero and n is also possible. We now spell out these\nimplicit assumptions in the form of conditions that so-called linear actions have\nto conform to in addition to Definition 2.4.\nDefinition 3.7. An action a\u0304 is linear if the following conditions hold.\n3.4 Planning with Linear Actions 81\n1. The effect of the action ea\u0304 is the generator of a semimodule [Gol99]\nEa\u0304 that is closed under composition (Ea\u0304, \u25e6) and multiplication with\nnon-negative scalars, so that (ea\u0304 \u25e6 ea\u0304)(\u03c3a\u0304) = (2ea\u0304)(\u03c3a\u0304) for all feasible\n\u03c3a\u0304.\n2. Let a\u0304n denote the n-fold application of a\u0304. If the action can be repeated\nn times (that is a\u0304n\u22121(\u03c3) \u2208 \u03a3a\u0304) then any number of repetitions between\nzero and n is possible.\n\u03c3 \u2208 \u03a3a\u0304 \u2227 a\u0304n(\u03c3) \u2208 \u03a3a\u0304 \u21d2 \u2200k \u2208 {0, . . . , n}, a\u0304k(\u03c3) \u2208 \u03a3a\u0304 (3.11)\n3. The action duration is identical for all feasible initial states.\n\u2200(\u03c3,\u03c3\u2032) \u2208 \u03a3a\u0304 \u00d7 \u03a3a\u0304, da\u0304(\u03c3a\u0304) = da\u0304(\u03c3\u2032a\u0304) (3.12)\n4. A constant reward ra\u0304 is generated for every action repetition.\nLinear actions have advantages over normal actions: First, once the maximum\nnumber of repetitions has been established, the preconditions don\u2019t need to be\nverified for every repetition. Second, the effect of repeatedly applying the action\ncan be computed with analytical shortcuts instead of n-fold composition of the\neffect function.\nThe notation for repeated application of an action resembles the notation\nfor action parameterization. This is intentional. Repetition of linear actions\nis a special case in the general framework of parameterized actions. If a\nparameterized action is also linear, the notation a\u03b8,n indicates that the same\nparameter \u03b8 \u2208 \u0398a\u0304 is applied for each of the n repetitions.\nThe following joke from the mathematical folklore [RD05] sets the frame for\ndiscussing the composition of linear actions and the superposition of the effects.\nA biologist, a physicist, and a mathematician sit in a street caf\u00e9 watching the\ncrowd. Across the street they see a man and a woman entering a building. Ten\nminutes later they reappear together with a third person.\nbiologist: They have reproduced.\nphysicist: The measurement wasn\u2019t accurate.\n82 3 Simulation-Based Planning for Concurrent Production Systems\nmathematician: If exactly one person enters the building now, it will be\nempty again.\nThe mathematician treats the operators \u201cperson entering the house\u201d and\n\u201cperson leaving the house\u201d as elements from an algebraic group (entering is\nthe inverse of leaving). The group is indeed closed under composition. But\nthe operator resulting from the composition does not apply to all situations.\nObviously, there can be no negative number of people in the house. Translated\nto our case, components cannot contain a negative number of products. This\nuniversal constraint has ramifications on the definition of linear action.\nSuppose that for the considered linear action a\u0304, the participating components\nCa\u0304 can hold products inside the component. So their state is described by a\ntuple s = (\u03be,p) for the configuration \u03be and the number of contained products\nfor every product type p (cf. Section 2.1). Definition 3.7 implies a linear effect\non the contained products in the components. This effect can be expressed\nby a fixed change vector \u03b4a\u0304c \u2208 Z|P |. So for a state transition \u03c3\u2032 = a\u0304(\u03c3) and\ncomponent c \u2208 Ca\u0304, the state transition is between sc = (\u03be,p) and s\u2032c = (\u03be\u2032,p\u2032)\nand the product change is p\u2032 = p + \u03b4a\u0304c .\nSince the number of products in the component cannot be negative, there\nis a universal positivity constraint for all linear actions. The feasible states all\nconform to the positivity constraint \u03a3a\u0304 \u2286 \u03a3+a\u0304 .\n\u03a3+a\u0304 = {\u03c3 \u2208 \u03a3 : \u2200c \u2208 C\u0304a\u0304, \u03c3c = ((\u03be,p), t), p + \u03b4a\u0304c \u0017 0} . (3.13)\nFor many linear actions, the condition (3.11) can be shown to hold with a\nconvexity argument. This is illustrated by the following example.\nExample 3.5. This example builds on the previous Example 3.4. Suppose\nstamp is a linear action with the participating components Cstamp =\n{box, press}. The lattice box has no particular configuration state\nand \u039ebox = \u2205. The configuration of the press \u03bepress = (\u03betool, \u03becoil)\nconsists of the press tooling for either product p1 or p2 and the remaining\nlength of the coil. So the configuration space for the press is \u039epress =\n{p1, p2}\u00d7R+. An additional condition of the press is that at least 50cm\n3.4 Planning with Linear Actions 83\nof coil need to remain after the action in order to facilitate replenishing.\nThe condition of the lattice box is that the maximum load of 300kg shall\nnot be exceeded.\nThe effect on the products in the lattice box \u03b4stampbox = \u03bdp1 contains\nmostly zeros with a single one-entry at the p1 position. There is no\neffect on the lattice box configuration. So the effect on the box is\n(nestamp)(\u03c3stamp)box = (\u2205,pbox + n\u03bdp1). Let the vector \u00b5 describe the\nweight of every product. Then the initial states that are feasible for the\nlattice box are\n\u03a3stamp:box = {\u03c3 \u2208 \u03a3 : \u00b5>(pbox + \u03bdp1) \u2264 300} .\nThe action has no effect on the products contained in the press and\n\u03b4\nstamp\npress = 0. (As before, 0 is the null-vector of appropriate size). For\nsimplicity, we refer to the state after executing stamp as \u03c3\u2032 (with\nanalogous notation for its components). The action has no effect on the\ntooling of the press \u03be\u2032tool = \u03betool and the remaining coil length is reduced\nby a fixed amount \u03be\u2032coil = \u03becoil \u2212 2.5. So the n-fold repetition has the\nfollowing effect (nestamp)(\u03c3stamp)press = ((\u03betool, \u03becoil \u2212 2.5n),0). At\nleast 50cm of coil need to remain in the press and\n\u03a0press(Fstamp) = {\u03c3 \u2208 \u03a3 : \u03becoil \u2212 2.5 \u2265 50} .\nThe valid initial states for stamp must lie in the feasible set for both the\npress and the lattice box. In addition, no negative number of products\nmust be contained in a component is given by the positivity constraint\n\u03a3+stamp. In total, the feasible states for beginning the action are\n\u03a3stamp = \u03a3stamp:box \u2229 \u03a3stamp:press \u2229 \u03a3+stamp .\nThe following proof sketch shows that (3.11) holds for stamp. Let\n\u03c8(\u03c3) = (pbox, \u03becoil) a projection of the set of feasible initial statesX =\n{\u03c8(\u03c3) : \u03c3 \u2208 \u03a3stamp}. The three constraints \u03a3stamp:box, \u03a3stamp:press and\n84 3 Simulation-Based Planning for Concurrent Production Systems\n\u03a3+stamp are then expressed as a system of linear inequalities for all x \u2208 X .\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u2212\u00b5> 0\n01\u00d7|P | 1\nI |P | 0\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fbx \u0017\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u00b5>\u03b4stampbox \u2212 300\n52.5\n\u2212\u03b4stampbox\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb . (3.14)\nSince X is equivalent to {x \u2208 (N|P |0 \u00d7 R) : condition (3.14) is true},\nthe space of projected valid initial states is convex. The effect of stamp\non X is described by a linear operator f(x) = x + (\u03b4stampbox , 2.5). The\noperators stamp and f are related as \u03c8 \u25e6 stamp = f \u25e6 \u03c8. The n-fold\napplication of f is a linear equation. Due to the described convexity\nproperty of X , for all n \u2208 N0 and initial state representations x \u2208 X ,\nthere is\n(\nx+n\n\uf8ee\uf8ef\uf8f0\u03b4stampbox\n2.5\n\uf8f9\uf8fa\uf8fb ) \u2208 X \u21d2 \u2200k \u2208 {0, . . . , n}, (x+k\n\uf8ee\uf8ef\uf8f0\u03b4stampbox\n2.5\n\uf8f9\uf8fa\uf8fb ) \u2208 X .\nSince for every x \u2208 X there exists at least one \u03c3 \u2208 \u03a3stamp such that\nx = \u03c8(\u03c3), the linear action stamp satisfies Equation 3.11.\n3.4.2 MILP Relaxation of the Planning Problem\nLinear actions were introduced with the promise to simplify reasoning and\nplanning of action sequences with many repetitions. Now we relax the planning\nproblem with linear actions so that it can be solved as a Mixed-Integer Linear\nProgram (MILP) [BW05]. The MILP formulation can be solved with off-the-\nshelf solvers [Gur16]. In constrast to MCTS, the planning complexity for the\nrelaxed planning problem is mostly independent of the number of repetitions for\neach action. Used as part of a rollout policy, the MILP relaxation allows the\nscaling to scenarios with hundreds of individual products that are considered at\nonce. On the downside, it imposes limits on the model dynamics that can be\nrepresented.\n3.4 Planning with Linear Actions 85\nAssumption 3.8. In the remainder of this chapter, the following two assumptions\nare made.\n1. All considered actions are linear.\n2. The constraints for the feasible initial states \u03a3a, only refer to the number\nof contained products and not the component configuration.\n3. All actions can be executed \u201cin parallel\u201d even if they have the same\ncomponents participating and their effect superimposes for the final\nsystem state.\nIn the Example 3.5, suppose a second action take that takes out one finished\npiece from the lattice box. In order to take out 500 pieces, we need to run stamp\n500 times as well. Now that we assume actions can run \u201cin parallel\u201d on the\nsame components, how can the preconditions for the feasible initial states be\nrepresented? So far we have worked with feasible initial states \u03a3a. For linear\nactions, this can be transformed to the set of feasible post-states \u0393a \u2286 \u03a3.\n\u0393a = {\u03c3 \u2208 \u03a3 : \u2203\u03c9 \u2208 \u03a3a, \u03c3 = a(\u03c9)} (3.15)\nFor linear actions with a fixed effect vectors \u03b4ac , the conversion between \u03a3a and\n\u0393a can be achieved by a simple translation of the constraints describing the set\n\u03a3a. Instead of tracking the feasible initial states before the execution of the\nactions, we only demand that the final system state, when each action has been\nrepeated the desired number of times, is a feasible post-state for all the actions.\nEvery action and every component are assigned an index from {1, . . . , |A|}\nand {1, . . . , |C|} respectively. Let x = (pc)c\u2208C denote the concatenated\ncolumn vector for the products initially contained in the different components.\nSo x is a vector with |C||P | elements. In the second statement of Definition 3.7,\nit is demanded that a feasible n-fold repetition indicates that any number of\nrepetitions between zero andnmust be feasible. Since the effect on the number of\ncontained products (and only these are considered here) is linear, the constraints\nfor the feasible initial states must be the intersection of a convex set with the\nset of integers. Otherwise, it would be possible to find a system stat \u03c3 where\nthe action a in question can be executed n times but not n \u2212 1 times. As the\n86 3 Simulation-Based Planning for Concurrent Production Systems\nconstraints encoded in \u03a3a (and therefore also \u0393a) are convex in that sense, they\ncan be represented as the intersection of half-spaces via a set of linear inequalities\n[BV04] defined by a matrix Ha and vector ga, such that Hax \u0017 ga.\nIn a production scenario, most actions are associated with costs for material,\nenergy, worker\u2019s wages, and so on. But some actions have positive reward, such\nas finishing an order for the customer. After completing the order, we could\nmake more products. But if the customer won\u2019t pay for them they only incurr\ncosts. This is represented for the MILP as follows: Denote with the vector n the\nnumber of repetitions for each action. The vector r contains the costs incurred\nfor every repetition of the actions.\nGoals are defined by a number of target repetitions ng \u2208 N |A|0 for every\naction. Each repetition of the action a up to nga yields the additional goal reward\nrga. The total goal reward for the repetitions n \u2013 in addition to the reward\ngenerated from each action\u2019s fixed reward ra \u2013 is\u2211\na\u2208A\n[\nmin{na, nga} rga\n]\n. (3.16)\nThe MILP computes (3.16) by the introduction of a slack variable v that counts\nthe missing repetitions for each action according to the goal definition. The\nobjective function takes the reward for reaching all goals and subtracts the\nmissing repetitions according to the slack variable.\nThe column vector \u03b4a \u2208 N|C||P | describes the effect of action a on the\nproducts contained in all components. These effect vectors are assembled to a\nmatrix \u2206 \u2208 Z|C||P |\u00d7|A| for the effect across all actions.\n\u03b4a = (\u03b4ac )c\u2208C , \u2206 = [\u03b41, . . . , \u03b4|A|] (3.17)\nThe post-state after executing all action repetitionsn isx\u2032 = x+\u2206n. Optimizing\nthe repetitions to maximize the reward under the defined constraints then gives\nthe MILP formulation:\nV\u0304 (x,ng, rg) = max\nn\u2208N|A|0\n[\nn>r\u2212 v>rg\n]\n+ ng>rg (3.18)\n3.4 Planning with Linear Actions 87\nsuch that\nx + \u2206n = x\u2032 (3.19)\nHax\u2032 \u0017 ga, \u2200a \u2208 A (3.20)\nn + v \u0017 ng (3.21)\nx\u2032 \u0017 0, n \u0017 0, v \u0017 0 (3.22)\nx\u2032 \u2208 R|C||P |0 ,n \u2208 N\n|A|\n0 , v \u2208 R\n|A|\n0 (3.23)\nFunction V\u0304 approximates the value of the system state x (with only the contained\nproducts) for optimal decision making in the MILP relaxation. The goal is to\nmaximize the reward, including the goal reward. The constant additive term\nng>rg can be removed for the actual optimization. But it is required to recover\nthe actual V -value for the relaxed planning problem including the goal reward.\nLagrangian relaxation is used to penalize if an action a is repeated less than\nnga times. The slack vector v gives the number of repetitions lacking for every\naction. (If the goal is met, the slack variable is zeroed out by the optimizer.) In\npractice, the dimensionality of x and \u2206 can be reduced by considering only the\nproducts that are actually referred to by the linear actions. The maximum number\nof repetitions for each action is nmax. This maximum number of repetitions is\nonly introduced to model binary values: The vector m contains binary values\nfor the fixed reward incurred if an action is repeated at least once.\nThe constraints for the optimization are as follows. The post-state x\u2032 after\nall repetitions have been executed is computed in (3.19). The post-conditions\nfor all actions must hold simultaneous for x\u2032 according to (3.20). In (3.21), the\nslack value v is set to the number of missing repetitions according to the goal\ndefinition. The constraints in (3.22) ensure that the number of products in the\nfinal state, the number of repetitions and the slack repetitions are all non-negative.\nIn (3.23), the repetitions n are required to be integers. The number of remaining\nproducts x\u2032 and the slack v are real values. But they will only take on integer\nvalues since the repetitions are a natural number and the system dynamics in \u2206\nleads to integer changes.\nFor every action selection in the rollout policy, the relaxed planning problem\nis solved. Actions that are slated for zero repetitions by the relaxed solution and\n88 3 Simulation-Based Planning for Concurrent Production Systems\nactions that are not immediately executable due to their preconditions are ignored.\nA sensitivity analysis is performed for the remaining actions: For every action a\nmodified version of the original MILP is solved where the number of repetitions\nfor that action is fixed to be one less than in the original solution. The difference\nof the new solution in the objective function is a grade for \u201cimportance\u201d of that\naction. The rollout policy then returns the action with the highest importance\nand the number of repetitions chosen for the action via the MILP relaxation.\nAlgorithm 13 Rollout policy for linear actions. Takes as input the current state\nand returns a linear action for the next step and its repetitions.\n1: procedure \u03c0linear(\u03c3,h,ng, rg)\n2: x\u2190 (pc)c\u2208C . State vector of contained products in all components\n3: n\u2217 \u2190 V\u0304 (x,ng, rg) . Optimal repetitions in the MILP relaxation\n4: B \u2190 {b \u2208 A : \u03c3 \u2208 \u03a3b \u2227 n\u2217b > 0 \u2227 TestLNF(h, b)}\n5: b \u223c U(B) . Uniform sampling among the eligible actions\n6: n\u2032 \u2190 max{m \u2208 {1, . . . , n\u2217b} : bm\u22121(\u03c3) \u2208 \u03a3b}\n7: return (b, n\u2032)\nThe above description of the setting can be translated to a MILP. Since all\nactions are linear, no additional relaxations are required besides the assumption\nthat actions can execute \u201cin parallel\u201d. By using the solution to the linear program\nto guide the rollout, the global optimum is found already in the first rollout.\n3.4.3 Evaluation\nConsider a simplified supply chain for the production of mobile phones. See\nFigure 3.12 for an overview. The OEM (Original Equipment Manufacturer)\nowns the phone brand as well as production sites for soldering, assembly and\npackaging. Parts are bought from suppliers. The final phone is assembled from\na case, a battery, a screen and a PCB (printed circuit board) with a chipset\nsoldered on. If the production capacity of the OEM is insufficient, assembled\nphones can be bought from an external contract manufacturer. The cost for\nsoldering, assembly and packaging are $10 each. Transportation costs are not\nassumed for the example. The following prices are demanded by the suppliers.\n3.4 Planning with Linear Actions 89\nPCB2\nChipset\nPCB1\nSoldering Assembly Packaging\nCase\nExternalBattery Screen\n4000 1000\n5000\n5000\n5000 5000\n5000\n5000\n1000\n6000\nFigure 3.12: Supply chain example. The arrows denote the possible number of\ntransported products between production sites and suppliers.\n\u2022 PCB1: $5\n\u2022 PCB2: $2\n\u2022 Chipset: $20\n\u2022 Battery: $30\n\u2022 Screen: $30\n\u2022 Case: $10\n\u2022 Assembled Phone: $150\nThe supplier PCB1 has limited stock and can deliver at most 1,000 PCB. The\nchipset supplier has limited stock of 5,000 remaining chipsets. As a consequence,\nthe first 1,000 phones cost $122 to make (bill of material and production costs).\nPCB for additional phones have to be bought from the alternative supplier PCB2\nat a higher price. The phones then cost $125 to make. For more than 5,000\nphones, the required chipset is no longer available. But assembled phones can\nstill be bought from the contract manufacturer. This comes at the increased cost\nof $160 for each phone: $150 for the phone and $10 for branding and packaging.\nSo buying from the contract manufacturer is more expensive than producing the\nphones in the OEM\u2019s production facilities. It might however be required to buy\nassembled phones in order to complete a large order.\nConsider now a scenario where a customer orders 6,000 phones for the price\nof $175 each. What are the maximum earnings (revenue minus cost) the OEM\ncan achieve in each scenario? For this supply-chain example, the optimization\nproblem was solved exactly by the MILP. Hence the decisions by the rollout\npolicy immediately led to the globally optimal action and parameter sequence.\n(This is not the case for all planning problems. For example when only a subset\n90 3 Simulation-Based Planning for Concurrent Production Systems\nof the actions is linear.) The MILP was solved with the commercial solver\nGurobi [Gur16]. For details, refer to the literature for optimization of convex\nfunctions and optimization over integers [BV04; BW05]. The phones are sold\nfor $1,050,000 and were produced at a cost of $762,000. This leaves a profit\nmargin of $288,000.\n4 Distributed Planning for Self-Organizing\nProduction Systems\nOutside the firm, price movements direct production, which\nis co-ordinated through a series of exchange transactions\non the market. Within a firm, these market transactions are\neliminated and in place of the complicated market structure\nwith exchange transactions is substituted the entrepreneur-\ncoordinator, who directs production. It is clear that these\nare alternative methods of coordinating production. Yet,\nhaving regard to the fact that, if production is regulated by\nprice movements, production could be carried on without\nany organization at all might we ask, why is there any\norganization?\nRonald H. Coase [Coa37]\nThe coordination of industrial production is historically performed either\nby a central planner or market-mechanisms for coordination. The former is\nfraught with the problem of keeping the model for planning up-to-date and\nthe complexity of planning itself. The latter has the problem of suboptimal\nsolutions arising from market-based coordination. The core idea of markets is\nto have selfish participants maximize their personal gain. Under some technical\nconditions, markets are \u201cefficient\u201d for the incorporation of information into\nprices and the allocation of goods according to a preference function of the\nbuyers [MF70]. From Game Theory, we know the existence of suboptimal\nequilibria in situations with competing agents where no participant has an\nincentive to change his strategy even though an equilbrium with higher overall\nwelfare exists [Nas51]. In this thesis we instead assume cooperating agents that\naim to jointly maximize the overall reward.\n92 4 Distributed Planning for Self-Organizing Production Systems\nThis chapter extends the model from Chapter 2 to include multiple agents\nthat coordinate their actions in a distributed fashion. Afterwards the POHTP\nalgorithm from Chapters 3 is adapted for the distributed setting. The result is a\ndistributed planning algorithm where agents exchange messages for coordination\nvia \u201cutility propagation\u201d. The postulate for this chapter is the following:\nIndependent agents can jointly perform planning in a pro-\nduction scenario where every agent only has a simulation\nmodel of the system part in his visible scope.\n4.1 Background: The Generalized Distributive Law\nJudea Pearl introduced Belief Propagation (BP) as a way to efficiently compute\ninference tasks on (conditional) probability distributions [Pea88]. The algorithms\nthat perform BP have become known as \u201cmessage passing\u201d algorithms since they\nare based on the exchange of messages representing conditional distributions\nbetween nodes in a graph [KF09]. In the years following the publication of\n[Pea88] the similarities between BP and other preexisting techniques in different\nscientific communities have been discovered. The common core of these\ntechniques has been developed into the Generalized Distributive Law (GDL)\nfamily of algorithms [AM00; KFL01]. The GDL comprises as special cases the\nBaum-Welch algorithm for state estimation in Hidden Markov Models [Wel03],\nthe Max-Plus algorithm for finding the maximum a-posteri event in a probability\ndistribution, Turbo codes for error correction on noisy communication channels,\nand many more. We now summarize message passing for the distributed\noptimization of a function. Full proofs are omitted here. They can be found\ntogether with more pointers to the literature in [AM00; KF09].\nThe function g : X \u2192 R is defined for the domain X . For simplicity, let\nX contain only a finite number of members. The domain decomposes into\nvariables v such that X = \u00d7v\u2208VXv. We write x \u2208 X for the vector with\n4.1 Background: The Generalized Distributive Law 93\nfbc\nfc\nfab\nfa\nfbd\nfd\nFigure 4.1: Factor graph for a problem decomposition. Factors that share are\nvariable are neighbors and connected with an edge. The subscript indicates the\nvariables in the domain of the factor.\nentries xv \u2208 Xv . The function g decomposes into a sum of factors f \u2208 F .\ng(x) =\n\u2211\nf\u2208F\nf(xf )\nEvery factor depends on a subset of the variables Vf \u2286 V and Xf = \u00d7v\u2208VfXv .\nIn the context of a vector x, the projection of x on the variables in the domain of\nf is written as xf . The goal is to find the maximizer x\u2217 = arg maxx\u2208X g(x).\nUsually, the optimization for each factor arg maxxf \u2208Xf f(xf ) is much easier\nas it only has to consider a fraction of the full domain X .\nNow we constrain the domain for the optimization by fixing some of the\nvariables. Assume that the variables in the scope of the factor f have been fixed\nto some yf \u2208 Xf . The optimization problem with this additional constraints is\nsaid to be conditioned on yf :\narg max\nx\u2208X | yf\ng(x) (4.1)\nSince the domainXf is finite, we can write a table with the results of Equation 4.1\nfor each yf \u2208 Xf . This changes the perspective of the optimization. We can\nask which yf \u2208 Xf is best, knowing what the optimal \u201creaction\u201d will be.\nTabular representations of this kind (for finite domains) are the messages that\nare exchanged in the message passing algorithms.\n94 4 Distributed Planning for Self-Organizing Production Systems\nIf the factors form a tree-graph, then the computational effort for solving\nthe optimization problem can be reduced drastically. Figure 4.1 represents the\nfactors of an example problems as nodes. The factor name indicates the variables\nin the factor domain. So the factor fbd has the domain Xfbd = Xb \u00d7Xd. This\ntree structure is a so-called junction tree with respect to the variables of each\nfactor [Cow+99]. In a junction tree, nodes can be connected (are neighbors) if\nthey share at least one variable. They don\u2019t have to be connected if they share a\nvariable. But if they do share a variable, then all nodes on the paths between\nthese two nodes must also refer to that variable. An example in Figure 4.1 are\nthe nodes fab and fbd. They share the variable b. So all nodes on a path between\nfab and fbd must have b in their domain for the graph to be a junction tree.\nOn a tree-graph, every edge separates the tree into two otherwise unconnected\nhalves. Take the edge (fab, fbc) in Figure 4.1. Cutting at the edge splits the set\nof factor functions into disjoint sets F = Fab \u222a Fbc. This results in two smaller\noptimization problems gab(x) =\n\u2211\nf\u2208Fab(xf ) and gbc(x) =\n\u2211\nf\u2208Fbc(xf ).\nNote that, given a fixed assignment to xb, the two subproblems are \u201cconditionally\nindependent\u201d from one another. That is, for a fixed xb, the overall optimization\nproblem can be solved by optimizing each subproblem individually and merging\nthe partial solutions.\nBy convention, we denote the nodes representing factor functions as i and\nj \u2208 N(i). The set N(i) contains the neighbors with a direct edge to i. The\nsubtree behind the edge (i, j) on the side of i contains the factor functions\nFi\u2192j \u2286 F . The factors i and j share the variables Vij = Vi \u2229 Vj with the\ndomain xij \u2208 Xij . The message sent from i to j then is (a tabular representation\nof) a function mi\u2192j : Xij \u2192 R. It contains the value of the best-possible\nsolution for the subproblem with the factors Fi\u2192j conditioned on the shared\ndomain.\nmi\u2192j(yij) = arg max\nx\u2208X | yij\n\u2211\nf\u2208Fi\u2192j\nf(xf ) (4.2)\nIn the junction tree, the messages mi\u2192j can be computed in such a way that\nthe computation at every node i only considers the domain Xi.The result of\nEquation 4.2 can then be computed by only considering the local factor and the\n4.1 Background: The Generalized Distributive Law 95\nreceived messages:\nmi\u2192j(yij) = arg max\nxi\u2208Xi | yij\n[\nfi(xi) +\n\u2211\nl\u2208N(i)\\{j}\nml\u2192i(xil)\n]\n(4.3)\nIn a so-called forward-backward pass, the messages are first sent out by the edge-\nnodes with only one neighbor. Here, computing the message with Equation 4.2\nis straightforward, as it only requires access to the factor function of the node\nitself. Other nodes compute and send out a message to their neighbor j as\nsoon as a message has arrived from all other neighbors (not considering the\nreceiving neighbor j). In a tree-graph, the exchanged messages converge after a\nforward-backward pass when a message has been sent over every edge in both\ndirections. Every node i then chooses the solution\narg max\nxi\u2208Xi | yij\n[\nfi(xi) +\n\u2211\nl\u2208N(i)\nml\u2192i(xil)\n]\n(4.4)\nfrom his domainXi. If the solution of Equation 4.4 is unique at every node, then\nthe nodes agree with respect to the assignment of shared variables and the joint\nassignment of values to x is optimal. Additional communication is required to\nbreak ties. In practice, small random disturbances added to the values of the\nexchanged messages prevent ties effectively. Message passing generally works\non loopy graphs as well. The convergence is then not guaranteed. Still, the\nresults are often surprisingly good. If convergence in a loopy graph is achieved,\nthe solution quality can be characterized according to the so-called Bethe free\nenergy [YFW01].\nThe algorithm just presented is known under the name \u201cMax-Plus\u201d or \u201cMax-\nSum\u201d according to the operations for joining partial solutions and marginalization.\nThe general approach also works in any algebraic semiring where the operators\nmax and + are replaced with their respective counterparts. The underlying\nprinciple of the message-passing algorithm is traced back to the distributive\nproperty of the two operators of the semiring, hence the name Generalized\nDistributive Law. In this text, we are only considering the GDL for finite domains.\nSee the publication [WJ+08] for the application of the GDL to inference on\ncontinuous probability distribution from the exponential family.\n96 4 Distributed Planning for Self-Organizing Production Systems\n4.2 A Model of Distributed Concurrent Production Systems\nThe established models for multi-agent coordination decompose the planning\nproblem in such a way that the sets of actions available to each agent are disjoint.\nCompare for example with the popular MA-STRIPS [BD08] and DEC-POMDP\n[BZI00] models. We take a different route. The actions available to every agent\nand the components that are visible in their scope overlap. This overlap is the\ncommon language that is required for coordination. Informally spoken, the\noverlap acts as the \u201chinge\u201d between the per-agent models.\nDefinition 4.1. A distributed planning problem is represented by a tuple(\nC,A,\u03c30, I, {Ci, Ai, ri}i\u2208I\n)\n.\nThe definitions for the set of components C, the actions A and the initial\nsystem state\u03c30 are identical to the central planning problem from Chapter 3. The\nadditional agents i \u2208 I each have a limited scope with regards to the part of the\noverall system that is visible to them. This is reflected in the visible components\nCi \u2286 C, and the actionsAi \u2286 A with parameters from \u0398i. The joint state of the\ncomponents in the scope of i is \u03c3i with the state-space \u03a3i = \u03a3Ci . Each agent\nhas a private reward function ri : \u03a3i\u00d7Ai\u00d7\u0398i\u00d7\u03a3i \u2192 R. The components and\nactions in the scope of two agents i and j can overlap. The shared components\nand actions are Cij = Ci \u2229 Cj and Aij = Ai \u2229Aj . Two agents are considered\nneighbors if they share a component in their scope. The set J(i) contains\nthe neighbors of the agent i. The neighbor relation is of course symmetric\nj \u2208 N(i)\u21d4 i \u2208 N(j).\nJ(i) = {j \u2208 (I \\ {i}) : Ci \u2229 Cj 6= \u2205}\nExample 4.1. Consider again the manufacturing scenario from Ex-\nample 2.2. Now, two agents jointly control the system. One agent is\nresponsible for production and the other for packaging. Each agent has\nonly a subset of the system components in his local scope. The lattice\n4.2 A Model of Distributed Concurrent Production Systems 97\nbox in the middle is in the scope of both agents. See Figure 4.2 for\ndetails.\nThe agents see all actions where a component in their scope par-\nticipates. Therefore, Cprod = {produce, put, take} and Cpack =\n{put, take, package}. But since the agent prod has no visibility for\nthe packaging robot, he can only have a partial view on the action take.\nThe same is true for the pack agent and the action put.\nproduce put take package\nScope of the agent prod\nScope of the agent pack\nFigure 4.2: Minimal production scenario from Example 2.2 with two\nagents and their respective scope.\nEvery agent i is equipped with a simulation model of the components and\nactions in his scope. An agent may have actions a in his scope where some\nof the components participating in the action are outside of the scope of i so\nCa * Ci. It would be preferable that all actions entirely fit into the scope of\nevery participating agent. But then we could not correctly model interactions\nacross the boundaries of an agent scope. Take the situation of Example 4.1.\nProducts are moved from the machine tool to the packaging robot. For this,\nthe products leave the scope of the agent prod and enter the scope of the\nagent pack. The component of the lattice box is shared by both agents. More\nformally, box \u2208 (Cprod \u2229 Cpack). The agent prod must be able to predict \u2013 in\nhis private model of the system dynamics \u2013 when the lattice box will be free\nagain. But he does not see the packaging robot who takes out products. If the\n98 4 Distributed Planning for Self-Organizing Production Systems\naction representations for the individual agents were to include all participating\ncomponents and the agents know all actions that act on components in their\nscope, then the agents would have to keep all components C in their scope.\nTo overcome this, each agent has an internal representation of the actions that\nonly describes the preconditions and effect on components that are in the agents\nscope. In Example 4.1, the agent prod has a partial representation of the action\ntake to work with action sequences where multiple products are sequentially\nmoved to pack. From the perspective of the agent prod, the products simply\ndisappear when they are actually moved to the component package. The\nremainder of this section spells out the assumptions that are required for the\nagents\u2019 individual partial system models to be mutually compatible. This is\nrequired for the distributed planning methods introduced in the later sections of\nthis chapter.\nDefinition 4.2. Based on Definition 2.4, the projection of an action a to the\nscope of an agent i is\nai = (Ca,i, \u03a3\u0304a,i, ea,i, da,i)\n\u2022 with participating components Ca,i = Ca \u2229 Ci,\n\u2022 feasible initial states \u03a3\u0304a,i = \u03a0Ca,i(\u03a3\u0304a), and\n\u2022 effects and durations ea,i : \u03a3\u0304a,i \u2192 SCa,i and da,i : \u03a3\u0304a,i \u2192 R+.\nSimilar to the global action definition, per-agent actions ai are operators on\nthe domain \u03a3a,i = {\u03c3i \u2208 \u03a3i : \u03a0Ca,i(\u03c3i) \u2208 \u03a3\u0304a,i}. The full operator signature\nis ai : \u03a3a,i \u2192 \u03a3i.\nAssumption 4.3. If a component in the scope of an agent i participates in an\naction a, then the projected action ai is in the scope of that agent.\n\u2200i \u2208 I, \u2200a \u2208 A, Ca,i 6= \u2205\u21d2 ai \u2208 Ai\nThe participating agents of the action a are those with at least one participating\ncomponent in their scope Ia = {i \u2208 I : Ca,i 6= \u2205}. From the definition\nof \u03a3\u0304a,i, the projected action imposes less constraints on the feasible initial\n4.2 A Model of Distributed Concurrent Production Systems 99\nstates. The inverse projection of the feasible set is \u03a0\u22121Ca,i(\u03a3\u0304a,i) = {\u03c3 \u2208 \u03a3 :\n\u03a0Ca,i(\u03c3) \u2208 \u03a3\u0304a,i}. Since less constraints are imposed on feasible initial states\n\u03a3a \u2286 \u03a0\u22121Ca,i(\u03a3\u0304a,i). So there may be global states \u03c3 where agent i beliefs \u03c3i\nto be feasible for his projected action ai so that \u03c3i \u2208 \u03a3a,i but which are not\nfeasible for the original action \u03c3 /\u2208 \u03a3a. In order to prevent the agents from\njointly selecting an action that is infeasible for the current global system state \u03c3\n(and possible damaging equipment or endangering human operators) we assume\nthat the action definitions and the decomposition into agents does not lead to\ninfeasible action selections if the agents jointly agree on the feasibility.\nAssumption 4.4. If the participating agents i \u2208 Ia agree that action a is feasible\nbased on their individual projected action ai with preconditions \u03a3a,i, then the\naction is also globally feasible.( \u22c2\ni\u2208Ia\n\u03a0\u22121Ca,i(\u03a3\u0304a,i)\n)\n\u2286 \u03a3a\nAssumption 4.4 implies restrictions for the possible preconditions with respect\nto timing and synchronization between agents. The feasibility of an action can\nnot depend on the simulation time of a participating components outside the\nscope of a participating agent. Otherwise, it would be possible to construct\nsituations where all agents jointly, but incorrectly, belief an action to be feasible.\nSuppose a situation where molten iron ore is transferred from a component\nexclusively in the scope of agent i to a component exclusively in the scope\nof agent j. The global action for the transfer rightly imposes constraints on\nthe simulation time to ensure that the component with the molten ore does\nnot idle for too long. But this timing constraint cannot be represented in the\nprojected action for either agent, violating Assumption 4.4. If timing conditions\nare critical, then all participating need to be in the scope of the agents.\nIn addition to assumptions for the feasible initial states, we limit the effect\nso that the post-state of the components Ca,i is correctly predicted by ai. That\nmeans for deterministic scenarios that the effect on the components Ca,i follows\nfrom the initial state of the Ca,i. In stochastic scenarios, the distribution\nfor the post-states of the components Ca,i is conditionally independent from\ncomponents outside of Ca,i.\n100 4 Distributed Planning for Self-Organizing Production Systems\nAssumption 4.5. If an action a has a participating agent i, then the effect on\nthe components Ca,i is determined by the initial state of the components Ca,i\nonly. If the action is deterministic, then\n\u2200\u03c3,\u03c9 \u2208 \u03a3a, \u03c3a,i = \u03c9a,i \u21d2 \u03a0Ca,i(ea,i(\u03c3)) = \u03a0Ca,i(ea,i(\u03c9)) .\nIf the action is stochastic, so that the post-state and observations are sampled as\n(\u03c3\u2032,oa) \u223c a(\u03c3) with s\u2032 the untimed state of the components from \u03c3\u2032, then\n(s\u2032a,i,oa,i |\u03c3a,i) \u22a5 \u03c3C\\Ci .\nNote that Assumption 4.5 restricts the effect on the resulting state sa,i, but\nnot on the resulting simulation time of the components. This allows the time\nsynchronization of components across the scope of a single agent.\nLast, we require that the reward generated by the actions does not depend on\nthe simulation time of the components. This will become important later on,\nwhen the agents predict their reward based on an internal simulation model that\nis restricted to their scope.\nAssumption 4.6. For any two system states \u03c3 and \u03c3\u2032 where the untimed\ncomponent states are identical s = s\u2032, the reward from any feasible action a is\nidentical\nr(\u03c3, a, \u03b8, a(\u03c3)) = r(\u03c3\u2032, a, \u03b8, a(\u03c3\u2032)) . (4.5)\nIf an action a is completely outside the scope of agent i, then the projection\nis the identity action \u03b5 \u2013 also used to denote an empty action sequence. The\nidentity action can be simply omitted in an action sequence.\nCa \u2229 Ci = \u2205\u21d2 ai = \u03b5\nAction sequences w are projected to the scope of agent i as\n\u03a0i(w) = wi = (wki )k\u2208{1,...,|w|} .\nSince actions project to the identity \u03b5 for an agent i that is not participating in\nit, the sequence wi may contain less elements than w. We continue to use the\n4.2 A Model of Distributed Concurrent Production Systems 101\nsame index notation k for both global and per-agent action sequences and make\nthe number of sequence members explicit only when this is needed.\nAs described in Section 2.1, the set W = A\u2217 contains all action sequences\nof finite length generated from a set of base actions A. It implies a tree-graph\nwhere every edge denotes an action that is appended to the previous sequence.\nThe sequence trees W\u03c3 with a defined initial state \u03c3 contains only feasible\nsequences starting from the initial state. The sequence treeWi = A\u2217i considered\nby the agent i contains all sequences formed from the actions in i\u2019s scope. The\nsequence tree W\u03c3i contains the sequences from Wi that agent i beliefs to be\nfeasible starting from the initial state \u03c3i. The inverse projection of the per-agent\nsequence tree \u03a0\u22121i (W\u03c3i ) contains all global sequences that are compatible with\n(project to) a sequence from W\u03c3i and that are also feasible for some compatible\ninitial state \u03c9 with \u03c9i = \u03c3i.\n\u03a0\u22121i (W\n\u03c3\ni ) = {w \u2208W : \u2203\u03c9 \u2208 \u03a3, \u03c9i = \u03c3i, w \u2208W\u03c9, wi \u2208W\u03c3i } (4.6)\nSince the considered system dynamics takes concurrency into account, the\nindex of an action in the action sequence could no longer coincide with the order\nin which the actions are executed according to the simulation time. The state of\ncomponent c after executing the first k actions is w:k(\u03c3)c = \u03c3kc = (skc , tkc ).\nProposition 4.7. From the Assumptions 4.3, 4.4 and 4.5 follows that for any\nglobal state \u03c3 \u2208 \u03a3 and agent i \u2208 I( \u22c2\nj\u2208I\n\u03a0\u22121j (W\n\u03c3\nj )\n)\n= W\u03c3 \u2286 \u03a0\u22121i (W\n\u03c3\ni ) .\nProof. Consider the subset relation W\u03c3 \u2286 \u03a0\u22121i (W\u03c3i ). Assume there exists\na sequence v \u2208 W\u03c3. But an agent i beliefs that the projected sequence is\nnot feasible for his scope so that v /\u2208 \u03a0\u22121i (W\u03c3i ). Let k the index in v where\nv:k \u2208 \u03a0\u22121i (W\u03c3i ). Such a k must exist since the empty sequence that is always\nfeasible. From Equation 4.6 the agent i regards the shortened sequence as feasible\n\u03a0i(w:k) \u2208W\u03c3i . A consequence of Assumption 4.3 and Assumption 4.5 is that\nthe agent i correctly predicts the (untimed) system state of the components in\n102 4 Distributed Planning for Self-Organizing Production Systems\nhis scope based on the projected sequence w:ki .\n\u2200\u03c3 \u2208 \u03a3w:k , \u03c3\u2032 = w:k(\u03c3), \u03c9i = w:ki (\u03c3i), s\n\u03c3\u2032i\ni = s\n\u03c9i\ni\nHere, s\u03c3\n\u2032\ni and s\n\u03c9i\ni denote the untimed state of the components in i\u2019s scope in\nthe respective timed state vectors \u03c3\u2032 and \u03c9i. Since w \u2208 W\u03c3 we know that\n\u03c3\u2032 \u2208 \u03a3wk+1 . From the preconditions of projected action from Definition 4.2 it\nmust be that \u03c9i \u2208 \u03a3wk+1,i. This contradicts the initial assumption.\nWe first show that\n( \u22c2\nj\u2208I \u03a0\n\u22121\nj (W\u03c3j )\n)\n\u2286 W\u03c3. Assume an action sequence\nu where u /\u2208 W\u03c3 and u \u2208\n( \u22c2\nj\u2208I \u03a0\n\u22121\nj (W\u03c3j ). There exists an index l such\nthat the subsequence u:l is contained in W\u03c3 but u:l+1 is not. Let \u03c3\u2032 = u:k(\u03c3).\nThe agents agree that their projection of uk+1 is feasible \u2200i \u2208 I, \u03c3i \u2208 \u03a3uk+1,i.\n(The identity action \u03b5 is always feasible.) But \u03c3\u2032 /\u2208 \u03a3uk+1 . This contradicts\nAssumption 4.4. The equality relation\n( \u22c2\nj\u2208I \u03a0\n\u22121\nj (W\u03c3j )\n)\n= W\u03c3 is then a\ndirect consequence of the previously established fact that for all agents j \u2208 I\nthe set \u03a0\u22121j (W\u03c3j ) is a superset of W\u03c3\nProposition 4.7 summarizes the first important result for distributed planning\nfrom this section. All feasible global sequences are projected to a feasible\nsequence from the standpoint of the individual agents. On the other hand, an\nindividual agent could assume a sequence wi to be valid that has no feasible\nglobal counterpart. If the agents however jointly agree on a sequence by each\nconsidering the projection to their scope, then the sequence is globally feasible.\n4.3 Distributed Planning for Deterministic Action Sequences\nThe sequence tree shared between two agents i and j \u2208 N(i) is written as\nWij . It contains all sequences of the joint actions Wij = (Ai \u2229 Aj)\u2217. Note\nthat the sequences in Wij may be unfeasible. They are partial sequences and\neach agent has to \u201cfill the holes\u201d for the components in his scope. Based on a\n(partial) sequence wij \u2208Wij , the sequence tree of the individual agent i can be\nconditioned to contain only sequences that are in accordance with the shared\nsequence wij .\n4.3 Distributed Planning for Deterministic Action Sequences 103\nDefinition 4.8. For an action sequence vij \u2208Wij shared by the agents i and\nj \u2208 N(i), the conditional tree W\u03c3i |vij contains only those sequences for agent\ni whose projection to Wij is compatible with vij in the following sense.\nW\u03c3i |vij = {wi \u2208W\u03c3i : wij = vij}\nExample 4.2. Consider the two agents from Example 4.1 and an initial\nstate \u03c3 where no component contains products.\n\u03b5\nproduce\nput\ntake\nproduce\nput\n...\n...\nproduce\ntake\nput\n...\n...\n(a) W\u03c3prod|vprod,pack\n\u03b5\nput\ntake\nput\ntake\nput\n...\n(b) vprod,pack\n\u03b5\nput\ntake\npackage\nput\ntake\n...\n...\nput\npackage\ntake\n...\n...\n(c) W\u03c3pack|vprod,pack\nFigure 4.3: Conditioned sequence trees of two agents.\nEvery agent internally considers the sequence tree W\u03c3prod and W\u03c3pack\nrespectively. By imposing the shared sequence vprod,pack, the agents\nsequence trees are pruned to the conditional sequence trees shown in\nFigure 4.3b, Also compare with the sequence tree for the overall scenario\nfrom Figure 2.3.\n104 4 Distributed Planning for Self-Organizing Production Systems\nFor a given initial state \u03c3, the global reward generated from a history w is\nr(\u03c3,w) =\n|w|\u2211\nk=1\nr\n(\nw:k\u22121(\u03c3), wk,w:k(\u03c3)\n)\n.\nThe local reward for the agents i \u2208 I (who know the initial state of the\ncomponents in their scope \u03c3i) is\nri(\u03c3i,wi) =\n|w|\u2211\nk=1\nri\n(\nw:k\u22121i (\u03c3i), w\nk\ni ,w\n:k\ni (\u03c3i)\n)\n.\nNow, we can state the planning problem for action sequences as a factorized\noptimization problem with factors ri and overlapping factor domains Wi.\nProposition 4.9. If the reward generated by the actions a is factorized into\nper-agent reward as r(\u03c3, a,\u03c3\u2032) =\n\u2211\ni\u2208I ri(\u03c3i, ai,\u03c3\u2032i), then the reward r(w)\nfor a global action sequence w factorizes to the sum of the per-agent reward\nfunctions ri : Wi \u2192 R.\nr(\u03c3,w) =\n\u2211\ni\u2208I\nri(\u03c3i,wi)\nProof. Take the following sequence of equations. The gist of the proof lies in\nthe equality between the Equations 4.7 and 4.8.\nr(\u03c3,w) =\n|w|\u2211\nk=1\nr\n(\nw:k\u22121(\u03c3), wk,w:k(\u03c3)\n)\n(4.7)\n=\n|w|\u2211\nk=1\n\u2211\ni\u2208I\nri\n(\nw:k\u22121i (\u03c3i), w\nk\ni ,w\n:k\ni (\u03c3i)\n)\n(4.8)\n=\n\u2211\ni\u2208I\n|w|\u2211\nk=1\nri\n(\nw:k\u22121i (\u03c3i), w\nk\ni ,w\n:k\ni (\u03c3i)\n)\n=\n\u2211\ni\u2208I\nri(\u03c3i,wi)\nFirst, Proposition 4.7 guarantees that for any system state \u03c3 and feasible\nsequence w the projected sequence wi is feasible for the projected system state\nwi. Secondly, from Assumption 4.5 follows that knowledge of wi suffices to\n4.3 Distributed Planning for Deterministic Action Sequences 105\ndetermine the untimed state of the components Ci. Third, the agents reward\ndepends only on the untimed state of the components in their scope according to\nAssumption 4.6. Therefore the reward of the individual agents is determined by\njust the components in their scope and the action sequence projected to their\nscope.\nDefinition 4.10. The V-value of the agent i with agent-state \u03c3i is the sum of\nrewards generated by the best feasible action sequence from the perspective of\nthe agent.\nvi(\u03c3i) = max\nwi\u2208W\u03c3i\nri(\u03c3i,wi)\nWe are not discounting later reward to compute the V-value. Instead it is\nimplied that the tree W either has a maximum height. Either because the\nscenario is \u201cdone\u201d after a finite number of actions or based on a cutoff height of\nthe sequence tree.\nDefinition 4.11. The conditional V-value of an agent i for the action sequence\nvij shared with the neighbor j \u2208 N(i) is the best reward the agent can achieve\nwith a sequence that projects to vij .\nvi(\u03c3i |vij) =\n\uf8f1\uf8f2\uf8f3 maxwi\u2208W\u03c3i |vij ri(\u03c3i,wi), W\n\u03c3\ni |vij 6= \u2205\n\u2212\u221e, else\nThe local V-value is defined as \u2212\u221e if the shared sequence vij is infeasible\nfor the initial state of the components in the agent\u2019s scope \u03c3i. This becomes\nimportant later on when vi is used by the agents to signal preferences for shared\nsequences to their neighbors.\nProposition 4.12. In a setting with just two agents i and j, the global V-value\ncan be decomposed as follows.\nv(\u03c3) = max\nw\u2208W\u03c3\nr(\u03c3,w) = max\nwij\u2208Wij\n[\nvi(\u03c3i |wij) + vj(\u03c3j |wij)\n]\nProof. Let u \u2208W an optimal global action sequence, so the reward generated\nby u is r(\u03c3,u) = v(\u03c3). (There may be several optimal action sequences.) This\n106 4 Distributed Planning for Self-Organizing Production Systems\nreward decomposes into the private reward of the agents i and j.\nr(\u03c3,u) = ri(\u03c3i,ui) + rj(\u03c3j ,uj)\nGiven the shared sequence uij , agent j can choose any action sequence\nfrom W\u03c3j |uij without impacting the reward for i. We know that rj(\u03c3j ,uj) =\nmaxvi\u2208W\u03c3j |uij rj(\u03c3j ,vj). Otherwise, if the agent j could find a better sequence\nthanui,u could not be a maximizer for the global sequence. Sinceuj \u2208W\u03c3j |uij\nwe know that W\u03c3j |uij is nonempty and therefore with Definition 4.11\nr(\u03c3,u) = ri(\u03c3i,ui) + vj(\u03c3j |uij) .\nThe same line of reasoning can be followed for the agent i so that r(\u03c3,u) =\nvi(\u03c3i,uij) + vj(\u03c3j |uij).\nIn the case with two agents, given precomputed conditional V-value functions\nvi(\u03c3 |wij), (e.g. available as a lookup table), the optimization problem to find\nthe optimal reward for a given system state \u03c3 is simplified from a search over\nW\u03c3 to a search over just Wij . Now assume a case with three agents i, j, l.\nThe agents i and j have shared components and the agents j and l have shared\ncomponents. But i and l do not share any components. Conditioned on the\naction sequence wjl, the agent l is not only independent from the actions of j\nbut also of the actions of i. This mechanism is used for \u201cutility propagation\u201d\nbetween agents that form a tree-graph. The difference to the original GDL is\nthat the overall domain W is not a cartesian product of the Wi.\nAssumption 4.13. The agents and their neighbor relations between the agents\nform a tree-graph. The components in the scope of agent i are in the shared\nscope with at most one of i\u2019s neighboring agents.\n\u2200j \u2208 N(i), \u2200c \u2208 Cij \u21d2 \u2200l \u2208 N(i) \\ {j}, c /\u2208 Cil\nFor a given initial system state \u03c3, the messages mi\u2192j : Wij \u2192 R exchanged\nbetween neighboring agents are computed as follows:\nmi\u2192j(vij) = max\nwi\u2208W\u03c3i |vij\n[\nvi(\u03c3i,wi) +\n\u2211\nl\u2208N(i)\\{l}\nml\u2192i(wil)\n]\n(4.9)\n4.3 Distributed Planning for Deterministic Action Sequences 107\nThe messages mi\u2192j : Wij \u2192 R describe the best reward that the subgraph\nof agents \u201cbehind\u201d the edge i \u2192 j can achieve for a given shared sequence\nwij . Computing the messages m quickly becomes intractable. The number of\npossible shared sequences grows exponentially with the length of the shared\nsequence. Furthermore, the optimization performed for each messages mi\u2192j\nand shared sequence wij requires in itself an optimization of over W\u03c3i |vij that\ntakes the messages received by the other neighbours N(i) \\ j into account. The\nconditional treeW\u03c3i |vij also grows exponentially with the tree depth. (Although\npruning non-conforming sequences can drastically reduce the overall size).\nThe Max-Plus algorithm from the GDL family is used to efficiently solve\nthe maximum a-posteriori (MAP) problem of finding the event with highest\nprobability. It has been used for \u201cutility propagation\u201d for multi-agent decision\nmaking by [KV05]. To overcome the combinatorial explosion of the search space,\nwe develop a novel combination of Max-Plus with MCTS. See Algorithm 14\nfor the full algorithm specification. Similar to standard UCT, the Distributed\nUpper Confidence on Trees (DUCT) algorithm performs iterative playouts and\ngenerates statistics that guide decision-making in later playouts. Every agent\ni \u2208 I stores the reward he can make after a sequence wi in a hashmap vi[wi]. As\nbefore, the hashmap returns zero when no entry has been set prior. Every agent\nis performing independent playouts based on his internal simulator. Actions are\nselected according to the UCT rule with the addition that conditional reward\nsignaled by they neighbors is considered as well. For the updates, the computed\nV-value estimate for a sequence wi considers only the reward the agent receives.\nBut the action a\u2217i are selected to maximize the reward for all agents. Afterwards,\nthe messages to the neighboring agents are computed. Here the action a\u2217i is\nimplied by the use of the local V-value vi. Note that the reward signaled by\nthe agent j to i is not mirrored back in the messages from i to j. Here, the\nagents are jointly exploring the scenario tree. Initially, all messages are set to\nzero. Therefore, if rewards are generally negative, then the agents will initially\noverestimate the value of sequences where no empirical reward estimate from\nthe neighbors exist.\n108 4 Distributed Planning for Self-Organizing Production Systems\nAlgorithm 14 Distributed Upper Confidence on Trees (DUCT) Algorithm\n1: procedure DUCT(\u03c30)\n2: mi\u2192j [ \u00b7 ]\u2190 0 \u2200i \u2208 I, j \u2208 N(i)\n3: ni[ \u00b7 ]\u2190 0, vi[ \u00b7 ]\u2190 0 \u2200i \u2208 I\n4: while enough time do\n5: for i \u2208 I do\n6: (wi, ri)\u2190 Playi(\u03c30i )\n7: Updatei(wi, ri)\n8: return arg maxa\u2208A\n[ \u2211\ni\u2208I:\nai\u2208Ai\nvi[ai]\n]\n1: procedure Playi(\u03c3i)\n2: wi \u2190 \u03b5, ri \u2190 \u03b5\n3: while \u00acdone(\u03c3i) do\n4: B \u2190 {bi \u2208 Ai : n[wibi] = 0}\n5: if B 6= \u2205 then\n6: ai \u2190 \u03c0Bi (\u03c3i)\n7: else\n8: ai \u2190 arg max\nbi\u2208Ai\n[\nvi[wibi] + \u03b1\n\u221a\nlogn[wi]+1\nn[wibi] +\u2211\nj\u2208N(i)\nmj\u2192i(\u03a0ij(wibi))\n]\n9: (\u03c3i, ei)\u2190 ai(\u03c3i)\n10: wi \u2190 wiai, ri \u2190 (r1i , r2i , . . . , ei)\n11: return wi, ri\n1: procedure Updatei(wi, ri)\n2: for k = |wi|, . . . , 1 do\n3: ui \u2190 w:ki\n4: n[ui]\u2190 n[ui] + 1\n5: a\u2217i \u2190 arg max\nai\u2208Ai:n[uiai]>0\n[\nq[uiai] +\n\u2211\nj\u2208N(i) mj\u2192i[\u03a0ij(uiai)]\n]\n6: vi[ui]\u2190 rki + vi[uia\u2217i ]\n7: for j \u2208 N(i) do\n8: u\u2190 vi[ui] +\n\u2211\nl\u2208N(i)\\{l} ml\u2192i(\u03a0il(ui))\n9: if e > m[\u03a0ij(ui)] then\n10: m[\u03a0ij(ui)]\u2190 e\n4.4 Distributed Planning under Uncertainty 109\n4.4 Distributed Planning under Uncertainty\nIn stochastic scenarios, following the description from Section 2.3, the current\nstate is not known with absolute certainty. Instead, the system state can only be\ninferred from indirect observations. Recall that histories h are comprised of\nepisodes hk = (ak\u03b8kok) with an action, action-parameters and observations.\nThe set of all possible global histories of finite length is H = (A\u00d7\u0398\u00d7O)\u2217.\nThe set of histories H implies a tree-graph with edges between observations\nand actions, actions and parameters, and parameters and observations if they\ncan occur in sequence in a history. From every history, the current system state\ncan be inferred P(\u03c3 |h). For this, an belief distribution for the initial state \u03c30 is\nupdated with the received observations. We now make the additional distinction\nbetween histories and complete histories. Complete histories are the leafs in the\ntree-graph of H . They denote histories after which the scenario is \u201cdone\u201d. This\ncan also be enforced by a maximum history depth. The set of complete histories\nis H \u2286 H .\nThe algorithm enhances our prior work in [Pfr16a] in several regards. Most\nimportantly, every agent participating in the decision making has a local\nsimulator to predict the evolution of the system state based on his restricted\nlocal knowledge. An important inspiration came from [AO15]. However, they\nuse Variable Elimination [KF09] for selecting joint actions instead of message\npassing. In addition, they rely on a central simulator for the global system to\ngenerate sample plays. Since MCTS is an online algorithm, they would require\na simulator for the global system also at runtime for the agent coordination.\nAs the agents i \u2208 I have a limited scope, they can only observe a portion\nof the full history. In particular, the projection to the agent-scope \u03a0i(h) = hi\ncontains only the episodes with actions a \u2208 Ai. The observed action parameters\nare from the full parameter space of the action \u03b8 \u2208 \u0398a. The observations\nreceived by the agent i are from components that participate in action a and are\nin the scope of the agent oi \u2208 Oa,i = (\u00d7c\u2208Ca,iOc).\nDefinition 4.14. A history h \u2208 H projects to the scope of an agent i \u2208 I as\nhi = a1i \u03b81i o1i\ufe38 \ufe37\ufe37 \ufe38\nh1\ni\n. . . a\n|h|\ni \u03b8\n|h|\ni o\n|h|\ni\ufe38 \ufe37\ufe37 \ufe38\nh\n|h|\ni\n.\n110 4 Distributed Planning for Self-Organizing Production Systems\nThe set of histories for agent i isHi = (Ai\u00d7\u0398i\u00d7Oi)\u2217 where \u0398i = (\u222aa\u2208Ai\u0398a)\nand Oi = (\u222aa\u2208AiOa,i).\nSimilar to the projection of deterministic action sequences from Section 4.3,\nthe episodes are indexed with k. If an episode of the global sequence refers\nto an action outside of agent i\u2019s scope, then the action projects to the identity\noperator a /\u2208 Ai \u21d2 ai = \u03b5 and the episode does not occur in the agent\u2019s local\nhistory. The global history thus may contain more episodes than are visible to\nthe individual agent. The difference in the index k will be made explicit only\nwhen the meaning is not clear from context.\nAgents have a local decision-making policy \u03c0i. Since the components in the\nagents scope are overlapping, neighboring agents need to coordinate to select\nthe next action in their shared scope. Disagreement would lead to incompatible\naction selections for the components in the shared scope. This needs to be\navoided. So the local decision-making policy of an agent i is no longer a\ndeterministic result from the local history hi alone. It also depends on the\ncoordination with neighboring agents \u2013 and hence on the observations the agents\nj \u2208 N(i) have made that are not necessarily in the scope of i. This lack of\ninformation from the limited viewpoint of agent i is expressed by taking the\npolicy as a random variable as well. The next action and action parameters are\nsampled as (ai, \u03b8i) \u223c \u03c0i(hi).\nThe value for optimal decision making in each node (from the viewpoint\nof agent i), the V-value and the Q-value, can be computed recursively with\nBellman\u2019s Equation [Put94]. Note that the decision-making step is split into\naction-selection and parameter-selection. To simplify the notation, we refer to\nboth the V-value and the Q-value of an agent history as q.\nDefinition 4.15. The Q-value of selfish agent i assumes optimal decision making\nby i. The other agents I \\ {i} coordinate with i by agreeing to i\u2019s decisions for\nthe components in the shared scope.\nqi(hi) =\n\uf8f1\uf8f2\uf8f30, hi \u2208 Himax\nai\u2208Ai\nqi(hiai), else\n(4.10)\nqi(hiai) = max\n\u03b8i\u2208\u0398a,i\nqi(hiai\u03b8i) (4.11)\n4.4 Distributed Planning under Uncertainty 111\nqi(hiai\u03b8i) = E\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\noi\u2208Oa,i\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) + qi(hiai\u03b8ioi)\n\u2223\u2223hiai\u03b8i] (4.12)\nA distinction by cases is made whether the last episode contains only an action,\nan action with action parameters, or an action with parameters and the resulting\nobservations. When action, parameter and observation are appended to a history,\nas in h\u2032i = hiai\u03b8ioi, then h\u2032i matches with Equation 4.10 that is defined for\nhistories with complete episodes. Equations 4.11 and 4.12 take histories with\nan incomplete last episode as input. The case distinction in Equation 4.10 is\nrequired so that the recursive formulation terminates at the leaf nodes of Hi.\nA shared history hij \u2208 Hij = (Aij \u00d7\u0398ij \u00d7Oij)\u2217 between an agent i and\nhis neighbor j \u2208 N(i) contains only the episodes with a shared action a \u2208 Aij .\nThe agents i and j both observe the complete action parameters for the shared\nactions. The observations in the shared history contain only the observations\nfrom components in the shared scope Oij = (\u222aa\u2208Aij (\u00d7c\u2208Ca\u2229CijOc)). The\nV-value and Q-value are now conditioned on a shared history for the future\nepisodes. Observations that are not compatible with the shared history are\nmarginalized out in the probabilistic expectation. Incompatible action and\nparameter choices are disallowed in the maximization steps.\nDefinition 4.16. A conditional Q-value for a selfish agent i assumes optimal\ndecision making under the constraint that future episodes (after the initial history\nhi) project to the partial history gij shared with the neighbor j \u2208 N(i).\nqi(hi | gij) =\n\uf8f1\uf8f4\uf8f2\uf8f4\uf8f3\n0, hi \u2208 Hi\nmax\nai\u2208(Ai\\Aij)\u222a{a1ij}\nqi(hiai | gij), else\n(4.13)\nqi(hiai | gij) =\n\uf8f1\uf8f2\uf8f3qi(hiai\u03b8\n1\nij | gij), ai = a1ij\nmax\n\u03b8i\u2208\u0398a,i\nqi(hiai\u03b8i | gij), else\n(4.14)\n112 4 Distributed Planning for Self-Organizing Production Systems\nqi(hiai\u03b8i | gij) =\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\nE\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\nui\u2208Oa,i,\nuij=o1ij\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) +\nqi(hiai\u03b8iui | g2:ij)\n\u2223\u2223hiai\u03b8i], ai = a\n1\nij\nE\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\noi\u2208Oa,i\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) +\nqi(hiai\u03b8ioi | gij)\n\u2223\u2223hiai\u03b8i], else\n(4.15)\nThe action, action parameters and observations of the first episode of the\npartial history gij are referred to as a1ij , \u03b81ij and o1ij respectively. As episodes are\nadded to per-agent history hi, the remaining shared history for future episodes is\ngetting shorter. Once no shared history for the conditioning remains with gij = \u03b5,\nthe Q-value and V-value fall back to the formulations from Equations 4.10\nto 4.12. The action choice is constrained to agree with the remaining partial\nhistory gij . Actions without participating components from Cij can be freely\nchosen as they are not constrained by the partial history. The case distinction in\nEquation 4.14 requires that the matching parameters from the partial history gij\nare taken if the action is from the partial history. Finally, Equation 4.15 also\nmakes a case distinction for actions from the constraining partial history gij .\nEquation 4.15 then recurses by adding the expected reward from future episodes\nconstrained on the remaining partial history. If the current action is from the\nshared history, then the remaining shared history g:2ij has the current episode\nremoved.\nThe agents in Definition 4.16 are self-interested. In order to have collaborative\nagents jointly optimize the global reward (across all agents), each individual\nagents has to assess the impact of his choices on the expected future reward\nfor himself as well as for the other agents. Analogous to the previous section\non distributed planning for deterministic action sequences, the agents are\nassumed to form a tree-graph with their neighborhood relations. (Cf. the\ndiscussion of Assumption 4.13.) To coordinate, the agents exchange messages\nmi\u2192j : Hij \u2192 R with their neighbors j \u2208 N(i). The value of the message\nmi\u2192j(gij) evaluated for a given shared history gij describes the expected\nQ-value (the reward for optimal play in the remaining episodes) for the agents\nbehind the edge i\u2192 j conditional to the given shared partial history. See the\nlater Definition 4.18 for the messages. The per-agent history is projected to\n4.4 Distributed Planning under Uncertainty 113\nthe shared scope with hij = \u03a0il(hi). The expected immediate reward in the\nsubtree behind the edge l\u2192 i\nr\u0304j\u2192i(hi, ai\u03b8ioi) = mj\u2192i(hij)\u2212mj\u2192i(\u03a0ij(hiai\u03b8ioi))\nrefers to the reward the agents in the sub-tree expect to make when they \u201cfill the\ngaps\u201d between the partial histories hij and \u03a0ij(hiai\u03b8ioi).\nDefinition 4.17. The global Q-value for an unselfish agent i conditioned on the\nfuture partial shared history gij assumes optimal decision making by the agent\ni with respect to the expected global reward and a fixed policy followed by the\nother agents.\nq\u2217i (hi | gij) =\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\n\u2212\u221e, hi \u2208 Hi, gij 6= \u03b5\n0, hi \u2208 Hi, gij = \u03b5\narg max\nai\u2208(Ai\\Aij)\u222a{a1ij}\nq\u2217i (hiai | gij), else\n(4.16)\nq\u2217i (hiai | gij) =\n\uf8f1\uf8f2\uf8f3q\n\u2217\ni (hiai\u03b81ij | gij), ai = a1ij\nmax\n\u03b8i\u2208\u0398a,i\nq\u2217i (hiai\u03b8i | gij), else\n(4.17)\nq\u2217i (hiai\u03b8i | gij) =\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\nE\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\nui\u2208Oa,i,\nuij=o1ij\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) +\u2211\nl\u2208N(i)\n[\nr\u0304l\u2192i(hi, ai\u03b8iui)\n]\n+\nq\u2217i (hiai\u03b8iui | g2:ij)\n\u2223\u2223\u2223hiai\u03b8i],\nai = a1ij\nE\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\noi\u2208Oa,i\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) +\u2211\nl\u2208N(i)\n[\nr\u0304l\u2192i(hi, ai\u03b8ioi)\n]\n+\nq\u2217i (hiai\u03b8ioi | gij)\n\u2223\u2223\u2223hiai\u03b8i],\nelse\n(4.18)\nAgain, Equation 4.16 can return negative infinity in the case where the\nscenario is \u201cdone\u201d but the constraint to fulfill the partial history gij has not\nbeen fulfilled. The use of messages ml\u2192i(hil) relies on Assumption 4.13. So at\nmost two agents share a component in their scope. Otherwise for a given future\nshared history gij , the expected reward for the agents in the sub-tree behind\n114 4 Distributed Planning for Self-Organizing Production Systems\nthe edge l\u2192 i could also be conditional to a portion of the shared history gij\nthat also applies to l, i.e. \u03a0il(gij). The messages m would then be conditioned\nto this as ml\u2192i(\u03a0il(hi) |\u03a0il(gij)). Assumption 4.13 removes this source of\nfurther complexity.\nNow a word on the difference between the global Q-value q\u2217i estimated by\nthe agents i and the messages mi\u2192j between neighboring agents i and j. In\naccordance with the principles of the GDL described in Section 4.1, it has to be\navoided that the agents \u201cmirror back\u201d expected reward that was signaled to them\nby a neighbor j. Only the expected reward from the other neighbors N(i) \\ {j}\nis forwarded in the messages. In essence the message contains the expected\nreward generated in the subtree (according to the agent\u2019s neighbor relation)\nbehind the edge i\u2192 j under the assumption of globally optimal decision making\nby the agents according to their respective Q-value estimation.\nDefinition 4.18. The messages exchanged over the edge i\u2192 j between neigh-\nboring agents are computed for optimal decisions based on q\u2217i .\nqi\u2192j(hi | gij) =\n\uf8f1\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f3\n\u2212\u221e, hi \u2208 Hi, gij 6= \u03b5\n0, hi \u2208 Hi, gij = \u03b5\nqi\u2192j(hia\u2217i | gij), else\n(4.19)\nwhere a\u2217i = arg max\nai\u2208(Ai\\Aij)\u222a{a1ij}\nq\u2217i (hiai | gij),\nqi\u2192j(hiai | gij) =\n\uf8f1\uf8f2\uf8f3qi\u2192j(hiai\u03b81ij | gij), ai = a1ijqi\u2192j(hiai\u03b8\u2217i | gij), else (4.20)\n4.4 Distributed Planning under Uncertainty 115\nwhere \u03b8\u2217i = arg max\n\u03b8i\u2208\u0398a,i\nq\u2217i (hiai\u03b8i | gij),\nqi\u2192j(hiai\u03b8i | gij) =\n\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\nE\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\nui\u2208Oa,i,\nuij=o1ij\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) +\u2211\nl\u2208N(i)\\{j}\n[\nr\u0304l\u2192i(hi, ai\u03b8iui)\n]\n+\nqi\u2192j(hiai\u03b8iui | g2:ij)\n\u2223\u2223\u2223hiai\u03b8i],\nai = a1ij\nE\n\u03c3i,\u03c3\n\u2032\ni\u2208\u03a3i,\noi\u2208Oa,i\n[\nri(\u03c3i, ai, \u03b8i,\u03c3\u2032i) +\u2211\nl\u2208N(i)\\{j}\n[\nr\u0304l\u2192i(hi, ai\u03b8ioi)\n]\n+\nqi\u2192j(hiai\u03b8ioi | gij)\n\u2223\u2223\u2223hiai\u03b8i],\nelse\n(4.21)\nFinally the message from i to the neighbor j is\nmi\u2192j(gij) = qi\u2192j(\u03b5 | gij) . (4.22)\nDecision-making by the agent i depends on optimal decision-making by his\nneighbors, as communicated in the messages mj\u2192i and vice versa. Astute\nreaders will have noticed a circular dependency between Definition 4.17 and\nDefinition 4.18. Taken together the values are well-defined. Suppose that\nH is only one level deep. Then the messages m can be computed with a\nforward-backward pass similar to the standard Max-Plus algorithm. Now let H\nallow two actions in a row. With the same argument, the messages that evaluate\nthe second action choice can be generated. Once these messages are known, the\nagents can compute the Q-value for the possible first actions. By induction, the\nmessage values are well defined on H where all sequences have finite length.\nExample 4.3. Suppose that an Original Equipment Manufacturer (OEM)\nowns two production sites. One in Germany and the other in China. A\ncustomer buys a lot of 1000 items to be made to order. The German\nsite can produce the items for $40 a piece. The Chinese site can\nfulfill the order for $35 a piece. But due to uncertainties for the\nlong transport, there is a 10% chance that the products will not reach\n116 4 Distributed Planning for Self-Organizing Production Systems\nthe OEM headquarters in time for packaging and delivery. For this,\nthe scenario defines three components C = {oem, de, cn}. Every\ncomponent also represents an agentC = I . There are six actions defined:\nA = {pass_de, prod_de, prod_cn, pass_cn, pass_oem, deliver}.\nThe \u201cpass\u201d action terminates the scenario for the respective agent. The\nparticipants of the action Cpass_de = {de}, Cprod_de = {oem, de},\nCpass_cn = {cn}, Cprod_cn = {oem, cn}, Cdeliver = Cpass_oem =\n{oem}. The shared actions are Aoem,de = {prod_de} and Aoem,cn =\n{prod_cn}. The action prod_cn returns an observation that is either\nof or os indicating either failure or success. None of the actions take a\nparameter. The reward generated by the actions for the involved agents\nis stated in Table 4.1.\nAction / Reward (in k$) rprod_de rprod_cn rprod_oem\nprod_de \u221240 \u2212 0\nprod_cn \u2212 \u221235 0\ndeliver \u2212 \u2212 55\nTable 4.1: Reward generated by the actions in the supply-chain example.\nThe possible histories are (prod_de, deliver), (prod_cn of) and\n(prod_cn os, deliver), as well as the sub-histories with only the\nfirst action. The empty action parameters and observations are omit-\nted for readability. From the perspective of global optimisation, the\ndeterministic reward for going with the German production site is\n(\u221240 + 55) = 15. The expected reward with the production in China is\n0.9(\u221235 + 55) + 0.1(\u221235) = 14.5.\nWe now show some selected examples for the Q-value and the messages\nbetween the agents from Definition 4.17 and 4.18. Once the production\nsites have either produced or passed on the production, the scenario is\n\u201cdone\u201d for them and no further rewards are generated. As de and cn\nhave only one neighbor, no received messages are \u201cmirrored back\u201d in\n4.4 Distributed Planning under Uncertainty 117\nqde\u2192oem and qcn\u2192oem.\nqde\u2192oem(prod_de | \u00b7 ) = 0, qde\u2192oem(pass_de | \u00b7 ) = 0\nqcn\u2192oem(prod_cn | \u00b7 ) = 0, qcn\u2192oem(pass_cn | \u00b7 ) = 0\nGiven a either the production-production or the pass-action as a condi-\ntional, the optimisation of the actions is trivial for de and cn as there is\nonly one action that can be selected in accordance with the conditional.\nThe Equations 4.19 through 4.21 return the following.\nmde\u2192oem(prod_de | \u00b7 ) = qde\u2192oem(\u03b5 | prod_de) = \u221240\nmde\u2192oem(pass_de | \u00b7 ) = qde\u2192oem(\u03b5 | pass_de) = 0\nmcn\u2192oem(prod_cn | \u00b7 ) = qcn\u2192oem(\u03b5 | prod_cn) = \u221235\nmcn\u2192oem(pass_cn | \u00b7 ) = qcn\u2192oem(\u03b5 | pass_cn) = 0\nWith these messages transferred, the agent oem can continue with the\ncomputation of q\u2217oem.\nq\u2217oem(prod_cn) = P(os)\n[\nroem(prod_cn) +\nr\u0304de\u2192oem(\u03b5, prod_cn os) +\nr\u0304cn\u2192oem(\u03b5, prod_cn os) + q\u2217oem(prod_cn os)\n]\n+\nP(of)\n[\nroem(prod_cn) +\nr\u0304de\u2192oem(\u03b5, prod_cn of) +\nr\u0304cn\u2192oem(\u03b5, prod_cn of) + q\u2217oem(prod_cn of)\n]\n= 0.9 \u00b7 [0 + 0\u2212 35 + roem(deliver)] +\n0.1 \u00b7 [0 + 0\u2212 35 + 0] = 14, 5\n118 4 Distributed Planning for Self-Organizing Production Systems\nThe message from oem to its neighbors do not contain the reward that\nwas signaled from the neighbor itself.\nmoem\u2192de(prod_de) = 55, moem\u2192de(pass_de) = 14.5,\nmoem\u2192cn(prod_cn) = 49.5, moem\u2192de(pass_cn) = 15\nWith that, the agents can jointly maximize the expected global reward\neven though they have only a limited scope to the system state and\npossible actions.\nThe messages mi\u2192j assign a value to every node of the shared history tree\nHij . Computing the messages mi\u2192j is computationally challenging. Instead of\ncomputing the message values directly, they are approximated via Monte-Carlo\nsampling. See Algorithm 15 for the full specification of the The Distributed\nPartially-Observable Hybrid Tree Planning (DPOHTP) algorithm.\nSimilar to the DUCT algorithm, the agents I are exchanging messages as they\njointly explore the solution space. Every agent can use his private model for the\ncomponents in his scope. So DPOHTP does not rely on a central simulator. The\nagents optimize for the global reward with their action choices. But they keep\nthe reward for the different agents separated for the statistics on expected reward.\nThe Playi procedure generates playout histories by sampling from the stochastic\nsimulator and using the current reward statistics, exchanged messages and policy\n\u03c0 for decision making. The Paramsi procedure is used to select parameters for\nthe current action. It uses Optimistic Optimization similarly to StoSOO. But\nevery call to Paramsi returns exactly one parameter vector. So several actions\nwith a parameter each can be selected in one playout. The Updatei procedure\ntakes the last playout of the agent i and updates his internal reward statistics as\nwell as the messages sent to the neighbors. Every parameter node stores the\nempirical direct reward that was generated by the action-parameter combination\nin a hashmap ei. The Q-value of the parameter additionally considers the\nexpected reward for optimal decision-making later on. Optimal decision-making\nhere refers to the maximization of the global reward, taking the reward signaled\nby the neighboring agents via messages into account. Note that the messages\n4.4 Distributed Planning under Uncertainty 119\nare updated with an averaging procedure in lines 14\u201318 instead of maximizing\nover the actions and parameters. This is due to the fact that several histories hi\nproject to the same hij . A maximization under the premise that only the current\nhi is considered in the message would distort the message which represents an\nexpectation over the future reward.\nAlgorithm 15 The Distributed Partially-Observable Hybrid Tree Planning\n(DPOHTP) algorithm\n1: procedure DPOHTP(\u03c30)\n2: mi\u2192j [ \u00b7 ]\u2190 0 \u2200i \u2208 I, j \u2208 N(i)\n3: ni\u2192j [ \u00b7 ]\u2190 0 \u2200i \u2208 I, j \u2208 N(i)\n4: ni[ \u00b7 ]\u2190 0, qi[ \u00b7 ]\u2190 0 \u2200i \u2208 I\n5: ei[ \u00b7 ]\u2190 0 \u2200i \u2208 I\n6: Li[ \u00b7 ]\u2190 {(0, 1)} \u2200i \u2208 I\n7: d\u0304\u2190 1\n8: while enough time do\n9: for i \u2208 I do\n10: \u03c3i \u223c \u03c30i\n11: (hi, ri)\u2190 Playi(\u03c30i )\n12: Updatei(hi, ri)\n13: d\u0304\u2190 d\u0304 + 1\n14: if d\u0304 > log2(ni[\u03b5] then\n15: d\u0304\u2190 1\n16: return arg max\na\u2208A, \u03b8\u2208\u0398a,\n\u2200i\u2208Ia, ni[a\u03b8]>0[ \u2211\ni\u2208I qi[\u03a0i(a\u03b8)]\n]\n1: procedure Playi(\u03c3i, d\u0304)\n2: hi \u2190 \u03b5, ri \u2190 \u03b5\n3: while not done(\u03c3i) do\n4: B \u2190 {bi \u2208 Ai : n[hibi] = 0}\n5: if B 6= \u2205 then\n6: (ai, \u03b8i)\u2190 \u03c0i(hi, Bi)\n7: d\u0304\u2190 d\u0304\u2212 1\n8: else\n9: ai \u2190 arg max\nbi\u2208Ai\n[\nqi[hibi] +\n\u03b1\n\u221a\nlog ni[hi]+1\nni[hibi]\n+\u2211\nj\u2208N(i) mj\u2192i[\u03a0ij(hibi)]\n]\n10: d\u0304\u2190 d\u0304\u2212 1\n11: \u03b8i \u2190 Parami(hiai, d\u0304)\n12: d\u0304\u2190 d\u0304\u2212 depth(Li[hiai]\n13: (\u03c3i,oi, vi) \u223c a\u03b8ii (\u03c3i)\n14: hi \u2190 hiai\u03b8ioi, ri \u2190 (ri, vi)\n15: return hi, ri\n120 4 Distributed Planning for Self-Organizing Production Systems\n1: procedure Parami(hiai, d\u0304)\n2: if d\u0304 > depth(L[hiai]) then\n3: return arg max\n\u03b8:\u2203(u,v)\u2208Li[hiai],\nxi[hiai;u,v]=\u03b8\nq[hiai\u03b8]\n4: else if d\u0304 < 1 then\n5: G\u2190 Li[hiai]\n6: else\n7: G\u2190 Li[hiai; d\u0304]\n8: (u, v)\u2190 arg max\n(c,j)\u2208G,\nxi[hiai;c,j]=\u03b8\n[\nqi[hiai\u03b8] + \u03b1\n\u221a\nlog ni[hiai]+1\nni[hiai\u03b8]\n+\u2211\nj\u2208N(i) mj\u2192i(\u03a0il(hiai\u03b8))\n]\n9: \u03b8 \u2190 xi[hiai; u, v]\n10: if ni[hiai\u03b8] < \u03ba \u2227 l = lmax then\n11: return \u03b8\n12: u[ha; l, i]\u2190 u[ha; l, i] + 1, \u00b5\u2190 u[ha; l, i]\n13: n\u2190 dim(\u0398a), \u03b4 \u2190 mod(l, n) + 1\n14: \u03be \u2190 |L[ha; l + 1]|+ 1\n15: x[ha; l + 1, \u03be]\u2190 \u03b8 + (\u00b5\u2212 2)\u03bd\u03b4\n(\n1\n3\n)bl/nc+1\n16: L[ha]\u2190 L[ha] \u222a {(l + 1, \u03be)}\n17: if \u00b5 = 3 then\n18: L[ha]\u2190 L[ha] \\ {(l, i)}\n19: return x[ha; l + 1, \u03be]\n1: procedure Updatei(hi, ri)\n2: for k = |hi|, . . . , 1 do\n3: (ai, \u03b8i,oi)\u2190 hki\n4: gi \u2190 h:k\u22121i\n5: ni[gi]\u2190 ni[gi] + 1, ni[giai]\u2190 ni[giai] + 1, ni[giai\u03b8i]\u2190 ni[giai\u03b8i] + 1\n6: ei[giai\u03b8i]\u2190 ei[giai\u03b8i] +\nrki \u2212ei[giai\u03b8i]\nni[giai\u03b8i]\n7: qi[giai\u03b8i]\u2190 ei[giai\u03b8i] +\n\u2211\noi\u2208Oi\n[\nqi[giai\u03b8ioi] n[giai\u03b8ioi]n[giai\u03b8i]\n]\n8: \u03b8\u2217i \u2190 arg max\u03c6i\u2208\u0398ai\nn[giai\u03c6i]>0\n[\nqi[giai\u03c6i] +\n\u2211\nj\u2208N(i) mj\u2192i(\u03a0ij(giai\u03c6i))\n]\n9: qi[giai]\u2190 qi[giai\u03b8\u2217i ]\n10: a\u2217i \u2190 arg maxbi\u2208Ai\nn[gibi]>0\n[\nqi[gibi] +\n\u2211\nj\u2208N(i) mj\u2192i(\u03a0ij(gibi))\n]\n11: qi[gi]\u2190 qi[gia\u2217i ]\n12: for j \u2208 N(i) : ai \u2208 Aij do\n13: gij \u2190 \u03a0ij(gi)\n14: ni\u2192j [gijai\u03b8i]\u2190 ni\u2192j [gijai\u03b8i] + 1, ni\u2192j [gijai]\u2190 ni\u2192j [gijai] + 1\n15: q\u2032 \u2190 qi[gijai\u03b8i] +\n\u2211\nl\u2208N(i)\\{j} ml\u2192i(\u03a0il(giai\u03b8i))\n16: mi\u2192j [gijai\u03b8i]\u2190 mi\u2192j [gijai\u03b8i] + q\n\u2032\u2212mi\u2192j [gij ai\u03b8i]\nni\u2192j [gij ai\u03b8i]\n17: q\u2032\u2032 \u2190 qi[gijai] +\n\u2211\nl\u2208N(i)\\{j} ml\u2192i(\u03a0il(giai))\n18: mi\u2192j [gijai]\u2190 mi\u2192j [gijai] + q\n\u2032\u2032\u2212mi\u2192j [gij ai]\nn[gij ai]\n4.5 Evaluation 121\n4.5 Evaluation\nA preliminary version of DPOHTP was evaluated in [Pfr16a]. The main\ndifference is that this version allows each agent to run simulations in a private\nsimulator. So the agents are completely decoupled besides their message\nexchange. Existing benchmark examples from the Dec-POMDP literature\nassume a central simulator.\nThe scenario from autonomous driving was chosen since it enables a good\nvisual understanding of the effect of agent coordination. Autonomous driving\ncan be considered as one of the activites on the lower levels of the control\nhierarchy for supply-chain logistics. Furthermore, it shows the ability of the\napproach to adjust to changing system topologies with agent entering and leaving\nat runtime. Note that the example does not claim to be a physically accurate\nsimulation for autonomous driving. It is a highly stylized benchmark example\nand not intended for practical use. Still, the model is based on results from the\nrelevant literature that uses MCTS for planning of car maneuvers [LKK16]. If\nrequired, the simulation model can be readily replaced with something more\naccurate without changing the (implementation of) the GMCTS algorithm used\nfor planning and coordination.\nTwo versions of the driving scenario are shown in Figures 4.4 and 4.5. Both\nstart from the same initial situation. Three cars (blue, green and red) are\ndriving close to each other at the same speed. They head toward the grey car\nthat blocks the left lane after an accident. The cars have only a limited radius of\nvisibility (assume some fog or heavy rain blocking the view). The cars seeing\neach other are marked with blue and green lines respectively.\nThe timeline of the scenario is discretized to 100 millisecond periods. In\nevery period the cars may choose between five actions: nothing, accelerate,\nbreak, moveLeft and moveRight. The cars receives a reward at every iteration.\nA negative reward of \u22121 is assigned for every action besides nothing. This\ngives an incentive not to over-react. An additional negative reward of \u221250 is\nassigned to every car that crosses onto the shoulder of the road. Cars touching\neach other receive a reward of \u22121000 each. Each car has an internal simulator\nto predict future situations given joint actions for all cars in their visibility\n122 4 Distributed Planning for Self-Organizing Production Systems\nscope. Cars outside the visibility scope are not considered in the simulator. The\nsimulator is the basis for MCTS-based planning.\nIn the first figure, the red car \u201csees\u201d the accident at a very late point when\nthe green car has already nearly passed. Until then, the red car stays in his\nline and keeps the original speed. Then, to prevent a crash that can now be\npredicted by the red car, the red car moves behind the blue car. The second\nfigure was produced by identical parameters than the first figure. The only\nchange is the exchange of messages between agents. So they use our DPOMCP\nalgorithm instead of plain MCTS. It can be seen that the red car reacts much\nsooner to the accident, even before the grey car moves into his scope of visibility.\nThe reason for this change of behavior is as follows: In the second line of\nFigure 4.5, the green car already sees the accident. Therefore the potential crash\nof the red and grey cars are predicted by the green car. When the green cars\nexchanges a message with preferences with the red car, then the danger of the\ncrash is marginalized into the expected reward starting from possible shared\naction sequences. Thus, the red car learns about the potential strong negative\nconsequences for staying in its line. The red cars therefore moves to the right\nlane and inserts even before the blue car. The change of exchanging messages\nleads to a very different \u2013 and more safe \u2013 outcome compared to the scenario\nwithout coordination.\nThe advantage of our work compared to previous results [FB10] is that it\ndoes not require that cars explicitly define coordination groups. Second, the\ncomplexity of the coordination algorithm grows exponentially only in the number\nof neighbors at every agent. Since every agent has a limited scope (and just a\nfew neighbors), scaling to very large systems is easily possible. Third, when\nagents enter and leave the system at runtime, this has only a very local impact as\njust the direct neighbours need to coordinate.\n4.5 Evaluation 123\n\u02d9\n\u02d9\n\u02d9\n\u02d9\n\u02d9\n\u02d9\n\u02d9\nFigure 4.4: Autonomous driving example without coordination. The blue lines\nindicate neighbor relations.\n124 4 Distributed Planning for Self-Organizing Production Systems\n\u02d9\n\u02d9\n\u02d9\n\u02d9\n\u02d9\n\u02d9\n\u02d9\nFigure 4.5: Autonomous driving example with coordination. The green lines\nindicate neighbor relations that are also communication relations.\n5 Modeling of Production Skills\nThe tape was a small loop that fed continuously between\nmagnetic pickups. On it were recorded the movements of\na master machinist turning out a shaft. [. . .] Rudy Hertz,\nan old timer, who had been about ready to retire. And here,\nnow, this little loop [. . .] was Rudy as Rudy had been to his\nmachine that afternoon. Rudy, the turner-on of power, the\nsetter of speeds, the controller of the cutting tool. This was\nthe essence of Rudy as far as his machine was concerned.\nKurt Vonnegut \u2013 Player Piano [Von52]\nThe model of production systems developed in Chapter 2 demands that every\npossible behavior of the manufacturing resources is captured in the form of\nactions with well-defined preconditions and effects. This lays a heavy burden on\nplant operators to manage the set of available actions. Especially when changes\nare made to the plant topology and the targeted product lineup. While the actions\nare conceptually uniform, the complexity of a flexible manufacturing plant\nmanifests itself in the large number of actions required to model the relevant\naspects. For tens of considered final products with tens of manufacturing steps\neach, as well as tooling and transportation, plant operators need to model (and\nkeep up-to-date) thousands of actions.\nIn addition to just defining the actions, their execution requires custom control\ncode or the parameterization of reusable functionality for the product at hand.\nThis custom effort to foresee, implement and deploy actions that are possibly\nneeded at runtime is then a bottleneck for system integrators and operators who\nwant to introduce changes at a later time. To reduce this burden, we introduce\nhigher-level abstractions for the skills of the system components. Together with\na similar description of the production requirements, the low-level actions are\nthen generated automatically or with tool assistance.\n126 5 Modeling of Production Skills\nExecutable actions for planning and runtime control in\na production systems can be generated from higher-level\ndescriptions of the production system and the requirements.\nNote: Our work on skill modeling [PSB13a; Pfr+14c; PSB13b; Pfr+15b] was\npublished starting in 2013. The more recent literature already references and\nincorporates these results. This chapter provides a synthesis of our published\nwork together with a novel representation of the concepts in Description Logics.\nOur own publications are not referenced in the summary of the state-of-the-art.\n5.1 Background: Skill Models for Production\nSussman was one of the first to define a \u201ctheory of skill\u201d that was not focused\non the skilled human but on the computer [Sus73]. He writes:\n[. . .] a skill is a set of answer procedures, each indexed by a\ndescription of the problem types for which it is appropriate, along\nwith a set of pitfalls to avoid when it is necessary to construct a new\nanswer procedure. A skill is acquired by the construction of such a\nstore of \u201crunnable\u201d knowledge \u2013 canned answers to problems \u2013 by\n\u201ccompiling\u201d it from knowledge of the problem domain supplied in a\nmore \u201cintelligible\u201d form \u2013 a form designed more for communication\nthan for use as answers to problems.\nThis early work already talks about representations for the skill and the problem\ndescription, as well as the \u201ccompilation\u201d of their combination into an executable\nform. Since then, work on technical skill definitions has continued mainly in\nthe robotics domain. Many authors have worked on methods for learning of\nparticular robot skills [GFB94; MK97; FRD98]. But we are rather interested in\nskill definitions that applies across different application domains.\nIn the last 10 years, interest in using skill definitions specifically for the\nproduction domain has considerably gained in importance. Some authors from\n5.1 Background: Skill Models for Production 127\nthe production community differentiate between the terms skill and capability.\nIn this text, we will use the terms interchangeably.\nThe authors from the SIARAS project [Mal+07] use ontologies to store skills\nand their relations for production. This information is then used for automatic\nreconfiguration of production systems. Naumann et al. [NWS07] use an ontology\nto model robot skills and use state-charts for sequences within manufacturing\nprocesses. J\u00e4rvenp\u00e4\u00e4 et al. [Jar+11] define an ontology for skills in manufacturing\nand use it to map resources to manufacturing steps. Kluge [Klu11] uses skill\nmodels for assembly planning. Huckaby and Christensen [HC12] provide a\ntaxonomy for assembly tasks and related skill primitives. Constraints specify\nwhether they are executable in a certain situation. Bj\u00f6rkelund et al. [Bj\u00f6+12]\nfirst make use of the PPR (Product, Process, and Resource) concepts in the\ncontext of skills. They relate skills to all three views of PPR and represent skills\nas finite state machines. Keddis et al. [KKZ14] define a description vocabulary\nfor skills of production resources and an accompanying algorithm for production\nplanning and scheduling. Legat et al. [LSV14] use a description of the resource\nskills to guide engineers in the implementation of field control code. Backhaus\net al. [BUR14] present a classification of manufacturing skills to enable task-\noriented programming. This concept is expanded in [BR15] and used to generate\nexecutable tasks for a welding robot. Malakuti et al. discuss challenges of\nskill-based production control for practitioners and possible solutions [Mal+18].\nThe authors of [J\u00e4r+18] use semantic inference to determine the capabilities of\nresource combinations. For example of a robotic manipulator combined with a\ngripper.\nMany interesting approaches to describe the skills of production resources\nvia ontologies and high-level description schemas have been proposed in the\nliterature. All authors report the successful application in the demonstration\nscenarios for which their description schemas were developed. We argue\nthat modelling semantic knowledge about production systems facilitates the\nintegration of resources in a Plug & Produce fashion. But it is not enough. First,\nas ontologies for describing manufacturing skills become more detailed, the less\ngeneral they are. This leads to the difficult situation where\n\u2022 general skill description schemas require additional information to cover\nimplementation-specific edge-cases and constraints, and\n128 5 Modeling of Production Skills\n\u2022 detailed skill description schemas are applicable to only a narrow subset\nof resources and will have difficulties in getting the required support\nacross vendors and integration tooling suppliers. A possible scenario is\nthe emergence of a standardized core skill description schema from which\ndomain-specific and sometimes overlapping schemas will branch off.\nSecond, semantic reasoners were developed to infer further information from\nan existing knowledge-base. But they are not equipped for reasoning about\nnumerical optimization problems, such as the resource- and time-efficient\nproduction of many products on concurrent resources. Therefore, we see the\nrole of semantic skill descriptions primarily for integration and configuration\ntasks. To make the flexibility of generic resource skills available on the level\nof large-scale systems, they need to be propagated to dedicated planning and\nruntime control systems that may use different representations. This also offers\nthe possibility to integrate overlapping and domain-specific skill description\nschemas if they can be interfaced to a unified abstraction used for planning and\nruntime control.\n5.2 Background: Description Logics\nDescription Logics (DL) [Baa03] are a family of formal knowledge representation\nlanguages developed to represent hierarchical and relational structures and to\nenable reasoning over these structures. DL are the formal basis of semantic\nmodels with ontologies. DL models are defined in terms of constants, concepts\nand roles. The semantics of a DL is defined in terms of first-order logic. Hence,\nno DL is more powerful than first-order logic. Let the domain \u2206 a fixed\ncountably infinite set. The interpretation I is a function \u00b7 I that assigns\n\u2022 to every constant c an element of \u2206 so that cI \u2208 \u2206,\n\u2022 to every concept C members of \u2206 as CI \u2286 \u2206,\n\u2022 to every role R binary relations between members of \u2206 as RI \u2286 \u2206\u00d7\u2206.\nThe interpretation has to be consistent with respect to assurances that are defined\nfor the model.\n5.2 Background: Description Logics 129\nTable 5.1 gives an overview on the syntax of the EL DL [KKS14] with the\naddition of concrete domains to express and reason about numerical attributes\n[BH91]. More expressive DL than EL exist. It was selected for the exposition\ndue to its relative simplicity and the existence of performant solvers. By\nconvention, we write the elements of DL models as follows: Constants are\nwritten in typewriter font, Concepts in a sans-serif font with a leading uppercase\nand hasRole definitions in a sans-serif font with a leading lowercase.\nExample 5.1. Begin with the constants alice and bob. Both of them\nare humans and therefore, Human(Alice) and Human(Bob). Every\nhuman is either male or female. Therefore Female v Human, Male v\nHuman and Female u Male v >. Suppose Alice is the daughter\nof Bob. The role childOf describes the parent-child relation. We\nassert this relation between our two humans as childOf(Alice, Bob).\nDaughters are the female children of a human. This can be stated as\ndaugherOf v childOf with the domain dom(daughterOf) v Human and\nrange ran(daughterOf) v Human u Female. From this we can infer\nthat in effect daughterOf(Alice, Bob).\nAttributes from concrete domains are also assigned via role re-\nlations. Alice is 11 years old. So she has the attributes\nhasAge(Alice, 11) and hasName(Alice, \u201cAlice\u201d). Queries over con-\ncrete domains are stated in the form of predicates. The concept\nHuman u \u2203hasAge.(<, 12) u \u2203hasName.(=, \u201cAlice\u201d) contains all hu-\nmans named Alice and less than 12 years old.\n130 5 Modeling of Production Skills\nDL Syntax Set-Theoretic Semantics\nConcepts\nUniversal Concept (Top) > \u2206I\nEmpty Concept (Bottom) \u22a5 \u2205\nConcept Assertion C(a) aI \u2208 CI\nConjunction C uD CI \u2229DI\nInclusion C v D CI \u2286 DI\nRestriction \u2203R.C {x | \u2203y : (x, y) \u2208 RI \u2227 y \u2208 CI}\nRoles\nRole Assertion R(a, b) (aI , bI) \u2208 RI\nDomain Restriction dom(R) v C RI \u2286 CI \u00d7\u2206I\nRange Restriction ran(R) v C RI \u2286 \u2206I \u00d7 CI\nInclusion R v S RI \u2286 SI\nComposition R1 \u25e6R2 v S (x, y) \u2208 RI1 \u2227 (y, z) \u2208 RI2 \u2192 (x, z) \u2208 SI\nData Types\nRestriction \u2203F.r {x | \u2203v \u2208 D : (x, v) \u2208 F I \u2227 r(v)}\nTable 5.1: Syntax and Semantics of the EL+\u22a5 Description Logic.\n5.3 The PPRS Model for Production Skills\nWe begin with an informal characterization of the PPRS model. In production,\nprocesses are used to create products. Processes stand for a type of operation,\nsuch as welding. The processes are performed by the resources of a production\nsystem, such as machines and technical equipment in general. Skills describe\nwhat a component is capable of in general. Transformations describe a specific\nproduction step that changes the attributes of a workpiece, consumes ingoing\nworkpieces and material to create some output, and so on. Transformations\nare associated with one or more processes. Actions are realizations of a skill.\nFor example to perform a specific transformation of a workpiece. Figure 5.1\ngives a high-level overview on the six concepts and their relations. More precise\ndefinitions are now given, together with the representation the language of DL.\n5.3 The PPRS Model for Production Skills 131\nProduct Process Resource\nTransformation Skill\nAction\nFigure 5.1: Outline of the relations between the PCM concepts.\nExample 5.2. The example used for the remainder of this chapter comes\nfrom the production of automotive battery systems. The example is\nheavily simplified to serve as an educational example. From a high-level\nperspective, battery systems are comprised of battery cells that are\nwelded to a conductive busbar. See [Das+18] for a detailed account of\nthe different joining techniques in battery production.\nDefinition 5.1 (Product). A product is a type of marketable good, raw material\nor intermediate workpiece between production steps. Products describe discrete\n(countable) entities. Bulk material and fluids must be \u201cpackaged\u201d to be\nconsidered a discrete product. Whenever product types and product instances\nneed to be differentiated, product instances are denoted as workpieces to make\nthe distinction clear.\nIn DL, products are represented as constants. The properties of the product\ntype are defined via attributes from concrete domains. The definition corresponds\nto the product definition from Chapter 2. Workpieces (product instances) of the\nsame product type are interchangeable.\nExample 5.3. The products defined for the battery production example\nare cell, busbar and battery.\n132 5 Modeling of Production Skills\nProduct(cell)\nProduct(busbar)\nProduct(battery)\nDefinition 5.2 (Process). Processes denote a type of production operation.\nEvery process defines a set of process attributes that are used to characterize\ninstances derived from the process. Processes form a hierarchy where attributes\nare inherited from parent processes.\nThe term process is overloaded and understood differently in the fields of\ncomputer science, statistics, workflow management, production, and many more.\nThe definition used here corresponds to the use of the term manufacturing\nprocess in DIN 8580 [DIN8580]. In DL, processes are represented as concepts.\nProcesses form a hierarchy of concepts derived from the topmost concept\nProcess.\nExample 5.4. The processes defined for the battery production example\nare welding and the more specialized laser-welding. The processes\nare described by the power used for welding and, for the laser-welding\nprocess, the wavelength of the laser.\nLaserWelding vWelding v Process\ndom(hasPower) vWelding\nran(hasPower) = P (R+)\ndom(hasWaveLength) v LaserWelding\nran(hasWaveLength) = P (R+)\nThe use of the powerset P (R+) as the concrete domain of the hasPower role\nallows instances of a welding process to refer to ranges of possible temperatures\ninstead of a single scalar. Note that the concrete domains for process attributes\nmay become quite complex, e.g. to describe the possible tool positions and\nrotations for a 5-axis CNC mill. Implementation may restrict concrete domains\nfor example to one-dimensional ranges, where the representation and verification\nof predicates on a computer is trivial.\n5.3 The PPRS Model for Production Skills 133\nSeparation (DIN 8580 \u2013 3)\nCutting with geometrically\ndefined cutting edges\n(DIN 8580 \u2013 3.2)\nSevering (DIN 8580 \u2013 3.1)\nDrilling (DIN 8580 \u2013 3.2.2)\n\u2022 Position / mm2 (R\u00d7 R)\n\u2022 Diameter / mm (R+)\n\u2022 Depth / mm (R+)\nTurning (DIN 8580 \u2013 3.2.1)\nCooled Drilling\n\u2022 Coolant Type ({water, oil})\n\u2022 Max. Temperature / \u00b0C (R)\nCountersink Drilling\n\u2022 Chamfer Angle / mm (R+)\n\u2022 Outer Diameter / mm (R+)\nFigure 5.2: Excerpt from a hierarchy of production processes based on DIN\n8580 [DIN8580]. The process attributes are from the indicated concrete domains.\nArrows denote an inheritance relation, which is expressed in DL via concept\ninclusion, such as CountersinkDrilling v Drilling.\nFigure 5.2 shows a more complete example process hierarchy, specializing\nprocesses for drilling from DIN 8580. Processes usually originate from the\nproduction and logistics domain. But they can also be auxiliary to the core\nproduction operations. For example processes for machine maintenance.\nDefinition 5.3 (Resource). Resources denote machines and technical assets in\ngeneral. Resources are components in the nomenclature of Chapter 2.\nRenaming the components from Chapter 2 to resources may seem unnecessary.\nThis is done in this chapter only to assure the possibility of comparison with\nexisting production skill models from the literature.\nIn DL, resources are represented as constants. The set of all resources is\ndenoted with the concept Resource. In addition, derived concepts can be used to\ngroup resources. For example 5AxisManipulator v Manipulator v Resource.\nThis is useful to query for specific resources. But this grouping of resource has\nno further purpose in this text.\n134 5 Modeling of Production Skills\nExample 5.5. In the battery production example, we consider only one\nresource: The (imginary) LaserWelder200.\nResource(LaserWelder200)\nDefinition 5.4 (Transformation). Transformations are production operations\nthat transition one or several input products into one or several output products\nby the application of production processes.\nIn DL, transformations are represented as constants that are instances of\nthe Transformation concept. Two new roles, hasInput and hasOutput, both\nwith the range Transformation and the range Product, are used to model which\ningoing products are transformed to which output. The input/output relations\nbetween transformations can be used to draw a graph of a bill of processes. Note\nhowever, that transformations must act on a product. Auxiliary processes, such\nas machine tooling and transportation steps, are not considered.\nIn addition, transformations are also instances of one or more process concepts.\nTransformation v Process\nWith that, the transformations can assign values to the respective process\nattributes. The attributes of a transformation describe requirements that need\nto be fulfilled by implementations of the transformation. As described earlier,\nprocess attributes can have powersets for their domain in order to describe subsets,\nsuch as ranges. For example, a transformation for welding two workpieces\ntogether could indicate the range of supported temperatures in reference to the\ntemperature attribute specified for the welding process.\nExample 5.6. To produce a battery, cells are welded together with a\nbusbar. The welding process requires a power to be applied from the\nrange between 2kW and 3kW.\nTransformation(JoinBatteryCells)\nhasInput(JoinBatteryCells, cell)\n5.3 The PPRS Model for Production Skills 135\nhasInput(JoinBatteryCells, busbar)\nhasOutput(JoinBatteryCells, battery)\nWelding(JoinBatteryCells)\nhasPower(JoinBatteryCells, [2.000, 3.000])\nDefinition 5.5 (Skill). Skills describe that a resource can execute a process\nunder constraints defined in terms of the process attributes.\nIn DL, skills are represented as constants. Similar to transformations, skills\nare also instances of processes.\nSkill v Process\nTherefore, skills refer to the same attributes used to defined the transformation\nrequirements. But it in the case of skills, the attributes describe the possibility\nto realize a process for given attributes.\nExample 5.7. The LaserWelder has the skill to weld with a power\nbetween 2.5kW and 5kW. The CO2 laser used has a fixed wavelength of\n10.6\u00b5m.\nSkill(LW200LaserWeld)\nhasSkill(LaserWelder200, LW200LaserWeld)\nLaserWelding(LW200LaserWeld)\nhasPower(LW200LaserWeld, [2.500, 5.000])\nhasWavelength(LW200LaserWeld, 10.6)\nNow we can formulate a query to find all skills that match with the\nJoinBatteryCells transformation in terms of supported processes and\nprocess attributes. This leads us to the resources that possess said skills.\nThe \u2229 operator is used to find attributes where the overlap with the\nindicated range is nonempty.\nSkillMatch vWelding u \u2203hasPower(\u2229, [2.000, 3.000])\nResourceMatch v \u2203hasSkill.SkillMatch\n136 5 Modeling of Production Skills\nThe skill representations cannot capture all details of a production system.\nTherefore, we can only test whether a resource can perform a transformation\nin general. For some domains, the attributes might be sufficient to guarantee\nfeasibility of the match. In other domains, additional checks need to be performed\neither by detailed descriptions of the machine and product geometry or by manual\nintervention.\nHowever, once a skill has been specialized for a transformation or auxiliary\noperation, implemented, tested and deployed to the production system, e.g. in\nthe form of PLC control code, then we know the exact conditions under which\nthe concrete operation can be applied.\nDefinition 5.6 (Action). An action is an executable process instance with\nwell-defined preconditions and effects. Actions are defined for one or several\nparticipating resources. The DL concept Action contains instance elements that\ncorrespond to the formal action definition from Chapter 2.\nActions are assumed to encapsulate all the required information to execute on\nthe resource. For example in the form of IEC-61131 PLC code, configuration\nparameters, and so on. As a consequence, actions can be triggered simply by\nreference to their identifier, provided that all the preconditions are fulfilled.\nExample 5.8. The action LW200BatteryWeld is an implementation\nof the JoinBatteryCells transformation. It makes use of the\nLW200LaserWeld skill.\nAction(LW200BatteryWeld)\nimplements(LW200BatteryWeld, JoinBatteryCells)\nuses(LW200BatteryWeld, LW200LaserWeld)\n5.4 Assisted Generation of Executable Actions\nIn a Plug & Produce scenario, at some point the generic skills of machines\nand equipment need to be specialzied into executable actions with known\npreconditions and effects. This splits into two steps:\n5.4 Assisted Generation of Executable Actions 137\n1. Selection of the actions that are required for runtime planning and control.\n2. Implementation and deployment of the actions.\nThe assistend generation of actions was considered as part of the arhitecture of\nthe SkillPro project. See Figure 5.3 for an overview.\nThe machines and equipment are assigned to a Skill Execution Engine (SEE).\nThe SEE provide smart wrappers to the physical resources, which range from\nconveyor belts with little configurability to complex machine tools and even\nhuman workers. Facing towards the underlying resources, the SEE implement\ndomain-specific connectivity, e.g. based on a fieldbus protocol or OPC UA. In\ncase of the human worker, this is accomplished with a tablet-based graphical-\nuser-interface. Also, the SEE may contain domain-specific knowledge on how\nto derive actions from high-level skill-based descriptions\nThe Manufacturing Execution System (MES) is responsible for orchestrating\nthe available resources in order to achive short- to mid-term manufacturing\ngoals. For this, the MES implements two main features working in lockstep:\ncomputing a fine-grained execution plan that accomplishes the manufacturing\ngoals, and the orchestration of the manufacturing resources at runtime.\nThe Asset Management System AMS constitutes the central knowledge base of\na manufacturing facility and provides this information to the adjacent components.\nIt contains semantic descriptions of the available resources and their skills,\nas well as a detailed plant model including topological (e.g. how resources\nare arranged in work cells) and topographical (e.g. layout and position of the\nresources) relations. The AMS also holds product models, including drawings,\nbills of material and bills of processes. The AMS furthermore manages customer\norders on a long-term horizon and ensures that the required resources with\nthe right skills are available. Lastly, it interfaces the SkillPro framework with\nenterprise level ERP (Enterprise Resource Planning) and PDM (Product Data\nManagement) systems.\nAssume that a list of product transformations (bill of processes) are initially\nprovided or it could be inferred from the product description itself [TMP92].\nThe task of determining the right operations to produce a specific product was\noriginally investigated as Computer-Aided Process Planning (CAPP) [ElM93;\nKir95]. CAPP deals with finding \u201ca way through the production system\u201d.\n138 5 Modeling of Production Skills\nAMS\nMES MES\nSEE SEE SEE SEESEESEE\nFigure 5.3: Architecture of the SkillPro project [Pfr+15b]\nSo CAPP is different from production planning and scheduling, where the\nproduction of many products on a given plant layout is considered.\nThe generation of executable actions from high-level skill-based descriptions\nrequires the communication of AMS and SEE framework components. The\nSEE may internally implement actions with a variety of technologies. Possible\nways for implementing actions are:\n\u2022 Customization of predefined procedures by parametrization, where the\ndefined parameters are either resource- or production-domain specific\n[ON15]. Note that a description of the entire product in an appropriate\nformat may constitute a parameter in this context. More examples of\nreasoning on the execution of a high-level task model can be found for\nexample in the RoboEarth project [TB09; Wai+11].\n\u2022 Automatic code synthesis from a high-level description [VWK05], which\ncan also be either resource-specific or based on a domain specific language\n[DM97b; MOW01; Mit+05].\n\u2022 Manually programmed procedures, for example IEC-61131 function\nblocks.\nThe architecture from Figure 5.3 was implemented in the SkillPro project. At\nruntime, every SEE is represented by an OPC UA server that provides a uniform\n5.4 Assisted Generation of Executable Actions 139\ninterface. Clients can connect to the OPC UA server and discover the current state\nof the component, as well as the available actions. So from the perspective of a\nhigher-level control system, the SEE are all uniform. Even if they represent very\ndifferent types of production equipment. If coordination between components\nfor an action is required (for example the time-synchronization beginning of\na procedure), they can also use OPC UA or rely some other communication\ntechnology in the background. The latter is rather disapproved of, since this\nadds technically rigid solution where tool-support for quick adaptations in the\nsense of Plug & Work do not have as much tool-support.\n\n6 Conclusion\nAutomated production systems face a tradeoff between efficiency and flexibility.\nThis thesis aims to improve the flexibility of automated production systems by\nthe use of a unified model representation on all levels of the control hierarchy.\nRecall the postulate from the outset of Chapter 2:\nThe same set of modeling principles can represent the relevant prop-\nerties of production systems on all levels of the control hierarchy.\nThe thesis developed modeling principles that are able to represent both contin-\nuous and discrete production on all levels of the control hierarchy, including\nconcurrency, i.e. parallel operations and the synchronization of system compo-\nnents, as well as uncertainty in stochastic scenarios. To our knowledge, no prior\napproach was able to encompass all of these properties. In order to make use of\nsuch a model for planning and runtime control appropriate decisions need to be\nderived. Chapter 3 started with the following postulate:\nThe same algorithm can be used for planning and runtime control\non all levels of the control hierarchy \u2013 ranging from continuous\ndynamics of a physical system to global supply-chain operations \u2013\nand for both continuous and discrete production.\nAccordingly, an algorithm for optimal sequential decision making was developed\nbased on forward-simulation of the model from Chapter 2. Now that a model\nfor all levels of the control hierarchy and a matching planning algorithm exist,\nthe remaining challenge is to speed up planning for production operations at an\nindustrial scale. A range of measures were developed in this thesis to speed up\nplanning.\n\u2022 Pruning action sequences that are equivalent in a precise sense (Sec-\ntion 3.1).\n142 6 Conclusion\n\u2022 The use of Monte-Carlo Tree Search and Optimistic Optimisation to\nreplace trivial tree search and Branch & Bound methods (Section 3.2 and\nSection 3.3).\n\u2022 The relaxation of an important special case of the planning problem to a\nMixed-Integer Linear Program (Section 3.4).\nA way to speed up planning that is orthogonal to the techniques just mentioned\nis to decompose the planning problem into smaller subproblems to be solved\nby independent agents. For this, the algorithm from Chapter 3 is extended for\nmulti-agent coordination. The chapter sets out to achieve the following target\nresult:\nIndependent agents can jointly perform planning in a production\nscenario where every agent only has a simulation model of the\nsystem part in his visible scope.\nThe core idea of the developed planning algorithm is to use \u201cutility propagation\u201d\nfor the agent coordination similar to \u201cbelief propagation\u201d in probabilistic\ngraphical models. The decomposition into independent agent not only reduces\nthe planning complexity. Companies in a supply-chain can jointly optimize their\nactions without a central entity that has access to all private information.\nBut in order to optimise production with planning algorithms, the model\nrepresentations of the production system need to be accurate. Furthermore, if the\nresulting plans shall be used for automated control, then the action abstractions\nused in the model need to available as automated procedures on the actual\nmachines and equipment. Keeping the model and the physical production\nsystem synchronized can become quite resource-intensive when the production\nis flexible and changes over time. It is therefore preferable to automate much\nof the configuration work as well. The beginning of Chapter 5 postulates the\nfollowing.\nExecutable actions for planning and runtime control in a production\nsystems can be generated from higher-level descriptions of the\nproduction system and the requirements.\nWe put forward a framework to describe the skills of production equipment\nbased on Description Logic (i.e. semantic modeling). The framework also\n143\nencompasses the description of product transformations and the manufacturing\nprocesses involved. These descriptions are then used to match production steps\nwith machines and equipment capable of performaing than. Then, executable\nactions are generated and deployed for use by the runtime control systems. This\nis relevant for to achieve flexible production. Instead of manually programming\na PLC, higher-level abstractions can be used to generate and parameterized the\nrequired control code.\nThe thesis has answered all four postulates in the affirmative. Example from\ndifferent production scenarios and from all levels of the control hierarchy have\nbeen used to substantiate the claim. But surely this work can only be a stepping\nstone towards future automated production systems that are both efficient and\nflexible. To realize this goal, a large research programme is necessary that goes\nbeyond the scope of a single thesis. We now enumerate open research questions\nand some of the key results that need to be obtained future for the work from\ndifferent domains to coalesce into a coherent whole.\nDerive existing models for production and logistics from a common core\nThe production and logistics domain has developed numerous approaches for\nmodeling operations with varying degree of detail. This text has proposed a high-\nfidelity model as the common basis for all such models used in production and\nlogistics. To support that claim, examples from several production domains and\non several levels of the automation hierarchy have been used for the exposition.\nBut a more comprehensive treatment is required next to mere examples.\nIt is an open research question which limiting assumptions need to be made\non top of the high-fidelity model to recover more coarse-grained models that\nare already in productive use today. Such an investigation is the basis for\nan automated treatment of interfaces where subsystems that are controlled by\ndifferent modeling approaches connect.\nUsing Machine Learning to Guide Exploration Monte-Carlo Tree Search\n(MCTS) as a planning algorithm is essentially blind once it reaches a point\nin the scenario tree that was never visited before. Machine Learning methods\ncan be used to enable MCTS to \u201clearn to see\u201d. The Q-value of the system\nstate (or a belief distribution for the system state) can be approximated from\n144 6 Conclusion\nsimilar experiences in the past that were (reached with a different sequence of\nactions). In that sense, the model structure is not explicitly represented a-priori\nbut learned from the interaction with the scenario over a series of plays. This\nhas becomes known as Approximate Dynamic Programming [Ber+05; Pow07].\nThe combination of MCTS with neural networks as function approximators has\nfamously been used in the Deepmind AlphaGo system [Sil+16]. The expectation\nis that a further reduction of the sample complexity for simulation-based planning\nwith concurrent production system model can be achieved.\nThere is currently an active community working on Multi-Agent Reinforce-\nment Learning (MARL) [BBD08]. Recent advances in deep learning are now\nbeing integrated with MARL. Recent work also lets the agents learn how to\ncommunicate instead of predefining the information flow [Foe+16]. \u201cUtility\npropagation\u201d as used in Chapter 4 could be combined with recent MARL\ntechniques. For example by sending neural networks for Q-value estimation as\nmessages instead of an explicit Q-value representations on a search-tree.\nExplicit representation of product attributes The model from Chapter 2\nassumes that products are interchangeable. Instead of representing them\nindividually, only a count of products of the same type at the possible locations\nis considered. But there are of course differences between products of the same\nproduct type. This becomes apparent for example when quality issues come\nup. Quality (for which different the definition depends on the case at hand) is\nthen conditionally dependent on the attributes of incoming raw material and\nsemi-finished products, process settings and the state of the physical process. A\ncomplete \u201ctheory of production\u201d should therefore encompass product attributes\nas well.\nOpen systems with agents entering and leaving at runtime The decentralized\nplanning approach proposed in Chapter 4 allows for agents to enter and leave\nthe system at runtime. Such changes do not have to be communicated within the\nentire system and only neighboring agents have to be informed. A remaining\nquestion is to see how fast the overall system can adjust to the changes.\n145\nDomain-specific action generation The generation of executable actions\nfrom skill definitions requires domain-specific tool support. In some domains,\ncommercial products are already available that can transform higher-level\ndescriptions to executable definitions. Notably in the robotics domain where\nclear categories of equipment exist (cf. https://www.artiminds.com and\nhttps://www.keba.com). Another example is the standardized \u201cG-code\u201d for\nnumerically controlled machine tools [ISO82]. G-code can be exported by\nvirtually CAD/CAM tools that target product design. The control synthesis\nsolutions for the individual application domains then have to be integrated.\nFor example to assist the integration of systems that combine robotics for\nloading and unloading into a machine tool that transforms the work piece and\nvisual inspection for quality control. To us, high-level descriptions based on\nskill-definitions are the most promising inroad for control synthesis in domains\nwith more variety in the types of machines and equipment as well as a larger\nrange of products to consider.\n\nBibliography\n[Abe+06] E Abele et al. \u201cGlobalization and decentralization of manufac-\nturing\u201d. In: Reconfigurable Manufacturing Systems and Trans-\nformable Factories. Springer, 2006, pp. 3\u201313.\n[ABZ88] Joseph Adams, Egon Balas, and Daniel Zawack. \u201cThe shifting\nbottleneck procedure for job shop scheduling\u201d. In: Management\nscience 34.3 (1988), pp. 391\u2013401.\n[ACF02] Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. \u201cFinite-time\nanalysis of the multiarmed bandit problem\u201d. In: Machine learning\n47.2-3 (2002), pp. 235\u2013256.\n[Agn+14] Alessandro Agnetis et al. Multiagent scheduling. Springer, 2014.\n[Ali05] Knut Alicke. Planung und Betrieb von Logistiknetzwerken. Springer,\n2005.\n[AM00] Srinivas M Aji and Robert J McEliece. \u201cThe generalized dis-\ntributive law\u201d. In: IEEE Transactions on Information Theory 46.2\n(2000), pp. 325\u2013343.\n[AO15] Christopher Amato and Frans A Oliehoek. \u201cScalable Planning\nand Learning for Multiagent POMDPs\u201d. In: Twenty-Ninth AAAI\nConference on Artificial Intelligence. 2015, pp. 1995\u20132002.\n[Ara+00] T Arai et al. \u201cAgile assembly system by \u2019plug and produce\u2019\u201d. In:\nCIRP Annals-Manufacturing Technology 49.1 (2000), pp. 1\u20134.\n[Aza+16] Selma Azaiez et al. \u201cTowards Flexibility in Future Industrial\nManufacturing: A Global Framework for Self-organization of\nProduction Cells\u201d. In: Procedia Computer Science 83 (2016),\npp. 1268\u20131273.\n[Baa03] Franz Baader. The description logic handbook: Theory, implemen-\ntation and applications. Cambridge university press, 2003.\n148 Bibliography\n[Bac+92] Fran\u00e7ois Baccelli et al. \u201cSynchronization and linearity: an algebra\nfor discrete event systems\u201d. In: (1992).\n[Bad11] Iman Badr. \u201cAgent-based dynamic scheduling for flexible manu-\nfacturing systems\u201d. PhD thesis. University of Stuttgart, 2011.\n[Bas+75] Forest Baskett et al. \u201cOpen, closed, and mixed networks of queues\nwith different classes of customers\u201d. In: Journal of the ACM\n(JACM) 22.2 (1975), pp. 248\u2013260.\n[BBD08] Lucian Busoniu, Robert Babuska, and Bart De Schutter. \u201cA com-\nprehensive survey of multiagent reinforcement learning\u201d. In: IEEE\nTransactions on Systems, Man, And Cybernetics-Part C: Applica-\ntions and Reviews, 38 (2), 2008 (2008).\n[BCG07] Fabio Luigi Bellifemine, Giovanni Caire, and Dominic Greenwood.\nDeveloping multi-agent systems with JADE. Vol. 7. John Wiley &\nSons, 2007.\n[BD08] Ronen I Brafman and Carmel Domshlak. \u201cFrom One to Many:\nPlanning for Loosely Coupled Multi-Agent Systems.\u201d In: ICAPS.\n2008, pp. 28\u201335.\n[BDH99] Craig Boutilier, Thomas Dean, and Steve Hanks. \u201cDecision-\ntheoretic planning: Structural assumptions and computational\nleverage\u201d. In: Journal of Artificial Intelligence Research 11.1\n(1999), p. 94.\n[Bel57] Richard Ernest Bellman. \u201cDynamic Programming\u201d. In: (1957).\n[Ben93] Stuart Bennett. \u201cDevelopment of the PID controller\u201d. In: IEEE\ncontrol systems 13.6 (1993), pp. 58\u201362.\n[Ber+05] Dimitri P Bertsekas et al. Dynamic programming and optimal\ncontrol. Vol. 1. 3. Athena scientific Belmont, MA, 2005.\n[Ber+95] Dimitri P Bertsekas et al. Dynamic programming and optimal\ncontrol. Vol. 1. 2. Athena scientific Belmont, MA, 1995.\n[Ber38] Daniel Bernoulli. Hydrodynamica. Dulsecker, 1738.\n[BG01] Blai Bonet and H\u00e9ctor Geffner. \u201cPlanning and control in artificial\nintelligence: A unifying perspective\u201d. In: Applied Intelligence 14.3\n(2001), pp. 237\u2013252.\nBibliography 149\n[BH91] Franz Baader and Philipp Hanschke. \u201cA Scheme for Integrating\nConcrete Domains into Concept Languages\u201d. In: Proceedings of\nthe 12th International Joint Conference on Artificial Intelligence -\nVolume 1. IJCAI\u201991. Sydney, New South Wales, Australia: Morgan\nKaufmann Publishers Inc., 1991, pp. 452\u2013457. isbn: 1-55860-160-\n0. url: http://dl.acm.org/citation.cfm?id=1631171.\n1631239.\n[Bj\u00f6+12] Anders Bj\u00f6rkelund et al. \u201cKnowledge for Intelligent Industrial\nRobots.\u201d In: AAAI Spring Symposium: Designing Intelligent Robots.\n2012.\n[BPM18] Lucian Bu\u015foniu, El\u0151d P\u00e1ll, and R\u00e9mi Munos. \u201cContinuous-action\nplanning for discounted infinite-horizon nonlinear optimal control\nwith Lipschitz values\u201d. In: Automatica 92 (2018), pp. 100\u2013108.\n[BR15] J Backhaus and G Reinhart. \u201cAdaptive and Device Independent\nPlanning Module for Task-Oriented Programming of Assembly\nSystems\u201d. In: Procedia CIRP 33 (2015), pp. 545\u2013550.\n[Bri03] Douglas Brinkley. Wheels for the world: Henry Ford, his company,\nand a century of progress, 1903-2003. Viking Press, 2003.\n[Bro+12] Cameron B Browne et al. \u201cA survey of monte carlo tree search\nmethods\u201d. In: IEEE Transactions on Computational Intelligence\nand AI in Games 4.1 (2012), pp. 1\u201343.\n[Bro+84] Jim Browne et al. \u201cClassification of flexible manufacturing sys-\ntems\u201d. In: The FMS magazine 2.2 (1984), pp. 114\u2013117.\n[BS88] MIRYAM BARAD and Daniel Sipper. \u201cFlexibility in manufactur-\ning systems: definitions and Petri net modelling\u201d. In: International\nJournal of Production Research 26.2 (1988), pp. 237\u2013248.\n[BUR14] Julian Backhaus, Marco Ulrich, and Gunther Reinhart. \u201cClassifi-\ncation, Modelling and Mapping of Skills in Automated Production\nSystems\u201d. In: Enabling Manufacturing Competitiveness and Eco-\nnomic Sustainability. Springer, 2014, pp. 85\u201389.\n150 Bibliography\n[Bus+13] Lucian Busoniu et al. \u201cOptimistic planning for continuous-action\ndeterministic systems\u201d. In: Adaptive Dynamic Programming And\nReinforcement Learning (ADPRL), 2013 IEEE Symposium on.\nIEEE. 2013, pp. 69\u201376.\n[BV04] Stephen Boyd and Lieven Vandenberghe. Convex optimization.\nCambridge university press, 2004.\n[BW05] Dimitris Bertsimas and Robert Weismantel. Optimization over\nintegers. Dynamic Ideas, Belmont, 2005.\n[BZI00] Daniel S Bernstein, Shlomo Zilberstein, and Neil Immerman. \u201cThe\ncomplexity of decentralized control of Markov decision processes\u201d.\nIn: Proceedings of the Sixteenth conference on Uncertainty in\nartificial intelligence. Morgan Kaufmann Publishers Inc. 2000,\npp. 32\u201337.\n[C\u00e2n+11] Gon\u00e7alo C\u00e2ndido et al. \u201cService-oriented infrastructure to support\nthe deployment of evolvable production systems\u201d. In: Industrial\nInformatics, IEEE Transactions on 7.4 (2011), pp. 759\u2013767.\n[Car84] Nancy Cartwright. How the laws of physics lie. Oxford University\nPress, 1984.\n[CF69] Pierre Cartier and Dominique Foata. Problemes combinatoires\nde commutation et r\u00e9arrangements. Vol. 85. Lecture Notes in\nMathematics. Springer, 1969.\n[Cha+08] Guillaume Chaslot et al. \u201cMonte-Carlo Tree Search: A New\nFramework for Game AI.\u201d In: Proceedings of the Fourth Artificial\nIntelligence and Interactive Digital Entertainment Conference.\n2008.\n[Chr00] Martin Christopher. \u201cThe agile supply chain: competing in volatile\nmarkets\u201d. In: Industrial marketing management 29.1 (2000),\npp. 37\u201344.\n[CM15] Felipe Caro and Victor Mart\u00ednez-de-Alb\u00e9niz. \u201cFast fashion: busi-\nness model overview and research opportunities\u201d. In: Retail Supply\nChain Management. Springer, 2015, pp. 237\u2013264.\nBibliography 151\n[Coa37] Ronald H Coase. \u201cThe nature of the firm\u201d. In: Economica 4.16\n(1937), pp. 386\u2013405.\n[Com93] International Electrotechnical Commission. IEC 61131-3: Pro-\ngrammable Controllers. Tech. rep. 1993.\n[Cow+99] Robert G Cowell et al. \u201cProbabilistic Networks and Expert Sys-\ntems\u201d. In: (1999).\n[Dan66] Sven Dan\u00f8. Industrial production models: A theoretical study.\nSpringer, 1966.\n[Das+18] Abhishek Das et al. \u201cJoining technologies for automotive battery\nsystems manufacturing\u201d. In: World Electric Vehicle Journal 9.2\n(2018), p. 22.\n[De +08] Luciana Moreira S\u00e1 De Souza et al. \u201cSocrades: A web service\nbased shop floor integration infrastructure\u201d. In: The internet of\nthings. Springer, 2008, pp. 50\u201367.\n[De 70] Morris H De Groot. \u201cOptimal statistical decisions\u201d. In: (1970).\n[Dep+16] Torben Deppe et al. \u201cBidirektionale Kommunikation mit OPC\nUnified Architecture\u201d. In: Kommunikation in der Automation -\nKommA 2016. Lemgo, Germany, Nov. 2016.\n[DF04] David S Dummit and Richard M Foote. Abstract Algebra. John\nWiley and Sons, 2004.\n[Dim15] Todor Dimitrov. \u201cPermanente Optimierung dynamischer Probleme\nder Fertigungssteuerung unter Einbeziehung von Benutzerinterak-\ntionen\u201d. PhD thesis. Karlsruhe Institute of Technology, 2015.\n[DIN18] DIN. DIN SPEC 16593-1: RM-SA - Reference Model for Industrie\n4.0 Service Architectures - Part 1: Basic Concepts of an Interaction-\nbased Architecture. Tech. rep. 2018.\n[DIN8580] DIN8580: Manufacturing processes - Terms and definitions, divi-\nsion. Standard. Deutsches Institut f\u00fcr Normung, 2003.\n[DM97a] Volker Diekert and Yves M\u00e9tivier. \u201cPartial commutation and\ntraces\u201d. In: Handbook of formal languages 3 (1997), pp. 457\u2013533.\n152 Bibliography\n[DM97b] Donald Dragomatz and Stephen Mann. \u201cA classified bibliography\nof literature on NC milling path generation\u201d. In: Computer-Aided\nDesign 29.3 (1997), pp. 239\u2013247.\n[Dor+17] Kirill Dorofeev et al. \u201cDevice adapter concept towards enabling\nplug&produce production environments\u201d. In: Emerging Technolo-\ngies and Factory Automation (ETFA), 2017 22nd IEEE Interna-\ntional Conference on. IEEE. 2017, pp. 1\u20138.\n[DP87] Neil A Duffie and Rex S Piper. \u201cNon-hierarchical control of a\nflexible manufacturing cell\u201d. In: Robotics and computer-integrated\nmanufacturing 3.2 (1987), pp. 175\u2013179.\n[DT98] Alberto De Toni and Stefano Tonchia. \u201cManufacturing flexibility: a\nliterature review\u201d. In: International journal of production research\n36.6 (1998), pp. 1587\u20131617.\n[D\u00fcr+12] Lars D\u00fcrkop et al. \u201cTowards autoconfiguration of industrial au-\ntomation systems: A case study using Profinet IO\u201d. In: Emerging\nTechnologies & Factory Automation (ETFA), 2012 IEEE 17th\nConference on. IEEE. 2012, pp. 1\u20138.\n[D\u00fcr+14] Lars D\u00fcrkop et al. \u201cA field level architecture for reconfigurable real-\ntime automation systems\u201d. In: Factory Communication Systems\n(WFCS), 2014 10th IEEE Workshop on. IEEE. 2014, pp. 1\u201310.\n[DW91] Thomas L Dean and Michael P Wellman. Planning and control.\nMorgan Kaufmann Publishers Inc., 1991.\n[Dyc03] Harald Dyckhoff. \u201cNeukonzeption der Produktionstheorie\u201d. In:\nZeitschrift f\u00fcr Betriebswirtschaft 73.7 (2003), pp. 705\u2013732.\n[Dyc06] Harald Dyckhoff. Produktionstheorie: Grundz\u00fcge industrieller\nProduktionswirtschaft. Springer-Verlag, 2006.\n[ElM93] Hoda A ElMaraghy. \u201cEvolution and future perspectives of CAPP\u201d.\nIn: CIRP Annals-Manufacturing Technology 42.2 (1993), pp. 739\u2013\n751.\n[F\u00e4r88] Rolf F\u00e4re. Fundamentals of production theory. Springer, 1988.\nBibliography 153\n[FB10] Christian Frese and J\u00fcrgen Beyerer. \u201cPlanning cooperative motions\nof cognitive automobiles using tree search algorithms\u201d. In: Annual\nConference on Artificial Intelligence. Springer. 2010, pp. 91\u201398.\n[FD16] Pascal Faure and Philippe Darmayan. \u201cLe plan fran\u00e7ais \u00abIndustrie\ndu futur\u00bb\u201d. In: Annales des Mines-R\u00e9alit\u00e9s industrielles. 4. FFE.\n2016, pp. 57\u201360.\n[FFW07] Victor Fung, William Fung, and Yoram Jerry Wind. Competing in\na flat world: building enterprises for a borderless world. Wharton\nSchool Publishing, 2007.\n[Fis99] Klaus Fisher. \u201cAgent-based design of holonic manufacturing\nsystems\u201d. In: Robotics and autonomous Systems 27.1-2 (1999),\npp. 3\u201313.\n[Foe+16] Jakob Foerster et al. \u201cLearning to communicate with deep multi-\nagent reinforcement learning\u201d. In: Advances in Neural Information\nProcessing Systems. 2016, pp. 2137\u20132145.\n[FRD98] Holger Friedrich, Oliver Rogalla, and R\u00fcdiger Dillmann. \u201cInte-\ngrating skills into multi-agent systems\u201d. In: Journal of Intelligent\nManufacturing 9.2 (1998), pp. 119\u2013127.\n[FT63] H. Fisher and G.L. Thompson. \u201cProbabilistic learning combina-\ntions of local job-shop scheduling rules\u201d. In: Industrial Scheduling.\nEd. by J.F. Muth and G.L. Thompson. Prentice Hall, 1963, pp. 225\u2013\n251.\n[Fuj98] Richard M Fujimoto. \u201cTime management in the high level archi-\ntecture\u201d. In: Simulation 71.6 (1998), pp. 388\u2013400.\n[Fur18] Kai Furmans. Material Handling and Production Systems Modelling-\nBased on Queuing Models. Springer, 2018.\n[FYK92] Katsuhisa Furuta, M Yamakita, and S Kobayashi. \u201cSwing-up\ncontrol of inverted pendulum using pseudo-state feedback\u201d. In:\nProceedings of the Institution of Mechanical Engineers, Part I:\nJournal of Systems and Control Engineering 206.4 (1992), pp. 263\u2013\n269.\n154 Bibliography\n[Gar18] Gartner. Market Share Analysis: ERP Software, Worldwide, 2017.\nTech. rep. 2018. url: https://www.gartner.com/doc/\n3879510/market-share-analysis-erp-software.\n[Ger93] Donald Gerwin. \u201cManufacturing flexibility: a strategic perspec-\ntive\u201d. In: Management science 39.4 (1993), pp. 395\u2013410.\n[Ger99] Gary Gereffi. \u201cInternational trade and industrial upgrading in the\napparel commodity chain\u201d. In: Journal of international economics\n48.1 (1999), pp. 37\u201370.\n[GF08] Harald Glei\u00dfner and J Christian Femerling. IT in der Logistik.\nSpringer, 2008.\n[GFB94] Vijaykumar Gullapalli, Judy A Franklin, and Hamid Benbrahim.\n\u201cAcquiring robot skills via reinforcement learning\u201d. In: IEEE\nControl Systems 14.1 (1994), pp. 13\u201324.\n[GG89] Yash P Gupta and Sameer Goyal. \u201cFlexibility of manufacturing\nsystems: concepts and measurements\u201d. In: European journal of\noperational research 43.2 (1989), pp. 119\u2013135.\n[Gie04] Ronald N Giere. \u201cHow models are used to represent reality\u201d. In:\nPhilosophy of science 71.5 (2004), pp. 742\u2013752.\n[GJS76] Michael R Garey, David S Johnson, and Ravi Sethi. \u201cThe com-\nplexity of flowshop and jobshop scheduling\u201d. In: Mathematics of\noperations research 1.2 (1976), pp. 117\u2013129.\n[GLK98] Ling Gou, Peter B Luh, and Yuji Kyoya. \u201cHolonic manufacturing\nscheduling: architecture, cooperation mechanism, and implemen-\ntation\u201d. In: Computers in Industry 37.3 (1998), pp. 213\u2013231.\n[Gol99] Jonathan S Golan. Semirings and their applications. Kluwer\nAcademic Publishers, 1999.\n[GPP15] Sten Gr\u00fcner, Julius Pfrommer, and Florian Palm. \u201cA RESTful\nextension of OPC UA\u201d. In: Factory Communication Systems\n(WFCS), 2015 IEEE World Conference on. IEEE, 2015, pp. 1\u20134.\n[GPP16] Sten Gr\u00fcner, Julius Pfrommer, and Florian Palm. \u201cRESTful Indus-\ntrial Communication With OPC UA\u201d. In: IEEE Transactions on\nIndustrial Informatics 12.5 (2016), pp. 1832\u20131841.\nBibliography 155\n[Gro05] Ignacio Grossmann. \u201cEnterprise-wide optimization: A new frontier\nin process systems engineering\u201d. In: AIChE Journal 51.7 (2005),\npp. 1846\u20131857.\n[Gro08] Donald Gross. Fundamentals of queueing theory. John Wiley &\nSons, 2008.\n[GT60] Bernard Giffler and Gerald Luther Thompson. \u201cAlgorithms for\nsolving production-scheduling problems\u201d. In: Operations research\n8.4 (1960), pp. 487\u2013503.\n[Gur16] Gurobi Optimization, Inc. Gurobi Optimizer Reference Manual.\n2016. url: http://www.gurobi.com.\n[GVM16] Jean-Bastien Grill, Michal Valko, and R\u00e9mi Munos. \u201cBlazing\nthe trails before beating the path: Sample-efficient Monte-Carlo\nplanning\u201d. In: Advances in Neural Information Processing Systems.\n2016, pp. 4680\u20134688.\n[HC12] Jacob Huckaby and Henrik I Christensen. \u201cA taxonomic frame-\nwork for task modeling and knowledge transfer in manufacturing\nrobotics\u201d. In: Workshops at 26th AAAI Conference on Artificial\nIntelligence. 2012.\n[Hem66] J Hemelrijk. \u201cUnderlining random variables\u201d. In: Statistica Neer-\nlandica 20.1 (1966), pp. 1\u20137.\n[HL05] Willy Herroelen and Roel Leus. \u201cProject scheduling under uncer-\ntainty: Survey and research potentials\u201d. In: European journal of\noperational research 165.2 (2005), pp. 289\u2013306.\n[Hou85] David Hounshell. From the American system to mass production,\n1800-1932: The development of manufacturing technology in the\nUnited States. 4. JHU Press, 1985.\n[HU79] John E Hopcroft and Jeffrey D Ullman. Introduction to Automata\nTheory, Languages and Computation. Addison-Wesley, 1979.\n[ISO82] ISO. ISO 6983-1: Automation systems and integration \u2013 Numerical\ncontrol of machines \u2013 Program format and definitions of address\nwords \u2013 Part 1: Data format for positioning, line motion and\ncontouring control systems. 1982.\n156 Bibliography\n[Jac+07] F Robert Jacobs et al. \u201cEnterprise resource planning (ERP)\u2014A\nbrief history\u201d. In: Journal of Operations Management 25.2 (2007),\npp. 357\u2013363.\n[Jar+11] E Jarvenpaa et al. \u201cPresenting capabilities of resources and re-\nsource combinations to support production system adaptation\u201d. In:\nAssembly and Manufacturing (ISAM), 2011 IEEE International\nSymposium on. IEEE. 2011, pp. 1\u20136.\n[J\u00e4r+18] Eeva J\u00e4rvenp\u00e4\u00e4 et al. \u201cUtilizing SPIN rules to infer the parameters\nfor combined capabilities of aggregated manufacturing resources\u201d.\nIn: IFAC-PapersOnLine 51.11 (2018), pp. 84\u201389.\n[Jay03] Edwin T Jaynes. Probability theory: The logic of science. Cam-\nbridge university press, 2003.\n[Jel06] Mohieddine Jelali. \u201cAn overview of control performance assess-\nment technology and industrial applications\u201d. In: Control engi-\nneering practice 14.5 (2006), pp. 441\u2013466.\n[JM98] Anant Singh Jain and Sheik Meeran. A state-of-the-art review of\njob-shop scheduling techniques. Tech. rep. Department of Applied\nPhysics, Electronic and Mechanical Engineering, University of\nDundee, Dundee, Scotland, 1998.\n[Joh87] David G Johnson. Programmable controllers for factory automa-\ntion. Marcel Dekker, Inc., 1987.\n[JPS93] Donald R Jones, Cary D Perttunen, and Bruce E Stuckman. \u201cLips-\nchitzian optimization without the Lipschitz constant\u201d. In: Journal\nof Optimization Theory and Applications 79.1 (1993), pp. 157\u2013\n181.\n[JS05] Fran\u00e7ois Jammes and Harm Smit. \u201cService-oriented paradigms in\nindustrial automation\u201d. In: Industrial Informatics, IEEE Transac-\ntions on 1.1 (2005), pp. 62\u201370.\n[Jun+17] Jieun Jung et al. \u201cDesign of smart factory web services based\non the industrial internet of things\u201d. In: Proceedings of the 50th\nHawaii International Conference on System Sciences. 2017.\nBibliography 157\n[KBT17] Ilya Kovalenko, Kira Barton, and Dawn Tilbury. \u201cDesign and\nimplementation of an intelligent product agent architecture in\nmanufacturing systems\u201d. In: Emerging Technologies & Factory\nAutomation (ETFA). IEEE, 2017, pp. 1\u20138.\n[Ken15] Scott Kennedy. \u201cMade in China 2025\u201d. In: Center for Strategic\nand International Studies (2015).\n[KF09] Daphne Koller and Nir Friedman. Probabilistic graphical models:\nprinciples and techniques. MIT press, 2009.\n[KFL01] Frank R Kschischang, Brendan J Frey, and H-A Loeliger. \u201cFactor\ngraphs and the sum-product algorithm\u201d. In: Information Theory,\nIEEE Transactions on 47.2 (2001), pp. 498\u2013519.\n[KHL08] Hanna Kurniawati, David Hsu, and Wee Sun Lee. \u201cSARSOP:\nEfficient Point-Based POMDP Planning by Approximating Opti-\nmally Reachable Belief Spaces.\u201d In: Robotics: Science and systems.\nVol. 2008. 2008.\n[Kir95] Dimitris Kiritsis. \u201cA review of knowledge-based expert systems for\nprocess planning. Methods and problems\u201d. In: The International\nJournal of Advanced Manufacturing Technology 10.4 (1995),\npp. 240\u2013262.\n[KKS14] Yevgeny Kazakov, Markus Kr\u00f6tzsch, and Franti\u0161ek Siman\u010d\u0131k.\n\u201cThe incredible ELK\u201d. In: Journal of automated reasoning 53.1\n(2014), pp. 1\u201361.\n[KKZ14] Nadine Keddis, Gerd Kainz, and Alois Zoitl. \u201cCapability-based\nplanning and scheduling for adaptable manufacturing systems\u201d.\nIn: Emerging Technology and Factory Automation (ETFA), 2014\nIEEE. IEEE. 2014, pp. 1\u20138.\n[KLC98] Leslie Pack Kaelbling, Michael L Littman, and Anthony R Cas-\nsandra. \u201cPlanning and acting in partially observable stochastic\ndomains\u201d. In: Artificial intelligence 101.1 (1998), pp. 99\u2013134.\n[Klu11] Stefan Kluge. \u201cMethodik zur f\u00e4higkeitsbasierten Planung modu-\nlarer Montagesysteme\u201d. PhD thesis. Universit\u00e4t Stuttgart, 2011.\n158 Bibliography\n[KMN02] Michael Kearns, Yishay Mansour, and Andrew Y Ng. \u201cA sparse\nsampling algorithm for near-optimal planning in large Markov\ndecision processes\u201d. In: Machine learning 49.2-3 (2002), pp. 193\u2013\n208.\n[Koe68] Arthur Koestler. \u201cThe ghost in the machine.\u201d In: (1968).\n[KS06] Levente Kocsis and Csaba Szepesv\u00e1ri. \u201cBandit based monte-carlo\nplanning\u201d. In: European conference on machine learning. Springer.\n2006, pp. 282\u2013293.\n[Kuh62] Thomas S Kuhn. The structure of scientific revolutions. University\nof Chicago Press, 1962.\n[KV05] Jelle R Kok and Nikos Vlassis. \u201cUsing the max-plus algorithm\nfor multiagent decision making in coordination graphs\u201d. In: Robot\nSoccer World Cup. Springer. 2005, pp. 1\u201312.\n[KWH13] H Kagermann, W Wahlster, and J Helbig. \u201cUmsetzungsempfehlun-\ngen f\u00fcr das Zukunftsprojekt Industrie 4.0\u2013Abschlussbericht des\nArbeitskreises Industrie 4.0\u201d. In: Forschungsunion im Stifterver-\nband f\u00fcr die Deutsche Wissenschaft. Berlin (2013).\n[Lam78] Leslie Lamport. \u201cTime, clocks, and the ordering of events in a\ndistributed system\u201d. In: Communications of the ACM 21.7 (1978),\npp. 558\u2013565.\n[LaV06] Steven M LaValle. Planning algorithms. Cambridge university\npress, 2006.\n[Lei09] Paulo Leit\u00e3o. \u201cAgent-based distributed manufacturing control: A\nstate-of-the-art survey\u201d. In: Engineering Applications of Artificial\nIntelligence 22.7 (2009), pp. 979\u2013991.\n[Lep+11] Wilfried Lepuschitz et al. \u201cToward self-reconfiguration of manu-\nfacturing systems using automation agents\u201d. In: Systems, Man, and\nCybernetics, Part C: Applications and Reviews, IEEE Transactions\non 41.1 (2011), pp. 52\u201369.\n[Lib11] Daniel Liberzon. Calculus of variations and optimal control theory:\na concise introduction. Princeton University Press, 2011.\nBibliography 159\n[Lim15] Li&Fung Limited. Li&Fung Annual Report 2015. 2015. url:\nhttps://www.lifung.com/investors/financial-reports-\npresentations/2015/.\n[Lit+63] John DC Little et al. \u201cAn algorithm for the traveling salesman\nproblem\u201d. In: Operations research 11.6 (1963), pp. 972\u2013989.\n[LK08] J-H Lee and C-O Kim. \u201cMulti-agent systems applications in\nmanufacturing systems and supply chain management: a review\npaper\u201d. In: International Journal of Production Research 46.1\n(2008), pp. 233\u2013265.\n[LK15] Paulo Leit\u00e3o and Stamatis Karnouskos. Industrial Agents: Emerg-\ning Applications of Software Agents in Industry. Morgan Kaufmann,\n2015.\n[LKK16] David Lenz, Tobias Kessler, and Alois Knoll. \u201cTactical cooperative\nplanning for autonomous highway driving using Monte-Carlo Tree\nSearch\u201d. In: Intelligent Vehicles Symposium (IV), 2016 IEEE. IEEE.\n2016, pp. 447\u2013453.\n[LL94] Tim C Lueth and Thomas Laengle. \u201cTask description, decom-\nposition, and allocation in a distributed autonomous multi-agent\nrobot system\u201d. In: Intelligent Robots and Systems\u2019 94.\u2019Advanced\nRobotic Systems and the Real World\u2019, IROS\u201994. Proceedings of the\nIEEE/RSJ/GI International Conference on. Vol. 3. IEEE. 1994,\npp. 1516\u20131523.\n[LMV13] Paulo Leit\u00e3o, Vladim\u00edr Ma\u0159\u00edk, and Pavel Vrba. \u201cPast, present, and\nfuture of industrial agent applications\u201d. In: IEEE Transactions on\nIndustrial Informatics 9.4 (2013), pp. 2360\u20132372.\n[Los+11] Matthias Loskyll et al. \u201cSemantic service discovery and orchestra-\ntion for manufacturing processes\u201d. In: Emerging Technologies &\nFactory Automation (ETFA). IEEE. 2011, pp. 1\u20138.\n[Los+12] Matthias Loskyll et al. \u201cContext-based orchestration for control of\nresource-efficient manufacturing processes\u201d. In: Future Internet\n4.3 (2012), pp. 737\u2013761.\n160 Bibliography\n[LP12] Gisela Lanza and Steven Peters. \u201cIntegrated capacity planning\nover highly volatile horizons\u201d. In: CIRP Annals-Manufacturing\nTechnology 61.1 (2012), pp. 395\u2013398.\n[LPW97] Hau L Lee, Venkata Padmanabhan, and Seungjin Whang. \u201cIn-\nformation distortion in a supply chain: The bullwhip effect\u201d. In:\nManagement science 43.4 (1997), pp. 546\u2013558.\n[LS92] Grace Yuh-jiun Lin and James J Solberg. \u201cIntegrated shop floor\ncontrol using autonomous agents\u201d. In: IIE transactions 24.3 (1992),\npp. 57\u201371.\n[LSV14] Christoph Legat, Daniel Sch\u00fctz, and Birgit Vogel-Heuser. \u201cAu-\ntomatic generation of field control strategies for supporting (re-)\nengineering of manufacturing systems\u201d. In: Journal of Intelligent\nManufacturing 25.5 (2014), pp. 1101\u20131111.\n[Lue69] David G Luenberger. Optimization by vector space methods. John\nWiley & Sons, 1969.\n[LV15] Christoph Legat and Birgit Vogel-Heuser. \u201cAn Orchestration\nEngine for Services-Oriented Field Level Automation Software\u201d.\nIn: Service Orientation in Holonic and Multi-agent Manufacturing.\nEd. by Theodor Borangiu, Andr\u00e9 Thomas, and Damien Trentesaux.\nVol. 594. Springer International Publishing, 2015, pp. 71\u201380.\n[Mac+06] C Matthew MacKenzie et al. OASIS Reference model for service\noriented architecture 1.0. Tech. rep. 2006.\n[Mac02] Jan Marian Maciejowski. Predictive control: with constraints.\nPearson education, 2002.\n[Mal+07] J. Malec et al. \u201cKnowledge-Based Reconfiguration of Automation\nSystems\u201d. In: Automation Science and Engineering, 2007. CASE\n2007. IEEE International Conference on. 2007, pp. 170\u2013175.\n[Mal+18] Somayeh Malakuti et al. \u201cChallenges in Skill-based Engineering of\nIndustrial Automation Systems\u201d. In: 2018 IEEE 23rd International\nConference on Emerging Technologies and Factory Automation\n(ETFA). Vol. 1. IEEE. 2018, pp. 67\u201374.\nBibliography 161\n[Maz77] Antoni Mazurkiewicz. \u201cConcurrent program schemes and their\ninterpretations\u201d. In: DAIMI Report Series 6.78 (1977).\n[MB00] Duncan C McFarlane and Stefan Bussmann. \u201cDevelopments in\nholonic production planning and control\u201d. In: Production Planning\n& Control 11.6 (2000), pp. 522\u2013536.\n[Mes13] VDI/VDE - Gesellschaft f\u00fcr Mess und Automatisierungstechnik\n(GMA). Cyber-Physical Systems: Chancen und Nutzen aus Sicht\nder Automation. Tech. rep. 2013.\n[MF70] Burton G Malkiel and Eugene F Fama. \u201cEfficient capital markets:\nA review of theory and empirical work\u201d. In: The journal of Finance\n25.2 (1970), pp. 383\u2013417.\n[Mit+05] S Mitsi et al. \u201cOff-line programming of an industrial robot for\nmanufacturing\u201d. In: The International Journal of Advanced Man-\nufacturing Technology 26.3 (2005), pp. 262\u2013267.\n[MK97] J Daniel Morrow and Pradeep K Khosla. \u201cManipulation task\nprimitives for composing robot skills\u201d. In: Robotics and Automa-\ntion, 1997. Proceedings., 1997 IEEE International Conference on.\nVol. 4. IEEE. 1997, pp. 3354\u20133359.\n[ML99] Manfred Morari and Jay H Lee. \u201cModel predictive control: past,\npresent and future\u201d. In: Computers & Chemical Engineering 23.4\n(1999), pp. 667\u2013682.\n[MLD09] Wolfgang Mahnke, Stefan-Helmut Leitner, and Matthias Damm.\nOPC Unified Architecture. Springer, 2009.\n[Mon14] L\u00e1szl\u00f3 Monostori. \u201cCyber-physical production systems: Roots,\nexpectations and R&D challenges\u201d. In: Procedia Cirp 17 (2014),\npp. 9\u201313.\n[MOW01] Swee M Mok, Kenlip Ong, and Chi-haur Wu. \u201cAutomatic gen-\neration of assembly instructions using STEP\u201d. In: Robotics and\nAutomation, 2001. Proceedings 2001 ICRA. IEEE International\nConference on. Vol. 1. IEEE. 2001, pp. 313\u2013318.\n162 Bibliography\n[Mun+14] R\u00e9mi Munos et al. \u201cFrom Bandits to Monte-Carlo Tree Search:\nThe Optimistic Principle Applied to Optimization and Planning\u201d.\nIn: Foundations and Trends in Machine Learning 7.1 (2014),\npp. 1\u2013129.\n[Mun11] R\u00e9mi Munos. \u201cOptimistic optimization of a deterministic function\nwithout the knowledge of its smoothness\u201d. In: Advances in neural\ninformation processing systems. 2011, pp. 783\u2013791.\n[MVK06] L\u00e1szl\u00f3 Monostori, J\u00f3zsef V\u00e1ncza, and Soundar RT Kumara.\n\u201cAgent-based systems for manufacturing\u201d. In: CIRP Annals-\nManufacturing Technology 55.2 (2006), pp. 697\u2013720.\n[MW59] Born Max and Emil Wolf. Principles of optics. Pergamon Press,\n1959.\n[MWL11] Christopher R Mansley, Ari Weinstein, and Michael L Littman.\n\u201cSample-Based Planning for Continuous Action Markov Decision\nProcesses.\u201d In: ICAPS. 2011.\n[Nas51] John Nash. \u201cNon-cooperative games\u201d. In: Annals of mathematics\n(1951), pp. 286\u2013295.\n[Neu55] John von Neumann. The impact of recent developments in science\non the economy and on economics. Speech to the National Plan-\nning Association, Washington D.C., reprinted in Collected Works\n(Pergamon Press, 1963). 1955.\n[NHR99] Andrew Y Ng, Daishi Harada, and Stuart Russell. \u201cPolicy invari-\nance under reward transformations: Theory and application to\nreward shaping\u201d. In: ICML. Vol. 99. 1999, pp. 278\u2013287.\n[NW10] Peter Nyhuis and Hans-Peter Wiendahl. \u201cAnsatz zu einer Theorie\nder Produktionstechnik\u201d. In: ZWF Zeitschrift f\u00fcr wirtschaftlichen\nFabrikbetrieb 105.1-2 (2010), pp. 15\u201320.\n[NWS07] Martin Naumann, Kai Wegener, and Rolf Dieter Schraft. \u201cControl\narchitecture for robot cells to enable Plug\u2019n\u2019Produce\u201d. In: Robotics\nand Automation, 2007 IEEE International Conference on. IEEE.\n2007, pp. 287\u2013292.\nBibliography 163\n[OHN14] Jens Otto, Steffen Henning, and Oliver Niggemann. \u201cWhy cyber-\nphysical production systems need a descriptive engineering\napproach\u2013a case study in plug & produce\u201d. In: Procedia Technol-\nogy 15 (2014), pp. 295\u2013302.\n[Ohn88] Taiichi Ohno. Toyota production system: beyond large-scale pro-\nduction. CRC Press, 1988.\n[ON15] Jens Otto and Oliver Niggemann. \u201cAutomatic Parameterization\nof Automation Software for Plug-and-Produce\u201d. In: The AAAI-15\nWorkshop on Algorithm Configuration (AlgoConf 2015), Austin,\nTexas (2015).\n[Ono+12] Mauro Onori et al. \u201cThe IDEAS project: plug & produce at shop-\nfloor level\u201d. In: Assembly automation 32.2 (2012), pp. 124\u2013134.\n[Oue+99] Djamila Ouelhadj et al. \u201cA multi-contract net protocol for dynamic\nscheduling in flexible manufacturing systems (FMS)\u201d. In: Robotics\nand Automation, 1999. Proceedings. 1999 IEEE International\nConference on. Vol. 2. IEEE. 1999, pp. 1114\u20131119.\n[Pal+14] Florian Palm et al. \u201copen62541 - der offene OPC UA-Stack\u201d. In:\nLemgo, Nov. 2014.\n[Par87] H Van Dyke Parunak. \u201cManufacturing experience with the contract\nnet\u201d. In: Distributed Artificial Intelligence, Volume I. Elsevier,\n1987, pp. 285\u2013310.\n[Pea84] Judea Pearl. \u201cHeuristics: intelligent search strategies for computer\nproblem solving\u201d. In: (1984).\n[Pea88] Judea Pearl. Probabilistic Reasoning in Intelligent Systems: Net-\nworks of Plausible Inference. Morgan Kaufmann Publishers Inc.,\n1988.\n[Pfr+14a] Julius Pfrommer et al. \u201cBegrifflichkeiten um Industrie 4.0 \u2013 Ord-\nnung im Sprachwirrwarr\u201d. In: Tagungsband zu Entwurf komplexer\nAutomatisierungssysteme (EKA) 2014. Ed. by Ulrich Jumar and\nChristian Diedrich. Magdeburg, May 2014.\n164 Bibliography\n[Pfr+14b] Julius Pfrommer et al. \u201cDynamic vehicle redistribution and online\nprice incentives in shared mobility systems\u201d. In: IEEE Transactions\non Intelligent Transportation Systems 15.4 (2014), pp. 1567\u20131578.\n[Pfr+14c] Julius Pfrommer et al. \u201cModelling and Orchestration of Service-\nBased Manufacturing Systems via Skills\u201d. In: Emerging Technolo-\ngies & Factory Automation (ETFA), 2014 IEEE 19th Conference\non. Barcelona, Spain, Sept. 2014.\n[Pfr+15a] Julius Pfrommer et al. \u201cPlug & Produce by Modelling Skills and\nService-Oriented Orchestration of Reconfigurable Manufacturing\nSystems\u201d. In: at Automatisierungstechnik 10.63 (2015).\n[Pfr+15b] Julius Pfrommer et al. \u201cPlug & produce by modelling skills and\nservice-oriented orchestration of reconfigurable manufacturing\nsystems\u201d. In: at-Automatisierungstechnik 63.10 (2015), pp. 790\u2013\n800.\n[Pfr+16a] Julius Pfrommer et al. \u201cA common core for information modeling\nin the Industrial Internet of Things\u201d. In: at-Automatisierungstechnik\n64.9 (2016), pp. 729\u2013741.\n[Pfr+16b] Julius Pfrommer et al. \u201cDeploying software functionality to manu-\nfacturing resources safely at runtime\u201d. In: Emerging Technologies\nand Factory Automation (ETFA), 2016 IEEE 21st International\nConference on. Berlin, Germany: IEEE, Sept. 2016, pp. 1\u20137.\n[Pfr+18] Julius Pfrommer et al. \u201cOptimisation of manufacturing process\nparameters using deep neural networks as surrogate models\u201d.\nIn: Proceedings of the 51st CIRP Conference on Manufacturing\nSystems. Stockholm: CIRP, 2018.\n[Pfr14] Julius Pfrommer. Information and Control in Cyber-Physical\nProduction Systems. Tech. rep. 2014, pp. 61\u201374.\n[Pfr15] Julius Pfrommer. Distributed Constraint Optimization over Con-\nstrained Communication Topologies. Tech. rep. 2015, pp. 77\u2013\n87.\nBibliography 165\n[Pfr16a] Julius Pfrommer. \u201cGraphical Partially Observable Monte-Carlo\nPlanning\u201d. In: Workshop on Learning, Inference and Control of\nMulti-Agent Systems, Conference on Neural Information Process-\ning Systems (NIPS). Dec. 2016.\n[Pfr16b] Julius Pfrommer. \u201cSemantic Interoperability at Big-Data Scale with\nthe open62541 OPC UA Implementation\u201d. In: 2nd International\nWorkshop on Interoperability and Open-Source Solutions for the\nInternet of Things (InterOSS-IoT). Stuttgart, Germany, Nov. 2016.\n[Pfr16c] Julius Pfrommer. Towards Graphical Partially Observable Monte-\nCarlo Planning. Tech. rep. 2016, pp. 113\u2013125.\n[PGP16] Julius Pfrommer, Sten Gr\u00fcner, and Florian Palm. \u201cHybrid OPC\nUA and DDS: Combining architectural styles for the industrial\ninternet\u201d. In: Factory Communication Systems (WFCS), 2016\nIEEE World Conference on. Aveiro, Portugal: IEEE, May 2016,\npp. 1\u20137.\n[Pin08] Michael L Pinedo. \u201cScheduling: Theory, Algorithms, and Systems\u201d.\nIn: (2008).\n[PLM13] Jani Puttonen, Andrei Lobov, and Jose L Martinez Lastra.\n\u201cSemantics-based composition of factory automation processes\nencapsulated by web services\u201d. In: Industrial Informatics, IEEE\nTransactions on 9.4 (2013), pp. 2349\u20132359.\n[Pow07] Warren B Powell. Approximate Dynamic Programming: Solving\nthe curses of dimensionality. Vol. 703. John Wiley & Sons, 2007.\n[Pro+17] Stefan Profanter et al. \u201cOPC UA for plug & produce: Automatic\ndevice discovery using LDS-ME\u201d. In: Proceedings of the IEEE\nInternational Conference on Emerging Technologies And Factory\nAutomation (ETFA). IEEE. 2017.\n[PSB13a] Julius Pfrommer, Miriam Schleipen, and J\u00fcrgen Beyerer. \u201cF\u00e4higkeiten\nadaptiver Produktionsanlagen\u201d. In: atp-edition 55 (11) (2013).\n166 Bibliography\n[PSB13b] Julius Pfrommer, Miriam Schleipen, and J\u00fcrgen Beyerer. \u201cPPRS:\nProduction skills and their relation to product, process, and re-\nsource\u201d. In: Proceedings of the 2013 IEEE 18th Conference on\nEmerging Technologies & Factory Automation (ETFA). IEEE.\nCagliari, Italy, 2013.\n[Put94] Martin L Puterman. Markov Decision Processes: Discrete Stochas-\ntic Dynamic Programming. John Wiley & Sons, Inc., 1994.\n[RD05] Paul Renteln and Alan Dundes. \u201cFoolproof: A sampling of mathe-\nmatical folk humor\u201d. In: Notices of the AMS 52.1 (2005), pp. 24\u2013\n34.\n[Rei+10] G Reinhart et al. \u201cAutomatic configuration (plug & produce) of\nindustrial ethernet networks\u201d. In: Industry Applications (INDUS-\nCON), 2010 9th IEEE/IAS International Conference on. IEEE.\n2010, pp. 1\u20136.\n[Rei91] J Francis Reintjes. Numerical control: making a new technology.\nOxford University Press, Inc., 1991.\n[Ros+08] St\u00e9phane Ross et al. \u201cOnline planning algorithms for POMDPs\u201d.\nIn: Journal of Artificial Intelligence Research 32 (2008), pp. 663\u2013\n704.\n[Sal+10] Yves Sallez et al. \u201cThe lifecycle of active and intelligent products:\nThe augmentation concept\u201d. In: International Journal of Computer\nIntegrated Manufacturing 23.10 (2010), pp. 905\u2013924.\n[Sch+11] G\u00fcnther Schuh et al. \u201cDeveloping a production engineering based\ntheory of production\u201d. In: Concurrent Enterprising (ICE), 2011\n17th International Conference on. IEEE. 2011, pp. 1\u20139.\n[Sch+15a] Miriam Schleipen et al. \u201cRequirements and concept for plug-and-\nwork\u201d. In: at-Automatisierungstechnik 63.10 (2015), pp. 801\u2013\n820.\n[Sch+15b] G\u00fcnther Schuh et al. \u201cHypotheses for a Theory of Production in the\nContext of Industrie 4.0\u201d. In: Advances in Production Technology.\nSpringer, 2015, pp. 11\u201323.\nBibliography 167\n[Sch+16] Miriam Schleipen et al. \u201cOPC UA & Industrie 4.0 - enabling\ntechnology with high diversity and variability\u201d. In: 49th CIRP Con-\nference on Manufacturing Systems (CIRP-CMS 2016). Stuttgart,\nGermany: CIRP, May 2016.\n[Sch+17] G\u00fcnther Schuh et al. \u201cTowards a technology-oriented theory of\nproduction\u201d. In: Integrative Production Technology. Springer,\n2017, pp. 1047\u20131079.\n[Sch04] Christoph Schneewei\u00df. \u201cOn the empirical validity of production\ntheory\u201d. In: Central European Journal of Operations Research\n12.2 (2004), p. 107.\n[Sch34] Erich Schneider. Theorie der Produktion. J. Springer, 1934.\n[Sch86] Christoph Schneewei\u00df. Einf\u00fchrung in die Produktionswirtschaft.\nSpringer, 1986.\n[She+07] Weiming Shen et al. \u201cAn agent-based service-oriented integra-\ntion architecture for collaborative intelligent manufacturing\u201d. In:\nRobotics and Computer-Integrated Manufacturing 23.3 (2007),\npp. 315\u2013325.\n[She03] Khalid Sheikh. Manufacturing resource planning (MRP II): with\nintroduction to ERP, SCM and CRM. McGraw-Hill New York,\nNY, 2003.\n[She71] Ronald William Shepherd. Theory of cost and production functions.\nPrinceton University Press, 1971.\n[Sil+16] David Silver et al. \u201cMastering the game of Go with deep neural\nnetworks and tree search\u201d. In: nature 529.7587 (2016), p. 484.\n[Sil+17] David Silver et al. \u201cMastering the game of Go without human\nknowledge\u201d. In: Nature 550.7676 (2017), p. 354.\n[SKB97] Ashraf Saad, Kazuhiko Kawamura, and Gautam Biswas. \u201cPerfor-\nmance evaluation of contract net-based heterarchical scheduling\nfor flexible manufacturing systems\u201d. In: Intelligent Automation &\nSoft Computing 3.3 (1997), pp. 229\u2013247.\n168 Bibliography\n[Sko04] Sigurd Skogestad. \u201cControl structure design for complete chemical\nplants\u201d. In: Computers & Chemical Engineering 28.1 (2004),\npp. 219\u2013234.\n[Smi80] Reid G Smith. \u201cThe contract net protocol: High-level commu-\nnication and control in a distributed problem solver\u201d. In: IEEE\nTransactions on computers 12 (1980), pp. 1104\u20131113.\n[SP97] Rainer Storn and Kenneth Price. \u201cDifferential evolution\u2013a simple\nand efficient heuristic for global optimization over continuous\nspaces\u201d. In: Journal of global optimization 11.4 (1997), pp. 341\u2013\n359.\n[SS73] Richard D Smallwood and Edward J Sondik. \u201cThe optimal control\nof partially observable Markov processes over a finite horizon\u201d.\nIn: Operations research 21.5 (1973), pp. 1071\u20131088.\n[SS90] Andrea Krasa Sethi and Suresh Pal Sethi. \u201cFlexibility in manufac-\nturing: a survey\u201d. In: International journal of flexible manufactur-\ning systems 2.4 (1990), pp. 289\u2013328.\n[Sus73] Gerald J Sussman. \u201cA computational model of skill acquisition\u201d.\nPhD thesis. 1973.\n[SV10] David Silver and Joel Veness. \u201cMonte-Carlo planning in large\nPOMDPs\u201d. In: Advances in neural information processing systems.\n2010, pp. 2164\u20132172.\n[SWH06] Weiming Shen, Lihui Wang, and Qi Hao. \u201cAgent-based distributed\nmanufacturing process planning and scheduling: a state-of-the-art\nsurvey\u201d. In: Systems, Man, and Cybernetics, Part C: Applications\nand Reviews, IEEE Transactions on 36.4 (2006), pp. 563\u2013577.\n[SZW17] Jan-Philipp Schmidt, Andreas Zeller, and Michael Weyrich. \u201cMod-\nellgetriebene Entwicklung serviceorientierter Anlagensteuerun-\ngen\u201d. In: at-Automatisierungstechnik 65.1 (2017), pp. 26\u201336.\n[TB09] Moritz Tenorth and Michael Beetz. \u201cKnowRob: knowledge pro-\ncessing for autonomous personal robots\u201d. In: Intelligent Robots and\nSystems, 2009. IROS 2009. IEEE/RSJ International Conference\non. IEEE. 2009, pp. 4261\u20134266.\nBibliography 169\n[TMP92] HK T\u00f6nshoff, E Menzel, and HS Park. \u201cA knowledge-based\nsystem for automated assembly planning\u201d. In: CIRP Annals-\nManufacturing Technology 41.1 (1992), pp. 19\u201324.\n[UPS14] Thomas Usl\u00e4nder, Julius Pfrommer, and Miriam Schleipen. \u201cDas\nInternet der Dinge in der Automation - Anforderungen und Tech-\nnologien\u201d. In: 5. Jahreskolloquium \"Kommunikation in der Au-\ntomation\" (KommA 2014). Lemgo, 2014.\n[Van+98] Hendrik Van Brussel et al. \u201cReference architecture for holonic\nmanufacturing systems: PROSA\u201d. In: Computers in industry 37.3\n(1998), pp. 255\u2013274.\n[VCM13] Michal Valko, Alexandra Carpentier, and R\u00e9mi Munos. \u201cStochastic\nsimultaneous optimistic optimization\u201d. In: Proceedings of the 30th\nInternational Conference on Machine Learning (ICML-13). 2013,\npp. 19\u201327.\n[VHL03] Guilherme E Vieira, Jeffrey W Herrmann, and Edward Lin.\n\u201cRescheduling manufacturing systems: a framework of strate-\ngies, policies, and methods\u201d. In: Journal of scheduling 6.1 (2003),\npp. 39\u201362.\n[Von52] Kurt Vonnegut. Player Piano. Charles Scribner\u2019s Sons, 1952.\n[VWK05] Birgit Vogel-Heuser, Daniel Witsch, and Uwe Katzke. \u201cAutomatic\ncode generation from a UML model to IEC 61131-3 and system\nconfiguration tools\u201d. In: Control and Automation, 2005. ICCA\u201905.\nInternational Conference on. Vol. 2. IEEE. 2005, pp. 1034\u20131039.\n[Vya11] Valeriy Vyatkin. \u201cIEC 61499 as enabler of distributed and intelli-\ngent automation: State-of-the-art review\u201d. In: IEEE transactions\non Industrial Informatics 7.4 (2011), pp. 768\u2013781.\n[Wai+11] M. Waibel et al. \u201cRoboEarth\u201d. In: IEEE Robotics Automation\nMagazine 18.2 (2011), pp. 69\u201382.\n[Wal12] Mark John Walker. \u201cThe programmable logic controller: its prehis-\ntory, emergence and application\u201d. PhD thesis. The Open University,\n2012.\n170 Bibliography\n[War93] Hans-J\u00fcrgen Warnecke. The Fractal Company\u2014A Revolution in\nCorporate Culture. Springer, 1993.\n[WD51] Marshal K. Wood and George B. Dantzig. \u201cThe programming of\ninterdependent activities: general discussion\u201d. In: Activity analysis\nof production and allocation. Ed. by Tjalling C. Koopmans. John\nWiley & Sons, Inc., 1951.\n[Wel03] Lloyd R Welch. \u201cHidden Markov models and the Baum-Welch\nalgorithm\u201d. In: IEEE Information Theory Society Newsletter 53.4\n(2003), pp. 10\u201313.\n[Wey+14] Michael Weyrich et al. \u201cFlexibilisierung von Automatisierungssys-\ntemen - Systematisierung der Flexibilit\u00e4tsanforderungen von In-\ndustrie 4.0\u201d. In: wt Werkstattstechnik online 104.3 (2014), pp. 106\u2013\n111.\n[Wie+07] H-P Wiendahl et al. \u201cChangeable manufacturing-classification, de-\nsign and operation\u201d. In: CIRP Annals\u2013Manufacturing Technology\n56.2 (2007), pp. 783\u2013809.\n[Wie48] Norbert Wiener. \u201cCybernetics; or control and communication in\nthe animal and the machine\u201d. In: (1948).\n[Wig81] Oliver W Wight. MRP II: Unlocking America\u2019s productivity po-\ntential. Omneo, 1981.\n[WJ+08] Martin J Wainwright, Michael I Jordan, et al. \u201cGraphical models,\nexponential families, and variational inference\u201d. In: Foundations\nand Trends\u00ae in Machine Learning 1.1\u20132 (2008), pp. 1\u2013305.\n[WNH10] H-P Wiendahl, P Nyhuis, and W Hartmann. \u201cShould CIRP develop\na Production Theory? Motivation, Development Path, Framework\u201d.\nIn: 43rd CIRP International Conference on Manufactoring Systems.\nCIRP. 2010.\n[Woo95] Robert Simpson Woodward. \u201cAn Historical Survey of the Science\nof Mechanics\u201d. In: Science 1.6 (1895), pp. 141\u2013157.\n[WS11] Stephan M Wagner and Victor Silveira-Camargos. \u201cDecision\nmodel for the application of just-in-sequence\u201d. In: International\nJournal of Production Research 49.19 (2011), pp. 5713\u20135736.\nBibliography 171\n[WS15] Stephanie Wong and Paula Sailes. \u201cWal-Mart Takes Back Some\nGoods Sourcing From Li & Fung\u201d. In: (2015). url: https://www.\nbloomberg.com/news/articles/2015-05-22/wal-mart-\ntakes-back-some-goods-sourcing-business-from-li-\nfung.\n[XL08] Wei Xiang and Heow Pueh Lee. \u201cAnt colony intelligence in\nmulti-agent dynamic manufacturing scheduling\u201d. In: Engineering\nApplications of Artificial Intelligence 21.1 (2008), pp. 73\u201385.\n[YFW01] Jonathan S Yedidia, William T Freeman, and Yair Weiss. \u201cBethe\nfree energy, Kikuchi approximations, and belief propagation algo-\nrithms\u201d. In: Advances in neural information processing systems\n13 (2001).\n[ZR89] Gilad Zlotkin and Jeffrey S Rosenschein. \u201cNegotiation and task\nsharing among autonomous agents in cooperative domains\u201d. In:\nProceedings of the 11th International Joint Conference on Artificial\nIntelligence (IJCAI). Morgan Kaufmann Publishers Inc. 1989,\npp. 912\u2013917.\n[Zur14] Richard Zurawski. Industrial communication technology handbook.\nCRC Press, 2014.\n",
      "id": 112321073,
      "identifiers": [
        {
          "identifier": "425276032",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:evastar-karlsruhe.de:1000131731",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.5445/ir/1000131731",
          "type": "DOI"
        },
        {
          "identifier": "653804052",
          "type": "CORE_ID"
        }
      ],
      "title": "Distributed Planning for Self-Organizing Production Systems",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:evastar-karlsruhe.de:1000131731"
      ],
      "publishedDate": "2021-04-21T01:00:00",
      "publisher": "KIT-Bibliothek, Karlsruhe",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://publikationen.bibliothek.kit.edu/1000131731/111130032"
      ],
      "updatedDate": "2025-05-08T21:36:11",
      "yearPublished": 2021,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/425276032.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/425276032"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/425276032/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/425276032/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/112321073"
        }
      ]
    }
  ],
  "searchId": "d82447b20cffdc36959d399803d0838f"
}