{
  "totalHits": 654,
  "limit": 10,
  "offset": 0,
  "results": [
    {
      "acceptedDate": "",
      "arxivId": "2310.19778",
      "authors": [
        {
          "name": "Cho, Sue Min"
        },
        {
          "name": "Gomez, Catalina"
        },
        {
          "name": "Huang, Chien-Ming"
        },
        {
          "name": "Ke, Shichang"
        },
        {
          "name": "Unberath, Mathias"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/596213960"
      ],
      "createdDate": "2024-01-18T00:05:19",
      "dataProviders": [
        {
          "id": 144,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/144",
          "logo": "https://api.core.ac.uk/data-providers/144/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "Efforts in levering Artificial Intelligence (AI) in decision support systems\nhave disproportionately focused on technological advancements, often\noverlooking the alignment between algorithmic outputs and human expectations.\nTo address this, explainable AI promotes AI development from a more\nhuman-centered perspective. Determining what information AI should provide to\naid humans is vital, however, how the information is presented, e. g., the\nsequence of recommendations and the solicitation of interpretations, is equally\ncrucial. This motivates the need to more precisely study Human-AI interaction\nas a pivotal component of AI-based decision support. While several empirical\nstudies have evaluated Human-AI interactions in multiple application domains in\nwhich interactions can take many forms, there is not yet a common vocabulary to\ndescribe human-AI interaction protocols. To address this gap, we describe the\nresults of a systematic review of the AI-assisted decision making literature,\nanalyzing 105 selected articles, which grounds the introduction of a taxonomy\nof interaction patterns that delineate various modes of human-AI interactivity.\nWe find that current interactions are dominated by simplistic collaboration\nparadigms and report comparatively little support for truly interactive\nfunctionality. Our taxonomy serves as a valuable tool to understand how\ninteractivity with AI is currently supported in decision-making contexts and\nfoster deliberate choices of interaction designs",
      "doi": null,
      "downloadUrl": "http://arxiv.org/abs/2310.19778",
      "fieldOfStudy": null,
      "fullText": "Designing AI Support for Human Involvement in AI-assisted Decision Making: ATaxonomy of Human-AI Interactions from a Systematic ReviewCATALINA GOMEZ, Johns Hopkins University, USASUE MIN CHO, Johns Hopkins University, USASHICHANG KE, Johns Hopkins University, USACHIEN-MING HUANG, Johns Hopkins University, USAMATHIAS UNBERATH, Johns Hopkins University, USAEfforts in levering Artificial Intelligence (AI) in decision support systems have disproportionately focused on technological advance-ments, often overlooking the alignment between algorithmic outputs and human expectations. To address this, explainable AI promotesAI development from a more human-centered perspective. Determining what information AI should provide to aid humans is vital,however, how the information is presented, e. g., the sequence of recommendations and the solicitation of interpretations, is equallycrucial. This motivates the need to more precisely study Human-AI interaction as a pivotal component of AI-based decision support.While several empirical studies have evaluated Human-AI interactions in multiple application domains in which interactions cantake many forms, there is not yet a common vocabulary to describe human-AI interaction protocols. To address this gap, we describethe results of a systematic review of the AI-assisted decision making literature, analyzing 105 selected articles, which grounds theintroduction of a taxonomy of interaction patterns that delineate various modes of human-AI interactivity. We find that current inter-actions are dominated by simplistic collaboration paradigms and report comparatively little support for truly interactive functionality.Our taxonomy serves as a valuable tool to understand how interactivity with AI is currently supported in decision-making contextsand foster deliberate choices of interaction designs.CCS Concepts: \u2022 Human-centered computing \u2192 Interaction design theory, concepts and paradigms; Interaction paradigms,Collaborative interaction.Additional Key Words and Phrases: human-AI interaction, decision-making, interactivityACM Reference Format:Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang, and Mathias Unberath. 2024. Designing AI Support for HumanInvolvement in AI-assisted Decision Making: A Taxonomy of Human-AI Interactions from a Systematic Review. In Under submission..ACM, New York, NY, USA, 26 pages. https://doi.org/XXXXXXX.XXXXXXX1 INTRODUCTIONAdvances in Artificial Intelligence (AI) developments open new possibilities for supporting human decision makingacross a wide variety of applications. To combat the shortcomings of so-called black-box recommendations, the emergingfield of Explainable AI (XAI) further attempts to expand model capabilities by providing not just recommendations butalso justification, which is argued to enrich end users\u2019 experience and satisfy their needs. A combination of technicalcontributions and a human-centered approach to designing XAI have provided valuable insights on what end usersPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are notmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for componentsof this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or toredistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\u00a9 2024 Association for Computing Machinery.Manuscript submitted to ACM1arXiv:2310.19778v2  [cs.HC]  31 Oct 2023Under submission, 2023, C. Gomez et al.may actually need [29, 84], but how and when to best communicate this information is equally crucial to understand.The latter aspects are closely related to the type and sequence of interactions between humans with AI, which areultimately enabled by the affordances of certain assistance elements [68].Interactivity is a familiar concept to humans and widely studied in more specialized domains such as informationvisualization, interface and software design [136].We have learned from these disciplines that we need to make deliberatechoices on what type of interactions we need to successfully achieving certain goals, rather than imbuing unnecessaryhigh levels of interactivity that do not result in better products [112]. Previous renowned AI design guidelines considerpertinent aspects during the interaction with end users, including the time when to act or interrupt, display informationrelevant to the user\u2019s current task, and deliver an experience aligned with expectations and avoid bias reinforcement [4].As noted from these aspects, implementing interactivity requires an understanding of capabilities of both agents andmaterialization through an interface. However, current interactivity with AI agents in empirical studies is trivialized tosimple menu selections, such as clicking buttons.Which forms of interactivity to incorporate in human-AI interactions is an open question and may depend on theoverall context, emphasizing the need to deliberately study interaction patterns between humans and AI that can guidethe development of better solutions. Several empirical studies have started to evaluate human-AI interactions in variedapplication domains and decision tasks [15, 68]. However, the specific configurations needed to evaluate the effect ofdifferent AI assistance elements (or other context-related factors) on humans interacting with AI, can result in multipleforms of collaboration or the actual interactions afforded. Previous works attempted to describe different possibleinteractions between humans and machines or AI, grouping them by user control and initiative [124], task nature [92],and level of automation [78]. These categorizations serve as a base to build on more comprehensive taxonomiesgrounded on and informed by evidence from empirical studies and incorporating knowledge from interaction design inother disciplines. Referring to different types of interactions is particularly difficult since we lack of a common languagethat captures a broad range of ways in which humans can interact with AI when solving decision making tasks. Thishighlights the importance of a structured framework for categorizing different interaction patterns, providing designersnot only with an understanding of existing ways for humans to collaborate with AI but also to make informed decisionson interaction design to build more effective and better AI systems.To address this gap, we first conduct an extensive systematic review on human-AI interactions that have beenreported for AI-advised decision making scenarios, a simple form of human-AI teammwork where an AI systemprovides a recommendation and the human makes the final decision [9]. We searched for relevant articles from fivedatabases that cover Human-Computer Interaction (HCI) studies and related disciplines and selected 105 to conducta detailed coding and analysis of the sequences of interactions that exist between humans and AI. Furthermore, weconsidered the task context, AI system involved, and the evaluation methods included in these empirical studies. Themain events in the sequences of interactions served as the building blocks that constitute our proposed taxonomyof seven interaction patterns that arise between humans and AI. To the best of our knowledge, there is not yet acomprehensive and structured classification of existing interaction patterns between humans and AI. We propose ourtaxonomy of interactions as a tool to better understand existing interaction patterns across domains and applications;allowing us to identify the occurrences of common interactions across multiple domains. We envision the use oftaxonomy to foster dialogues on interactivity in human-AI studies, encourage refinement and evaluation of novelpatterns, and ultimately design better and more user-centered AI-based solutions.2Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,2 BACKGROUND2.1 Humans in decision-makingDecision-making is the selection of an action within discrete choices, usually guided by multiple factors, such asrationality, emotion, experience, intuition, and heuristics [44, 99]. With multiple factors to consider, human decision-making can be affected by cognitive biases that impair information processing [90]. A common framework to understandhuman decision-making is the dual process model, which distinguishes between fast and intuitive (System 1) and slowand logical (System 2) cognitive processes [60]. System 1 can be efficient but error-prone due to simplifications or quickassessments (also known as heuristics), while System 2 can be more accurate but costly. Understanding human decisionmaking processes can inform the design of AI systems that complement human strengths and mitigate weaknesses asthey make decisions. It further informs the design of user interfaces that afford certain interaction mechanisms, e.g.,depending on the presentation and framing of information and incorporation of user feedback. Research on interactionmechanisms can provide insights to mitigate biases in human decision making and improve the outcomes as humanscollaborate with AI.Moreover, many human decisions are not made in isolation but in collaboration with others who may have differentperspectives, opinions, or expertise. Collaboration can enhance decision-making by providing access tomore information,diverse viewpoints, and constructive feedback [7]. However, collaboration may introduce costs and challenges, suchas coordination difficulties, social influence, group thinking, or conflict [83]. Therefore, it is important to understandhow humans incorporate others\u2019 advice in their decision-making process, and under what conditions collaborationcan improve or impair judgment quality. Several factors can change one\u2019s initial judgment after receiving advice fromanother person, such as the perceived credibility of the advisor, the similarity or dissimilarity of the initial judgments,the type and format of the advice, and the motivation and personality of the decision maker [45]. Human collaborationprovides workflows and insights for studying human-AI interaction because it can inform the design and evaluation ofAI systems to provide effective and trustworthy advice to humans.2.2 AI integration in decision makingArtificial intelligence developments provide solutions to perform tasks that normally require human intelligence, suchas perception, reasoning, learning, decision making, and problem solving [37]. AI has been applied to various domainsand contexts, ranging from low-stakes to high-stakes, where human decision-making is involved or affected [37].Depending on the level of autonomy and authority that AI has in the decision-making process, AI can play differentroles for humans: support human decision making by providing information, suggestions, or feedback that can helphumans make better or faster decisions; augment human decision making by performing some tasks that are toocomplex, tedious, or risky for humans, while still allowing humans to have control or oversight over the final decisions;replace human decision making by taking over the entire responsibility and accountability for the decisions and actions,without requiring human intervention or approval [73]. Overall, AI provides novel ways of human-machine interactionand emerging aspects that require further investigation.Similar to collaborations in human decision-making, ensuring effective cooperation between humans and machinesalso has many challenges. Cooperation requires trust and acceptance from both parties, which depend on factors such astransparency, explainability, accuracy, fairness, and ethics of the AI system [50]. Another challenge is balancing the levelof automation and human involvement in the decision-making process. Too much automation can lead to over-relianceor complacency from humans, who may lose their skills or situational awareness due to reduced cognitive load or3Under submission, 2023, C. Gomez et al.feedback [78]. Too little automation can lead to algorithmic aversion or resistance from humans, who may distrust ordisregard the AI system due to perceived errors or biases [109]. Thus, the amount of automation provided by AI directlyaffects human actions and their sense of agency, which are later reflected in different human behaviors. Understandingdifferent factors that shape interactions is crucial for selecting design elements that best fit a scenario that integrates AIin decision making. Thinking about human-AI interactions from the early development of AI solutions and iteratingcontinuously over design choices follows a human-centered approach to AI, in which developers reach to end users andtheir contexts, as it has been the case of building explainable AI in the medical domain [29, 122].2.3 Surveys in human-AI interactionThe growing interest to augment human decision-making with AI assistance has been captured by surveys focusedon human-AI interactions studies. A recent survey started by characterizing what the community defines as human-centered AI and how these claims are related to the interaction with AI [27]. This definition comprises approachesto design and evaluate AI, humans teaming with AI, ethical AI, and a new emerging area of interaction design thatinvestigates how people interact with AI systems and how AI is represented in the user interface. An overview of human-AI decision-making studies identified trends in different aspects of the design space in empirical works, suggestingmore careful consideration and justification of tasks and evaluation metrics [90]. Another aspect more closely relatedto interactions examined AI assistance elements, namely the type of model predictions, support information andinterventions or workflows, as these ultimately allow for interactions with a user. Only a few examples were usedto illustrate different levels of user control or machine agency. As the concept of trust is critical in AI-embeddedsystems, previous surveys have characterized the experimental protocols used to evaluate trust and provided practicalguidelines [127]. Other surveys have suggested taxonomies to organize human-AI studies across multiple dimensions,including components related to the interactions with AI. For instance, the complementing flow in the human-AI teamdetermines the interactions that can take place [138], i.e., the human can provide inputs to improve the AI system orthe AI can make it results understandable, while bidirectional complementing requires communications or actions fromboth agents and their cooperation as such. Furthermore, the teaming goal can be affected by the interaction state. Thehuman and machine part of the interaction was analyzed separately considering factors unique to each one, such as theamount and type of human input, or the AI\u2019s feedback to humans and interpretability [34]. Another survey identifiedfactors that influence collaboration between humans and AI, especially the utility of explanations to achieve betterteam outcomes[51]. Collaboration characteristics included the degree of automation, the order in which predictionsand explanations are made available, and the interactivity of the system, although the discussion was limited to a usecase when explanations are adaptive. Recommendations for future research suggested to actively involve the humanin the decision making process, resulting in dynamic interactions, such as delegation or choosing to reveal the AIrecommendations; both observed in the studies within our survey. As the emerging field of XAI constitutes a large portionof human-AI interaction studies, previous surveys have focused on explainability in human-AI interaction[14, 15, 29].These surveys have provided a comprehensive description of different explainable AI components, such as existingexplainability techniques and evaluation approaches used in the medical domain [29], cognitive biases that affect orare affected by XAI systems [14], and user evaluations of interactive explanations [15]. In addition, the latter createda classification of interactive techniques specific to XAI and grouped the resulting categories according to their rolein the cognitive process of explanation: \u201cselective\u201d, \u201cmutable\u201d or \u201cdialogic\u201d. Selective techniques help users filter outirrelevant information, mutable techniques help users modify the AI model or its inputs, and dialogic techniques helpusers engage in a conversation with the AI system.4Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,We expanded the characterization of interactivity beyond the functions that explanations can provide and integratedthe human and machine parts of the interaction together, which allowed us to consider the full picture of incorporatingAI systems as decision support. In this way, our classification of interaction patterns covers other factors such as thetype of assistance that AI can provide and when it is presented to the users during their interaction.2.4 Interaction patternsUnderstanding interactions requires delving into multiple dimensions that involve subjects, modes, and purposes ofinteraction, and the context in which they take place [107]. Among these, interaction patterns emerge as sequences ofbehaviors that occur more often than by chance between agents and systems or artifacts. For purposes of this work,studying interaction patterns can help researchers understand how humans and AI can work together and designsystems that are easy to use and achieve the intended goals. Psychology and social sciences have extensively studiedhuman-human interactions, revealing patterns of reciprocal actions, such as \"Question-Answer\" and \"Request-Offer\" [80],which can also be applied in a setup where humans interact with AI. For example, when an AI system provides answersto the user\u2019s questions or asks questions to elicit the user\u2019s preferences or feedback. Likewise, the field of Human-RobotInteraction (HRI) has studied how humans and robots communicate, collaborate, and engage with each other, oftenthrough the analysis of observable patterns in their interactions. Researchers have created templates and librariesfor programming and designing human-robot interactions, using building blocks of interaction as interaction designpatterns [33, 77, 104]. These patterns cover various aspects of social interactions, such as greetings, attention, feedback,turn-taking, social cues, and farewell. All these elements foster a more natural and efficient communication experience,which can take place in AI technologies that incorporate natural language abilities. Other domains such as informationvisualization and user interface design have also developed taxonomies and libraries of interaction patterns, based ondifferent criteria such as user\u2019s intent, purpose, scope, abstraction level, and granularity [111, 136]. These criteria helpdesigners to understand the characteristics and relationships of different design patterns and choose the most suitableones for the systems they are building.In the context of human-AI interaction, one way to classify interactions is by frequency: intermittent (occasionalinteractions), continuous (more frequent interactions), and proactive (led by AI\u2019s initiative) [124]. Another way toclassify interactions is by autonomy: human-dominated, machine-dominated, or balanced [135]. Human-dominatedinteraction refers to situations where machines act as an aid and humans retain the final right to make decisions.Machine-dominated interaction refers to situations where machines act as an authority and humans follow theirinstructions. Balanced interaction refers to situations where machines act as a partner and humans share decision-making power. A third way to classify interactions is by task complexity: simple (routine or repetitive tasks), moderate( partially defined and uncertain tasks), or complex (ill-defined and dynamic tasks) [92]. Decision-making workflowscan further result in different interaction paradigms: a sequential one where AI advice follows the human\u2019s initialindependent judgment, allowing for subsequent revisions, and a concurrent one when AI advice is presented alongsidethe prediction problem [117]. Similarly, a survey grouped interaction flows into four types of decision making processesthat basically differ by the presentation of recommendations [127]. As this categorization was proposed by a surveyconcerned with the empirical evaluation of trust, the analysis of interaction flows was associated with behavioralmetrics that can be calculated for each one. A synthesis of types of interactions explored in prior works on AI-assistedtext generation informed the definition of a taxonomy that is primarily structured around human actions and the extentof their control over the final text output [30]. User interviews evaluating the experience with these different types ofinteractions underscored the trade-offs between maintaining control and achieving task efficiency.5Under submission, 2023, C. Gomez et al.Overall, the existing classifications of interactions that involve AI are mostly focused on specific domains or contextsbut do not provide a general and comprehensive framework for characterizing and analyzing interaction patterns thatapply to multiple domains. The dimensions of frequency, autonomy, complexity, workflows, and human actions can becombined to form an extensive taxonomy of human-AI interaction patterns. Combining insights and principles frominteraction patterns in other disciplines and the findings from our systematic review, in this work we take a first step toprovide a common vocabulary to describe human-AI interaction patterns in a broader set of decision making tasks.3 METHODS3.1 Search strategy and selection criteriaThis survey focuses on Human-AI interaction paradigms for explicit decision-making tasks, in contrast to proxy taskwhere users are asked to simulate the AI outputs. Therefore, we aim to understand and evaluate the works that studyhuman-AI interactions during decision-making tasks under AI assistance, instead of improvements of the model. Oursurvey covers studies conducted between 2013 and June 2023. Specifically, we searched within five databases: ACMDigital Library, IEEE Explore, Compendex, Scopus, and PubMed. The first four have extensive coverage of relevantstudies in HCI covering conference proceedings and journal publications (Compendex and Scopus included papers frommore subjects), while PubMed allowed us to capture research specifically related to medical applications of Human-AIinteraction and decision-making. We defined the search terms covering four dimensions: use of AI systems, human-AIinteraction or collaboration studies, decision-making tasks, and interaction design. We included the last term since wewanted to focus on articles that evaluate interactions with AI systems during decision making tasks. The complete setof keywords used in our search can be found in the appendix. We defined the following inclusion criteria:\u2022 The tasks in consideration are those related to decision-making, and in particular, we limit the study selectionto those that implement complete decision making processes and not only evaluations of decision makers\u2019perceptions, such as understanding, preferences, or judgments of AI\u2019s advice.\u2022 The paper shows an implementation of the interface that was presented to human users to interact with AI.\u2022 The modes of interaction encompass screen-based interfaces, virtual agents, and non-embodied setups.\u2022 We have restricted our selection solely to papers featuring empirical user studies.In addition to the inclusion criteria above, our search excluded studies in robotics and gaming by filtering out thesekeywords in the title and abstract. We excluded studies that involve robots because physical embodiment enablesmore dimensions of an interaction and those involving gaming scenarios because they are more complex, with lessconstraints to study how humans can interact with AI assistance. However, studies that implement decision makingtasks through gamified tasks were included. Other survey papers or comments were also excluded by filtering outkeywords in the title and abstract.3.2 Study selectionThe initial search returned 3,770 papers, and 358 duplicates were found and deleted automatically. This left us witha total of 3,412 papers to screen. They were assigned to two authors to first go through title and abstract screening,followed by full-text screening. The screening phase was oriented towards the exclusion of papers that were not focusedon human-AI interaction, i.e., limited to technical contributions, did not involve a complete decision-making task, wereshort papers (less than 8 pages), involve gaming or robotics, have not been peer-reviewed, and were review or surveypapers. We did not constrain our selection to works that directly manipulate the type of interaction between the human6Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,and AI. Our main interest was on which were the existing/available ways for humans to interact with AI agents in theevaluation of human-AI decision making. The total and abstract screening excluded 2,893 papers, and at the full-textreview stage, 363 papers were filtered out. Lastly, 156 were considered for the information extraction stage, of which51 were removed as a more detailed reading allowed us to identify that they did not satisfy the inclusion criteria ofsupporting actual AI-assisted decision making tasks. Figure 3 in the Appendix summarizes the complete paper selectionprocess. At the end, 105 articles were included in our review.3.3 Data extraction strategy3.3.1 Analysis process. The data extraction template was developed by all authors and informed by previous surveysof empirical studies in human-AI interaction [15, 68]. Two authors distributed the final selected articles to be analyzedand coded the assigned articles independently. Then, one author checked the individual reports of each article to ensureconsistency in the final extraction. Further discussions with the other authors took place to clarify discrepancies in theinteractions or ambiguous cases. For the analysis of the interaction patterns, the authors reviewed the sequences ofinteractions and discussed how to group them into the design patterns that were repeated and are presented by thiswork. We iterated over the definition of each pattern to refine the actual components that constitute the interaction.3.3.2 Context. We identified general information in which the decision making task takes place. This includes thedomain and we adapted the categories initially proposed in this survey of AI-assisted decision making [68]. Furthermore,we specified the decision making task to be completed by the human (e.g., detection of hate speech, sleep stageclassification, price estimation) and the level of expertise required to successfully complete the task.3.3.3 AI system. As we are interested in humans interactions with AI agents, we retrieved the original goal ofincorporating AI assistance in the decision making task, and briefly characterized the AI system used in the study.In particular, we extracted the technique supporting the AI\u2019s recommendations (whether a real model was used orthe outcomes were simulated), its performance (if any evaluation metric was reported), and the terminology used tointroduce the AI agent to participants in the user study. Further details such as data type and source, output type werenot reported as the main focus of this survey is on the interactions rather than the type of AI methods as previouslyreported in [68].3.3.4 Evaluation. In the empirical studies selected for this survey, humans were directly interacting with an AI systemsand it is relevant to evaluate how they perceive such assistance and the outcomes of this interaction. We extracted theconstructs evaluated in the studies and classified them as objective or subjective dependent variables depending onhow they were assessed.3.3.5 Interaction building blocks. An interaction involves a reciprocal action or influence between two agents in thecontext of this survey [107]. To characterize this, we defined two elements: the action undertaken and the resultingoutput of that action. These two elements constitute the interaction building blocks that can be integrated into morecomplex interactions. In the definition of our taxonomy of human-AI interactions, we considered these buildingblocks as the main elements that constitute the interaction patterns. Drawing insights from prior studies on human-AIinteractions, we defined the following (action - output) pairs available for the agents involved in the interaction. Thesebuilding blocks primarily focus on the AI assisting the user in decision-making processes.7Under submission, 2023, C. Gomez et al.\u2022 Predict - Outcome: The agent produces a solution to the primary decision-making task after receiving taskinformation. This action is observed to be executed by either the AI or the user.\u2022 Decide - Outcome: The agent integrates the assistance they received to finalize the decision outcome. This actionis typically observed to be executed by the user.\u2022 Provide - Options: The agent offers solutions for a secondary task that, while not directly resolving the primarydecision-making task, are still informative. This action is typically observed to be executed by the AI.\u2022 Display - Information: The agent presents supplementary evidence (e.g., explanations, uncertainty values,alternate solutions) supporting a solution to the primary decision-making task. This action is observed to bepredominately executed by the AI.\u2022 Request - Outcome/Information: The agent seeks information or solutions from its counterpart. This action isobserved to be either mandatory or optional and is typically executed by the AI when it requires user inputs, orby the user when they seek a direct solution or supplementary information from the AI.\u2022 Collect - Inputs: The agent gathers task-related information and provides it to the other agent. This action isobserved to be typically executed by the user when their input is needed for the AI to provide a solution to thedecision-making task.\u2022 Modify - Outcome/Information: The agent makes changes to the solutions or supplementary information providedby its counterpart. This action is typically observed to be optional and executed by the user.\u2022 Delegate - Decision: The agent decides whether to retain responsibility for the task or transfer to its counterpart.This action is observed to be executed by either the AI or the user. Events after delegation can differ, rangingfrom complete surrender of agency to opportunities for supervising the other agent\u2019s decision-making process.\u2022 Other: if an action does not fit the other types.These concepts were refined and iterated as we reviewed more works. We identified all possible pairs of (action -output) as building blocks for each agent involved in the decision-making task. For each paper, we first selected thepairs present in the interaction (with a brief description in free text form) and then defined a sequence of interactionsconsidering the order in which these events take place and the agent in charge. The sequences were not preset inadvance in the extraction template since we wanted to discover the interaction patterns here. We note that dependingon the experimental manipulation of the user study, different modes of interactivity with the user could be plausibleand we separated these into different sequences.4 RESULTS4.1 Interaction patterns discovery in AI-assisted decision makingWe present seven categories of interaction patterns that we have identified in our corpus, illustrated in Figure 1. We beginby reviewing previous literature containing taxonomies of interaction techniques in other domains, such as informationvisualization [136], human-robot interaction [104], multi-agent systems [24], and educational technologies [112].Contrasting the concepts in these taxonomies with a sample of studies in human-AI interaction that we were familiarwith, we identified potential ways in which the types of interactions described previously could potentially apply tohumans interacting with AI during decision making. In each pattern formulation, we considered an appropriate level ofabstraction so that they can capture multiple actions of the agents and generalize over various studies. Interactionsinvolve changes over time and we attempted to capture this evolution/progression in the interaction patterns presentedbelow and in the diagrams that illustrate them. Furthermore, we included a \u201cOther patterns\u201d category to present8Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,Modify - OutcomeModify - Information\u22ef\u22ef\u22ef\u22efPredict - Outcome endDecide - Outcome Collect - InformationRequest - InformationPredict - Outcome endDecide - Outcome Request - OutcomeRequest - InformationDisplay - InformationPredict - Outcome endDecide - Outcome Provide - OptionsendDecide - Outcome Predict - Outcome Display - InformationPredict - Outcome endDecide - Outcome Predict - Outcome Display - Information\u22ef\u22ef\u22ef\u22efDelegate \u2013 DecisiontruefalsePredict - Outcome Predict - Outcome 1) AI-first assistance 2) AI-follow assistance 3) Secondary assistance4) Request-driven AI assistance 5) AI-guided dialogic user engagement 6) User-guided interactive adjustments 7) DelegationFig. 1. Taxonomy of interaction patterns identified in AI-assisted decision making. The user (human) and the AI are representedas separate agents and the temporal evolution of the interactions is illustrated from top to down. The boxes contain the buildingblocks (action-output) pairs that compose each pattern. The direction of arrows denote the agent who started the action. Dashedlines represent optional operations.the interaction patterns that did not exactly fit into the main categories. However, the interactions we identified arecomprised of the interaction building blocks and can borrow some of the other pattern categories. We identified thedifferent categories of interaction patterns formulated in our taxonomy using a combination of an automated search forcertain action-output pairs present in sequences of interactions and manual inspection and verification. In the followingdescriptions, we assume that users already have some background knowledge or intuitions that can be used during thedecision making task. Lastly, the classification of interaction patterns does not mean they are mutually exclusive events,but elements that can be consolidated and combined.AI-first assistance. This pattern manifests when the decision-making problem and the AI-predicted outcome aresimultaneously displayed to the user. As the ultimate decision maker, the user can choose to incorporate the AI\u2019s adviceinto their final decision or opt to disregard it. When task-related stimuli (e.g., images or case details) are presentedalongside the AI-predicted outcome, the user is provided with a more comprehensive set of information to consider. Thispattern has been previously observed and referred to as the \"concurrent paradigm\" [117] or \"one-step workflow\" [40].AI-follow assistance. This pattern begins with the user forming an independent preliminary prediction given thedecision-making problem. Following this initial judgment, the AI\u2019s predicted outcome is presented. This procedure9Under submission, 2023, C. Gomez et al.provides the user with a reference (their initial assessment) to compare against the AI\u2019s advice, and an opportunityto reassess their initial judgment. This approach has been identified as the \u201csequential paradigm\u201d [117] or \u201ctwo-stepworkflow\u201d [40] and has been commonly used to evaluate the human\u2019s reliance on the AI\u2019s advice.Secondary assistance. In this pattern, the AI offers information that does not serve as direct solutions to the decision-making problem. The user must interpret this supplementary information as an auxiliary task to determine its relevanceand decide how to incorporate it into their primary decision-making process. We distinguish this as a unique interactionpattern because users respond differently to direct assistance compared to more secondary assistance in their decision-making process. For example, machine learningmodels can predict risk values associated with certain profile informationand the human\u2019s decision problem is to make an investment decision [36].Request-driven AI assistance. In this interaction pattern, the user has to actively seek information or solutions fromthe AI. Rather than the AI\u2019s inferences being automatically presented, the user can control when they want to receivethe AI assistance. Meanwhile, the user can spend more time deliberating about the problem, a strategy known ascognitive forcing [20, 93]. This pattern can be perceived as less intrusive to the user, as it empowers the user to \u201cask\u201dfor information or solutions from the AI, and allows the user to anticipate the AI\u2019s assistance in the decision-makingprocess.AI-guided dialogic user engagement. Within this interaction pattern, the AI facilitates a dialogue-like engagementwith the user. Guided by the AI\u2019s instructions, the user responds by providing pertinent information. The iterativeexchange continues until AI\u2019s instruction requirements are satisfied, and is followed by the presentation of the AI\u2019spredicted outcome for the decision-making task. This responsive exchange not only involves retrieving and sharinginformation in line with the task but also ensures that the users recognize the influence of their inputs on the AI\u2019spredicted outcome. While this pattern has been commonly observed in humans interacting with conversational agents[49, 59], it is not only limited to traditional conversational interfaces [46].User-guided interactive adjustments. Inspired by the taxonomy of interactive explanations recently proposed froma scoping review [15], we included an interaction pattern where humans can modify the outcome space of the AIagent. Typically, information flows from the AI to the user. However, in this pattern, the direction of flow is reversed,with humans providing the AI with feedback, corrections, or information to shape its inferences. While a detailedclassification of potential modifications is beyond the scope of this survey, we distinguished cases in which the changesare merely visual updates in the interface or considered as feedback to improve the underlying AI models, as ininteractive machine learning [3].Delegation. In this interaction pattern, both the user and the AI leverage their unique strengths and capabilities tooptimize the decision-making outcome. Delegation can be a strategic choice when one agent assesses its counterpart asbetter equipped for a particular task [41]. On the other hand, if an agent feels confident in their ability to complete thetask, they will take the lead. Studies highlight that the complementary abilities of humans and AI when synergizedproperly, can enhance the decision-making outcome [139].Others. We included within this category those patterns that involve a combination of the main interaction blocksand did not fit into the patterns described before. More complex interaction emerges when the decision making problemmay involve multiple individual decisions, agents (more than two), and continuous interactions with an AI agent.10Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,4.2 Identification of interaction patterns in AI-assisted decision making studiesWe identified the different categories of interaction patterns in the selected 105 articles. If a study included more thanone interaction sequence, i.e., the experimental manipulation resulted in different ways in which users can interactwith the AI, we considered them separately and counted patterns in each one. In total, we analyzed 131 sequences. Themost common interaction pattern during empirical evaluations of AI-assisted decision making tasks was the AI-firstassistance (n=67), followed by the AI-follow assistance (n=28). Furthermore, the AI\u2019s solutions to the decision makingtask were presented along with additional information in the majority of the cases, 81% and 68% during concurrent andsequential interactions, respectively. We observed 16 instances of the Secondary assistance pattern in which the AIsupport did not propose a direct solution to the decision making task but rather estimated an outcome informative forthe task. In particular, we noticed that most of the decision making tasks required expertise (11/16). Sometimes duringthe decision making task, users had to actively seek support from the AI agent as specified in the Request-driven AIassistance (n=25). More specifically, the requests could be for a direct a solution to the decision making task (n=14) orfor the presentation of support information (n=13). In the former, only in three cases the request for the AI\u2019s solutionwas optional [12, 66, 119], meaning that users could come with a solution to the decision making task on their own.Meanwhile, the support information at the user\u2019s discretion was identified in eight cases [25, 75, 85, 96, 115, 126, 129],for demanding explanations in particular. In the AI-first assistance pattern, where the user may not have an opportunityto form an independent assessment of the decision making problem, we observe cases (n=10) in which users are giventhe ability to control when they want to receive the AI assistance via a request [12, 20, 46, 62, 78, 85].To a lesser extent, we found the interaction patterns that involve more interactive components between the humanand the AI agent. For the AI-guided dialogic user engagement, as the name suggests, five out of the six interactionswere supported via conversations with the AI agent. Through conversational interfaces, users had to provide someconstraints given in the decision making problem for the AI to propose a candidate solution [49, 59, 62]. However, suchexchange of information does not necessarily rely on a conversational interface, as demonstrated in [46], where the AIcould constantly provide guidance on the sub-problem introduced in the instruction. Interactivity components alsosupport the adjustment of the AI\u2019s outcome space, and we found the User-guided interactive adjustments in nine casesthat differed on the observed effect of the adjustment. For instance, manipulations of the inputs result in new AI\u2019soutcome computations for exploratory purposes [48, 75, 88, 116, 144]. When adjustments did not directly translate intoan updated AI\u2019s outcome, users\u2019 feedback was considered for future improvement of the model [6, 71, 85, 113].An opportunity to delegate decisions was observed in nine sequences of interactions, though with differences inthe conditions for delegation. For instance, in some cases the users \u201cblindly\u201d delegate the decision to the AI withouthaving access to their outcome and not being able to supervise it later [31, 41, 81, 142]. In others, the AI agent has thedecision to delegate and the user is assigned some of the decision making tasks to be completed on their own [41, 52],or presented with the AI\u2019s outcome as support, resulting in the concurrent pattern [17]. In addition, the user can objectto the delegation decision of the AI and take charge of the decision if considered appropriate [126].Lastly, the articles that we included in the \u201cOthers\u201d category of interaction patterns can be separated into three groups.First, decision making tasks that involved more than one decision outcome [76, 95] and corresponding support from theAI agent. Second, decision making problems where multiple instances of decision tasks can take place and the interactionwith the AI agent is continuous [38, 74, 89, 100, 123]. Third, interactions that involved a third agent [8, 18, 134]. Inaddition, a different case results when independent solutions, from the human and the AI agent, to the decision makingproblem are averaged as the final verdict [135].11Under submission, 2023, C. Gomez et al.4.3 Landscape over domains evaluated in AI-advised human decision makingWhat domains have been defined as contexts to evaluate AI-assisted decision making? The selected articles includedin this survey cover a broad range of different domain categories previously identified [68]. Articles that includedmore than one experimental decision making task were counted toward more than one domain. Table 1 presents asummary of the major domains and the different decision making tasks evaluated. Overall, the majority of the studiesconducted human-AI interaction evaluations in real-world applications, with less than 15% formulating artificial tasks.We included medical related databases in our search strategy, which contributes to the large representation of decisionmaking tasks on the healthcare domain (26/108). In addition to healthcare, decision making tasks that may involvehigh-stakes outside of an experimental setup were identified in the finance and business (15/108), and law domains(6/108). The second most common domain was in the context of generic tasks (20/108) that are low-effort processingfor humans but have mostly been used to develop AI benchmarks and demonstrate technical feasibility of algorithms.Other domains that typically include tasks targeted to non-expert users are social media (8), labeling (8) and leisure (1).We assigned tasks with unique applications to the Other domain (6/108). Even though we identified multiple decisionmaking tasks in applications that require a specialized population, making it more difficult to achieve a large sample ofparticipants, the majority of human-AI interactions have been evaluated with non-expert uses (60/108). The type of AIsystems behind the interactions with users in the studies that covered these decision-making tasks were distributedamong three categories: simulated models or Wizard of Oz experiments (39/105), deep learning-based models (34/105),and shallow models (35/105).In what contexts were the interaction patterns observed during AI-assisted decision making processes? To better un-derstand the existence and availability of the interaction patterns in different domains, we quantified the occurrenceof patterns per domain and provide an overview describing the trends. Figure 2 shows the distribution of interactionpatterns within our taxonomy for different domains. Values equal to zero mean that certain interaction pattern was notobserved in the studies included in this survey for a specific domain. Tables in the supplementary material providemore details on the interactions for each paper included in this review.Human-AI interactions in AI-advised decision makings in the healthcare domain mostly adhered to the AI-firstassistance pattern (n=14), followed by Secondary assistance (n=7). Request-driven AI assistance was observed in afew cases (n=4) as well as AI-follow assistance (n=4). We identified one interaction that supported AI-guided dialogicuser engagement, three interactions in the User-guided interactive adjustments, and one in which delegation was anoption. Five sequences of interactions were in the \u201cOthers\u201d category due to the higher complexity of the interactions. Inthe domain of finance and business, AI-first assistance was the most common type of interaction (n=6), followed byAI-follow assistance (n=4) and Secondary assistance (n=4). Some interactions supported Request-driven AI assistance(n=3), AI-guided dialogic user engagement (n=2), and delegation (n=3). We did no identify support for User-guidedinteractive adjustments. We identified four types of interaction patterns in the law and civic domain: AI-first assistance(n=4), AI-follow assistance (n=2), Request-driven assistance (n=2), and User-guided interactive adjustments (n=2).Decision-making tasks that involve professional related topics mostly followed AI-first assistance (n=4). Request-drivenAI assistance and user-guided interactive adjustments were observed in one case each one. The other interactionpatterns were not observed. Interaction patterns during decision making tasks involved in social media contexts weremostly of the AI-first (n=4), AI-follow (n=4), and Request-driven AI assistance types (n=4). We identified Secondaryassistance in one case, and two cases in which User-guided interactive adjustments were enabled, in particular, forupdating relevant terms for content moderation purposes. No Delegation or AI-guided dialogic user engagement was12Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,Table 1. Domains and corresponding decision tasks used to study AI-assisted decision making.Domain Decision making task Total tasksEducation student performance prediction [97] 1Artificial identify the category of a shape [139]; estimate quantities [55, 93]; policy-verification task [89]; quality control [137]; delivery method selection[42]; pipe failure prediction [143]; nutrition prediction [19]; object move-ment prediction [66]; Memorizing images [1]; ranking [63]; spatial rea-soning task [26]; pumping decisions [135]; predict Titanic passenger\u2019sfate [12]14Finance/Business stockmarket trading [28, 81]; lending/loan assessment [5, 36, 58]; incomeprediction [2, 141]; revenue forecasting [129]; housing [31, 32, 49, 54,96, 119, 133]15Healthcare Medical Diagnosis and Classification [5, 22, 25, 40, 43, 48, 56, 70, 74,100, 100, 105, 116, 120, 123, 130]; Clinical Decision Support Systems andTreatment Planning [16, 57, 59, 71, 82, 87, 91, 91, 95, 125, 126]26Generic image classification [17, 23, 41, 46, 52, 115, 117, 128]; text classification[10, 23, 28, 69, 101\u2013103, 113, 114]; question answering [10, 39, 110];speech classification [121, 140]20Labeling text labeling [6, 13, 18, 35, 78, 106, 108]; image labeling [28] 8Law recidivism prediction [2, 47, 75, 131] criminal referral decision [144]penal sentence prediction [61]6Leisure travel planning [62] 1Social media friend matching [76, 98] content filtering [21, 67, 76, 85] fact checking[8, 88]8Professional human resources [53, 94]; profession prediction [75] 3Other environment [72, 86]; ethical decision-making [118, 134]; nutrition [20]UX usability evaluation [38]6observed and two cases fell into the \u201cOthers\u201d patterns category. During decision making tasks in generic applications,most of the interactions were dominated by the AI-first assistance (n=21), while only two cases involved the AI-followassistance interaction. Regarding the more interactive patterns, two cases supported Request-driven AI assistance,two AI-guided dialogic user engagement, and one User-guided interactive adjustments. Only in one case the type ofassistance was secondary. Delegation was featured in five cases. Labeling tasks mostly included AI-first assistancepatterns (n=6), followed by Request-driven AI (n=4) and Secondary assistance (n=3), mostly clustering similar datapoints. We further identified AI-follow assistance and User-guided interactive adjustments once each one, and two typesof interactions in the \u201cOthers\u201d patterns category. Artificial decision making tasks were mostly dominated by AI-followfollow (n=8) and AI-first assistance (n=7). Request-driven AI assistance was featured in four cases and four interactionswere in the \u201cOthers\u201d patterns category. Lastly, AI-guided dialogic user engagement was the type of interaction in theleisure-related task and AI-first assistance in the task within the education domain. Interactions during decision-makingtasks that belong to other domains mainly contained AI-first (n=4) and AI-follow (n=3) assistance types, or patterns inthe \u201cOthers\u201d category (n=3). Further, one case supported Request-driven AI assistance.What evaluation methods and measures have been used in the study of AI-assisted decision making across domains? Wedescribe the variety of evaluation measures used in the selected articles for our study of AI-assisted decision making.Table 2 in the Appendix presents a summary for each domain, separated by whether they correspond to objective13Under submission, 2023, C. Gomez et al.Fig. 2. Percentage of interaction patterns observed in each domain of AI-assisted decision making tasks included in this survey.The numbers in the cells denote the percentage values (e.g., 17% of the patterns identified in the healthcare domain correspond toSecondary assistance). One study can include multiple sequences of interaction and interaction patterns are not mutually exclusive.or subjective measurements, and the constructs evaluated with the metrics. Broadly, we can observe a joint use ofobjective and subjective measures used in empirical evaluations of AI support for decision making tasks across multipledomains, as indicated by a previous review on interactive explanations [15]. Objective measures covered four constructsoverall. Efficacy is directly related to the joint (human and AI) task performance and is typically measured as theaccuracy of decisions, errors, or other performance-related metrics. Trust and reliance construct is generally capturedusing agreement with AI advice or other variations (e.g., compliance frequency and over-reliance), weight of adviceduring AI-follow assistance, and delegation rate if the delegation pattern is present. Efficiency is considered during theexecution of the decision-making task, directly measuring the actual decision time or more general total task time andexploration of other task functionalities. Although more commonly evaluated subjectively, questionnaires to capture AImodel understanding have been developed [131].Some of the constructs captured through objective metrics can be evaluated from a subjective perspective as well,allowing researchers to identify potential mismatches between how users behaved and what they perceived during theirinteraction with AI. For instance, efficacy is easily quantifiable objectively, but has further been recorder from users\u2019perceptions on their own, their AI partner\u2019s, or joint success to complete the task. Trust and reliance is another constructtypically captured through standardized subjective questionnaires (e.g., [65, 79]) that cover multiple dimensions, such ascompetence, reliability, trustworthiness, intention to comply, credibility, uncertainty, among others. This last constructwas evaluated in all the domains covered in this review but one (professional), highlighting the importance of developingtrustworthy AI systems for humans to interact with. As with trust and reliance, the evaluation of system usability wascovered in almost all the domains, except for education. Usability measurements include multiple dimensions suchas usefulness, acceptance, satisfaction with the system, potential implementation, and system complexity. Anotherconstruct naturally captured through users\u2019 perception is decision satisfaction and mental demand, including ratings onconfidence in the task, cognitive load, task difficulty or complexity, frustration, and workload. In order to evaluate users\u201914Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,processing of the information presented by the AI, understanding of these systems is commonly evaluated, especiallywhen explainability components are involved. The construct of fairness did not stand out in the most frequent subjectivemeasures but we attribute this to the fact that we excluded works in which decision making tasks were the context forevaluating humans\u2019 perceptions of the AI\u2019s outcomes, usually involving judgments of fairness. We included the metricsthat did not fit into the categories mentioned above in a separate group labeled other.5 DISCUSSIONIn establishing the interaction patterns presented in this paper, we drew from our observations of the Human-AIinteractions used in AI-advised decision-making scenarios in prior empirical studies. While many of these studieseffectively described their interfaces and user study procedures, there were instances where the information providedwas not sufficient for a complete recreation of the interactions. Consequently, we had to carefully interpret and encodethe interactions from these papers to the best of our abilities.Constructing a taxonomy is inherently challenging due to the wide array of potential approaches that can be adopted.Specifically, in the domain of Human-AI interaction, interactions can be examined through various lenses (e.g., system-centric, oriented around user goal/task, distinguished by varying levels of granularity in interaction techniques). In thiswork, we have taken a preliminary step to structure an approach by integrating our perspectives with observations ofinteraction paradigms used in existing studies. We hope this framework can serve as a foundation for further expansionand refinement to be made in subsequent research.The most frequently observed interaction was the AI-first assistance pattern, where the user is given a direct presen-tation of the AI\u2019s prediction for the decision-making task. Its popularity can be attributed to the straightforwardness ofdemonstrating the effects of incorporating AI assistance into a decision-making task. However, it presents challenges,notably the difficulty in measuring the actual influence of AI assistance on user decision-making. Since the AI\u2019s solutionis revealed before the user has had the opportunity to process the task independently, it can be convenient for the userto either dismiss or follow the AI\u2019s recommendation without sufficient reflection. This interaction also makes the usersusceptible to the \u201canchoring bias\u201d, a phenomenon where a person\u2019s judgment is biased based on initial information. Thisbias can be avoided through the use of Secondary assistance, where the user must interpret supplementary information,determine its relevance, and decide how to incorporate it into their primary decision-making process.In contrast, in the AI-follow assistance pattern, the user is given a chance to solve the problem on their own, thus,potentially minimizing anchoring bias. Yet, whether users actually restart their decision making process is open toquestion.An article found that participants in the \u201ctwo-step\u201d workflow rarely revised their provisional diagnoses whenthe AI inferences differed from their earlier assessment [40]. This hints at confirmation bias, a person\u2019s tendency toseek supporting evidence for their current hypothesis. In case the user does re-evaluate their prior assessments, thecognitive costs increase. Cognitive costs of re-examination, when new information becomes available, can be viewed asanalogous to interruption and recovery on the initial task with new information [40].In general, while most interactions observed were AI-first, AI-follow, or Secondary assistance, we did also notethe presence of more dynamic interactions (e.g., Request-driven AI assistance, AI-guided dialogic user engagement,User-guided interactive adjustments), although less frequently. A finer analysis per domain revealed the limited use andsupport for diverse interaction patterns, represented by most cell values equal to zero in Figure 2. However, it is worthnoticing that for high-stake domains, such as healthcare and finance, multiple interaction patterns have been exploredwhen AI provides decision support.15Under submission, 2023, C. Gomez et al.Direct presentation of AI inferences can lead to a lack of \"sense of agency\" for the user, which refers to the subjectivefeeling of controlling one\u2019s actions, and influencing external events through them [132]. Request-driven AI assistancecan empower the user with the choice to view AI inferences and foster a sense of agency. It is worth noting that merely10 of the identified AI-first assistance occurrences permitted the user to request AI inferences. However, althoughRequest-driven AI assistance gives the user more sense of agency, it can give rise to possible confirmation bias oranchoring bias, especially when the user seeks explanations for decision verification or knowledge acquisition [11].From our thorough exploration of interaction patterns in a sample of over 100 articles, we have identified gaps andopportunities. Much of the HCI literature on AI assistance has concentrated on intermittent scenarios (i.e., turn-taking).This is in contrast to continuous user interaction scenarios, where user input is sustained and can receive AI feedbackat any given moment, which would be a more realistic and organic setup. Another noticeable gap was regardingmulti-agent teamwork collaboration. Most studies focus on interactions between a single user and a single AI, wherethere could be potential scenarios where an additional agent can be added. Also, while the current Delegation patternallows the agent to change the assignment of decision-making, task coordination and allocation between agents can beexplored. Moreover, we observed that the nature of the decision-making task is a notable point of consideration. Asignificant number of the interactions are evaluated within artificial tasks. Such controlled and simulated environmentsmay not truly reflect the complexities faced in real-world applications. For instance, interactions in most studies endpost-decisions, and decision-makers are not exposed to the full consequences of their choice [64]. Thus, even whenlabeled as high-stakes, the lack of real consequences can influence the user\u2019s engagement. We must think more aboutdifferences in how users behave in experimental tasks and in equivalent real-life scenarios.Furthermore, we need to evaluate the relevance of AI assistance in simpler tasks (i.e., when humans can effortlesslycomplete a task). Does AI assistance truly add value, and what would the experimental relevance to real-worldapplicability be? This disparity can also be seen in specialized fields, where the users are often required to have acertain level of expertise. These domain experts have their unique set of capabilities that can directly influence thechoice and efficacy of interactions with the AI. For these experts, Secondary assistance can be beneficial, since theyhave the insights to effectively use the supplementary AI information for the primary decision-making task. However,for non-experts, the most suitable and beneficial choice of interaction pattern is unclear. There remain questions aboutthe universality of certain interaction patterns across varied user groups and task scenarios.The design choices for Human-AI interactions must be made with deliberation. Factors such as user psychology \u2014including tendencies like confirmation bias and anchoring bias \u2014 user agency, and the cognitive costs in terms of timeand effort, should all be taken into careful consideration.5.1 LimitationsThe works included in this survey are limited to published manuscripts that conduct empirical evaluations of human-AIinteractions. This focus, while intentional, could have introduced certain limitations. The terminology used in thesearch could have excluded relevant work if the interaction design was not explicitly mentioned in the title or abstract,or even in the body of the text. Moreover, publication bias may have resulted in the exclusion of works relevant to thisreview. We also constrained our analysis to screen-based interfaces for AI-assistance, acknowledging that embodiedAI might support additional interactions. Our strict selection criteria centered on studies encompassing completedecision-making tasks to ensure actual Human-AI interactions. Given the diversity of experimental designs and factorsin the papers reviewed in this survey, we abstracted the interactions to discern patterns across the varied studies.16Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,6 CONCLUSIONIn this paper, we presented a systematic review of human-AI interactions in AI-advised decision making tasks thatinformed and grounded the formulation of a taxonomy of interaction patterns. Our proposed taxonomy of interactionpatterns provides a structured foundation for understanding and designing these crucial interactions. It reveals thatcurrent practices often lean toward AI-driven or human-led decision processes, with limited emphasis on fosteringinteractive functionalities throughout the interactions. Recognizing the significance of interaction design, we advocatefor deliberate choices in system development to enhance collaboration between humans and AI. Moving forward, thetaxonomy presented here serves as a valuable resource to inform the design and development of AI-based decisionsupport systems, ultimately fostering more productive, engaging, and user-centered collaborations.REFERENCES[1] K Allan, N Oren, J Hutchison, and D Martin. 2021. In search of a Goldilocks zone for credible AI. Scientific Reports 11, 1 (2021).[2] Yasmeen Alufaisan, Laura R Marusich, Jonathan Z Bakdash, Yan Zhou, and Murat Kantarcioglu. 2021. Does Explainable Artificial IntelligenceImprove Human Decision-Making?, Vol. 8A. Association for the Advancement of Artificial Intelligence, 6618\u20136626.[3] Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza. 2014. Power to the people: The role of humans in interactive machinelearning. Ai Magazine 35, 4 (2014), 105\u2013120.[4] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, KoriInkpen, et al. 2019. Guidelines for human-AI interaction. , 13 pages.[5] Ksenia Appelganc, Tobias Rieger, Eileen Roesler, and Dietrich Manzey. 2022. How Much Reliability Is Enough? A Context-Specific View on HumanInteraction With (Artificial) Agents From Different Perspectives. Journal of Cognitive Engineering and Decision Making 16, 4 (2022), 207\u2013221.[6] Z Ashktorab, M Desmond, J Andres, M Muller, N N Joshi, M Brachman, A Sharma, K Brimijoin, Q Pan, C T Wolf, E Duesterwald, C Dugan, W Geyer,and D Reimer. 2021. AI-Assisted Human Labeling: Batching for Efficiency without Overreliance. inproceedings of the ACM on Human-ComputerInteraction 5, CSCW1 (2021).[7] Bahador Bahrami, Karsten Olsen, Peter E Latham, Andreas Roepstorff, Geraint Rees, and Chris D Frith. 2010. Optimally interacting minds. Science329, 5995 (2010), 1081\u20131085.[8] John A Banas, Nicholas A Palomares, Adam S Richards, David M Keating, Nick Joyce, and Stephen A Rains. 2022. When Machine and BandwagonHeuristics Compete: Understanding Users\u2019 Response to Conflicting AI and Crowdsourced Fact-Checking. Human Communication Research 48, 3(04 2022), 430\u2013461. https://doi.org/10.1093/hcr/hqac010 arXiv:https://academic.oup.com/hcr/article-pdf/48/3/430/44308147/hqac010.pdf[9] Gagan Bansal, Besmira Nushi, Ece Kamar, Walter S Lasecki, Daniel S Weld, and Eric Horvitz. 2019. Beyond accuracy: The role of mental models inhuman-AI team performance. In Proceedings of the AAAI conference on human computation and crowdsourcing, Vol. 7. 2\u201311.[10] Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco Tulio Ribeiro, and Daniel Weld. 2021. Does theWhole Exceed Its Parts? The Effect of AI Explanations onComplementary Team Performance.[11] Barda AJ, Horvat CM, and Hochheiser H. 2020. A qualitative research framework for the design of user-centered displays of explanations formachine learning model predictions in healthcare. BMC Med Inform Decis Mak 20, 1 (2020), 257.[12] T Baudel, M Verbockhaven, V Cousergue, G Roy, and R Laarach. 2021. ObjectivAIze: Measuring Performance and Biases in Augmented BusinessDecision Systems, Vol. 12934 LNCS. 300\u2013320.[13] J Bernard, M Hutter, M Zeppelzauer, D Fellner, and M Sedlmair. 2018. Comparing Visual-Interactive Labeling with Active Learning: An ExperimentalStudy. IEEE Transactions on Visualization and Computer Graphics 24, 1 (2018), 298\u2013308.[14] Astrid Bertrand, Rafik Belloum, James R Eagan, and Winston Maxwell. 2022. How cognitive biases affect XAI-assisted decision-making: Asystematic review. , 78\u201391 pages.[15] Astrid Bertrand, Tiphaine Viard, Rafik Belloum, James R Eagan, and Winston Maxwell. 2023. On Selective, Mutable and Dialogic XAI: a Review ofWhat Users Say about Different Types of Interactive Explanations. , 21 pages.[16] A Bhattacharya, J Ooge, G Stiglic, and K Verbert. 2023. Directive Explanations for Monitoring the Risk of Diabetes Onset: Introducing DirectiveData-Centric Explanations and Combinations to Support What-If Explorations. 204\u2013219.[17] E Bondi, R Koster, H Sheahan, M Chadwick, Y Bachrach, T Cemgil, U Paquet, and K Dvijotham. 2022. Role of Human-AI Interaction in SelectivePrediction, Vol. 36. 5286\u20135294.[18] M Brachman, Z Ashktorab, M Desmond, E Duesterwald, C Dugan, N N Joshi, Q Pan, and A Sharma. 2022. Reliance and Automation for Human-AICollaborative Data Labeling Conflict Resolution. inproceedings of the ACM on Human-Computer Interaction 6, CSCW2 (2022).[19] Z Bu\u00e7inca, P Lin, K Z Gajos, and E L Glassman. 2020. Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems.454\u2013464.17Under submission, 2023, C. Gomez et al.[20] Zana Bu\u00e7inca, Maja Barbara Malaya, and Krzysztof Z Gajos. 2021. To Trust or to Think: Cognitive Forcing Functions Can Reduce OverrelianceonAI in AI-Assisted Decision-Making. Proc. ACM Hum. -Comput. Interact. 5, CSCW1 (2021).[21] E Bunde. 2021. AI-assisted and explainable hate speech detection for social media moderators - A design science approach, Vol. 2020-January.1264\u20131273.[22] F Cabitza, A Campagner, C Natali, E Parimbelli, L Ronzio, and M Cameli. 2023. Painting the Black Box White: Experimental Findings from ApplyingXAI to an ECG Reading Setting. Machine Learning and Knowledge Extraction 5, 1 (2023), 269\u2013286.[23] \u00c1ngel Alexander Cabrera, Adam Perer, and Jason I Hong. 2023. Improving Human-AI Collaboration With Descriptions of AI Behavior. Proc. ACMHum. -Comput. Interact. 7, CSCW1 (2023).[24] Giacomo Cabri, Letizia Leonardi, Franco Zambonelli, et al. 2002. Modeling role-based interactions for agents. In The Workshop on Agent-orientedmethodologies at OOPSLA. Citeseer.[25] F M Calisto, C Santiago, N Nunes, and J C Nascimento. 2022. BreastScreening-AI: Evaluating medical intelligent agents for human-AI interactions.Artificial Intelligence in Medicine 127 (2022).[26] S Cao and C-M Huang. 2022. Understanding User Reliance on AI in Assisted Decision-Making. inproceedings of the ACM on Human-ComputerInteraction 6, CSCW2 (2022).[27] Tara Capel and Margot Brereton. 2023. What is Human-Centered about Human-Centered AI? A Map of the Research Landscape. In Proceedings ofthe 2023 CHI Conference on Human Factors in Computing Systems. 1\u201323.[28] Federico Maria Cau, Hanna Hauptmann, Lucio Davide Spano, and Nava Tintarev. 2023. Supporting High-Uncertainty Decisions through AI andLogic-StyleExplanations. , 251\u2013263 pages.[29] Haomin Chen, Catalina Gomez, Chien-Ming Huang, and Mathias Unberath. 2022. Explainable medical imaging AI needs human-centered design:guidelines and evidence from a systematic review. NPJ digital medicine 5, 1 (2022), 156.[30] Ruijia Cheng, Alison Smith-Renner, Ke Zhang, Joel R Tetreault, and Alejandro Jaimes. 2022. Mapping the design space of human-ai interaction intext summarization. arXiv preprint arXiv:2206.14863 (2022).[31] C-W Chiang and M Yin. 2021. You\u2019d Better Stop! Understanding Human Reliance on Machine Learning Models under Covariate Shift. 120\u2013129.[32] C-W Chiang and M Yin. 2022. Exploring the Effects of Machine Learning Literacy Interventions on Laypeople\u2019s Reliance on Machine LearningModels. 148\u2013161.[33] Porfirio David, Maya Cakmak, Allison Saupp\u00e9, Aws Albarghouthi, and Bilge Mutlu. 2022. Interaction Templates: A Data-Driven Approach forAuthoring Robot Programs.[34] Dominik Dellermann, Adrian Calma, Nikolaus Lipusch, Thorsten Weber, Sascha Weigel, and Philipp Ebel. 2021. The future of human-AIcollaboration: a taxonomy of design knowledge for hybrid intelligence systems. arXiv preprint arXiv:2105.03354 (2021).[35] M Desmond, M Muller, Z Ashktorab, C Dugan, E Duesterwald, K Brimijoin, C Finegan-Dollak, M Brachman, A Sharma, N N Joshi, and Q Pan. 2021.Increasing the Speed and Accuracy of Data Labeling through an AI Assisted Interface. 392\u2013401.[36] M Dikmen and C Burns. 2022. The effects of domain knowledge on trust in explainable AI and task performance: A case of peer-to-peer lending.International Journal of Human Computer Studies 162 (2022).[37] Yanqing Duan, John S Edwards, and Yogesh K Dwivedi. 2019. Artificial intelligence for decision making in the era of Big Data\u2013evolution, challengesand research agenda. International journal of information management 48 (2019), 63\u201371.[38] M Fan, X Yang, T Yu, Q V Liao, and J Zhao. 2022. Human-AI Collaboration for UX Evaluation: Effects of Explanation and Synchronization.inproceedings of the ACM on Human-Computer Interaction 6, CSCW1 (2022).[39] S Feng and J Boyd-Graber. 2022. Learning to Explain Selectively: A Case Study on Question Answering. 8372\u20138382.[40] R Fogliato, S Chappidi, M Lungren, P Fisher, D Wilson, M Fitzke, M Parkinson, E Horvitz, K Inkpen, and B Nushi. 2022. Who Goes First? Influencesof Human-AI Workflow on Decision Making in Clinical Imaging. 1362\u20131374.[41] A F\u00fcgener, J Grahl, A Gupta, and W Ketter. 2022. Cognitive Challenges in Human\u2013Artificial Intelligence Collaboration: Investigating the PathToward Productive Delegation. Information Systems Research 33, 2 (2022), 678\u2013696.[42] G. L. Liehner, P. Brauner, A. K. Schaar, and M. Ziefle. 2022. Delegation of Moral Tasks to Automated Agents\u2014The Impact of Risk and Context onTrusting a Machine to Perform a Task. IEEE Transactions on Technology and Society 3, 1 (2022), 46\u201357.[43] S Gaube, H Suresh, M Raue, E Lermer, T K Koch, M F C Hudecek, A D Ackery, S C Grover, J F Coughlin, D Frey, F C Kitamura, M Ghassemi, and EColak. 2023. Non-task expert physicians benefit from correct explainable AI advice when reviewing X-rays. Scientific Reports 13, 1 (2023).[44] Gerd Gigerenzer. 2008. WhyHeuristicsWork. Perspectives on Psychological Science 3, 1 (2008), 20\u201329. https://doi.org/10.1111/j.1745-6916.2008.00058.xarXiv:https://doi.org/10.1111/j.1745-6916.2008.00058.x PMID: 26158666.[45] Francesca Gino and Maurice E Schweitzer. 2008. TAKE THIS ADVICE AND SHOVE IT. , 5 pages.[46] C Gomez, M Unberath, and C-M Huang. 2023. Mitigating knowledge imbalance in AI-advised decision-making through collaborative userinvolvement. International Journal of Human Computer Studies 172 (2023).[47] N Grgic-Hlaca, C Engel, and K P Gummadi. 2019. Human decision making with machine advice: An experiment on bailing and jailing. inproceedingsof the ACM on Human-Computer Interaction 3, CSCW (2019).[48] Hongyan Gu, Yuan Liang, Yifan Xu, Christopher Kazu Williams, Shino Magaki, Negar Khanlou, Harry Vinters, Zesheng Chen, Shuo Ni, ChunxuYang, Wenzhong Yan, Xinhai Robert Zhang, Yang Li, Mohammad Haeri, and Xiang \u2018anthony\u2019 Chen. 2023. Improving Workflow Integration withXPath: Design and Evaluation of aHuman-AI Diagnosis System in Pathology. ACM Trans. Comput. -Hum. Interact. 30, 2 (2023).18Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,[49] Akshit Gupta, Debadeep Basu, Ramya Ghantasala, Sihang Qiu, and Ujwal Gadiraju. 2022. To Trust or Not To Trust: How a Conversational InterfaceAffects Trust in a Decision Support System. Association for Computing Machinery, Inc, 3531\u20133540.[50] Tessa Haesevoets, David De Cremer, Kim Dierckx, and Alain Van Hiel. 2021. Human-machine collaboration in managerial decision making.Computers in Human Behavior 119 (2021), 106730.[51] Patrick Hemmer, Max Schemmer, Michael V\u00f6ssing, and Niklas K\u00fchl. 2021. Human-AI Complementarity in Hybrid Intelligence Systems: AStructured Literature Review. PACIS (2021), 78.[52] P Hemmer, M Westphal, M Schemmer, S Vetter, M V\u00f8ssing, and G Satzger. 2023. Human-AI Collaboration: The Effect of AI Delegation on HumanTask Performance and Task Satisfaction. 453\u2013463.[53] L Hofeditz, S Clausen, A Rie\u00df, M Mirbabaie, and S Stieglitz. 2022. Applying XAI to an AI-based system for candidate management to mitigate biasand discrimination in hiring. Electronic Markets 32, 4 (2022), 2207\u20132233.[54] Kenneth Holstein, Maria De-Arteaga, Lakshmi Tumati, and Yanghuidi Cheng. 2023. Toward Supporting Perceptual Complementarity in Human-AICollaboration viaReflection on Unobservables. Proc. ACM Hum. -Comput. Interact. 7, CSCW1 (2023).[55] Yoyo Tsung-Yu Hou and Malte F Jung. 2021. Who is the Expert? Reconciling Algorithm Aversion and Algorithm Appreciation in AI-SupportedDecision Making. Proc. ACM Hum. -Comput. Interact. 5, CSCW2 (2021).[56] J Hwang, T Lee, H Lee, and S Byun. 2022. A Clinical Decision Support System for Sleep Staging Tasks with Explanations from Artificial Intelligence:User-Centered Design and Evaluation Study. Journal of Medical Internet Research 24, 1 (2022).[57] M Jacobs, M F Pradier, T H McCoy, R H Perlis, F Doshi-Velez, and K Z Gajos. 2021. How machine-learning recommendations influence cliniciantreatment selections: the example of the antidepressant selection. Translational Psychiatry 11, 1 (2021).[58] Johannes Jakubik, Jakob Sch\u00f6ffer, Vincent Hoge, Michael V\u00f6ssing, and Niklas K\u00fchl. 2023. An Empirical Evaluation of Predicted Outcomes asExplanations in Human-AI Decision-Making, Vol. 1752 CCIS. 353\u2013368.[59] J Jiang, S Kahai, and M Yang. 2022. Who needs explanation and when? Juggling explainable AI and user epistemic uncertainty. InternationalJournal of Human Computer Studies 165 (2022).[60] Daniel Kahneman. 2011. Thinking, Fast and Slow. Farrar, Straus and Giroux, New York.[61] P K Kahr, G Rooks, M C Willemsen, and C C P Snijders. 2023. It Seems Smart, but It Acts Stupid: Development of Trust in AI Advice in a RepeatedLegal Decision-Making Task. 528\u2013539.[62] P Khadpe, R Krishna, L Fei-Fei, J T Hancock, and M S Bernstein. 2020. Conceptual Metaphors Impact Perceptions of Human-AI Collaboration.inproceedings of the ACM on Human-Computer Interaction 4, CSCW2 (2020).[63] T Kim and H Song. 2023. Communicating the Limitations of AI: The Effect of Message Framing and Ownership on Trust in Artificial Intelligence.International Journal of Human-Computer Interaction 39, 4 (2023), 790\u2013800.[64] Geir Kirkeb\u00f8en, Erik Vasaasen, and Karl Halvor Teigen. 2013. Revisions and regret: The cost of changing your mind. Journal of Behavioral DecisionMaking 26, 1 (2013), 1\u201312.[65] Moritz K\u00f6rber. 2019. Theoretical considerations and development of a questionnaire to measure trust in automation. In Proceedings of the 20thCongress of the International Ergonomics Association (IEA 2018) Volume VI: Transport Ergonomics and Human Factors (TEHF), Aerospace HumanFactors and Ergonomics 20. Springer, 13\u201330.[66] A Kumar, T Patel, A S Benjamin, and M Steyvers. 2021. Explaining Algorithm Aversion with Metacognitive Bandits. 2780\u20132786.[67] V Lai, S Carton, R Bhatnagar, Q V Liao, Y Zhang, and C Tan. 2022. Human-AI Collaboration via Conditional Delegation: A Case Study of ContentModeration.[68] Vivian Lai, Chacha Chen, Alison Smith-Renner, Q Vera Liao, and Chenhao Tan. 2023. Towards a Science of Human-AI Decision Making: AnOverview of Design Space in Empirical Human-Subject Studies. , 1369\u20131385 pages.[69] Vivian Lai, Han Liu, and Chenhao Tan. 2020. \"Why is \u2019Chicago\u2019 Deceptive?\" Towards Building Model-Driven Tutorials for Humans. In Proceedingsof the 2020 CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA) (CHI \u201920). Association for Computing Machinery, NewYork, NY, USA, 1\u201313. https://doi.org/10.1145/3313831.3376873[70] J Lam Shin Cheung, A Ali, M Abdalla, and B Fine. 2022. U\u201cAI\u201d Testing: User Interface and Usability Testing of a Chest X-ray AI Tool in a SimulatedReal-World Workflow. Canadian Association of Radiologists Journal (2022).[71] M H Lee, D P Siewiorek, and A Smailagic. 2021. A human-ai collaborative approach for clinical decision making on rehabilitation assessment.[72] B Leichtmann, C Humer, A Hinterreiter, M Streit, and M Mara. 2023. Effects of Explainable Artificial Intelligence on trust and human behavior in ahigh-risk decision task. Computers in Human Behavior 139 (2023).[73] Gabriel A Le\u00f3n, Erin K Chiou, and Adam Wilkins. 2021. Accountability increases resource sharing: Effects of accountability on human and AIsystem performance. International Journal of Human\u2013Computer Interaction 37, 5 (2021), 434\u2013444.[74] M Lindvall, C Lundstr\u00f6m, and J L\u00f6wgren. 2021. Rapid Assisted Visual Search: Supporting Digital Pathologists with Imperfect AI. 504\u2013513.[75] H Liu, V Lai, and C Tan. 2021. Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI DecisionMaking. inproceedings of the ACM on Human-Computer Interaction 5, CSCW2 (2021).[76] M. A. Rahman, S. M. N. Sadat, A. T. Asyhari, N. Refat, M. N. Kabir, and R. A. Arshah. 2021. A Secure and Sustainable Framework to MitigateHazardous Activities in Online Social Networks. IEEE Transactions on Sustainable Computing 6, 1 (2021), 30\u201342.[77] KeMa and Jing Cao. 2019. Design pattern as a practical tool for designing adaptive interactions connecting human and social robots. , 613\u2013617 pages.19Under submission, 2023, C. Gomez et al.[78] M Mackeprang, C M\u00fcller-Birn, and M Stauss. 2019. Discovering the sweet spot of human\u2014computer configurations: A case study in informationextraction. inproceedings of the ACM on Human-Computer Interaction 3, CSCW (2019).[79] Maria Madsen and Shirley Gregor. 2000. Measuring human-computer trust. In 11th australasian conference on information systems, Vol. 53. Citeseer,6\u20138.[80] Magnus S. Magnusson. 2018. Temporal Patterns in Interactions: T-Patterns and Their Detection with THEMETM. Cambridge University Press, 323\u2013353.https://doi.org/10.1017/9781316286302.017[81] T Maier, J Menold, and C McComb. 2022. The Relationship Between Performance and Trust in AI in E-Finance. Frontiers in Artificial Intelligence 5(2022).[82] S Matthiesen, S Z Diederichsen, M K H Hansen, C Villumsen, M C H Lassen, P K Jacobsen, N Risum, B G Winkel, B T Philbert, J H Svendsen,and T O Andersen. 2021. Clinician preimplementation perspectives of a decision-support tool for the prediction of cardiac arrhythmia based onmachine learning: near-live feasibility and qualitative study. JMIR Human Factors 8, 4 (2021).[83] Julia A Minson and Jennifer S Mueller. 2012. The cost of collaboration: Why joint decision making exacerbates rejection of outside information.Psychological Science 23, 3 (2012), 219\u2013224.[84] Sina Mohseni, Niloofar Zarei, and Eric D Ragan. 2021. A multidisciplinary survey and framework for design and evaluation of explainable AIsystems. ACM Transactions on Interactive Intelligent Systems (TiiS) 11, 3-4 (2021), 1\u201345.[85] Molina and S S Sundar. 2022. When AI moderates online content: Effects of human collaboration and interactive transparency on user trust.Journal of Computer-Mediated Communication 27, 4 (2022).[86] Katelyn Morrison, Donghoon Shin, Kenneth Holstein, and Adam Perer. 2023. Evaluating the Impact of Human Explanation Strategies on Human-AIVisualDecision-Making. Proc. ACM Hum. -Comput. Interact. 7, CSCW1 (2023).[87] M Naiseh, D Al-Thani, N Jiang, and R Ali. 2023. How the different explanation classes impact trust calibration: The case of clinical decision supportsystems. International Journal of Human Computer Studies 169 (2023).[88] A T Nguyen, A Kharosekar, S Krishnan, E Tate, B C Wallace, and M Lease. 2018. Believe it or not: Designing a human-Ai partnership formixed-initiative fact-checking. 189\u2013199.[89] Mahsan Nourani, Chiradeep Roy, Jeremy E Block, Donald R Honeycutt, Tahrima Rahman, Eric Ragan, and Vibhav Gogate. 2021. Anchoring BiasAffects Mental Model Formation and User Reliance inExplainable AI Systems. , 340\u2013350 pages.[90] Aileen Oeberst and Roland Imhoff. 2023. Toward Parsimony in Bias Research: A Proposed Common Framework of Belief-Consistent InformationProcessing for a Set of Biases. Perspectives on Psychological Science (2023), 17456916221148147.[91] C Panigutti, A Beretta, F Giannotti, and D Pedreschi. 2022. Understanding the impact of explanations on advice-taking: a user study for AI-basedclinical Decision Support Systems.[92] Raja Parasuraman, Thomas B Sheridan, and Christopher D Wickens. 2000. A model for types and levels of human interaction with automation.IEEE Transactions on systems, man, and cybernetics-Part A: Systems and Humans 30, 3 (2000), 286\u2013297.[93] Joon Sung Park, Rick Barber, Alex Kirlik, and Karrie Karahalios. 2019. A Slow Algorithm Improves Users\u2019 Assessments of the Algorithm\u2019s Accuracy.Proc. ACM Hum. -Comput. Interact. 3, CSCW (2019).[94] A Peng, B Nushi, E Kiciman, K Inkpen, and E Kamar. 2022. Investigations of Performance and Bias in Human-AI Teamwork in Hiring, Vol. 36.12089\u201312097.[95] T Porat, I J Marshall, E Sadler, M A Vadillo, C McKevitt, C D AWolfe, and V Curcin. 2019. Collaborative design of a decision aid for stroke survivorswith multimorbidity: A qualitative study in the UK engaging key stakeholders. BMJ Open 9, 8 (2019).[96] S Prabhudesai, L Yang, S Asthana, X Huan, Q Vera Liao, and N Banovic. 2023. Understanding Uncertainty: How Lay Decision-makers Perceive andInterpret Uncertainty in Human-AI Decision Making. 379\u2013396.[97] C Rastogi, Y Zhang, D Wei, K R Varshney, A Dhurandhar, and R Tomsett. 2022. Deciding Fast and Slow: The Role of Cognitive Biases in AI-assistedDecision-making. inproceedings of the ACM on Human-Computer Interaction 6, CSCW1 (2022).[98] A Rechkemmer and M Yin. 2022. When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in MachineLearning Models.[99] A David Redish. 2013. The mind within the brain: How we make decisions and how those decisions go wrong. Oxford University Press, USA.[100] Reverberi C, Rigon T, Solari A, Hassan C, Cherubini P, and Cherubini A. 2022. Experimental evidence of effective human-AI collaboration inmedical decision-making. Sci Rep 12, 1 (2022), 14952.[101] M Riveiro and S Thill. 2021. \u201cThat\u2019s (not) the output I expected!\u201d On the role of end user expectations in creating explanations of AI systems.Artificial Intelligence 298 (2021).[102] Maria Riveiro and Serge Thill. 2022. The Challenges of Providing Explanations of AI Systems When They Do NotBehave like Users Expect. ,110\u2013120 pages.[103] Vincent Robbemond, Oana Inel, and Ujwal Gadiraju. 2022. Understanding the Role of Explanation Modality in AI-AssistedDecision-Making. ,223\u2013233 pages.[104] Allison Saupp\u00e9 and Bilge Mutlu. 2014. Design patterns for exploring and prototyping human-robot interactions. , 1439\u20131448 pages.[105] M Schaekermann, G Beaton, E Sanoubari, A Lim, K Larson, and E Law. 2020. Ambiguity-aware AI Assistants for Medical Data Analysis.[106] M Schemmer, N Kuehl, C Benz, A Bartos, and G Satzger. 2023. Appropriate Reliance on AI Advice: Conceptualization and the Effect of Explanations.International Conference on Intelligent User Interfaces, inproceedings IUI (2023), 410\u2013422.20Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,[107] Sebastian Schleidgen, Orsolya Friedrich, Selin Gerlek, Galia Assadi, and Johanna Seifert. 2023. The concept of \u201cinteraction\u201d in debates onhuman\u2013machine interaction. Humanities and Social Sciences Communications 10, 1 (2023), 1\u201313.[108] T Schrills and T Franke. 2020. Color for characters - Effects of visual explanations of AI on trust and observability, Vol. 12217 LNCS. 121\u2013135.[109] Ruey-Kai Sheu and Mayuresh Sunil Pardeshi. 2022. A Survey on Medical Explainable AI (XAI): Recent Progress, Explainability Approach, HumanInteraction and Scoring System. Sensors 22, 20 (2022), 8068.[110] A Silva, M Schrum, E Hedlund-Botti, N Gopalan, and M Gombolay. 2023. Explainable Artificial Intelligence: Evaluating the Objective and SubjectiveImpacts of xAI on Human-Agent Interaction. 39, 7 (2023), 1390\u20131404.[111] Viridiana Silva-Rodr\u00edguez, Sandra Edith Nava-Mu\u00f1oz, Luis A Castro, Francisco E Mart\u00ednez-P\u00e9rez, H\u00e9ctor G P\u00e9rez-Gonz\u00e1lez, and FranciscoTorres-Reyes. 2020. Classifying design-level requirements using machine learning for a recommender of interaction design patterns. IET Software14, 5 (2020), 544\u2013552.[112] Rod Sims. 1997. Interactivity: A forgotten art? Computers in human behavior 13, 2 (1997), 157\u2013180.[113] A Smith-Renner, R Fan, M Birchfield, T Wu, J Boyd-Graber, D S Weld, and L Findlater. 2020. No Explainability without Accountability: An EmpiricalStudy of Explanations and Feedback in Interactive ML.[114] M C Stites, M Nyre-Yu, B Moss, C Smutz, and M R Smith. 2021. Sage Advice? The Impacts of Explanations for Machine Learning Models on HumanDecision-Making in Spam Detection, Vol. 12797 LNAI. 269\u2013284.[115] H Suresh, N Lao, and I Liccardi. 2020. Misplaced Trust: Measuring the Interference of Machine Learning in Human Decision-Making. 315\u2013324.[116] H Suresh, K M Lewis, J Guttag, and A Satyanarayan. 2022. Intuitively Assessing ML Model Reliability through Example-Based Explanations andEditing Model Inputs. 767\u2013781.[117] Heliodoro Tejeda, Aakriti Kumar, Padhraic Smyth, and Mark Steyvers. 2022. AI-assisted decision-making: A cognitive modeling approach to inferlatent reliance strategies. Computational Brain & Behavior 5, 4 (2022), 491\u2013508.[118] S Tolmeijer, M Christen, S Kandul, M Kneer, and A Bernstein. 2022. Capable but Amoral? Comparing AI and Human Expert Collaboration inEthical Decision Making.[119] S Tolmeijer, U Gadiraju, R Ghantasala, A Gupta, and A Bernstein. 2021. Second chance for a first impression? Trust development in intelligentsystem interaction. 77\u201387.[120] P Tschandl, C Rinner, Z Apalla, G Argenziano, N Codella, A Halpern, M Janda, A Lallas, C Longo, J Malvehy, J Paoli, S Puig, C Rosendahl, H PSoyer, I Zalaudek, and H Kittler. 2020. Human\u2013computer collaboration for skin cancer recognition. Nature Medicine 26, 8 (2020), 1229\u20131234.[121] A A Tutul, E H Nirjhar, and T Chaspari. 2021. Investigating Trust in Human-Machine Learning Collaboration: A Pilot Study on Estimating PublicAnxiety from Speech. 288\u2013296.[122] Niels Van Berkel, Maura Bellio, Mikael B Skov, and Ann Blandford. 2023. Measurements, algorithms, and presentations of reality: Framinginteractions with AI-enabled decision support. ACM Transactions on Computer-Human Interaction 30, 2 (2023), 1\u201333.[123] N Van Berkel, J Opie, O F Ahmad, L Lovat, D Stoyanov, and A Blandford. 2022. Initial Responses to False Positives in AI-Supported ContinuousInteractions: A Colonoscopy Case Study. ACM Transactions on Interactive Intelligent Systems 12, 1 (2022).[124] Niels Van Berkel, Mikael B Skov, and Jesper Kjeldskov. 2021. Human-AI interaction: intermittent, continuous, and proactive. Interactions 28, 6(2021), 67\u201371.[125] A van den Brandt, M Christopher, L M Zangwill, J Rezapour, C Bowd, S L Baxter, D S Welsbie, A Camp, S Moghimi, J L Do, R N Weinreb, C C PSnijders, and M A Westenberg. 2020. GLANCE: Visual Analytics for Monitoring Glaucoma Progression, Vol. 2020-September. 85\u201396.[126] Jasper van der Waa, Sabine Verdult, Karel van den Bosch, Jurriaan van Diggelen, Tjalling Haije, Birgit van der Stigchel, and Ioana Cocu. 2021.Moral decision making in human-agent teams: Human control and the role of explanations. Frontiers in Robotics and AI 8 (2021), 640647.[127] Oleksandra Vereschak, Gilles Bailly, and Baptiste Caramiaux. 2021. How to evaluate trust in AI-assisted decision making? A survey of empiricalmethodologies. Proceedings of the ACM on Human-Computer Interaction 5, CSCW2 (2021), 1\u201339.[128] K Vodrahalli, R Daneshjou, T Gerstenberg, and J Zou. 2022. Do humans trust advice more if it comes from ai? an analysis of human-Ai interactions.763\u2013777.[129] M V\u00f6ssing, N K\u00fchl, M Lind, and G Satzger. 2022. Designing Transparency for Effective Human-AI Collaboration. Information Systems Frontiers 24,3 (2022), 877\u2013895.[130] Ruiqian Wang, Guanghui Fu, Jianqiang Li, and Yan Pei. 2022. Diagnosis after zooming in: A multilabel classification model by imitating doctorreading habits to diagnose brain diseases. Medical Physics 49, 11 (2022), 7054\u20137070.[131] X Wang and M Yin. 2021. Are Explanations Helpful? A Comparative Study of the Effects of Explanations in AI-Assisted Decision-Making. 318\u2013328.[132] Wen Wen and Hiroshi Imamizu. 2022. The sense of agency in perception, behaviour and human\u2013machine interactions. Nature Reviews Psychology1, 4 (2022), 211\u2013222.[133] M Westphal, M V\u00f6ssing, G Satzger, G B Yom-Tov, and A Rafaeli. 2023. Decision control and explanations in human-AI collaboration: Improvinguser perceptions and compliance. Computers in Human Behavior 144 (2023).[134] Y Wu, K J Kim, and Y Mou. 2022. Minority social influence and moral decision-making in human\u2013AI interaction: The effects of identity andspecialization cues. New Media and Society (2022).[135] Wei Xiong, Chen Wang, and Liang Ma. 2023. Partner or subordinate? Sequential risky decision-making behaviors under human-machinecollaboration contexts. Computers in Human Behavior 139 (2023), 107556.21Under submission, 2023, C. Gomez et al.[136] Ji Soo Yi, Youn ah Kang, John Stasko, and Julie A Jacko. 2007. Toward a deeper understanding of the role of interaction in information visualization.IEEE transactions on visualization and computer graphics 13, 6 (2007), 1224\u20131231.[137] Kun Yu, Shlomo Berkovsky, Ronnie Taib, Jianlong Zhou, and Fang Chen. 2019. Do I Trust My Machine Teammate? An Investigation from PerceptiontoDecision. , 460\u2013468 pages.[138] Zahra Zahedi and Subbarao Kambhampati. 2021. Human-AI symbiosis: A survey of current approaches. arXiv preprint arXiv:2103.09990 (2021).[139] Qiaoning Zhang, Matthew L Lee, and Scott Carter. 2022. You Complete Me: Human-AI Teams and Complementary Expertise.[140] W Zhang and B Y Lim. 2022. Towards Relatable Explainable AI with the Perceptual Process.[141] Yunfeng Zhang, Q Vera Liao, and Rachel KE Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in AI-assisteddecision making. , 295\u2013305 pages.[142] Yunfeng Zhang, Q Vera Liao, and Rachel K E Bellamy. 2020. Effect of Confidence and Explanation on Accuracy and Trust Calibration inAI-AssistedDecision Making. , 295\u2013305 pages.[143] J Zhou, S Z Arshad, S Luo, and F Chen. 2017. Effects of uncertainty and cognitive load on user trust in predictive decision making, Vol. 10516 LNCS.23\u201339.[144] A Zytek, D Liu, R Vaithianathan, and K Veeramachaneni. 2022. Sibyl: Understanding and Addressing the Usability Challenges of Machine Learningin High-Stakes Decision Making. IEEE Transactions on Visualization and Computer Graphics 28, 1 (2022), 1161\u20131171.APPENDIXA SEARCH STRATEGYWe used the following search string to screen titles, abstracts, and keywords in all the databases consulted:(artificial intelligence OR machine learning OR deep learning OR neural network OR ai technology OR ai assistanceOR ai OR algorithm OR hybrid intelligence) AND (human-ai collaboration OR human-ai interaction OR human-centeredOR human centered OR human-ai teaming) AND (decision-making tasks OR ai decisions OR ai-assisted decision ORdecision-making OR ai predictions OR ai-assisted decision-making OR ai-assisted diagnosis) AND (interaction ORinteraction design OR interaction paradigm OR interface design)We excluded articles with (\u201csurvey\" OR \u201cworkshop\" OR \u201cguideline\" OR \"review\") and (\u201crobot\" OR \u201cgame\" OR \u201cgaming\"OR \u201cdriving\" OR \u201cautonomous vehicle\" OR \u201ccar\" OR \u201cAV\") in the title and abstract.B SURVEY FINDINGSTable 2. Metrics used to study AI-assisted decision making, grouped by domain. We classify metrics by the construct they werecapturing and whether the correspond to objective or subjective measures.Domain Metrics No. papersArtificialObjectiveefficacy: decision accuracy 5trust and reliance: user-AI agreement, delegation to AI rate,compliance frequency, gaze duration on AI10efficiency: decision time 4Subjectiveefficacy: perceived team performance, perceived expertise 4trust and reliance: competence, predictability, dependability,responsibility, faith, reliability, trustworthiness, conformity,perceived expertise, perceived user-AI agreement8system usability: usefulness, helpfulness, pleasure 3decision satisfaction & mental demand: self-confidence,confidence in task, perceived AI\u2019s willingness tocollaborate, cognitive load522Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,understanding: understanding of the system 1fairness: responsibility attribution of loss 1other: decision risk perception 1EducationObjectiveefficacy: decision accuracy 1trust and reliance: user-AI agreement 1Subjectivetrust and reliance: reliability, trustworthiness, intention tocomply1Finance/BusinessObjectiveefficacy: decision accuracy, errors, performance 11trust and reliance: user-AI agreement, delegation to AI rate,weight of advice, decision outcome, overreliance,compliance frequency, number of options explored by user,decision time13efficiency: task duration, number of options explored byuser, decision time3Subjectiveefficacy: perceived self performance, perceived modelperformance2trust and reliance: reliability, trustworthiness, intention tocomply8system usability: usefulness, enjoyment, satisfaction 3decision satisfaction & mental demand: confidence in task,task difficulty, task complexity3understanding: understanding of the system,understanding of the tutorial2other: decision strategies, quality of explanations,perception of uncertainty information, interpretation andincorporation of uncertainty information into finalrecommendations3GenericObjectiveefficacy: decision accuracy 16trust and reliance: user-AI agreement, delegation to AI rate,weight of advice, overtrust, undertrust, compliancefrequency, decision time13efficiency: task duration, decision time 4Subjectiveefficacy: perceived model accuracy, perceived taskperformance, perceived model capability, perceived selfperformance2trust and reliance: reliability, trustworthiness, perceived AIuncertainty, perceived credibility, perceived agreement9system usability: usefulness, satisfaction, helpfulness,likeliness to use again723Under submission, 2023, C. Gomez et al.decision satisfaction & mental demand: confidence in task,frustration4understanding: understanding of the system 3efficiency: perceived efficiency, perceived effectiveness 1fairness: perceived AI contribution, perceived teamwork 1other: quality of explanations, feedback importance,helpfulness of visualization, suggestions6HealthcareObjectiveefficacy: decision accuracy, specificity, sensitivity,coefficient of variability, inter-rater reliability17trust and reliance: user-AI agreement, delegation to AI rate,weight of advice, overtrust, compliance frequency, decisiontime, appropriate trust, dominance10efficiency: task duration, decision time, number of taskscompleted7other: user epistemic uncertainty 1Subjectiveefficacy: perceived model accuracy 3trust and reliance: reliability, trustworthiness, integrabilityperception12system usability: usefulness, satisfaction, perceivedacceptance, possibility of adoption/implementation,perceived hindrance due to AI, richness, perceived utility11decision satisfaction & mental demand: confidence in task,confidence in AI, mental support, workload, task difficulty11understanding: understanding of the system, explainability,predictability4efficiency: perceived efficiency 2fairness: moral compliance, feeling of control 2other: quality and usefulness of explanations, perceptionfree text5LabelingObjectiveefficacy: decision accuracy, F-1 score, precision, recall 7trust and reliance: user-AI agreement, overreliance,decision time, delegation to AI rate5efficiency: task duration, decision time, number of taskscompleted5Subjectivetrust and reliance: reliance, perceived AI uncertainty,trustworthiness, perceived agreement3system usability: usefulness, acceptance, usability 3decision satisfaction & mental demand: confidence in task,self-confidence, satisfaction4understanding: observability 124Designing AI Support for Human Involvement in AI-assisted Decision Making Under submission, 2023,fairness: perceived AI contribution 5LawObjectiveefficacy: decision accuracy 3trust and reliance: decision time, compliance frequency,appropriate trust, overtrust, undertrust, user-AI agreement,weight on advice5efficiency: decision time 1understanding: objective understanding 1Subjectivetrust and reliance: trustworthiness 2system usability: usefulness, helpfulness 2decision satisfaction & mental demand: confidence in task 3understanding: subjective understanding 1other: self-reported decision-making strategies 1LeisureObjective efficiency: duration of interaction, word count 1Subjectivesystem usability: perceived usability and warmth, intentionto adopt, desire to cooperate1ProfessionalObjectiveefficacy: decision accuracy, true positive rate 2trust and reliance: user-AI agreement 2Subjective system usability: usefulness 1Social MediaObjectiveefficacy: decision accuracy and union precision, true andfalse positive difference2trust and reliance: user-AI agreement, compliancefrequency2Subjectivetrust and reliance: observed security, reliability, faith,perceived agreement, trustworthiness5efficacy: perceived model accuracy & competence 3system usability: usefulness, ease of use, intention to use 1decision satisfaction and mental demand: confidence intask, workload1understanding: understanding of the system 2OtherObjectiveefficacy: decision accuracy, precision, recall 3trust and reliance: user-AI agreement, compliancefrequency, overreliance5Subjectivetrust and reliance: trustworthiness, perceived credibility 5system usability: helpfulness, system complexity,satisfaction3decision satisfaction & mental demand: confidence in task,mental demand2fairness: responsibility attribution 1understanding: understanding of the system 225Under submission, 2023, C. Gomez et al.Fig. 3. PRISMA diagram for article selection in this survey.Received 20 February 2007; revised 12 March 2009; accepted 5 June 200926",
      "id": 152503205,
      "identifiers": [
        {
          "identifier": "596213960",
          "type": "CORE_ID"
        },
        {
          "identifier": "2310.19778",
          "type": "ARXIV_ID"
        },
        {
          "identifier": "oai:arxiv.org:2310.19778",
          "type": "OAI_ID"
        }
      ],
      "title": "Designing AI Support for Human Involvement in AI-assisted Decision\n  Making: A Taxonomy of Human-AI Interactions from a Systematic Review",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:arxiv.org:2310.19778"
      ],
      "publishedDate": "2023-10-31T00:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "http://arxiv.org/abs/2310.19778"
      ],
      "updatedDate": "2024-01-18T00:05:19",
      "yearPublished": 2023,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "http://arxiv.org/abs/2310.19778"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/152503205"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Dignum, Frank"
        },
        {
          "name": "Erdogan, Emre"
        },
        {
          "name": "Verbrugge, Rineke"
        },
        {
          "name": "Yolum, P\u0131nar"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Ajmeri, Nirav",
        "Morris Martin, Andreasa",
        "Savarimuthu, Bastin Tony"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/581187913",
        "https://api.core.ac.uk/v3/outputs/581197414"
      ],
      "createdDate": "2023-09-04T10:50:40",
      "dataProviders": [
        {
          "id": 5394,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/5394",
          "logo": "https://api.core.ac.uk/data-providers/5394/logo"
        },
        {
          "id": 5364,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/5364",
          "logo": "https://api.core.ac.uk/data-providers/5364/logo"
        },
        {
          "id": 5375,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/5375",
          "logo": "https://api.core.ac.uk/data-providers/5375/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "In everyday life, people often depend on their theory of mind, i.e., their ability to reason about unobservable mental content of others to understand, explain, and predict their behaviour. Many agent-based models have been designed to develop computational theory of mind and analyze its effectiveness in various tasks and settings. However, most existing models are not generic (e.g., only applied in a given setting), not feasible (e.g., require too much information to be processed), or not human-inspired (e.g., do not capture the behavioral heuristics of humans). This hinders their applicability in many settings. Accordingly, we propose a new computational theory of mind, which captures the human decision heuristics of reasoning by abstracting individual beliefs about others. We specifically study computational affinity and show how it can be used in tandem with theory of mind reasoning when designing agent models for human-agent negotiation. We perform two-agent simulations to analyze the role of affinity in getting to agreements when there is a bound on the time to be spent for negotiating. Our results suggest that modeling affinity can ease the negotiation process by decreasing the number of rounds needed for an agreement as well as yield a higher benefit for agents with theory of mind reasoning.</p",
      "doi": "10.1007/978-3-031-20845-4_6",
      "downloadUrl": "https://core.ac.uk/download/581191271.pdf",
      "fieldOfStudy": null,
      "fullText": "   University of GroningenComputational Theory of\u00a0Mind for\u00a0Human-Agent CoordinationErdogan, Emre; Dignum, Frank; Verbrugge, Rineke; Yolum, P\u0131narPublished in:Coordination, Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems XV -International Workshop, COINE 2022, Revised Selected PapersDOI:10.1007/978-3-031-20845-4_6IMPORTANT NOTE: You are advised to consult the publisher's version (publisher's PDF) if you wish to cite fromit. Please check the document version below.Document VersionPublisher's PDF, also known as Version of recordPublication date:2022Link to publication in University of Groningen/UMCG research databaseCitation for published version (APA):Erdogan, E., Dignum, F., Verbrugge, R., & Yolum, P. (2022). Computational Theory of\u00a0Mind for\u00a0Human-Agent Coordination. In N. Ajmeri, A. Morris Martin, & B. T. Savarimuthu (Eds.), Coordination,Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems XV - InternationalWorkshop, COINE 2022, Revised Selected Papers (pp. 92-108). (Lecture Notes in Computer Science(including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics); Vol. 13549LNAI). Springer Science and Business Media Deutschland GmbH. https://doi.org/10.1007/978-3-031-20845-4_6CopyrightOther than for strictly personal use, it is not permitted to download or to forward/distribute the text or part of it without the consent of theauthor(s) and/or copyright holder(s), unless the work is under an open content license (like Creative Commons).The publication may also be distributed here under the terms of Article 25fa of the Dutch Copyright Act, indicated by the \u201cTaverne\u201d license.More information can be found on the University of Groningen website: https://www.rug.nl/library/open-access/self-archiving-pure/taverne-amendment.Take-down policyIf you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediatelyand investigate your claim.Downloaded from the University of Groningen/UMCG research database (Pure): http://www.rug.nl/research/portal. For technical reasons thenumber of authors shown on this cover page is limited to 10 maximum.Download date: 01-11-2023Nirav AjmeriAndreasa Morris MartinBastin Tony Roy Savarimuthu (Eds.) 123LNAI 13549International Workshop, COINE 2022 Virtual Event, May 9, 2022 Revised Selected PapersCoordination, Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems XVLecture Notes in Artificial Intelligence 13549Subseries of Lecture Notes in Computer ScienceSeries EditorsRandy GoebelUniversity of Alberta, Edmonton, CanadaWolfgang WahlsterDFKI, Berlin, GermanyZhi-Hua ZhouNanjing University, Nanjing, ChinaFounding EditorJ\u00f6rg SiekmannDFKI and Saarland University, Saarbr\u00fccken, GermanyMore information about this subseries at https://link.springer.com/bookseries/1244Nirav Ajmeri \u00b7 Andreasa Morris Martin \u00b7Bastin Tony Roy Savarimuthu (Eds.)Coordination, Organizations,Institutions, Norms, and Ethicsfor Governanceof Multi-Agent Systems XVInternational Workshop, COINE 2022Virtual Event, May 9, 2022Revised Selected PapersEditorsNirav AjmeriUniversity of BristolBristol, UKBastin Tony Roy SavarimuthuUniversity of OtagoDunedin, New ZealandAndreasa Morris MartinUniversity of BathBath, UKISSN 0302-9743 ISSN 1611-3349 (electronic)Lecture Notes in Artificial IntelligenceISBN 978-3-031-20844-7 ISBN 978-3-031-20845-4 (eBook)https://doi.org/10.1007/978-3-031-20845-4LNCS Sublibrary: SL7 \u2013 Artificial Intelligence\u00a9 The Editor(s) (if applicable) and The Author(s), under exclusive licenseto Springer Nature Switzerland AG 2022This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of thematerial is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation,broadcasting, reproduction on microfilms or in any other physical way, and transmission or informationstorage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology nowknown or hereafter developed.The use of general descriptive names, registered names, trademarks, service marks, etc. in this publicationdoes not imply, even in the absence of a specific statement, that such names are exempt from the relevantprotective laws and regulations and therefore free for general use.The publisher, the authors, and the editors are safe to assume that the advice and information in this book arebelieved to be true and accurate at the date of publication. Neither the publisher nor the authors or the editorsgive a warranty, expressed or implied, with respect to the material contained herein or for any errors oromissions that may have been made. The publisher remains neutral with regard to jurisdictional claims inpublished maps and institutional affiliations.This Springer imprint is published by the registered company Springer Nature Switzerland AGThe registered company address is: Gewerbestrasse 11, 6330 Cham, SwitzerlandPrefaceCoordination, organizations, institutions, norms and ethics (COINE) are five key gov-ernance elements that regulate the functioning of open multi-agent systems. The goalof the COINE workshop series that began in 2006 is to bring together researchers inautonomous agents and multi-agent systems (MAS) working on these five topics. Theworkshop focuses on both scientific and technological aspects of social coordination,organizational theory, artificial (electronic) institutions, normative and ethical MAS.This edition of the COINE workshop, co-located with the 21st International Confer-ence on Autonomous Agents and Multi-Agent Systems (AAMAS), was held virtually(through Zoom) due to the COVID-19, on May 9, 2022. A total of 15 papers were sub-mitted to the workshop and 14 were accepted after peer review (11 full and three short).These papers were reviewed by three Program Committee members using a single-blindreview method.The papers were presented in three sessions. About 30 participants attended theworkshop. This workshop also featured an invited talk on \u201cConsent as a Foundationfor Responsible Autonomy\u201d from Munindar P. Singh, North Carolina State University,USA. The abstract of the talk is included in this volume.This volume contains extended and revised versions of the 14 papers accepted to theworkshop. The revisions made to the papers were reviewed by one reviewer, and thisformed the second round of peer review. We are confident this process has resulted inhigh-quality papers.The workshop could not have taken place without the contribution of many people.We are very grateful to our invited speaker as well as to all the COINE 2022 partic-ipants who took part in the discussions. We thank all the members of the ProgramCommittee for their hard work (who are listed after this preface), and the guidanceoffered by the COIN(E) Champions. We also thank EasyChair for the use of theirconference management system. Thanks also goes to the Springer for publishing thepost-proceedings.September 2022 Nirav AjmeriAndreasa Morris MartinBastin Tony Roy SavarimuthuOrganizationChairsNirav Ajmeri University of Bristol, UKAndreasa Morris Martin University of Bath, UKBastin Tony Roy Savarimuthu University of Otago, New ZealandProgram CommitteeHuib Aldewereld HU University of Applied Sciences, NetherlandsNatasha Alechina Utrecht University, NetherlandsStefania Costantini University of L\u2019Aquila, ItalyMarina De Vos University of Bath, UKNicoletta Fornara Universit\u00e0 della Svizzera italiana, SwitzerlandChristopher Frantz Norwegian University of Science and Technology,NorwayBenjamin Kuipers University of Michigan, USAMaite L\u00f3pez-S\u00e1nchez University of Barcelona, SpainEric Matson Purdue University, USAJuan Carlos Nieves Ume\u00e4 University, SwedenPablo Noriega IIIA-CSIC, SpainJulian Padget University of Bath, UKLu\u00eds Moniz Pereira Universidade Nova de Lisboa, PortugalJaime Sim\u00e3o Sichman Universidade de S\u00e3o Paulo, BrazilM. Birna van Riemsdijk University of Twente, NetherlandsHarko Verhagen Stockholm University, SwedenP\u0131nar Yolum Utrecht University, NetherlandsConsent as a Foundation for Responsible Autonomy(Abstracts)Munindar P. SinghNorth Carolina State University, Raleigh NC 27695, USAmpsingh@ncsu.eduAbstract.This talk focuses on a dynamic aspect of responsible autonomy,namely, to make intelligent agents act responsibly at run time. That is, itconsiders settings where decision making by agents impinges upon theoutcomes perceived by other agents. For an agent to act responsibly, itmust accommodate the desires and other attitudes of its users and, throughother agents, of their users.The contribution of this talk is twofold. First, it provides a concep-tual analysis of consent, its benefits and misuses, and how understandingconsent can help achieve responsible autonomy. Second, it outlines chal-lenges for AI (in particular, for agents and multiagent systems) that meritinvestigation to form a basis for modeling consent in multiagent systemsand applying consent to achieve responsible autonomy.ContentsDesigning International Humanitarian Law into Military AutonomousDevices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1Jonathan Kwik, Tomasz Zurek, and Tom van EngersEpistemic Diversity and Explanatory Adequacy in Distributed InformationProcessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19Asimina Mertzani, Jeremy Pitt, Andrzej Nowak, and Tomasz MichalakThe Complexity of Norm Synthesis and Revision . . . . . . . . . . . . . . . . . . . . . . . . . . 38Davide Dell\u2019Anna, Natasha Alechina, Fabiano Dalpiaz, Mehdi Dastani,Maarten L\u00f6ffler, and Brian LoganEmbracing AWKWARD! Real-Time Adjustment of Reactive Plans UsingSocial Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54Leila Methnani, Andreas Antoniades, and Andreas TheodorouSelf-learning Governance of Black-Box Multi-Agent Systems . . . . . . . . . . . . . . . 73Michael Oesterle, Christian Bartelt, Stefan L\u00fcdtke,and Heiner StuckenschmidtComputational Theory of Mind for Human-Agent Coordination . . . . . . . . . . . . . . 92Emre Erdogan, Frank Dignum, Rineke Verbrugge, and P\u0131nar YolumComputational Discovery of Transaction-Based Financial Crimevia Grammatical Evolution: The Case of Ponzi Schemes . . . . . . . . . . . . . . . . . . . . 109Peter Fratric\u030c, Giovanni Sileno, Tom van Engers, and Sander KlousCentralized Norm Enforcement in Mixed-Motive MultiagentReinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121Rafael M. Cheang, Anarosa A. F. Brand\u00e3o, and Jaime S. SichmanSupporting the Reasoning About Environmental Consequencesof Institutional Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134Rafhael R. Cunha, Jomi F. H\u00fcbner, and Maiquel de BritoSocial Motives and Social Contracts in Cooperative Survival Games . . . . . . . . . . 148Matthew Scott, Mathieu Dubied, and Jeremy PittEvaluating Human and Agent Task Allocators in Ad Hoc Human-AgentTeams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167Sami Abuhaimed and Sandip Senx ContentsFleur: Social Values Orientation for Robust Norm Emergence . . . . . . . . . . . . . . . 185Sz-Ting Tzeng, Nirav Ajmeri, and Munindar P. SinghReasoning About Collective Action in Markov Logic: A Case Studyfrom Classical Athens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201Sriashalya Srivathsan, Stephen Cranefield, and Jeremy PittDesign Heuristics for Ethical Online Institutions . . . . . . . . . . . . . . . . . . . . . . . . . . . 213Pablo Noriega, Harko Verhagen, Julian Padget, and Mark d\u2019InvernoAuthor Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231Designing International HumanitarianLaw into Military Autonomous DevicesJonathan Kwik1 , Tomasz Zurek2(B) , and Tom van Engers31 Faculty of Law, University of Amsterdam, Amsterdam, The Netherlandsh.c.j.kwik@uva.nl2 T.M.C. Asser Institute, R.J. Schimmelpennincklaan 20-22, 2517 JN The Hague,The Netherlandst.zurek@asser.nl3 Complex Cyber Infrastructure, Informatics Institute, University of Amsterdam,Amsterdam, The NetherlandsT.M.vanEngers@uva.nlAbstract. This position paper presents a discussion on the problem ofimplementing the rules of International Humanitarian Law in AI-drivenmilitary autonomous devices. We introduce a structure of a hybrid data-and knowledge-driven computational framework of a hypothetical target-ing system built from the ground up with IHL compliance in mind. Weprovide a model and a discussion of necessary legal tests and variables.Keywords: Military AI \u00b7 International Humanitarian Law \u00b7Autonomous devices \u00b7 Autonomous weapon1 IntroductionThe application of artificial intelligence (AI) in weapon systems has become amajor point of contention in the past decade. While many States have embracedthe potential that AI brings for increasing precision and speed, improving theirwarfighting capacity, and reducing unneeded casualties [30,46], a significantopposition group has also formed which contests whether AI can ever be usedin military contexts in a lawful and ethical manner [44].One point which is not in debate is the applicability of international human-itarian law (IHL), the body of international law which governs the conduct ofparties to an armed conflict. In particular, IHL [2] provides that belligerentsdo not have full freedom in their choice of means of warfare, i.e., the weaponsthey deploy. Any new weapon adopted by belligerents must be in compliance toIHL, and any new technology introduced must conform itself to these existingrules [25]. This includes AI. States [6,48], international organisations and NGOs[24,34] and commentators [39,46] universally agree that any weapon systemwhich incorporates AI must uphold IHL.Tomasz Zurek received funding from the Dutch Research Council (NWO) Platformfor Responsible Innovation (NWO-MVI) as part of the DILEMA Project on DesigningInternational Law and Ethics into Military Artificial Intelligence.c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 1\u201318, 2022.https://doi.org/10.1007/978-3-031-20845-4_12 J. Kwik et al.In light of this universal point of departure, there has been disagreementwhether AI can actually be designed to comply with the legal rules. Many haveexpressed doubt that this can be done, arguing that AI will never be able toreplace humans in this regard [42]. Those that elaborate usually point to themany (subjective) variables involved in IHL decisions and that these legal eval-uations can only practically be effectuated by humans, not by the narrow AI oftoday [9]. In particular, the principles of distinction and proportionality in IHLare frequently cited as examples of rules which would be impossible to imple-ment through AI [43]. Indeed, if a system is unable to properly execute thesetests but is deployed regardless for tasks which would require it to conduct suchlegal assessments, it would be deployed unlawfully.In this article, we counterbalance this perspective by proposing a structure ofa hypothetical system which is constructed from the ground up with IHL rulesin mind. The basic structure of the system is based on a commander\u2019s targetingcycle. During this process, commanders rigorously conduct several evaluationsderived from IHL, and it is one of the primary mechanisms which ensure thatprinciples such as distinction and proportionality are upheld in the field [8]. Bytranslating this process into an equivalent in AI form, we provide one potentialway IHL can be designed directly into an AI weapon system, and demonstratethat the demands for an IHL-compliant AI weapon system can theoretically bemet. Our proposal aims at filling the gap between legal research on IHL andresearch on AI-driven autonomous decision-making systems.Our system is deliberately built optimistically, in the sense that we captureall relevant legal tests required during targeting directly into one system. Thisincludes target selection and sorting, distinction, proportionality calculation,and harm minimisation. It reflects what some define as a (fully) autonomousweapon system [38], i.e., where AI takes over all the functions of a commander.However, not all AI-controlled weapon systems will necessarily perform all of thesteps described in our framework. A decision-making aid might only need thetarget sorting and collateral damage calculation functions, while a smart missilemight only execute the proportionality calculation functionality. We make nostatements on how, in detail, particular modules would be built in practice andthe feasibility of such a system [30]. Rather, our main aim is explorative, i.e.,to demonstrate that purely from a programming perspective, such a task canbe undertaken. Another reason for including all legal tests into one frameworkis that variables such as military advantage and harm reduction are utilisedthroughout the various steps of the cycle. By capturing the entire targetingprocess at once, we are able to illustrate how different legal tests interlink anddraw from the same variables and inputs.Another distinctive feature of our framework is its hybrid nature which com-bines knowledge-driven and data-driven reasoning. One major dilemma oftenraised in the debate concerning AI and weapons is the dual problem that, onthe one hand, the complexity and dynamicity of the modern battlefield practi-cally requires resort to data-driven techniques such as deep neural networks foradaptability [12,41], while on the other hand, a level of decision-making trans-parency is required in IHL for the purposes of predictability and accountabilityDesigning International Humanitarian Law 3[20,27]. Through the use of a hybrid system, we draw on the strengths of bothtechniques while addressing both these challenges.While we focus exclusively on the legal duties in IHL as the basis for ourframework, it should be noted that in practice, many other factors - such aspolitical and ethical perspectives - will also be important when defining thesystem\u2019s design requirements. [7,11,16,21,33] provide useful overviews of suchconsiderations in the field of AI and weapon systems. We do not integrate thesefactors into our system at this point to maintain the framework\u2019s generality, aseach State and military organisation will have different policies in force. By focus-ing primarily on the legal requirements, which are universal and non-derogable,we present a framework that is at a minimum IHL-compliant, after which organ-isations can adopt additional ethical, organisational and political requirementsin accordance with their respective preferences and policies.This paper proceeds as follows. We begin with a brief comment on thelaw applicable to military systems and the targeting cycle in general. We thenexplore, in depth, the military targeting cycle upon which our system\u2019s frame-work was built. This includes two aspects. First, we discuss the formal stepsof the targeting process and how these are implemented during military oper-ations. Second, we discuss what IHL principles are relevant for the targetingstage and their respective timings. We then integrate the law into the targetingprocess and present formalisations of specific rules of IHL, such as proportional-ity and minimisation, thereby also highlighting the variables which are the mostimportant as inputs for these tests. On this basis, we subsequently introducethe framework of our system, briefly discuss the necessary functionalities of thesystem, its structure, and required data.2 The Law and the Operational FrameworkLimitations on the use of particular weapons are among the oldest provisions inthe law of war and are inextricably woven into the fabric of modern IHL [50].While there have been specific conventions restricting or prohibiting particularweapons such as chemical weapons or landmines, IHL also contains general prin-ciples such as the principle of distinction and proportionality which apply as amatter of customary international law [19]. For our framework, we will primarilyrely the latter for two reasons. First, there evidently is no specialised normativeconvention as of yet for AI weapons, as the matter is still under discussion beforethe CCW Conferences in Geneva at the time of writing. Second, even if such aconvention would exist, it is highly unlikely that all States would accede to it[51]. It is therefore in any situation relevant to consider more general IHL as aunifying normative standard applicable to all States.As referenced in the introduction, there is little doubt that IHL applies toAI weapons. While modern IHL was born in the twentieth century and manynew technologies have been introduced since then (e.g. precision weapons, cyber-weapons, AI), any new weapon is to conform itself to the applicable rules, andnot vice versa [25]. IHL is applicable \u201cwithout regard to the kind of technology4 J. Kwik et al.in question\u201d [17]. This is confirmed consistently throughout the debate on AIweapons. While there is some contention on whether existing IHL is necessarilysufficient to regulate all challenges that arise from AI in weapon systems [24], itis uncontroversial that IHL continues to apply for the use of military AI [18]. Weecho Canada\u2019s [6] position that ensuring the lawfulness of AI weapons should be\u201cconstant reference points\u201d for any discussion on the matter.The ability of weapons to fulfil IHL requirements must be tested as earlyas the development, testing and adoption stages [23]. For parties to AdditionalProtocol I (API), this is explicitly provided in the form of a duty to conduct an\u2018Article 36\u2019 legal review [2]. Nevertheless, in our discussion, we will focus more onthe operational half of the weapon\u2019s lifecycle. The reason for this is that reviewsare conducted with respect to the envisaged tasks and circumstances of use forthat particular weapon, and not in abstracto [37]. An example can be drawn fromlegacy weapons. During the Gulf War, Iraq was broadly condemned for the useof SCUD missiles, which had rudimentary guidance systems (i.e., a low accuracyrate), against Israeli population centres. However, such a weapon might validlypass a legal review if it was designed to be deployed only in civilian-free locations[40]. Similarly, an AI weapon with a very low specificity rate for distinguishingbetween military and civilian objects is not necessarily indiscriminate if, forinstance, it is designed to operate underwater [46]. We argue, for this reason, thatit is of particular importance to highlight the deployment phase of an AI weapon,i.e., the law that applies to military operations. Any generalised conclusionsthat may be drawn for the purposes of legal review (e.g. accuracy rates) cansubsequently be drawn from the principles applicable to operations.When we speak of the operational half of a weapon\u2019s lifecycle (i.e., deploy-ment and use), the targeting cycle becomes our primary reference point. Theaim of this process is to synchronise the choice of weapon, target and operationalconstraints to obtain the desired military effect [10]. Crucially, this effect mustbe achieved while ensuring compliance with IHL [8]. For this reason, militariesdirectly integrate legal tests into the targeting process to ensure that any weaponthat is being considered meets the standards required for lawful use. Unfortu-nately, this operational perspective has not garnered the attention it deserves:Ekelhof [15] notes that much of the discussion on AI in weapon systems fails toproperly take into account the military targeting process. We will therefore placegreater scrutiny on this military art of targeting and the way IHL principles areimplemented in practice during concrete operational circumstances.2.1 The Targeting CycleIn this section, we summarise the key steps of the targeting cycle based on theUS military and NATO standard. While specific details and protocols may differbetween military organisations, there the six steps explained below are generallyapplicable to most military operations.11 The following overview is drawn from [13,15,32,35].Designing International Humanitarian Law 5(1) Goal analysis involves the commander analysing the broader goals previ-ously set at the strategic or operational levels. For instance, in the NATOcontext, goals, target sets and guidance are generally provided by the JointForce Commander. The commander considers the desired end state describedby the broader goals and how to best achieve it.(2) Target analysis, also called target development, involves the identificationand specification of eligible targets. From this analysis, a general calculus ismade of the action, time, and resources required to engage this target, to whatextent this would contribute toward achieving the goals determined in Step(1), and whether there is a risk of collateral damage in view of its location,function, or characteristics.(3) Capability analysis involves an assessment of the means and methods ofwarfare available to the commander [8]. It is during this phase that a weaponor weapons mix is selected which would best achieve the desired effects in lightof details of the potential targets identified in Step (2). The art of comparingdifferent alternatives and assigning the optimal combination, quantity anddelivery of weapons (systems) to minimise collateral damage to the furthestextent possible while still achieving the desired objective is frequently referredto as weaponeering [44].(4) Capability assignment features the definitive matching of the cho-sen capability mix to the targets. If necessary, the commander can orderadditional operational safeguards or considerations to be implemented. Theassigned order is then forwarded to component commanders for final planningand execution.(5) Execution takes place at the tactical level and features the operation beingcarried out based on the considerations made during all previous phases. Aminiature version of the targeting cycle is performed here by the componentcommander. At some point, a decision to use force is made that cannot beundone, such as the drawing of the trigger on a sniper rifle or the launching ofa weapon that cannot be recalled [35]. This is called the execution moment.(6) Assessment is a crucial element in the iterative targeting procedure. Anychange in the environment as a result of Step (5) is assessed, noted, and reportedback to determine the impact of the use of force both in terms of achievingthe desired military effect and damage to civilians. From this new information,the operational goals are re-assessed and the process begins anew in Step (1)until the desired military objective is achieved [22]. Additionally, even if no newengagements are planned, results from Step (6) are still recorded for the pur-poses of general after-action reviews and lessons learnt, both important pro-cesses for preventing the repetition of mistakes in future operations [32].A graphical representation of this process can be found in Fig. 1.2.2 Integrating the Law into the CycleCertain obligations in IHL are considered to be inextricably linked to the target-ing process. These requirements are for a major part to be found in Article 576 J. Kwik et al.Fig. 1. Graphical illustration of the targeting cycleof API. For instance, the UK Ministry of Defence [47] notes that \u201cany system,before an attack is made, must verify that targets are military entities, takeall feasible precautions to minimise civilian losses and ensure that attacks donot cause disproportionate incidental losses\u201d. In Thurnher\u2019s [45] view, targetingrequires \u201cexamination of three key requirements of the law of armed conflict: dis-tinction, proportionality, and precautions in the attack\u201d. A summation of theseobligations, however, does not provide us with an indication of when and howthey are exactly applied within the operational context. For this reason, we takea closer look at how militaries implement these legal tests when executing thetargeting cycle.As with the individual steps of the targeting cycle itself, there is no universaltemplate to fall back upon, but there is usually an efficient order adopted bymost militaries. Some authors, such as Corn [8] and Ducheine and Gill [14], haveproposed flowcharts to this effect as shown in Fig. 2. Corn\u2019s approach is moreakin to a decision tree, while Ducheine and Gill\u2019s approach better illustrates howindividual legal tests are timed within the 6 steps illustrated in Fig. 1. The latteralso demonstrates well the effects of different variables such as collateral damageand military advantage and that the process can skip tests or loop around,depending on the applicable inputs.Fig. 2. Proposed flowcharts by Corn [8] and Ducheine and Gill [14]While such flowcharts are useful for human commanders, for our hypotheticalAI system, we need to extract more clearly the specific legal tests, how they areexecuted, and what inputs are required for each. We expand on this now.Designing International Humanitarian Law 73 Timing and Application of Legal TestsNo particular legal test is applied during (1) Goal analysis. However, the goaland rationale of the operation itself may have ramifications in terms of definingthe importance of particular objectives or targets, i.e., the military advantagethat can be gained. We will thus refer back to these goals in later phases whentheir legal relevance becomes more apparent.(2) Target analysis features several important legal requirements. First,the principle of distinction (API Art.48) requires the collection of informationand intelligence to ensure that the envisaged target(s) are indeed valid objec-tives. IHL asks attackers to \u201cverify that the objectives to be attacked are neithercivilians nor civilian objects and are not subject to special protection but aremilitary objectives\u201d (API Art.57(2)(a)(i)). Step (2) is usually deemed the idealmoment to apply this test [14]. Militaries also conduct collateral damage esti-mation at this phase, i.e., whether there is risk of incidental civilian harm tiedto the target [32,44].A specific form of precautions found in API Art.57(3), and our first mainlegal test, can be applied at this stage [35]. This paragraph requires the follow-ing: \u201cWhen a choice is possible between several military objectives for obtaininga similar military advantage, the objective to be selected shall be that the attackon which may be expected to cause the least danger to civilian lives and to civil-ian objects\u201d. This test involves two variables: military advantage and collateraldamage, both of which can be derived from Step (1) and Step (2) respectively.While both variables are complex to quantify, the rule itself is relatively straight-forward. If by D = {D1,D2, ...} we denote a set of possible Decisions (in casu,attacking a particular target), and we define the Military Advantage gained fromdecision Dt as MAt and the collateral damage involved from decision Dt as IHt(from \u2018Incidental Harm\u2019), then in a binary situation between D1 and D2, wecould formalise the rule as follows:if \u2203Dx\u2208D\u2200Dy\u2208D\\Dxs.t.MAx \u2248 MAy \u2227 IHx < IHy then select Dx (1)(3) Capability analysis is the most involved step in terms of legal tests.The two most important principles addressed at this stage concern proportion-ality and minimisation, which both relate to collateral damage. First, propor-tionality prohibits any Decision (i.e., a combination of a target, capability andmethod of delivery) which causes incidental civilian harm excessively dispropor-tionate to the concrete military advantage anticipated (API Art.57(2)(a)(iii)).As with the test in Art.57(3) above, this involves a comparison between militaryadvantage and collateral damage. Multiple options can be considered \u2018propor-tionate\u2019 as long as the threshold of excessiveness is not exceeded [31]; in otherwords, proportionality effectively sets a maximum threshold of how much col-lateral damage remains acceptable vis-a\u0300-vis the anticipated military advantage.If we define this threshold as p, we can formalise2 the rule as:2 A similar approach to the modeling of proportionality rule can be found in [52].8 J. Kwik et al.if \u2203Dx\u2208D s.t.IHxMAx\u2264 p then status(Dx) = legal else status(Dx) = illegal(2)It is not sufficient to only look at proportionality. IHL also mandates thatincidental harm to civilians must be minimised to the furthest extent feasible(API Art.57(2)(a)(ii)). Essentially, \u201c[i]f there is a choice of weapons or methodsof attack available, a commander should select those which are most likely toavoid, or at least minimize, incidental damage\u201d [26]. This obligation involvescomparing different options in terms of capabilities, operational constraints andmethods of delivery. For instance, applying this test may result in less accu-rate weapons being discarded, altering the timing of attack, or selecting a lessdestructive damage mechanism [37]. Commanders are not expected to do theimpossible: the corollary of feasibility empowers commanders to take into con-sideration all relevant circumstances, including those relevant to the success ofmilitary operations [37]. If too much military advantage is lost due to a particu-lar minimisation measure, they are permitted to select a more reasonable optionthat better balances the humanitarian and military considerations in play [40].In a binary comparison therefore, this rule would be formulated:if \u2203Dy\u2208D\u2200Dx\u2208D\\Dy :IHyMAy<IHxMAxthen select Dy (3)It must also be emphasised that because proportionality and minimisationare both concerned with the variable of collateral damage (IH), the tests canbe disregarded in cases where this variable does not factor [14]. If the weaponis projected to function only in a military-exclusive environment, for example,these tests may be skipped.Finally, there is one additional requirement that must be mentioned at thisstage related to weapons which are inherently illegal . Customary law generallyrecognises two aspects which make a weapon unlawful per se: that of causingunnecessary suffering and of being inherently indiscriminate [37,45]. In addi-tion, weapons treaties may be in force for the belligerent which limit the useof certain weapons beyond what customary law requires [4]. While these areimportant legal restrictions, it is irregular for these weapons to reach the target-ing stage: It is the role of weapons reviewers to filter out such weapons duringdevelopment and adoption [23,48]. Nevertheless, it cannot be ruled out that aweapon fulfilling such criteria actually reaches the front lines at some point. Toguard against this possibility and maintain IHL-compliance, we add this func-tion to allow the AI to deny its own use if its deployment would be unnecessarilyinjurious, inherently indiscriminate or prohibited by treaty.During (4) Capability assignment up to the execution moment, a seriesof final precautionary measures are enacted. In part these involve continuous re-tests of all previous obligations on a more detailed level [35]. The reason for thisis to ensure that all input assumptions related to the classification of the target,its military worth and the collateral damage estimations underlying the previ-ous decisions remain applicable. Related to this, IHL also requires cancellingDesigning International Humanitarian Law 9the ordered attack if it becomes known throughout this period that any of theseassumptions are no longer valid (API Art.57(2)(b)). In addition, advance warn-ing must be provided in cases where civilians can be affected (API Art.57(2)(c)),although this duty only applies in cases where this is reasonable, i.e., where itwould not compromise the success of the attack [37].Finally, during (6) Assessment, a legal obligation that could be relevantis the duty to suppress and repress. It is part of the broader obligation torespect and ensure respect for IHL at all times [1], and involves both generalmeasures to prevent and address violations of IHL (\u2018suppression\u2019) and, in casea serious breach has occurred, that the persons responsible for such violationsbe held criminally responsible (\u2018repression\u2019) [1]. Thus, requirements related toforeseeability, understandability, traceability and the keeping of digital recordsmay become relevant at this stage [27].Fig. 3. Overview of legal tests and inputs during the targeting cycleA graphical summary of targeting phases and the corresponding legal tests,in addition to supporting actions that contribute toward the fulfilment of theselegal obligations, are depicted in Fig. 3. Legal tests are represented by orangeboxes, important inputs by purple boxes, and the formulae described above byblack circles. The framework is intended to be function-agnostic, but whethereach test is to be applied by a human or an AI will depend on the specific AIunder consideration. If the execution of a particular phase is left to an AI, thenit must be demonstrated that the AI in question is capable of executing the legaltests necessary for that phase [4].10 J. Kwik et al.4 The General Framework of the Autonomous TargetingSystemIn the previous section, we described the general targeting sequence and thelegal tests that must be applied during each step for lawful use of force. In thissection, we are going to present the general structure of our autonomous tar-geting system which incorporates these legal tests into its functionality. Notethat we will not discuss any particular targeting scenario, but rather introducea general (function agnostic) framework which is IHL-compliant. Moreover, wewill not discuss the technical details of the machinery which can be used toimplement the targeting system, but only propose a structure and possible tech-niques which may allow for creation of a targeting system which can observe thelegal requirements identified in Sect. 2. Further technical details of this systemwill be discussed in future papers. We realize that some functionalities may stillbe very difficult to implement in real life systems (e.g. distinguishing betweencombatants and civilians) [43]. However, we can expect that such modules, atleast for some tasks (e.g. distinguishing military and civilian aircraft), will befeasible in the near future.One of the most important assumptions on the basis of which we designed ourmodel is rooted in the observation that although the transparency and explain-ability requirements are crucial for many legal tests [27], the requirements forthe cognitive elements of the decision process are less restrictive. IHL is a purelynormative framework and does not provide rigid requirements or standards forcommanders when conducting tests which involve MA (military advantage) andIH (incidental harm) as variables. In fact, the opposite is true: these assessmentsare frequently described as eminently qualitative and subjective in nature [3].On the basis of the above, we can assume that at least some functions of thecognitive part can be created with the use of much less transparent data-drivenapproaches, especially deep learning neural networks.One prominent element of the procedure described in the previous sectionis the comparison between anticipated military advantage and anticipated inci-dental harm. Obviously, while making his decision, a human commander doesnot represent either variable in a quantifiable form. An autonomous AI-drivenmodel, however, requires not only a quantifiable representation, but also a rep-resentation which allows for their formal comparison [5].We will use values as a central concept allowing for representation of bothmilitary advantage and incidental harm. Values we understand as an abstract(trans-situational) concept which allows for the estimation of a particular actionor a state of affairs and which influences one\u2019s behavior. Consequently, on thebasis of such a definition, we assume that particular values can be satisfied to acertain degree [53]. Such a definition of value can be seen as a kind of abstractionof concrete results of an action, and allows us to use them as a central conceptin our model where they play an important role as an intermediate conceptrepresenting an abstraction of a targeting situation.On the basis of the above, we provide a discussion of how, from a technicalviewpoint, the requirements of each stage of the targeting process can be fulfilled.Designing International Humanitarian Law 11Since this is a position paper presenting the overall structure of the system, wewill not enter into the technical details of particular functions used in the model,unless it is necessary to make the model understandable or when it constitutesa key element of the discussion. More detailed presentations of the technicalnuances will be included in future work.A battlefield is a multiagent environment par excellence featuring manyallied, neutral and adversarial agents which the system must be able to under-stand and account for [36]. In our framework, we present all functions as if theyare fulfilled by a single agent for simplicity. In actual systems, it is possible thatseveral agents are involved which contribute together toward the execution ofthe framework\u2019s different functions, or that particular functions are performed bydistinct agents working together. Additionally, input data such as signal intel-ligence may be obtained from an allied agent, which can either be a humanobserver or another AI unit such as a reconnaissance drone [49]; similarly, thefinal decision resulting from our framework can be effectuated by an agent on thefrontlines such as a human squad or combat robot. These permutations do notaffect the viability of our framework as long as all functions are executed correctlyby the agents involved and, in the case of collaborating agents, all necessary teststake into consideration all involved agents. With regard to adversarial agents,sufficient robustness and adaptability against opponents\u2019 efforts to disrupt thesystem\u2019s proper functioning must be made into important design requirements[12].5 The Structure of the SystemIn this section we introduce the general structure of the proposed system.5.1 The Basics of the ModelFirstly, we discuss the basics:\u2013 Introduction of goals. In the first stage of the targeting process, the com-mander performs the analysis of the desired state on the strategic and opera-tional levels. Since such an analysis is performed from a broader perspective,taking into account the general goals of military operations, we argue that forthe autonomous device, such a goal can be represented as a set of thresholdsof a group of values which constitute a more general value military advantage.\u2013 Input data. In order to perform all required tests and to decide whichdecision should be made, some necessary data has to be prepared. Firstly,the agent should distinguish a set of available actions with their anticipatedresults and evaluate them in the light of MA and IH. In order to fulfill thisstage, a set of preparatory tasks should be performed:\u2022 Generation, on the basis of signal intelligence and the general circum-stances of the case (denoted by S), of the set of decisions which can pos-sibly be made in given circumstances. By D we denote a set of availabledecisions.12 J. Kwik et al.\u2022 Prediction of the result of every decision from the set. Note that for thetests described in the previous section, the levels of MA and IH relate tothe anticipated results of decisions, which means that they are by natureuncertain. Let R be a set of all possible results of actions (decisions fromset D) and let PR be a set of conditional probabilities of those results,given a particular situation and decision.\u2022 Evaluation of the decision results in the light of the set of relevant values.Suppose a set of decision results R and a set of functions \u03a6V which returnsthe level of satisfaction of a particular value vx by result ry. By V R wedenote a set of levels of satisfaction of all values by the results of allavailable decisions.Since function \u03a6 has a crucial character for our model, we briefly presenthere how it can be obtained. The goal is to find a function which forevery possible result (r \u2208 R) can predict the level of satisfaction of everyvalue (the level to which a predicted result of a decision would satisfythe relevant value, e.g. military advantage, life of civilians, etc.). Supposethat every result from set R (possible results of actions) will be evaluatedand labelled by human annotators in the light of every value (by assigninga number representing the level of satisfaction of a given value). On thebasis of such data and a ML-based regression mechanism, a regressionfunction can be trained which can predict the level of satisfaction of agiven value on the basis of a particular result. A more detailed analysisand discussion of this approach will be presented in future work.\u2022 Calculation of the expected level of satisfaction of a particular value (itcan be calculated on the basis of probabilities of results PR and evalu-ation of the decisions\u2019 results V R.) By EV we denote a set of levels ofsatisfaction of all values by all available decisions.5.2 The StructureIn this section we present the structure of the proposed system:\u2013 Extraction of available decisions is responsible for obtaining a set of availabledecisions (S is an input, D is an output of the module).\u2013 Result prediction module is responsible for predicting results of decisions withtheir probabilities (D and S are inputs to the module, while PR and R areoutputs).\u2013 Evaluation module is responsible for performing function \u03c6 (G, S, and R areinputs to the module, V R is an output).\u2013 Parameters\u2019 extraction module is the module which returns the set of param-eters of decisions. By the parameters of a decision we understand details of adecision such as type of weapon, timing, etc. D is an input, PAR is an outputof the module.\u2013 Expected evaluation module is responsible for calculating the expected evalu-ation of decisions in the light of values (V R and PR are an input, EV is anoutput of the module).Designing International Humanitarian Law 13\u2013 Treaties fulfillment module is responsible for performing function filteringdecisions which do not fulfill treaties (PAR and FPAR are inputs, DTR isan output of the module). If by FPAR we denote the set of requirementsimposed by treaties, then the module can work as a logic-based reasoningmechanism.\u2013 Goals fulfillment module is responsible for performing function filtering deci-sions which do not fulfill the commander\u2019s goals (G and EV is an input, DGis an output of the module). If by a goal we understand the minimal accept-able levels of values\u2019 satisfaction (see [53]), then a given decision will fulfillthe goal if the expected level of satisfaction of relevant values will be abovethe thresholds assumed in G.\u2013 Harm minimization filter is responsible for the process of minimization ofincidental harm (EV is an input, DMH is an output). A given decision willpass the test if for this decision formula 3 will be fulfilled.\u2013 Proportionality test is responsible for performing the proportionality test (EVis an input, DP is an output). A given decision will pass the test if for thisdecision formula 2 will be fulfilled.\u2013 Article 57(3) Filter is responsible for the process of filtering decisions whichfor the same military advantage causes greater harm to civilians (Article57(3), EV is an input, DT is an output). A given decision will pass the testif for this decision formula 1 will be fulfilled.\u2013 Fulfillment of requirements is responsible for joining together results of theabove tests (DT , DP , DMH, DG, and DTR are inputs and DAV is anoutput). A given decision will fulfill this requirement if all tests have beenpassed.\u2013 Decisions ordering is responsible for ordering available decisions (those ful-filling the above tests) on the basis of the level of satisfaction of MilitaryAdvantage (DAV and V R is an input, Decisions is an output of the mod-ule).The structure of the proposed model is presented in Fig. 4. The model features aclear distinction between (1) the cognitive part of the decision process, includingfunctions extracting available decisions, their results, and evaluation (the upperpart of the scheme) and (2) the reasoning part of the decision process, includinglegal tests, goal test, treaties test, etc. (lower part of the scheme). This distinctionbetween the parts of the decision process is a notable strength of the frameworkwe propose because it provides some degree of transparency and explainability.These attributes have been identified as crucial both for the lawful use of AIweapon systems and upholding the responsibility of its users [27].As such, the structure we propose relies on the conviction that for the sakeof transparency, legal tests should be performed in an explainable way, i.e. thesystem should explicitly check whether a given decision passes all necessarytests, while the other elements of the decision process can utilize data-drivenapproaches. Such an approach is compliant with the general approach regardinghybrid systems, in which the data-driven part is used for extraction of the inputdata for a knowledge-based system, and generally allows for filling the so-calledsemantic gap between data and knowledge [29].14 J. Kwik et al.Fig. 4. Graphical illustration of the system\u2019s structure6 Discussion and ConclusionsThe paper introduces a framework for creating an AI-based hybrid targetingsystem for military autonomous agents capable of operating within the boundsof IHL. The main goal was to present a way how IHL can be integrated fromthe ground up into a military AI system in order to better guarantee IHL-compliance. We present the main stages of the targeting process, identify whichlegal requirements are imposed by IHL and what variables and elements thesetests encompass, and introduce a mechanism which allows for the developmentof a system fulfilling those requirements.To achieve this, we introduced a model of a hybrid system which combinesdata-driven parts (possibly created with the use of deep learning neural net-works) and knowledge-driven parts. This type of system composition allows usto draw from the advantages of both AI paradigms, while also compensatingfor at least part of their respective disadvantages. In particular, one major dis-Designing International Humanitarian Law 15advantage of data-driven AI, lack of transparency, is overcome to some extent,which is a boon for IHL compliance.Further development of our framework requires the verification of the model.Since this paper presents a general model of the decision-making process only,we cannot introduce here a fully-fledged, technical verification of our proposal.Instead we briefly sketch how the verification of the model can be performed.Since our framework consists of two parts - cognitive and reasoning ones -the verification should be performed twofold:\u2013 The cognitive part should be verified on the basis of statistical quality of allmodules. For example, the quality of sensors, the accuracy of predictions andevaluations, etc. The verification of this part is task-dependent. For example,signal intelligence should be verified in the light of accuracy of object detectionrelated to the specific sensors: cameras, recorded sound, satellite picturesetc.; the prediction module should be evaluated in the light of accuracy ofpredictions made; etc. Every module should be verified in the context of theconcrete intended purpose for which the device is designed [28].\u2013 The reasoning part requires formal and legal verification of all tests (see Sect. 3where we discuss some legal aspects concerning the model) and the wholereasoning process and the formal and experimental analysis of the reasoningmachinery used to performing necessary tests, which will be presented in ourfuture works.Our hypothetical framework was developed with the aim of identifying andelaborating the functionalities which would be necessary for AI-driven systemsto conform to IHL. We make no practical pronouncements concerning technicalimplementation or in what type of weapon this framework would be incorpo-rated, as these details would depend on the military organisation\u2019s specific needs.In addition, it is possible that comparable systems are currently under devel-opment by militaries. These systems are likely to remain confidential and thus,it is difficult for us to test our framework vis-a\u0300-vis those systems. Our proposalnevertheless can be used as a reference or guideline for both current and futureconstructors intending to build systems with IHL compliance in mind.References1. Geneva Convention for the Amelioration of the Condition of the Wounded andSick in Armed Forces in the Field (adopted 12 August 1949, entered into force 21October 1950) 75 UNTS 312. Protocol Additional to the Geneva Conventions of 12 August 1949, and relating tothe Protection of Victims of International Armed Conflicts (adopted 8 June 1977,entered into force 7 December 1978) 1125 UNTS 3 (1977)3. Anderson, K., Waxman, M.C.: Law and ethics for autonomous weapon systems:why a ban won\u2019t work and how the laws of war can (2013)4. Boothby, W.H.: Regulating new weapon technologies. In: Boothby, W.H. (ed.) NewTechnologies and the Law of War and Peace, pp. 16\u201342. Cambridge UniversityPress, Cambridge (2019)16 J. Kwik et al.5. Boulanin, V.: Mapping the development of autonomy in weapon systems: a primeron autonomy. Stockholm International Peace Research Institute, Stockholm (2016)6. Canada: Opening Statement by Canada at Second Meeting of the Group of Gov-ernmental Experts on Lethal Autonomous Weapons Systems (LAWS), 9\u201313 April2018. Technical report (2018)7. Chavannes, E., Arkhipov-Goyal, A.: Towards Responsible Autonomy: The Ethicsof Robotic and Autonomous Systems in a Military Context. The Hague Centre forStrategic Studies, The Hague (2019)8. Corn, G.S.: War, law, and the oft overlooked value of process as a precautionarymeasure. Pepperdine Law Rev. 42, 419\u2013466 (2014)9. Crootof, R.: The killer robots are here: legal and policy implications. Cardozo LawRev. 36, 1837\u20131915 (2015)10. Curtis E. Lemay Center: Air Force Doctrine Publication 3\u201360 - Targeting (2019).https://www.doctrine.af.mil/Doctrine-Publications/AFDP-3-60-Targeting11. Dahlmann, A., Dickow, M.: Preventive regulation of autonomous weapon systems.Technical report. Stiftung Wissenschaft und Politik Research Paper 2019/RP 03,Berlin (2019). https://doi.org/10.18449/2019RP0312. Defense Innovation Board: AI principles: recommendations on the ethical use ofartificial intelligence by the department of defense defense innovation board. Tech-nical report, Department of Defense (2019). https://media.defense.gov/2019/Oct/31/2002204458/-1/-1/0/DIB AI PRINCIPLES PRIMARY DOCUMENT.PDF13. Department of the Army: The Operations Process (2019)14. Ducheine, P., Gill, T.: From cyber operations to effects: some targeting issues.Militair Rechtelijk Tijdschrift 111(3), 37\u201341 (2018)15. Ekelhof, M.: Human control in the targeting process. In: Autonomous Weapon Sys-tems: Implications of Increasing Autonomy in the Critical Functions of Weapons,pp. 53\u201356. ICRC, Versoix (2016)16. Eklund, A.M.: Meaningful Human Control of Autonomous Weapon Systems: Def-initions and Key Elements in the Light of International Humanitarian Law andInternational Human Rights Law. Totalfo\u0308rsvarets forskningsinstitut, Stockholm(2020)17. Gei\u00df, R., Lahmann, H.: Autonomous weapons systems: a paradigm shift for the lawof armed conflict? In: Ohlin, J.D. (ed.) Research Handbook on Remote Warfare,pp. 371\u2013404. Edward Elgar, Cheltenham (2017)18. Group of Governmental Experts on Lethal Autonomous Weapons Systems (GGEon LAWS): Report of the 2019 session of the Group of Governmental Expertson Emerging Technologies in the Area of Lethal Autonomous Weapons Systems,UN document CCW/GGE.1/2019/3, 25 September 2019. Technical report, Geneva(2019)19. Henckaerts, J.M., Doswald-Beck, L.: Customary International Humanitarian Law,Volume I - Rules. ICRC, Geneva (2005)20. Holland Michel, A.: The black box, unlocked: predictability and understand-ability in Military AI. Technical report, United Nations Institute for Disarma-ment Research, Geneva, Switzerland, September 2020. https://doi.org/10.37559/SecTec/20/AI1. https://unidir.org/black-box-unlocked21. House of Lords: Select committee on artificial intelligence, report of session 2017\u201319, AI in the UK: Ready, willing, and able? Technical report, HL Paper 100, 16April 2018 (2018)22. Huffman, W.B.: Margin of error: potential pitfalls of the ruling in the prosecutorv. Ante Gotovina. Military Law Rev. 211, 1\u201356 (2012). https://hdl.handle.net/10601/2104Designing International Humanitarian Law 1723. International Committee of the Red Cross: A Guide to the Legal Review of NewWeapons, Means and Methods of Warfare: Measures to Implement Article 36 ofAdditional Protocol I of 1977. ICRC, Geneva (2006)24. International Committee of the Red Cross: Report of the ICRC Expert Meeting onAutonomous weapon systems: technical, military, legal and humanitarian aspects,26\u201328 March 2014, Geneva. Technical report (2014)25. International Court of Justice: Legality of the Threat or Use of Nuclear Weapons(1996)26. International Criminal Tribunal for the Former Yugoslavia: Final Reportto the Prosecutor by the Committee Established to Review the NATOBombing Campaign Against the Federal Republic of Yugoslavia. Technicalreport (2001). https://www.icty.org/en/press/final-report-prosecutor-committee-established-review-nato-bombing-campaign-against-federal27. Kwik, J., Van Engers, T.: Algorithmic fog of war: when lack of transparency vio-lates the law of armed conflict. J. Future Robot Life, 1\u201324 (2021). https://doi.org/10.3233/FRL-20001928. Meier, M.W.: Lethal autonomous weapons systems. In: Complex Battlespaces, pp.289\u2013316. Oxford University Press, Oxford, January 2019. https://doi.org/10.1093/oso/9780190915360.003.001029. Meyer-Vitali, A., et al.: Hybrid AI white paper. Technical report, TNO (2019).tNO 2019 R1194130. Ministe\u0300re des Arme\u0301es (France): L\u2019intelligence artificielle au service de la de\u0301fense.Technical report, Ministe\u0300re des Arme\u0301es, Paris (2019)31. Neuman, N.: Applying the rule of proportionality: force protection and cumulativeassessment in international law and morality. Yearb. Int. Hum. Law 7, 79\u2013112(2004). https://doi.org/10.1017/S138913590400079032. North Atlantic Treaty Organisation: Allied Joint Doctrine for Joint Targeting,Edition A Version 1 (April 2016) AJP-3.9 (2016)33. Office of the Assistant Secretary of Defense for Research and Engineering: TechnicalAssessment: Autonomy. US Department of Defense, Washington, D.C. (2015)34. Roff, H.M.: Meaningful human control or appropriate human judgment? The nec-essary limits on autonomous weapons (2016)35. Roorda, M.: NATO\u2019s targeting process: ensuring human control over (and lawfuluse of) \u2018autonomous\u2019 weapons. In: Williams, A.P., Scharre, P.D. (eds.) AutonomousSystems: Issues for Defence Policymakers, pp. 152\u2013168. NATO, The Hague (2015)36. Russell, S.J., Norvig, P.: Artificial Intelligence: A Modern Approach, 3rd edn. Pear-son, New Jersey (2010)37. Sandoz, Y., Swinarski, C., Zimmerman, B.: Commentary on the Additional Proto-cols of 8 June 1977 to the Geneva Conventions of 12 August 1949. Martinus Nijhoff(1987)38. Scharre, P., Horowitz, M.C.: An introduction to autonomy in weapon systems.Technical report, Center for a New American Security (2015)39. Scharre, P.D.: The opportunity and challenge of autonomous systems. In: Williams,A.P., Scharre, P.D. (eds.) Autonomous Systems: Issues for Defence Policymakers,pp. 3\u201326. NATO, The Hague (2015)40. Schmitt, M.N., Garraway, C.H., Dinstein, Y.: The Manual on the Law ofNon-international Armed Conflict, With Commentary. International Institute ofHumanitarian Law, San Remo (2006)41. Schuller, A.: At the crossroads of control: the intersection of artificial intelligencein autonomous weapon systems with international humanitarian law. Harv. Natl.Secur. J. 8, 379 (2017)18 J. Kwik et al.42. Sharkey, N.E.: Towards a Principle for the Human Supervisory Control of RobotWeapons. Politica Societa\u0300 3, 305 (2014)43. Szpak, A.: Legality of use and challenges of new technologies in warfare - the useof autonomous weapons in contemporary or future wars. Eur. Rev. 28(1), 118\u2013131(2020). https://doi.org/10.1017/S106279871900031044. Thorne, J.G.: Warriors and war algorithms: leveraging artificial intelligence toenable ethical targeting. Technical report, Naval War College (2020). https://apps.dtic.mil/sti/citations/AD110417145. Thurnher, J.S.: Examining autonomous weapon systems from a law of armed con-flict perspective. In: Nasu, H., McLaughlin, R. (eds.) New Technologies and theLaw of Armed Conflict, pp. 213\u2013228. T.M.C. Asser Press, The Hague (2014)46. Thurnher, J.S.: Feasible precautions in attack and autonomous weapons. In:Heintschel von Heinegg, W., Frau, R., Singer, T. (eds.) Dehumanization of Warfare,pp. 99\u2013117. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-67266-3 647. UK Ministry of Defence: The UK approach to unmanned aircraft systems: jointdoctrine note 2/11. Technical report, United Kingdom Ministry of Defence (2011)48. United States Office of General Counsel of the Department of Defense: Law of WarManual, Updated December 2016. Technical report, Department of Defense (2015)49. U.S. Air Force Office of the Chief Scientist: Autonomous horizons: system auton-omy in the air force a path to the future, volume I: human-autonomy teaming.Technical Report, AF/ST TR 15\u201301 (2015)50. Wallace, D.: Cyber weapon reviews under international humanitarian law: a criticalanalysis, Tallinn paper no 11. Technical report (2018)51. Wilson, C.: Artificial intelligence and warfare. In: Martellini, M., Trapp, R. (eds.)21st Century Prometheus, pp. 125\u2013140. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-28285-1 752. Zurek, T., Woodcock, T., Pacholska, M., van Engers, T.: Computational modellingof the proportionality analysis under international humanitarian law for militarydecision-support systems, January 2022. https://ssrn.com/abstract=400894653. Zurek, T.: Goals, values, and reasoning. Expert Syst. Appl. 71, 442\u2013456 (2017).https://doi.org/10.1016/j.eswa.2016.11.008Epistemic Diversity and Explanatory Adequacyin Distributed Information ProcessingAsimina Mertzani1(B) , Jeremy Pitt1,2, Andrzej Nowak2,3, and Tomasz Michalak41 Department of Electrical and Electronic Engineering, Imperial College London, London, UKasimina.mertzani20@imperial.ac.uk2 Robert B. Zajonc Institute for Social Studies, University of Warsaw, Warsaw, Poland3 Department of Psychology, Florida Atlantic University, Boca Raton, FL 33431, USA4 Institute of Informatics, University of Warsaw, Warsaw, PolandAbstract. A common problem facing an organisation of autonomous agents isto track the dynamic value of a signal, by aggregating their individual (and possi-bly inaccurate or biased) observations (sensor readings) into a commonly agreedresult. A meta-problem is to explain the observation of the value: to say whatrules produced the signal value that has been observed. In this paper, we use theRegulatory Theory of Social Influence and self-organising multi-agent systemsto simulate a Distributed Information Processing unit (DIP) trying to solve sucha meta-problem. Specifically, we examine what configuration of initial condi-tions on the DIP produce what type of epistemic condition for the collective, anddetermine the explanatory adequacy of this condition, i.e. to what extent does theDIP\u2019s explanation of the rules match the actual rules. The results offer some fur-ther insight into the need for epistemic diversity for self-improvement in dynamicself-organising systems.Keywords: Distributed information processing \u00b7 Explanatory adequacy \u00b7Knowledge processing \u00b7 Social influence \u00b7 Multi-agent systems1 IntroductionA commonly recurring problem confronting an organisation, composed of autonomousagents connected by a (social) network but lacking a central authority, is to map a setof individual measurements, judgements, votes, opinions or preferences into a singlecollective output. This problem is typically encountered in social systems (e.g. jurytrials, deliberative assemblies, etc.) as well as cyber-physical systems (e.g. cyberneticsystems, sensor networks, etc.)An instance of this general problem is truth tracking, when the task of an organi-sation of autonomous agents is to track the dynamic value of a signal, by aggregatingtheir individual (and possibly inaccurate or biased) observations (sensor readings) intoa commonly agreed result. In this sense, the organisation can be seen as a DistributedInformation Processing (DIP) unit. However, such a DIP can also face a meta-problem:to explain the observation of the value \u2013 i.e. to say what rules produced the signal valuethat has been observed. In this case, the DIP is not trying to pool its diverse opinionsto order to produce a social choice, but to pool its diverse knowledge to produce a\u2018plausible\u2019 explanation.c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 19\u201337, 2022.https://doi.org/10.1007/978-3-031-20845-4_220 A. Mertzani et al.This paper investigates a solution to this problem using the Regulatory Theory ofSocial Influence (RTSI) [12]. RTSI is chosen because it has two unique propositions:firstly, that social influence is bilateral, i.e. that as well as sources seeking targets toinfluence, targets are seeking sources by whom to be influenced; and secondly that inaddition to exchanging opinions, people also exchange information processing rules.Both of these propositions are essential for addressing the problem: the first becausewe want experts or \u2018specialists\u2019 to emerge, because they know more and are better atsolving the problem; and the second because we want their knowledge (of the rules) toflow over the social network.Therefore, we implement an algorithmic model of RTSI within a self-organisingmulti-agent systems\u2019 to simulate a DIP trying to solve such a meta-problem by propos-ing (collectively) a set of rules to explain the observed value that may (or may not)match the actual rules that produce the value. Specifically, we experimentally investi-gate what configuration of initial conditions on the DIP produce what type of epistemiccondition of the DIP.We then want to evaluate the explanatory adequacy of the DIP\u2019s solution. The term\u2018explanatory adequacy\u2019 is used in linguistics to describe an analysis which providesa \u2018reasonable\u2019 account of a linguistic phenomenon [18]. We want to know if the DIPcan produce a \u2018reasonable\u2019 or \u2018plausible\u2019 explanation, based on the extent to which itscollective explanation matches the actual cause (i.e. the ground truth). We measure thedifference using a suitable metric (cosine similarity) and use that as an indicator ofexplanatory adequacy.Accordingly, this paper is structured as follows. Section 2 establishes the back-ground of DIP and RTSI, and gives a formal specification of the problem. Section 3describes the experimental design, Sect. 4 defines the multi-agent simulation, andSect. 5 presents a set of experimental results. After a consideration of related and furtherwork in Sect. 6, Sect. 7 concludes that these results offer some further insight into theneed for epistemic diversity for self-improvement in dynamic self-organising systems.2 Background: DIP, RTSI and Plato\u2019s CaveIn this section we review the background to this work: organisations as distributed infor-mation processing units (DIP), a theory of social influence in such units, the RegulatoryTheory of Social Influence (RTSI), and a specification of the problem we are trying tosolve, which has similarities, at an abstract level, to the problem posed in the allegoryof Plato\u2019s Cave (see http://classics.mit.edu/Plato/republic.mb.txt).2.1 Distributed Information Processing Units (DIPs)Many organisations, in the form of complex cyber-physical, socio-technical or socialsystems, often have to function as Distributed Information Processing units (DIPs), i.e.,although composed of many different autonomous components, the components haveto act as a collective to transform a set of data inputs into a single output. Although,depending on the context, the precise definition differs (cf. [23] vs. [12]), in this paperthe term DIP refers to an organisation of autonomous, (socially) networked agentsEpistemic Diversity and Explanatory Adequacy 21encountering a requirement to self-manage their diverse, dispersed, and potentiallyincomplete and inconsistent knowledge.In general, successful knowledge management enables a DIP to make correct deci-sions, identify expertise, maintain collective memory, provide education, spark innova-tion and even accumulate \u201cwisdom\u201d. A more mundane function, perhaps, is to convergeon a ground truth from a set of observations that may have been influenced by environ-mental or community bias (cf. [20]). Here, though, rather than converging on the truth,we want to study how a DIP can produce explanatory adequacy: can the DIP convergeon the rules that produced that truth, rather than the truth itself. In this situation, we needa theory which considers social influence not just in terms of the exchange of opinions,but also in the exchange of processing rules. The theory we use is the Regulatory Theoryof Social Influence.2.2 Regulatory Theory of Social Influence (RTSI)RTSI is a psychological theory proposed by Nowak [12] that focuses on the target\u2019s per-spective of social influence, and specifically, examines how the targets look for sourcesby whom to be influenced. This theory emphasises a target\u2019s intentions and strategies,and posits that targets actively monitor others\u2019 opinions and behaviours, and are fullyengaged in the controlling the influence process.In this way, a target tries to optimise its decision-making and conserve its ownresources by delegating the tasks of information gathering and/or information process-ing to individuals that they credit for the such tasks. This enables targets to leverageothers\u2019 network, processing capacity or knowledge, maximising their access to infor-mation and information processing rules. Therefore, social influence becomes an instru-ment of targets to maximise their individual cognitive efficiency and quality of their out-comes, which are reflected by improvements in individual and collective performanceover time.2.3 Problem SpecificationIn this study, the situation to be addressed by a DIP, using RTSI, is illustrated in Fig. 1.The DIP is embedded in an environment, in which there is a process P that convertssome set of inputs into an output. The process P is parameterised by a set of n process-ing rules, each with an associated weight in [0..1]. This set of rules, denoted by K, isthe ground truth knowledge given by:K = {(ri, wi) | i \u2208 [1..n] \u2227 \u03a3ni=1wi = 1.0}We denote by Kr the set of rules in K (without the weights).Each agent a in the DIP \u2018knows\u2019Ka, which is some subset ofm rules ofKr,m \u2264 n.Each agent associates a random weight with each of its rules, with the weights nor-malised to sum to 1.0, so that the knowledge of agent a is:Ka = {(r1, w1), . . . , (rm, wm)} such that \u2200i, 0 \u2264 i \u2264 m.ri \u2208 KrNote, that if i = 0, then the agent knows nothing.22 A. Mertzani et al.PKK = {(r1, w1), (r2, w2), . . . , (wn, rn)}K(self )r \u2286 Kra1K(self )r \u2286 Kra2 K(self )r \u2286 KraNDIPinputs outputKDIPEnvironmentFig. 1. The Problem: Is KDIP an \u2018adequate explanation\u2019 for output of P(K)?The problem for the N agents comprising the DIP is to use their partial and dis-tributed knowledge to \u2018explain\u2019 the solution to process P as parameterised by K. Thisis done by each agent offering its own explanation Ka for parameters to process P , andthese are \u2018aggregated\u2019 into a collective explanation KDIP . In addressing this task, theagents have three \u2018tools\u2019 at their disposal:\u2013 sharing: using RTSI, an agent can ask one of the neighbouring agents in its socialnetwork, for a processing rule (or rules) that it (the neighbouring agent) used in its\u2018explanation\u2019 of K.\u2013 feedback: each agent receives feedback from the environment on the quality of thecollective knowledge and their own contribution, which is used to update \u2018attitudes\u2019to itself and a neighbouring agent (if it asked one); and\u2013 \u2018discovery\u2019: new agents joining the system may bring new knowledge to the system,which may then be shared as above, using RTSI.Given this context, we investigate:\u2013 what different initial conditions of the DIP, including population variation (e.g.static, dynamic), rate of social learning, and rate of \u2018discovery\u2019, . . .\u2013 . . .produce what different epistemic condition on the individual knowledge bases,i.e. the similarity of {Ka | a \u2208 N}, which we identify as either diversity, incongru-ence, or stagnation, and. . .\u2013 . . .evaluate explanatory adequacy of KDIP , i.e. the (dis)similarity of KDIP to K.In passing, we note that this problem can be seen, at its most abstract, as a formof Plato\u2019s Cave, wherein a group of people in a cave try to derive the true nature of anobject from the shadow it casts on the cave wall. Note, though, there are three perspec-tives on knowledge: K, the ground truth knowledge, KDIP , the aggregated knowledgeof the DIP, and the \u201cknowledge potential\u201d K\u222a, which is an epistemological limit onwhat it is possible for an agent to know, because this knowledge exists somewhere inthe DIP.However, as in Plato\u2019s Cave, this is not a once-off, one-shot problem. The overallsituation is as illustrated in Fig. 2, where it can be seen that the DIP composition isEpistemic Diversity and Explanatory Adequacy 23Fig. 2. The DIP unit and knowledge changing over timedynamic (agents may leave and join), and the knowledge made available (\u201cdiscovered\u201d,or introduced along with new agents) also varies.Therefore, \u201cexpertise\u201d in the group is also temporary, and knowledgeable agentswho may be good at the task may also be lost to the group. As such, there are twoperspectives on the collective: one being a functional perspective as a DIP, where thecollective pool knowledge and identify expertise in order to accomplish a common goal(cf. [1]), and the other being a societal perspective, where the group is using socialinfluence as a way to persuade and change attitudes about a common problem (cf. [13]).Accordingly, we will use the terms \u2018experts\u2019 or \u2018specialists\u2019 in the DIP and the sourcesof influence in RTSI inter-changeably, and equate knowledge with the processing rules;likewise the terms DIP, community and collective are all inter-changeable.3 Experimental DesignTo address the problem defined in the previous section, this section details the experi-mental design, firstly specifying the initial conditions on the DIP, (i.e. the independentvariables), and secondly specifying a metric for computing the DIP\u2019s epistemic condi-tion and explanatory adequacy (i.e. the dependent variables).3.1 Initial Conditions for the DIP (Independent Variables)For specifying the initial conditions on the DIP, we define two independent experimentalvariables, F and R. The former determines the rate of change of the population and rateof change of knowledge. The latter defines a constraint on the RTSI algorithm whichaffects how the agents communicate the processing rules and how they influence oneanother.The DIP will operate in a succession of T epochs, and every t < T epochs (exceptin the static condition) some new agents are added and some are removed. In each epochthe DIP will produce and evaluate KDIP against K, so F can have one of eight values:24 A. Mertzani et al.\u2013 static: The population consists of N agents, they remain active throughout all Tepochs. Each agent a is initialised with knowledge Ka being any subset of K.\u2013 dynamic: The population consists of N agents, and every t epochs a new generationof N10 agents joins the network andN10 of the existing agents leave. The agents areinitialised having any subset of the eight processing rules.\u2013 restart: The population consists of N agents, and every t epochs N10 new agents jointhe network and N10 leave. The 1st generation of N agents is initialised so that eachagent\u2019s a knowledge is a subset of {(r1, w1), (r2, w2)}. The next generation, whichconsists of N10 agents, is initialised knowing either a new rule or no rule, so each newagent\u2019s knowledge Ka is either {(r3, 1)} or {}, and so on till the generation the gen-eration that knows {}, or {(r8, 1)}. After that generation, the upcoming generationsare initialised with knowledge Ka being any subset of K.\u2013 iterate: The population consists of N agents, and every t epochs N10 new agentsjoin the network and N10 leave. The 1st generation is initialised knowing {(r1, 1)},the next knows a new rule, so their knowledge is {(r2, 1)}, and so on, so everynew generation knows only a new processing rule and the only way to access pastknowledge is to interact with others.\u2013 add rapid: The population consists of N agents, and every t epochs N10 new agentsjoin and N10 leave. The 1st generation of N agents is initialised so that each agent\u2019s aknowledge is a subset of {(r1, w1), (r2, w2)}. The next generation knows what theirancestors knew and a new processing rule, so the knowledge of each new agent a isa subset of the rules {(r1, w1), (r2, w2), (r3, w3)}, and so on. So, new knowledge isprogressively added to the population through the new generations.\u2013 add slow: The is scenario is similar with add rapid, but, in this setting, the newgenerations are added every t \u2217 1.6 epochs instead of t.\u2013 add rapid/slow long: New generations are added every t/t \u2217 1.6 epochs as per addrapid/slow, but the simulator runs for T \u2217 2 epochs.Additionally, for each of the different values of F we specify two ways of commu-nicating the processing rules R:\u2013 max: The sources can only share only one processing rule, therefore they select therule with greatest weight, which corresponds to the rule that they perceive as themost important piece of knowledge.\u2013 all: The sources share their knowledge base, so the target gains access to all the rulesthat the source knows.3.2 Epistemic Condition and Explanatory AdequacyTo \u2018measure\u2019 the epistemic condition and the explanatory adequacy of the DIP underdifferent initial conditions, we require a metric to measure diversity in two dimensions:\u2013 the epistemic diversity, i.e. how different the agents\u2019 knowledge bases are from eachother, given by\u2211Ni=1\u2211Nj=1 diff(i, j); and\u2013 the explanatory adequacy, i.e. the divergence of the DIP\u2019s knowledge from theground truth knowledge, given by diff(KDIP ,K).Epistemic Diversity and Explanatory Adequacy 25For the diff function, there are many metrics to measure diversity, such as EuclideanDistance, Manhattan Distance, KL divergence etc. We use cosine similarity, becausewe want to identify the variations between the vectors of weights on processing rules \u2013which represent agents\u2019 knowledge and ground truth of the environment \u2013 and thereforeneed a metric that focuses on the orientation rather than the magnitude.Cosine similarity is a metric used for the comparison of the similarity between twonon zero vectors A and B in Rn. Specifically, it measures the cosine of the anglebetween the two vectors, and its value is given by Eq. 1:cos sim(A, B) = cos(\u03b8) =A \u00b7 B\u2016A\u2016\u2016B\u2016 =\u2211ni=1 AiBi\u221a\u2211ni=1 Ai2\u221a\u2211ni=1 Bi2(1)After defining the metric for evaluating the performance of the collective and theindividuals, we need then to define the two groups of the population being observed.The first group is the participantswhich refers to all the agents that have been randomlyselected to participate to the next epoch. The other group, who are the \u2018specialists\u2019, is asubset of the participants and identifies the sources of processing rules. In particular, inthis context, if agent i asks for processing rules agent j, and j asks agent k, then specialistis considered the agent k which constitute the actual source of influence. These agentsdon\u2019t have any notion of expertise, but they are the ones credited by their network.In the beginning of the experiments, all the agents give equal credence for process-ing rules to all the agents of their network, they are initialised with different knowledge,and consequently, they give different processing rules to the agents that ask them, andthe credence that others give to them is adjusted overtime based on the utility of theinformation that they offer.Aiming to identify the capability of the agents to adequately explain the environ-ment (explanatory adequacy), we computed the cosine similarity of the knowledgebases Ka of agents with the ground truth K, which we denote with CE1 as well asthe cosine similarity of the knowledge bases Ka of specialists with the ground truth K,which we denote with CS1. Moreover, to observe knowledge distribution and diversitythrough the exchange of processing rules (epistemic diversity), we measured the differ-ence between the pairwise comparison of the cosine similarity of the knowledge basesKa of the agents and the number of participants divided by the difference between thesquare of the number of participants and the number of participants which we denoteby CE2, and difference between the pairwise comparison of the cosine similarity ofthe knowledge bases Ka of the specialists and the number of specialists divided by thedifference between the square of the specialists and the number of specialists, whichwe denote by CS2. Moreover, the calculation of CE1 and CE2 is given by Eqs. 2 and 3respectively, and the calculation of CS1 and CS2 can be computed by substituting par-ticipants with specialists on those equations.CE1 =\u2211participantsi=1 cos sim(Ki,K)\u2211participantsi=1 i(2)CE2 =\u2211participants,i=1\u2211participants,j \u0004=ij=1 cos sim(Ki,Kj) \u2212\u2211participantsi=1 i(\u2211participantsi=1 i)2 \u2212 \u2211participantsi=1 i(3)26 A. Mertzani et al.4 Formal SpecificationThis section provides the formal specification of the multi-agent model. This sectiondefines the agents of the system, the environment in which they exist as well as the RTSIalgorithm for knowledge processing based on which the agents act in this environment.4.1 The EnvironmentThe environment E consists of a network of agents which try to identify the completeknowledge base K corresponding to the ground truth. The agents are connected througha network G(N ,m, \u03bc) which is a Klemm-Eguiluz network [8] with N nodes (whereeach node is a agent), m the number of fully connected agents used for the generationof the network and characterised as \u201cactive\u201d, and \u03bc the probability of a new agent to beattached to one of the \u201cactive\u201d agents (otherwise the agents attaches to an inactive agentand becomes active, substituting a randomly selected agent from the active agents) asdescribed in [17]. This network type was selected because it combines all three prop-erties of many \u201creal world\u201d irregular network, that is high clustering coefficient, shortaverage path length, and scale-free degree distribution.4.2 Agent SpecificationThe autonomous networked units of the population are described by the term \u201cagents\u201d.The specification of the agents is based on the specification in [15], and is given by the6-tuple defined in Eq. 4:i = \u3008SN ,Ki, sci,TNi , a, b\u3009 (4)where SN i is its social network (connected neighbours), Ki its knowledge, which is asubset of the knowledge in the environment K (possibly with different weights), sci isa measure of self-confidence of its knowledge (relative to its neighbours), in whom italso gives credence \u03c4i,j for each agent j \u2208 SN i (cf. [3]). These values are stored in anordered list of credence to neighbours TNi , and are updated each time agent i asks aneighbour j for knowledge (i.e. for a processing rule or rules) depending on how well(similarly) this neighbour approximates the complete knowledge of the environment K.Each agent orders its neighbours in descending order of credence. Each agent has alsotwo reinforcement coefficients a, b which define the rate of change of self-confidenceand credence to the network after each epoch.4.3 AlgorithmThe algorithm is an iterative process of T epochs, and in every epoch each participatingagent goes through the steps described in Algorithm 1. Therefore, in every epoch, asubset of agents A is randomly selected to participate in the next epoch participants \u2282A. The aim of the agents is to manage to produce a good approximation of the completeknowledge base of the environment K, while they are only given only a subset of thisknowledge.Epistemic Diversity and Explanatory Adequacy 27Throughout the epochs each agent looks for sources in the DIP that can provide theprocessing rules that produce the best approximation of the complete knowledgeK. Theknowledge of theDIP can be accessed by asking a neighbouring agent. Therefore, in eachepoch, each agent iterates over its social network SNi according to the order of credenceTNi , to find the source to ask. The neighbour selected j is questioned how similar is itsknowledgewith the complete knowledge baseS\u222a and also the agent asking computes thesimilarity of its own knowledge with the ground truth S(self). If the neighbour asked canoffer a better approximation of the ground truth than the agent asking has, then the agentproceeds in asking the neighbour for processing rules. Depending on the value of theindependent variable R, the agent that asked for processing rules (target) either receivesas a reply a processing rule with a weight (which is the processing rule of the neighbourj that has the greatest weight for j), if R = max , otherwise it receives all the processingrules and their weights. Then, i is integrating this knowledge K\u222a to its knowledge Ki.After that follows the process of reflection, in which each agent updates its credence tothe neighbour selected \u03c4ij and its self-confidence sci depending on whether it can moreadequately explain the environmental knowledge than its neighbour.wriavg =\u2211participantsj=1 wrij\u2211participantsj=1 j(5) wric =wriavg\u2211ni=1 wriavg(6)In this way, the collective forms a knowledge KDIP which is the outcome of theaggregation of the participating agents\u2019 knowledge and normalising the weights, asshown in 5 and 6. The collective/DIP knowledge is defined as in 7.KDIP = {(r1, wr1c), ..., (rr , wrrc)} (7)Algorithm 1: RTSI for knowledge seeking: for each agent ij = selected neighbour from network ;S(self ) = cos sim(K(self ),K);S\u222a = cos sim(K\u222a,K);if S(self ) < S\u222a thenif R = max thenK\u222a = {(rx, wrx)|(rx, wrx) \u2208 Kj \u2227 \u00ac\u2203(ry, wry ) \u2208 Kj .wry > wrx} ;elseK\u222a = Kj ;endendif S(self )i > S\u222a thensci = sci + a \u2217 (1 \u2212 sci);\u03c4i,j = \u03c4i,j \u2212 b \u2217 \u03c4i,j ;endif S(self ) < S\u222a thensci = sci \u2212 b \u2217 sci;\u03c4i,j = \u03c4i,j + a \u2217 (1 \u2212 \u03c4i,j);end28 A. Mertzani et al.According to this formal specification, a multi-agent simulator has been imple-mented in Python3, which is an extension of the system presented in [14] to include theexchange of processing rules. This simulator was used to run a series of experiments,the results of which are present in Sect. 5.Table 1 presents the simulator parameters for the agents and the RTSI algorithm.This specifies either a fixed representative value used in the experiments (e.g. the num-ber or agents, reinforcement coefficients, etc.) or a range of values for those that arerandomly assigned (e.g. the individual agent knowledge bases). Other experimentscould examine different combinations of initialisation of these variables, e.g. to lookfor effects of scale, but this is left for further work.Table 1. Simulator Parameters and VariablesSymbol Description: factor of agent i Initial Condition/RangeN Network of agents 100m Total number of edges N10\u03bc Number of edges to \u2018active\u2019 agents 0.75participants Agents participating in the next epoch N2Ki Individual knowledge base {(r1, w1), . . . , (rm, wm)}, \u2200i, 0 \u2264 i \u2264 m.ri \u2208 Krrk Processing rule k k = {1,2,...,r}wrk Weight of rule rk 0 \u2264 wrk \u2264 1sci Self-confidence for similarity of knowledge 0.5a, b Self-confidence & credence reinforcement coefficients 0.1, 0.1SNi Social network 1 to N agentsTNi Ordered list of credence to social network list length from 1 to N\u03c4ij Credence to agent j 0 \u2264 \u03c4ij \u2264 1S(self) cos sim between self and environmental knowledge 0 \u2264 S(self) \u2264 1S\u222a cos sim between knowledge of agent (neighbour) askedand ground truth0 \u2264 S\u222a \u2264 1r\u222a Rule proposal of (neighbour) agent asked rk. \u2208 Krw\u222a Weight proposal of (neighbour) agent asked 0 \u2264 w\u222a \u2264 1K\u222a Knowledge proposal of (neighbour) agent asked {(r1, w1), . . . , (rm, wm)}, \u2200i, 0 \u2264 i \u2264 m.ri \u2208 KrKDIP Collective knowledge {(r1, w1), . . . , (rm, wm)}, \u2200i, 0 \u2264 i \u2264 m.ri \u2208 Krwriavg Average weight of rule ri 0 \u2264 wriavg \u2264 N2wric Normalised average weight of rule ri 0 \u2264 wric \u2264 15 Experimental ResultsThis section describes three experiments which investigate what initial conditions onthe DIP produce what type of epistemic condition, and how \u2018adequately\u2019 does that epis-temic condition explain the ground truth knowledge. The experiments range over thevariables F and R of Sect. 3.1 under the initial conditions specified in Table 1, withT = 5000, t = 300:\u2013 Experiment 1: Static population of agents, with complete fixed knowledge, anddynamic population with complete fixed knowledge (all the knowledge is availablefrom the first epoch of the simulation).Epistemic Diversity and Explanatory Adequacy 29\u2013 Experiment 2: Dynamic population with progressive addition of new knowledge butnon-persistence of \u2018discovered\u2019 knowledge.\u2013 Experiment 3: Dynamic population with progressive addition of new knowledge andwith persistence of already \u2018discovered\u2019 knowledge.The following subsections describe the results of each experiment in turn, before dis-cussing some over-arching results in Sect. 5.4.5.1 Experiment 1: Static and Dynamic PopulationsIn the first set of experiments, we explore the dynamics of the system for F being setto static and dynamic, and agents are initialised with any combination of the availableprocessing rules.Figure 3 illustrates the evolution of common and specialists knowledge for the dif-ferent settings. Specifically, the 1st column illustrates the results for static and the 2ndfor dynamic for R being max and all. The black line is calculated according to CE1, thered based on CS1, the green according to CE2, and, finally, the blue line based on CS2.Therefore, the black line indicates how \u2018adequately\u2019 the DIP identifies the groundtruth K, while the red line indicates whether how \u2018adequately\u2019 the specialists identifythe ground truth K. The green and blue lines demonstrate the diversity of knowledgewithin the collective and within the specialists, showing the (dis)similarity between theknowledge of each group.R static dynamicmaxallFig. 3. Exp. 1: Knowledge dynamics for static and dynamic population.Starting with the static condition, when R = max , the similarity between the pro-cessing rules of the agents is high, since the group as a whole is influenced by thespecialists to promote a single rule. By contrast, when the sources share all their knowl-edge (R =all), the community and the specialists similarity is decreased. However, the30 A. Mertzani et al.lines corresponding to how well do specialists and community track the environmentalknowledge (red and black) remain low in both cases. This is because the populationis static, therefore the community is prone to ask the sources credited during the firstepochs, regardless of whether they maintained their knowledge. Static populations arestable but also stagnant and agent don\u2019t increase significantly their processing capacityalthough they could (since all the knowledge is discovered).With the dynamic condition, for both max and all, the agents can better explain theenvironmental knowledge. In the former case, the knowledge of the specialists and thecommunity is continuously modified as illustrated by the fluctuating green and bluelines. This demonstrates that different epistemes are generated in this condition, and thesystem could be characterised as quasi-stable and moving from one temporary equi-librium to another with different values for its control variables (cf. [16]). In the lattercase, the specialists are well-identified and have significantly higher similarity with theenvironmental knowledge than the community; however it seems that the other agentscannot assimilate this knowledge and the DIP knowledge seems stagnant.5.2 Dynamic Population, Progressive Addition, non-PersistenceIn this experiment, we observe how the system works with a dynamic population (inwhich the specialist sources are not so easily identified), there is progressive additionof new knowledge brought by joining agents, but knowledge is non-persistent (i.e. newagents only bring new \u2018discovered\u2019 knowledge).Figure 4 illustrates the results for restart and iterate in the first and the second col-umn respectively.R restart iteratemaxallFig. 4. Exp. 2: Knowledge dynamics for DIP with non-persistent knowledgeIn the restart condition, the first generation is initialised with two rules available,the next joins with the third rule, and so on until the 8th generation that has all the rulesEpistemic Diversity and Explanatory Adequacy 31available (as defined in Sect. 3.1). For R = max , the similarity of processing ruleswithin the community is high since agents are given only one rule from the sources.This phenomenon is less striking for R = all , where agents quickly assimilate newknowledge. Note that when new generations possess only one processing rule (only thenew piece of knowledge), agents consider that they cannot learn from others, and theirknowledge remains narrow (low similarity with the environmental knowledge). How-ever, after epoch 2100, when all the processing rules are made available for the newgenerations, there is a significant increase in the community and specialists\u2019 knowl-edge because agents have different levels of knowledge (i.e. different similarity withenvironmental knowledge) and they seek sources to provide them with missing bits ofknowledge.The phenomenon of agents not asking for processing rules because they perceiveothers as having similar knowledge is even clearer under the iterate condition. Par-ticularly, in both max and all, most agents seem to have equal knowledge (i.e. equalsimilarity of own processing rules and environmental processing rules), due to the factthat they all have either zero or one processing rule, and consequently only agents hav-ing an empty knowledge base ask for knowledge. This variation between the emptyknowledge base and the knowledge base containing one processing rule generates thedifference in the similarity of the knowledge of the sources and the community (red andgreen lines), with the specialists. Additionally, the fluctuation of the intrinsic similarityof the collective as well as the group of specialists is caused by the randomness in theselection of agents to leave and join the network.5.3 Dynamic Population, Progressive Addition, PersistenceIn this experiment, we observe the behaviour of the system under progressive additionof knowledge, but new agents may bring any discovered knowledge. Figure 5 demon-add rapid add slow add rapid long add slow long(1).jpg(1).jpgFig. 5. Exp. 3: Knowledge dynamics for progressively added knowledge.32 A. Mertzani et al.strates CE1, CS1, CE2, and CS2 for the add rapid/slow (long) scenarios, for R max inthe first row and all in the second.The rapid progressive addition of knowledge allows minor improvement both inshort-term and long-term (add rapid and add rapid long). Particularly, in both maxand all, the specialists and community knowledge remains low (red and black lines)because new rules cannot be assimilated. By contrast, the slow addition fosters epis-temic improvement (add slow and add slow long). Moreover, in all these scenarios,when R = max different epistemes are produced because sources share parts of theirknowledge and both the community and the sources develop different beliefs over time.5.4 Summary of ExperimentsTo conclude this section, Table 2 summarises what configuration of initial conditionsfor the DIP produces what type of epistemic condition of the DIP, and assesses thecapability of the DIP to explain adequately the environment.Table 2. Summary of experimental resultsF R Epistemic condition Explanatory adequacyStatic Max Epistemic stagnation KDIP \u0002 KStatic All Epistemic stagnation KDIP \u0002 KDynamic Max Epistemic incongruence Conditionally KDIP \u223c= KDynamic All Epistemic incongruence Conditionally KDIP \u223c= KRestart Max Epistemic diversity KDIP \u223c= KRestart All Epistemic diversity KDIP \u223c= KIterate Max Epistemic stagnation KDIP \u0002 KIterate All Epistemic stagnation KDIP \u0002 KAdd rapid Max Epistemic incongruence Conditionally KDIP \u223c= KAdd rapid All Epistemic incongruence conditionally KDIP \u223c= KAdd slow Max Epistemic diversity KDIP \u223c= KAdd slow All Epistemic diversity KDIP \u223c= KStarting from static, we observe that with a static population the DIP has a highsimilarity of knowledge, and therefore they seem to be congruent, but knowledge doesnot seem to be exchanged over the social network. This does not allow further improve-ment in the system and potential adaptation to a dynamic environment. Moreover, thecollective has a low similarity of knowledge with the environment, which means thatthey are not adequately explaining the knowledge K. In contrast, dynamic populationsthat have all the knowledge available from the first epochs (dynamic) seem to be morediverse, and they transition from a status of higher to lower congruence and vice-versa.Epistemic Diversity and Explanatory Adequacy 33Although for certain periods of time they manage to accurately explain the environment,there are other periods that they do not succeed in identifying the ground truth.Moreover, when agents perceive their knowledge to be similar to others knowledge,they do not ask for processing rules and the collective knowledge stagnates. Specifically,in the restart condition, during the first epochs where they are given only one processingrule, agents do not communicate their knowledge. This is also the case for the iteratecondition, where knowledge remains stagnant while the collective is fragmented. There-fore, we argue that knowledge remains static and the agents do not manage to modelthe phenomenon which they observe in the environment, when they consider that oth-ers are incapable of helping them (perceiving their knowledge similar with their ownknowledge), although they might have different knowledge that is useful for them.This would suggest that systemic evolution and epistemic diversity require bothknowledge differentiation and the capability of agents to perceive this differentiation.However, in restart, when all the knowledge becomes available (after 2500 epochs), theagents quickly increase the utility of the collective knowledge with respect to explana-tory adequacy and they produce a collective knowledge that is a better approximationof the knowledge situated in the environment. It is worth noting that the sources seemto \u2018emerge\u2019, i.e. to increase the utility of their knowledge, significantly more than thecommunity, which shows that the ones identified by the collective as specialists are alsomore likely to assimilate new knowledge.Furthermore, the rapid addition of new processing rules fosters diversity, but theagents do not have enough time to adapt and assimilate new knowledge; therefore theycan be congruent in the short term but incongruent in the long-term. This cannot guar-antee that the DIP will manage to produce an adequate explanation of the environmentalknowledge for an extended period. In this case, we observe different epistemes beinggenerated, which could be considered a demonstration of Foucault\u2019s Theory of Knowl-edge & Power in cyber-physical systems. However, when agents share all their knowl-edge (all) the population becomes more congruent with the environment and has thepotential to evolve since it can provide an adequate explanation of the environment.6 Related and Further ResearchRelated research has extensively studied issues of consensus formation in complex sys-tems [11]. More specifically, previous work has focused on the conditions which leadto the alignment of the network [4], as well as the division of it into multiple opin-ions [7]. Much effort has also been made to identify the probability of forming a major-ity depending on the network topology [5].A baseline for using RTSI as a model of distributed information processing, propos-ing the exchange of subjective opinions for the formation of a collective decision andthe self-organisation have been established in [15]. This work extends this model ofRTSI in a different direction, and specifically proposes the communication of process-ing rules not for forming a collective opinion but for developing a collective knowledgeand social explanations. Lopez-Sanchez and Mu\u0308ller [10] suggest that social influencein the form of hate speech can propagate through the whole virtual community and pro-pose countermeasures such as education, deferring hateful content and cyber activism34 A. Mertzani et al.as mechanisms for altering it. In this research, we argue that social influence can be alsoused as an instrument for spreading knowledge and providing explanations instead ofpropagating hate and negative opinions.Additionally, there is a substantial body of literature in topics of information sharingand norm emergence. Villatoro et al. [22] proposed the use of social instruments to facil-itate norm convergence and proved that the subconventions delay global convergenceand jeopardise stability. Incremental social instruments and creating ties between agentshas also provided a mechanism for dissolving self-reinforcing structures and facilitat-ing global norm emergence [9]. Norm or convention emergence can be also achievedthough social learning [19], and under various topologies [2]. Although these worksoffer deep insight into the emergence of a collective property (socially-constructedbehaviours) from local interactions, our approach differs by proposing RTSI as a mecha-nism for producing \u2018adequate\u2019 collective explanations for external properties from localinteractions.Further research could establish a set of evaluation criteria and metrics for multi-agent populations that face problems of producing social and environmental explana-tions. Additionally, further work on different conditions in the population such as agentshaving personalities or intentionally sharing only that part of their knowledge they wantto, in order to direct opinions and thoughts, or more advanced methods for develop-ing self-confidence and credence to the network, such as models of costly signaling orblock-based approaches. Moreover, future research could extend the communication ofthe network and allow not only the exchange of processing rules but also the exchangeof the reasons for selecting these processing rules.Furthermore, the present setting could be modified so that not only can the com-munity adapt its knowledge but also the environmental knowledge can change, towardsor away from to the knowledge of the collective. Moving towards the might cause aloss of expertise that becomes critical when the environmental knowledge moves awayfrom the DIP knowledge. Finally, a really ambitious step is to move from explanationto innovation, how knowledge of the rules can be used to shape the environment forpurposes of self-improvement.7 Summary and ConclusionIn summary, the contributions of this paper are:\u2013 We have specified a problem of explanatory adequacy for self-organising multi-agent systems, as disparate agents use their social network to aggregate their possi-bly incomplete and inconsistent knowledge bases to \u2018explain\u2019 some observed phe-nomenon;\u2013 We have implemented an algorithm based on the Regulatory Theory of Social Influ-ence (RTSI), which includes bilateral influence between targets and sources and theexchange of information processing rules, and implemented it in a simulator for aDistributed Information Processing unit (DIP); and\u2013 We have run three experiments to explore what initial conditions of the DIP andthe RTSI algorithm lead to what type of epistemic condition for the collective, andEpistemic Diversity and Explanatory Adequacy 35use a similarity metric to determine how well these conditions do indeed provideexplanatory adequacy.In conclusion, these experiments point to the following postulates that will beexplored in further work, but we regard as crucial for developing DIP for socio-technicaland cyber-physical systems embedded in dynamic environments. These postulates arethat systemic self-improvement through epistemic evolution requires diversity, a will-ingness to learn, and having good intentions.Primarily, we argue that systemic self-improvement epistemic evolution requiresdiversity. We observed that DIP composed of almost identical agents, in terms of havingthe same knowledge, could not improve their explanatory adequacy. It is also importantthat knowledge should be preserved somewhere in the network, because this knowledgemight yet be relevant and useful at a later time. Moreover, not only should the knowl-edge of the agents be diverse, but the agents should be capable of understanding thediversity of knowledge sources, and be able to identify from whom or where they canreliably acquire or consult expertise.Secondly, systemic evolution requires each individual to be willing to learn. Epis-temic evolution requires agents who are, in the first place, willing to make the effort toask and to answer, but are also willing to make the effort to assimilate the answer. Bothof these are assumptions made by the RTSI algorithm, and factoring in obdurate agents(who will not ask) or intentionally disruptive agents (who block or break communica-tion chains) are scenarios that require further experimentation.Finally, two further requirements for RTSI to enable a DIP to solve the explana-tory adequacy problem are that both sources and targets must have good intentionsagainst a background of popular legitimacy. For example, the DIP might have to dealwith intentionally deceptive agents: for example, a single knowledge source, which isresponsible for transferring knowledge, should not try to manipulate a target, or worse,to perturb the value of KDIP for its own interests rather than the collective (public)interest; or, for another example, \u2018denialist\u2019 cliques, in the form of a group of mutu-ally self-supporting agents whose inaccurate knowledge is altered by neither evidencenor argument but whose \u2018noisy\u2019 presence has a detrimental impact on effective overallperformance. These situations require rules, which implies both institutions capable ofconstraining behaviour and popular legitimacy (i.e. general acceptance of those institu-tions and their rules and punishments) [21].To highlight the importance of good intentions and popular legitimacy, from thesource\u2019s side, we note that all the experiments implicitly share a common characteris-tic: the strong relationship between knowledge and power. In particular, under all con-ditions, the DIP does manage to identify the \u2018specialist\u2019 individuals (who are best, orleast bad, at the task) and credits them for sharing their knowledge. Consequently, themost knowledgeable agents are also the ones who could, in effect control and manipu-late common knowledge and public opinion. This way, these agents can not only occupythe prosocial role of knowledge gatekeeper, but could also become an antisocial \u2018knowl-edge dictator\u2019. This dynamic is clearly illustrated in Foucault\u2019s [6] observation thatpower is based on and reproduces knowledge, while knowledge in turn begets power.Therefore, if the sources have other motives for sharing their knowledge, the expertiseof the network can degenerate into an oligarchy (a \u2018knowligarchy\u2019).36 A. Mertzani et al.Acknowledgements. We are particularly grateful to the three anonymous reviewers whose manyinsightful comments helped to revise and improve the presentation of this work.References1. Afshar, M., Asadpour, M.: Opinion formation by informed agents. J. Artif. Soc. Soc. Simul.13(4), 5 (2010)2. Airiau, St., Sen, S., Villatoro, D.: Emergence of conventions through social learning. Auton.Agents Multi-Agent 28(5), 779\u2013804 (2014)3. Asch, S.E.: Studies of independence and conformity: I. A minority of one against a unani-mous majority. Psychol. Monogr. Gen. Appl. 70(9), 1\u201370 (1956)4. Chacoma, A., Zanette, D.H.: Opinion formation by social influence: from experiments tomodeling. PLoS One 10(10), e0140406 (2015)5. Fadda, E., He J., Tessone, Cl., Barucca, P.: Consensus formation on heterogeneous networks.CoRR abs/2111.11949 (2021)6. Foucault, M.: Power/Knowledge: Selected Interviews & Other Writings. Colin Gordon(1980)7. Hegselmann, R., Krause, U.: Opinion formation by social influence: opinion dynamics andbounded confidence: models, analysis and simulation. J. Artif. Soc. Soc. Simul. 5(3) (2002)8. Klemm, K., Eguiluz, V.M.: Growing scale-free networks with small-world behavior. Phys.Rev. E 65(5), 057102 (2002)9. Liu, Y., et al.: From local to global norm emergence: dissolving self-reinforcing substruc-tures with incremental social instruments. In: International Conference on Machine Learning(PMLR), pp. 6871\u20136881 (2021)10. Lopez-Sanchez M., Mu\u0308ller A.: On simulating the propagation and countermeasures of hatespeech in social networks. Appl. Sci. 11(24), 12003 (2021)11. Medo, M., Mariani, M.S. and Lu\u0308, L.: The fragility of opinion formation in a complex world.Commun. Phys. 4(75), 1\u201310 (2021)12. Nowak, A., Vallacher, R., Rychwalska, A., Roszczyn\u0301ska-Kurasin\u0301ska, M., Ziembowicz, K.,Biesaga, M., Kacprzyk-Murawska, M.: Target in Control. SC, Springer, Cham (2019).https://doi.org/10.1007/978-3-030-30622-913. Cacioppo, J.T., Petty, R.E.: The elaboration likelihood model of persuasion. In: Kinnear,T. (ed.) NA - Advances in Consumer Research 11:673\u2013675, Association for ConsumerResearch (1984)14. Pitt, J., Nowak, A., Michalak, T., Borkowski, W., Vallacher, R.: Knowing what the bits know:social influence as the source of collective knowledge. In: Second International Workshopon Agent-Based Modelling of Human Behaviour (ABMHuB) (2020). http://abmhub.cs.ucl.ac.uk/2020/papers/Pitt.pdf15. Pitt, J.: interactional justice and self-governance of open self-organising systems. In: 11thIEEE International Conference on Self-Adaptive and Self-Organizing Systems (SASO), pp.31\u201340 (2017)16. Pitt, J. and Ober, J.: Democracy by design: basic democracy and the self-organisation ofcollective governance. In: 12th IEEE International Conference on Self-Adaptive and Self-Organizing Systems (SASO), pp. 20\u201329 (2018)17. Prettejohn, B., Berryman, M., Mcdonnell, M.: Methods for generating complex networkswith selected structural properties for simulations: a review and tutorial for neuroscientists.Front. Comput. Neurosc. 5 (2011). https://doi.org/10.3389/fncom.2011.00011. ISSN 1662-518818. Rizzi, L.: The concept of explanatory adequacy. In: Roberts, I. (ed.) The Oxford Handbookof Universal Grammar, Oxford University Press, Oxford (2016)Epistemic Diversity and Explanatory Adequacy 3719. Sen, S., Airiau, St.: Emergence of norms through social learning. In: 20th International JointConference on Artificial Intelligence (IJCAI), vol. 1507, pp. 1507\u20131512 (2007)20. S\u0131\u0302rbu, A., Pedreschi, D., Giannotti, F., Kerte\u0301sz, J.: Algorithmic bias amplifies opinion frag-mentation and polarization: a bounded confidence model. PLoS ONE 14(3), e0213246(2019)21. Trebilcock, M., Daniels, R.: Rule of Law Reform and Development: Charting the FragilePath of Progress. Edward Elgar, Cheltenham, UK (2008)22. Villatoro, D., Sabater-Mir, J., Sen, S.: Social instruments for robust convention emergence.In: 22nd International Joint Conference on Artificial Intelligence (IJCAI), pp. 420\u2013425(2011)23. Wiggins, R.E.: Distributed information processing: trends and implications. In: Aslib Pro-ceedings, vol. 37, no. 2, pp. 73\u201390 (1985)The Complexity of Norm Synthesis and RevisionDavide Dell\u2019Anna1(B) , Natasha Alechina2 , Fabiano Dalpiaz2 ,Mehdi Dastani2 , Maarten L\u00f6ffler2, and Brian Logan2,31 Delft University of Technology, Delft, The Netherlandsd.dellanna@tudelft.nl2 Utrecht University, Utrecht, The Netherlands{n.a.alechina,f.dalpiaz,m.m.dastani,m.loffler,b.s.logan}@uu.nl3 University of Aberdeen, Aberdeen, ScotlandAbstract. Norms have been widely proposed as a way of coordinating and con-trolling the activities of agents in a multi-agent system (MAS). A norm specifiesthe behaviour an agent should follow in order to achieve the objective of the MAS.However, designing norms to achieve a particular system objective can be diffi-cult, particularly when there is no direct link between the language in which thesystem objective is stated and the language in which the norms can be expressed.In this paper, we consider the problem of synthesising a norm from traces of agentbehaviour, where each trace is labelled with whether the behaviour satisfies thesystem objective. We show that the norm synthesis problem and several relatedproblems are NP-complete.1 IntroductionThere has been a considerable amount of work on using norms to coordinate the activ-ities of agents in a multi-agent system (MAS) [11]. Norms can be viewed as standardsof behaviour which specify that certain states or sequences of actions in a MAS shouldoccur (obligations) or should not occur (prohibitions) in order for the objective of theMAS to be realized [9]. We focus on conditional norms with deadlines which expressbehavioral properties [35]. Conditional norms are triggered (detached) in certain statesof the MAS and have a temporal dimension specified by a deadline, which is also astate property. The satisfaction or violation of a detached norm depends on whether thebehaviour of the agent brings about a specified state before a state in which the deadlinecondition is true. Conditional norms are implemented in a MAS through enforcement.That is, violation of a norm results in either the behaviour being pre-empted (regi-mented, [5]), or in the violating agent incurring a sanction, e.g., a fine. See, e.g., [14]for how to determine an appropriate level of sanction.For many applications it is assumed that the MAS developer will design an appro-priate norm to realise the system objective. However, this can be difficult, particularlywhen the internals of the agents are unknown, e.g., in the case of open MAS [6], andwhen there is no direct connection between the language in which the system objectiveis stated and the language in which norms can be expressed. For example, one objectiveof a traffic system may be to avoid traffic collisions, but \u2018not colliding\u2019 is not a prop-erty under direct agent control, and prohibition of collisions cannot be stated as a norm.c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 38\u201353, 2022.https://doi.org/10.1007/978-3-031-20845-4_3The Complexity of Norm Synthesis and Revision 39A poorly designed norm may fail to achieve the system objective, or have undesirableside effects, e.g., the objective is achieved, but the autonomy of the agents is restrictedunnecessarily.The increasing availability of large amounts of system behaviour data [1,23] intro-duces the possibility of a new approach to the design of norms, namely the synthesisof norms directly from data collected during the execution of the system. For exam-ple, data may show that collisions always happen when an agent\u2019s speed is very high,allowing us to state a norm prohibiting agents from speeding too much. In this paper,we consider the problem of synthesising conditional norms with deadlines from tracesof agent behaviour, where each trace is labelled with whether the behaviour satisfies thesystem objective.The contributions of this paper are the following.\u2013 We show that synthesising a conditional norm with deadline (i.e., an obligation ora prohibition) that correctly classifies the traces (i.e., the norm is violated on traceswhere the behaviour does not satisfy the system objective, and is not violated onother traces) is an NP-complete problem.\u2013 We show that analogous complexity results (NP-completeness) also hold for theproblem of the synthesis of sets of conditional norms with deadlines.\u2013 We also consider the problem of synthesizing a norm that is \u201cclose\u201d to a targetnorm. This problem is relevant where there is an existing norm that does not achievethe system objective, but which is accepted, e.g., by human users of a system, andwe wish a minimal modification that does achieve the objective. We show that theminimal norm revision problem is also NP-complete.This paper is organized as follows. Section 2 provides the necessary formal back-ground on conditional norms and on traces of agent behaviours. Section 3 discussesthe complexity of the problem of synthesising a single conditional norm. Section 4 dis-cusses the complexity of synthesising a set of conditional norms. Section 5 discusses thecomplexity of the minimal norm revision. Section 6 discusses related work and Sect. 7presents conclusions and future work.2 PreliminariesIn this section we give formal definitions of the behaviour of agents in the MAS and ofconditional norms.We assume a finite propositional language L that contains propositions correspond-ing to properties of states of the MAS. A state of the MAS is a propositional assignment.A conjunction of all literals (propositions or their negations) in a state s will be referredto as a state description of s. For example, for L = {p, q, r}, a possible state descriptionis p \u2227 \u00acq \u2227 r (a state where p is true, q is false, and r is true).A propositional formula is a boolean combination of propositional variables. Thedefinition of a propositional formula \u03c6 being true in a state s (s |= \u03c6) is the standardclassical one. We use \u0003 for a formula that is true in all states and \u22a5 for the formulawhich is false in all states.40 D. Dell\u2019Anna et al.A trace is a finite sequence of states. We use the notation \u03c1 = (s1, . . . , sk) for atrace consisting of states s1, . . . , sk. For example, a trace could be generated by theactions of all vehicles involved in a traffic accident. We denote the i-th state in a trace \u03c1by \u03c1[i]. We assume that the behaviour exhibited by the agents in the MAS is representedby a set of finite traces \u0393 . We denote by S(\u0393 ) or simply by S the set of states occurringin traces in \u0393 . Each subset X of S(\u0393 ) is definable by a propositional formula \u03c6X (adisjunction of state descriptions of states in X). Note that the size of \u03c6X is linear inthe size of X (the sum of sizes of state descriptions of states in X). For example, ifX = {s1, s2} where s1 = p \u2227 q \u2227 r and s2 = \u00acp \u2227 \u00acq \u2227 \u00acr, the description of X is(p \u2227 q \u2227 r) \u2228 (\u00acp \u2227 \u00acq \u2227 \u00acr). \u0393 is partitioned into two sets \u0393T (\u2018good\u2019, or positive,traces) and \u0393F (\u2018bad\u2019, or negative, traces). The partition is performed with respect tothe system objective, which typically does not correspond directly to the propertiesexpressible in L. We note that the assumption that each trace describing the behaviorof the agents can be labeled as either good or bad is realistic in several contexts and fordifferent kinds of MAS objectives. For example, instances of a process can be deemedas compliant or non-compliant w.r.t. a model [24]; in the traffic domain, traces canbe labeled individually w.r.t. the expected travel time or emissions, or based on theoccurrence of a collision.The problem we wish to solve is how to generate a conditional norm which isexpressed using propositions from L, and that is obeyed on traces in \u0393T and violatedon traces in \u0393F .Definition 1 (Conditional Norm). A conditional norm (over L) is a tuple (\u03c6C , Z(\u03c6Z),\u03c6D), where \u03c6C , \u03c6Z and \u03c6D are propositional formulas over L, and Z \u2208 {P,O} indi-cates whether the norm is a prohibition (P ) or an obligation (O).We refer to \u03c6C as the (detachment) condition of the norm, and \u03c6D as the deadline. \u03c6Zcharacterizes a state that is prohibited (resp. obligated) to occur after a state where thecondition of the norm \u03c6C holds, and before a state where the deadline of the norm \u03c6Dholds. We define the conditions for violation of norms formally below.Definition 2 (Violation of Prohibition). A conditional prohibition (\u03c6C , P (\u03c6P ), \u03c6D)is violated on a trace (s1, s2, . . . , sm) if there are i, j with 1 \u2264 i \u2264 j \u2264 m such that\u03c6C is true at si, \u03c6P is true at sj , and there is no k with i < k < j such that \u03c6D is trueat sk.In other words, a conditional prohibition is violated on a trace if the states in thetrace exhibit a pattern of the following type: a state where the norm is detached (orangein Fig. 1) is followed by a number of states (possibly none) where neither the prohibitionis violated nor the deadline is reached (the yellow states), after which there is a statewhere the deadline is still not reached but the prohibition is violated (the blue state).Note that the state where the prohibition is violated may be the same state where thenorm is detached (not shown in Fig. 1, which considers the case where the three typesof states are distinct).Definition 3 (Violation of Obligation). A conditional obligation (\u03c6C , O(\u03c6O), \u03c6D) isviolated on a trace (s1, s2, . . . , sm) if there are i, j with 1 \u2264 i \u2264 j \u2264 m such that \u03c6CThe Complexity of Norm Synthesis and Revision 41. . . \u03c6C ,\u00ac\u03c6D,\u00ac\u03c6P \u00ac\u03c6D,\u00ac\u03c6P . . . \u00ac\u03c6D,\u00ac\u03c6P \u00ac\u03c6D, \u03c6P . . .Fig. 1. Example of violation of a prohibition (Color figure online)is true at si, \u03c6D is true at sm, and there is no k with i \u2264 k \u2264 j such that \u03c6O is true atsk.In other words, a conditional obligation is violated on a trace if the states in the traceexhibit a pattern of the following type: a state where the norm is detached (light blue inFig. 2) is followed by a number of states (possibly none) where neither the obligation issatisfied nor the deadline is reached (the pink states), after which there is a state wherethe obligation is still not satisfied but the deadline is reached (the gray state). Note that,as in the case of conditional prohibitions, the state where the obligation is violated (thegray state) may be the same state where the norm is detached (not shown in Fig. 2,which considers the case where the three types of states are distinct).. . . \u03c6C ,\u00ac\u03c6D,\u00ac\u03c6O \u00ac\u03c6D,\u00ac\u03c6O . . . \u00ac\u03c6D,\u00ac\u03c6O \u03c6D,\u00ac\u03c6O . . .Fig. 2. Example of violation of an obligation (Color figure online)Note that the violation of a conditional prohibition or obligation does not distin-guish between a single or multiple violations, i.e., a trace violates a norm if at least oneviolation occurs.A conditional norm is obeyed on a trace if it is not violated on that trace. Violationconditions of conditional norms can be expressed in Linear Time Temporal Logic (LTL)and evaluated on finite traces in linear time [4].Example 1. Consider the following simple example. Let L = {p, q, r} be a languagewhere p means that a vehicle is on a particular stretch of a street, q means that it is alarge goods vehicle, and r means that its speed exceeds 15 mph. The p stretch is a steepincline with a blind corner, and heavy vehicles sometimes crash into a barrier at thebottom of the street. The system objective is that such crashes are avoided. An exampleset of positive and negative traces is given below.\u0393T = { \u03c11 = (s1 = p \u2227 q \u2227 \u00acr, s1 = p \u2227 q \u2227 \u00acr, s2 = \u00acp \u2227 q \u2227 \u00acr),\u03c12 = (s3 = \u00acp \u2227 \u00acq \u2227 \u00acr, s4 = p \u2227 \u00acq \u2227 r, s4 = p \u2227 \u00acq \u2227 r),\u03c13 = (s5 = \u00acp \u2227 q \u2227 r, s5 = \u00acp \u2227 q \u2227 r) }\u0393F = { \u03c14 = (s1 = p \u2227 q \u2227 \u00acr, s6 = p \u2227 q \u2227 r, s2 = \u00acp \u2227 q \u2227 \u00acr),\u03c15 = (s1 = p \u2227 q \u2227 \u00acr, s6 = p \u2227 q \u2227 r) }42 D. Dell\u2019Anna et al.Intuitively, positive traces involve only slowly driving trucks when p is true, and arbi-trary speeds otherwise. The following conditional prohibition is violated on all negativetraces: (p \u2227 q, P (p \u2227 q \u2227 r),\u00acp).13 Complexity of Norm SynthesisGiven a set of agent behaviour traces \u0393 partitioned into \u0393T and \u0393F , we wish to synthe-size a norm that correctly classifies each trace (that is, the norm is violated on all tracesin \u0393F , and is not violated on any trace in \u0393T ). Clearly, this is not always possible; twosets of traces may not be distinguishable by a single conditional norm (or even by a setof conditional norms). For example:\u0393T = {(s1, s2, s3)}, \u0393F = {(s1, s1, s2, s3)}cannot be distinguished by a conditional norm.3.1 Prohibition SynthesisWe first define formally the decision problem we call prohibition synthesis.Definition 4. The prohibition synthesis problem is the following decision problem:Instance A finite set of propositions L; a finite set of finite traces \u0393 partitioned into \u0393Tand \u0393F , each trace given as a sequence of state descriptions over L.Question Are there three propositional formulas \u03c6C , \u03c6P , and \u03c6D over L such thatNeg every trace in \u0393F violates (\u03c6C , P (\u03c6P ), \u03c6D)Pos no trace in \u0393T violates (\u03c6C , P (\u03c6P ), \u03c6D)The correspondence between sets of states and formulas over L allows us to restatethe prohibition synthesis problem as follows: given a set of positive traces \u0393T and neg-ative traces \u0393F , find three sets of states XC , XP , XD such that:Neg For every trace \u03c1 \u2208 \u0393F , there exists i and j with i \u2264 j such that \u03c1[i] \u2208 XC ,\u03c1[j] \u2208 XP , and there is no k with i < k < j such that \u03c1[k] \u2208 XD.Pos For every trace \u03c1 \u2208 \u0393T , if for some i and j, i \u2264 j, \u03c1[i] \u2208 XC , \u03c1[j] \u2208 XP , thenthere exists k such that i < k < j and \u03c1[k] \u2208 XD.Theorem 1. The prohibition synthesis problem is NP-complete.Proof. The prohibition synthesis problem is clearly in NP (a non-deterministic Turingmachine can guess the three sets and check in polynomial time that they satisfy theconditions). To prove that it is NP-hard, we reduce 3SAT (satisfiability of a set of clauseswith 3 literals) to prohibition synthesis.1 Clearly, alternative definitions of norms are also possible. For example, since trucks do notcease being trucks while driving along the street, we can also state the prohibition as (p \u2227q, P (r),\u00acp), or we can prohibit a truck driving fast on p: (\u0003, P (p \u2227 q \u2227 r),\u22a5).The Complexity of Norm Synthesis and Revision 433SAT is an NP-complete problem. An instance of 3SAT is a set of clauses, whereeach clause is a disjunction of at most 3 literals, for example, {(x1 \u2228x2 \u2228\u00acx3), (\u00acx1 \u2228\u00acx2 \u2228 x4)}. The question is whether the set of clauses is satisfiable, that is, whetherthere is an assignment of truth values 0 and 1 to the propositional variables that makesall the clauses true; in other words, is there an assignment such that each clause containsat least one true literal. In the example above, assigning 0 to x3 and 1 to x4, and, forexample, 0 to x1 and to x2, makes both clauses true.To start the reduction from 3SAT to prohibition synthesis, suppose an instance of3SAT is given; that is, we have a set of clauses C1, . . . , Cn over variables x1, . . . , xm.We generate an instance of the prohibition synthesis problem such that it has a solutionif, and only if, C1, . . . , Cn are satisfiable (each clause contains at least one true literal).We construct the corresponding instance of the prohibition synthesis problem as fol-lows. The set of states in the prohibition synthesis problem consists of two states s andt (s and t are a technical device; intuitively they serve as the detachment condition andthe violation of the prohibition), and for each variable xi, we need two states ui andvi. When we \u2018translate\u2019 a clause into a trace, we insert ui into the trace if xi occurspositively in the clause, and vi if it occurs negatively. Intuitively, ui in XD will be aproxy for \u2018xi should be assigned 1\u2019, and vi in XD will be a proxy for \u2018xi should beassigned 0\u2019. We give the rest of the construction below. Comments in square bracketsexplain the intuition for each step in the construction.The set of negative traces \u0393F contains:\u2013 a two state trace (s, t) [together with s, t \b\u2208 XC \u2229XP below, this forces s \u2208 XC andt \u2208 XP ];\u2013 for every variable xi in the input, a trace (s, vi, t, s, ui, t) [this ensures that either vior ui are not in XD].The set of positive traces \u0393T contains:\u2013 a single state trace (s) [so s cannot be in XC \u2229 XP ];\u2013 (t) [so t cannot be in XC \u2229 XP ];\u2013 for every variable xi in the input: (s, vi, ui, t) [this means that either vi or ui are inXD]; (vi); (ui); (vi, t); (ui, t); (s, vi); (s, ui);\u2013 for every pair of variables xi, xj in the input: (vi, uj); (uj , vi) [this together withpreceding traces ensures that vi and ui are not in XC or XP ];\u2013 for each clause C in the input over variables xj , xk, xl: (s, zj , zk, zl, t) where zi isui if xi occurs in C positively, and vi if it occurs negatively.It is easy to see that the reduction from the 3SAT instance to the prohibition synthe-sis instance is polynomial in the number m of variables (quadratic) and in the numbern of clauses (linear).We claim that there exists an assignment f of truth values 0, 1 to x1, . . . , xm suchthat all the clauses C1, . . . , Cn are true if, and only if, there is a solution to the prohibi-tion synthesis problem above, where XC = {s}, XP = {t}, and for every i, ui \u2208 XDiff f(xi) = 1 and vi \u2208 XD iff f(xi) = 0.\u2018only if\u2019 direction: Assume that an assignment f that makes C1, . . . , Cn true exists.Let XC = {s} and XP = {t}. For every i, place ui in XD if f(xi) = 1 and vi \u2208 Xd if44 D. Dell\u2019Anna et al.f(xi) = 0. This produces a solution to the prohibition synthesis problem because: s, tsatisfies Neg; for every i, either ui or vi are not in XD, so s, vi, t, s, ui, t satisfies Neg.Positive traces satisfy Pos: either s followed by t does not occur on a trace, or ui, vioccur between s and t and one of them is in XD, or (from the clause encoding) one ofthe literals in the clause is true, so for positive xi it means that ui is in XD and Pos issatisfied, or for negative \u00acxi it means that vi is in XD and again Pos is satisfied.\u2018if\u2019 direction: Assume there is a solution to the prohibition synthesis problem. It isclear (see the comments in square brackets above) that it has to be of the form XC ={s}, XP = {t} and XD containing some uis and vis. In particular, since (s, vi, ui, t)is a positive trace, for every i either ui or vi must not be in XD. Set f(xi) to be 1 ifui in XD and 0 otherwise. Then each clause C = {\u223c xj ,\u223c xk,\u223c xl} (where \u223c xjdenotes xj if it occurs positively or \u00acxj if it occurs negatively) is satisfied by f sincefor every clause there will be one literal which is true. This is because (s, zj , zk, zl, t) isa positive trace, and either for some positive literal xi, ui is in XD, or for some negativeliteral \u00acxi, vi is in XD, so ui is not in XD, so f(\u00acxi) = 1.3.2 Obligation SynthesisWe now consider the obligation synthesis problem.Definition 5. The obligation synthesis problem is the following decision problem:Instance A finite set of propositions L, a finite set \u0393 of finite traces partitioned into \u0393Tand \u0393F , where each trace is given as a sequence of state descriptions.Question Are there three propositional formulas \u03c6C , \u03c6O, and \u03c6D over L such thatNeg every trace in \u0393F violates (\u03c6C , O(\u03c6O), \u03c6D)Pos no trace in \u0393T violates (\u03c6C , O(\u03c6O), \u03c6D)Analogously to the prohibition synthesis problem, the obligation synthesis problemcan be equivalently restated in terms of states: are there three sets of states XC , XO andXD such that:Neg For every trace \u03c1 \u2208 \u0393F , there exist i and j with i \u2264 j such that \u03c1[i] \u2208 XC ,\u03c1[j] \u2208 XD, and there is no k with i \u2264 k \u2264 j such that \u03c1[k] \u2208 XOPos For every trace \u03c1 \u2208 \u0393T , if for some i and j, i \u2264 j, \u03c1[i] \u2208 XC , \u03c1[j] \u2208 XD, thenthere exists k such that i \u2264 k \u2264 j and \u03c1[k] \u2208 XO.Theorem 2. The obligation synthesis problem is NP-complete.Proof. The obligation synthesis problem is clearly in NP. To prove that it is NP-hard,we again use a reduction from the 3SAT problem.As before, consider a set of clauses C1, . . . , Cn over variables x1, . . . , xm, which isan instance of 3SAT. We generate an instance of the obligation synthesis problem suchthat it has a solution iff C1, . . . , Cn are satisfiable. The idea of the reduction is similarto that for prohibitions. We use two auxiliary states s and t, intuitively to serve as thedetachment condition and the deadline, and make sure that neither of them is also theobligation, but now instead of inserting a deadline between s and t in positive traces,we insert an obligation. We want to make some subset of {vi : i \u2208 [1, ...m]} \u222a {ui :The Complexity of Norm Synthesis and Revision 45i \u2208 [1, ...m]} to be the obligation (XO), so that exactly one of vi, ui for each i is inXO. Then ui \u2208 XO can encode that xi is true, and vi \u2208 XO that xi is false, and wecan make the encoding work by creating a positive trace corresponding to each clauseso that at least one of the literals in the clause should be true.The set of negative traces contains:\u2013 a 2 state trace (s, t) [this forces either s \u2208 XC \u2229 XD \u2229 XO, t \u2208 XD \u2229 XC \u2229 XO, ors \u2208 XC \u2229XD \u2229XO, or t \u2208 XC \u2229XD \u2229XO. To rule out the latter two possibilities,we require below that s and t on their own are positive traces.]\u2013 for every variable xi in the input, a trace (s, vi, t, s, ui, t) [this ensures that either vior ui are not in XO, because there is one (s, .., t) sub-trace that does not contain astate from XO].The set of positive traces contains:\u2013 a one state trace (s) [so s cannot be in XC \u2229 XD \u2229 XO]\u2013 a one state trace (t) [so t cannot be in XC \u2229 XD \u2229 XO]\u2013 for every variable xi in the input, a trace (s, vi, ui, t) [this ensures that either vi orui are in XO]\u2013 for each clause C in the input over variables xj , xk, xl, a trace (s, zj , zk, zl, t) wherezi is ui if xi occurs in C positively, and vi if it occurs negatively.The reduction is linear in the number of variables and clauses.We claim that there exists an assignment f of 0, 1 to x1, . . . , xm satisfyingC1, . . . , Cn if, and only if, there is a solution to the obligation synthesis problem abovewhere s \u2208 XC , t \u2208 XD, and for every i, ui \u2208 XO iff f(xi) = 1 and vi \u2208 XO ifff(xi) = 0. The proof of this claim is analogous to that of Theorem 1.Assume that an assignment f satisfying C1, . . . , Cn exists. Let XC = {s} andXD = {t}. For every i, place ui in XO iff f(xi) = 1 and vi \u2208 XO iff f(xi) = 0. It iseasy to check that this is a solution to the obligation synthesis problem.Assume there is a solution to the obligation synthesis problem. It is clear (see thecomments in brackets above) that any solution should satisfy s \u2208 XC \u2229 XD \u2229 XO andt \u2208 XD \u2229 XC \u2229 XO. Since (s, vi, t, s, ui, t) is a negative trace for every i, this meansthat it contains an unsatisfied conditional obligation. This means that for every i, eithervi or ui is not in XO. Since (s, vi, ui, t) is a positive trace, then in any solution, forevery i, either ui or vi has to be in XO. Hence we can use the membership in XO toproduce a boolean valuation of variables xi (1 if ui \u2208 XO, and 0 if vi \u2208 XO). Sincefor every clause C = {\u223c xj ,\u223c xk,\u223c xl}, the trace (s, zj , zk, zl, t) (where zi is vi if\u223c xi = \u00acxi, and ui if \u223c xi = xi) is a positive trace, at least one of zi is in XO. Thismeans that the valuation based on the membership in XO satisfies all the clauses (sinceat least one literal in each clause will evaluate to 1).4 Complexity of Synthesising a Set of NormsIn this section, we consider the problem of synthesising a set of norms. To motivatethe problem, we first give an example where classifying positive and negative tracescorrectly requires more than one norm.46 D. Dell\u2019Anna et al.Example 2. Let the language L be {p, q1, q2, r1, r2} where, for the sake of intuition, pdenotes a particular kind of customer who needs to be greeted in a particular way (r1)before they pass the greeter (q1) and \u00acp is all other customers who need to be greetedin a different way (r2), before q2.\u0393T = { \u03c11 = (s1 = p \u2227 \u00acq1 \u2227 \u00acq2 \u2227 \u00acr1 \u2227 \u00acr2, s2 = p \u2227 \u00acq1 \u2227 \u00acq2 \u2227 r1 \u2227 \u00acr2,s3 = \u00acp \u2227 q1 \u2227 \u00acq2 \u2227 \u00acr1 \u2227 \u00acr2, s4 = \u00acp \u2227 \u00acq1 \u2227 \u00acq2 \u2227 \u00acr1 \u2227 r2) }\u0393F = { \u03c12 = (s1 = p \u2227 \u00acq1 \u2227 \u00acq2 \u2227 \u00acr1 \u2227 \u00acr2),\u03c13 = (s3 = \u00acp \u2227 q1 \u2227 \u00acq2 \u2227 \u00acr1 \u2227 \u00acr2) }This example can only be solved by two norms, because a trace consisting only ofstate s1 is a violation (\u03c12), but s1 alone cannot be prohibited because the trace \u03c11 =(s1, s2, s3, s4) is in \u0393T . So, the trace (s1) must be ruled out by an obligation: after s1,there should be s2 or s3 or s4. From trace \u03c14 in \u0393F , (s3) is a violation, so s3 musteither be prohibited, or it must be ruled out by an obligation, that is, after s3, s4 shouldhappen. If s3 is prohibited, then \u03c11 = (s1, s2, s3, s4) would be a violation, but it isn\u2019t.So after s3, s4 should happen. Therefore two obligations are required, for example,(p,O(r1), q1) and (\u00acp,O(r2), q2).Similarly, two or more prohibitions may be required if different things are prohibited indifferent contexts.If there is a set of norms separating \u0393T and \u0393F , then its size is trivially bounded bythe number of all different non-equivalent norms given the language L. Since L is finite,there are 2\u00d73\u00d722|L| possible conditional norms (there are 2|L| state descriptions, 22|L|possible formulas in disjunctive normal form that can be parts of the norm, 3 positionson which they can occur, and 2 types of conditional norms). There are O(222|L|setsof non-equivalent norms. However, it is possible to produce a much better bound onthe maximal size of the set of norms correctly classifying \u0393T and \u0393F than a tripleexponential in |L|.Theorem 3. If it is possible to correctly classify \u0393T and \u0393F by a set N of norms, thenthis can be done by a set of norms of size at most |\u0393F |.Proof. First, observe that we do not need more than one norm to exclude each trace in\u0393F . So we need to have at most |\u0393F | norms. Second, if a set N of norms is not violatedon any of \u0393T traces, then no norm from N \u2032 \u2286 N is violated on a \u0393T trace.Definition 6. The multiple conditional norm synthesis problem is the following deci-sion problem:Instance A finite set of propositions L; an integer m; a finite set of finite traces \u0393partitioned into \u0393T and \u0393F , each trace given as a sequence of state descriptionsover L.Question is there a set N of conditional prohibitions and obligations over L with |N | \u2264m such thatNeg every trace in \u0393F violates one of the norms in NThe Complexity of Norm Synthesis and Revision 47Pos no trace in \u0393T violates any of the norms in N .Theorem 4. The problem of synthesising a set of conditional prohibitions or condi-tional obligations is NP-complete.Proof. For membership in NP, observe that it is possible to guess a set m \u2264 |\u0393F | normsand check in polynomial time that they correctly classify the traces.Hardness follows from the NP-hardness parts of Theorems 1 and 2.5 Complexity of Minimal RevisionIn this section, we consider the problems of (minimally) revising conditional prohi-bitions and obligations. These problems are relevant when there is an existing normthat does not achieve the system objective, and we wish a minimal modification of theexisting norm that does achieve the objective.Assume we are given a set of traces and a conditional norm (\u03c6C , Z(\u03c6Z), \u03c6D),(where Z \u2208 {P,O}) and need to change it in a minimal way so that it classifies thetraces correctly. The editing distance between conditional norms can be defined in var-ious ways, e.g., for formulas \u03c6C , \u03c6Z , \u03c6D in disjunctive normal form, this could be thesum of the numbers of added and removed disjuncts for all three formulas. Note thatthe set of non-equivalent propositional formulas built from the set L is finite, and sois the number of possible different conditional prohibitions or obligations. Regardlessof how the distance between different conditional norms is defined, for a fixed set ofpropositional variables L there is a maximal editing distance max(L) between any twonorms using formulas over L.5.1 Complexity of Minimal Prohibition RevisionGiven some distance measure dist defined for any two conditional prohibitions \u03b11 and\u03b12 over L, the decision problem for minimal prohibition revision can be stated as:Definition 7. The (decision form) of the minimal prohibition revision problem is asfollows:Instance A finite set of propositions L; a number m; a finite set \u0393 of finite traces parti-tioned into \u0393T and \u0393F ; a conditional prohibition (\u03c6C , P (\u03c6P ), \u03c6D) over L.Question Are there three propositional formulas \u03c6\u2032C , \u03c6\u2032P , and \u03c6\u2032D over L such thatDist dist((\u03c6C , P (\u03c6P ), \u03c6D), (\u03c6\u2032C , P (\u03c6\u2032P ), \u03c6\u2032D)) \u2264 mNeg every trace in \u0393F violates (\u03c6\u2032C , P (\u03c6\u2032P ), \u03c6\u2032D)Pos no trace in \u0393T violates (\u03c6\u2032C , P (\u03c6\u2032P ), \u03c6\u2032D)Theorem 5. Let dist(\u03b11, \u03b12) be computable in time polynomial in the size of \u03b11 and\u03b12, and the range of dist over norms built over propositions from L be bounded bymax(L). Then the minimal prohibition revision problem is NP-complete.Proof. The membership in NP follows from the fact that a solution can be guessed andchecked in polynomial time.NP-hardness is by reduction from the prohibition synthesis problem. Note that ifa solution to the prohibition synthesis problem exists, it will be at most at distancemax(L) from the input norm. So to solve the prohibition synthesis problem, we canask for a solution to the minimal prohibition revision problem with m = max(L).48 D. Dell\u2019Anna et al.5.2 Complexity of Minimal Obligation RevisionGiven some distance measure dist defined for any two conditional obligations \u03b11 and\u03b12 over L, the decision problem for minimal obligation revision can be stated as:Definition 8. The (decision form) of the minimal obligation revision problem is as fol-lows:Instance A finite set of propositions L; a number m; a finite set \u0393 of finite traces parti-tioned into \u0393T and \u0393F ; a conditional obligation (\u03c6C , O(\u03c6O), \u03c6D) over L.Question Are there three propositional formulas \u03c6\u2032C , \u03c6\u2032O, and \u03c6\u2032D over L such thatDist dist((\u03c6C , O(\u03c6O), \u03c6D), (\u03c6\u2032C , O(\u03c6\u2032O), \u03c6\u2032D)) \u2264 mNeg every trace in \u0393F violates (\u03c6\u2032C , O(\u03c6\u2032O), \u03c6\u2032D)Pos no trace in \u0393T violates (\u03c6\u2032C , O(\u03c6\u2032O), \u03c6\u2032D)Theorem 6. Let dist(\u03b11, \u03b12) be computable in time polynomial in the size of \u03b11 and\u03b12, and the range of dist over norms built over propositions from L be bounded bymax(L). Then the minimal obligation revision problem is NP-complete.Proof. The membership in NP follows from the fact that a solution can be guessed andchecked in polynomial time. Analogously to the minimal prohibition revision problem,NP-hardness is by reduction from the obligation synthesis problem; if a solution to theobligation synthesis problem exists, it will be at most at distance max(L) from theinput norm. So to solve the obligation synthesis problem, we can ask for a solution tothe minimal obligation revision problem with m = max(L).6 Related WorkThere has been a considerable amount of work on the automated synthesis of norms. Inthis section, we briefly review some of the main approaches, focussing on work that ismost closely related to our approach.We first review \u2018offline\u2019 approaches, in which norms are synthesised at design time.Shoham and Tennenholtz [34] (see also [16]), consider the problem of synthesising asocial law that constrains the behaviour of the agents in a MAS so as to ensure thatagents in a focal state are always able to reach another focal state no matter what theother agents in the system do. They show that synthesising a useful social law is NP-complete. Van der Hoek et al. [18] recast the problem of synthesising a social law as anATL model checking problem. The authors show that the problem of whether there existsa social law satisfying an objective expressed as an arbitrary ATL formula (feasibility) isNP-complete, while for objectives expressed as propositional formulae, feasibility (andsynthesis) is decidable in polynomial time. Bulling and Dastani [10] consider norm syn-thesis for LTL objectives. In their approach, agents are assumed to have LTL-definedpreferences with numerical values, and the aim of the synthesis is to produce a normthat enforces the objective for some Nash equilibrium. The problems they consider areweak and strong implementation, and norm-based mechanism design. A norm weaklyimplements a normative behaviour function if there exists a Nash equilibrium that satis-fies the LTL formula. A norm strongly implements a normative behaviour function iff allThe Complexity of Norm Synthesis and Revision 49Nash equilibria satisfy the formula. Weak implementation is \u03a3P2 -complete in the size ofthe CGS, preferences, objective and norm. The strong implementation problem can besolved by a deterministic polynomial-time oracle Turing machine that can make two non-adaptive queries to an oracle in \u03a3P2 and is both \u03a3P2 -hard and \u03a0P2 -hard. Weak implemen-tation existence is \u03a3P2 -complete. Strong implementation existence is \u03a3P3 -complete. In[19], the synthesis of dynamic prohibitions (that is, prohibitions corresponding to Mealymachines) for CTL objectives is shown to be EXPTIME-complete. In [32], the synthesisof dynamic norms for LTL objectives and Nash equilibria is shown to be 2EXPTIME-complete when considering the existence of a Nash equilibrium satisfying the objective,and in 3EXPTIME for enforcing all Nash equilibria to satisfy the objective. Other workon norm synthesis using logical specifications of objectives includes [2,36]. Alechinaet al. [4] introduce the concept of norm approximation in the context of imperfect moni-tors. A conditional norm is synthesized to approximate an \u2018ideal\u2019 norm in order to maxi-mize the number of violations that an imperfect monitor can detect. We assume, however,perfectly monitorable norms, and we aim at synthesizing norms that are better alignedwith the MAS objectives by using execution data. In contrast to the approach we presenthere, these approaches assume a complete model the agents\u2019 behaviour is available, e.g.,in the form of a transition system or a Kripke structure.Morales et al. present LION [28], an algorithm for the synthesis of liberal normativesystems, i.e., norms that place as few constraints as possible on the actions of agents. Toguide the synthesis process, LION makes use of a normative network: a graph structurethat characterises the generalisation relationship between different norms, which is usedto synthesise more general, that is, more liberal, norms when possible. The norms syn-thesised by LION are so-called action-based norms, which prohibit agents to performactions in certain states [5]. In our work, we focus on the problem of revising condi-tional norms with deadlines, which are behaviour-based, or path-based, norms, prohibit-ing (or obliging) agents from exhibiting certain behaviours. While both our work andLION synthesise norms to avoid undesirable system states, in our work we focus on theproblem of synthesising norms from data collected during the execution of the system(i.e., traces of agent behaviour), while in [28], the synthesis considers properties of thenormative system (e.g., liberality) which are independent of the behaviour of the agentsin the MAS. We consider the liberality of norms an interesting possible extension of ourwork that could be integrated as a criterion when selecting a new norm among possiblerevisions. Christelis et al. [12] present an EXPTIME algorithm based on AI planningfor synthesising state-based prohibitions that set preconditions to the actions the agentscan perform in a regimentation setting. In our work, we do not assume that norms canbe regimented.Another strand of work focuses on the \u2018online\u2019 synthesis of norms, where normsemerge from the interactions of agents in a decentralised way, e.g., [3,33]. Unlike ourapproach, such approaches typically assume that the agents are cooperative, and/or thatsome minimal standards of behaviour can be assumed. However, cooperation betweenagents cannot be always assumed, particularly in open MAS.Closer to our work are online approaches that use agents\u2019 behaviour to guide cen-tralised norm synthesis. For example, Morales et al. [27] present algorithms for theonline synthesis of compact action-based norms when the behaviour of agents leads to50 D. Dell\u2019Anna et al.undesired system states. In contrast, we consider conditional norms with deadlines thatregulate patterns of behaviour. In other work, Morales et al. have used game theoreticconcepts to guide norm synthesis [29,30]. Their control loop includes game recogni-tion, payoff learning, and norm replication. Their approach to norm synthesis makes useof evolutionary processes to determine, off-line and via simulation, effective and evolu-tionary stable norms, which are then enforced at run-time. However, while the resultingnorms are evolutionary stable, their approach requires sufficient knowledge about theagents, their goals and the environment in which they operate, to permit simulation oftheir interactions. In our work, instead, we focus on a setting where the only labeledtraces of agent behaviors are available. Miralles et al. [26] present a framework for theadaptation of MAS regulations at runtime. They consider norms expressed via normpatterns (i.e., IF-THEN rules associated with constraints on the operators and on thevalues that the norm components can take). The authors describe an adaptation mecha-nism based on Case Based Reasoning. Adaptation is performed at runtime individuallyby a number of assistant agents and then, via a voting mechanism, a final adaptationis approved. The decision on how to adapt norms is taken based on similar previouslyseen cases. On similar lines, Dell\u2019Anna et al. [14] propose a framework for the runtimeselection of alternative norms based on runtime data and for the revision of the sanc-tions of norms based on the knowledge of agents preferences. Unlike these approaches,we do not assume knowledge of the agents\u2019 internals, e.g., their preferences [14] ortheir reasoning and communication capabilities [26]. Corapi et al. [13] and Athakraviet al. [7] discuss the application of Inductive Logic Programming (ILP) [15] to normsynthesis and norm revision. In their work, the desired properties of the system aredescribed through use cases (event traces associated to a desired outcome state), and ILPis used to revise the current norms so to satisfy the use-cases. In their approach, normsand desired outcome are strictly coupled: the desired outcomes of execution traces areexpressed in the same language of the norms and, therefore, are directly enforceable.In our approach we consider MAS objectives that cannot be directly enforced, and weuse norms as a means to achieve such objectives (e.g., a speed limit norm is a meansto achieve vehicles\u2019 safety, but it is not possible to directly enforce safety on vehicles:\u201cno accidents should occur\u201d is not directly enforceable on drivers). In our work, theonly knowledge of the MAS objectives available to the revision mechanism, is a givenboolean labeling of the execution traces. The causal relation between norms and MASobjectives is not given. Because we do not assume that the underlying causal structureof the domain is known to our revision mechanism, we are unable to generate prov-ably correct norm revisions as in ILP-based approaches like those of Corapi et al. [13]and related ones (e.g., [21,31]). ILP-based approaches and our approach can thereforebe seen as representing different trade-offs between the amount of background knowl-edge assumed about the possible causes of norm violations, and the guarantees thatcan be given regarding a particular (candidate) revision. Mahmoud et al. [25] proposean algorithm for mining regulative norms that identifies recommendations, obligations,and prohibitions by analyzing events that trigger rewards and penalties. They focus onagents joining an open MAS who have to learn the unstated norms; we, instead, studyhow to alter existing norms from the point of view of a centralized authority.The Complexity of Norm Synthesis and Revision 51Finally, our work is influenced by research on norm change, including logics fornorm change [8,22], the study of the legal effects of norm change, analyzed and for-malized by [17], and the contextualization of norms [20], which studies how to refinenorms to make them suitable for specific contexts. In our framework, this correspondsto modifying the detachment condition and the deadline of the norms.7 ConclusionsWe considered the problem of synthesising and minimally revising norms to achievea system objective from labelled traces of agent behaviour in a multi-agent system(MAS). We considered a setting where the internals of the agents in the MAS areunknown and where norms are expressed in a different language from that of the systemobjective that they intend to bring about. In such setting, explicit knowledge about therelationship between the enforced norms, the agents\u2019 behavior and the MAS objective isnot given, and the norm synthesis and revision rely on traces of agent behaviour labeledas positive or negative, depending on whether each satisfies or not the system objective.We showed that the problems of norm synthesis and minimal revision are NP-complete.In future work, we plan to investigate the synthesis of approximate norms (i.e., normsthat do not classify all traces perfectly), and more tractable heuristic approaches tonorm synthesis and revision where, for instance, only a bounded number of candidaterevisions of a norm are synthesized based on the available data and the semantics ofconditional norms, and the most accurate norm (i.e., the norm with highest accuracyw.r.t. the labeled traces) is selected.References1. van der Aalst, W.M.P.: Process Mining - Data Science in Action, 2nd edn. Springer, Heidel-berg (2016). https://doi.org/10.1007/978-3-662-49851-42. \u00c5gotnes, T., van der Hoek, W., Rodr\u00edguez-Aguilar, J.A., Sierra, C., Wooldridge, M.J.: Onthe logic of normative systems. In: Veloso, M.M. (ed.) Proceedings of the 20th InternationalJoint Conference on Artificial Intelligence (IJCAI 2007), pp. 1175\u20131180 (2007)3. Airiau, S., Sen, S., Villatoro, D.: Emergence of conventions through social learning. Auton.Agents Multi-Agent Syst. 28(5), 779\u2013804 (2014)4. Alechina, N., Dastani, M., Logan, B.: Norm approximation for imperfect monitors. In: Inter-national conference on Autonomous Agents and Multi-Agent Systems, AAMAS 2014, pp.117\u2013124 (2014)5. Alechina, N., Logan, B., Dastani, M.: Modeling norm specification and verification inmultiagent systems. FLAP 5(2), 457\u2013490 (2018). https://www.collegepublications.co.uk/downloads/ifcolog00022.pdf6. Artikis, A., Pitt, J.: A formal model of open agent societies. In: Proceedings of the FifthInternational Conference on Autonomous Agents, AGENTS 2001, pp. 192\u2013193 (2001)7. Athakravi, D., Corapi, D., Russo, A., Vos, M.D., Padget, J.A., Satoh, K.: Handling changein normative specifications. In: International Conference on Autonomous Agents and Multi-agent Systems, AAMAS 2012, pp. 1369\u20131370 (2012)8. Aucher, G., Grossi, D., Herzig, A., Lorini, E.: Dynamic context logic. In: Proceedings ofLORI, pp. 15\u201326 (2009)52 D. Dell\u2019Anna et al.9. Boella, G., van der Torre, L.W.N.: Regulative and constitutive norms in normative multiagentsystems. In: Principles of Knowledge Representation and Reasoning: Proceedings of theNinth International Conference (KR2004), Whistler, Canada, 2\u20135 June 2004, pp. 255\u2013266(2004)10. Bulling, N., Dastani, M.: Norm-based mechanism design. Artif. Intell. 239, 97\u2013142 (2016)11. Chopra, A., van der Torre, L., Verhagen, H., Villata, S. (eds.): Handbook of Multiagent Sys-tems. College Publications, London (2018)12. Christelis, G., Rovatsos, M.: Automated norm synthesis in an agent-based planning environ-ment. In: Proceedings of The 8th International Conference on Autonomous Agents and Mul-tiagent Systems-Volume 1, pp. 161\u2013168. International Foundation for Autonomous Agentsand Multiagent Systems (2009)13. Corapi, D., Russo, A., Vos, M.D., Padget, J.A., Satoh, K.: Normative design using inductivelearning. Theory Pract. Log. Program. 11(4\u20135), 783\u2013799 (2011)14. Dell\u2019Anna, D., Dastani, M., Dalpiaz, F.: Runtime revision of sanctions in normative multi-agent systems. Auton. Agents Multi-Agent Syst. 34(2), 1\u201354 (2020). https://doi.org/10.1007/s10458-020-09465-815. Dzeroski, S., Lavrac, N.: Inductive logic programming: techniques and applications (1994)16. Fitoussi, D., Tennenholtz, M.: Choosing social laws for multi-agent systems: minimality andsimplicity. Artif. Intell. 119(1), 61\u2013101 (2000)17. Governatori, G., Rotolo, A.: Changing legal systems: legal abrogations and annulments indefeasible logic. Log. J. IGPL 18(1), 157\u2013194 (2010). https://doi.org/10.1093/jigpal/jzp07518. van der Hoek, W., Roberts, M., Wooldridge, M.J.: Social laws in alternating time: effective-ness, feasibility, and synthesis. Synthese 156(1), 1\u201319 (2007)19. Huang, X., Ruan, J., Chen, Q., Su, K.: Normative multiagent systems: the dynamic general-ization. In: Kambhampati, S. (ed.) Proceedings of the 25th International Joint Conference onArtificial Intelligence (IJCAI 2016), pp. 1123\u20131129 (2016)20. Jiang, J., Aldewereld, H., Dignum, V., Tan, Y.: Norm contextualization. In: Coordination,Organizations, Institutions, and Norms in Agent Systems VIII - 14th International Workshop,COIN 2012, Held Co-located with AAMAS 2012, Valencia, Spain, 5 June 2012, RevisedSelected Papers, pp. 141\u2013157 (2012)21. Katzouris, N., Artikis, A., Paliouras, G.: Incremental learning of event definitions with induc-tive logic programming. Mach. Learn. 100(2), 555\u2013585 (2015)22. Knobbout, M., Dastani, M., Meyer, J.C.: A dynamic logic of norm change. In: Proceedingsof ECAI, pp. 886\u2013894 (2016)23. Lorenz, R., Senoner, J., Sihn, W., Netland, T.: Using process mining to improve productivityin make-to-stock manufacturing. Int. J. Prod. Res., 1\u201312 (2021)24. Loreti, D., Chesani, F., Ciampolini, A., Mello, P.: Generating synthetic positive and negativebusiness process traces through abduction. Knowl. Inf. Syst. 62(2), 813\u2013839 (2020)25. Mahmoud, M.A., Ahmad, M.S., Yusoff, M.Z.M., Mostafa, S.A.: A regulative norms miningalgorithm for complex adaptive system. In: Ghazali, R., Deris, M.M., Nawi, N.M., Abawajy,J.H. (eds.) SCDM 2018. AISC, vol. 700, pp. 213\u2013224. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-72550-5_2126. Miralles, J.C., L\u00f3pez-S\u00e1nchez, M., Salam\u00f3, M., Avila, P., Rodr\u00edguez-Aguilar, J.A.: Robustregulation adaptation in multi-agent systems. TAAS 8(3), 13:1\u201313:27 (2013)27. Morales, J., Lopez-Sanchez, M., Rodriguez-Aguilar, J.A., Vasconcelos, W., Wooldridge, M.:Online automated synthesis of compact normative systems. ACM Trans. Auton. Adapt. Syst.(TAAS) 10(1), 1\u201333 (2015)28. Morales, J., L\u00f3pez-S\u00e1nchez, M., Rodr\u00edguez-Aguilar, J.A., Wooldridge, M., Vasconcelos, W.:Synthesising liberal normative systems. In: Proceedings of the 2015 International Confer-ence on Autonomous Agents and Multiagent Systems, pp. 433\u2013441. International Founda-tion for Autonomous Agents and Multiagent Systems (2015)The Complexity of Norm Synthesis and Revision 5329. Morales, J., Wooldridge, M., Rodr\u00edguez-Aguilar, J.A., L\u00f3pez-S\u00e1nchez, M.: Evolution-ary synthesis of stable normative systems. In: Proceedings of the 16th Conference onAutonomous Agents and MultiAgent Systems, AAMAS 2017, S\u00e3o Paulo, Brazil, 8\u201312 May2017, pp. 1646\u20131648 (2017)30. Morales, J., Wooldridge, M., Rodr\u00edguez-Aguilar, J.A., L\u00f3pez-S\u00e1nchez, M.: Off-line synthe-sis of evolutionarily stable normative systems. Auton. Agents Multi-Agent Syst. 32(5), 635\u2013671 (2018). https://doi.org/10.1007/s10458-018-9390-331. Muggleton, S.H., Lin, D., Pahlavi, N., Tamaddoni-Nezhad, A.: Meta-interpretive learning:application to grammatical inference. Mach. Learn. 94(1), 25\u201349 (2014)32. Perelli, G.: Enforcing equilibria in multi-agent systems. In: Agmon, N., Taylor, M.E., Elkind,E., Veloso, M. (eds.) Proceedings of the 18th International Conference on AutonomousAgents and Multiagent Systems (AAMAS 2019), pp. 188\u2013196 (2019)33. Savarimuthu, B.T.R., Cranefield, S.: Norm creation, spreading and emergence: a surveyof simulation models of norms in multi-agent systems. Multiagent Grid Syst. 7(1), 21\u201354(2011)34. Shoham, Y., Tennenholtz, M.: On social laws for artificial agent societies: off-line design.Artif. Intell. 73(1\u20132), 231\u2013252 (1995)35. Tinnemeier, N., Dastani, M., Meyer, J.J., van der Torre, L.: Programming normative arti-facts with declarative obligations and prohibitions. In: Proceedings of the IEEE/WIC/ACMInternational Conference on Intelligent Agent Technology (IAT 2009), pp. 69\u201378 (2009)36. Wooldridge, M., van der Hoek, W.: On obligations and normative ability: towards a logicalanalysis of the social contract. J. Appl. Logic 3(3), 396\u2013420 (2005)Embracing AWKWARD! Real-TimeAdjustment of Reactive Plans Using SocialNormsLeila Methnani1(B) , Andreas Antoniades2 , and Andreas Theodorou11 Department of Computing Science, Ume\u00e5 University, Ume\u00e5, Sweden{leila.methnani,andreas.theodorou}@umu.se2 Guildford, Surrey, UKAbstract. This paper presents the AWKWARD architecture for thedevelopment of hybrid agents in Multi-Agent Systems. AWKWARDagents can have their plans re-configured in real time to align withsocial role requirements under changing environmental and social circum-stances. The proposed hybrid architecture makes use of Behaviour Ori-ented Design (BOD) to develop agents with reactive planning and of thewell-established OperA framework to provide organisational, social, andinteraction definitions in order to validate and adjust agents\u2019 behaviours.Together, OperA and BOD can achieve real-time adjustment of agentplans for evolving social roles, while providing the additional bene-fit of transparency into the interactions that drive this behaviouralchange in individual agents. We present this architecture to motivatethe bridging between traditional symbolic- and behaviour-based AI com-munities, where such combined solutions can help MAS researchers intheir pursuit of building stronger, more robust intelligent agent teams.We use DOTA2\u2014a game where success is heavily dependent on socialinteractions\u2014as a medium to demonstrate a sample implementation ofour proposed hybrid architecture.Keywords: Reactive planning \u00b7 Normative agents \u00b7 Hybrid systems \u00b7Multi-agent systems \u00b7 Games AI1 IntroductionIn a Multi-Agent System (MAS) the ability for individual agents to adjust theirbehaviour when interacting with each other and their environment is criticalto the system\u2019s success [18]. Yet, agents in MAS need to dynamically re-orienttheir priorities away from their individual\u2014often selfish\u2014goals and towards thesystem\u2019s collective goals and vice versa as their environment changes.One technique used to develop agents in highly dynamic environments isBehaviour-Based Artificial Intelligence (BBAI) [11]. Instead of trying to modelthe environment, BBAI strictly focuses on the actions that an agent can takeA. Antoniades\u2014Independent scholar.c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 54\u201372, 2022.https://doi.org/10.1007/978-3-031-20845-4_4Real-Time Adjustment of Reactive Plans Using Social Norms 55and limiting search within a predefined plan for responsive and robust goal-oriented behaviour [15,22]. While this approach does indeed increase the searchspeed, it reduces the flexibility of the system as it is able to react only to what itsdevelopers have specified. Moreover, BBAI on its own is insufficient when appliedto MAS. It does not account for social interactions between agents or any teamwork explicitly, and thus fails any consideration of real-world challenges whereaccounting for social behaviours is required.In this paper, we combine BBAI with formal approaches to get the \u2018bestof both worlds\u2019 by developing a hybrid architecture: Agents With KnoWledgeAbout Real-time Duties (AWKWARD). We integrated the OperA framework[19] with Behaviour-Oriented Design (BOD) [15] for their individual and com-bined strengths in order to produce socially-aware BBAI agents. With OperA,we model the interactions between agents, which contributes towards both gov-erning social behaviour as well as increasing transparency of emerging systembehaviour. Transparency could help developers debug the system more effectivelyand help naive users understand the model [35]. With BOD, we can build reac-tive planning agents that are suited to interact within uncertain and dynamicenvironments. We have implemented a \u2018toy example\u2019, presented in this paper,for the popular video game DOTA2. Video games have traditionally been usedto test AI solutions due to their highly dynamic virtual worlds, which DOTA2offers as a test bed. Note, we do not consider the specifics of the DOTA2 imple-mentation as our contribution; our focus and contribution is the AWKWARDarchitecture.The paper is structured as follows: in Sect. 2, we discuss Behaviour OrientedDesign and OperA as the backbone of our architecture, outlining the relevantcharacteristics of each. In Sect. 3, we introduce the AWKWARD architecture,followed by a sample implementation of the architecture in Sect. 4 and resultspresented in Sect. 5. In the penultimate Sect. 6, we look at related work done innormative agents, comparing and contrasting those architectures with our own.Finally in Sect. 7, we summarise our contributions and identify future work.2 Background2.1 Behaviour Oriented DesignBOD is a BBAI approach that uses hierarchical representations of an agent\u2019spriorities [15]. These representations express both the priority of the agent interms of the goals it needs to achieve, and the contexts in which sets of actionsmay be applicable [12]. Another important feature is the usage of the parallel-rooted hierarchy, which allows for the quasi-parallel pursuit of behaviours and ahierarchical structure to aid the design of the agent\u2019s behaviour. On each plancycle, the planner alternates between checking for what is currently the highest-level priority that should be active and then progressing work on that priority.Wortham et al. [36] detail the building blocks of a reactive plan in BOD, whichare summarised as follows:56 L. Methnani et al.1. Drive Collection (DC): The root node of the plan\u2019s hierarchy: containsa set of Drives. The DC is responsible for giving attention to the highestpriority Drive as at any given cycle only Drive can be active.2. Drive: Allows for the design and pursuit of a specific behaviour. Each Drivehas its own release condition of one or more Senses. Even when it is notthe focus of the planner attention, each Drive maintains its execution stateallowing the quasi-parallel execution of multiple drives.3. Competence: A self-contained basic reactive plan representing the priori-ties within the particular plan. Each Competence contains at least one non-concurrent Competence Element (CE). Each of these elements is associatedwith both a priority relative to the other elements and a context which canperceive and report when that element can execute. The highest-priorityaction that can be executed will do so when the Competence receives atten-tion.4. Action Pattern: Fixed sequences of actions and perceptions used to reducethe design complexity, by determining the execution order in advance.5. Action: A possible \u2018doing\u2019 of the agent, such the use of an actuator to interactwith the environment; i.e. the means of altering the world and self.6. Sense: A reading of the world or internal status from a sensor of the agent,such as measuring distance between specified units in the world; i.e. the meansof reporting environmental and agent status.BOD aims to enforce the good-coding practice \u2018Don\u2019t Repeat Yourself\u2019 by split-ting the behaviour into two core modules: the planner and the behaviour library[14]. The former reads and \u2018runs\u2019 the plan at set intervals. The latter containsthe blocks of code used by the two primitive plan elements, Actions and Senses.The rest of the plan elements are textually listed in dedicated files, written inLisp-like format [15], read by the planner. A plan file contains descriptions ofboth the plan elements and of the connections between the elements.2.2 OperAOperA is an agent organisation framework for the design and development ofMAS consisting of three intermingling models [19]:1. Organisational Model (OM): Describes objectives and the concerns ofthe organisation from a social perspective. The development of an OM isapproached from a top down perspective, that is, with overarching goals anda means to reach them.2. Social Model: Outlines the agent\u2019s role enactment in the form of social con-tracts. These social contracts describe what capabilities and responsibilitieseach role demands.3. Interaction Model: Defines interaction agreements between role-enactingagents in the form of interaction contracts. These contracts serve as verifi-cation for the fulfilment of interaction agreements between relevant actorsspecified by organisational objectives as defined in the OM.Real-Time Adjustment of Reactive Plans Using Social Norms 57OperA requires that all interactions are expressed as scene scripts. A sceneis a formal specification defining which roles within the organisation partakein the interaction, what landmarks from the environment indicate the scene\u2019sstart, and what resulting signals describe its termination. More importantly,the specification contains a set of rules describing the social norms that theparticipating agents are expected to follow for the scene\u2019s full duration. OperAnorms use the deontic expressions of obligation, prohibition and permission as ameans of describing an agent\u2019s social behaviour and further validating whetherit satisfies or violates organisational expectations.The OperA framework provides a formal specification that depends on organ-isational structures and global objectives of the organisation as a whole [19].Moreover, OperA offers an interaction model between agents without requiringknowledge of the internal architecture of the individual agent itself; this qual-ity in particular is our primary motivation for selecting OperA as a normativeMAS framework. Further motivation is offered in Sect. 6 where we compare ourselection with other related methodologies.3 The AWKWARD ArchitectureThe AWKWARD architecture, depicted in Fig. 1, is a hybrid-systems architec-ture designed for agents operating in multi-agent systems. It consists of threemodules, each with a distinct purpose: 1) the reactive planner; 2) the OperAmodule; and 3) the behaviour library. Our solution, inspired by the dual-processtheory presented by [26], employs a \u2018fast\u2019 system 1 and a \u2018slow\u2019 system 2 workingin tandem for efficient decision making while taking into consideration its widerenvironmental and social context.3.1 The AWKWARD PlannerThe \u2018fast system\u2019 consists of the reactive planner. The planner allows the agentto act upon its intuitions: plans with multiple drives are triggered based onits environmental and internal changes. Each change may enable short-term orlong-term goals for the agent to achieve. Reactive planning has the advantageof faster action-selection and the ability to manage dynamic and unpredictableenvironments [11,15]. Most specifically, we use the BOD paradigm due to itsproven use in virtual environments, e.g. games [9,21,34] and simulations [13].BOD, unlike other BBAI approaches, allows the execution of multiple behavioursin pseudo-parallel and has a strong emphasis on modularity and reusability.BOD plans form a hierarchical tree structure that is traversed from the rootto the leaves in order of priority. This order determines the agent\u2019s behaviourgiven the world circumstance it finds itself in. The hierarchy is predeterminedby the plan developer and indicated in the plan. In AWKWARD, plans arewritten as JSON files. At its initiation, the Plan Parser component parses theplan to memory, accessed through the Plan Manager component, storing therelationships between the plan elements and the hierarchical order of those plan58 L. Methnani et al.Fig. 1. Conceptual diagram of the AWKWARD architecture. The diagram is colourcoded; in yellow, representing our System 1, are the parts of the OperA module, inblue are the components of system 2, i.e. the reactive planner; and in green the codecomponents and files shared during execution by multiple agents. (Color figure online)elements. Each agent\u2019s DCs can be constructed from the same drive elements,but will differ only in the order of execution, resulting in different expressedbehaviours per agent. By initiating all roles with the same plan (i.e. same drivecollection hierarchy) and enforcing social norms on agents who violate interactionagreements by explicitly re-prioritising drives, we can shape role- and interaction-dependent plans as needed by the current environment state.At set intervals, referred to as ticks, the planner\u2019s Cycle Manager promptsthe Action Selector component to re-evaluate the agents\u2019 perceived conditionsto check if a new plan element needs to be executed or the currently runningone should continue doing so. This continuous re-evaluation of the current planelements, called the plan cycle, requires access from the planner to the behaviourlibrary. That is, during each cycle, the planner retrieves the sensory inputs inthe form of Sense plan elements, and may trigger actuators in the form of Actionplan elements. The plan cycle is set on a fixed frequency based on an externalupdate signal; for example, in our toy implementation, the plan cycle is set onevery frame update inline with previous implementations of BOD in games [21].On every tick, the Action Selector component retrieves the plan from memoryand checks the Drive Collections (DCs) in a hierarchical order. If the conditionsof a DC are satisfied, as determined by its corresponding Sense elements, it isexecuted. The planner then traverses through the drive elements of the DC,checking if they are eligible to be executed or not. These comparisons are doneby checking by comparing current sensory reading against a set of preconditions,Real-Time Adjustment of Reactive Plans Using Social Norms 59expressed as sense elements, to determine if the behaviour should be pursued ornot by using simple boolean logic. If a drive fires, the planner stops its search atthe current tick. This approach of local search enables agents to produce complexbehaviours with minimal computational resources as there is no need to exploreevery possible behaviour at each time [22]. If the drive fired is a different one fromthe previous cycle, then the existing one \u2018pauses.\u2019 In other words, at the DC level,different drives can be in different states of execution enabling a quasi-parallelpursuit of multiple behaviours. Instead, the agent focuses\u2014like our system 1does\u2014on whatever the highest priority behaviour that should be triggered is,e.g. staying alive, instead of unnecessarily checking if lower priority behaviourscould also be triggered [15,36].3.2 The OperA ModuleIn AWKWARD, the \u2018slow\u2019 system is the OperA module. It validates the socialbehaviour of the agent and provides direction to the reactive planner upon thecompletion\u2014either with a success or failure\u2014of a drive\u2019s execution. As discussedin Sect. 2, OperA is instantiated with a collection of Interaction Scenes, i.e. formalspecification defining which roles within the organisation partake in the definedinteraction. Using the senses found in the behaviour library module, the CycleManager component prompts the OperA module to check whether a scene hasbeen initiated or terminated.While a scene is running, the OperA module verifies that the agent\u2019sbehaviour fulfils all social obligations that the agent has towards the otheragents participating in the same scene. If the agent does not fulfil its obliga-tions, then the OperA module instructs the planner to rearrange the priority ofthe drives in the currently running Drive Collection. This rearrangement is doneby pushing upwards in the hierarchy any drive that corresponds to the desirablesocial behaviour. The OperA module is informed through formal specificationsabout which drive should correspond to which social behaviour. It identifiesthem within the current in-memory version of the plan by using a string equal-ity operation. When the adjustment of drives is done, the new plan is storedin the system\u2019s memory, overwriting the old version. The OperA module checksif the re-prioritisation has produced behaviour that falls within the social andorganisational norms the agent needs to comply with. If not, the OperA modulecontinues to adjust the plan\u2019s drives further until the expected social behaviouris achieved. For this social norm validation, OperA uses the same senses as theplanner component does to check which plan elements should be executed.In its past implementations, a single instance of OperA operated at a globallevel [2,3], i.e. it was responsible for agents and interactions in the model. InAWKWARD, each agent contains its own local instance of OperA; i.e. eachAWKWARD agent only checks its own behaviour in its current interaction scene.An advantage of this approach is that it allows us, at least in larger environments,to keep track of the multiple localised interaction scenes that the agent can bein simultaneously.60 L. Methnani et al.The use of a localised instance of OperA takes inspiration from Dennett\u2019sdescription of social constructs, where local efforts are made by agents to \u201csteertheir part of the whole contraption while [remaining] blissfully ignorant of thecomplexities on which the whole system depends\u201d [17]. That is to say, each agentdoes not need to have any conceivable notion of the global system\u2019s intricacies,but rather a partial comprehension which may suffice for competence. In prac-tical terms, as demonstrated in our toy example that is further discussed inSect. 4, by having local copies of OperA carried with each agent also means thatan AWKWARD agent is not constrained to interacting with other AWKWARDagents only. Rather, the agent can consider and interact with any agent archi-tecture, as well as humans. Moreover, an AWKWARD agent does not requireperfect knowledge of all agents in the same environment\u2014which is impossibleto maintain in certain scenarios, e.g. competitive games\u2014to continuously adjustand moderate its behaviour within a defined socio-organisational role.3.3 Behaviour LibraryWhile each agent has its own individual plan structure, a single instance of thebehaviour library can be shared across all agents. It is the collection of all pos-sible primitives (i.e. Senses and Actions) as discussed in Sect. 2.1. It is accessedthrough global function calls in the primitives\u2019 tick functions. The behaviourlibrary must therefore maintain a direct pointer to the agent that makes anyparticular function call in order to return values appropriate to the agent thatrequested them. By having a single behaviour library for all agents, we not onlyenable code reusability, but also reduce memory footprint of the agents and sup-port the hosting of a remote behaviour library that runs complex actions andsenses [14].As discussed above, the behaviour library is accessible by both the plannerand the OperA modules as they each provide control over the agent\u2019s meansof environmental perception, internal status, and any actuators available. Thisdecision to reuse the same Senses enables code reusability but also constrainsOperA\u2019s knowledge to that of the agent, which it uses for the action-selectionprocess. Arguably, this is also a more realistic implementation of Kahneman\u2019sdual-system theory [26]: our system 1 acts reactively and system 2 acts deliber-ately, but the embodiment with its sensors and actuators, i.e. behaviour library,is shared by both systems.4 Implementation in DOTA2We developed a \u2018toy example\u2019 in DOTA2, a popular game characterised by itsextremely steep learning curve and complex emerging behaviour through theinteractions of the different actors between themselves and their environment.We selected this game due to its complexity, inherent need for a MAS approach,recognition in the AI research community, and access to a public API for AIReal-Time Adjustment of Reactive Plans Using Social Norms 61researchers1. Moreover, DOTA2 has been used in the past by the AI commu-nity; OpenAI [7] developed agents that were able to outperform 99% of theDOTA2 player base. Our interest, unlike OpenAI, extends beyond the scope ofthe individual agent and creating human-beating agents. Instead, we used thishighly dynamic environment to demonstrate how AWKWARD can be imple-mented and have BBAI agents working together in a team by using OperA tomodel and validate their social interactions.4.1 DOTA2In the game, two opposing teams of five players (i.e. agents) navigate through ter-rain, striving to destroy a structure in their enemy\u2019s base known as the Ancient,while also defending their own. There are five roles\u2014or positions\u2014to fill perteam. Each team agent is a hero that is assigned a position complementary totheir given skill-set. For instance, a hero with healing capabilities can fulfil theresponsibilities of a Position 5 role, which includes supporting a hero in the Posi-tion 1 role. In the early game, the Position 1 role is one of the weakest members.As the match progresses, Position 1 typically becomes the strongest on the team.However, to reach that state, a social norm exercised in most games involves giv-ing Position 1 priority, at least in certain scenes, to perform the self-advancingactivity known as farming. However, given specific circumstances, supportingroles may break that norm to farm in favour of advancing themselves. Hence, itis important to alternate strategies between pursuing behaviours for the benefitof others on the team and for your own personal performance. The resultingteam of agents demonstrate emergent behaviour in the arena as they interact.This emergent behaviour can be difficult to perfectly model or even understandfrom the observer\u2019s perspective.4.2 The Reactive Planner Module and Behaviour LibraryAs we discussed in the previous section, AWKWARD consists of a planner mod-ule and a behaviour library. In order for each agent to behave in compliance withits assigned role, its dedicated plan must consist of a distinctly ordered collec-tion of drives (i.e. DCs). In our DOTA2 implementation, the plan is describedin a JSON string that is parsed by the planner. We synchronised the plannerupdate frequency with the game\u2019s internal execution update; i.e. the plannerticks the DC to check its drives on every frame update. In our toy example, weimplemented a sample DC with multiple drives.One of our implemented drives is the DE-FarmLane, represented in Formal-ism 1. The drive prompts the behaviour of seeking out enemy units called creepsin the hero\u2019s assigned lane in the environment and striking them when they arelow on health in order to achieve what is referred to as a last hit. Last hits resultin a kill and a gold bounty for the hero to collect. Gold is the currency used topurchase items in-game providing heroes with added attributes and abilities in1 Available at: https://developer.valvesoftware.com/wiki/Dota_Bot_Scripting.62 L. Methnani et al.battle. For example, a healing salve can be purchased and consumed to aid inhealth regeneration.The option for health regeneration is captured by Formalism 2. This drive isexecuted in response to the agent\u2019s internal state: a measure of low health, asdefined by the agent designer. It is important to note that two drives such asthe external state of farm time in DE-FarmLane and internal state of low healthin DE-Heal, could be true at the same time. In our current implementation,which behaviour is expressed is determined by plan structure; namely the orderof executing drives. For example, if DE-Heal is prioritised over DE-FarmLane,then it will execute for as long as the world satisfies its low health condition, oruntil a drive of higher priority is able to run. For instance, if the agent has lowhealth while simultaneously taking damage the plan designer might prioritise abehaviour that more urgently involves retreating.farm time \u21d2\u0002\u23d0\u23d0\u23d0\u23d0\u23d0\u23d0\u23d0\u2329 laning phase ended?\u21d2 goalcreep can be last hit?\u21d2 lastHitCreepcreep wave far?\u21d2 goToCreepWave\u21d2 goToAssignedLane\u232a(1)low health \u21d2\u0002\u23d0\u23d0\u23d0\u23d0\u23d0\u23d0\u23d0\u23d0\u23d0\u2329full health?\u21d2 goalhealing ability?\u21d2 use healing abilityhealing item?\u21d2 use healing itemenough gold?\u21d2 buy healing item\u21d2 retreat\u232a(2)The drive element DE-Retreat, represented in Formalism 3, prompts thebehaviour of seeking refuge in the occurrence of declining health. This drive,as it is currently implemented, only fires when the hero is below 30% healthand directs the hero towards their home base where their fountain resides andprovides protection while regenerating health.under attack \u21d2\u0002\u23d0\u23d0\u23d0\u2329full health?\u21d2 goallow health AND taking damage? \u21d2 retreat\u232a(3)Drives may fire Competences or Action Patterns. The competences consistof an ordered list of competence elements that fire other competences or actionpatterns. The action patterns consist of a sequence of one or more actions\u2014aprimitive element found in the behaviour library along with senses. For instance,Formalism 1 depicts DE-FarmLane and lists lastHitCreep as a competence ele-ment that fires the action pattern shown in Formalism 4. The action patternsconsist of selectTarget followed by rightClickAttack, which are defined inthe behaviour library.\u3008selectTarget \u2192 rightClickAttack\u3009 (4)An agent\u2019s individual behavioural desire is shaped by how its plan element arearranged and executed. Consider again the drive element DE-FarmLane, whichReal-Time Adjustment of Reactive Plans Using Social Norms 63encourages a hero to individually collect as much bounty from last hitting lanecreeps as possible. All heroes have this drive in their plans, and while it is acommon desire for all members of the organisation to maximise their individualfarm, it would not benefit the collective team if all members were to continuouslyact selfishly. For instance, in the early game a hero with the role of Position 1is often vulnerable and weak with little of the gold needed to mature theirabilities and grow their arsenal. It is therefore the duty of the Position 5 role tosacrifice farm for the sake of their allied member who requires it more at thisearly stage. Social interactions become particularly interesting and importantfor us to capture here. This is also where the OperA framework shines, as itenables the definition of social role assignments and interaction agreements forthe advancement of the whole team unit.4.3 The OperA Module ImplementationWe use social interactions to alter the order in which a reactive agent\u2019s drivesare fired. Accomplishing this real-time adjustment should demonstrate successfulexpression of social behaviour. That is, altering selfish priorities for the collectivegood of the organisation the individual hero is a member of. The OperA mod-ule requires a record of the relevant members and their associated roles withinthe society. Currently, each hero\u2019s role assignment also determines their laneassignment in the environment, which further characterises their \u201cright\u201d.For example, Table 1 outlines the role of Position 1, indicating that theirultimate objective is to ensure their team\u2019s victory, which can only be done bycollecting enough items to become powerful. Their sub-objectives are thereforeto farm as much as possible, buying items with earned gold from farm. Theyhave the right to do so in their assigned zone: the safe lane\u2014named as such dueto its proximity to safety zones. An example norm that applies to a Position 1hero is the obligation to farm enemy creeps when they are close by. In contrast,Table 2 shows the role table for Position 5, who is not permitted to farm whilePosition 1 is nearby. This sacrifice is to ensure Position 1 gains enough gold toquickly advance their role and carry the team in the later phases of the game.Table 1. Position 1 role defined using the OperA frameworkRole id Position 1objectives Carry team to victorysub-objectives Farm and buy itemsrights High priority in safe lanerules IF enemy creep around THENOBLIGED to farmIn the OperA module, relevant norms are constructed by parsing JSONstrings with their descriptions. Each norm has a name identifier, an associated64 L. Methnani et al.Table 2. Position 5 role defined using the OperA frameworkRole id Position 5objectives Support team to victorysub-objectives Heal allies and take fightsrights Low priority in safe lanerules IF Position 1 nearby THENNOT PERMITTED to farmTable 3. Interaction Scene for Priority Lane FarmingScene Priority lane farmingroles Carry and supportlandmarks Partner and creeps nearbyresults Partner not nearbyrules IF highest priority around THENOBLIGED to farmELSENOT PERMITTED to farmbehaviour, and a deontic operator. The behaviour corresponds to the suitabledrive element of the agent\u2019s planner. The deontic operators we focus on for thisimplementation are NOT PERMITTED and OBLIGED. The PERMITTED operator is asofter norm that induces no change to the plan in the current implementation. Anorm also has a reference to an assigned agent\u2019s plan. It is validated by checkingthe agent\u2019s active drive against the expected (norm) behaviour, and whether itis permissible or required within a given circumstance. If a norm is violated,sanctions should be applied. In our implementation, a norm can alter the planin response to a violation. Recall that our planner implementation allows for theremoval and insertion of drive elements at runtime.While norms can\u2014and should\u2014be associated with the individual agent, whatis most interesting for our purposes is the use of norms to characterise interactionscenes between agents. An OperA interaction scene has a unique name identifier,a list of roles involved in the scene, a list of landmarks that indicate the startof a scene, a list of results that indicate the end of a scene, and the rules thatindicate the norms that constrain the agents\u2019 behaviours such that they remainwithin the social expectations of the team (Table 3). In our implementation ofscene objects, the landmarks and results correspond to sense primitives that werere-used from the reactive plan elements, as do the rule conditions that determinethe appropriate norm to apply in the scene.Consider again the agent\u2019s DE-FarmLane (Formalism 1). This drive is firedwhen the senses isFarmingTime and isSafeToFarm return true. We have definedfarming time as the early game (approximately the first 10 min.) and safetycorresponds to the fight activity and whether any enemy heroes are threateningthe agent\u2019s farm ability. For the purposes of this demonstration, we assume itis always safe to farm and the sense will return true. The competence elementsReal-Time Adjustment of Reactive Plans Using Social Norms 65that the farming drive consists of checks conditions in a prioritised order: if theagent is not at the creep wave, they must move there. (Unlike action patternswhich always execute in the same order, competences will skip this element ifthe condition returns false). If the agent is already at the creep wave, then thenext condition check is whether any enemy creep around can be last hit. A creepcan be last hit when their health is lower than the hero\u2019s attack damage andis located within attack range. If this condition is true, the agent will selectthe appropriate target and attempt to land the last hit. Notice that the driveis entirely self-directed and lacks any social consideration. That is, each agent,while expressing farming behaviour, will pay no mind to whether they have thehighest priority around or not. An agent pair farming in the same lane is notoptimal behaviour from a social perspective. The agents must abide by socialnorms for this given circumstance, and OperA can facilitate this interaction usingscene scripts. The result is preservation of interaction agreements and alteredplans that better suit each agent\u2019s role requirements.While this farm priority check is a simple example that can just as easily beincorporated into each agent\u2019s plan, we argue that it will become limiting andwasteful over the course of the game. We observed that when social awarenesswas incorporated into an individual agent\u2019s plan, the structure not only becamelonger to read and more complicated to understand, but also resulted in increasedidle time while an agent was attempting to express farming behaviour. When anagent of higher priority is farming, the agent should not continue to attempt tofarm, but should instead fire a different drive for productivity. This coordinationis best handled by an organisational/social-aware structure, like OperA. Weargue that the individual agent itself should not have too many intricate detailsabout interactions, especially considering the long-time horizons of a game likeDOTA2 where social behaviour itself is expected to shift along with the variousgame phases. In fact, OperA scene scripts very nicely accommodate this gameattribute. If behaviour can be altered by OperA, then the reactive plannersbecome simpler to construct. The complexity is captured and described by theOperA interaction models.5 ResultsIn this paper, we are exclusively concerned with developing a system that canalter agent plans in response to social interactions, regardless of whether otherentities in the society have a similar architecture or not. Hence, we designed theevaluation of our sample implementation to reflect that. For the scope of thisproject, we focus only on the first 10 minutes of the game; within this time inparticular, farming priority is important in terms of behaviour adjustment dueto expected social norms.The interaction under evaluation is described by the Priority Farm scene asdefined by an interaction scene object. The particular behaviour that is expectedis for the Position 5 agent\u2014the AWKWARD bot\u2014to give up its own farm for thebenefit of the ally of higher priority in the same lane. In this case, the relevantally is the Position 1 agent\u2014the default bot.66 L. Methnani et al.Fig. 2. (Left) Similar rate of gold acquisition between Position 5 (orange) and Position1 (blue) DOTA2 agents when OperA makes no alterations to Position 5\u2019s plan duringthe Priority Farm interaction scenes. (Right) Diverging rate of gold acquisition betweenPosition 5 and Position 1 DOTA2 agents as a result of AWKWARD rearranging theplan for the agent in the Position 5 role. Trend lines represent average over N = 5trials. (Color figure online)To demonstrate how these changes in the plan impacts the performance ofagents, we used gold acquisition as a quantitative metric. This is the standardmetric used for players\u2019 performance evaluation in DOTA2 tournaments. Theagent\u2019s value of gold is measured over the course of the first 10 min. of thegame. The right subplot in Fig. 2 shows the divergence in gold acquisition overtime between the AWKWARD bot of position 5 and the default DOTA2 bot ofposition 1 over five trials. This divergence can be explained by the AWKWARDbot\u2019s social behaviour change; OperA banning farm will result in the role sac-rificing its own gain and promoting its ally\u2019s acquisition of gold instead. TheAWKWARD bot\u2019s social adjustment is to deny itself from farming when thepriority ally (Position 1) is around.In this scenario, we mark the moments in time where plan changes areexpected to occur due to social interactions, but OperA is not inducing thechange in order to see the difference in each bot\u2019s gain. While both roles stillacquire gold, Position 1 has acquired less than expected, and both agents approx-imately match each other\u2019s gain.In contrast, the left subplot in Fig. 2 illustrates a different trend when theAWKWARD bot does not change its plan within the social context. These plotsshow the two roles on par with one another in terms of gold acquisition over time.When the AWKWARD bot does not alter its plan and continues to attempt tofarm, even while the ally of higher priority (Position 1) is also farming in thesame lane. The difference in gold acquisition between scenarios can be seen overnumerous trials (the dotted lines shows the average linear trend over 5 trials).Real-Time Adjustment of Reactive Plans Using Social Norms 67The data varies in time and gold value due to added randomness across gameinstances, but the overall trends remain similar.6 Related WorkThe AWKWARD architecture combines the normative framework OperA withthe Behaviour-Based AI architecture BOD. In this section, we review and com-pare our architecture to relevant approaches found in the literature. As a com-plete survey of the literature is beyond the scope of this article, we focus on themost relevant approaches that we considered during the conceptualisation of theAWKWARD architecture.6.1 Behaviour-Based AIVarious approaches of Behaviour-Based AI have been proposed for achievingreal-time performance in embodied\u2014physical or virtual\u2014agents including theSubsumption Architecture [10], Pengi [1], and ANA [29]. These bottom-up reac-tive planning approaches use condition-action pairs without\u2014or with minimal\u2014internal state; i.e. a simple functional mapping between perceived environmentalstimuli and their appropriate responses. Such reactive approaches have provenhighly effective for a variety of problems [30]. However, in comparison to BOD,these approaches expect little regularity in the arbitration of behaviour; i.e. allpossible behaviours must be considered at all times. Moreover, they cannot storeinformation dynamically, thus putting the onus on the developer to predict possi-ble stimuli and develop the appropriate behaviours. BOD overcomes these issuesby further decomposing behaviours into \u201cthings that need to be checked regu-larly, things that only need to be checked in a particular context, and thingsthat one can get by not checking at all\u201d [15].While BOD also originated as a robotics cognitive architecture with its POSHimplementation [15]\u2014and most recently Instinct [36]\u2014it has made its way tovirtual environments such as games, e.g. pyPOSH in Unreal Tournament [9],POSH-Sharp in StarCraft [21], and UNPOSH in Unity [34]. However, in theseimplementations of BOD, there was no mechanism to verify that the agentsadhere to their social roles. Instead, unlike our AWKWARD implementation, theplan developer had to ensure that any social norms were accounted for duringthe plan\u2019s development, limiting the possible interactions between agents andteam-level performance of the agents.6.2 Normative Agents and Self-organisationThe AWKWARD architecture is related to previous work done in the devel-opment of normative agents. Early work in the literature for normative agentsproposes architectures that extend Belief, Desire, Intention (BDI) models withnorms [16,27,28]. These agents deliberate around the generation and selectionof both goals and plans. For instance, [8] describe their (Beliefs, Obligations,68 L. Methnani et al.Intentions, and Desires) BOID agent architecture that appends obligations as amental attitude in addition to its beliefs, desires and intentions. However, as [20]argue, BDI agents focus towards their own goals instead of social interactions\u2014both with other artificial and human agents\u2014making such approaches unsuitablefor multi-agent systems where cooperation between agents is necessary.Another related approach is N-Jason, a norm-aware BDI agent interpreterequipped with the programming language for agent norm compliance at run-time [28]. It extends Jason/AgentSpeak(L) with addition of normative conceptssuch as obligations, permissions, prohibitions, deadlines, priorities, and duration.Similar to N-Jason, N-2APL is also a BDI agent architecture that supports norm-aware deliberation [4]. N-2APL allows agents to adopt normative behaviour inthe form of deontic obligations and prohibitions with specified deadlines. OperAbeing a framework for formal specifications of social interactions instead of acomplete architecture, enables us to define explicitly the social interactions inthe form of scene specifications while also keeping the reactive planner compo-nent independent; i.e. operational without the OperA module.Relevant work also includes existing methodologies for the development ofnormative agents in multi-agent organisations such as Moise [23] and its exten-sion Moise+ which adds an inheritance on the roles and structural verifica-tion features [24,25]. Moise+ is based on notions of roles, groups, and missions,enabling explicit specification of MAS organisations that agents can reason aboutand organisational platforms can enforce [25]. Moise+ offers an implicit descrip-tion of an interaction protocol through deontic links that specify agent permis-sions and obligations within their assigned missions. An agent belongs to groupswhere they are offered a set of permitted roles and missions. Thus, upon changingroles and missions, groups are also subject to change, allowing for task-orientedcoalitions to be defined. While interactions in Moise+ are task-driven, OperAleads by social expectation in the form of explicit contracts; a main motivationfor its adoption in the work presented here.All of these approach capture and represent social norms in order to enableagents to self organise. However, they rely on integrating the social normenforcement directly into the decision making system. In our architecture, weallow for both reactivity and social deliberation as the situation demands. Thisensures that our agents can act efficiently in their environment on their own,i.e. act as complete complex agents, while also organising themselves based ontheir social roles\u2014and corresponding responsibilities\u2014when they are a part ofa larger organisation. Moreover, our decision to use a distributed version ofOperA ensures that our AWKWARD agents can interact with other AWKWARDagents, non-AWKWARD agents, and even humans.Finally, AWKWARD considers that all agents have the capacity to act self-ishly and altruistically to varying degrees determined by their roles and socialinteractions. In contrast to above approaches, we use a reactive planning archi-tecture for the individual agent motivated by its ability to handle uncertaintyand dynamic environments. We assign obligations via external expectations thatmay be subject to change. This approach of global coordination also differsReal-Time Adjustment of Reactive Plans Using Social Norms 69from other work proposed for developing normative reactive planning agents,such as the NoA architecture [27]. While NoA adopts norms and deliberatesover their activation, our proposed framework concerns itself with dynamicallyimposing, monitoring and enforcing norms through global coordination, and thendistributed enforcement, rather than individual deliberation.6.3 Hybrid Approaches with Reactive PlanningAWKWARD combines formal reasoning, in the form of the OperA module, withreactive planning. A related approach is the logic-based subsumption architec-ture, where the different control layers that make up a subsumption system havebeen axiomatised using first-order logic [5,6]. The benefit of this approach isthe introduction of non-monotonic reasoning into reactive planning; i.e. devel-opers can understand and easily add control layers to the subsumption plan-ner at run time [6]. Similarly, the Layered Argumentation System combines\u2014at hardware level\u2014fuzzy reasoning and non-monotonic reasoning for run-timegeneration of reactive plans [32,33]. These combinations of reactive and formalreasoning approaches bridge together communities\u2014one of our goals\u2014but theirfocus has been to improve the overall performance of the agent by combiningthe two paradigms instead of enabling cooperation between multiple agents.With the latter goal in mind, ABC2 architecture combines classical plan-ning with reactive approaches [31]. ABC2, similar to AWKWARD, emphasisescooperation between agents. In ABC2 each agent has to define and broadcasttheir own \u2018skills\u2019; i.e. it requires active communication and coordination insteadof promoting self-coordination as AWKWARD\u2019s OperA implementation does.AWKWARD keeps the reactive and formal parts of the system completely sep-arate from each other; i.e. our reactive planner\u2014sans social consideration\u2014canoperate without the OperA module.AWKWARD uses both formal reasoning and reactive planning as comple-mentary approaches to each other. However, unlike past approaches, this combi-nation is done on an architectural level. By keeping the reactive planner separatefrom the normative system, our reactive planner can operate without the nor-mative reasoning module\u2014even if the agent is not behaving within the limits ofits socio-organisational role.7 Conclusions and Future WorkIn this paper, we presented the AWKWARD architecture for hybrid systems:agents that combine normative reasoning, in the form of OperA, and behaviour-based AI methods, in the form of BOD, at an architectural level. Combining theadvantages of BOD and OperA, AWKWARD achieves real-time adjustment ofagent plans for evolving social roles as it verifies\u2014and adjust plans to ensure\u2014adherence to any socio-organisational role prescribed to the agent. We provideda toy example, implemented in the game DOTA2, where we demonstrated how70 L. Methnani et al.AWKWARD enables continual manipulation of agent\u2019s behaviour over changingenvironmental and social circumstances.With the planner and OperA module implemented in DOTA2, we havedemonstrated how OperA can influence the behaviour of reactive planners underdefined social circumstances. However, manually designing and building reactiveplans can be inefficient and time consuming for system developers, especially asplans scale. As a next step, we intend to investigate methods of optimising planstructure automatically. To do this, Reinforcement Learning techniques can beemployed to guide the discovery of an optimal ordering and OpenAI Gym actsas a favourable toolkit for this task. Additionally, we are interested in extendingthe scope to cover variable autonomy, where varying levels of decision-makingcontrol can be passed between a human player\u2014who either directly controls ahero in the game or oversees a team of bots\u2014and artificial agents.Acknowledgements. Theodorou was supported by the Wallenberg AI, AutonomousSystems and Software Program (WASP) funded by the Knut and Alice WallenbergFoundation. We would like to thank Dignum V. for her input on OperA. All code isavailable at: https://github.com/lulock/dota.References1. Agre, P., Chapman, D.: Pengi: an implementation of a theory of activity. In: Pro-ceedings of the Sixth National Conference on Artificial Intelligence (1987)2. Aldewereld, H., Dignum, V.: OperettA: organization-oriented development envi-ronment. In: Dastani, M., El Fallah Seghrouchni, A., H\u00fcbner, J., Leite, J. (eds.)LADS 2010. LNCS (LNAI), vol. 6822, pp. 1\u201318. Springer, Heidelberg (2011).https://doi.org/10.1007/978-3-642-22723-3_13. Aldewereld, H., Dignum, V., Jonker, C.M., van Riemsdijk, M.B.: Agreeing on roleadoption in open organisations. KI-K\u00fcnstliche Intelligenz 26(1), 37\u201345 (2012)4. Alechina, N., Dastani, M., Logan, B.: Programming norm-aware agents. In: Pro-ceedings of the 11th International Conference on Autonomous Agents and Multi-agent Systems, vol. 2, pp. 1057\u20131064 (2012)5. Amir, E., Maynard-Reid, P.: Logic-based subsumption architecture. In: ArtificialIntelligence (2004)6. Amir, E., Maynard-Zhang, P.: LiSA: a robot driven by logical subsumption (2001)7. Berner, C., et al.: DOTA2 with large scale deep reinforcement learning. arXivpreprint:1912.06680 (2019)8. Broersen, J., Dastani, M., Hulstijn, J., van der Torre, L.: Goal generation in theBOID architecture. Cogn. Sci. Q. 2, 428\u2013447 (2002)9. Brom, C., Gemrot, J., Michal, B., Ondrej, B., Partington, S.J., Bryson, J.J.: Poshtools for game agent development by students and non-programmers. In: IEEE 9thComputer Games Conference (CGames 2006) (2006)10. Brooks, R.: A robust layered control system for a mobile robot. IEEE J. Robot.Autom. 2(1), 14\u201323 (1986)11. Brooks, R.A.: Intelligence without representation. Artif. Intell. 47, 139\u2013159 (1991)12. Bryson, J.J.: Action selection and individuation in agent based modelling. In: Sal-lach, D.L., Macal, C. (eds.) Proceedings of Agent 2003: Challenges in Social Sim-ulation, pp. 317\u2013330. Argonne National Laboratory, Argonne (2003)Real-Time Adjustment of Reactive Plans Using Social Norms 7113. Bryson, J.J., Ando, Y., Lehmann, H.: Agent-based modelling as scientific method:a case study analysing primate social behaviour. Philos. Trans. Roy. Soc. B Biol.Sci. 362, 1685\u20131699 (2007)14. Bryson, J.J., Theodorou, A.: How society can maintain human-centric artificialintelligence. In: Toivonen-Noro, M., Saari, E., Melkas, H., Hasu, M. (eds.) Human-Centered Digitalization and Services. Springer, Singapore (2019). https://doi.org/10.1007/978-981-13-7725-9_1615. Bryson, J.J.: Intelligence by design: principles of modularity and coordination forengineering complex adaptive agents. Ph.D. thesis, MIT (2001)16. Castelfranchi, C., Dignum, F., Jonker, C.M., Treur, J.: Deliberative normativeagents: Principles and architecture. In: International Workshop on Agent Theories,Architectures, and Languages (1999)17. Dennett, D.C.: The age of post-intelligent design. In: The Age of Artificial Intelli-gence: An Exploration (2020)18. Dignum, F.: Agents for Games and Simulations II: Trends in Techniques, Con-cepts and Design. Springer, Heidelberg (2011). https://doi.org/10.1007/978-3-642-18181-819. Dignum, V.: A model for organizational interaction: based on agents, founded inlogic. Ph.D. thesis, SIKS (2004)20. Dignum, V., Dignum, F.: Agents are dead. Long live agents! In: 19th InternationalConference on Autonomous Agents and Multi-Agent Systems (AAMAS) (2020)21. Gaudl, S., Davies, S., Bryson, J.J.: Behaviour oriented design for real-time-strategygames: an approach on iterative development for StarCraft AI. In: Foundations ofDigital Games (FDG) (2013)22. Guzel, M.S., Bicker, R.: A behaviour-based architecture for mapless navigationusing vision. Int. J. Adv. Robot. Syst. 9, 18 (2012)23. Hannoun, M., Boissier, O., Sichman, J.S., Sayettat, C.: MOISE: an organiza-tional model for multi-agent systems. In: Monard, M.C., Sichman, J.S. (eds.)IBERAMIA/SBIA 2000. LNCS (LNAI), vol. 1952, pp. 156\u2013165. Springer, Hei-delberg (2000). https://doi.org/10.1007/3-540-44399-1_1724. H\u00fcbner, J.F., Sichman, J.S.a., Boissier, O.: A model for the structural, functional,and deontic specification of organizations in multiagent systems. In: Proceedingsof the 16th Brazilian Symposium on Artificial Intelligence: Advances in ArtificialIntelligence (2002)25. H\u00fcbner, J.F., Sichman, J.S., Boissier, O.: Developing organised multiagent systemsusing the MOISE+ model: programming issues at the system and agent levels. Int.J. Agent Oriented Softw. Found. Eng. 1, 370\u2013395 (2007)26. Kahneman, D., Frederick, S.: A model of heuristic judgment. In: The CambridgeHandbook of Thinking and Reasoning (2005)27. Kollingbaum, M.J., Norman, T.J.: Norm adoption and consistency in the NoAagent architecture. In: Dastani, M.M., Dix, J., El Fallah-Seghrouchni, A. (eds.)ProMAS 2003. LNCS (LNAI), vol. 3067, pp. 169\u2013186. Springer, Heidelberg (2004).https://doi.org/10.1007/978-3-540-25936-7_928. Lee, J., Padget, J., Logan, B., Dybalova, D., Alechina, N.: N-Jason: Run-timenorm compliance in AgentSpeak. In: International Workshop on Engineering Multi-Agent Systems (2014)29. Maes, P.: Situated agents can have goals. Robot. Auton. Syst. 6, 49\u201370 (1990)30. Mataric, M.J.: Behaviour-based control: examples from navigation, learning, andgroup behaviour. J. Exp. Theor. Artif. Intell. 9, 323\u2013336 (1997)72 L. Methnani et al.31. Matell\u00e1n, V., Borrajo, D.: ABC(2) an agenda based multi-agent model for robotscontrol and cooperation. J. Intell. Robot. Syst. 32, 93\u2013114 (2001). https://doi.org/10.1023/A:101200942999132. Song, I., Governatori, G.: Designing agent chips. In: 5th International Joint Con-ference on Autonomous Agents and Multiagent Systems (AAMAS 2006) (2006)33. Song, I., Governatori, G., Diederich, J.: Automatic synthesis of reactive agents.In: 11th International Conference on Control, Automation, Robotics and Vision(ICARCV) (2011)34. Theodorou, A., Bandt-law, B., Bryson, J.J.: The sustainability game: AI tech-nology as an intervention for public understanding of cooperative investment. In:IEEE Conference on Games (2019)35. Theodorou, A., Wortham, R.H., Bryson, J.J.: Designing and implementing trans-parency for real time inspection of autonomous robots. Connect. Sci. 29, 230\u2013241(2017)36. Wortham, R.H., Gaudl, S.E., Bryson, J.J.: Instinct : a biologically inspired reactiveplanner for embedded environments. In: ICAPS 2016 PlanRob Workshop (2016)Self-learning Governance of Black-BoxMulti-Agent SystemsMichael Oesterle1(B) , Christian Bartelt1 , Stefan Lu\u0308dtke1 ,and Heiner Stuckenschmidt21 Institute for Enterprise Systems (InES), University of Mannheim,Mannheim, Germany{oesterle,bartelt,luedtke}@es.uni-mannheim.de2 University of Mannheim, Mannheim, Germanyheiner@informatik.uni-mannheim.deAbstract. Agents in Multi-Agent Systems (MAS) are not always builtand controlled by the system designer, e.g., on electronic trading plat-forms. In this case, there is often a system objective which can differfrom the agents\u2019 own goals (e.g., price stability). While much effort hasbeen put into modeling and optimizing agent behavior, we are concernedin this paper with the platform perspective. Our model extends Stochas-tic Games (SG) with dynamic restriction of action spaces to a new self-learning governance approach for black-box MAS. This governance learnsan optimal restriction policy via Reinforcement Learning.As an alternative to the two straight-forward approaches\u2014fully cen-tralized control and fully independent learners\u2014, this novel methodcombines a sufficient degree of autonomy for the agents with selectiverestriction of their action spaces. We demonstrate that the governance,though not explicitly instructed to leave any freedom of decision to theagents, learns that combining the agents\u2019 and its own capabilities isbetter than controlling all actions. As shown experimentally, the self-learning approach outperforms (w.r.t. the system objective) both \u201cfullcontrol\u201d where actions are always dictated without any agent autonomy,and \u201cungoverned MAS\u201d where the agents simply pursue their individualgoals.Keywords: Multi-Agent System \u00b7 Governance \u00b7 Self-learning system \u00b7Reinforcement Learning \u00b7 Electronic institution1 Introduction1.1 MotivationMulti-Agent Systems (MAS) are widely used as a general model for the interac-tion of autonomous agents, and have been applied to a vast range of real-worldsettings, for example Algorithmic Trading [1], Traffic Management [33], andMulti-Player Video Games [25] (see [42] for a recent survey of MAS applica-tions).c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 73\u201391, 2022.https://doi.org/10.1007/978-3-031-20845-4_574 M. Oesterle et al.Example 1. Consider a stock market where high-frequency trading algorithmstypically generate the vast majority of orders. Obviously, agents in this settingact autonomously and in a self-interested manner in order to maximize theirprofit. As is known, this behavior leads to problems like high volatility andextreme stock price behavior [26]. It is therefore crucial for regulators to pro-vide both stability (i.e., ensure that extreme price movement flash crashes willnot happen) and opportunity (i.e., ensure that investors can still use intricate,proprietary strategies to make profit).In this example\u2014as in many other applications areas\u2014the agents cannot (orshould not) be fully controlled, but must have a sufficient degree of freedomregarding their actions. At the same time, some level of control needs to beimposed on the agents such that a system objective can be achieved.The scope of this paper is therefore a subclass of MAS with three moreassumptions, inspired by the concept of Electronic Institutions (EI) [4] asdescribed in Sect. 2:(a) The agents are truly autonomous entities whose goals and strategies cannotbe known (\u201cblack boxes\u201d), but only observed through their actions,(b) in addition to the agents\u2019 individual goals, there is a system objective whichdoes not necessarily coincide with any of the former goals, and(c) agent actions can be restricted by a governance which has the power toenforce such restrictions.We propose a novel approach to governing an MAS which combines therestriction concept of EI with dynamic rule-setting, provided by a Reinforce-ment Learning (RL) component (the governance). This governance observes thepublic information of the MAS, i.e., actions and transitions, and learns opti-mal restrictions, which depend on the system state and the respective agent\u2019sobservation.A common method for governing agents in an EI is the use of norms witha focus on rewards and sanctions as the means of influencing agent behavior,while the action space itself is not affected. This makes two essential assump-tions about the agents: First, \u201cthe effectiveness of these norms depends heav-ily on the importance of the affected social reality for the individual\u201d [6], andsecond, the normative awareness needs to be comparable for all participatingagents (interpersonal utility comparison). For unknown agents, we argue thatthese assumptions cannot be expected to hold true, which is why we base ourgovernance on (mandatory) restrictions of the agents\u2019 action sets. The dynamicnature of the rule-setting process (rule synthesis) is due to the fact that agentsthemselves can act strategically and are therefore able to exploit any static ruleset.Of course, the governance\u2019s \u201cpower to restrict\u201d requires some sort of physicalcontrol over the MAS. This requirement is satisfied in a wide range of applica-tions, for example by any digital platform where agents are software components,and actions are chosen by exchanging messages. Therefore, we assume the adher-ence to restriction to be given in this work.Self-learning Governance of Black-Box Multi-Agent Systems 751.2 Illustration of the Governance ApproachThe simultaneous execution and learning of a Governed Multi-Agent System(GMAS) is shown in Fig. 1 (see the formal model in Sect. 3 for the definition andexplanation of the variables, and Algorithm1 for the actual run-time loop). Thegovernance is used, i.e., its restriction policy is queried, at every execution stepof the MAS to determine the set of allowed and forbidden actions, whereas thelearning happens in between those execution steps.In each learning step, the governance optimizes its restriction policy in orderto maximize the system objective, given the observation of the last step. At thesame time, the agents can update their own action policies, but this is not partof the GMAS (black-box agents).Fig. 1. Sequence of execution and learning steps in a Governed Multi-Agent System1.3 ContributionWe show in this paper how a self-learning governance with the ability to restrictaction spaces can add value to an MAS. This is demonstrated by comparing itsperformance to two natural alternatives (see also [37]):\u2013 Ungoverned MAS (UMAS), in which the agents alone decide on their actions,such that coordination or cooperation (if any) evolves on its own, and\u2013 Fully Controlled MAS (FMAS), where the governance prescribes all agentactions, leaving no room for autonomous decisions.The main contributions of this work are: We give a formal definition of aGoverned Multi-Agent System (Sect. 3), we conceptualize an RL governance forthis model, analyzing the assumptions made in the model and describing thegovernance\u2019s learning behavior (Sect. 4), and we present experiments (Sect. 5)to demonstrate that this method can significantly outperform both alternatives:UMAS and FMAS.2 Related WorkMost MAS literature focuses on the agents\u2019 perspective, attempting to improvetheir learning behavior [32,35]. The underlying model, the Stochastic Game76 M. Oesterle et al.(SG), is both an extension of a Markov Decision Process (MDP) to multipleagents, and an extension of a Normal-Form Game to multiple states. Hence,methods from both Stochastic Processes and Game Theory have been adaptedto this setting. Both in Game Theory and in Machine Learning, it is very commonto assume discrete time steps and therefore a synchronized interaction betweenagents. We will make use of this assumption for the interaction between envi-ronment, agents and governance (see Sect. 3).For a single-agent (stationary) MDP, the most common approach\u2014Reinforce-ment Learning\u2014includes a variety of algorithms which have beenproven to converge to an optimal strategy [38]. What makes it hard to transferthese algorithms to multi-agent settings is the fact that the rewards and transi-tions in an SG depend on the joint action of all agents, making the system non-stationary from the perspective of each agent. Coming from the game-theoreticside, the extension of solution approaches for normal-form games (mostly basedon the notion of equilibrium strategies) to SG is no less challenging.Nevertheless, there have been many successful approaches to the multi-agentlearning problem by introducing new concepts for equilibria (e.g. correlated equi-libria [19] and cyclic equilibria [43]) or by making additional assumptions: Amongothers, agents can learn optimal strategies if all agents receive the same rewards(Team Markov Games [39]), if the game is a Zero-Sum Game [23], if all oppo-nents are stationary [13], or if the \u201crate of non-stationarity\u201d is bounded by avariation budget [12]. The general problem of finding an optimal strategy in amodel-free, general-sum SG, however, is still an open challenge [42].As a consequence, researchers have introduced additional support for thelearning agents. This support can be either restricted to the interaction betweenthe agents, or it can involve another entity besides the agents.For the first type, agents are usually allowed to exchange additional infor-mation in order to find optimal strategies [11,21] (see also the recent MARLsurveys of Zhang et al. [42] and Gronauer and Diepold [20]).The second type relies on non-agent components to solve the learning prob-lem: In its most general notion, the concept of Environment-Mediated Multi-Agent Systems (EMMAS) states: \u201cWhen designing a system that is based onlyon local interactions in the environment and the emergent properties resultingfrom these interactions, it is a difficult research problem on the one hand toobtain the required global behavior of the system and on the other hand toavoid undesired global properties\u201d, and therefore suggests to \u201coff-load some ofthe agent complexity into the processes of the dynamic agent environment\u201d [40].Electronic Institutions (EI) [16,30] provide an institution as the entity whichregulates agent interactions, among many other features. The framework con-tains an \u201cimplementation of the control functionality of the institution infras-tructure [which] takes care of the institutional enforcement\u201d, which can referto both norms\u2014which can be violated\u2014and enforced rules. While these twoterms are not always used consistently, we use here the convention that rules are\u201cnorms that can be effectively controlled and thus enforced, such that violationis impossible\u201d [27].Self-learning Governance of Black-Box Multi-Agent Systems 77The EI framework itself does not only describe rule-setting capabilities, butalso Agents, Roles, a Performative Structure, and Normative Rules, among oth-ers [16]. The same holds for alternative models for social coordination, e.g.,ANTE [24], or INGENIAS [18] ([3] includes details of all these frameworks).However, we use only one feature of EI: The ability to restrict the space of avail-able actions for the participating agents. This has been described as an importantpart of an EI by Esteva et al.: \u201cAn electronic institution defines a set of rulesthat structure agent interactions, establishing what agents are permitted andforbidden to do\u201d [15]. Aldewereld et al. emphasize that \u201corganisational objec-tives are not necessarily shared by any of the individual participants, but canonly be achieved through their combined action\u201d [3], and that \u201cone cannot makeany assumptions about the inner workings of participants. [...] Rather, externalaspects of the participants (actions, interactions, etc.) have to be leveraged tocreate the required coordination structures\u201d [3].Norms are a very common approach for achieving system goals in MAS. Thedistinction between norms and rules (\u201c[Norms] are a concept of social reality [...]Therefore, it is possible to violate them\u201d [6]) has been made many times in theliterature; they have been called \u201csocial conventions\u201d and \u201cexplicit prescriptions\u201d[14], \u201clegalistic view of norms\u201d and \u201cinteractionist view of norms\u201d [9], \u201cnorms\u201dand \u201cregimented norms\u201d [6], or \u201cnorms\u201d and \u201chard constraints\u201d [17,27].Normative Multi-Agent Systems (NorMAS) [8,14] embrace the idea thatagent communities can self-regulate their interactions without a controlling force.Therefore, the field focuses on (violable) norms, their creation or emergence,observation, revision, adherence or violation, and sanctioning mechanisms. How-ever, this requires the two assumptions mentioned in Sect. 1.1: Norm-awarenessand inter-agent utility comparability. In our opinion, these requirements do nothold for black-box agents with individual goals (\u201cHow to deal with a lack of nor-mative awareness and if it is being considered, how to check the lack of normativeawareness if an agent\u2019s knowledge base is not accessible?\u201d [6]). In consequence,our focus lies on the other type of institutional enforcement: Rules for allowedand forbidden actions.The original implementation of EI (and its development environment EIDE[31]) envisaged a clear distinction between rule/norm creation at design-timeand agent interaction at run-time (i.e., all rules/norms are given independentlyof the agents and do not change during execution). A logical next step wasthe Autonomic Electronic Institutions (AEI) approach [5,10]: Acknowledgingthe fact that static norms are not always sufficient for dealing with self-adaptingagents, it moved norm creation from the design time to the run-time and allowedfor dynamic changes. EI was therefore extended to include an evolutionary normadaptation mechanism (e.g., a genetic algorithm). As we will see later, this issomewhat similar to our governance (defining and updating institutional rulesat run-time).Like multi-agent learning in general, normative capabilities in MAS can eitherbe part of the agents [34], or part of an additional entity [2] (or both). Whileearly work defined static norms at design-time [7,37], the field has since evolvedtowards run-time norm creation, synthesis and adaptation [28], applying meth-ods like Automated Theorem Proving [29] or Deep Learning [2] to NorMAS.78 M. Oesterle et al.This development towards dynamic norm creation and adaptation has, toour knowledge, not yet been examined for rules (i.e., hard constraints). In thispaper, we fill the gap by demonstrating that dynamic rules do have the potentialto enhance the capabilities of an MAS. Moreover, the RL approach employedhere for the governance component is shown to be well-suited for on-line learningof a restriction policy in an environment where the agents and their behaviorcan only be observed from outside.3 Model3.1 NotationVectorized Variables. Let S be a set, and I be an index set. A single variables \u2208 S is written in regular face, whereas a vector s = (si)i\u2208I \u2208 SI is written inbold face. The index set is usually omitted when the context is clear. Variablesthat change over time always have the current time step as a superscript, asin s(t) or \u03c0(t)i .Categorical Distribution. Given a finite set S, \u0394(S) denotes the set of alldiscrete probability distributions over S, i.e., the set of all functions p : S \u2192[0, 1] with\u2211s\u2208S p(s) = 1.Image and Support. Let f : A \u2192 B be a function. Then im(f) := {f(x) : x \u2208A} is the image of f . If B = R, supp(f) := {x \u2208 A : f(x) \u0004= 0} is the supportof f .3.2 Multi-Agent SystemConsider a Partially Observable Stochastic Game (POSG) over discrete timesteps t \u2208 N0, i.e., a 7-tuple (I,S,O,\u03c3,A, r, \u03b4) with agent set I = {1, ..., n}, stateset S, observation set O, observation functions \u03c3i : S \u2192 O \u2200i \u2208 I, fundamentalaction set A with k := |A| \u2208 N, agent reward functions ri : S \u00d7 AI \u2192 R \u2200i \u2208 Iand a probabilistic transition function \u03b4 : S \u00d7 AI \u2192 \u0394(S).Each agent has an (unknown) stochastic action policy \u03c0i : O \u00d7 2A \u2192 \u0394(A)which defines its behavior. These policies take as input not only the agent\u2019scurrent observation, but also a set A \u2286 A of allowed actions. Referring to theassumption of non-violable rules (see Sect. 1.1), we take as a given that forbiddenactions are never chosen, hence supp\u03c0i(s,A) \u2286 A\u2200i \u2208 I, s \u2208 S.An action policy is called static if it is constant in t; otherwise it is calleddynamic. Note that a static policy \u03c0 can still be non-deterministic, since theconcrete action is sampled from the categorical distribution \u03c0(o,A) \u2208 \u0394(A).3.3 GovernanceThe governance component returns a set A \u2286 A of allowed actions when givenan input pair consisting of the overall environmental state and an agent\u2019s obser-vation. This function is called the governance policy \u03c0G : S \u00d7 O \u2192 2A. Notethat the set of allowed actions can never be empty, i.e., \u2205 /\u2208 im(\u03c0G).Self-learning Governance of Black-Box Multi-Agent Systems 79In contrast to a standard MAS, where the environment provides all the inputfor the agents\u2019 action policies, there is now an intermediary step in which thegovernance computes the set of allowed actions for each agent, which is thenpassed to the agent\u2019s policy in addition to its observation.The system objective is given as a reward function rG : S \u00d7 AI \u2192 [0, 1],allowing the governance to directly measure the success of its restrictions aftereach environment step. The normalized range of rG is chosen for ease of compa-rability.Definition 1. A Governed Multi-Agent System (GMAS) is the 9-tuple(I,S,O,\u03c3,A, r, \u03b4, \u03c0G, rG) .The governance is a centralized controller insofar as it observes the entireMAS and defines restrictions in a centralized way. However, the fundamentaldifference to the usual notion of \u201ccentralized control\u201d is that the governanceleaves a substantial amount of autonomy to the agents. This is not enforced byits design, but emerges naturally: The synergy between the governance\u2019s and theagents\u2019 capabilities gives a performance advantage over full control, causing thegovernance to allow multiple actions at most times (see Sect. 5).3.4 Sequence of Actions in a GMASFig. 2. Execution step of a GMASFigure 2 shows the exchange of datain one execution step (see Fig. 1)of a GMAS: The environment pro-vides the agents with their respectiverewards and observations, while pass-ing to the governance the environ-ment state, the governance rewardand agent observations 1 . The gov-ernance then calculates the setsof allowed actions for each agent,and passes them to the respectiveagent 2 . Finally, the agents choosetheir actions and communicate themback to the environment 3 which executes the transition. For simplicity andclarity of presentation, all n queries to the governance have been wrapped upinto one arrow.In pseudocode (see Algorithm 1), the run-time loop is very similar to the stan-dard execution of an RL environment (e.g., in OpenAI Gym), with an additionalgovernance step.80 M. Oesterle et al.Algorithm 1: Run-time loop of a governed MASData: GMAS G =(I, S, O, \u03c3, A, r, \u03b4, \u03c0(0)G , rG)Choose initial environmental state s(0) \u2208 S ;for t \u2208 {0, ..., T} do// Execution stepfor i \u2208 I doo(t)i \u2190 \u03c3i(s(t)) // Compute agent observation from stateA(t)i \u2190 \u03c0G(s(t), o(t)i ) // Get allowed actions from governancea(t)i \u2190 \u03c0i(o(t)i , A(t)i ) // Get chosen action from agentendr(t) \u2190 r(s(t), a(t)) // Get rewardss(t+1) \u2190 \u03b4(s(t), a(t)) // Execute transition// Learning step\u03c0(t+1)G \u2190 train(\u03c0(t)G ) // Train governancefor i \u2208 I do\u03c0(t+1)i \u2190 train(\u03c0(t)i ) // Train agentendend3.5 Degree of RestrictionThere is a natural trade-off between achieving the system objective and preserv-ing agent freedom: The more actions the governance forbids, the higher its levelof control over the agents\u2014in the extreme case, only a single action is allowedfor any given observation, resulting in a fully deterministic trajectory. On theother end of the spectrum, the governance always allows all actions, reducingthe GMAS to an ordinary MAS.It is therefore reasonable to measure the degree of restriction, i.e., the percent-age of forbidden actions, and to assess this metric in relation to the governance\u2019sperformance:Definition 2. For an individual agent i \u2208 I and time step t \u2208 N0, the degreeof restriction is defined as\u03c1(t)i := 1 \u2212\u2223\u2223\u03c0G(s(t), oi(s(t)))\u2223\u2223|A| \u2208 [0, 1].The overall degree of restriction \u03c1(t) := 1n\u2211i\u2208I \u03c1(t)i is simply the mean overall agents. The higher the degree of restriction, the lower the autonomy of theagents.It should be noted that real-world agents oftentimes cannot choose everyaction at every step. Instead, only a subset of actions is feasible, depending onSelf-learning Governance of Black-Box Multi-Agent Systems 81the environmental state (parametric action spaces). In this case, the degree ofrestriction should be defined as the ratio between forbidden actions and feasibleactions.4 Model Analysis4.1 FairnessAgents who make the same observation o \u2208 O at a time step t are alwaysallowed to perform the same actions \u03c0G(s(t), o). This is in line with a common-sense definition of fairness: The governance treats all agents the same way. Toachieve this, learning (i.e., a change of the governance policy) cannot take placewithin a time step, but only after all agents have been given their action sets.4.2 LearningThe GMAS model does not specify any particular learning algorithm, but onlyrequires a governance policy \u03c0G to be available for querying at all times. Therestriction policy can be any function S \u00d7 O \u2192 2A, but, of course, the gover-nance\u2019s goal is to find a restriction policy which maximizes the reward rG, giventhe agents\u2019 behavior. Since the governance interacts with the ungoverned MASin a cycle of information, reward and action, RL seems to be the natural way tooptimize this policy.From this perspective, the governance itself is a Reinforcement Learningagent which acts on the entire MAS as its environment: The governance inter-acts with the MAS environment and the agents, but only sees how its ownactions (i.e., defining sets of allowed actions) influence its reward and the envi-ronmental state. Therefore, it can be treated as a reinforcement learner withaction policy \u03c0G and reward rG. Its environment has the transition function\u03b4\u2032 : S \u00d7(2A)I \u2192 \u0394(S) with \u03b4\u2032(s,A) := \u03b4 (s,\u03c0(\u03c3(s),A)), which is a compositionof observation functions \u03c3, agent policies \u03c0 and MAS transition function \u03b4.\u03b4\u2032 is not explicitly known to the governance, such that a model-free algorithmmust be used. Moreover, since the governance policy is the action policy of thegovernance, standard model-free RL algorithms like A3C, DQN or PPO canbe directly applied. The governance is structurally equivalent to a multi-labelclassifier: Its policy outputs a subset of the (finite) fundamental action set. Thus,specialized network architectures for this type of classifier could also be appliedin order to build a more effective governance policy.Since agents can (and probably will) change their behavior according to thecurrent restriction policy, a GMAS is inherently dynamic and therefore an on-line learning problem: Both sides (agents and governance) react to the otherside\u2019s actions and strategies by continuously adapting their own action policies.The initial restriction policy can be a random function, or it can be set to simplyallow all actions, i.e., \u03c0(0)G (s, o) := A \u2200s \u2208 S, o \u2208 O. At run-time, the governanceneeds to learn continuously in order to keep up with changing agent behavior.82 M. Oesterle et al.Therefore, there is no distinction between traning and evaluation as in classicalRL, but the governance learning process continues throughout the lifecycle ofthe GMAS.4.3 StationarityIt is known [12] that, for a stationary MDP, near-optimal regret bounds canbe achieved via RL. The situation is more complicated in the non-stationarycase, depending on whether non-stationarity occurs in discrete steps (piece-wisestationarity) or continuously (among other criteria).The transition function \u03b4 is assumed to be stochastic, but stationary. There-fore, the defining factor for the stationarity of a GMAS, seen from the gover-nance\u2019s view, is the set of agent policies \u03c0: \u03b4\u2032 is stationary if and only if all agentpolicies are static.While using static pre-trained models is very common for NLP, ComputerVision and Speech Recognition [41], this is unusual for agent models, since on-linelearning lies at the heart of useful behavior in an unknown world. Nevertheless,safety-critical agent-based systems like fully autonomous cars will likely requiresome sort of certification ensuring that they behave (exactly or approximately)in a certain way, which means that their policy should not, even when learninghow to deal with unforeseen situations, be allowed to deviate too far from theapproved policy.Hence, we cannot generally assume that a GMAS is stationary, but in somedomains there can be (quasi-)stationary agents, which means that the gover-nance is likely to perform better than in a setting where the agents adapt theirstrategies arbitrarily fast.5 Experimental EvidenceFig. 3. The dining diplomats\u2019 problemThe goal of the experiments is toinvestigate the effect of the gover-nance. For this purpose, we definea game in which the agents need toagree on an action, and then comparethree types of systems: UngovernedMAS (UMAS) which does not havea governance component at all, FullyControlled MAS (FMAS), and Gov-erned MAS (GMAS).5.1 The Dining Diplomats\u2019ProblemConsider an MAS with agent set I ={1, ..., n} and action set A = {1, ..., k} for all agents. The agents are positioned inSelf-learning Governance of Black-Box Multi-Agent Systems 83a circle such that each agent can only see their immediate neighbors (see Fig. 3).At each step, the agents play a card corresponding to one of their availableactions. The environmental state represents the currently played cards, i.e., S =An and O = A3.The agents\u2019 goal is to learn to coordinate their actions in order to play thesame cards. In the style of the famous dining philosophers\u2019 problem, we callthis problem the dining diplomats\u2019 problem, requiring the participating agentsto come to an agreement under imperfect information.5.2 Reward FunctionsConsider two reward functions\u2014a state-based reward and an observation-basedreward:rs : S \u2192 R, rs(s) ={1 if s1 = \u00b7 \u00b7 \u00b7 = sn0 elsero : O \u2192 R, ro(o) ={1 if o1 = o2 = o30 elseThe state-based reward function only differentiates between \u201cno coordina-tion\u201d and \u201cfull coordination\u201d, while the observation-based reward also showslocal coordination between three agents (i.e., the observation space of one agent).The three system types use these reward functions as follows:Agents GovernanceUMAS ro \u2013FMAS rs rsGMAS ro rsIn the FMAS type, agents and governance have the same information aboutachieving their goals, so the governance cannot use the agents as an additionalsource of intelligence. In GMAS, however, the agents have access to more detailedinformation through ro. Hence, the two pivotal dimensions are (a) access to low-level/high-level information and (b) dense and sparse rewards.5.3 ConfigurationsWe compare the three types for four different problem sizes: Tiny (n = 5, k = 3),small (n = 10, k = 5), medium (n = 15, k = 7) and large (n = 20, k = 10). Thisallows us to see clearly at which complexity the non-GMAS types fail to achievecoordination, and therefore highlights the value added by the synergy.The size |S| = kn of the state space grow polynomially in the number ofactions, but exponentially in the number of agents: In the tiny configuration,84 M. Oesterle et al.there are 35 = 243 states, while this number is 510 \u2248 107 for the small con-figuration, 715 \u2248 4 \u00b7 1012 for the medium configuration, and 1020 for the largeconfiguration.5.4 Frameworks and AlgorithmsFor our experiments, we used the RLlib library [22] for multi-agent learning,which is based on the Ray distributed computing framework. Both agents andgovernance use a standard configuration of the Proximal Policy Optimization(PPO) algorithm [36].The interaction between agents, governance, and environment requires asequential MAS execution: The governance needs to act (i.e., produce a setof allowed actions) before an agent can choose from this set. All agent actions,in turn, cause the environment to proceed to the next state. Therefore, the gov-ernance is queried n times for each environmental step, while the agents eachonly act once during the same period.All experiments were run in ten independent samples for 5 \u00b7 106 steps each(empirically determined to ensure sufficient convergence of the action policies).5.5 ReproducibilityThe source code to perform the experiments and generate the graphs is publiclyavailable as a Jupyter notebook, allowing for simple reproduction of the results.The exact results shown in Fig. 4 are stored as Tensorboard log files in the samepublic repository.5.6 ResultsThe results of the experiments can be found in Fig. 4. The governance reward rG,as the main performance indicator, is shown on the left side, while the graphson the right depict the corresponding degree of restriction \u03c1 (see Definition 2).Since the reward at every step is either 0 or 1, the governance reward r(t)G isthe average reward over time, i.e., the percentage of steps where full coordinationof all agent actions has been achieved.In each graph, the mean of the ten samples (thick line) and the individualsamples (thin lines) are plotted. The numbers vary strongly between samples,i.e., the mean should be seen as a general trend, but not as the \u201caverage run\u201d.Since the governance policy is initialized randomly, all governed types startwith \u03c1(0) \u2248 12 . The progression of \u03c1 depends on whether the governance is ableto learn a \u201cfully controlling\u201d way to create a high reward. If it succeeds, \u03c1 goesup to k\u22121k and stays there. Otherwise, the governance must utilize the agents\u2019freedom, and therefore allows more than one action. Notably, the degrees ofrestriction turn out to be roughly equal in the FMAS and GMAS types.Self-learning Governance of Black-Box Multi-Agent Systems 85Fig. 4. Experimental results. Thick lines show the mean of r(t)G and \u03c1(t) over ten inde-pendent samples, while thin lines are the results of the individual samples.86 M. Oesterle et al.Tiny Configuration. Both FMAS and GMAS achieve an almost perfectreward. While the FMAS solves the task by simply allowing a single actionfor each observation (\u03c1(t) \u2192 k\u22121k = 23 ), the GMAS uses a slightly lower degreeof restriction. The problem is relatively easy, so that the agents in the UMAScan also find a solution, albeit not a perfect one.Small Configuration. This is challenging for the UMAS, but FMAS andGMAS both achieve similar, good results. Sometimes the GMAS uses themaximum degree of restriction, but mostly, agents are given two or threeactions.Medium Configuration. The difference becomes larger: The UMAS cannotfind a system state that results in a nonzero reward at all, and the FMASperforms approximately half as well as the GMAS. We can see from \u03c1 thateven the FMAS governance does not use a maximally restrictive policy, sinceit cannot find the optimal actions for each observation.Large Configuration. Finally, both UMAS and FMAS are not able to get anyrewards. In contrast, the GMAS still achieves a reward of more than 15\u201320%in four out of ten samples, using a degree of restriction around 50%.The results show that the GMAS type succeeds in achieving full coordinationof the agent actions in a substantial number of time steps. As expected, theaverage reward decreases with increasing complexity of the setting, but it canhandle systems where neither UMAS nor FMAS are able to get any rewards.5.7 DiscussionQualitatively, we make the following observations of the three types:Tiny Small Medium LargeUMAS \u0002 \u0002FMAS \u0002 \u0002 \u0002GMAS \u0002 \u0002 \u0002 \u0002The hypothesis that the synergy of agents and governance significantly out-performs the conventional approaches of ungoverned agents and centralized con-trol, indeed holds true. Notably, the agents simply apply their own (self-learning)strategies, have no normative awareness, and their rewards are not influencedby the governance.In this section, we give an interpretation of the observed results:System Objective and Degree of Restriction. The governance in theGMAS type has the power of fully controlling the MAS\u2014it could simply allowonly one action for any state and observation. Therefore, the crucial observationin the experiments is that the degree of restriction does not converge to k\u22121k .Self-learning Governance of Black-Box Multi-Agent Systems 87Instead, the right side of Fig. 4 clearly shows that the governance leaves asubstantial amount of freedom to the agents, and that this freedom causes thegovernance reward to be much higher than using full control (i.e., the FMAStype).The balance between governance control and agent freedom is constantlychanging, depending on how well the system objective (as measured by thegovernance reward function) is achieved. It is a crucial feature of our approachthat the optimal balance is determined via RL and not defined in advance.Micro-level and Macro-level Knowledge. There are different types ofknowledge in the GMAS: The governance can see the entire environmental stateand knows which states are most desirable, but does not know effective actionsto get there, since its reward function only indicates whether the system objec-tive has been fully achieved. The agents, on the other hand, lack a view of thebig picture, but have a better grasp of how to act on a lower level, since theirreward function tells them when they are locally coordinated.In the UMAS, the overall state is not available to the agents at all, noteven through the governance. This prevents the agents from finding a globallycoordinated solution, even though they can coordinate locally. In the FMAS, thegovernance sees the big picture, but cannot figure out the necessary actions forthe agents to move in the right direction.The combination of these two levels allows the GMAS to reach global coordi-nation\u2014without ever being instructed how to combine agent and governanceknowledge. This setting was chosen since it represents a common pattern inMAS: Individual agents are situated at a specific location in the environmentand only able to perceive their surroundings, i.e., a small part of the environment.On the other hand, this small part is where their actions have the biggest impact.The system designer or operator, in contrast, sees the environment as a whole,but does not have the micro-level knowledge about optimal or even useful agentactions. Therefore, the goal is clear, but the way to get there is unknown.Incentives for Autonomy and Restriction. The governance can freelychoose the restrictions without being penalized for high degrees of restriction.Consequently, there is no real incentive for the governance to allow multipleactions: The chosen degree of restriction directly reflects the highest expectedreward. In the small scenarios, we observe that allowing only one action perobservation is a feasible strategy which leads to high rewards. As the scenariosget more complex, however, the governance policy is not maximally restrictiveanymore: The governance learns that the autonomous decisions of the agents aremore helpful than centralized control. Still, by selectively forbidding actions, thegovernance can support the agents\u2019 action policies.Penalties for Restrictions. A reasonable goal for the governance is to usethe least amount of restrictions to achieve its objective, and therefore strive to88 M. Oesterle et al.reduce the degree of restriction whenever this does not counteract the systemobjective. To this end, we experimented with giving the governance a penalty inproportion to the current degree of restriction by redefining its reward functionas r\u2032G := rG \u2212 \u03b1 \u00b7 \u03c1 with a constant weighting parameter \u03b1. This resulted ina much lower reward (even when ignoring the penalty), making the governancedrop nearly all restrictions early in the training, before it then defined new, moreeffective restrictions. However, the penalty often prevented the governance fromsufficiently exploring the possible restrictions, so there were many samples wherethere was never any reward, even in small scenarios.6 Conclusion and Future WorkIn this paper, we have motivated the need for governed MAS, a synergy-basedapproach for black-box MAS with an additional system objective. We havedemonstrated that full control as well as ungoverned learning agents fail toachieve their goals even in simple scenarios; a challenge solved considerably bet-ter by GMAS.The model and experiments give rise to several questions for future work:\u2013 In the experiments presented here, the objectives of agents and governancewere strongly correlated. How can the approach be applied to an arbitrarycombination of goals, and how do conflicts in the objective functions influencelearning?\u2013 What does an extension of the restriction policy to continuous action spaceslook like?\u2013 How do action space restrictions compare (empirically and theoretically) toother forms of governance, e.g., norms or inter-agent communication?\u2013 Is the approach viable for asynchronous MAS (e.g., cyber-physical systems)?Acknowledgements. This work is supported by the German Federal Ministry forEconomic Affairs and Energy (BMWi).References1. Abdunabi, T., Basir, O.: Holonic intelligent multi-agent algorithmic trading system(HIMAATS). Int. J. Comput. Appl. 21, 54\u201361 (2014)2. Aires, J.P., Meneguzzi, F.: Norm conflict identification using deep learning. In:AAMAS Workshops (2017)3. Aldewereld, H., Boissier, O., Dignum, V., Noriega, P., Padget, J. (eds.): SocialCoordination Frameworks for Social Technical Systems. Springer, Cham (2016).https://doi.org/10.1007/978-3-319-33570-44. Arcos, J.L., Esteva, M., Noriega, P., Rodr\u0301\u0131guez-Aguilar, J.A., Sierra, C.: Environ-ment engineering for multiagent systems. In: Engineering Applications of ArtificialIntelligence (2004)5. Arcos, J.L., Rodr\u0301\u0131guez-Aguilar, J.A., Rosell, B.: Engineering autonomic electronicinstitutions. In: Weyns, D., Brueckner, S.A., Demazeau, Y. (eds.) EEMMAS 2007.LNCS (LNAI), vol. 5049, pp. 76\u201387. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-85029-8 6Self-learning Governance of Black-Box Multi-Agent Systems 896. Balke, T., et al.: Norms in MAS: definitions and related concepts, p. 31. SchlossDagstuhl-Leibniz-Zentrum fuer Informatik (2013)7. Barbuceanu, M.: Coordinating agents by role based social constraints and conver-sation plans. In: AAAI/IAAI (1997)8. Boella, G., van der Torre, L., Verhagen, H.: Introduction to normative multiagentsystems. Comput. Math. Organ. Theory 12(2), 71\u201379 (2006). https://doi.org/10.1007/s10588-006-9537-79. Boella, G., van der Torre, L., Verhagen, H.: Introduction to the special issue on nor-mative multiagent systems. Auton. Agents Multi-Agent Syst. 17(1), 1\u201310 (2008).https://doi.org/10.1007/s10458-008-9047-810. Bou, E., Lo\u0301pez-Sa\u0301nchez, M., Rodr\u0301\u0131guez-Aguilar, J.A.: Towards self-configurationin autonomic electronic institutions. In: Noriega, P., et al. (eds.) COIN 2006. LNCS(LNAI), vol. 4386, pp. 229\u2013244. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-74459-7 1511. Cacciamani, F., Celli, A., Ciccone, M., Gatti, N.: Multi-agent coordination inadversarial environments through signal mediated strategies. In: Proceedings ofthe 20th International Conference on Autonomous Agents and MultiAgent Sys-tems. International Foundation for Autonomous Agents and Multiagent Systems,Richland (2021)12. Cheung, W.C., Simchi-Levi, D., Zhu, R.: Reinforcement learning for non-stationarymarkov decision processes: the blessing of (more) optimism. In: Proceedings of the37th International Conference on Machine Learning, ICML 2020, Virtual Event,13\u201318 July 2020 (2020)13. Conitzer, V., Sandholm, T.: AWESOME: a general multiagent learning algorithmthat converges in self-play and learns a best response against stationary opponents.Mach. Learn. 67, 23\u201343 (2003). https://doi.org/10.1007/s10994-006-0143-114. Conte, R., Falcone, R., Sartor, G.: Introduction: agents and norms: how tofill the gap? Artif. Intell. Law 7(1), 1\u201315 (1999). https://doi.org/10.1023/A:100839732850615. Esteva, M., et al.: Electronic institutions development environment. In: AAMASDemo Proceedings, vol. 3. International Foundation for Autonomous Agents andMultiagent Systems (2008)16. Esteva, M., Rodr\u0301\u0131guez-Aguilar, J.-A., Sierra, C., Garcia, P., Arcos, J.L.: On the for-mal specification of electronic institutions. In: Dignum, F., Sierra, C. (eds.) AgentMediated Electronic Commerce. LNCS (LNAI), vol. 1991, pp. 126\u2013147. Springer,Heidelberg (2001). https://doi.org/10.1007/3-540-44682-6 817. Frantz, C., Pigozzi, G.: Modelling norm dynamics in multi-agent systems. J. Appl.Logic 5, 491\u2013564 (2018)18. Gomez-Sanz, J.J.: Ingenias. In: Aldewereld, H., Boissier, O., Dignum, V., Noriega,P., Padget, J. (eds.) Social Coordination Frameworks for Social Technical Systems.Springer, Cham (2016). https://doi.org/10.1007/978-3-319-33570-4 519. Greenwald, A., Hall, K.: Correlated-Q learning. In: Proceedings of the Twenti-eth International Conference on International Conference on Machine Learning,ICML2003. AAAI Press (2003)20. Gronauer, S., Diepold, K.: Multi-agent deep reinforcement learning: a survey. Artif.Intell. Rev. 55, 895\u2013943 (2021). https://doi.org/10.1007/s10462-021-09996-w21. Hwang, K., Jiang, W., Chen, Y.: Model learning and knowledge sharing for amultiagent system with Dyna-Q learning. IEEE Trans. Cybern. 45(5), 978\u2013990(2015)22. Liang, E., et al.: RLlib: abstractions for distributed reinforcement learning. In:ICML (2018)90 M. Oesterle et al.23. Littman, M.L.: Markov games as a framework for multi-agent reinforcement learn-ing. In: Proceedings of the Eleventh International Conference on InternationalConference on Machine Learning, ICML 1994. Morgan Kaufmann Publishers Inc.,San Francisco (1994)24. Lopes Cardoso, H., Urbano, J., Rocha, A., Castro, A.J.M., Oliveira, E.: ANTE:a framework integrating negotiation, norms and trust. In: ldewereld, H., Boissier,O., Dignum, V., Noriega, P., Padget, J. (eds.) Social Coordination Frameworksfor Social Technical Systems, vol. 30. Springer, Cham (2016). https://doi.org/10.1007/978-3-319-33570-4 325. Mar\u0301\u0131n-Lora, C., Chover, M., Sotoca, J.M., Garc\u0301\u0131a, L.A.: A game engine to makegames as multi-agent systems. Adv. Eng. Softw. 140, 02732 (2020)26. McGroarty, F., Booth, A., Gerding, E., Chinthalapati, V.L.R.: High frequencytrading strategies, market fragility and price spikes: an agent based model perspec-tive. Ann. Oper. Res. 282(1), 217\u2013244 (2019). https://doi.org/10.1007/s10479-018-3019-427. Mellema, R., Jensen, M., Dignum, F.: Social rules for agent systems. In: AlerTubella, A., Cranefield, S., Frantz, C., Meneguzzi, F., Vasconcelos, W. (eds.)COIN/COINE 2017/2020. LNCS (LNAI), vol. 12298, pp. 175\u2013180. Springer, Cham(2021). https://doi.org/10.1007/978-3-030-72376-7 1028. Morales, J.: On-line norm synthesis for open Multi-Agent systems. Ph.D. thesis,Universitat de Barcelona (2016)29. Neufeld, E., Bartocci, E., Ciabattoni, A., Governatori, G.: A normative supervisorfor reinforcement learning agents. In: Platzer, A., Sutcliffe, G. (eds.) CADE 2021.LNCS (LNAI), vol. 12699, pp. 565\u2013576. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-79876-5 3230. Noriega, P.: Agent-mediated auctions: the fishmarket metaphor. Ph.D. thesis, Uni-versitat Autonoma de Barcelona (1997)31. Noriega, P., de Jonge, D.: Electronic institutions: the EI/EIDE framework. In:Aldewereld, H., Boissier, O., Dignum, V., Noriega, P., Padget, J. (eds.) SocialCoordination Frameworks for Social Technical Systems. LGTS, vol. 30, pp. 47\u201376.Springer, Cham (2016). https://doi.org/10.1007/978-3-319-33570-4 432. Nowe\u0301, A., Vrancx, P., De Hauwere, Y.M.: Game theory and multi-agent reinforce-ment learning. In: Wiering, M., van Otterlo, M. (eds.) Reinforcement Learning:State-of-the-Art. Springer, Heidelberg (2012). https://doi.org/10.1007/978-3-642-27645-3 1433. Padakandla, S., K. J., P., Bhatnagar, S.: Reinforcement learning algorithm for non-stationary environments. Appl. Intell. 50(11), 3590\u20133606 (2020). https://doi.org/10.1007/s10489-020-01758-534. Riad, M., Golpayegani, F.: Run-time norms synthesis in multi-objective multi-agent systems. In: Theodorou, A., Nieves, J.C., De Vos, M. (eds.) COINE 2021.LNCS, vol. 13239, pp. 78\u201393. Springer, Cham (2021). https://doi.org/10.1007/978-3-031-16617-4 635. Rizk, Y., Awad, M., Tunstel, E.: Decision making in multi-agent systems: a survey.IEEE Trans. Cogn. Dev. Syst. 10, 514\u2013529 (2018)36. Schulman, J., Wolski, F., Dhariwal, P., Radford, A., Klimov, O.: Proximal policyoptimization algorithms (2017)37. Shoham, Y., Tennenholtz, M.: On social laws for artificial agent societies: off-linedesign. Artif. Intell. 73(1), 231\u2013252 (1995)38. Sutton, R.S., Barto, A.G.: Reinforcement Learning: An Introduction. A BradfordBook, Cambridge (2018)Self-learning Governance of Black-Box Multi-Agent Systems 9139. Wang, X., Sandholm, T.: Reinforcement learning to play an optimal nash equilib-rium in team Markov games. In: NIPS (2002)40. Weyns, D., Bru\u0308ckner, S., Demazeau, Y.: Engineering Environment-Mediated Multi-Agent Systems. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-85029-841. Zaib, M., Sheng, Q.Z., Zhang, W.E.: A short survey of pre-trained language modelsfor conversational AI-A NewAge in NLP (2021)42. Zhang, K., Yang, Z., Bas\u0327ar, T.: Multi-agent reinforcement learning: a selectiveoverview of theories and algorithms. In: Vamvoudakis, K.G., Wan, Y., Lewis, F.L.,Cansever, D. (eds.) Handbook of Reinforcement Learning and Control. SSDC,vol. 325, pp. 321\u2013384. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-60990-0 1243. Zinkevich, M., Greenwald, A., Littman, M.L.: Cyclic equilibria in Markov games.In: Proceedings of the 18th International Conference on Neural Information Pro-cessing Systems, NIPS 2005. MIT Press, Cambridge (2005)Computational Theory of Mindfor Human-Agent CoordinationEmre Erdogan1(B) , Frank Dignum1,2 , Rineke Verbrugge3 ,and P\u0131nar Yolum11 Utrecht University, Utrecht, The Netherlands{e.erdogan1,p.yolum}@uu.nl2 Ume\u030aa University, Ume\u030aa, Swedendignum@cs.umu.se3 University of Groningen, Groningen, The Netherlandsl.c.verbrugge@rug.nlAbstract. In everyday life, people often depend on their theory of mind,i.e., their ability to reason about unobservable mental content of othersto understand, explain, and predict their behaviour. Many agent-basedmodels have been designed to develop computational theory of mind andanalyze its effectiveness in various tasks and settings. However, mostexisting models are not generic (e.g., only applied in a given setting),not feasible (e.g., require too much information to be processed), ornot human-inspired (e.g., do not capture the behavioral heuristics ofhumans). This hinders their applicability in many settings. Accordingly,we propose a new computational theory of mind, which captures thehuman decision heuristics of reasoning by abstracting individual beliefsabout others. We specifically study computational affinity and show howit can be used in tandem with theory of mind reasoning when designingagent models for human-agent negotiation. We perform two-agent simu-lations to analyze the role of affinity in getting to agreements when thereis a bound on the time to be spent for negotiating. Our results suggestthat modeling affinity can ease the negotiation process by decreasingthe number of rounds needed for an agreement as well as yield a higherbenefit for agents with theory of mind reasoning.Keywords: Social cognition \u00b7 Communication \u00b7 Affinity \u00b7Abstraction \u00b7 Heuristics \u00b7 Negotiation \u00b7 Human-inspired computationalmodel1 IntroductionTheory of Mind (ToM) is the ability of reasoning about the mental content ofother people, such as their beliefs and desires, making it possible to understandand predict their behaviour [9,25,27]. Being an important part of social cog-nition, the capability of ToM develops early in life and bestows on humans aplethora of social skills such as negotiating, teaching, and tricking. Recursivelyemploying ToM provides a direct path to reason about how others use ToM,c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 92\u2013108, 2022.https://doi.org/10.1007/978-3-031-20845-4_6Computational Theory of Mind for Human-Agent Coordination 93which is widely known as \u201chigher-order ToM\u201d (e.g., \u201cI believe that Alice doesnot know that Bob is planning a baby shower for her\u201d), and is particularlyhelpful for adapting to the complex dynamics of social life.Agent-based computational models have previously been used to analyzethe effectiveness of ToM in competitive [11,13] and cooperative [14] games andmixed-motive situations [15,16,21] in which the models are based on recursivereasoning and behaviourally limited by the complexity and rules of the games.Baker et al. [5] model ToM within a Bayesian framework using partially observ-able Markov decision processes and test its performance in a simple spatial set-ting. Osten et al. [26] propose a multiagent ToM model that extends the modeldescribed in [11] and evaluates its performance in a multiplayer stochastic game.Winfield [35] shows how robots can use a ToM model in improving their safety,making decisions based on simple ethical rules, and imitating other robots\u2019 goals.In most of the studies around computational ToM models, the results are gen-erally promising and demonstrate that the use of ToM leads to better outcomesfor the studied tasks. Still, the existing models have not been widely adopted asa computational tool in many real-life settings. We argue that for a ToM modelto be applicable, it needs to adhere to the following criteria:Generic: Most of the existing models (see [11\u201315,26,32]) are built for a specificgame-theoretic setting in mind. The models thus are based on the rules of thegame as well as interpreted semantics of the strategies. This creates a limitationbecause it is not straightforward to use these models outside of these settings.We argue that real-life social interaction is generally more complex and for amore comprehensive model of ToM, agents should take into account a variety ofboth context-dependent and context-independent information such as traits, aswell as social frames of reference such as roles, norms, and values [6,30]. Ideally, acomputational ToM model should be generic; i.e., independent of the particularsetting to which it is applied so that it can be used in a variety of settings.Feasible: In general terms, ToM is about beliefs and knowledge an agent hasor can derive about the mental attitudes of other agents. Without a proper con-trol, the number of elements in an agent\u2019s belief and knowledge set can increaserapidly over time. This has two immediate disadvantages. First, it will not beclear to the agent which beliefs about the other agents would be useful to considerin a given context, leading to complex decision processes. Second, the volumeof information will make it more difficult for the agent to make fast and accu-rate inferences about others. On the other hand, the agent can benefit from acontrol mechanism which can sort out the relevant and important informationaccording to the context that the agent operates in. Thus, for a more efficientcomputational model, it is necessary to ensure that the agent can abstract fromexisting information to yield feasible computation of ToM.Human-Inspired: In various social contexts, humans are known to rely onsocial skills that are based on more automatic and fast-working heuristics andrequire less conscious effort, such as repetition (i.e., repeating behaviours thatyield desirable results), imitation (i.e., mimic others) [20], and stereotypes [17].These agile mechanisms can be especially helpful for humans in social interac-tions where the time spent on reasoning and/or the cognitive resources allocated94 E. Erdogan et al.are vital concerns. For an agent to better explain the behaviour of humans thatit interacts with, its ToM should be human-inspired, such that it should be ableto capture and interpret the heuristics that humans use in every day dealings.An important area where ToM could be of particular use is hybrid intelli-gence [1], where an agent can coordinate with a human towards a particulargoal, where the agent would have varying capabilities that could complementthose of the human to yield the goal. As an example, consider a wearable phys-ical activity monitor agent a\u0300 la Fitbit that works with a human to ensure thatthe human establishes a healthy life. Typical interactions with such devices takethe form of information passing, such as that the device periodically informsthe human what more she has to do (e.g., \u201ctake another 200 steps\u201d), milestonesshe has achieved (e.g., \u201cyou received a Tiger badge\u201d); or it requests informa-tion (e.g., \u201center the foods consumed today\u201d). Take the first type of interaction.This necessitates the human to take an action that is not easy to do and thusrequires nudging from the agent. Ideally, if the agent could have a ToM for thehuman, it could create strategies as to how to proceed with such requests. Thelong-term goal of our research is thus to design and develop a generic, feasible,and human-inspired ToM that could be applicable in such settings to improvehuman-agent coordination and thus to facilitate hybrid intelligence.As an initial step towards this goal, we develop an abstraction framework forToM over which we construct an abstraction heuristic. The underlying idea isto employ an agent\u2019s belief and knowledge set to produce a more abstract, com-plex interaction state that can be readily used by the agent. To investigate theprinciple of abstraction we use the concrete concept of affinity that summarizeshow we relate to someone based on many things we know about that personand our history of interactions. Computational affinity captures how humansuse affinity in their interactions and can be used in tandem with ToM reasoningwhen designing agent models. To demonstrate its usage and power in human-agent interaction, we employ it in two-agent negotiation. Our results show thatcapturing affinity improves agent-agent coordination and agents who performToM reasoning obtain outcomes that are better than agents who do not.The rest of this paper is organized as follows. Section 2 describes abstractionheuristics and computational affinity. Section 3 explains our framework and howwe integrate ToM with affinity in negotiation. Section 4 evaluates our proposedmodel over two-agent simulations. Section 5 discusses our results, addressesrelated research in the literature, and points to future research directions.2 Abstraction Heuristics and AffinityHumans are known to use behavioural simplification mechanisms in theirdecision-making processes (e.g., stereotypes, biases) [34]. Inspired by this idea,we envision an abstraction-guided ToM agent paradigm that simplifies its beliefsand knowledge into compact representations that can serve for heuristics. Com-putationally, what we call an \u201cabstraction mechanism\u201d is an agent apparatusthat does the following (Fig. 1):Computational Theory of Mind for Human-Agent Coordination 95Fig. 1. Abstraction procedure: Individual beliefs (Li) and knowledge (Kj) are used tocreate abstractions Mk that are then used in interactions Sn.1. It takes a set of beliefs and knowledge as input.2. Using a shared prominent characteristic of such input, it produces an inter-mediate output in the form of a simple yet more abstract belief or piece ofknowledge, or simply an abstraction, which shares the same characteristic.3. Applying rules that govern the role of the intermediate output, it producesinteraction states for the agent to operate in.We claim that such an abstraction procedure embedded in a ToM agentshould produce interaction states that can be used in a variety of settings, aresimple enough to easily mesh with the agent\u2019s decision-making processes, andcapture and interpret the related human behaviour. Figure 1 shows our layeredapproach to such an abstraction mechanism. The first layer holds the set ofbeliefs and knowledge about others that could come from different sources, suchas observations or explicitly stated information from others. While the agent cankeep this set, it does not operate at that level but instead creates abstractionsin the second level. The first level influences the second level; thus, if the agentobserves more information at the first level, the abstractions in the second levelmight change. The abstractions in the second level influence how the agentsoperate in the third level. One can think of the third level as pertaining tothe application in question. Figure 1 also shows that beliefs and knowledge canhave multiple characteristics Ck, Cl, etc. which guide the production of thecorresponding abstractions Mk, Ml etc.; multiple abstractions can be used toproduce an interaction state Sn with respect to the corresponding rule Rn.Note that abstractions are not designed to prevent agents from using theirbeliefs and knowledge directly. Instead, abstractions act as additions that requirelow maintenance and that are used whenever possible to avoid having to use toomuch information. Here, we do not intend to provide a full-fledged abstractionmodel that addresses and gives possible solutions to all kinds of challenges aToM agent may face during its lifetime. We will discuss some important pointsthat can help us further develop our abstraction mechanism in Sect. 5.96 E. Erdogan et al.2.1 Computational AffinityWe propose that in principle, this abstraction approach can be used with complexhuman notions. We demonstrate our intuition in a specific type of abstractionmechanism, which captures affinity : \u201ca feeling of closeness and understandingthat someone has for another person because of their similar qualities, ideas,or interests\u201d [24]. People are inclined to get along with and gravitate to othersthat are similar to them [22,33]. One practical outcome of this feeling is gener-ating generous behaviour: People tend to do favors for others they like [2]. Weclaim that affinity can be captured within an abstraction mechanism in whichone can merge many beliefs and pieces of knowledge (e.g., \u201cI believe that heleads a healthy life like me.\u201d) into a more abstract belief that shares the samecharacteristic (\u201cI believe that he is very similar to me.\u201d) and then to an inter-action state (\u201cI feel a strong affinity towards him because I believe that he isvery similar to me.\u201d) which can be more effectively used within a rule set whenmaking decisions (\u201cI feel a strong affinity towards him. I can do small favors topeople that I feel strong affinity towards. Thus, I will do a small favor for him.\u201d).Observing a similarity is essential for affinity [7]. In our computational frame-work, we limit similarity to interacting agents having the same opinions on asubject and use opinions as comparable tokens that are Boolean in nature (e.g.,healthy living is important: yes/no). Moreover, we limit observation to commu-nication, meaning that opinions are private and unobservable unless the agentshares them with another agent. Following this intuition, we provide three differ-ent definitions of computational affinity that pertain to how it is brought about.Note that the aim is not to come up with the most precise definition but withreasonable, alternative definitions that an agent might adopt.All definitions are based on the agents exchanging opinions. Thus, we considereach agent A to have a set of fixed opinions on various subjects.Definition 1. For an agent A to have a type-1 affinity towards another agentB, at least one of the opinions B tells A must match with that of A.The most important aspect of this form of affinity is that it is static, meaningthat after A establishes affinity towards B, even if B later tells its opinion onanother subject that does not match with that of A, A does not lose its affinity.However, in real life, affinity is not always static; thus, we define another typeof affinity to capture its dynamic nature:Definition 2. For an agent A to have a type-2 affinity towards another agentB, the most recent opinion B tells A must match with that of A.Still, affinity does not have to depend only on the latest matching opinion.For example, agents can do multiple comparisons before establishing affinity.Thus, we give another, more concrete way to define affinity computationally:Definition 3. For an agent A to have a type-3 affinity towards another agentB, the majority of opinions B tells A must match with those of A (i.e., thenumber of matching opinions is bigger than zero and not smaller than the numberof non-matching opinions).Computational Theory of Mind for Human-Agent Coordination 97Note that the abstraction mechanism that the agents employ is relativelysimple: Comparing just one pair of opinions is enough to produce (or change)the abstract belief of similarity which agents further employ to decide whetherto establish affinity or not. Even with this simple mechanism, we observe thatcomputational affinity as an abstract entity that has a life-cycle: it is born, lives,and dies (and can be brought from the dead again). It can be active or passive,subject to the situation the agent is in. Plus, it holds basic information aboutthe relationship between agents. Depending on the communication history ofthe agents, it can be reciprocal or not since both agents should tell each othertheir opinions for both of them to have affinity towards the other. Other featuresthat we have not incorporated here can include the duration (e.g., how long itaffects the agent\u2019s decision) and strength (e.g., how strongly it affects the agent\u2019sdecision). Next we demonstrate how even a simple abstraction mechanism asdescribed can be useful in human-agent interactions.2.2 Computational Affinity and ToMIn its core, we observe that a person who has affinity towards another person canact in ways that would be helpful to the second person. This can mean differentthings depending on the context; here we define it in a two-agent setting and asgeneric as possible. In simplest terms, an agent A that has an affinity towardsanother agent B can do a thing that is more favorable to B than the thingA normally does when it does not have affinity towards B. For example, in anegotiation, a seller A with an affinity towards a buyer B can make an offer thatis more favorable for B than the offer A makes when it does not have affinity.In addition, we want our agents to not just establish affinity but also attributeit as a mental state to others, as people do. Essentially, we also design agentsthat have ToM about other agents and reason whether another agent has anaffinity towards a certain agent or not (e.g., \u201cI believe B has an affinity towardsme\u201d). The reasoning mechanism shall rely on basic perspective-taking and thecondition that both agents share their opinions (remember that affinity is notinherently mutual). Later on, we will explain how such an agent with ToM canalso use this affinity attribution mechanism to its benefit.In this body of work, we call the ToM agents that can have type-x affin-ity towards others \u201ctype-x affinity agents with 1st order ToM\u201d or shortly \u201cAx1agents\u201d. Similarly, we denote the agents that do not have ToM as \u201ctype-x affinityagents with 0th order ToM\u201d or shortly \u201cAx0 agents\u201d.3 Negotiation with Computational Affinity and ToMNow, we discuss how our proposed model can be used for human-agent negoti-ation. We return to our example in Sect. 1 where a wearable physical activitymonitor agent is working with a human to increase the number of steps thehuman takes. As the underlying mechanism, we choose two-agent negotiation,98 E. Erdogan et al.because it is a robust mixed-motive setting that also provides a good context forexploring behavioural capabilities of ToM agents.To make our setup concrete, we define an agent as an autonomous entitywhich can either be an activity monitor agent or a human agent, where theformer is working to increase the number of steps taken by the human while thehuman is reluctant to walk. To achieve its goal, each agent can make an offeror accept an offer made by the other agent. Furthermore, an agent has fixedopinions on various subjects (e.g., healthy living is important: yes/no). It cantell the other agent its opinions, including those about the negotiation outcomesthemselves, and compare a told opinion with its own opinion (same subject).3.1 Negotiation FrameworkThe subject matter of negotiation is agreeing on the number of steps to be taken.The negotiation protocol can be briefly described as alternating monotonic con-cession with communication, a variant of the monotonic concession protocol [31].Basically, it is a rule set for two agents to negotiate and communicate in alter-nating rounds. An agent can both negotiate and communicate with the otheragent in the same round in which it can either make a new offer or accept thelatest offer made by the other agent (negotiation part) and can tell the otheragent its opinions (communication part). Furthermore, negotiations should bedone in the form of monotonic concession: No agent can make an offer thatis less preferred by the other agent than an earlier offer that it made. Lastly, anegotiation ends when an agent accepts the latest offer made or a fixed numberof rounds pass without an agreement (e.g., 10 total rounds).Negotiating agents\u2019 offers and counter-offers are generally governed by theirstrategies: a prepared plan of action to achieve a goal under conditions of uncer-tainty. The negotiation literature is rich with sophisticated strategies [4,28]. Inorder to focus only on the effects of computational affinity and ToM, we opt fora simple strategy for agents such that each agent makes an offer and adjuststhe number of steps with a constant, predetermined value until it goes beyondthe reserve value (or reserve price). For example, a human agent starts theoffer at 5000 and increases it with 100 every round until it goes beyond 5500.1We call this value of 100 the unit increment/decrement value of agents andmake all agents use this strategy as the baseline strategy when making offers.3.2 Negotiating with Affinity and ToMAgent A that has affinity towards another agent B can give an offer that can bemore favorable for B than the offer A gives when it does not have affinity towardsB, as we have stated earlier. More specifically, we utilize computational affinityas a regulator for unit increment/decrement values that agents use when makingoffers. As a design decision, we make reserve values not affected by affinity inour framework. Here, we give an example.1 In this case, for example the activity monitor agent could start with an offer of 5700and decrease it with 100 until it goes beyond 5300.Computational Theory of Mind for Human-Agent Coordination 99Table 1. Four negotiation scenarios Sc1, Sc2, Sc3 and Sc4 are given (Example 1).(a) Opinions do not match in Sc1, but matchin Sc2. Only A tells its opinion.Sc1 Sc2R A B R A B1 1500 1 15001 Oyes 1 Oyes2 2100 2 21003 1600 3 16004 2000 4 19905 1700 5 17006 1900 6 18807 1800 7 18008 Accepts 8 Accepts(b) Opinions match and A (resp. B) starts inSc3 (resp. Sc4). Both tell opinions.Sc3 Sc4R A B R A B1 1500 1 21001 Oyes 1 Oyes2 2100 2 15002 Oyes 2 Oyes3 1610 3 19904 1990 4 16105 1720 5 18806 1880 6 17207 1830 7 17708 Accepts 8 AcceptsExample 1. A human agent A of type A10 and an activity monitor agent B oftype A10 are negotiating. The reserve values of A and B are set to be 1850 and1750, respectively. Their respective unit increment/decrement values are both100 and affinity increases it with 10. Each agent has a Boolean opinion on thesame subject O: It can be either Oyes or Ono. In Tables 1a and 1b, we give fourdifferent scenarios (Sc1, Sc2, Sc3, and Sc4).Example 1 depicts two crucial points. First, affinity does not always producea different result (e.g., Sc1 and Sc2) and second, either agent can benefit fromthe result when affinity is reciprocal (e.g., Sc3 and Sc4), since the final situationdepends on other factors as well (e.g., the reserve values, the starting agent).Additionally, one can see that although reciprocal affinity introduces variance inthe agreements (e.g., Sc3 and Sc4 in which the accepted offers are 1770 and 1830,respectively), it stays the same on average (e.g., 1800) due to the symmetry inthe provided benefits for both agents.In the previous section, we have noted that an Ax1 agent can use its ToM abil-ity to its benefit when making offers. In particular, when an Ax1 agent concludesthat there is a mutual affinity, it can change its unit increment/decrement valueso that its offer adjustments (not offers themselves) are not as generous as itsopponent\u2019s adjustments. For example, if an Ax1 activity monitor agent decidesthat there is a mutual affinity and observes that its opponent\u2019s current incrementvalue (i.e., the difference between the latest two offers of the opponent) is 110, itcan change its own to a value lower than 110, say 105. With this improvement,it is guaranteed that a reciprocal affinity between an Ax1 and an Ay0 will resultin an offer that Ax1 prefers more than Ay0. Here, we give an illustrating example.Example 2. A human agent A of type A11 and an activity monitor agent B oftype A10 are negotiating. The reserve values of A and B are set to be 1850 and1750, respectively. Their respective unit increment/decrement values are both100. Affinity increases it by 10 but mutual affinity increases it only by 5. Each100 E. Erdogan et al.Table 2. Two negotiation scenarios Sc5 and Sc6 are given for A and B. Both tell theiropinions in both scenarios (Example 2).Sc5: Opinions match, A starts. Sc6: Opinions match, B starts.R A B R A B1 1500, Ono 1 2100, Ono2 2100, Ono 2 1500, Ono3 1610 3 19904 1990 4 16055 1715 5 18806 1880 6 17107 1820 7 17708 Accepts 8 Acceptsagent has a Boolean opinion on the same subject O: It can be either Oyes orOno. In Table 2, two different scenarios (Sc5 and Sc6) are given.One can notice in Example 2 that Ax1 is designed to limit its own affinity-induced generousness using ToM. The superiority of Ax1 over Ax0 can be seen inthe newly introduced asymmetrical variance in the agreements (e.g., Sc5 andSc6 in which the accepted offers are 1770 and 1820, respectively) and the newaverage (e.g., 1795 < 1800), benefiting Ax1 agent A more than Ax0 agent B.4 Experiments and ResultsWe are interested in understanding the role of affinity in getting to agreementswhen there is a bound on the time spent for negotiating. To answer this generalquestion in detail, we have created an experimental setup with four simulationexperiments. We configure our negotiation framework (including the reserve val-ues, starting offers, and unit increment and decrement values) so that an agree-ment can be achieved in a maximum of 12 rounds, even without affinity. Inall simulations, activity monitor agents\u2019 and human agents\u2019 starting offers areset to 2000 and 1000 and reserve values are 1450 and 1550, respectively. Unitincrement and decrement values are both set to 100 at the beginning and it iscommon knowledge that agents do not decrease these values below 100 (agentscan increase them in case of affinity). The worst offer an agent can make for itselfis with its reserve value. A negotiation begins with two newly created agents,namely, an activity monitor agent and a human agent, where every opinion ofagents is created randomly: it can be a \u201cyes\u201d or \u201cno\u201d with the same probability.One of the agents is randomly chosen to start the process and the other agentcontinues accordingly. In the first two rounds, each agent gives its starting offer.There are two additional restrictions in the protocol we use. First, an agenttells all of its opinions in the negotiation process. Second, opinions are told in aComputational Theory of Mind for Human-Agent Coordination 101pre-arranged order (i.e., subject 1, subject 2, subject 3...) where an agent tellsonly one opinion per round in a conversational flow. This is because we intend tokeep the communication as simple as possible and do not want to analyze howdifferent communication patterns affect the life-cycle of affinity. We also want toensure that affinity can be formed reciprocally in the negotiations.Every round, an Ax0 agent first checks if the latest offer is acceptable. If yes,it accepts and ends the negotiation. If not, it compares the shared opinion(s) tocheck whether affinity ensues or not, following the criteria of its affinity definition.If it does not establish affinity, it gives an offer that is 100 higher (resp. lower)than its previous offer, if it is a human (resp. activity monitor) agent. On theother hand, if the agent establishes affinity, it changes 100 to a multiple of 5between 100 and 150 (including the boundaries) and makes an offer accordingly.Then, it ends its turn by telling one of its opinions according to the sharingorder until all are shared. We introduce this randomness into Ax0 agent\u2019s offer-making mechanism to make it more dynamic. It is worth to note that this canalso indirectly change the agent that gives the final offer.Every round, an Ax1 agent also checks if the latest offer is acceptable. If yes,it accepts and ends the negotiation. If not, it compares the shared opinion(s) tocheck whether affinity ensues or not, following the criteria of its affinity defini-tion. Additionally, it also decides whether the other agent has established affinityor not. If the Ax1 agent does not establish affinity or decides that its opponentdoes not have affinity, it gives an offer that is 100 higher (resp. lower) than itsprevious offer, if it is a human (resp. activity monitor) agent, like Ax0 agents. Oth-erwise, it changes 100 to a multiple of 5 between 100 and X (including X) andmakes an offer accordingly, where X is equal to the difference between the latesttwo offers of its opponent (i.e., the opponent\u2019s currently observed unit incre-ment/decrement value). It ends its turn by telling one of its opinions accordingto the sharing order until all are shared. Again, we introduce this opponent-dependent randomness into the offer-making mechanism of an Ax1 agent to makeit more dynamic and limit the agent\u2019s own affinity-induced generousness.There are four different experimental variations in which we use only A1m(V1), only A2m (V2), only A3m (V3), and all types of agents (V4), wherem \u2208 {0, 1} unless told otherwise. Every experimental variation consists of fourdifferent opinion settings: In the n-opinion setting, every agent has n opinion(s)on the same n subjects, where n \u2208 {1, 2, 3, 4}. Per setting, we perform sim-ulations with 10, 000 different agent pairs where every agent negotiates once.4.1 The Effect of Affinity on AgreementsIn the first experiment, our aim is to find how affinity affects the number ofagreements made when A10, A20, and A30 agents negotiate with each other (V4).An agent is created as an A10, A20, or A30 agent with the same probability. We limitthe maximum number of rounds of negotiation to 12. Through the simulation,we also keep track of the final rounds in which agreements are settled.102 E. Erdogan et al.Fig. 2. Affinity helps coordination.The stacked bars in Fig. 2a show the number of successful negotiations thatare done by Ax0 in the simulation. All different opinion settings are given in thex-axis (i.e., 0-4), while the y-axis shows the total number of achievable agree-ments; colors and hatches together represent the final round information of theagreements (i.e., 8-12).When no opinion is shared, all 12 rounds are necessary for reaching an agree-ment in all simulations. However, even sharing one opinion makes a big difference.We can see in Fig. 2a that nearly half of the agreements are done in 10 roundsin the 1-opinion setting. Other settings also show similar results: The number ofagreements that need 12 rounds decreases when the number of shared opinionsincreases. Hence, we can conclude that when Ax0 agents negotiate, the number ofagreements that are settled on earlier than 12 rounds increases with the numberof shared opinions. This shows that by modeling affinity explicitly, the agentscan reduce the number of interactions needed to agree.4.2 Affinity Types and Agreement RatesIn the second experiment, our aim is to find how affinity type and number ofshared opinions affect the number of agreements made when Ax0 agents negotiate.The experiment consists of the first three variations V1, V2, and V3. We limit themaximum number of rounds of negotiation to 10 to get a better understandingof how different affinity types get to early agreements.The line plots in Fig. 2b show the percentage of successful negotiations thatare achieved by Ax0 in 10 rounds over all negotiations per affinity type.When no opinion is shared, the number of agreements that can be achievedin 10 rounds is zero. Figure 2b shows that for the experiment\u2019s V1 variationwith 1-opinion setting, we can see that agents sharing just one opinion makes asignificant difference in the number of agreements. When A10 agents negotiate,nearly 0.50 of all simulations end with an agreement. The number increases to0.68 and 0.75 for 2-opinion and 3-opinion settings. This increase can be explainedComputational Theory of Mind for Human-Agent Coordination 103Fig. 3. Agreement rates depend on both ToM and affinity type.by the fact that when the agents exchange more opinions, the probability offinding a negotiating agent pair that has at least one matching opinion increases.In the 4-opinion setting, however, it does not go higher since we set hard limitson the unit increment/decrement values and also due to the overall randomnessin the agent creation and offer-making procedures. Thus, it shows that Type-1affinity affects the agents in such a way that the number of agreements madeincreases more slowly when the number of rounds is fixed.When A20 agents negotiate, we see a different pattern. For every opinion set-ting of the experiment\u2019s V2 variation, nearly 0.50 of all simulations end with anagreement. This is mainly because Type-2 affinity is not static like Type-1 affin-ity and every agent can lose its affinity during the opinion comparison process.Thus, Type-2 affinity affects and changes the average unit increment/decrementvalue that an agent uses before reaching an agreement, but not as much as Type-1 affinity. On the other hand, A30 agents generate a different pattern that is amixture of the previous ones. Excluding the 0-opinion setting, the agreementrate in the experiment\u2019s V3 variation is on average greater than 0.5 but not asmuch as the average we see in V1. Hence, we can say that Type-2 and Type-3affinity types do not create agreements as much as Type-1 affinity.4.3 Roles of ToM and Affinity in AgreementsIn the third (resp. fourth) experiment, our aim is to find how ToM reasoning andaffinity together affect the number of agreements made when human agents oftype Ax0 (resp. Ax1) and activity monitor agents of type Ay1 negotiate. Both exper-iments consist of variations V1, V2, and V3, similar to the second experiment.The maximum number of rounds is set to 10.The line plots in Fig. 3a (resp. Fig. 3b) show the percentage of successfulnegotiations that are achieved by Ax0 (resp. Ax1) human agents and Ay1 activitymonitor agents in 10 rounds over all negotiations per affinity type.104 E. Erdogan et al.Comparing with Fig. 2b, Fig. 3a shows a general decrease in the agreementrates by shared opinions and affinity types. For example, when Ax0 human agentsnegotiate with Ay1 activity monitor agents, nearly 0.40 of all simulations end withan agreement in the 1-opinion setting, instead of 0.50. This number increases upto 0.60 for the 4-opinion setting which is lower than the corresponding agreementrate given in Fig. 2b (0.76). The drop in the agreement rates is drastic when Ax1human agents negotiate with Ax1 activity monitor agents, as plotted in Fig. 3b.This is on par with what we have expected from the negotiating behaviour ofToM agents since it is affected by opponents\u2019 offer-making behaviour as well:ToM can have a relatively negative effect in the number of agreements when thenumber of rounds is fixed.We have done additional simulations to provide more depth to the negoti-ations in which ToM agents negotiate with agents that do not have ToM. InFig. 4a, we analyze Ax0\u2013Ay1 negotiations where all affinity types are used andonly one opinion is shared. The x-axis shows the number of agreements done in10 rounds and the y-axis shows the agreeable offer range (1450\u22121550). We cansee more agreements on the right side of the figure (>1500) than the left side(<1500), implying that Ay1 activity monitor agents end up with offers that areon average better for them (the average offer is approximately equal to 1512).In Fig. 4b, we analyze how an increase in the number of shared opinions changesthis asymmetrical benefit. Every line plot shows how number of agreements cor-relates with the final offers in a specific opinion setting. We can see that theAx0 human agents in many-opinion settings end up with better offers on averagethan the Ax0 human agents in few-opinion settings (still not better than their Ay1monitor agent counterparts). It shows that when more opinions are shared, thesuperiority of ToM agents over non-ToM agents decreases in negotiations wherewe explicitly model affinity. This emergent phenomenon reminds us that it is notso easy to develop and maintain affinity with sheer communication (i.e., it alsoneeds a strategy) and it is even harder to benefit from it (i.e., ToM\u2019s advantagediminishes).5 Discussion and Future WorkWithin our computational ToM framework, founded on the abstraction mech-anism defined in Sect. 2, we propose a human-inspired heuristic called compu-tational affinity for agents to improve coordination in hybrid interactions. Weuse agents to simulate a human-agent negotiation in the context of activitymonitoring. Our findings demonstrate that explicitly modeling affinity can easethe agreement process. We show how sharing more information can also helpthe activity monitoring agents forge more agreements, albeit depending on theagent\u2019s affinity type. Our results indicate that when negotiating with humanagents that do not have a ToM, activity monitoring agents that have a ToMend up with agreements that is more favorable to them than to their opponents.Although the communication part of negotiations needs further analysis andstrategies on its own [28], the results provide the motivation to develop moreComputational Theory of Mind for Human-Agent Coordination 105Fig. 4. ToM with affinity benefits agents.sophisticated ToM agents that can generate affinity and benefit from it, and testthem in real-life negotiations to see if and how they can improve human-agentcoordination.Research on computational ToM models suggests that ToM reasoning ben-efits agents in different ways and even more in the higher orders. De Weerd etal. [11] show that agents benefit from higher-order ToM reasoning in competitivegame-theoretic settings, although with diminishing returns beyond third-orderToM. Further, they investigate how higher-order ToM can be beneficial for agentsin a strictly cooperative game [14] and show that communication can be set upmore quickly when agents beyond zero-order ToM play the game. De Weerd etal. [15] determine to what extent agents benefit from higher-order ToM reasoningin a mixed-motive situation called the \u201cColored Trails\u201d. The results indicate thatthere is a considerable benefit in using second-order ToM; however, first-orderToM has a limited effectiveness. Kro\u0308hling and Mart\u0301\u0131nez [21] investigate the roleof ToM in single-issue negotiations between \u201ccontext-aware\u201d agents where thenegotiation context is modeled by two variables, summarized as necessity andrisk. Go\u0308ru\u0308r et al. [18] propose a ToM agent model for estimating humans\u2019 inten-tions in a shared human-robot task. Brooks and Szafir [8] show how robots cancreate second-order ToM models by using humans\u2019 actions in spatial settings.Observing and communicating are crucial components of human socialbehaviour. Our long-term goal is to design socially intelligent agents that canunderstand how humans \u201ctick\u201d and work with them in synergy. Computationallymodeling ToM ability with the abstraction heuristics that we defined in Sect. 2 isa first step toward this goal. Unlike the studies we mention above, we design ourhuman-inspired abstraction procedure to be as generic as possible and generateinteraction states which emulate how humans develop and maintain the mentalstates they experience through their lives. The procedure also provides a use-ful simplification technique for abstracting information for social agents to yieldfeasible ToM models of humans they interact with. Affinity, which is essentiallybased on abstracting observed and communicated similarities, is one particular106 E. Erdogan et al.interaction state we use in this paper. It presents a good starting point, beinga human mental state which is also a valuable heuristic in decision-making, andinspires us to computationally formalize other useful interaction states as well.As a follow-up work, we aim for a more complete model that captures theways humans abstract their beliefs and knowledge. We will start with a formal-ization from tip to toe (i.e., beliefs, abstractions, procedure etc.). For that, weneed to answer a couple of fundamental questions such as which beliefs to usewhen abstracting, when to stop the procedure, what to do in case of a beliefupdate, and which interaction states to activate after abstracting. In addition tothese issues, a ToM agent should also be able to correctly attribute this abstrac-tion process to others. As we aim to design higher-order ToM agents that canalso take into account how their own artificial minds are perceived by others, weplan to benefit from mind perception theory [19,23] when investigating the rolesof observation and communication in recursive ToM reasoning. Additionally, weconsider benefiting from value-based reasoning [3,10,29] to develop agents thattakes others\u2019 values into account when doing ToM reasoning. With a more com-prehensive, formalized model, we will further analyze how affinity can be usedwithin other negotiation and communication protocols and strategies as well asget a broader view of its effects in multi-issue negotiations.Acknowledgements. This research was funded by the Hybrid Intelligence Center,a 10-year programme funded by the Dutch Ministry of Education, Culture and Sci-ence through the Netherlands Organisation for Scientific Research, https://hybrid-intelligence-centre.nl, grant number 024.004.022.References1. Akata, Z., et al.: A research agenda for hybrid intelligence: augmenting humanintellect with collaborative, adaptive, responsible, and explainable artificial intel-ligence. Computer 53(08), 18\u201328 (2020)2. Aronson, E., Akert, R.M., Wilson, T.D.: Social Psychology, 7th edn. Prentice Hall,Upper Saddle River (2010)3. Atkinson, K., Bench-Capon, T.: Taking account of the actions of others in value-based reasoning. Artif. Intell. 254, 1\u201320 (2018)4. Baarslag, T., Hendrikx, M.J.C., Hindricks, K.V., Jonker, C.M.: Learning about theopponent in automated bilateral negotiation: a comprehensive survey of opponentmodeling techniques. Auton. Agents Multi-Agent Syst. 30(5), 849\u2013898 (2016)5. Baker, C.L., Saxe, R.R., Tenenbaum, J.B.: Bayesian theory of mind: modeling jointbelief-desire attribution. In: Proceedings of the Thirty-Third Annual Conferenceof the Cognitive Science Society, vol. 33, no. 33, January 20116. Baksh, R.A., Abrahams, S., Auyeung, B., MacPherson, S.E.: The Edinburgh SocialCognition Test (ESCoT): examining the effects of age on a new measure of theoryof mind and social norm understanding. PloS ONE 13(4), e0195818 (2018)7. Bell, R.A., Daly, J.A.: The affinity-seeking function of communication. Commun.Monogr. 51(2), 91\u2013115 (1984)8. Brooks, C., Szafir, D.: Building second-order mental models for human-robot inter-action. arXiv preprint arXiv:1909.06508 (2019)Computational Theory of Mind for Human-Agent Coordination 1079. Carruthers, P., Smith, P.K.: Theories of Theories of Mind. Cambridge UniversityPress, Cambridge (1996)10. Cranefield, S., Winikoff, M., Dignum, V., Dignum, F.: No pizza for you: value-basedplan selection in BDI agents. In: IJCAI, pp. 178\u2013184 (2017)11. De Weerd, H., Verbrugge, R., Verheij, B.: How much does it help to know what sheknows you know? An agent-based simulation study. Artif. Intell. 199\u2013200, 67\u201392(2013)12. De Weerd, H., Verbrugge, R., Verheij, B.: Agent-based models for higher-order the-ory of mind. In: Advances in Social Simulation, Proceedings of the 9th Conferenceof the European Social Simulation Association, vol. 229, pp. 213\u2013224 (2014)13. De Weerd, H., Verbrugge, R., Verheij, B.: Theory of mind in the Mod game: anagent-based model of strategic reasoning. In: European Conference on Social Intel-ligence, pp. 128\u2013136. Springer (2014)14. De Weerd, H., Verbrugge, R., Verheij, B.: Higher-order theory of mind in the tacitcommunication game. Biol. Inspir. Cogn. Archit. 11, 10\u201321 (2015)15. De Weerd, H., Verbrugge, R., Verheij, B.: Negotiating with other minds: the roleof recursive theory of mind in negotiation with incomplete information. Auton.Agents Multi-Agent Syst. 31(2), 250\u2013287 (2017)16. De Weerd, H., Verbrugge, R., Verheij, B.: Higher-order theory of mind is especiallyuseful in unpredictable negotiations. Auton. Agents Multi-Agent Syst. 36(2), 1\u201333(2022)17. Fiske, S.T.: Stereotyping, prejudice, and discrimination. In: Gilbert, D.T., Fiske,S.T., Lindzey, G. (eds.) Handbook of Social Psychology, vol. 2, 4 edn., pp. 357\u2013411.McGraw-Hill, New York (1998)18. Go\u0308ru\u0308r, O.C., Rosman, B.S., Hoffman, G., Albayrak, S\u0327.: Toward integrating theoryof mind into adaptive decision-making of social robots to understand human inten-tion. In: International Conference on Human-Robot Interaction. Workshop on theRole of Intentions in Human-Robot Interaction (2017)19. Gray, H.M., Gray, K., Wegner, D.M.: Dimensions of mind perception. Science315(5812), 619 (2007)20. Heyes, C.M.: Imitation, culture and cognition. Anim. Behav. 46(5), 999\u20131010(1993)21. Kro\u0308hling, D., Mart\u0301\u0131nez, E.: On integrating theory of mind in context-aware nego-tiation agents. In: XX Simposio Argentino de Inteligencia Artificial (ASAI 2019)-JAIIO 48 (Salta), pp. 180\u2013193 (2019)22. Lazarsfeld, P.F., Merton, R.K.: Friendship as a social process: a substantive andmethodological analysis. Freedom Control Mod. Soc. 18(1), 18\u201366 (1954)23. Lee, M., Lucas, G., Gratch, J.: Comparing mind perception in strategic exchanges:human-agent negotiation, dictator and ultimatum games. J. Multimod. User Inter-faces 15(2), 201\u2013214 (2021)24. Merriam-Webster: Affinity. Merriam-Webster.com dictionary (n.d.). https://www.merriam-webster.com/dictionary/affinity25. Michlmayr, M.: Simulation theory versus theory theory: theories concerning theability to read minds. Master\u2019s thesis, Leopold-Franzens-Universita\u0308t Innsbruck(2002)26. Osten, F.B.V.D., Kirley, M., Miller, T.: The minds of many: opponent modelingin a stochastic game. In: IJCAI, pp. 3845\u20133851. AAAI Press (2017)27. Premack, D., Woodruff, G.: Does the chimpanzee have a theory of mind? Behav.Brain Sci. 1(4), 515\u2013526 (1978)28. Raiffa, H.: The Art and Science of Negotiation. Harvard University Press, Cam-bridge (1982)108 E. Erdogan et al.29. Rangel, A., Camerer, C., Montague, P.R.: A framework for studying the neurobi-ology of value-based decision making. Nat. Rev. Neurosci. 9(7), 545\u2013556 (2008)30. Rosati, A., Knowles, E., Kalish, C., Gopnik, A., Ames, D., Morris, M.: What theoryof mind can teach social psychology: traits as intentional terms. In: Malle, B.F.,Moses, L.J., Baldwin, D.A. (eds.) Intentions and Intentionality: Foundations ofSocial Cognition, pp. 287\u2013303. MIT Press, Cambridge (2003)31. Rosenschein, J.S., Zlotkin, G.: Designing conventions for automated negotiation.AI Mag. 15(3), 29 (1994)32. Stevens, C., Taatgen, N.A., Cnossen, F.: Metacognition in the prisoner\u2019s dilemma.In: 13th Annual International Conference on Cognitive Modeling, p. 112, April201533. Suls, J., Martin, R., Wheeler, L.: Social comparison: why, with whom, and withwhat effect? Curr. Direct. Psychol. Sci. 11(5), 159\u2013163 (2002)34. Tversky, A., Kahneman, D.: Judgment under uncertainty: heuristics and biases.Science 185(4157), 1124\u20131131 (1974)35. Winfield, A.F.T.: Experiments in artificial theory of mind: from safety to story-telling. Front. Robot. AI 5, 75 (2018)Computational Discoveryof Transaction-Based Financial Crimevia Grammatical Evolution: The Caseof Ponzi SchemesPeter Fratri\u010d1(B), Giovanni Sileno1, Tom van Engers1,2, and Sander Klous11 Informatics Institute, University of Amsterdam, Amsterdam, The Netherlandsp.fratric@uva.nl2 Leibniz Institute, TNO/University of Amsterdam, Amsterdam, The NetherlandsAbstract. The financial sector continues to experience wide digitaliza-tion; the resulting transactional activity creates large amounts of data,in principle enabling public and private actors to better understand thesocial domain they operate on, possibly facilitating the design of inter-ventions to reduce illegal activity. However, the adversarial nature offrauds and the relatively low amount of observed instances make theproblem especially challenging with standard statistical-based methods.To address such fundamental issues to non-compliance detection, thispaper presents a proof-of-concept of a methodological framework basedon automated discovery of instances of non-compliant behaviour in asimulation environment via grammatical evolution. We illustrate themethodology with an experiment capable of discovering two known typesof Ponzi schemes from a modest set of assumptions.1 IntroductionFinancial crime occurs at many levels of society, from credit card fraud, to taxfraud, money laundering, terrorist financing, financial market manipulation, upto the corruption of the highest representatives of individual countries or interna-tional political bodies. A unifying aspect of all these instances of non-complianceis that the transaction of assets with the aim of illegal profit is typically con-ducted in such a way that no suspicion of illicit activity arises. In order to detectnon-compliant activity from available evidence, researchers and analysts haveapplied over the years various computational methods, ranging from rule-basedsystems, knowledge graphs, machine learning models, to executable models ofsocial systems. Although these applications have shown various levels of success,several issues remain at present, still exploited by non-compliant actors [4,17].Research Background. Synthetizing non-compliant behaviour into a set ofpatterns, either explicitly via a set of logical rules, or implicitly by somemachine learning method, typically face difficulties as e.g. explainability (forML-based methods), unavailability of data, high false positive rate, or overlook-ing the adaptability of non-compliant agents. All these issues make traditionalc\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 109\u2013120, 2022.https://doi.org/10.1007/978-3-031-20845-4_7110 P. Fratri\u010d et al.approaches both ineffective and inefficient, particularly on the medium-longerterm. We will elaborate therefore on three other trends observed in the litera-ture. According to a recent review [3], network analysis tools have been slowlyfinding their way into prominence. These tools capitalize on the ability of net-works to represent complex relationships, and at the same time being both inter-pretable and easy to visualize. Once the transaction graph is formed, the maingoal becomes essentially to detect non-compliant individuals, suspicious events,or anomalous structures [1,2]. Several methods of this type have already beenproposed in the area of financial fraud detection [23]. Comparatively, approachesbased on modeling and simulation are covered by a much smaller number ofstudies [6,18], most of which focus on the possibility of training detection mod-els on simulated data, also to mitigate the issue of high false negatives. Only afew simulation environments were developed in the literature to generate illicittransaction activity. Instead, the issue of adaptivity is addressed mostly in thecontext of adversarial machine learning [12,14,16,25]. However, this approachtargets the local fraud space defined by the parametric model determined by thedataset, so it can hardly generalize to illicit behaviour in a global sense, i.e. notincluded in the data or encoded in the classifier. If we target the design of intel-ligent agents autonomously learning frauds by interacting with the environment(and so capable of generating new illicit behaviours), the number of studies iseven lower, e.g. co-evolutionary methods to discover tax frauds tested in a trans-action tax network environment in [15]; reinforcement learning [19] to design anagent learning credit card fraud in an adversarial environment.Generalizing to any kind of adversarial system where the detection modelis tested against a model of an adaptive perpetrator, the research seems to beprogressing faster in other areas. For instance, adversarial systems are moreextensively studied in the area of artificial intelligence [7], although still on arelatively low scale level. The area of cybersecurity is advancing comparativelyfaster than the socio-legal domain, probably because the implementation of amodel of cyber environment is less of a challenge compared to social systems,which means model-based testing methods can be effectively implemented [24].Aims and Contribution of the Paper. Fraud schemes target specific vulnera-bilities of a socio-legal system and/or psychological weaknesses of its victims,and very often exhibit a modular structure: more complex schemes tend to bemodifications of simpler ones. This short paper presents and elaborates on thisintuition, focusing on Ponzi schemes (PSs) implemented on distributed ledger,i.e. smart contracts. The reason why we choose specifically smart contract PSs isthat the complex legal terminological nuances involved in arbitrary contracts aremitigated with smart contracts because of their mechanistic transaction environ-ment. This, and public availability of data, makes the distributed ledger suitablefor the type of investigations. Moreover, due to popularization of this technology,the question of smart contract PS detection is a pressing issue [8,9].In our study, we pursue a long term goal of developing a fraud discovery assis-tant, where illicit behaviour can be generated depending on presumed observ-ables, socio-psychological modules of the simulation model, or potentially evenComputational Discovery of Transaction-Based Financial Crime 111the implemented countermeasures. At this point of research, we focus on the first(generation) and briefly discuss the second (internal socio-psychological modules)and third (couuntermeasures) aspects. Depending on observables considered, twoknown types of PSs will be discovered using grammatical evolution. The illicitactivity discovered and simulated in the model will be visualized as a series ofsnapshots of the transaction network.Case Study: Types of Ponzi Schemes. Various types of smart contract PSsalready exist on the Ethereum blockchain [5]. In its basic version, each time anew participant enters the scheme, the entry fee is redistributed equally amongother participants. A modification that aims to create a community of highlyprofitable users can be implemented by imposing a preference ordering on thecapital redistribution. For example, to exploit risk-appetite and deceivability ofsociety, early-stage investors can be benefited by repaying the premium chrono-logically; therefore, the participants that joined later might not be repaid oncethe capital is depleted. This type of smart contract PS is known as waterfalltype. Another type, that is in a way a modification of the previous two types, isthe array type. In this case, the redistribution mechanism keeps track of whichparticipant was paid last in order to equalize the frequency of payments, but atthe same time pays the next participant only if there is enough capital to send apayment exceeding the entry fee of the participant. This means that it prioritizesthe size of the user base that is already in profit, therefore it is more likely thescheme will be perceived as a valid investment in the society. Clearly, there canbe more sophisticated variations of smart contract PSs, for example including areward for participants recruiting new users; however, for our current aims, thetwo previous schemes are sufficient.2 General FrameworkIn order to generate and evaluate possible fraud schemes, we propose a frame-work for (re)construction of non-compliant behaviour that requires four opera-tional components. These are: (i) a search space defined by an action space (inwhich a fraud scheme can be constructed); (ii) a simulation environment to exe-cute actions of agents including a non-compliant (or fraudulent) agent, in which(iii) a fitness function can be calculated to determine how good each scheme isby evaluating its outcome; (iv) a search algorithm to explore the search space,that we typically identify with the reasoning mechanism of the non-compliantagent. If all four instruments are well-defined, then it is possible to (re)createthe fraudulent behaviour as illustrated on Fig. 1.Expert knowledge is used to formulate hypotheses about the functioning ofthe simulation environment and representation of the search space, includingrelevant observables for the non-compliant agent (search algorithm). The innerloop (continuous lines) searching the space of non-compliant schemes producesa dataset of transaction schemes. The set of hypotheses can be subsequentlyextended with assumptions that give rise to new instances of non-compliantbehaviour (dashed lines).112 P. Fratri\u010d et al.Fig. 1. Overview of methodology to (re)construct non-compliant behaviourArguably, a detection algorithm is also an important part of the theoreticalframework. However, at the current stage of research, we consider it as essentiallya different research question subsequent to the generation problem (see the dis-cussion section for insights on future directions). Moreover, note that simulationenvironment can be also combined with additional goals as assessing algorithmicfairness (see e.g. [11]).3 Generation of Ponzi SchemesIn general, a simulation model generates a sequence of transactional graph snap-shots G0, ..., GT as a record of agents interacting in the environment for a finitenumber of steps T . The fraudulent subgraph sequence H0, ..,Ht for t < T is gen-erated during the simulation process, in association with non-compliant activity.For the sake of this study, the agent-based model will be designed to be min-imalistic, which means that only the minimal set of assumptions necessary toapproximate PS mechanism will be employed. Since PSs do not in principledepend on transactions that are happening outside the scheme, it is not neededto assume any direct transactional interactions between the agents. While thismight intuitively seem an unsound manner to model social systems, it turnsout to be an advantage, because it allows us to generate data related to illicitbehaviour only by using the assumptions necessary for the illicit behaviour toarise. Obviously, it is true that other forms of interactions happen in the realworld during a PS spread, but this extension is needed only for more sophisti-cated types of schemes (see p. 9).In practice, no additional economic activity producing value is assumed inthe model, which means except for trivial cases every transaction sequence is aPS. This simplifies the modelling as there is no need to define a PS either ona phenomenological or a logical basis. Yet, the adaptation mechanism to findprofitable schemes will plausibly work for more complex settings (e.g. societalpolicies, physical constraints, additional economic actions). Consequently, byrelaxing this assumption, more sophisticated schemes can be addressed.Contract Mechanism. We assume that the initial transaction graph G0 is anempty graph with N + 2 nodes; one node represents the contract, one nodeComputational Discovery of Transaction-Based Financial Crime 113Fig. 2. Initial state is an empty transaction graph G0 (blue nodes) and subgraph H0(red nodes). In G1 a transfer of 11.15 cash is made between the node 1 and the contractnode. In the state G2 the subgraph H2 has three nodes. (Color figure online)represents the initiator of the contract, and N nodes represent the agents thatcan join the contract. The contract and its members constitute the subgraphsequence H0, ...,HT and therefore the initial subgraph H0 will consist only oftwo nodes (the contract node and the initiator) and zero edges.The contract has two attributes: a deposit account and a list of members. Inorder to join the contract, an agent needs to send an entry fee, that is initializedfor each agent randomly from a prespecified distribution. If an agent decidesto join the contract, the entry fee is sent to the contract deposit address. Themechanism, specified in the following excerpt, is illustrated on Fig. 2.1 if contract.isTrustworthy(agent.threshold):2 G.addEdge(agent , contract , agent.entryFee)3 G.executeTransactions ()In the simulation environment, the method addEdge adds a directed edge fromthe node in the first argument to the node in the second argument. The methodexecuteTransactions is called on a graph object by an agent to execute trans-actions defined by the edges. The threshold attribute of an agent and thecontract method isTrustworthy serve to model the agents\u2019 attitude, and willbe explained in the next section.Contract Trustworthiness and Agent Trust. During the simulation, the trustwor-thiness of the contract is calculated as a numerical value in the zero-one interval.There is no general agreement what exactly makes a contract trustworthy to peo-ple; for the sake of example we consider two plausible basic assumptions, anddefine a function based on these assumptions1. The trustworthiness Tr of a con-tract is (a) proportional to the relative amount of agents in profit n+ comparedto the number of agents n that have already joined; (b) inversely proportionalto the root of the density of agents that joined the contract. Following these twoassumptions, we can define the function:1 The model of trust used in this study is simplistic and serves only for the purposeof demonstration. For overviews on trust models see, e.g. [10,22].114 P. Fratri\u010d et al.Tr(n+, n) =1 + n+n\u00b7( nN) 1K(1)where K > 1 is a societal coefficient, that controls the interplay between the twoassumptions.Each agent has an internal threshold that determines if an agent joins thecontract. The method isTrustworthy returns True if the trustworthiness of thecontract is higher than the threshold of the agent, and False otherwise. Weassume that the internal threshold parameter of each agent is proportional tothe entry fee the agent is willing to pay to join the contract, because we deema plausible assumption that the agents considering to pay more will be equallymore skeptical of their investment.Fitness. Clearly, the profit attained by the PS heavily depends on the Eq. (1),and therefore the scheme initiator needs to decide the optimal redistribution ofcapital such that the scheme is attractive for the agents in the environment.This means that the initiator needs to balance out short-term profit with long-term sustainability of the scheme. This is a core parameter for this type ofnon-compliant behaviour. The fitness of a PS is then defined as the amount ofcapital generated for the initiator, that is, the amount of redistributed capitalthat ends up in the deposit address of the initiator node.Search Space Representation. Once the graph G0 and the subgraph H0 areinitiated, the scheme is defined by its specific capital redistribution structure.This redistribution structure consists of a set of logical rules that evolve thetransaction graph, deciding which members should be paid. In our framework,the characteristic form of the PS is expressed as illustrated below:1 if contract.FeeReceived(new_user):2 H.addNode(new_user)3 H.addEdge(new_user , contract , new_user.entryFee)4 G.executeTransactions ()5 try:6 H.evaluate(instructionSequence)7 G.executeTransactions ()8 else:9 exit()The set of instructions instructionSequence consists of instruction that modifythe payment scheme Ht\u22121. Then the payments defined by the modified graphHt are carried out by the executePayments() method2. Note that an entrycondition can be considered for potential new users, e.g. a minimal entry fee.For simplicity, we assume no special conditions are in place: anyone can join.2 It can be argued whether executePayments should be called after every instruction,or after graph modifications, e.g. AddNode already applied during the evaluation ofinstructionSequence; however, this choice does not affect the model profoundly.Computational Discovery of Transaction-Based Financial Crime 115The syntax of the instructions instructionSequence will be defined by acontext-free grammar, defined in Backus-Naur form below:<instruction> ::= <clause> ; <instruction> | <clause><clause> ::= if (<premise>) <action><action> ::= H.addNode(<node>) | H.addEdge(contract, <node>, <weight>)| H.removeEdges(contract, <node>)The actions addNode, addEdge, and removeEdges, add node, edge, and removeedges of the subgraph Ht respectively. The rest of the terminal symbols willbe formulated later to illustrate how specific assumptions of observables dependon what kind of scheme is generated. In the trivial case displayed on Fig. 2,the instruction sequence would consist of three instructions: H.addNode(1),H.addEdge(contract, 1, 11.15), and H.removeEdges(contract, 1), where11.15 is the weight of an edge that corresponds to the amount of currency trans-ferred. As will be defined later, the symbol <node> can be replaced by a variable,which means the instruction sequence of the initiator essentially acts as an openformula that is grounded in an event of a new agent joining the PS3.Note that not all words generated in the exploration are semantically correct(e.g. adding a node that was already added), which is why the code above requirestry method to call the exit() method if an error is detected on runtime.4 Experiments and ResultsThe present work empirically demonstrates how two PS types can be discoveredbased on the introduction of hypothetically relevant observables, as following themethodology described in Fig. 1. In practice, the context-free grammar presentedabove is extended with further terminal symbols (standing for the hypotheticalrelevant predictors), i.e. dedicated query-methods (used by agents to perceivesome property from the environment), and premises (used by agents to conditionperformance).In our experiments, the search algorithm used by the agent to discover newinstances of illicit schemes from the given set of predictors is grammatical evolu-tion [21].4 For the simulation environment, we will consider N = 100 agents andthe societal coefficient K of the trustworthiness function will be set to 10. Thedistribution of the entry fees follows a Beta distribution with both first and sec-ond shape parameter equal to two, which means the distribution approximatesa Gaussian. The sampled value from the Beta distribution is scaled by a factorof 10 for better readability.3 This reflects the event-driven architecture integrated into the smart contract pro-gramming language Solidity. In general, it captures the cyclic characteristic of fraud-ulent business models.4 In general, grammatical evolution is an evolutionary algorithm where words of agrammar are mapped to integer vectors, and an evolutionary optimization procedureis used to optimize the fitness function. Then integer vectors are mapped back towords.116 P. Fratri\u010d et al.Waterfall-Type Topology. The basic Waterfall type of PS can be found by includ-ing a set of rather trivial terminal symbols into the grammar. In the instructionsequence, it must be indicated who is the initiator of the scheme and who isthe new user that wants to join. The getFee method returns the entry fee ofthe agents that already joined. Further on, the possible percentages of eitherthe entry fee or the contract balance to be paid to the contract participants areassumed. A handy piece of information to include is the NUsers query-method,that takes as an argument an integer and returns true if the number of marketparticipants is equal to the argument.By visually analysing the best 20 generated transaction graph sequences, wehave observed that all of them had a star graph structure, that is typical for thewaterfall type (Fig. 3). The only deviation from this pattern occurred when thealgorithm decided to send capital to the initiator only after a sufficiently highnumber of contract participants was reached. This means that the evolutionaryalgorithm discovered that the spread of the PS is greater, and therefore also theamount of capital accumulated, if the capital is redistributed more generouslyat the beginning.Array Topology. As already discussed, the waterfall type can be made moreefficient if the scheme will have a concept of who was paid last and who shouldbe paid next. Indeed, each time the method executeTransactions is called forthe waterfall scheme, many of the transactions cannot be executed because theFig. 3. Snapshots of the transaction graph for the waterfall type (upper row) and thearray type (lower row) of Ponzi Schemes (PS).Computational Discovery of Transaction-Based Financial Crime 117capital of the contract is depleted. This issue can be resolved by including threemore query-methods into the grammar, modifying it as such:<premise> ::= TRUE | NUsersEq(<int>)| BalanceFeeHigherAndNotConnected(<node>, <weight>)<node> ::= new_user | initiator | getNextToPay() | getLastPaid()where getNextToPay and getLastPaid keep track of which agent was paid lastand which agent is next in order; BalanceFeeHigherAndNotConnected returnstrue if the contract node is not connected to the node provided by the firstargument and the capital balance of the contract is higher than the secondargument. Running the search procedure over the extended search space yieldsthe array type of PS. The typical \u201cclock\u201d pattern is depicted on Fig. 3. As inthe waterfall case, a number of different transaction patterns were discovered.These mutants differ slightly in the transaction topology, usually adding one ortwo instructions more into the instruction sequence.5 DiscussionConvergence. Computation-wise, the evolutionary algorithm for a population ofsize 100 with other parameters kept default [21] can easily find profitable PSs ofWaterfall type in less than 200 iterations. In order to discover the Array-type,the algorithm had to be extended with an adaptive mutation chance parame-ter to avoid getting trapped in local optima5 of the Waterfall-type. Moreover,the maximum depth parameter, required to ensure termination of the recursivegrammar defined above, is increased due to the higher complexity of the scheme.Extending to Other Types of Ponzi Schemes. Other types of PS can be exploredsimilarly. For instance, to include a PS spread mechanism as those observedin social systems [20], a simple network spread model [13] can be imple-mented, extending the grammar accordingly. Participants to the scheme hasto be rewarded by how many new members they have recruited. Adding to thegrammar a query-method that returns the number of new contract participantsrecruited by an agent would be sufficient in terms of predictors. However, a mech-anism that motivates the individual agent to recruit new participants would alsoneed to be present.Detection supported by generation Without loss of generality, assume we use acertain neural network to decide whether a certain behaviour is compliant ornot. This detection model can be trained on labelled data records of a givensocio-economic system, and then tested also on labelled data obtained via thesimulation environment. The training dataset can be subsequently extended bygenerated instances of non-compliant behaviour to enhance the performance ofthe classifier, mitigating the issue of unbalanced datasets as motivated in theintroduction. Note that these instances can correspond to previously unobserved5 See the source code: https://github.com/fratric/Ponzi-Scheme-Discovery.118 P. Fratri\u010d et al.types of non-compliant behaviour. More interestingly, since the noncompliantagents are assumed to be capable to adapt, the detection model can be also usedto incentivize the discovery of new schemes, producing co-evolutionary adver-sarial dynamics (see e.g. [15]).Beyond Grammatical Evolution. Grammatical evolution can be challenging touse for more complex applications, both regarding the computational complex-ity and the representation by a context-free grammar. In systems consisting ofseveral transactional sub-systems, where a variety of transaction operations canoccur, the search space represented by a context-free grammar would be too largeto be explored using evolutionary operators. In such case, the search algorithmassociated with the noncompliant agent (or a group of agents) would require amore sophisticated type of reasoning, e.g. bringing some context into the gram-mar, such that the noncompliant agent(s) are capable to plan ahead dependingon the environment and the actions of other agents, thus allowing modularizationof the search space. Moreover, the behaviour of the noncompliant agent oughtnot to be deterministic, which is also important for generation of rich syntheticdata. However, this challenge is similar to planning and cooperation in complex,diverse and stochastic environments which remain still open questions.6 ConclusionsOur present research deals with exploration of non-compliant behaviours in thecontext of policy-making. The paper sketched a general computational frame-work to generate instances of transaction-based financial crime and illustrated itsapplication on a well known case of smart contract Ponzi schemes. It was demon-strated that with only a modest set of assumptions it is possible to generate asequence of transaction graphs that captures the functional and modular aspectsof two well-known types of Ponzi schemes, that differ in their dynamic topologydefining the redistribution of capital. We argue that the lines of research revis-ited in this paper are relatively unexplored and deserve much more attention, asthey have the potential to successfully address certain important issues presentin the contemporary research on fraud detection. However, more examples offraud generated in simulation environment needs to be provided before creatinga sound basis for deployment into real socio-economical systems.References1. Aggarwal, C.C.: An introduction to outlier analysis. In: Outlier Analysis, pp. 1\u201334.Springer, Cham (2017). https://doi.org/10.1007/978-3-319-47578-3_12. Ahmed, M., Naser Mahmood, A., Hu, J.: A survey of network anomaly detectiontechniques. J. Netw. Comput. Appl. 60, 19\u201331 (2016)3. Al-Hashedi, K.G., Magalingam, P.: Financial fraud detection applying data miningtechniques: A comprehensive review from 2009 to 2019. Comput. Sci. Rev. 40,100402 (2021)Computational Discovery of Transaction-Based Financial Crime 1194. Bao, Y., Hilary, G., Ke, B.: Artificial intelligence and fraud detection. SSRN Elec-tron. J. 7(2), 223\u2013247 (2020)5. Bartoletti, M., Carta, S., Cimoli, T., Saia, R.: Dissecting Ponzi schemes onEthereum: identification, analysis, and impact. Futur. Gener. Comput. Syst. 102,259\u2013277 (2020)6. Brito, J., Campos, P., Leite, R.: An agent-based model for detection in economicnetworks. In: Bajo, J., et al. (eds.) PAAMS 2018. CCIS, vol. 887, pp. 105\u2013115.Springer, Cham (2018). https://doi.org/10.1007/978-3-319-94779-2_107. Caminero, G., Lopez-Martin, M., Carro, B.: Adversarial environment reinforcementlearning algorithm for intrusion detection. Comput. Netw. 159, 96\u2013109 (2019)8. Chen, W., Zheng, Z., Cui, J., Ngai, E., Zheng, P., Zhou, Y.: Detecting PonziSchemes on Ethereum. In: Proceedings of the 2018 World Wide Web Conferenceon World Wide Web - WWW 2018, New York, New York, USA, pp. 1409\u20131418.ACM Press (2018)9. Chen, W., Zheng, Z., Ngai, E.C., Zheng, P., Zhou, Y.: Exploiting blockchain datato detect smart Ponzi schemes on Ethereum. IEEE Access 7, 37575\u201337586 (2019)10. Cho, J.H., Chan, K., Adali, S.: A survey on trust modeling. ACM Comput. Surv.(CSUR) 48(2), 1\u201340 (2015)11. D\u2019Amour, A., Srinivasan, H., Atwood, J., Baljekar, P., Sculley, D., Halpern, Y.:Fairness is not static. In: Proceedings of the 2020 Conference on Fairness, Account-ability, and Transparency, New York, NY, USA, pp. 525\u2013534. ACM (2020)12. Delecourt, S., Guo, L.: Building a robust mobile payment fraud detection sys-tem with adversarial examples. In: 2019 IEEE Second International Conferenceon Artificial Intelligence and Knowledge Engineering (AIKE), pp. 103\u2013106. IEEE(2019)13. Fu, P., Zhu, A., Ni, H., Zhao, X., Li, X.: Threshold behaviors of social dynamicsand financial outcomes of Ponzi scheme diffusion in complex networks. Phys. A490, 632\u2013642 (2018)14. Fursov, I., et al.: Adversarial attacks on deep models for financial transactionrecords. In: Proceedings of the 27th ACM SIGKDD Conference on KnowledgeDiscovery & Data Mining, New York, NY, USA, vol. 1, pp. 2868\u20132878. ACM(2021)15. Hemberg, E., Rosen, J., Warner, G., Wijesinghe, S., O\u2019Reilly, U.-M.: Detectingtax evasion: a co-evolutionary approach. Artif. Intell. Law 24(2), 149\u2013182 (2016).https://doi.org/10.1007/s10506-016-9181-616. Kumar, N., Vimal, S., Kayathwal, K., Dhama, G.: Evolutionary adversarial attackson payment systems. In: 2021 20th IEEE International Conference on MachineLearning and Applications (ICMLA), pp. 813\u2013818. IEEE (2021)17. Kurshan, E., Shen, H., Yu, H.: Financial crime & fraud detection using graphcomputing: Application considerations & outlook. In: 2020 Second InternationalConference on Transdisciplinary AI (TransAI), pp. 125\u2013130. IEEE (2020)18. Lopez-Rojas, E.A., Axelsson, S.: A review of computer simulation for fraud detec-tion research in financial datasets. In: 2016 Future Technologies Conference (FTC),pp. 932\u2013935. No. December, IEEE (2016)19. Mead, A., Lewris, T., Prasanth, S., Adams, S., Alonzi, P., Beling, P.: Detectingfraud in adversarial environments: a reinforcement learning approach. In: 2018Systems and Information Engineering Design Symposium (SIEDS), pp. 118\u2013122.IEEE (2018)20. Nash, R., Bouchard, M., Malm, A.: Investing in people: the role of social networksin the diffusion of a large-scale fraud. Soc. Networks 35(4), 686\u2013698 (2013)120 P. Fratri\u010d et al.21. Noorian, F., de Silva, A.M., Leong, P.H.W.: gramEvol: grammatical evolution inR. J. Stat. Softw. 71(1), 1\u201326 (2016)22. Pinyol, I., Sabater-Mir, J.: Computational trust and reputation models for openmulti-agent systems: a review. Artif. Intell. Rev. 40(1), 1\u201325 (2013)23. Pourhabibi, T., Ong, K.L., Kam, B.H., Boo, Y.L.: Fraud detection: a systematicliterature review of graph-based anomaly detection approaches. Decis. SupportSyst. 133, 113303 (2020)24. Utting, M., Legeard, B.: Practical Model-Based Testing: A Tools Approach. Else-vier (2010)25. Zeager, M.F., Sridhar, A., Fogal, N., Adams, S., Brown, D.E., Beling, P.A.: Adver-sarial learning in credit card fraud detection. In: 2017 Systems and InformationEngineering Design Symposium (SIEDS), pp. 112\u2013116. IEEE (2017)Centralized Norm Enforcement inMixed-Motive Multiagent ReinforcementLearningRafael M. Cheang1,2(B) , Anarosa A. F. Brand\u00e3o1 ,and Jaime S. Sichman11 Laborat\u00f3rio de T\u00e9cnicas Inteligentes (LTI), Universidade de S\u00e3o Paulo (USP),S\u00e3o Paulo, Brazil{rafael_cheang,anarosa.brandao,jaime.sichman}@usp.br2 Centro de Ci\u00eancia de Dados (C2D), Universidade de S\u00e3o Paulo (USP), S\u00e3o Paulo,BrazilAbstract. Mixed-motive games comprise a subset of games in which indi-vidual and collective incentives are not entirely aligned. These games arerelevant because they frequently occur in real-world and artificial soci-eties, and their outcome is often bad for the involved parties. Institutionsand norms offer a good solution for governing mixed-motive systems. Still,they are usually incorporated into the system in a distributed fashion, orthey are not able to dynamically adjust to the needs of the environment atrun-time. We propose a way of reaching socially good outcomes in mixed-motive multiagent reinforcement learning settings by enhancing the envi-ronment with a normative system controlled by an external reinforcementlearning agent. By adopting this proposal, we show it is possible to reachsocial welfare in a mixed-motive system of self-interested agents using onlytraditional reinforcement learning agent architectures.Keywords: Mixed-motive games \u00b7 Centralized norm enforcement \u00b7Multiagent reinforcement learning1 IntroductionMixed-motive games, comprise a subset of games in which individual and collec-tive incentives are not entirely aligned. These games describe situations in whichthe combined effects of every individual\u2019s selfishness do not yield a good outcomefor the group, a problem also known as the collective action problem [24]. Twobasic properties define this type of games [8]: a) every individual is incentivizedto socially defect and b) all individuals are better off if all cooperate than if alldefect.Olson develops the notion of a collective action problem starting from theraison d\u2019etre of organizations [24]. These, as he describes, are groups that serveto further the interests of their members. The problem emerges when the indi-viduals of such groups also have antagonistic incentives to those common to thecollective. Individuals, in this case, are left to choose between harming the orga-nization as whole in favor of their own benefit, or to pass on the opportunityc\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 121\u2013133, 2022.https://doi.org/10.1007/978-3-031-20845-4_8122 R. M. Cheang et al.for bigger gains in favor of the group. A collective action problem happens whenthe former is systematically preferred over the latter.Global warming is a real-world case of the collective action problem. In it,most players\u2014be it an individual, institution, or government\u2014have an incentiveto emit as much greenhouse gases as desired\u2014for matters of comfort, financialgains, or popularity\u2014, regardless of how much others are emitting. If collectiveemissions surpass some threshold to these ends, the system increasingly dips intoan undesirable state that is bad for all involved.It has been noted that real-world communities are capable of circumventingthis problem with varying success, conditioned on variables such as group size,the existence of a communication channel, etc. [25,26]. These are tied and serveto strengthen the idea of social norms; a guide of conduct, or the expectationindividuals hold of others in certain situations [22].Social norms and norm enforcement mechanisms can be a useful tool in guid-ing groups of people out of social dilemmas [17], but they can also be incorpo-rated into multiagent systems (MAS) [5,6]. This institutional machinery providesways of governing mixed-motive games either via centralized solutions\u2014when acentral governing body is tasked with running the institutional apparatus byitself\u2014or decentralized solutions\u2014when the normative system is conducted bythe agents in the system.Decentralized norm-enforcement approaches have been used to deal withdegrading system properties in MASs [9,15], such as the collective action prob-lem. However, these decentralized solutions either imply a) pro-social behaviorfrom the agents or b) some form of direct or indirect retaliatory capacity\u2014e.g.having the choice not to cooperate in future interactions\u2014that is at least similarin intensity to the harm caused by the aggressor. We acknowledge the effective-ness of these solutions in some cases but also recognize they are no panacea.For instance, how can one\u2014agent or group of agents\u2014successfully drive acomplex MAS towards social order [5] from within without assuming anythingabout others\u2019 beliefs, intentions, or goals, and given that punishing uncompliantbehavior is not desirable or allowed? This problem is akin to many situationsin modern society; thus far is impossible to know the beliefs and intentions ofevery person we might interact with, and not every problem we face is ideallysolvable by a \u201ctaking matters into own hands\u201d approach.Consider as an example the problem with burglary. We\u2014as society\u2014don\u2019texpect social norms and good moral values to completely solve the problem\u2014although they certainly change the rate to which it happens\u2014and when a bur-glary does happen, we don\u2019t expect the victim to return the favor with a responseof similar intensity\u2014like stealing from the aggressor\u2019s house.A similar issue may also occur in MASs. Consider a system of self-drivingautonomous vehicles. Every vehicle in it might have an incentive to get to itsdestination as fast as possible. Suppose that, to this end, a vehicle engages incareless maneuvers and risky overtakes to gain a few extra seconds, harmingothers\u2014safety and/or performance\u2014close to it in the process. Could we safelyassume agents in this system are pro-social to the degree that such a situationwould never happen?Centralized Norm Enforcement in Mixed-Motive MARL 123This might not always be a good premise. In this example, the system itselfis embedded in a competitive environment of firms fiercely fighting for marketshare. Performance, in the form of getting to the final destination faster, mightrepresent getting a bigger slice of the pie. Does the designer behind the agenthave the right incentives to design pro-social agents? Social defection for the sakeof financial gains is not unthinkable by any means in the automobile industry1.Now, suppose that an uncompliant behavior has been identified by anothervehicle close by. Could any form of punishment by the latter be accomplishedwithout compromising the safety of passengers riding in both vehicles? Further-more, even if we agree on the safety to reciprocate, there are many situationswhere direct retaliation might be undesirable. For instance, how do we addressfairness in these systems? If highly interconnected, even a small violation couldbe met with a huge wave of public bashing, similar to the problem of internetcancel culture2.In case it is not safe to assume other agents will cooperate and it is notdesirable that agents directly or indirectly punish each other, we may need toresort to centralized governance of some kind. Jones and Sergot (1994) proposetwo complementary models of centralized norm enforcement [16]:1. Regimentation: Assumes agents can be controlled by some external entity,therefore non-compliant behavior does not occur.2. Regulation: Assumes agents can violate norms, and violations may be sanc-tioned when detected.A drawback of the former is that it constrains agents\u2019 autonomy [22]. Fur-thermore, implementing a regimentation system is not necessarily trivial; edgecases may arise such that violations may still occur [16]. On the other hand, thelatter preserves\u2014to some degree\u2014agents\u2019 autonomy by allowing their actions toviolate norms.This work proposes a way out of the collective action problem in mixed-motive multiagent reinforcement learning (MARL) environments through cen-tralized regulation. The proposal involves enhancing regular mixed-motive envi-ronments with a normative system, controlled by a reinforcement learning (RL)agent playing the role of a regulator; able to set norms and sanctions of thesystem according to the ADICO grammar of institutions [7]. The primary aimof this proposal is to solve the collective action problem in mixed-motive MARLenvironments given two assumptions:1. We have no prior knowledge about the agents\u2019 architectures, thus it\u2019s impos-sible to predict their incentives and behaviors.2. It\u2019s not desirable for agents in the system to punish each other.1 https://www.bbc.com/news/business-34324772.2 https://nypost.com/article/what-is-cancel-culture-breaking-down-the-toxic-online-trend/.124 R. M. Cheang et al.We also show that, by employing this method, social control can be achievedusing only off-the-shelf, traditional RL agent architectures3,4.2 Related WorkMany studies have addressed the collective action problem in mixed-motiveMARL environments [9,15,18,20,27]. Still, most of them have tackled this prob-lem from an agent-centric perspective; their solutions involve modifying an RLarchitecture to the specific needs of multiagent mixed-motive environments. Thishas been accomplished in different ways, such as allowing agents to have pro-social intrinsic motivation [15,20,27], coupling agents with a reciprocity mecha-nism [9,18], and deploying agents with a normative reasoning engine [23].This very same problem\u2014and others\u2014has also been addressed in MASsthrough the adoption of electronic institutions (EI) [10,11], which specifiesamong other definitions, a set of rules that determines what the agents in thesystem ought to do or not under predefined circumstances, similar to the roletraditional institutions play [1]. Likewise, the autonomic electronic institution(AEI) is also a framework that can be used to govern MASs and may be bettersuited to cope with the dynamism of complex systems of self-adapting agentsdue to its autonomic capabilities (norm-setting at run-time) [1,2].Our work here presented is similar to the AEI framework in the sense that italso proposes to overcome a system-level problem by dynamically regulating thesystem\u2019s norms at run-time. Still, it differs from such framework by leveragingin a single agent the learning capabilities RL together with the normative con-cepts spread across a broad literature. Our work also broadly resembles the AIEconomist framework proposed by Zhen et al. [33], that allows for the training ofRL social planners, that learn optimal tax policies in a multiagent environmentof adaptable economic actors by observing and optimizing for macro-propertiesof the system (productivity and equality).In summary, to the best of our knowledge, none of the studies cited abovehave: a) proposed a centralized norm enforcement solution to mixed-motiveMARL environments using another RL agent as a central governing author-ity, and b) proposed a solution that uses only traditional RL architectures whenpeer retaliation is not allowed.3 Normative Systems and the ADICO Grammar ofInstitutionsOne way of preventing MASs from falling into social disorder [5] is to augmentthe system with a normative qualifier. Thus, a normative system can be simply3 By traditional RL agent architectures we mean commonly used in other RL taskssuch as A2C [21].4 All relevant code and data for this project is available at https://github.com/rafacheang/social_dilemmas_regulation.Centralized Norm Enforcement in Mixed-Motive MARL 125defined as one in which norms and normative concepts interfere with its outcomes[22]. In these settings, despite not having an unified definition, a norm can begenerally described as a behavioral expectation the majority of individuals in agroup hold of others in the same group in certain situations [31].In normative systems, norms that are not complied with might be subjectto being sanctioned. Sanctions can be generally classified into direct materialsanctions, that have an immediate negative effect on a resource the agent cherish,such as a fine, or indirect social sanctions, such as a lowering effect on the agent\u2019sreputation, that can influence its future within the system [4]. Nardin [22] alsodescribes a third type of sanction; psychological sactions are those inflicted byan agent to himself as a function of the agent\u2019s internal emotional state.The ADICO grammar of institutions [7] provides a framework under whichnorms can be conceived and operationalized. The ADICO grammar is definedwithin five dimensions:\u2013 Attributes: is the set of variables that defines to whom the institutional state-ment is applied.\u2013 Deontic: is a holder from the three modal operations from deontic logic: may(permitted), must (obliged), and must not (forbidden). These are used todistinguish prescriptive from nonprescriptive statements.\u2013 Aim: describes a particular action or set of actions to which the deonticoperator is assigned.\u2013 Conditions: defines the context\u2014when, where, how, etc.\u2014an action isobliged, permitted or forbidden.\u2013 Or else: defines the sanctions imposed for not following the normExample 1. The norm All Brazilian citizens, 18 years of age or older, mustvote in a presidential candidate every four years, or else he/she will be unableto renew his/her passport as per defined in the ADICO grammar, can be brokendown into: A: Brazilian citizens, 18 years of age or older, D: must, I: vote in apresidential candidate, C: every four years, O: will be unable to renew his/herpassport.4 Reinforcement Learning (RL)4.1 Single-Agent Reinforcement LearningThe reinforcement learning task mathematically formalizes the path of an agentinteracting with an environment, receiving feedback\u2014positive or negative\u2014forits actions, and learning from them. This formalization is accomplished throughthe Markov decision process (MDP), defined by the tuple \u3008S,A,R,P, \u03b3\u3009 whereS denotes a finite set of environment states; A, a finite set of agent actions; R,a reward function R : S \u00d7 A \u00d7 S \u2192 R that defines the immediate\u2014possiblystochastic\u2014reward an agent gets for taking action a \u2208 A in state s \u2208 S, andtransitioning to state s\u2032 \u2208 S thereafter; P, a transition function P : S \u00d7A\u00d7S \u2192[0, 1] that defines the probability of transitioning to state s\u2032 \u2208 S after taking126 R. M. Cheang et al.action a \u2208 A in state s \u2208 S; and finally, \u03b3 \u2208 [0, 1], a discount factor of futurerewards [29].In these settings, the agent\u2019s goal is to maximize its long-term expectedreward Gt, given by the infinite sum E[rt+1 + \u03b3rt+2 + \u03b32rt+3 + ... + \u03b3nrt+n+1].Solving an MDP ideally means finding an optimal policy \u03c0\u2217 : S \u2192 A, i.e., amapping that yields the best action to be taken at each state [29].4.2 Multi-Agent Reinforcement Learning (MARL)One critical difference between RL and MARL is that, instead of the environmenttransitioning to a new state as a function of a single action, it does so as a functionof the combined efforts of all agents.The MDP counterpart in MARL is the Markov Game (MG) [19] also knownas Stochastic Game, and it is defined by a tuple \u3008N ,S, {Ai}i\u2208N , {Ri}i\u2208N ,P, \u03b3\u3009,where N = {1, ..., N} denotes the set of N > 1 agents, S, a finite set of environ-ment states, Ai, agent\u2019s i set of possible actions. Let A = A1 \u00d7 ... \u00d7 AN be theset of agents\u2019 possible joint actions. Then Ri denotes agent\u2019s i reward functionRi : S\u00d7A\u00d7S \u2192 R that defines the immediate reward earned by agent i given atransition from state s \u2208 S to state s\u2032 \u2208 S after a combination of actions a \u2208 A;P, a transition function P : S \u00d7 A \u00d7 S \u2192 [0, 1] that defines the probabilityof transitioning from state s \u2208 S to state s\u2032 \u2208 S after a combination of actionsa \u2208 A; and \u03b3 \u2208 [0, 1], a discount factor on agents future rewards [32].5 Centralized Norm Enforcement in MARLHere, we propose a norm-enhanced Markov Game (neMG) for governing mixed-motive MGs by making use of an RL regulator agent and some added norma-tive concepts. The proposal builds upon regular mixed-motive MGs. It involvesenhancing the environment\u2019s states with the ADICO information introduced inSect. 3. The regulator is then able operate within this new ADICO information,which is also available for other agents in the game and can be considered fordecision-making.The method comprises two types of RL agents: N > 1 players and oneregulator. Players are simple RL agents, analogous to the ones that interactwith regular versions of MARL environments. These agents could be modeledas average self-interested RL agents with off-the-shelf architectures such as A2C[21]\u2014which facilitates the engineering side.The regulator, in turn, is able to operate on the environment\u2019s norms repre-sented by the ADICO five dimensions; it can modify one or more dimensions atevery period\u2014a period consists of m time steps, m being a predefined integervalue. This agent senses the state of the environment through a social metric\u2014i.e. a system-level diagnostic\u2014and the efficacy of its actions is signaled back bythe environment based on the social outcome of past institutions. The regulatorcan also be modeled as a self-interested agent with off-the-shelf RL architectures.Centralized Norm Enforcement in Mixed-Motive MARL 127Definition 1. A norm-enhanced Markov Game (neMG) can be formallydefined by a 11-tuple \u3008Np,Sp, {Aip}i\u2208Np , {Rip}i\u2208Np ,Pp, \u03b3p,Sr,Ar,Rr,Pr, \u03b3r\u3009,with Np,Sp,Aip,Rip,Pp, \u03b3p being the players\u2019 original MG as per defined inSect. 4.2. Sr, denotes the regulator\u2019s set of states; Ar, the regulator\u2019s set ofactions; Rr, the regulator\u2019s reward function Rr : Sr \u00d7Ar \u00d7Sr \u2192 R that deter-mines the immediate reward earned by the regulator following a transition fromstate sr \u2208 Sr to s\u2032r \u2208 Sr after an action a \u2208 Ar; Pr, the regulator\u2019s transitionfunction Pr : Sr \u00d7 Ar \u00d7 Sr \u2192 [0, 1] that defines the environment\u2019s probabilityof transitioning from state sr \u2208 Sr to state s\u2032r \u2208 Sr after an action ar \u2208 Ar; and\u03b3r \u2208 [0, 1], the regulator\u2019s discount factor.In these settings, a neMG could be run following two RL loops; an outer onerelative to the regulator, and an inner one relative to the players. Algorithm1exemplifies how these could be implemented.Algorithm 1: neMG Pseudocodealgorithm parameters: number of players n, steps per period m;initialize policy and/or value function parameters;foreach episode doinitialize environment (set initial states sr0 and sp0);foreach period doregulator sets norm by consulting its policy \u03c0r in state sr;for m/n doforeach player doplayer acts based on its policy \u03c0p in state sp, state transitions tos\u2032p, player observes its reward rp, and updates its policy \u03c0p;end foreachend forregulator observes next state s\u2032r, its reward rr and updates its policy \u03c0r;end foreachend foreach6 Tragedy of the Commons ExperimentThe method was tested on a mixed-motive environment that emulates thetragedy of the commons problem described by Hardin (1968) [14]. The tragedyof the commons describes a situation wherein a group of people shares a commonresource that replenishes at a given rate. Every person has the own interest toconsume the resource as much as possible, but if the consumption rate consis-tently exceeds the replenishment rate, the common soon depletes.128 R. M. Cheang et al.6.1 A neMG of a Tragedy of the Commons EnvironmentThe environment built closely resembles that of Ghorbani et al. (2021) [12] andwas built using both the OpenAI gym [3] and pettingzoo [30] frameworks. Anepisode begins with an initial quantity R0 of the common resource. Every n simu-lation steps\u2014n being the number of agents; five for this simulation\u2014the resourcegrows by a quantity given by the logistic function \u0394R = rR(1 \u2212 RK ), with \u0394Rbeing the amount to increase; r, the growth rate; R, the current resource quan-tity; and K, the environment\u2019s carrying capacity\u2014an upper bound to resources.For this experiment, r was set to 0.3, R0 is sampled from a uniform distributionU(10000, 30000), and K was set to 50000.The environment also encodes the ADICO variables as described in Sect. 5.The A, D, and I dimensions remain fixed for this experiment since a) the normapplies to all players, b) the norm always defines a forbidden action, and c)players have only one action to choose from\u2014they can only decide how much ofthe resource to consume and their rewards are proportional to their consumption.The C and O dimensions, on the other hand, may be changed by the regulatoragent; i.e., every 100 steps the regulator may change how much of the resourcea player is allowed to consume (l)\u2014sampled at the beginning of each episodefrom a normal distribution N(375, 93.75)\u2014and the fine applied to those whoviolate this condition (f(c, l, \u03bb))\u2014by setting the value of \u03bb, which is sampled atthe beginning of each episode from a normal distribution N(1, 0.2). Thus theADICO information that enhances this environment is made up of:\u2013 A: all players;\u2013 D: forbidden;\u2013 I: consume resources;\u2013 C: when consumption is greater than li;\u2013 O: pay a fine of f = (ci \u2212 li)\u00d7 (\u03bb+1), with ci being the agent\u2019s consumptionin step i; li the consumption limit in step i; and \u03bb, a fine multiplier.The fine is subtracted from the violator\u2019s consumption in the same step thenorm is violated.Before a new institution is set, the regulator can evaluate the system-levelstate of the environment by observing how much of the resource is left, and ashort-term and long-term sustainability measurement, given by S =\u2211tj=t\u2212prpjcjdefined for cj > 0 and p \u2265 0, with p being the number of periods considered asshort-term and long-term\u2014respectively one and four for this simulation \u2014; rpj ,the total amount of resources replenished in period j; cj , the total consumptionin period j; and t, the current period. At the end of the period, the success ofpast norms is feed-backed to the regulator by the environment as a reward valuedirectly proportional to the last period\u2019s total consumption.At every simulation step, players in the environment can observe Ri, li, and\u03bbi, and can choose how much of the resource to consume. An agent\u2019s consumptionmay vary from 0 to cmax, where cmax is a consumption limit that represents aphysical limit in an analogous real-world scenario. Here, this value was set to1500. An episode ends after 1000 simulation steps or when resources are depleted.Centralized Norm Enforcement in Mixed-Motive MARL 129Agents in this simulation were built using traditional RL architectures\u2014SAC[13] for the regulator and A2C [21] for the players\u2014using the Stable Baselines3 framework [28], and players were trained on a shared policy. The learningrates for all agents were set to 0.00039. A summary with all environment relatedvariables used in this experiment and their values is presented in Table 1.Table 1. Summary of the variables used in the experiment, their abbreviations, andvalues.Variable name Description Valuen Number of players 5m Number of steps in a period 100R0 Initial quantity of common resource U(10000, 30000)R Current quantity of common resource varK Environment\u2019s carrying capacity (resources upper bound) 50000r Resources growth rate 0.3\u0394R Replenishment amount at a single step varl Norm-set consumption limit varc Single player consumption var\u03bb Norm-set fine multiplier varS Sustainability metric varp Number of periods considered for calculating S 1, 4c Player(s) consumption varcmax Players max consumption (hard limit) 1500rp Period\u2019s total replenishment var6.2 Results and DiscussionFigure 1 shows the average total consumption per episode over a 10 simulationrun with and without the regulator agent acting on the environment. As pre-dicted by the Nash equilibrium, we notice there isn\u2019t much hope for generalizedcooperation in case selfish agents are left playing the game by themselves\u2014i.e.resources quickly deplete in the beginning of each episode.Conversely, this is not the case when the regulator is put in place. After ashort period of randomness at the beginning of the simulation, players learn notto consume from the resource since they frequently get punished when doing so.Around episode 300, players progressively learn to consume around as much ofthe resource as the set limit and the regulator increasingly learns to adjust suchlimit so as to keep resources at a sustainable level. A comparison between anepisode at the beginning of a simulation and one at the end is shown in Fig. 2.Every once in a while, the regulator overshoots by setting too big of a limitat the beginning of the episode and players quickly deplete the resource. Thisexplains in parts the total consumption variation depicted in Fig. 1.130 R. M. Cheang et al.Fig. 1. The total consumption per episode average over a 10 simulation run for thetragedy of the commons experiment. The green line shows the total consumption forwhen the regulator is active and the blue line for when it is inactive. The green shadedarea covers the region one standard deviation above and below the mean for the sim-ulation with the active regulator. (Color figure online)Fig. 2. Time step consumption vs. consumption limit set by the regulator at an earlierepisode a) and at a later episode b). The orange line shows the resource level at all timesteps and the dotted red line shows the resource level in which the replenishment rateis greatest (25000). In a) players and the regulator act somewhat randomly and, for thisreason, resources are kept at a sustainable range but consumption is sub-optimal. Playersin b) learn to approximate their consumption to the norm-set consumption limit and theregulator learns to decrease such limit at times when resources are lower and increase itwhen resources are higher. Resources in this episode are still kept at a sustainable rangeand consumption sharply increases in comparison to a). (Color figure online)Centralized Norm Enforcement in Mixed-Motive MARL 131Note the system gets relatively close to an upper consumption benchmark bythe end of the simulation\u2014when agents\u2019 combined consumption equals the maxi-mum replenishment in every iteration. We can calculate this value by multiplyingthe maximum replenishment (3750) by the maximum count of replenishmentsin a given episode (200). In this case, the value is 750000 units of resource.7 ConclusionDelegating norm enforcement to an external central authority might seemcounter-intuitive at first, as we tend to associate distributed solutions withrobustness. It also might seem to go against the findings of Elinor Ostrom [25,26],who showed that the collective action problem could be solved without the needof a regulatory central authority and for that, won the nobel prize in economicsin 20095.That being said, central regulation is still an important mechanism to governcomplex systems. Many of the world\u2019s modern social and political systems use itin some form or shape. With this work, we try to show that central regulation isalso a tool that could be useful in governing MAS and MARL, especially whenit is not desirable for actors in the system to punish each other.Still, centralized norm enforcement brings about many other challenges thatare not present in decentralized norm enforcement. For instance, if poorlydesigned (purposefully or not) the regulator himself, through the impositionnorms and sanctions, may drive the system to socially bad outcomes. Whatif the designer behind the regulator does not have the good incentives? Con-straints as such must be taken into consideration when judging the applicabilityof centralized norm enforcement in MASs.As further work, we plan to test this very same method in other mixed-motiveMARL environments.Acknowledgements. This research is being carried out with the support of Ita\u00faUnibanco S.A., through the scholarship program of Programa de Bolsas Ita\u00fa (PBI),and it is also financed in part by the Coordena\u00e7\u00e3o de Aperfei\u00e7oamento de Pessoal deN\u00edvel Superior (CAPES), Finance Code 001, Brazil.References1. Bou, E., L\u00f3pez-S\u00e1nchez, M., Rodr\u00edguez-Aguilar, J.A., Sichman, J.S.: Adaptingautonomic electronic institutions to heterogeneous agent societies. In: Vouros, G.,Artikis, A., Stathis, K., Pitt, J. (eds.) OAMAS 2008. LNCS (LNAI), vol. 5368, pp.18\u201335. Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-642-02377-4_22. Bou, E., L\u00f3pez-S\u00e1nchez, M., Rodr\u00edguez-Aguilar, J.A.: Towards self-configurationin autonomic electronic institutions. In: Noriega, P., V\u00e1zquez-Salceda, J., Boella,G., Boissier, O., Dignum, V., Fornara, N., Matson, E. (eds.) COIN 2006. LNCS(LNAI), vol. 4386, pp. 229\u2013244. Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-74459-7_155 https://www.nobelprize.org/prizes/economic-sciences/2009/ostrom/facts/.132 R. M. Cheang et al.3. Brockman, G., et al.: OpenAI Gym. arXiv preprint arXiv:1606.01540 (2016)4. Cardoso, H.L., Oliveira, E.: Adaptive deterrence sanctions in a normative frame-work. In: Proceedings of the 2009 IEEE/WIC/ACM International Joint Conferenceon Web Intelligence and Intelligent Agent Technology, pp. 36\u201343. IEEE ComputerSociety (2009)5. Castelfranchi, C.: Engineering social order. In: Omicini, A., Tolksdorf, R., Zam-bonelli, F. (eds.) ESAW 2000. LNCS (LNAI), vol. 1972, pp. 1\u201318. Springer, Hei-delberg (2000). https://doi.org/10.1007/3-540-44539-0_16. Conte, R.: Emergent (info)institutions. Cogn. Syst. Res. 2(2), 97\u2013110 (2001).https://doi.org/10.1016/S1389-0417(01)00020-17. Crawford, S.E.S., Ostrom, E.: A grammar of institutions. Am. Polit. Sci. Rev.89(3), 582\u2013600 (1995). https://doi.org/10.2307/20829758. Dawes, R.M.: Social dilemmas. Annu. Rev. Psychol. 31(1), 169\u2013193 (1980).https://doi.org/10.1146/annurev.ps.31.020180.0011259. Eccles, T., Hughes, E., Kram\u00e1r, J., Wheelwright, S., Leibo, J.Z.: Learning reci-procity in complex sequential social dilemmas (2019)10. Esteva, M., de la Cruz, D., Rosell, B., Arcos, J.L., Rodr\u00edguez-Aguilar, J., Cun\u00ed, G.:Engineering open multi-agent systems as electronic institutions. In: Proceedings ofthe 19th National Conference on Artificial Intelligence, AAAI 2004, pp. 1010\u20131011.AAAI Press (01 2004)11. Esteva, M., Rodr\u00edguez-Aguilar, J.-A., Sierra, C., Garcia, P., Arcos, J.L.: On the for-mal specification of electronic institutions. In: Dignum, F., Sierra, C. (eds.) AgentMediated Electronic Commerce. LNCS (LNAI), vol. 1991, pp. 126\u2013147. Springer,Heidelberg (2001). https://doi.org/10.1007/3-540-44682-6_812. Ghorbani, A., Ho, P., Bravo, G.: Institutional form versus function in a commonproperty context: the credibility thesis tested through an agent-based model. LandUse Policy 102, 105237 (2021). https://doi.org/10.1016/j.landusepol.2020.105237.https://www.sciencedirect.com/science/article/pii/S026483772032575813. Haarnoja, T., Zhou, A., Abbeel, P., Levine, S.: Soft actor-critic: off-policy max-imum entropy deep reinforcement learning with a stochastic actor. In: Dy, J.,Krause, A. (eds.) Proceedings of the 35th International Conference on MachineLearning. Proceedings of Machine Learning Research, vol. 80, pp. 1861\u20131870.PMLR, 10\u201315 July 2018. https://proceedings.mlr.press/v80/haarnoja18b.html14. Hardin, G.: The tragedy of the commons. Science 162(3859), 1243\u20131248 (1968).https://doi.org/10.1126/science.162.3859.1243. https://science.sciencemag.org/content/162/3859/124315. Hughes, E., et al.: Inequity aversion improves cooperation in intertemporal socialdilemmas. In: Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi,N., Garnett, R. (eds.) Advances in Neural Information Processing Systems, vol.31. Curran Associates, Inc. (2018). https://proceedings.neurips.cc/paper/2018/file/7fea637fd6d02b8f0adf6f7dc36aed93-Paper.pdf16. Jones, A.J.I., Sergot, M.: On the characterization of law and computer systems:the normative systems perspective, pp. 275\u2013307. Wiley, Chichester (1994)17. Kollock, P.: Social dilemmas: the anatomy of cooperation. Annu. Rev. Sociol. 24(1),183\u2013214 (1998). https://doi.org/10.1146/annurev.soc.24.1.18318. Lerer, A., Peysakhovich, A.: Maintaining cooperation in complex social dilemmasusing deep reinforcement learning (2018)19. Littman, M.L.: Markov games as a framework for multi-agent reinforcement learn-ing. In: Proceedings of the Eleventh International Conference on InternationalConference on Machine Learning, ICML 1994, pp. 157\u2013163. Morgan KaufmannPublishers Inc., San Francisco (1994)Centralized Norm Enforcement in Mixed-Motive MARL 13320. McKee, K.R., Gemp, I., McWilliams, B., Du\u00e8\u00f1ez Guzm\u00e1n, E.A., Hughes, E., Leibo,J.Z.: Social diversity and social preferences in mixed-motive reinforcement learning.In: Proceedings of the 19th International Conference on Autonomous Agents andMultiAgent Systems, AAMAS 2020, pp. 869\u2013877. International Foundation forAutonomous Agents and Multiagent Systems, Richland (2020)21. Mnih, V., et al.: Asynchronous methods for deep reinforcement learning. In: Balcan,M.F., Weinberger, K.Q. (eds.) Proceedings of The 33rd International Conferenceon Machine Learning. Proceedings of Machine Learning Research, vol. 48, pp.1928\u20131937. PMLR, New York, 20\u201322 June 2016. https://proceedings.mlr.press/v48/mniha16.html22. Nardin, L.G.: An adaptive sanctioning enforcement model for normative multiagentsystems. Ph.D. thesis, Universidade de S\u00e3o Paulo (2015)23. Neufeld, E., Bartocci, E., Ciabattoni, A., Governatori, G.: A normative supervisorfor reinforcement learning agents. In: Platzer, A., Sutcliffe, G. (eds.) CADE 2021.LNCS (LNAI), vol. 12699, pp. 565\u2013576. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-79876-5_3224. Olson, M.: The Logic of Collective Action: Public Goods and the Theory of Groups.Harvard Economic Studies, vol. 124, p. 176. Harvard University Press, Cambridge(1965). https://www.hup.harvard.edu/catalog.php?isbn=978067453751425. Ostrom, E.: Coping with tragedies of the commons. Annu. Rev. Polit. Sci. 2(1),493\u2013535 (1999). https://doi.org/10.1146/annurev.polisci.2.1.49326. Ostrom, E.: Collective action and the evolution of social norms. J. Econ. Perspect.14(3), 137\u2013158 (2000). https://doi.org/10.1257/jep.14.3.13727. P\u00e9rolat, J., Leibo, J.Z., Zambaldi, V., Beattie, C., Tuyls, K., Graepel, T.: A multi-agent reinforcement learning model of common-pool resource appropriation. In:Guyon, I., et al. (eds.) Advances in Neural Information Processing Systems, vol.30. Curran Associates, Inc. (2017). https://proceedings.neurips.cc/paper/2017/file/2b0f658cbffd284984fb11d90254081f-Paper.pdf28. Raffin, A., Hill, A., Gleave, A., Kanervisto, A., Ernestus, M., Dormann, N.: Stable-baselines3: reliable reinforcement learning implementations. J. Mach. Learn. Res.22(268), 1\u20138 (2021). http://jmlr.org/papers/v22/20-1364.html29. Sutton, R.S., Barto, A.G.: Reinforcement Learning: An Introduction, 2nd edn. TheMIT Press, Cambridge (2018)30. Terry, J.K., et al.: PettingZoo: a standard API for multi-agent reinforcementlearning. In: Advances in Neural Information Processing Systems (2021). https://proceedings.neurips.cc//paper/2021/file/7ed2d3454c5eea71148b11d0c25104ff-Paper.pdf31. Ullmann-Margalit, E.: The Emergence of Norms. Oxford University Press, Oxford(1977)32. Zhang, K., Yang, Z., Ba\u015far, T.: Multi-agent reinforcement learning: a selectiveoverview of theories and algorithms. In: Vamvoudakis, K.G., Wan, Y., Lewis, F.L.,Cansever, D. (eds.) Handbook of Reinforcement Learning and Control. SSDC,vol. 325, pp. 321\u2013384. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-60990-0_1233. Zheng, S., et al.: The AI economist: improving equality and productivity withAI-driven tax policies (2020)Supporting the Reasoning AboutEnvironmental Consequencesof Institutional ActionsRafhael R. Cunha1,2(B) , Jomi F. Hu\u0308bner2 , and Maiquel de Brito31 Federal Institute of Education, Science and Technology of Rio Grande do Sul(IFRS), Campus Vacaria, Vacaria, Brazil2 Automation and Systems Department, Federal University of Santa Catarina,Floriano\u0301polis, Brazilrafhael.cunha@posgrad.ufsc.br, jomi.hubner@ufsc.br3 Control, Automation, and Computation Engineering Department,Federal University of Santa Catarina, Blumenau, Brazilmaiquel.b@ufsc.brAbstract. In this paper we are considering multi-agent systems (MAS)with agents that have both goals and anti-goals. Goals represent environ-ment states that agents want to achieve and anti-goals represent environ-ment states they want to avoid. To achieve their goals, agents performsome actions that may have institutional consequences. Which couldpotentially change the environment towards as a counter effect. Sincethese consequences are institutional, they should be explicitly specifiedso that agents are able take them into consideration in their decisionprocess. However, existing models of artificial institutions do not con-sider such consequences. Considering this problem, this paper proposesto extend the institutional specification making explicit the implicationsof the institutional actions in the environment. The proposal is presented,discussed and implemented using the JaCaMo framework, highlightingits advantages for agents while reasoning about the consequences of theiraction both in the institution and the environment.Keywords: Purposes \u00b7 Status-functions \u00b7 Artificial institutions1 IntroductionThe achievement of the goals of an agent may depend on some status assignedto the actions that it performs instead of depending on the actions themselves.Consider a scenario where an agent called sBob has the goal of conquering anew territory. The agent knows from some available guidelines that the goalis achieved by performing a digital action (e.g. sending a message, posting ona webservice) that has the status (or counts as) commanding an attack. Thisaction is supposed to produce in the environment the effects corresponding tosuch status (e.g. destroying buildings, killing opponents, etc.). However, thesec\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 134\u2013147, 2022.https://doi.org/10.1007/978-3-031-20845-4_9Supporting the Reasoning About Environmental Consequences 135effects may not be explicit to the agent. It can choose the action to performbased solely on its status.Inspired by human societies, some works propose models and tools to man-age the assignment of statuses to the elements involved in the Multi-Agent Sys-tem (MAS) [15]. In this paper, the element of the system in charge of managingthe assignment of status is called institution. Through the institution, agentsmay have the status of soldiers, while some of their digital actions may have thestatus of commanding an attack. These works focus on assigning status to theelements that compose the MAS in a process called constitution. However, theydo not address the effects in the environment1 of such statuses. For example, adigital action with the assigned status of commanding an attack can trigger aseries of consequences in the environment such as killing a soldier from alliedbase, killing innocent people, etc. that may be unknown/unwanted to agents andthat would not happen if the action did not have the status.There are some drawbacks of not specifying the consequences in the environ-ment of actions that have a status (see more in [9]). This work focuses on actionswhose status leads to a goal achievement but whose effects in the environmentare undesirable for the agent. For example, consider an institutional specifica-tion stating that sending a broadcast message has the status of commanding anattack. In this case, sBob can use this specification to discover how to achieve itsgoal, i.e., by broadcasting a message. However, if the institutional specificationdoes not express the effects in the environment of commanding an attack, sBobcan not rely on this specification to discover the consequences of broadcastingthe message. If sBob has the principle of not killing a soldier from the alliedbase but commanding an attack can make this consequence possible, sBob mayviolate its principle if not aware of these consequences.Regarding these issues, the main contribution of this paper is a proposal ofa mechanism that allows agents to discover what are the consequences in theenvironment of performing an action that has a status. This proposal is inspiredby the Construction of the social reality by John Searle [22,23] theory that seemsto be fundamental for comprehending the social reality.This paper is organized as follows: Sect. 2 introduces the main backgroundconcepts necessary to understanding our proposal and its position in the litera-ture. It includes philosophical theory and related works. Section 3 presents theproposed model, its definitions and functions and algorithms to use of the model.Section 4 illustrates how the use of artificial institutions and purposes facilitatesthe development of agents capable of reasoning about the implications of statusactions in the environment. Finally, Sect. 5 presents some conclusions about thiswork and suggests future works.1 In this paper, environment refers to the set of physical and digital resources whichthe agents perceive and act upon [26].136 R. R. Cunha et al.2 Artificial InstitutionsThe problem described in the introduction is rooted in the fact that concreteelements of MAS may have statuses that are not necessarily related to theirdesign features. In MAS, these statuses are managed by Artificial Institutions.Artificial Institutions are inspired by John Searle\u2019s theory [22,23], which claimsthat the social reality where human beings are immersed arises from the concreteworld (i.e., the environment) based on some elements, including status-functionsand constitutive rules. Status-functions are status that assign functions to theconcrete elements [22,23]. These functions cannot be explained through theirphysical virtues. For example, the status buyer assigns to an agent some func-tions such as perform payments, take loans, etc. Constitutive rules specify theassignment of status-functions to concrete elements with the following formula:X count-as Y in C. For example, a piece of paper count-as money in a bank,where X represents the concrete element, Y the status-function, and C the con-text where that attribute is valid. The attribution of status-functions throughconstitutive rules to environment elements is called constitution and createsinstitutional facts. The set of institutional facts gives rise to institutions [22].Artificial Institutions (or simply institutions) are the component of the MASthat is responsible for defining the conditions for an agent to become a buyer,or an action to become a payment [22,23].Works on Artificial Institutions are usually inspired by the theory of JohnSearle [22,23]. Some works present functional approaches, relating brute factsto normative states (e.g., a given action counts as a violation of a norm). Theseworks do not address ontological issues, and, therefore, it becomes even moredifficult to support the meaning of abstract concepts present in the institutionalreality. Other works have ontological approaches, where brute facts are relatedto concepts used in the specification of norms (e.g., sending a message counts asa bid in an auction). However, these works have some limitations.Some approaches allow the agents to reason about the constitutive rules [1,6,8,10,11,25]. However, generally the status-function (Y ) is a label assignedto the concrete element (X ) that is used in the specification of the regulativenorms. Therefore, Y does not seem to have any other purpose than to serve as abasis for the specification of stable regulative norms [1,24]. Some exceptions are(i) in [11\u201314] where Y represents a class formed with some properties as rolesresponsible for executing actions, time to execute them, condition for execution,etc.; (ii) in [24] where Y is a general concept, and X is a sub-concept that canbe used to explain Y. Although the exceptions contain more information thanjust a label in the Y element, these data are somehow associated with regulativenorms.In short, existing works in artificial institutions are mainly concerned withspecifying and managing the constitution. However, the constitution is based onfacts occurring in the environment that may even produce further environmentalconsequences. While the constitution is explicit, it is implicit in these works theenvironmental states that can be reached because an action constitutes a status-function. In the previous example, while the constitutive rule specifies how toSupporting the Reasoning About Environmental Consequences 137constitute commanding an attack, the effects in the environment of commandingan attack are not explicit. Some agent cannot rely on the institutional specifica-tion to evaluate the effects in the environment of achieving a goal that dependson the constitution of a status-function. Designers make this association betweenthe constitution of a status-function and its environmental consequences in anad-hoc manner. The main disadvantage of an ad-hoc association is that the agentworks only in scenarios foreseen by the developer.The limitation discussed indicates the need to develop a model that explainsthe purposes of status-functions belonging to institutional reality. Aguilar etal. [21] corroborate this conclusion by stating that institutions have not yetconsidered how to help agents in decision-making, helping them to achieve theirown goals. The modeling of purposes of status-functions, described in the nextsection, is a step to fill this open gap.3 The Purposes of Status-FunctionsThe mentioned issues are associated with the relationship between constitutionsof status-functions and their consequences in the environment. While works onMAS ignore these relations, Searle addresses them under the notion of Pur-pose [22,23]. Functions related to statuses are called agentive functions becausethey are assigned from the practical interests of agents [23, p.20]. These prac-tical interests of agents are called purposes [22, p.58]. Thus, the purposes pointto the consequences in the environment of the constitution of status-functionsthat are aligned with the agents\u2019 interests. For example, someone has a goalof inhabiting a piece of land when he broadcasts a message that institutionallyis considered as commanding an attack. In this example, inhabiting a piece ofland represents a state of the world that is pointed by a purpose. This state isenabled (and will probably happen) when the status-function commanding anattack is constituted. The states must reflect the interest of the agents involvedin that context. Moreover, the agents involved in the interaction should have acommon understanding of these facts and purposes and consider them in theirdeliberation. Otherwise, none of them achieve their social goal2.The essential elements of the proposed model are agents, states, institutions,and purposes, depicted in the Fig. 1. Agents are autonomous entities that pursuetheir goals in the MAS [28]. The literature presents several definitions of goalthat are different but complementary to each other (see more in [3,16\u201318,20,27]).In this work, goals are something that agents aim to achieve (e.g. a certain state,the performance of an action. According to Aydemir, et al. [2], anti-goal is anundesired circumstance of the system. In this work, anti-goal represents statesthat the agent does not wish to reach for ethical reasons, particular values,prohibition by some regulative norm, etc. Moreover, agents can perform actionsthat trigger events in the MAS. If this action produces events that may constitutesome status-function, this action is an institutional action. States are formed by2 In this paper, a social goal is an goal that depends on other agents acting on thesystem.138 R. R. Cunha et al.one or more properties that describe the characteristics of the system at somepoint of its execution [7].StateSystemConstitutive Rule Status-Function Agentgoal1..* 1..*1..*Purposeanti-goal1..*1..*1..*EventactionEnvironmentInstitution1..*1..*1..*1..*Fig. 1. Overview of the model.Institutions provide the social interpretation of the environmental elements ofthe MAS as usually proposed in the literature. This social interpretation occursthrough the interpretation of constitutive rules that assign status to environ-mental elements, as described in Sect. 2. It is beyond the scope of this paper topropose a model of artificial institution. Rather, it considers this general notionof the institution as the entity that constitutes status-functions, that is adoptedby several models in the field of MAS.While agents, states and institutions are known concepts, purposes are intro-duced in this model. The functions associated with status-functions can satisfythe practical interests of agents. From the institution\u2019s perspective, these inter-ests are called Purposes. From the agents\u2019 perspective, these interests are theirgoals or anti-goals. Then, we claim that (i) the goals or anti-goals of the agentsmatch with the purposes of the status-functions and (ii) goals, anti-goals and pur-poses point to environmental states related to the status-functions. For example,in the war scenario, an agent that performs an action that counts as commandingan attack triggers intermediate events that bring the system to states such asconquer a new territory (i.e., the agent goal) or killing a soldier from the alliedbase (i.e., the agent anti-goal). The intermediate events (e.g. shoot someone)between the constitution of the status-functions and the environmental statesreached are ignored in our proposal, since we consider that the agent is onlyinterested in the states that can be reached after the status-functions is consti-tuted.Shortly, this model provides two relationships: (i) between purposes andstatus-functions and (ii) between purposes and agent goals and anti-goals. Thus,if (i) there is a constitutive rule specifying how a status-function is constituted,(ii) a purpose associated with that status-functions, and (iii) an agent that has agoal or anti-goal that matches with the states pointed to by the purpose, then itis explicit how the agent should act to achieve its goal or avoid an anti-goal. Inthe previous example, sBob can know that if it constitutes the status-functioncommanding an attack to satisfy its goal of conquering a new territory, someSupporting the Reasoning About Environmental Consequences 139other states will be reached such as killing a soldier from the allied base, killinginnocent people, which may be undesirable to the agent.3.1 DefinitionsThis section formally3 describes the model by specifying (i) the purposes associ-ated with the status-functions and (ii) the purposes associated with the conse-quences in the environment of constituting status-functions. These consequencesare states of the world that agents want to reach or prefer to avoid. Althoughthe concept of purpose is independent, it is used in conjunction with the states,agents and institutions that make up the MAS.Definitions 1 to 5 represent the MAS states, events, agents, agents goals andanti-goals, and the relationships that exist between these concepts. These defini-tions express the environmental elements that belong to the MAS (expressed inthe Environment rectangle in the Fig. 1). Definitions 6 and 7 are imported fromthe Situated Artificial Institution (SAI) model [5,10] and represent the elementsthat make up the institution and its connection with the environmental elements(expressed in the Institution rectangle in the Fig. 1). The Definitions 8 to 11 rep-resent the purposes and the relationships that exist between them and the institu-tion and between purpose and the states of the world that agents wish to achieveor avoid (expressed in the Purpose rectangle and its relations in the Fig. 1).Definition 1 (States). Properties are characteristics of the system at somepoint of its execution. The set of all properties that the system can presentis represented by T . The state of the system at some point of its executionis the set of all the standing properties. S = 2T is the set of all the possi-ble states of the MAS. For example, the sets s1 = {territory conquered} ands2 = {killed from allied base} define states that exist in the MAS, where s1 \u2208 Sand s2 \u2208 S.Definition 2 (Events). Event is an instantaneous occurrence within the sys-tem [7]. Events may be both triggered by actions of the agents (e.g. sending ofa message) and spontaneously produced by some non autonomous element (e.g.a clock tick). The set of all events that may happen in the system is repre-sented by E. Each event is represented by an identifier. For example, the setE = {broadcast a message} defines the event that can happen in the MAS.Definition 3 (Agents). The set of all agents that can act in the MAS isrepresented by A. Each agent is represented by an identifier. For example, theset A = {sBob} defines the agent that exists in the MAS.3 We formalize the model to make it more accurate and facilitate the development ofalgorithms that can be used to improve the agents\u2019 decision process.140 R. R. Cunha et al.Definition 4 (Relationship between Agents and their goals). In thiswork, agents goals are states of the world that agents desire to reach4. The set ofthe goals of the agents acting in the system is given by G \u2286 A \u00d7 S. For example,the pair \u3008sBob, territory conquered\u3009 \u2208 G means that the agent sBob has the goalterritory conquered.Definition 5 (Relationship between Agents and their anti-goals).Anti-goals are states in the MAS that agents desire to avoid. The set of theanti-goals of the agents is given by G \u2286 A \u00d7 S. For example, the pair\u3008sBob, soldier killedfrom allied base\u3009 \u2208 G means that the agent sBob has theanti-goal \u201csoldier killed from allied base\u201d. From a general point of view, there is nodifference between an anti-goal and the denial of a goal (the negation of a goal).However, to avoid the addition of negated goals in the model, we opted to haveexplicit anti-goals. The intersection between agent goal and anti-goal should beempty (G \u2229 G = \u2205).Definition 6 (Status-Functions). A status is an identifier that assigns to theenvironmental elements an accepted position, especially in a social group. It allowsthe environmental elements to perform functions (associated with the status) thatcannot be explained through its physical structure [22, p.07]. For simplicity, in thisformalization we only consider statuses assigned to events. The set of all the event-status-functions of an institution is represented by F . For example, the set f ={command an attack} defines a status that exists in the MAS, where f \u2286 F .Definition 7 (Constitutive rules). Constitutive rules specify the constitutionof status-functions from environmental elements. Searle proposes to express theserules as X count-as Y in C, explained in Sect. 2. Since the process of constitutionis beyond the scope of this paper, the element C can be ignored. For simplicity, aconstitutive rule is hereinafter expressed as X count-as Y. The set of all constitutiverules of an institution is represented by C. A constitutive rule c \u2286 C is a tuple \u3008x, y\u3009,where x \u2208 E and y \u2208 F , meaning that x count-as y. For example, the set c ={\u3008broadcast a message, command an attack \u3009} defines a constitutive rule relatedto the scenario.Definition 8 (Purposes). The purposes are related to the agents\u2019 practicalinterests. We assume that the set of all purposes is represented by P. Each pur-pose is represented by an identifier. For example, the set P = {new territory},define the unique purpose that exists in the MAS.Definition 9 (Relationship between status-functions and purposes).Wedefine that purposes can be satisfied through the constitution of status-functions.Thus, there must be a relationship between these two concepts. This relation is rep-resented by FP \u2286 F \u00d7P. For example, {\u3008command an attack, new territory\u3009} \u22084 We focus on declarative goals (i.e., goals that describe desirable situations) becausewe are interested in the effects of the constitution of status-functions that may evenproduce further environmental consequences (i.e., new states of the world). Thereare some other types of goals (e.g. procedural goal) that focus on the execution ofthe action and therefore are not compatible with the concept of purpose.Supporting the Reasoning About Environmental Consequences 141FP means that the constitution of the status-function command an attack satisfiesthe purpose new territory.Definition 10 (Relationship between purposes and agent\u2019s goals andanti-goals). The relationship between purpose and agent goal and anti-goal con-siders that a purpose point to one or more states in the MAS that matches theagents goals and anti-goals. The relationship GP is a tuple \u3008p, agag\u3009 where p \u2208 Pand agag \u2208 2G\u222aG. For example, the set GP = {\u3008new territory, {territory conque-red}, {soldier killed from allied base}\u3009} defines the relation that exists betweenthe purpose and the states of the world that it points that match with agents\u2019 goalor anti-goal.Definition 11 (Model). The model is a tuple \u3008S, E ,A,AGA,F , C,P,FP ,GP \u3009,where S is the set of states that may be maintained in the MAS, E is the set ofevents happen that may happen in the MAS, A is the set of agents that can actin the MAS, AGA is the set of goals and anti-goals of agents (i.e., AGA = G\u222aG),F is the set of status-functions, C is the set of constitutive-rules that may existsin the MAS, P is the set of purposes, FP is set that expresses the relationshipbetween the F and P sets and GP is the set that represents the relationshipbetween P and AGA.3.2 Functions and AlgorithmsIn this section we formalize some functions that can be used by an agent to discoverthe environmental effects of performing an institutional action. For that, we needthe status-functions related to the events produced by an action (Definition 14),the purposes of these status-functions (Definition 12), and the states of these pur-poses (Definition 13). In the example of this paper, sBob knows by doing broadcastamessage that it satisfies its goal.With the proposed functions, it can discover thatthis action has other consequences (e.g., someone being killed) which are amongits anti-goals. It may thus avoid that action to achieve its goal.Definition 12 (Mapping status-functions to purposes). Given a set Fof status-functions and a set P of purposes, the set of purposes that are enabledwhen a status-function is constituted is given by the function fp : F \u2192 2P s.t.fp(f) = {p | \u3008f, p\u3009 \u2208 FP }.For example, if FP = {\u3008command an attack, new territory\u3009}, thenfp(command an attack) = {new territory}.Definition 13 (Mapping purposes to states). Given a set P of purposesand a set AGA (AGA = G \u222a G) of agents goals and anti-goals, the set of agentsgoals and anti-goals that are pointed by a purpose is given by the function fsw :P \u2192 2AGA s.t. fsw(p) = {aga | \u3008p, aga\u3009 \u2208 GP }.For example, if GP = {\u3008new territory, {territory conquered}, {soldierkilled from allied base}\u3009}, then fsw(new territory) = {{territoryconquered}, {soldier killed from allied base}}.142 R. R. Cunha et al.Definition 14 (Mapping events to status-functions). Given a set F ofstatus-functions and a set of events E, the status-functions that are constitutedby an event are given by the function fc : E \u2192 2F s.t. fc(e) = {f | \u3008e, f\u3009 \u2208 C}.For example, if C = {\u3008broadcast a message, command an attack \u3009}, thenfc(broadcast a message) = {command an attack}.Definition 15 (Mapping status-functions to events). Given a set F ofstatus-functions and a set of events E, the events that constitute the status-functions are given by the function fca : F \u2192 2E s.t. fca(f) = {e | \u3008e, f\u3009 \u2208 C}.For example, if C = {\u3008broadcast a message, command an attack \u3009}, thenfca(command an attack) = {broadcast a message}.From these functions, the Algorithm1 can be used by the agent to find outwhich are the environmental effects if some action is executed in an institutionalcontext. The algorithm can be summarized in some steps: (1) verify whether theaction is an institutional action, i.e., it its events constitutes something in theinstitution (lines 4 and 5), if true, go to the next step, otherwise returns theempty set (line 12); (2) consider all status-functions related to the action (line6); (3) consider all purposes of such status-functions (line 7); and (4) for eachpurpose, looks for the states it points to and add them in the answer of thealgorithm.Algorithm 1. Find the effects of an action in the environment1: Input: an action ac2: Output: the set of possible states after ac3: s \u2190 {}4: e \u2190 event produced by action ac5: if fc(e) \u0003= {} then \u0002 if the event e may constitute a status-functions6: for f \u2208 fc(e) do \u0002 f is the set of status-functions that e count-as7: for p \u2208 fp(f) do \u0002 p is the set of purposes that are associated with f8: s \u2190 s \u222a fsw(p) \u0002 add states pointed to by p9: end for10: end for11: end if12: return sTo verify if some action can produce some state considered as an anti-goal,we developed Algorithm 2. To illustrate it, in the case of sBob considering theaction broadcast a message to achieve some goal, the execution of the algorithmfor this action returns true, meaning that the action can also produce effectsconsidered as an anti-goal.Supporting the Reasoning About Environmental Consequences 143Algorithm 2. Verifies whether some action can produce states considered asanti-goals.1: Input: G, ac2: Output: returns true if ac implies anti-goals and false otherwse3: se \u2190 algorithm 1(ac) \u0002 se is the set of states pointed to by ac4: return \u2203ag\u2208G ag \u2208 se \u0002 checks whether anti goals are included in se4 Implementing the Purpose ModelTo illustrate the use of this model, we recall the example introduced at the begin-ning of this paper: the scenario where sBob desires to reach its goal of territoryconquered. To this end, sBob knows that to achieve territory conquered, it needsto perform an (institutional) action that count-as commanding an attack. Fromthe constitutive rule \u2014 broadcast a message count-as commanding an attack \u2014it knows that it needs to broadcast a message to achieve its goal. The purposemodel it is possible to specify that the status-function commanding an attackis associated with the purpose new territory, which, on its turn, is associatedwith a state with the following properties: territory conquered and soldier killedfrom the allied base. Thus, sBob is now able to reason about the consequencesof performing the action broadcast a message in the institutional context. Suchan institution could include other status-functions but, for simplicity, we focusonly on those essential to illustrate the main features of the model proposed inSect. 3.The example is implemented through the components depicted in Fig. 2. Theagent sBob is programmed in Jason [4] and the environment in CArtAgO [19].To implement the artificial institution, we use an implementation of the SituatedArtificial Institution model (SAI) model [10]. It provides means to specify status-functions and constitutive rules and to manage the constitution process. Thepurpose model is implemented through an ontology encapsulated in a CArtAgOartifact which is accessible to the agents. The query and persistence of datain the ontology are enabled by the MasOntology5, a set of tools developed inCArtAgO to interact with ontologies6.Figure 3 depicts the agent program. Line 1 specifies an anti-goal of sBob. sBobgoal can be achieved by the plan illustrated in lines 3\u201311. This plan creates sub-goals alg1 and alg2 that can be achieved by plans in lines 13\u201322, which arethe Jason implementation of Algorithms 1 and 2. Regarding the plan for alg1,if the Action does not constitute a status-function, the States are empty (line17). Otherwise, some operations are used to retrieve the list of States relatedto the action in lines 14 and 15. Regarding the plan for alg2, it simply gets thelist of states from alg1 and tests if some anti-goal is member of this list. Theresult is unified with variable R. The value of R is then used to decide whether to5 https://github.com/smart-pucrs/MasOntology.6 An initial implementation of this platform can be found in https://github.com/rafhaelrc/psf model.144 R. R. Cunha et al.Fig. 2. Component diagram with the systems used to compose the example.Fig. 3. Plan of the agent sBob.execute broadcasting a message, if R is false it means that the action doesnot promote some of the agent anti-goals.The code snippet depicted in Fig. 3 illustrates how the algorithms and themodel proposed in this work can be used by the agent to check if the action to beperformed can constitute a status-functions and enable new states in the systemand verify if these new states are unwanted by the agent. We can notice thatthe code from lines 6 to 11 are just an example of how the proposed model andalgorithms can be used. Of course, more complex solutions could be developedfor other applications.5 Conclusions and Future WorkThe problem motivating this paper is some difficulty for agents to reason aboutthe consequences in the environment when performing an action that has aninstitutional interpretation (i.e., it has a status-function). To help agents withthis issue, we introduce the notion of purpose in artificial institutions. Pur-poses connect two concepts: status-functions in the institutional side and goalsand anti-goals in the agent side. While status-functions represent how the envi-ronment changes the institution, purposes represent how the institution canSupporting the Reasoning About Environmental Consequences 145potentially change the environment. From an agent perspective, their goals andanti-goals are also considered in the proposal: purposes point to states of theworld that are of interest to the agents. Thus, the model connects institutionalfacts with the interests of the agents.The main advantage of purposes in MAS regards the agents. We have animprovement in agent decision-making, since it has more information availableto help it to decide whether to achieve its goals or avoid its anti-goals. Withthe proposed model, agents can access and reason about the consequences ofinstitutional actions and adapt themselves to different scenarios. They can noticethat (a) some purposes point to states that are similar to their interests andtherefore useful to reach their goals or (b) avoid these purposes because theypoint to states that are similar to their anti-goals. In both cases, the agent hasmore information while deciding whether a particular action will help it or not.This kind of reasoning is important for advances in agents autonomy [21].As future work, we plan to explore additional theoretical aspects related tothe proposal, such as (i) investigations about how other proposed institutionalabstractions (e.g. social functions) fit on the model, and (ii) check if the purposesrelated to status must be further detailed. We plan to also address more practicalpoints such as (i) the modeling of a status-functions purposes based on a realscenario, (ii) the implementation of the proposal in a computer system (iii)its integration in an computational model that implements the constitution ofstatus-functions in an MAS platform and (iv) evaluate the application of themodel in scenarios that involve ethical reasoning of agents.Acknowledgments. This study was supported by the Federal Institute of Education,Science and Technology of Rio Grande do Sul (IFRS). We thank the reviewers for thevaluable contributions that allowed this work to evolve.References1. Aldewereld, H., A\u0301lvarez-Napagao, S., Dignum, F., Va\u0301zquez-Salceda, J.: Mak-ing norms concrete. In: Proceedings of the 9th International Conference onAutonomous Agents and Multiagent Systems: volume 1, vol. 1, pp. 807\u2013814. Inter-national Foundation for Autonomous Agents and Multiagent Systems (2010)2. Aydemir, F.B., Giorgini, P., Mylopoulos, J.: Multi-objective risk analysis with goalmodels. In: 2016 IEEE Tenth International Conference on Research Challenges inInformation Science (RCIS), pp. 1\u201310. IEEE (2016)3. Boissier, O., Bordini, R.H., Hubner, J., Ricci, A.: Multi-Agent Oriented Program-ming: Programming Multi-agent Systems Using JaCaMo. MIT Press, Cambridge(2020)4. Bordini, R.H., Hu\u0308bner, J.F., Wooldridge, M.: Programming Multi-Agent Systemsin AgentSpeak Using Jason, vol. 8. Wiley, Hoboken (2007)5. de Brito, M., et al.: A model of institucional reality supporting the regulation inartificial institutions. Ph.D. thesis, Universidade Federal de Santa Catarina (2016)6. Cardoso, H.L., Oliveira, E.: Institutional reality and norms: specifying and moni-toring agent organizations. Int. J. Coop. Inf. Syst. 16(01), 67\u201395 (2007). https://doi.org/10.1142/s0218843007001573146 R. R. Cunha et al.7. Cassandras, C.G., Lafortune, S.: Introduction to Discrete Event Systems. Springer,New York (2008). https://doi.org/10.1007/978-0-387-68612-78. Cliffe, O., De Vos, M., Padget, J.: Specifying and reasoning about multiple institu-tions. In: Noriega, P., et al. (eds.) COIN 2006. LNCS (LNAI), vol. 4386, pp. 67\u201385.Springer, Heidelberg (2007). https://doi.org/10.1007/978-3-540-74459-7 59. Cunha, R.R., Hu\u0308bner, J.F., de Brito, M.: Coupling purposes with status-functionsin artificial institutions. arXiv preprint arXiv:2105.00090 (2021)10. De Brito, M., Hu\u0308bner, J.F., Boissier, O.: Situated artificial institutions: stability,consistency, and flexibility in the regulation of agent societies. Auton. Agents Multi-Agent Syst. 32(2), 219\u2013251 (2018)11. Fornara, N.: Specifying and monitoring obligations in open multiagent systemsusing semantic web technology. In: Elc\u0327i, A., Kone\u0301, M.T., Orgun, M.A. (eds.)Semantic agent systems. SCI, vol. 344, pp. 25\u201345. Springer, Heidelberg (2011).https://doi.org/10.1007/978-3-642-18308-9 212. Fornara, N., Colombetti, M.: Ontology and time evolution of obligations and prohi-bitions using semantic web technology. In: Baldoni, M., Bentahar, J., van Riems-dijk, M.B., Lloyd, J. (eds.) DALT 2009. LNCS (LNAI), vol. 5948, pp. 101\u2013118.Springer, Heidelberg (2010). https://doi.org/10.1007/978-3-642-11355-0 713. Fornara, N., Colombetti, M.: Representation and monitoring of commitments andnorms using owl. AI Commun. 23(4), 341\u2013356 (2010)14. Fornara, N., Tampitsikas, C.: Using OWL artificial institutions for dynamicallycreating open spaces of interaction. In: AT, pp. 281\u2013295 (2012)15. Fornara, N., Vigano\u0300, F., Colombetti, M.: Agent communication and artificial insti-tutions. Auton. Agents Multi-Agent Syst. 14(2), 121\u2013142 (2007). https://doi.org/10.1007/s10458-006-0017-816. Hindriks, K.V., de Boer, F.S., van der Hoek, W., Meyer, J.-J.C.: Agent program-ming with declarative goals. In: Castelfranchi, C., Lespe\u0301rance, Y. (eds.) ATAL2000. LNCS (LNAI), vol. 1986, pp. 228\u2013243. Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-44631-1 1617. Hu\u0308bner, J.F., Bordini, R.H., Wooldridge, M.: Declarative goal patterns for AgentS-peak. In: Proceedings of the Fifth International Joint Conference on AutonomousAgents and Multiagent Systems (AAMAS 2006) (2006)18. Nigam, V., Leite, J.: A dynamic logic programming based system for agentswith declarative goals. In: Baldoni, M., Endriss, U. (eds.) DALT 2006. LNCS(LNAI), vol. 4327, pp. 174\u2013190. Springer, Heidelberg (2006). https://doi.org/10.1007/11961536 1219. Ricci, A., Piunti, M., Viroli, M.: Environment programming in multi-agent systems:an artifact-based perspective. Auton. Agents Multi-Agent Syst. 23(2), 158\u2013192(2011)20. van Riemsdijk, B., van der Hoek, W., Meyer, J.J.C.: Agent programming in dribble:from beliefs to goals using plans. In: Proceedings of the Second International JointConference on Autonomous Agents and Multiagent Systems, pp. 393\u2013400 (2003)21. Rodriguez-Aguilar, J.A., Sierra, C., Arcos, J.L., Lopez-Sanchez, M., Rodriguez, I.:Towards next generation coordination infrastructures. Knowle. Eng. Rev. 30(4),435\u2013453 (2015). https://doi.org/10.1017/S026988891500009022. Searle, J.: Making the Social World: The Structure of Human Civilization. OxfordUniversity Press, Oxford (2010)23. Searle, J.R.: The Construction of Social Reality. Simon and Schuster, New York(1995)Supporting the Reasoning About Environmental Consequences 14724. Va\u0301zquez-Salceda, J., Aldewereld, H., Grossi, D., Dignum, F.: From human reg-ulations to regulated software agents\u2019 behavior. Artif. Intell. Law 16(1), 73\u201387(2008)25. Vigano, F., Colombetti, M.: Model checking norms and sanctions in institutions. In:International Workshop on Coordination, Organizations, Institutions, and Normsin Agent Systems pp. 316\u2013329 (2007)26. Weyns, D., Omicini, A., Odell, J.: Environment as a first class abstraction in mul-tiagent systems. Auton. Agents Multi-Agent Syst. 14(1), 5\u201330 (2007)27. Winikoff, M., Padgham, L., Harland, J., Thangarajah, J.: Declarative and proce-dural goals in intelligent agent systems. In: International Conference on Principlesof Knowledge Representation and Reasoning. Morgan Kaufman (2002)28. Wooldridge, M.: An Introduction to Multiagent Systems. Wiley, Chichester (2009)Social Motives and Social Contractsin Cooperative Survival GamesMatthew Scott1 , Mathieu Dubied1,2 , and Jeremy Pitt1(B)1 Imperial College London, London SW7 2BX, UK{mss2518,md1721,jpitt}@ic.ac.uk2 ETH Zu\u0308rich, 8092 Zu\u0308rich, SwitzerlandAbstract. Cooperative survival games are a sub-class of resource com-petition games wherein self-interest appears to be the rational choicein the short-term, but if every \u2018player\u2019 always acts out of self-interest,extinction is guaranteed in the long-term. The situation is dramatisedin the film The Platform (El Hoyo); in this paper, we implement a self-organising multi-agent system that approximately recreates the coop-erative survival game depicted in this film. In a series of experiments,we investigate how communication, a pre-existing tendency to sociality(characterised by social motives) and a capacity for social construction(characterised by social contracts) enables a collective of random indi-viduals to establish a stable institution that increases their overall lifeexpectancy. The experimental results provide some insight into how apro-social personality and the ability to bootstrap institutions enable arandom collective to find a psychologically and sociologically plausiblesolution to what is effectively a cooperative survival game merged withRawl\u2019s Veil of Ignorance.Keywords: Multi-agent system \u00b7 Social contracts \u00b7 Collective action1 IntroductionCooperative survival games are a sub-class of iterative resource competitiongames wherein self-interest appears to be the rational choice in the short-term,but if every \u2018player\u2019 always acts out of self-interest, elimination or extinctionis inevitable in the long-term. The players need to maintain a critical massthat can gather sufficient resources to survive this iteration to ensure that thereare sufficient players to survive the next iteration. Dropping below a certainthreshold means that \u201cif one is lost, all are lost\u201d.Cooperative survival games are a popular form of entertainment in low- orzero-stakes entertainment, as seen in board games (e.g. Ravine) and computergames (e.g. Don\u2019t Starve, Rust and Minecraft), and have been analysed exten-sively in anthropological studies of collective behaviour in extreme environmen-tal conditions [3,12]. Addressing anthropogenic climate change can be seen as aSupported by Imperial College London and the Swiss Study Foundation.c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 148\u2013166, 2022.https://doi.org/10.1007/978-3-031-20845-4_10Social Motives and Social Contracts in Cooperative Survival Games 149high-stakes cooperative survival game on a planetary scale with nation states asthe players.Ostrom has shown how collectives have solved the common-pool resourcemanagement (CPR) problem by using self-governing institutions [15], i.e. setsof mutable, mutually-agreed conventional rules which the members voluntarilyregulate their behaviour. Considering a cooperative survival games as a form ofextreme, high-stakes CPR problem where any one individual maximising self-interest or free-riding is an existential hazard to all, this paper addresses thequestion of how to bootstrap the formation of such an institution from a start-ing position of complete ignorance. In this initial situation, the players have noknowledge of the other players, and there are no rules, no social network, and noexternal authority. The players only have their personal psychological character-istics (which we call social motives) and an ability for the social construction [2]of social contracts (which we call treaties).Accordingly, this paper is structured as follows. In Sect. 2, we first presenta scenario, which is based on the film The Platform (El Hoyo), and relatedwork that provides the background to the multi-agent simulator developed inSect. 3, and the social motives for agents specified in Sect. 4. Section 5 presentsthe experimental results which show how communication, a pre-existing ten-dency to sociality (characterised by social motives) and a capacity for socialconstruction (characterised by social contracts or treaties) enables a collectiveof random individuals to establish a stable institution that increases their overalllife expectancy. Finally, Sect. 6 concludes with some observations on how pro-social behaviour and the ability to bootstrap institutions enable a collective tofind a psychologically and sociologically plausible solution to what is effectivelya cooperative survival game merged with Rawl\u2019s Veil of Ignorance [18].2 Scenario and Related WorkFor this paper, we consider the social dilemma presented the 2019 film \u2018ThePlatform\u2019 (El Hoyo). This film envisions a tower consisting of N floors with apair of prisoners on each floor.A platform laden with food descends through a central shaft in the tower,starting from floor 1, at the very top, and stopping at consecutive floors. Theprisoners are allowed to eat as much as they want while the platform has stoppedon their floor, but cannot save food \u201cfor later\u201d. At the beginning of each day,the platform is replenished with food and descends again, always starting at thetop of the tower.Obviously it is advantageous to be on a low-numbered (upper) floor to havefirst access to the food on the platform; however there is a \u2018reshuffle\u2019 after Ddays, with all the agents are randomly re-assigned to new floors, and with noknowledge of which floor they will be re-assigned. When an agent dies due to thelack of food, it is replaced by a new agent. The exact rules that our simulatorfollows to replace the agents are introduced in Sect. 3.It has been shown that by taking an approach inspired by moral philosophythere are solutions to the social contract design problem [5]. This means that, for150 M. Scott et al.any non-cooperative game, it is theoretically feasible to define a social contractwhich produces a modified game that optimises for a moral imperative. In ourpaper, we distance ourself from the game-theoretic setting used in [5], and ratherfocus on the effects of specific social contracts in our scenario.Ostrom\u2019s work, as previously mentioned [15], provides empirical evidence thatit is practically possible for groups of people to resolve collective action situationsthrough the social construction of self-governing institutions. Effectively, this isidentifying the institutions, understood as a set of rules, as the social contract,and sustainability of the common-pool resource as the moral imperative.The studied setting of this paper can be classified as an iterative game ofRawl\u2019s Veil of Ignorance [18]. Rawls\u2019 Veil of Ignorance is a thought experimentintended to expose the principles, preferences and thought processes that informthe structure of a society. The experiment imagines asking someone, that ifthey started from a blank slate and no knowledge beforehand of their eventualposition in a society, what sort social structures, form of governance, etc., wouldbe selected for such a society. The thought experiment is in many ways analogousto the situation presented in the platform: if the players have no idea beforehandto which tower level they will be assigned, then what sort of principles wouldthey prefer to manage access to the food on the platform.The question addressed in this paper is under what conditions is it practi-cally possible for groups of agents to resolve a collective action situation, specif-ically that posed by The Platform scenario. In this scenario, we presume thatthe motivation for creating a social contract comes from an abstraction of thepsychological concept of social motives [14,19], which Folmer describes as \u201cthepsychological processes that drive people\u2019s thinking, feeling and behavior in inter-actions with other people.\u201d Social motives are further identified as a potentialsource of conflict, with Folmer also claiming that \u201cthe actions that are dictatedby one individual\u2019s motives are incompatible with, or even harmful to, the inter-ests of others,\u201d creating what is termed a \u2018social dilemma.\u2019 In other words, thesocial contract must not only solve this social dilemma, but must also resolveany residual tension between potentially conflicting social motives.Although, without loss of generality, we make some modifications to thescenario from the film \u2013 for example, we assume one prisoner per floor ratherthan a pair (although that is only required for dramatic effect), no movementbetween floors, and direct communication allowed between adjacent floors only(although a message may be propagated along multiple floors, assuming thatthe prisoners are willing to cooperate). We are assuming strict constraints ofno prior knowledge, no pre-existing social network and no external authority,with the additional complications of a dynamic population, where \u2018new\u2019 prison-ers are \u2018injected\u2019 into the tower after death, and periodic floor re-assignment.The challenge is then to determine whether, despite the combination of limitedcommunication and varied social motives, a propensity for social constructionenables the agents to \u2018find\u2019 a social contract which is a solution to the currentformulation of the game and perpetuates across subsequent re-formulations.Social Motives and Social Contracts in Cooperative Survival Games 1513 Simulator DesignTo simulate The Platform, we implement a self-organising, multi-agent system.This system consists of a set of agents connected by a social network; each link inthe social network is associated with a weight. The social network is iterativelyconstructed by proximity on adjacent levels of the tower through a predefinedcommunication language (not further discussed here). These agents are storedinside a \u2018tower\u2019 data structure which acts a server, handling agent interactionsover the network and containing the setup parameters for the simulation.External to the basic representation of agents in the tower, we further repre-sent the infrastructure of the simulator by modelling the agents\u2019 health, globalutility, and treaties.3.1 Health ModellingAll agents have a health value that exists on a continuous spectrum with threeadditional discrete levels of criticalLevel, weakLevel and maxHP. An agent is con-sidered to have critical health if it falls between the criticalLevel, the minimumpossible health, and weakLevel, the cutoff for the critical region. An agent processis terminated if they remain in this region for N days, equal to maxDaysCritical.An agent\u2019s health is updated through two mechanisms: agents eating food(appropriating resources), which causes a positive change, and the cost of living,which causes a negative change.Mathematically, the mapping between food intake and health is parame-terised as follows:newHP = currentHP + w(1 \u2212 e\u2212foodTaken\u03c4 ) (1)with \u03c4 offered as a tuning parameter to either increase or decrease the magnitudeof health change from one unit of food and w a variable to represent the widthof the gap between the weakLevel and maxHP. This function is chosen similarlyto a step response function to replicate \u2018diminishing returns\u2019 and prevent rapidchanges in health. An agent in the critical region has a slightly different updatefunction:newHP = currentHP + min{HPReqCToW , w(1 \u2212 e\u2212foodTaken\u03c4 )}(2)to ensure that a critical agent must first transition to weak, before applyingEq. (1). Hence, HPReqCToW represents the change in health required to tran-sition from the critical region to the weak level.To offset an agent\u2019s health gain, its health will also decay at the end of eachday according to the equation:newHP = currentHP \u2212 [b + s(currentHP \u2212 WeakLevel)] (3)where b and s are parameters that are set constant for all the simulations of thispaper. The agent\u2019s health is subsequently bounded to the range [criticalLevel,maxHP ]. We note that critical agents are affected differently by health decay. Ifan agent is unable to achieve HPReqCToW, they will be reset to the criticalLevel.Conversely, if they do appropriate this food, they will be reset to the weakLevel.152 M. Scott et al.3.2 Global UtilityTo assess the performance of the agents in the tower as a group, we investigatetheir social welfare, based on each agent\u2019s individual utility [16].In this scenario, each agent i \u2208 {1, . . . , N} carries out four actions at each iter-ation t \u2208 {1, . . . ,\u221e}: it first determines the resources it has on the platform (gi),then its need for resources (qi). After this, it receives an allocation of resources (ri)from the treaties it has formed and finally makes an appropriation of resources (r\u2032i).Since agents are programmed to be honest, we assert that r\u2032i = ri.The need for resources qi, looks to reward agents who take food only whennecessary. Hence:qi =numberDaysInCriticalStatemaxDaysInCriticalState(4)The total resources accrued at the end of an iteration, Ri, is then defined as:Ri = r\u2032i + gi (5)which gives the utility per agent:ui ={\u03b1iqi + \u03b2i(Ri \u2212 qi) if Ri \u2265 qi\u03b1iRi \u2212 \u03b3i(qi \u2212 Ri) else(6)where \u03b1i, \u03b2i and \u03b3i are tuning parameters that follow the rule \u03b1i > \u03b3i > \u03b2i. Inour work, we use the values \u03b1i = \u03b1 = 0.2, \u03b2i = \u03b2 = 0.1, and \u03b3i = \u03b3 = 0.18.Finally, we use (6) to compute an average global utility, which correspondsto the social welfare SW divided by the number of agents:U =\u2211Ni uiN=SWN(7)3.3 TreatiesTo successfully handle treaties, an agent must be able to propose, evaluate, andpropagate treaties. In addition, we enforce the agents act honestly, and thereforecomply with the treaties to which they agree. This section aims to describe thegeneral structure of treaties, whereas the actions related to the treaties (proposal,acceptance, etc.) are described in Sect. 4.3.Treaties are codified as data structures with three main parts: a condition,a request concerning the amount of food to be \u201ctaken\u201d or \u201cleft\u201d and a dura-tion. Whilst the condition for the validity of the treaty can be any variable,for this paper only the health of the agent is concerned. One such example ofa treaty is: \u201cif currentHP \u2265 60, take \u2264 5 food for 5 days.\u201d. They serve as anextension of message passing, wherein a treaty is proposed verbally either 1 floorabove or below the floor of the proposer. Such proposals happen asynchronouslyin the tower and are implemented with concurrent channels, meaning that allagents can send treaties simultaneously. When a treaty is proposed, it enters thereceiver\u2019s \u2018inbox\u2019 to be processed.Social Motives and Social Contracts in Cooperative Survival Games 153Table 1. Parameters held in the Treaty data structure.Parameter RangeCondition HPConditionValue intRequest [Leave, Take]RequestValue intConditionOp [>,\u2265,=,\u2264, <]RequestOp [>,\u2265,=,\u2264, <]SignatureCount intDuration intTreatyID UUIDProposerID UUIDAn agent may compile a treaty with newTreaty(t1, t2, . . . tn), which packagesthe different treaty parameters, ti, into the data structure discussed in Table 1 tobe subsequently sent as a proposal to an agent. Upon agreeing with a treaty, bothagents involved will place this data into their respective activeTreaties arrays.The treaties in this array are then processed iteratively to find constraints onthe agents\u2019 consumption.4 Agent DesignThe N agents in the tower forms a group of agents we name A. Each agenti \u2208 A are implemented as a data structure with parameterisation to participatein the various communication methods c \u2208 C, resulting in a set of interactionsdefined by I = <A,C>. Each agent inherits from the baseAgent structure andalso contains the fields contained in Table 2. We note only the most relevantfields for quantifying the agent have been included.Table 2. The Config (left) and Agent (right) data structures.Parameter RangeBaseBehaviour int \u2208 [0,10]Stubbornness float \u2208 [0,1]MaxBehaviourSwing int \u2208 [0,10]ParamWeights { HPW :int, FW :int }FloorDiscount float \u2208 [0,1]MaxBehaviour int = 10Parameter RangeConfig config{}CurrBehaviour intMaxFloorGuess intAverageFoodIntake intShortTermMemory [int]LongTermMemory [int]ActiveTreaties [Treaty]4.1 Social MotivesSocial Motives Spectrum. The agent\u2019s behaviour revolves around the conceptof social motives [14], which Folmer defines as \u201cthe psychological processes that154 M. Scott et al.drive people\u2019s thinking, feeling and behavior in interactions with other people\u201d[19]. This in turn leads to a \u201cmixed-motive\u201d setting [20] in the tower. From thisconcept, we abstract 4 distinct social motives:Altruist: The disinterested and selfless concern for the well-being of others.An altruist then acts in a way that purely benefits others, even if it meansharming themselves.Collectivist: The practice or principle of giving a group priority over eachindividual in it. A collectivist then acts in a way that benefits the group, them-selves included, over purely the individual.Selfish: Being concerned excessively or exclusively with oneself. A selfishagent will act in a way to satisfy themselves, but not necessarily with the intentto harm the other agents.Narcissist: An excessive interest or admiration of oneself. A narcissistic agentwill act in a way that not only benefits themselves, but also hinders the collective.For this implementation, we assert that all agents\u2019 social motives can bedefined on a spectrum, with one end corresponding to pure altruism, and theother to pure narcissism, which we codify as a continuous value between 0.0 and10.0 respectively. Figure 1 illustrates the spectrum of social motives.NarcissistSelfishCollectivistAltruistbaseBehaviourmaxBehaviourSwingnextBehaviourPrediction = w\u0002pbehaviourUpdatescaledUpdatenewBehaviour012345678910Fig. 1. Illustration of a change in social motive.Changing Social Motives. This paper proposes that it is both limiting andunrealistic for an agent to express one social motive for its entire lifespan. Forthis reason, agents are able to dynamically update their initially assigned socialmotive to reflect the duality of \u201cnature vs nurture\u201d [11]: an agent\u2019s genotypedoes not necessarily match the agent\u2019s phenotype.To codify this idea, we use a \u2018predictor\u2019 that calculates a behaviourUpdatefrom the feature transformations of the 1) current health of the agent (8) and 2)floor that the agent is located on (9). These feature transformations map theirSocial Motives and Social Contracts in Cooperative Survival Games 155respective features to a range [0, 1], with poorer performances (low health, lowfloor) tending towards 1 to represent a skew towards narcissistic behaviour:hpScore = 1 \u2212 currentHPmaxHP(8)Agents forecast the maxFloor by keeping track of the lowest floor they havevisited. The lower down the floor, the faster Eq. (9) tends to 1. This is to havethe agents tend towards narcissism faster as they reach lower floors. We take \u03bbas the floorDiscount variable from Table 2 to \u2018tune\u2019 the function.floorScore =e\u03bb\u00b7currentFloormaxFloore\u03bb(9)The predictor then weights these feature transformations with the \u2018HPweight,\u2019 HPW and \u2018floor weight,\u2019 FW variables from Table 2 to yield a value inthe range [0, 10]:p = [hpScore,floorScore]\u0005, w = [HPW ,FW ]\u0005nextBehaviourPrediction = w\u0005p(10)and we construct a vector illustrating the change in social motive as:behaviourUpdate = nextBehaviourPrediction \u2212 currentBehaviour (11)This paper further asserts that agents are unlikely to rapidly change theirsocial motive, instead requiring multiple similar experiences to alter their pheno-type. We hence offer a concept of stubbornness, which limits the vectorial changein behaviourUpdate:scaledUpdate = behaviourUpdate \u00b7 (1 \u2212 stubbornness) (12)newBehaviour = currentBehaviour + scaledUpdate (13)With the new social motive defined as the movement from the currentbehaviour using the scaledUpdate vector. Finally, we propose that a genotyp-ically altruistic agent, say, is unlikely to make a severe transition in personalityto full narcissism. This is solved by introducing a maxBehaviourSwing, whichbounds the total change in social motive that an agent can experience.Agents are also able to dynamically update the weights in Eq. (10) in orderto make more permanent shifts towards narcissism if one of the parameters isconstantly evaluated poorly. If the agent\u2019s health is below 20, we increase HPWby 0.05 and decrease FW by 0.05. Alternatively, if the agent\u2019s average foodintake is less than 1 per turn, we decrease HPW by 0.1 and increase FW by 0.1.After this update, we ensure that the weights remain in the range [0, 1].4.2 Food ConsumptionResources are conditionally appropriated depending on both the social motiveand environmental factors such as commitments to messages and treaties. Thebaseline behaviours exhibited by the different social motives are as follows:156 M. Scott et al.Altruist: An altruistic agent always takes 0 food, as it is only concerned forthe well-being of others with a total disregard for itself.Collectivist: A collectivist agent consume the food required to survive, andconsumes no food when not in danger of dying. To codify this, agents randomlychoose a day in the range [1, maxDaysCritical ] and take food once they haveremained at critical health for this period. This has the effect of staggering whencollectivists are able to take food, to prevent the entire tower simultaneouslydepleting resources.Selfish: A selfish agent always aims to stay at the healthyLevel. This meansthat it will always appropriate the food required to reach this point.Narcissist: A narcissistic agent takes maximum amount of food consumable,since it is purely be concerned for its own well-being whilst sabotaging the others.4.3 Handling TreatiesEvaluating Treaties. It is through the agents interacting with one anotherthat a social network is formed. Agents use techniques from risk assessment,forecasting and utility theory to handle the acceptance or rejection of treaties.Risk assessment is performed by agents evaluating the link weights againsta predefined threshold to decide whether or not to reject a treaty. This is arudimentary form of \u2018trust\u2019 which represents, in this simulation, an agent\u2019s will-ingness to expose itself to the risk from accepting or rejecting a treaty. Richercomputational models of trust are possible [17], but this is not primary focus ofthe agent\u2019s decision-making process.Given that treaties do not have any immediate effect, but instead influencethe future consumption of an agent, agents forecast to assess the present valueof a treaty. This is codified by using two separate arrays corresponding to long-term and short-term memory and storing the amount of food received each day(Fig. 2), with the short-term memory reset after each reshuffle. The reason forhaving two memory types is to allow agents to separately look at the currentreshuffle period and total experience in the tower, which aligns with the coreassumption in cognitive psychology that there are separate systems for long-and short-term memory [13].. . . 21 17 19 18 4 0 0 3 0 9 6 8 7 8 ? ?Long-term memoryShort-term memoryAverage reassignment period tfoodprobabilityfoodprobabilityMemory:Prediction:Fig. 2. Illustration of different agent memory types.Social Motives and Social Contracts in Cooperative Survival Games 157Since the reshuffle period is unknown to agents, they forecast this informationby averaging over all previous reshuffling periods.Agents must also contrast the effect that a treaty will have on the futurefood intake to assess if it is beneficial or not. Since the satisfaction of gaining orlosing wealth is non-linear [7], utility functions can account for this by mappingthe monetary value of a good or service to an individual\u2019s preference [6].Therefore, an agent calculates the expected utility both with and without atreaty and subsequently maximises the estimated future benefit. The utility ofgaining an uncertain amount of food per turn, xi with probability pi (based onpast experience), is computed with:E[U(x)] = p1 \u00d7 U(x1) + p2 \u00d7 U(x2) + ... + pn \u00d7 U(xn) (14)Prospect theory [10] is a well-established model of how a change in value isperceived or, alternatively, how much utility is gained or lost from a change invalue. This model comprises four main principles:Greediness: Agents are generally greedy, meaning that more of a resource isat least beneficial. Utility functions are hence generally increasing.Diminishing sensitivity: Marginal returns are strictly decreasing, thus thegreater the personal wealth of an agent, the less they value the resource.Risk aversion: Agents generally try to avoid risk. With risk aversion, theamount of food the agent perceives as equivalent to a random distribution (itscertainty equivalent C) is hence less than its mean.U(C) = E[U(x)] < U(E[x]) (15)Loss aversion: Losing some amount of food is generally perceived as worsethan gaining that same amount. Agents hence weight loss higher than gainUsing these concepts, we identify a gain (g) and cost (c) associated with eachunit of food received (x), as well as the risk aversion (r) to define the utilityof receiving a unit of food. The amount of food that the collectivist and selfishagents would need to consume in order to maximise their utility varies dependingon the current health level. The peak of its total utility function thus needs tobe able to vary too. We account for this by introducing a scaling factor a as:a =1z(crg) r1\u2212r(16)yielding:U(x) = g(ax)1r \u2212 cax (17)with z being the desired food intake, falling at the maximum of this function.The utility calculation for each different social motive has been parameterisedaccording to three insights: 1) the more selfish an agent is, the greedier it is, 2)the more an agent cares for the greater good, the greater its social cost associatedwith consumption and 3) more narcissistic people are generally less risk-averse[4]. The resulting utility functions are shown in Fig. 3.158 M. Scott et al.0 5 10 15 20\u2212100\u221280\u221260\u221240\u2212200foodutility0 0.5 1 1.5 2\u22122\u2212101foodutility0 10 20 30 40\u221220\u221210010foodutility0 20 40 60 80100020406080foodutilityg = 0, r = 1, c = 5 g = 2, r = 1.5, c = 2 g = 5, r = 2, c = 1 g = 10, r = 2.5, c = 0(a) Altruist (b) Collectivist (c) Selfish (d) NarcissistFig. 3. Different utility functions used to rate treaties according to the social motiveof the agents.Agents also use the proportion of estimated days before the next reshuffleperiod in order to weight how much they should focus on the short term. Tooptimise survivability, agents ignore the expected long-term utility when theirhealth is on a critical level.Let bshort and blong be the estimated short and long term benefit of a treaty,respectively. Also, let the estimated days remaining on the current level be givenby dcurrent and the duration of a treaty by dtreaty . The total benefit, btot is then:btot =dcurrentdtreaty\u00d7 bshort + (1 \u2212 dcurrentdtreaty) \u00d7 blong (18)Overall, the algorithm that agents follow when considering treaties is sum-marised as follows:1. Check if the link weight with the proposing agent is above a threshold2. Check that the treaty does not conflict with treaties the agent already signed13. Calculate the expected short- and long-term utility according to Eq. (14)4. Amplify the utility if it is negative to simulate loss-aversion.5. Calculate the utility of the food it can feasibly take under the treaty6. Compute the estimated benefits of signing the treaty as U(sign) \u2212U(don\u2019t sign)7. Choose to focus on the long- or short-term benefit according to Eq. (18)8. Sign the treaty if its overall benefit is positiveProposing and Propagating Treaties. Altruist agents wish to sacrifice them-selves by taking 0 food and narcissist agents wish to sacrifice others by takingall the food. This means that these agent types will never sign treaties, as itgoes against their strategy. The collectivist and selfish agents are therefore thetwo social motives that propose treaties. These proposed treaties are taken froma list of possible treaties, following the structure introduced in Table 1. For thispaper, we consider the three following treaties:\u2013 T1: \u201cIf currentHP > 0.6 \u00d7 maxHP , take 0 food.\u201d1 It is, for example, not possible for an agent to sign a treaty asking it to take 5 food,when it has already signed a treaty requesting it to take 0 food.Social Motives and Social Contracts in Cooperative Survival Games 159\u2013 T2: \u201cIf currentHP \u2265 weakLevel , take 0 food.\u201d\u2013 T3: \u201cIf currentHP < weakLevel , take \u2264 2 food.\u201dT1 can be proposed by the selfish agents, whereas T2 and T3 can be proposedby the collectivist agents. The three treaties are valid for a period of 2D days,where D is the \u2018reshuffling period\u2019 as introduced in Sect. 2.Once a treaty has been accepted or rejected, it is possible for the agent to re-propose the same treaty to its neighbour. Logically, the best possible strategy isto propagate one single treaty throughout the tower and have all agents behaveuniformly. Narcissist agents act to avoid this, hoping for the downfall of thecollective and hence refuse to propagate treaties. All other agents, however,propagate the treaty five floors above and below if these floors exist.5 Experimental Results and DiscussionIn this section, we use the simulator and agent designs introduced in Sect. 3 andSect. 4 to assess the performance of the studied system.We divide the simulations into 4 groups (A to D) characterised by having dif-ferent initialisation parameters. Table 3 summarises the simulations parametersfor each simulation. The percentages of each social motive (first four rows of thetable) correspond to the initial distribution of the agents\u2019 \u2018types\u2019. If not explic-itly mentioned, we run experiments using 100 agents, with 100 food initially onthe platform for 60 days and with a reshuffle period D of 30 days. As mentionedin Sect. 2, the agents are replaced upon death, following the distribution givenin Table 3. Our simulations results are given as the average over 30 repeatedsimulations.Table 3. Summary of the experiments.A1 A2 A3 A4 B1 B2 C1 C2 C3 D1 D2% Altruist 100 0 0 0 10 0 10 10 10 100 100% Collectivist 0 100 0 0 40 80 40 40 40 0 0% Selfish 0 0 100 0 40 20 40 40 40 0 0% Narcissist 0 0 0 100 10 0 10 10 10 0 0Stubbornness \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 0.2 0.2 0.2 0.8 0.8MaxBehaviourSwing 0 0 0 0 0 0 8 8 8 6 6Treaties T1\u20132 T1\u20132 T1\u20132 T1\u20132 T1\u20132 T1\u20132 T1\u20132 \u2013 T1\u20133 T1\u20132 T1\u20133In addition, the treaties used in cases C3 and D2 are slightly different, includ-ing all three treaties (T1, T2, T3) introduced in Sect. 4.3. C2 does not use anytreaty. The other cases use treaties T1 and T2.160 M. Scott et al.5.1 Simulation AThe first set of simulations we analyse are simulations that include agents thatall have the same social motive. Moreover, these agents do not have the abilityto change their social motive. The simulations results are shown in Fig. 4.We observe that a system containing purely altruists (Fig. 4 (a)) effectivelyself-destructs, since by acting purely selflessly, these agents never take anyresources. As the agents all die at the same time and are replaced by a newgroup of altruists, we see a step pattern in the number of deaths over time.0 20 40 60\u22120.2\u22120.100.10.2globalutility0 20 40 60\u22120.2\u22120.100.10.20 20 40 60\u22120.2\u22120.100.10.20 20 40 60\u22120.2\u22120.100.10.20 20 40 600150300450600days#ofdeaths0 20 40 60\u22125051015days0 20 40 600150300450600days0 20 40 600150300450600days(a) A1: Altruist (b) A2: Collectivist (c) A3: Selfish (d) A4: NarcissistFig. 4. Simulation results for a group of agents with uniform fixed social motive.Similar to the altruist agents, the narcissists have a large number of deathsamong them every 10 days (Fig. 4 (d)). This is due to the agents on the upperfloors of the tower taking all of the food, leaving none for the agents below.The main difference between the altruist and the narcissist agents can beseen in their corresponding global utility. The patterns can be explained by (6),which yields positive values only for A1, but leads to negative spikes for A4.As a compromise between the two systems, a system including only selfishagents present a lower number of deaths and a better global utility than A4(Fig. 4 (c))Finally, the collectivists instantaneously achieve a stable society in which(almost) none of the agents die (Fig. 4 (b)). We also note a uniformly positivecurve for global utility over time that is smoother than for the other socialmotives. This reflects the increased social cohesion between the agents and iden-tifies the almost perfect allocation of resources, leading to no wasted utility.5.2 Simulation BHaving assessed groups of agents of each social motive individually in Sect. 5.1,we increase the complexity of the system by having agents with different fixedSocial Motives and Social Contracts in Cooperative Survival Games 161social motives in the tower. The inability for these agents to change their socialmotive with time leads to the simulation results shown in Fig. 5.0 20 40 60\u22120.2\u22120.100.10.2daysglobalutility0 20 40 60\u22120.2\u22120.100.10.2days0 20 40 600150300450600days#ofdeaths0 20 40 600150300450600days(a) B1: utility (b) B2: utility (c) B1: deaths (d) B2: deathsFig. 5. Simulation results for a group of agents with different fixed social motives.Through comparing B1 to B2, we see that the system comprising a largeramount of collectivists (B2) outperforms the system with a comparativelysmaller amount of collectivists (B1). This is to be expected, as the more col-lectivist agents there are, the more similar to Fig. 4 (b) the system will be.A second result illustrated by this simulation is that the action of introduc-ing treaties (Sect. 4.3) is not always relevant. The collectivist agents sign thecollectivist and selfish treaty (the collectivist one being more restrictive), butthe selfish agents only sign the selfish treaty. This way, the two agent types arefollowing their natural strategy concerning food intake (Sect. 4.2). Knowing this,the system shows similar results with and without treaties, hence we only showthe results where communication is allowed.5.3 Simulation CThis set of simulations builds on top of the framework set by simulation B,instead investigating the behaviour of a system comprising different distributionsof fluid social motives. We utilise different levels of communication and treatiesto contrast the results using the treaties introduced in Sect. 4.3 (Fig. 6 (a\u2013c)).We simulate the system under two other configurations: without consideringany form of communication (Fig. 6 (d\u2013f)), and by restricting the agents\u2019 actionsfurther through the additional use of the treaty T3 (Fig. 6 (g\u2013i)).The treaty T3 restricts the amount of food its members can take when theirhealth drops below the weakLevel : \u201cif currentHP < weakLevel, take \u2264 2 food.\u201dThe overarching comment to draw from this set of results is the impact ofspecific treaties on the global utility. Although thought to improve the globalutility, treaties might have a negative effect on it: the results C1, using the col-lectivist treaty as introduced Sect. 4.3, are worst than the ones obtained withoutcommunication (C2).As the agents\u2019 health falls, their social motives tend to change toward nar-cissist. Instead of following the natural decision of this social motive, the agentshave to follow the treaties they signed (T1 and T2 for case C1). The moment162 M. Scott et al.Fig. 6. Simulation results for case C. C1 and C3 include communication, but C2 doesnot. C3 includes a more restrictive treaty.their health falls below the weakLevel, these treaties no longer apply and theywill follow their natural food intake rule defined in Sect. 4.2. However, this leadsto a lot of wasted resources at this critical health level. Notably, each food intakegreater than 2 will not offer additional utility to agents whose health falls belowthe weakLevel : any food intake greater than or equal to 2 upgrades the agentshealth to the weakLevel. The waste of common pool resources can also be visu-alised in Fig. 6 (c), where the global utility becomes strongly negative every 10days.This waste of common resources induced by agents following the collectivisttreaty is arguably due to a poor treaty design. To contrast these results, wecan consider the addition of a different, more effective treaty. Simulation C3introduced the treaty T3 that applies when the agents HP is below the weakLevel.As can be seen in Fig. 6 (h) and (i), this treaty allows for better performance ofthe system.Social Motives and Social Contracts in Cooperative Survival Games 1635.4 Simulation DIn these experiments, we initialise the tower\u2019s population with collectivist agentsonly, but with the possibility for them to change their social motive over time.The goal of these experiments is to evaluate if a society comprised solely ofcollectivists is able to remain stable over time. In addition, we investigate theeffect of treaties on such a system. The simulation results are shown in Fig. 7.Fig. 7. Simulation results different treaties acceptances.The results of D1 are similar to the ones of C1 in terms of (high) numberof deaths and (low) global utility. The replacement of terminated agents bycollectivist agents leads to an oscillatory behaviour between 2 quasi-stable states,with convergence to both a high concentration of collectivists and selfish agentsin inverse proportions. We hence deem this experiment as 2-phase polystable [1].Using the more restrictive treaty T3 on a system initially composed solelyof collectivist agents leads to an impressive performance (Fig. 7 (e) and (f)). Inaddition, the use of this treaty also allows for a stable distribution of the socialmotives across the tower (Fig. 7 (d)). This stability can also be seen in Fig. 6 (g).Despite the presence of selfish (and even narcissistic) agents in the tower, theyall follow the rule dictated by the treaties they signed whilst being collectivist.In addition, we can also see the effect of the reshuffle period on the socialmotives distribution in Fig. 7 (d). The reshuffle period is 30 days in this case andwe see a global shift toward collectivism at that moment.164 M. Scott et al.6 Summary and Conclusions6.1 SummaryOur first set of experiments shows the natural strategies taken by agents of differ-ent (fixed) social motives, and therefore gives us a baseline (A). The collectiviststrategy is by far the one achieving the highest global utility. Consequently, themore collectivist agents in the tower, the higher the global utility (B).However, the natural tendency of agents in an economy of scarcity is to makea transition towards the narcissistic end of the spectrum. This leads to a higheroverall distribution of selfish agents, and therefore a higher number of deaths andlower global utility (C, D). Such a drastic change is supported by the Conserva-tion of Resources Theory (COR) [8,9], which suggests that \u201cindividuals seek tocreate circumstances that will protect and promote the integrity of the individ-ual.\u201d This behaviour also parallels \u2018Thorndike\u2019s Law of Effect,\u2019 [21] which statesthat actions that produce a favourable outcome are likely to be repeated. Theagents\u2019 behaviours combine these two observations, as the initial negative effectsof scarcity produce a selfish behavioural change, which persists until narcissismis reached.To counteract this fact, it is possible to design social contracts in the form oftreaties between the agents. Treaties serve as a stabilising self-organising mech-anism, with appropriately constrictive treaties (C3, D2) even allowing for theintegration of narcissists into the population, despite their natural tendency todestabilise a system. Treaties may also change a polystable system into a purelystable system, when sufficiently strong as to enforce a collectivist mindset. Oscil-latory distributions of social motives can be brought to a static distribution usingthis mechanism (D1, D2). However, designing treaties that lead to a high globalutility is not a trivial task; agents using poorly designed treaties may even per-form worse than agents only following their natural strategy without using anysort of communication (C1, C2).6.2 Future WorkOur future work would focus around adapting the ways in which we model theagents\u2019 changes in social motives. One such way is to make agents tend towardsaltruism, rather than narcissism, when faced with adversarial conditions. Thiscould be interpreted as an understanding of the agent\u2019s environment and thelong-term improvement of the individual utility through a short-term sacrifice,thus bringing the system back to an equilibrium.Furthermore, we might imagine a randomly distributed assignment ofbehavioural weights (Table 2) across different agents. This would illustrate howdifferent agents react to their condition, from which the concept of agent person-ality could be derived. For example, some agents may encounter a comfortablesituation (high HP, high floor) and take advantage of it by acting selfishly, whileanother agent may encounter the same situation and take the opportunity tomake a positive impact for their fellow agents below by acting altruistically.Social Motives and Social Contracts in Cooperative Survival Games 165The physical arrangement of the tower can also be investigated and leansinto the possibility of having different non-linear topologies. This would allowfor fully-connected graphs, where all agents can communicate with all otheragents or planar lattices, with connections between the four or eight closestneighbouring agents, for example.Finally, we want to analyse the effects of a larger number of treaties on globalutility. The choice of treaties which lead to an increase in the global utility is notstraightforward. Since treaties are expressed in a generic way, it may be possibleto tune the treaty parameters to find optimal treaties in a given scenario.6.3 ConclusionIn conclusion, we observe that the scenario demands that the prisoners in thetower are effectively faced with an iterated version of Rawls\u2019 Veil of Ignorance:they have to decide repeatedly what sort of society they would prefer if theydid not know what position they would occupy in such a society. This workshows that even with limited communication and a population with diversesocial motives, the ability to construct social contracts leads to a stable societywhich perpetuates across generations, arguably showing that there is some psy-chological and sociological plausibility to Rawls\u2019 theory, although there is stillwork to be done on establishing whether or not, even if our agents establish astable and self-perpetuating social contract, it is the \u2018best\u2019 social contract.Acknowledgements. We are particularly grateful to the three anonymous reviewerswhose many insightful comments helped to revise and improve the presentation of thiswork. The experiments reported in this paper have used the Imperial College London2021\u201322 SOMAS Cohort\u2019s engine, and many thanks to everyone involved in the creationof this platform (sic).References1. Ashby, W.: Design for a Brain; The Origin of Adaptive Behavior - Scholar\u2019s ChoiceEdition, Chap. 4\u20135. Creative Media Partners, LLC (2015)2. Berger, P., Luckmann, T.: The Social Construction of Reality. Penguin Books,Harmondsworth (1966)3. Briggs, J.: Never in Anger: Portrait of an Eskimo Family. Harvard University Press,Cambridge (1970)4. Campbell, W.K., Goodie, A.S., Foster, J.D.: Narcissism, confidence, and risk atti-tude. J. Behav. Decis. Mak. 17(4), 297\u2013311 (2004)5. Davoust, A., Rovatsos, M.: Social contracts for non-cooperative games. In: AIES2020: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, pp.43\u201349. Association for Computing Machinery, New York (2020)6. Fishburn, P.C.: Utility theory for decision making. Technical report, ResearchAnalysis Corp McLean VA (1970)7. Fishburn, P.C.: Nonlinear Preference and Utility Theory, p. 2. Johns Hopkins Uni-versity Press, Baltimore (1988)166 M. Scott et al.8. Hobfoll, S.E.: Conservation of resource caravans and engaged settings. J. Occup.Organ. Psychol. 84(1), 116\u2013122 (2011)9. Hobfoll, S.E., Shirom, A., Golembiewski, R.: Conservation of resources theory. In:Handbook of Organizational Behavior, pp. 57\u201380 (2000)10. Kahneman, D., Tversky, A.: Prospect theory: an analysis of decision under risk,pp. 99\u2013127. World Scientific (2013)11. Kong, A., Thorleifsson, G.: The nature of nurture: effects of parental genotypes.Science 359(6374), 424\u2013428 (2018)12. Norberg-Hodge, H.: Ancient Futures: Learning from Ladakh. Sierra Club Books,San Francisco (1991)13. Norris, D.: Short-term memory and long-term memory are still different. Psychol.Bull. 143(9), 992 (2017)14. Oppenheimer, O.: The origin of social motives. Educ. Theory 4(2), 95\u2013104 (1954)15. Ostrom, E.: Governing the Commons. Cambridge University Press, Cambridge(1990)16. Pitt, J.: Self-Organising Multi-Agent Systems, pp. 149\u2013151. World Scientific, Sin-gapore (2021)17. Ramchurn, S., Huynh, T., Jennings, N.: Trust in multi-agent systems. Knowl. Eng.Rev. 19, 1\u201325 (2004)18. Rawls, J., Kelly, E.: Justice as Fairness: A Restatement. Belknap Press, Cambridge(2001)19. Reinders Folmer, C.: Social motives. In: The SAGE Encyclopedia of Theory inPsychology. pp. 886\u2013890. SAGE (2016)20. Schelling, T.C.: The strategy of conflict prospectus for a reorientation of gametheory. J. Conflict Resolut. 2(3), 203\u2013264 (1958)21. Thorndike, E.L.: The law of effect. Am. J. Psychol. 39(1/4), 212\u2013222 (1927)Evaluating Human and Agent TaskAllocators in Ad Hoc Human-Agent TeamsSami Abuhaimed(B) and Sandip SenTandy School of Computer Science, The University of Tulsa, Tulsa, USA{saa8061,sandip}@utulsa.eduAbstract. With accelerated progress in autonomous agent capabilities,mixed human and agent teams will become increasingly commonplacein both our personal and professional spheres. Hence, further examina-tion of factors affecting coordination efficacy in these types of teams areneeded to inform the design and use of effective human-agent teams.Ad hoc human-agent teams, where team members interact without priorexperience with teammates and only for a limited number of interac-tions, will be commonplace in dynamic environments with short oppor-tunity windows for coordination between diverse groups. We study vir-tual ad-hoc team scenarios pairing a human with an agent where bothneed to assess and adapt to the capabilities of the partner to maximizeteam performance. In this work, we investigate the relative efficacy oftwo human-agent coordination protocols that differ in the team memberresponsible for allocating tasks to the team. We designed, implemented,and experimented with an environment in which virtual human-agentteams repeatedly coordinate to complete heterogeneous task sets.Keywords: Human-agent coordination \u00b7 Team performance \u00b7 Taskallocation1 IntroductionRecent intelligent agent applications assume traditionally human roles in human-agent teams, e.g., tutor [35] and trainer [22]. Agents can also coordinate withpeople in critical tasks, including guiding emergency evacuations [33] and disas-ter relief [32]. New environments have been developed recently to enable groupactivities or coordination between people and agents, such as crowd-work andmultiplayer online games. Human and agent teams are increasingly common-place where they play different team roles. Since human-agent teams are beingrecognized as a routine and functionally critical important component of oursocieties, researchers have been studying the interactions and dynamics withinthese teams to understand and improve on their design [13]. Such human-agentteams have been studied in physical (robotic) and virtual settings [34].We are studying ad hoc coordination scenarios where humans start coordi-nating with agents in a new environment with no prior interaction experiencewith the agent. The agent also does not have prior knowledge about its humanc\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 167\u2013184, 2022.https://doi.org/10.1007/978-3-031-20845-4_11168 S. Abuhaimed and S. Senpartners\u2019 abilities and preferences. Such coordination environments correspondto ad hoc teams: An ad hoc team setting is one in which teammates must worktogether to obtain a common goal, but without any prior agreement regarding howto work together [11]. Coordination in ad hoc teams is more challenging becauseof absence of prior knowledge and established relationships. Ad hoc human-agentcoordination also raises critical new issues compared to ad hoc agent teams.In this paper, we consider ad hoc teams trying to accomplish a set of taskschosen from diverse task types. We assume that different human users will havedifferent competence and expertise over various task types. We use a fixed agentexpertise distribution (simulated) over the task types. To optimize the perfor-mance of a given human-agent team, therefore, it is necessary to have differenttask allocation distributions to the team members based on the expertise of thehuman team member. The allocation problem is exacerbated by the fact that ateam member does not know the expertise levels of its partner a priori. Whilewe allow for human and agent partners to share their estimated expertise overdifferent task types, the accuracy and consistency of such expressed estimatesby humans are unreliable [17].Repeated interaction allows partners to refine the initial estimates provided,but such opportunities are few due to (i) only a limited number of repeatedteamwork episodes and (ii) allocation decisions that determine what task typesare performed by a partner in an episode. The success of such ad hoc human-agent teams in completing assigned team tasks, therefore, will critically dependon effective adaptability in the task allocation process.Task allocation have been studied extensively in agent teams [27] as well asin human team and organizations literature [31]. However, we are not aware ofprior examination of autonomous agents with task allocation roles, compared tohumans, in virtual and ad hoc human-agent teams.Some critical questions on task allocation decisions and human-agent ad hocteam efficacy that we study in this paper are:\u2022 Is the performance of human-agent teams influenced by who allocates thetasks? If so, who produce higher team performance?\u2022 How is the performance of human-agent teams affected by over/under-confidence of humans in their performance on different task types?\u2022 How quickly can the task allocator in an ad hoc human-agent team learnabout the relative capabilities of team members to optimize allocation oftasks?We designed a new human-agent team coordination framework for task allo-cation and performance analysis: the Collaborative Human-Agent Taskboard(CHATboard). We use CHATboard for ad hoc human-agent team coordination,for repeated team task allocation scenarios, with human workers recruited fromthe Amazon Mechanical Turk (MTurk) platform. We present some conjecturesas hypotheses about human confidence level in their expertise, about the rela-tive effectiveness of human and agent task allocators, about the ability of agentsto learn about human capabilities and adapt task allocations, and the abilityof agents to harness human potential. We ran experiments involving repeatedEvaluating Human and Agent Task Allocators 169coordination using the Human and Agent Allocation protocols. We present theresults and our analysis to confirm our hypotheses and identify interesting phe-nomena that suggests future research tasks.2 Related WorkHuman-agent teams have been studied in different domains such as spacerobotics [13], therapy [1], deception-detection [20], programming [23] anddecision-making [3]. The focus has been on agents who play supportive rolesto human teammates [20], and they have been studied in robotic and simulationsettings [34].We, however, focus on an ad hoc environment, whereas studies, such as [13],incorporate training or interaction sessions with the agent and environment priorto the study. We are also interested in agents that are autonomous; DeChurchand Larson view an autonomous agent as a \u201cteam member fulfilling a distinctrole in the team and making a unique contribution\u201d [21].Task allocation has been studied extensively in multi-agent teams [12,14,18,27,28]. In agent teams, the focus is on designing efficient mechanisms for agentsto distribute tasks within their society; current approaches include integer pro-gramming [9], genetic [29], consensus and auction algorithms [6], and markets [8],and in domains such as Search and Rescue [37]. There is a recent focus on adhoc environments [5] in which agents coordinate without pre-coordination. Themajority of agent teams work is focused on simulation and robotic environments,and few have studied task allocation in ad hoc human-agent teams. Moreover,there is a general lack of investigating environments that include human team-mates; including humans in same agent teams may require new approaches, aswe do not know If the same mechanisms would produce similar results.Task allocation is also studied in humans\u2019 team and organization literature.The mechanism of task allocation, which includes capabilities identification, rolespecification, and task planning, is considered an important component of team-work [10,24,25]. Any organization needs to solve four universal problems, includ-ing task allocation, to achieve its goals [31]. In human teams, the focus is onunderstanding human team characteristics to design the best possible task allo-cation mechanism; however, there is little investigation of autonomous agents\u2019effects on human teams when they are included in teams\u2019 allocation mechanisms.Thus, the study of task allocation with combined human and agent team mem-bers is promising [4,34]. The few existing work examine different dimensions. [34]and [32] investigate an agent assisting humans\u2019 control of robots in a simulation andexperiments; the focus is supporting operators. Some of this work do not empir-ically investigate the area, focused on industrial settings, configure the agent insupporting roles, and it is unclear whether human participants received trainingprior to experiments, which means that the scenario not ad hoc.In summary, studies that investigate task allocation within teams composedof humans and autonomous agents in ad hoc environments over repeated inter-actions are limited. We, therefore, study task allocation in ad hoc human-agentteams while being informed by potential human miscalibration tendencies.170 S. Abuhaimed and S. Sen3 Hypotheses DevelopmentWe now motivate and present a number of research hypotheses related to adhoc human-agent team task allocation and team performance that we will beexperimentally evaluating in this paper. We study two task allocation protocolsthat govern the human-agent teamwork: Human Allocator Protocol and AgentAllocator Protocol. The former assigns task allocator role to human teammate,and the later to agent teammate (Section 5 presents more details).We assume there is considerable variability in ability to complete tasksamongst average citizens. If this was not the case, human expertise in taskscan be gauged offline, and optimal task allocation can be performed, i.e., ad hocteams would be no different than teams with significant prior working experience.Hypothesis 0a (H0a): Different human participants have different perceptionand actual performance for different task types.We also assume that humans are unable to accurately estimate or express theirperformance (confidence levels) on different, somewhat routine task types. Ifthis was not the case, then again, we could simply ask the human about theirexpertise levels for different task types and use that accurate information for taskallocation, i.e., ad hoc teams would be no different than teams with significantprior working experience.Hypothesis 0b (H0b): Human\u2019s average confidence levels on task types arenot consistent with their performance on those task types.We conjecture that the agent allocator has several advantages over the humanallocator for effectively allocating team tasks: (a) lack of personal bias or prefer-ence for task types that is not performance motivated (for example, humans maylike to do certain tasks even though they may not be good at it), (b) agents willhave better estimates of their capabilities on known task types whereas humanstypically over or under-estimate their expertise or performance on task types,(c) agents can consistently follow optimal allocation procedures given confidencelevels over task types, (d) agents can more consistently learn from task perfor-mance of teammates in early episodes to update confidence level estimates andadapt task allocation to improve performance. This lack of bias may also resultin the agent allocator allocating tasks such that together with higher team per-formance we also observe better performance of the human team member, i.e.,better realize the human potential, compared to when the humans allocate tasksbetween team members! When the agent is assigned allocator role, it follows anallocation strategy that search for allocations that maximize total performancewhile learning about actual human performances (See Sect. 5.2 for more details).We believe that agent allocation strategies that effectively embody advantages(a)\u2013(d) above will conform to following set of hypotheses:Hypothesis 1 (H1): Agent Allocator Protocol produces higher teamwork overallperformance than Human Allocator Protocol.Hypothesis 2 (H2): Agent Allocator can learn from ad hoc teamwork experi-ence to quickly improve team performance through adaptation.Evaluating Human and Agent Task Allocators 171Fig. 1. CHATboard showing allocation phase of human allocation protocol.Hypothesis 3 (H3): Agent allocator will engender higher Human potentialrealization compared to the Human Allocator.4 Collaborative Human-Agent Taskboard (CHATboard)For systematic experimentation to evaluate the above hypotheses, we needed adomain that encapsulates the following characteristics:\u2022 The team tasks used should be such that there would be significant variationin expertise level in the general populace. Larger variability would allow formore space for team adaptation and for human satisfaction with teamwork.We should also have the latitude to easily and believably configure varyingagent capability distribution over the task types.\u2022 The domain should allow an agent to be perceived as autonomous and playinga distinct peer role in the team.\u2022 The domain should not require significant prior knowledge or training forhuman participants and should be accessible to non-experts for effectivelyoperating in an ad hoc team setting.\u2022 There should be flexibility in sharing team information, including task allo-cations and completions, with team members. The environment should beconfigurable between perfect and imperfect information scenarios as necessi-tated by the research question being investigated.We developed CHATboard, an environment that facilitates human-agent,as well as human-human, team coordination. CHATboard contains a graphicalinterface that supports human-agent team coordination to complete a set of tasks(see Fig. 1). CHATboard allows for displaying the task sets to be completed, sup-ports multiple task allocation protocols, communication between team membersfor expressing confidence levels, displaying task allocations and performance byteam members on assigned tasks, etc.172 S. Abuhaimed and S. SenFig. 2. Instances of different task types.The framework utilizes the concept of tasks posted on blackboards, oftenused in coordination within human teams, to facilitate a human team memberperceiving an agent as a distinct team member. Blackboards have also beeneffectively used in agent teams as a common repository for information sharingbetween agents [16]. Figure 1 shows the shared taskboad on top, which includesthe set of team tasks organized by type, and two other boards respectively forthe tasks assigned to the human and the agent team member. Figure 2 presentsexamples of task types. These task boards facilitate coordination, and act aseasily navigable repositories for team information allowing team members toshare and view information through these boards.We define a set of n team members N : {p1, p2, ..., pn}, a set of m task typesM : {y1, y2, ..., ym}, a set of r tasks, Tjr: {tj1, tj2, ..., tjr}, for each task typeyj . Team member i can share their confidence levels pi(yj) over task types yj .The set Ci: {pi(y1),pi(y2), ..., pi(ym)} represent confidence levels for differenttask types for team player, pi. The team members will interact over E episodes,where episode numbers range from 1 . . . E. Ai,e denotes the set of tasks allocatedto player i in episode e and we assume that all available tasks are exhaustivelyallocated, i.e.,\u22c3i Ai,e =\u22c3j Tjr. The performance of player pi for a task tjk inepisode e is referred to as oijke \u2208 {0, 1}. We define the performance of pi on tasktype yj in episode e as \u03bci,yj ,e =\u2211tjk\u2208Ai,e oijke.5 MethodologyWe present details about the team interaction protocol, agent behavior, evalua-tion metrics, and experiment design in this section.5.1 Interaction ProtocolsWe describe the protocols that govern the human-agent ad hoc teamwork. Twointeraction protocols have been designed to guide task allocation process in an adhoc environment: (i) the Human Allocator Protocol and (ii) the Agent AllocatorProtocol. The former assigns the task allocator role to the human teammate,and is illustrated as follows:Evaluating Human and Agent Task Allocators 1731. The protocol asks agent teammate for its task types confidence levels.2. The protocol passes the agent\u2019s confidence levels to the human.The following steps comprise an episode and are repeated N timesEpisode starts: e \u2190 13. The protocol asks Human to provide task allocations for the team.4. Allocated tasks are assigned to the team members.5. The protocol receives human and agent task performance measures and computesstatistics.6. The protocol displays team overall team performance as well as individual teammember performances for the episode on their respective task boards.Episode endse \u2190 e + 1; if (e < N), Go to step 3The Agent Allocator Protocol is the flip side of the coin and assigns thetask allocator role to the agent. Team members repeatably interact over differ-ent stages in both protocols: Task Allocation, Task Completion, and Taskworkresults (see Though these protocols provide a framework for team interactionand task allocation, they do not dictate the allocation strategy used by the allo-cator. For the current study, we use a perfect information scenario, where allteam information, such as set of team tasks, task assignments to team members,and the task performance is fully observable for all team members.5.2 Agent CharacteristicsExpertise: We configure an agent team member with a fixed expertise profilethat has different expertise level for different task types, represented as a vector ofprobabilities for successful completion of task types1. Agent Allocator Strat-egy: In the current paper, we also use the following additional constraints withinthe CHATboard framework that informs the allocator strategy. We assume eachtask is allocated to and performed by a single team member and does not requirework from multiple individuals, i.e., Ai,e \u2229 Aj,e = \u03c6. We additionally requiredthat the total number of tasks assigned to each team member be the same, i.e.,\u2200x, y, |Ax| = |Ay|. Different number of tasks can however be assigned to twoteam members for different task types.The primary allocation goal is to maximize utilization of the available teamcapacity given the expertise of the team. Additionally, agent should account forthe constraint that team members have to do equal number of task items. Insteadof using task items for task division, the agent uses task types. The agent storesand uses estimates of on task completion rates by task types for the human teammember in the allocation procedure.Max\u2211y\u2208M(xya(y) + (1 \u2212 xy)h(y)); s.t.\u2200y, xy \u2208 0, 11 Agent expertise is simulated in our experiments: given a expertise (confidence) levelPt of the agent for task type t, a task of type t is considered successfully completedif a coin flipped with probability Pt returns head; else failure is reported on the task.174 S. Abuhaimed and S. SenAlgorithm 1. Agent Allocator StrategyInput: N= {ph, pg}, M= {y1,. . . ,ym} , E1: for e = 1....E do2: if e = 1 then3: Qi,yj \u2190 pi(yj), \u2200pi \u2208 N, yj \u2208 M4: each Tyj is partitioned into n equal size subsets, which are randomly allo-cated to agent i to form Ai,1, for each pi \u2208 N5: else6: Ai,e \u2190 getAllocations(Qi,e)7: end if8: if yj is allocated to pi then9: Qi,yj \u2190 (1 \u2212 \u03b1) \u00b7 Qi,yj + \u03b1 \u00b7 \u03bci,yj ,e10: end if11: end for\u2211y\u2208Mxy =\u2211y\u2208M(1 \u2212 xy) = |M |2 .In the above equations, xy is binary variable indicating whether a task type,y, is assigned to human or agent, based on the current performance estimateof the human, h(y), and agent, a(y), on that task type. As per requirement,each team member is assigned exactly half of the task types. This is an unbal-anced assignment problem, as number of task types is greater than number ofteam members (m > n). It can be solved by transforming it into a balancedformulation, e.g., adding dummy variables, and running, e.g., Hungarian algo-rithm [19]. We utilize the SCIP mixed integer programming solver [30], repre-sented by getAllocations() procedure in Line 6 of Algorithm1, to find theallocation that maximizes utilization of team\u2019s confidence levels.In many task allocation formulations, e.g., matching markets, assignmentproblems, and others, participants\u2019 preferences or confidence levels are assumedto be accurately known [36]. In our formulation, however, learning is needed aswe believe human participant\u2019s estimates of their capabilities can be inaccurate.The second goal that agent\u2019s strategy should account for is related to learningand adaptation. Since this is an ad hoc environment, the second goal of our agentis to quickly learn about its partner\u2019s expertise levels and quickly adapt theallocations accordingly for improved team performance. After each interaction,e, the agent updates the capability model, Qi,yj , of team member, pi, for eachtask type, yj , from the observed performances, \u03bci,yj ,e, as follows: Qi,yj \u2190 (1 \u2212\u03b1) \u00b7 Qi,yj + \u03b1 \u00b7 \u03bci,yj ,e. In the first episode, however, the agent allocator exploresteam member\u2019s capabilities by partitioning task items within each task type,Tyj , equally among team members, as shown in Line 4 in Algorithm1.5.3 Evaluation MetricsHuman Teammate Miscalibration and Variability Trends: In our exper-iments, human teammates coordinate with agent to accomplish tasks items fromEvaluating Human and Agent Task Allocators 175m task types (we have used m = 4 in our experiments). We measure the vari-ability, over task types, of the difference between the human teammates\u2019 statedconfidence levels and their actual performance.The confidence levels shared by a human teammate for each task type areused as estimated probability of success for the respective task types. The agentmaintains a moving average over the episodes of the team member\u2019s performanceon a task type as the percentage of tasks of that type that the human successfullycompletes. We measure miscalibration for a human player i for task type yj ,based on the stated confidence level, pi(yj), and actual average performanceon that task type over all episodes, \u03bci,yj =1E\u2211Ee=1 \u03bci,yj ,e, as squared error:Miscalibrationi,yj \u2190 (pi(yj) \u2212 \u03bci,yj )2.Team Performance: Human and agent collaborate as a team to complete theset of tasks. We consider boolean task completion: a task allocated to a teammember is either successfully completed or a failure is reported. Team overallperformance is measured as the percentage of successful completion of assignedtasks over all episodes: Unweighted Team Performance is measured as the aver-age team performance over episodes, 1E\u2211Ee=1 Rteam,e, where Rteam,e is the teamperformance in episode e, which is the average performance, \u03bc, of all team mem-bers over all task types in that episode Rteam,e \u2190 1mn\u2211ni=1\u2211mj=1 \u03bci,yj ,e.Team Improvement and Learning: Since our scenario is ad hoc, it requiresquick learning and improvements in team performance from task allocators.We investigate the differences in mean performance between episodes to gaugeimprovements. We also measure the ability to improve as the weighted teamperformance over episodes, with the performance of latter episodes are weightedmore than the earlier ones: Weighted Team Performance \u2190 1E\u2211Ee=1 ze \u00b7Rteam,e,where ze is the weight for episode e.Potential Realization: An effective allocator will better utilize the capacity ofthe team and realize as much of their teammate\u2019s potential as possible. Potentialrealization can be measured through the difference between available capacityand utilized capacity. We have perfect knowledge of the agent\u2019s capacity, whichis fixed at design time. We do not know, however, know of the available capacityof human team members. We compare the difference in the capacity utilizedby human and agent allocators. We measure utilized capacity of humans as theindividual performance level within the team. The performance (success rate)of an agent i over all episodes, referred to as Potential Realization of i, is Si =\u2211Ee=1\u2211yj\u2208M \u03bci,yj ,e. We designate by Shi and Sai the performance (potentialrealization) of agent i under human and agent allocator protocol respectively.Weighted Likeability: The human-agent team is expected to accomplish mtask types over the interaction episodes. At the end of the study, we askhuman participants how much they liked each task type by asking them torate their likeability of each task type on a 10-point Likert scale. For eachparticipant, pi, we compute the weighted likeability over all allocated tasks as\u2211yj\u2208M li,yj\u2211Ee=1 |Ai,yj ,e|, where Ai,yj ,e is the set of tasks of type yj allocated176 S. Abuhaimed and S. Sento player pi in episode e and li,yj is the human player pi\u2019s stated likeability oftask type yj .5.4 Experimental ConfigurationsWe conduct experiments with teams of one human and one agent (n = 2), i.e.,N = {pa, ph}. We use four task types (m = 4), i.e., M : {y1, y2,y4,y4}, whichare Identify Language, Solve WordGrid, Identify Landmark, and Identify Event(examples of these task types shown in Fig. 2). The task types in this paper areselected so that, for each type, sufficient expertise variations in recruited humansubjects are likely. For example, Identify Language is a task type in which teamare asked to identify the language, e.g. Japanese, in a text message from a numberof options, e.g., Japanese, German, Hebrew, Arabic.We created 32 (r = 8) task item instances for each episode, and the total num-ber of interactions is four, E = 4. The confidence levels are stated in a [1, 100]range, which are then scaled by the agent internally into a [0, 1] to be inter-preted as probabilities of completing tasks of that type. Also, we configure theagent strategy with \u03b1 = 0.4 since Ad hoc situations require allocation strategiesto quickly learn about team\u2019s capabilities. Additionally, for the weighted per-formance measure, we have used the following vector of weights over episodes:z = [0.15, 0.20, 0.30, 0.35]; it assign more value to performance on latter episodes(any weights that does that would qualitatively produce similar results).We recruited 130 participants from Amazon Mechanical Turk, 65 for eachcondition, as is recommended for a medium-sized effect [7]. We use a between-subject, and each team is assigned randomly to one protocol or the other.After participants agree to the Informed Consent Form, they read a descrip-tion of the study, and then start the first episode. Each episode contains threephases: taskwork allocation, taskwork completion, and taskwork results. Aftereach episode, the results are displayed to both human and agent teammates,which include overall and per-type performance levels. Once participants com-plete all four episodes, they are asked to complete a survey including their sat-isfaction on various aspects of teamwork and their likeability for task types. Weincorporate random comprehension attention checks to ensure result fidelity [15].Participants receive a bonus payment based on team performance.6 Experimental ResultsHuman Variability and Miscalibration: We analyze human variabilityand task type perceptions in their stated confidence levels and their perfor-mance. We first analyze human variability in their stated confidence levels usingone-way ANOVA. We find that confidence level between task types (MA =63.27, SDA = 23.16,MB = 57.01, SDB = 21.45,MC4 = 77.64, SDC =19.06,MD = 41.49, SDD = 21.70) are significantly different, F=31, p < 0.001.We similarity evaluate variability in humans\u2019 actual performances and find thatactual performance levels between task types (MA = 77.52, SDA = 17.01,MB =Evaluating Human and Agent Task Allocators 177Fig. 3. Human variability in stated confidence (right) and actual performance (Left).Table 1. Stated levels and performances for task types.Task Type LevelStated ActualMean SD Mean SDIdentify Language (A) 63.27 23.16 77.52 17.01Identify Landmark (B) 57.01 21.45 75.87 16.28Solve WordsGrid (C) 77.64 19.06 95.0 6.4Identify Event (D) 41.49 21.70 37.30 25.4375.87, SDB = 16.28.45,MC4 = 95.0, SDC = 6.4,MD = 37.30, SDD = 25.43)are significantly different, F=123, p < 0.001. As Fig. 3 and Table 1 show, humansare exhibiting variability and different perceptions toward the task types. H0ais supported.We analyze confidence levels estimates stated by human teammates in theAgent Allocator Protocol for the different task types: A, B, C, and D. We analyzethe average squared error of the difference between the stated confidence leveland actual performance over all task types, 0.08, and was found to be significantlydifferent from zero, t = 7.4, p < 0.001. We then compute the squared error foreach task type (MA = 0.07, SDA = 0.13, MB = 0.08, SDB = 0.13, MC =0.06, SDC = 0.12, MD = 0.12, SDD = 0.14), and find that it is significantlydifferent from zero, tA = 4.37, pA < 0.001, tB = 5.28, pB < 0.001, tC = 4.16,pC < 0.001, tD = 7.11, pD < 0.001 (See Fig. 4). Thus, human teammates areshowing miscalibration tendencies in all task types. H0b is supported.To determine whether human teammates are over- or under-estimating theirstated confidence levels in different task types, relative to actual performance,we run non-parametric Sign Tests. We found that, on average, human tendto underestimate their capabilities relative to actual performance (Savg = 18,pavg = 0.001). We then run Sign Test for each task type, and find that humanteammates are significantly underestimating their capabilities for task type A,B, and C (SA = 15, pA < 0.001, SB = 13, pB < 0.001, SC = 7, pC < 0.001),178 S. Abuhaimed and S. SenFig. 4. Density of squared estimation error for task types.and over-estimating for task type D (SD = 38, pD = 0.018). We analyze tasktype characteristics, and found that task type A, B, and C share one commontrait in which they are more general and familiar to typical human teammates,whereas task type D, Identify Event, is more specialized [2].Team Performance: The teams using Agent Allocator Protocol (M = 0.75,SD = 0.04) compared to ones using Human Allocator Protocol (M= 0.69, SD= 0.09) demonstrated significantly higher team performance, t = 4.4, p < 0.001,with a large size effect, cohen\u2019s d = 0.86 (See Table 2). H1 is supported.Learning and Improvement: Since the teams are working in an ad hoc envi-ronment, task allocators need to quickly learn about team capabilities andincrease team performance. First, we investigate if team performances overepisodes is different in each protocol. We find that it is significantly differ-ent for the Agent Allocator Protocol (Meps1 = 0.59, SDeps1 = 0.10,Meps2 =0.76, SDeps2 = 0.11,Meps3 = 0.82, SDeps3 = 0.10,Meps4 = 0.83, SDeps4 =0.11), Fa = 167.17, pa < 0.001. We also find that it is significantly differ-ent for the Human Allocator Protocol (Meps1 = 0.66, SDeps1 = 0.10,Meps2 =0.67, SDeps2 = 0.13,Meps3 = 0.71, SDeps3 = 0.12, Meps4 = 0.71, SDeps4 =0.12), Fh = 3.17, and ph = 0.024.The agent allocator starts has lower performance, Meps1 = 0.59, than humanallocator, Meps1 = 0.66 in the first episode. This is due to the agent strategyof exploration during the first episode. However, the agent improves quickly,and outperforms human in the second, third, and fourth episodes. The agentimproves team performance by a significant margin going from episode 1 toepisode 2, and then by smaller margins going from episode 2 to episode 3, andepisode 3 to episode 4. The improvements over episodes by the Human allocatoris less pronounced.Evaluating Human and Agent Task Allocators 179Table 2. Team performance (*p < 0.001).Performance Allocator tHuman AgentMean SD Mean SDUnweighted 0.69 0.09 0.75 0.04 4.4*Weighted 0.70 0.10 0.78 0.04 5.8*Fig. 5. Tukey\u2019s HSD Test: differences in mean levels of four episodes (E1 to E4). Left:Agent, Right: Human.Moreover, we run Post hoc analysis, using Tukey\u2019s HSD Test, to evaluate theperformance differences between episodes (See Fig. 5). When Human is allocat-ing, we find no significant mean differences between the episodes, E2 \u2212 E1 =0.007, p = 0.98, E3 \u2212 E1 = 0.05, p = 0.10, E4 \u2212 E1 = 0.05, p = 0.08, E3 \u2212 E2 =0.04, p = 0.20, E4 \u2212 E2 = 0.42, p = 0.17, E4 \u2212 E3 = 0.001, p = 0.99. Wedo, however, find significant mean differences between episodes with the AgentAllocator, except for E4-E3, E2 \u2212 E1 = 0.17, p < 0.001, E3 \u2212 E1 = 023, p <0.001, E4\u2212E1 = 0.25, p < 0.001, E3\u2212E2 = 0.06, p < 0.001, E4\u2212E2 = 0.08, p <0.001, E4\u2212E3 = 0.02, p = 0.52. This shows that the agent is, indeed, improvingafter each experience. One possible interpretation between the small differencebetween episode 3 and 4, relative to the larger differences from episodes E1 toE2, and from E2 to E3, is that the agent is getting close to the optimal allocationof tasks based on the team member capabilities.We also note that performance of teams using the Agent Allocator Protocol(M = 0.78, SD = 0.04) are better than teams using the Human Allocator Protocol(M = 0.70, SD = 0.10) in weighted performance, t = 5.8, p< 0.001. In otherwords, the agent is showing better learning of its teammate\u2019s capabilities andadapting the task allocations accordingly to further improve team performancein latter rounds. since weighted performance measures overall team performanceover the latter, rather than, earlier episodes. The agent allocator significantly180 S. Abuhaimed and S. Senoutperforms the human allocator using the weighted performance measures (SeeTable 2). H2 is supported.Potential Realization: We compared teams based on how allocators realizepotential of teammates and themselves. The pertinent question is: which alloca-tor utilizes human capacity better? We find that teams who have agents as taskallocators (M = 0.87, SD = 0.06) realize significantly more human potential thanHuman Allocator (M = 0.81, SD = 0.10), t = 2.2, p = 0.02. H3 is supported.Table 3. Self, teammate potential realization by allocators.Performance AllocatorHuman AgentMean SD Mean SDHuman 0.81 0.10 0.87 0.06Agent 0.59 0.12 0.74 0.05Fig. 6. Weighted likeability density for human and agent protocols.We also analyze how team allocators effectively utilize agent capacity. We findthat agent capacity utilization or performance is significantly higher in teamswho have agents as task allocators (M = 0.74, SD = 0.05) compared to teamswith Human allocators (M = 0.59, SD = 0.12), t = 5.02, p< 001. Thirdly, weinvestigate which allocator utilizes the capacity of their teammate better. Wefind that teams who Agent allocators (M = 0.87, SD = 0.06) significantly realizemore performance from their teammates than Human Allocator (M = 0.59, SD= 0.12), t = 13.4, p< 0.001.We do not analyze self-realization between human and agent allocators sincehuman capacity in the Human Allocator Protocol is unknown. We also definethe level of agent capacity or confidence level structure prior to the interaction;Evaluating Human and Agent Task Allocators 181thus, we cannot compare self-realization of human and agent allocators. Weposit, however, when allocators are agents, they realize more potential in theteam; both in themselves and in the human team member (See Table 3)2.Weighted Likeability: To understand the performance differences between theHuman and Agent Allocator Protocols, we analyze the task types allocated tohuman teammates. Do humans allocate more tasks of types they like to them-selves? We find that Agent allocators (Ma = 6.77, SDa = 1.51) allocate moreitems of liked task types to the human team member than does the humanallocator (Mh = 6.07, SDh = 1.80), tlike = 2.3, plike = 0.01 (See Fig. 6).7 Discussion and Future WorkWe introduced CHATboard, a flexible task allocation framework between humanand agent team members for ad hoc scenarios. While CHATboard can be config-ured to support larger teams and more complex constraints between tasks, suchas multiple workers per task, in this paper we showed its efficacy in supportingcoordination between one human and one autonomous agent.To understand team dynamics with respect to task allocation within human-agent teams, we presented two interaction protocols and team designs in whichtask allocator role is either assigned to human or agent team member: Humanand Agent Allocator Protocols. We ran experiments with these team designs andshowed human teammates often exhibit miscalibration, where they either over-or under-estimate their capabilities.We demonstrated that agent task allocators generally increase the quality ofteam with respect to team performance and realizing potential of team comparedto human allocators. The agent allocators learn quickly about team capabilities,and realize more potential in the team, both their own and of their humanteammate. Our analysis of the experiments also confirms various hypotheses wehad posed about such ad hoc human-agent team coordination.Though finding the reason for the lower performance of human allocatorsis beyond scope of this paper, we conjectured that it might be due to humansallocating more tasks they like to themselves, even though they may not be goodat it. We find, however, that the agent is allocating more likeable tasks to thehuman teammate. The lower performance might be explained by biases iden-tified in behavioral economics, such as prospect theory, in which they perceiveperformance gains or success differently than losses or failure rate. We leave thisline of investigation to future work.While our work provides interesting insights into effective task allocationprotocols and strategies in human-agent teams, our current work has some lim-itations. The first is concerned with the types of tasks the team allocates. Theteam only allocates intellective tasks, and it is unclear how the results wouldgeneralize if the team is responsible for other classifications of task types [26]. In2 Humans outperform agents for both allocators as agents are endowed with medium-level capabilities. Increasing agent expertise will change relative performances.182 S. Abuhaimed and S. Senaddition, in the current study the protocol is configured to allow for only tasksharing. We do not know the effect of removing this constraint.As future work, we will evaluate the effect of different agent expertise dis-tributions on team performances. We also plan to experiment with differentenvironment and protocol configurations, including those where the constraintof equal division of tasks is relaxed, and where allocator role is shared. Lastly, weplan to study how the dynamics of human-agent teams change when the teamconsists of more than two members.References1. Abdulrahman, A., Richards, D., Bilgin, A.A.: Reason explanation for encouragingbehaviour change intention. In: Proceedings of the 20th International Conferenceon Autonomous Agents and MultiAgent Systems, pp. 68\u201377 (2021)2. Adams, P.A., Adams, J.K.: Confidence in the recognition and reproduction of wordsdifficult to spell. Am. J. Psychol. 73, 544\u2013552 (1960)3. Anderson, A., Kleinberg, J., Mullainathan, S.: Assessing human error against abenchmark of perfection. ACM Trans. Knowl. Disc. Data (TKDD) 11(4), 1\u201325(2017)4. Athey, S.C., Bryan, K.A., Gans, J.S.: The allocation of decision authority to humanand artificial intelligence. In: AEA Papers and Proceedings, vol. 110, pp. 80\u201384(2020)5. Barrett, S., Stone, P., Kraus, S.: Empirical evaluation of ad hoc teamwork in thepursuit domain. In: AAMAS, pp. 567\u2013574 (2011)6. Binetti, G., Naso, D., Turchiano, B.: Decentralized task allocation for surveillancesystems with critical tasks. Robot. Auton. Syst. 61(12), 1653\u20131664 (2013)7. Brinkman, W.P.: Design of a questionnaire instrument. In: Handbook of MobileTechnology Research Methods, pp. 31\u201357. Nova Publishers (2009)8. Dias, M.B., Zlot, R., Kalra, N., Stentz, A.: Market-based multirobot coordination:a survey and analysis. Proc. IEEE 94(7), 1257\u20131270 (2006)9. Ernst, A., Jiang, H., Krishnamoorthy, M.: Exact solutions to task allocation prob-lems. Manag. Sci. 52(10), 1634\u20131646 (2006)10. Fisher, D.M.: Distinguishing between taskwork and teamwork planning in teams:relations with coordination and interpersonal processes. J. Appl. Psychol. 99(3),423 (2014)11. Genter, K., Agmon, N., Stone, P.: Role-based ad hoc teamwork. In: Proceedingsof the Plan, Activity, and Intent Recognition Workshop at the Twenty-Fifth Con-ference on Artificial Intelligence (PAIR 2011), August 201112. Gerkey, B.P., Matari\u0107, M.J.: A formal analysis and taxonomy of task allocation inmulti-robot systems. Int. J. Robot. Res. 23(9), 939\u2013954 (2004)13. Gervits, F., Thurston, D., Thielstrom, R., Fong, T., Pham, Q., Scheutz, M.: Towardgenuine robot teammates: improving human-robot team performance using robotshared mental models. In: AAMAS, pp. 429\u2013437 (2020)14. Gunn, T., Anderson, J.: Effective task allocation for evolving multi-robot teamsin dangerous environments. In: 2013 IEEE/WIC/ACM International Joint Con-ferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT), vol.2, pp. 231\u2013238. IEEE (2013)15. Hauser, D., Paolacci, G., Chandler, J.: Common concerns with MTurk as a partic-ipant pool: evidence and solutions (2019)Evaluating Human and Agent Task Allocators 18316. Hayes-Roth, B.: A blackboard architecture for control. Artif. Intell. 26(3), 251\u2013321(1985)17. Kahneman, D.: Thinking, Fast and Slow. Macmillan, London (2011)18. Korsah, G.A., Stentz, A., Dias, M.B.: A comprehensive taxonomy for multi-robottask allocation. Int. J. Robot. Res. 32(12), 1495\u20131512 (2013)19. Kuhn, H.W.: The Hungarian method for the assignment problem. Naval Res.Logist. Q. 2(1\u20132), 83\u201397 (1955)20. Lai, V., Tan, C.: On human predictions with explanations and predictions ofmachine learning models: a case study on deception detection. In: Proceedingsof the Conference on Fairness, Accountability, and Transparency, pp. 29\u201338 (2019)21. Larson, L., DeChurch, L.A.: Leading teams in the digital age: four perspectiveson technology and what they mean for leading teams. Leadersh. Q. 31(1), 101377(2020)22. Lin, R., Gal, Y., Kraus, S., Mazliah, Y.: Training with automated agents improvespeople\u2019s behavior in negotiation and coordination tasks. Decis. Support Syst. (DSS)60, 1\u20139 (2014)23. Lott, C., McAuliffe, A., Kuttal, S.K.: Remote pair collaborations of CS students:leaving women behind? In: 2021 IEEE Symposium on Visual Languages andHuman-Centric Computing (VL/HCC), pp. 1\u201311. IEEE (2021)24. Mathieu, J.E., Hollenbeck, J.R., van Knippenberg, D., Ilgen, D.R.: A century ofwork teams in the Journal of Applied Psychology. J. Appl. Psychol. 102(3), 452(2017)25. Mathieu, J.E., Rapp, T.L.: Laying the foundation for successful team performancetrajectories: The roles of team charters and performance strategies. J. Appl. Psy-chol. 94(1), 90 (2009)26. McGrath, J.E.: Groups: Interaction and Performance, vol. 14. Prentice-Hall, Engle-wood Cliffs (1984)27. Mosteo, A.R., Montano, L.: A survey of multi-robot task allocation. Technicalreport, Instituto de Investigacin en Ingenier\u0142a de Aragn (I3A) (2010)28. Nunes, E., Manner, M., Mitiche, H., Gini, M.: A taxonomy for task allocationproblems with temporal and ordering constraints. Robot. Auton. Syst. 90, 55\u201370(2017)29. Patel, R., Rudnick-Cohen, E., Azarm, S., Otte, M., Xu, H., Herrmann, J.W.:Decentralized task allocation in multi-agent systems using a decentralized geneticalgorithm. In: 2020 IEEE International Conference on Robotics and Automation(ICRA), pp. 3770\u20133776. IEEE (2020)30. Perron, L., Furnon, V.: OR-tools. https://developers.google.com/optimization/31. Puranam, P., Alexy, O., Reitzig, M.: What\u2019s \u201cnew\u201d about new forms of organizing?Acad. Manag. Rev. 39(2), 162\u2013180 (2014)32. Ramchurn, S.D., et al.: HAC-ER: a disaster response system based on human-agentcollectives. In: Proceedings of the 2015 International Conference on AutonomousAgents and Multiagent Systems, pp. 533\u2013541. International Foundation forAutonomous Agents and Multiagent Systems, Richland (2015)33. Robinette, P., Wagner, A.R., Howard, A.M.: Building and maintaining trustbetween humans and guidance robots in an emergency. In: AAAI Spring Sym-posium: Trust and Autonomous Systems, Stanford, CA, pp. 78\u201383, March 201334. Rosenfeld, A., Agmon, N., Maksimov, O., Kraus, S.: Intelligent agent supportinghuman-multi-robot team collaboration. Artif. Intell. 252, 211\u2013231 (2017)35. Sanchez, R.P., Bartel, C.M., Brown, E., DeRosier, M.: The acceptability and effi-cacy of an intelligent social tutoring system. Comput. Educ. 78, 321\u2013332 (2014)184 S. Abuhaimed and S. Sen36. Shoham, Y., Leyton-Brown, K.: Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations. Cambridge University Press, Cambridge(2008)37. Zhao, W., Meng, Q., Chung, P.W.: A heuristic distributed task allocation methodfor multivehicle multitask problems and its application to search and rescue sce-nario. IEEE Trans. Cybern. 46(4), 902\u2013915 (2015)FLEUR: Social Values Orientationfor Robust Norm EmergenceSz-Ting Tzeng1(B), Nirav Ajmeri2, and Munindar P. Singh11 North Carolina State University, Raleigh, NC 27695, USA{stzeng,mpsingh}@ncsu.edu2 University of Bristol, Bristol BS8 1UB, UKnirav.ajmeri@bristol.ac.ukAbstract. By regulating agent interactions, norms facilitate coordina-tion in multiagent systems. We investigate challenges and opportunitiesin the emergence of norms of prosociality, such as vaccination and maskwearing. Little research on norm emergence has incorporated social pref-erences, which determines how agents behave when others are involved.We evaluate the influence of preference distributions in a society onthe emergence of prosocial norms. We adopt the Social Value Orientation(SVO) framework, which places value preferences along the dimensionsof self and other. SVO brings forth the aspects of values most relevantto prosociality. Therefore, it provides an effective basis to structure ourevaluation.We find that including SVO in agents enables (1) better social expe-rience; and (2) robust norm emergence.Keywords: Agent-based simulation \u00b7 Norm adherence \u00b7 Preferences \u00b7Social value orientation \u00b7 Ethics1 IntroductionWhat makes people make different decisions? Schwartz [23] defined ten funda-mental human values, and each of them reflects specific motivations. Besidesvalues, preferences define an individual\u2019s tendency to make a subjective selec-tion among alternatives. Whereas values are relatively stable, preferences aresensitive to context and constructed when triggered [25].In the real world, humans with varied weights of values evaluate the outcomesof their actions subjectively and act to maximize their utility [23]. In additionto values, an individual\u2019s social value orientation (SVO) influences the individ-ual\u2019s behaviors [30]. Whereas values define the motivational bases of behaviorsand attitudes of an individual [23], social value orientation indicates an individ-ual\u2019s preference for resource allocation between self and others [8]. Specifically,social value orientation provides stable subjective weights for making decisions[17]. When interacting with others is inevitable, one individual\u2019s behavior mayaffect another. SVO revises an individual\u2019s utility function by assigning differentweights to itself and others. Here is an example of a real-world case of SVO.c\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 185\u2013200, 2022.https://doi.org/10.1007/978-3-031-20845-4_12186 S.-T. Tzeng et al.Example 1. SVO.During a pandemic, the authorities announce a mask-wearing regulationand claim that regulation would help avoid infecting others or being infected.Although Felix tests positive on the pandemic and prefers not to wear a mask,he also cares about others\u2019 health. If he stays in a room with another healthyperson, Elliot, Felix will put the mask on.An agent is an autonomous, adaptive, and goal-driven entity [22]. Whereasmany works assume agents consider the payoff of themselves, humans may fur-ther consider social preferences in the real world. e.g., payoffs of others or socialwelfare [5]. When humans are in the loop along with software, there are emerg-ing need to consider human factors when building modern software and systems.These systems should consider human values and be capable of reasoning overhumans\u2019 behaviors to be realistic and trustworthy.In a multiagent system, social norms or social expectations [2,21] are societalprinciples that regulate our behavior towards one another by measuring ourperceived psychological distance. Humans evaluate social norms based on humanvalues. Most previous works related to norms do not consider human values andassume regimented environments. However, humans are capable of deliberatelyadhering to or violating norms. Previous works on normative agents considerhuman values and theories on sociality [4,31] in decision-making process. SVOas an agent\u2019s preference in a social context has not been fully explored.Contributions. We investigate the following research question.RQSVO. How do the preferences for others\u2019 rewards influence norm compli-ance?To address RQSVO, we develop Fleur, an agent framework that considersvalues, personal preferences, and social norms when making decisions. Our pro-posed framework Fleur combines world model, cognitive model, emotion model,and social model. Since values are abstract and need further definition, we startwith social value orientations, the stable preferences for resource allocation, inthis work. Specifically, Fleur agents take into account social value orientationin utility calculation.Findings. We evaluate Fleur via an agent simulation of a pandemic scenariodesigned as an iterated single-shot and intertemporal social dilemma game. Wemeasure compliance, social experiences, and invalidation during the simulation.We find that the understanding of SVO helps agents to make more ethical deci-sions.Organization. Section 2 presents the related works. Section 3 describes theschematics of Fleur. Section 4 details the simulation experiments we conductand the results. Section 5 presents our conclusion and directions for future exten-sions.Fleur: Social Values Orientation for Robust Norm Emergence 1872 Related WorksGriesinger and Livingston Jr. [8] present a geometric model of SVO, the socialvalue orientation ring as Fig. 2. Van Lange [30] proposes a model and interpretsprosocial orientation as enhancing both joint outcomes and equality in the out-comes. Declerck and Bogaert [6] describe social value orientation as a personalitytrait. Their work indicates that prosocial orientation positively correlates withadopting others\u2019 viewpoints and the ability to infer others\u2019 mental states. On thecontrary, an individualistic orientation shows a negative correlation with thesesocial skills. Fleur follows the concepts of social preferences from [8].Szekely et al. [26] show that high risk promotes robust norms, which havehigh resistance to risk change. de Mooij et al. [15] build a large-scale data-driven agent-based simulation model to simulate behavioral interventions amonghumans. Each agent reasons over their internal attitudes and external factorsin this work. Ajmeri et al. [3] show that robust norms emerge among interac-tions where deviating agents reveal their contexts. This work enables agents toempathize with other agents\u2019 dilemmas by revealing contexts. Instead of shar-ing contexts, values, or preferences, Fleur approximates others\u2019 payoff withobservation. Serramia et al. [24] consider shared values in a society with normsand focus on making ethical decisions that promote the values. Ajmeri et al. [4]propose an agent framework that enables agents to aggregate the value prefer-ences of stakeholders and make ethical decisions accordingly. This work takesother agents\u2019 values into account when making decisions. Mosca and Such [16]describe an agent framework that aggregates the shared preferences and moralvalues of multiple users and makes the optimal decisions for all users. Kalia et al.[10] investigate the relationship between norm outcomes and trust and emotions.Tzeng et al. [29] consider emotions as sanctions. Specifically, norm satisfactionor norm violation may trigger self-directed and other-directed emotions, whichfurther enforce social norms. Dell\u2019Anna et al. [7] propose a mechanism to regu-late a multiagent system by revising the sanctions at runtime to achieve runtimenorm enforcement. Agrawal et al. [1] provide and evaluate explicit norms andexplanations. Winikoff et al. [33] construct comprehensible explanations withbeliefs, desires, and values. Kurtan and Yolum [11] estimate privacy values withexisting shared images in a user\u2019s social network. Tielman et al. [27] derivenorms based on values and contexts. However, these works do not consider thedifferences between agents and the influences of an individual\u2019s behavior on oth-ers. Mashayekhi et al. [13] model guilt based on inequity aversion theory for anindividual perspective on prosociality. In addition, they consider justice froma societal perspective on prosociality. Whereas Mashayekhi et al. [13] assumeagents may be self-interested and their decisions may be affected by others\u2019performance, Fleur investigates the influence of social value orientations.Table 1 summarizes related works on ethical agents. Adaptivity describesthe capability of responding to different contexts. Empathy defines the abilityto consider others\u2019 gain. The information share indicates information sharingamong agents. The information model describes the applied models to processinformation and states. Among varied information models, contexts describe the188 S.-T. Tzeng et al.situation in which an agent stands. Emotions are the responses to internal orexternal events or objects. Guilt is an aversive self-directed emotion. Explicitnorms state causal normative information, including antecedents and conse-quences. Values and preferences both define desirable or undesirable states.Table 1. Comparisons of works on ethical agents with norms and values.Research Adaptivity Empathy Information share Information modelFleur \u2713 \u2713 \u2717 Preferences & Emotions & ContextsAgrawal et al. [1] \u2713 \u2717 \u2713 Explicit normsAjmeri et al. [3] \u2713 \u2713 \u2713 ContextsAjmeri et al. [4] \u2713 \u2713 \u2713 Values & Value preference & ContextsKalia et al. [10] \u2713 \u2717 \u2717 Trust & EmotionsKurtan and Yolum [11] \u2713 \u2717 \u2717 ValuesMashayekhi et al. [13] \u2713 \u2713 \u2713 GuiltMosca and Such [16] \u2713 \u2713 \u2713 Preferences & ValuesSerramia et al. [24] \u2713 \u2717 \u2717 ValuesTielman et al. [27] \u2713 \u2717 \u2713 Values & ContextsTzeng et al. [29] \u2717 \u2717 \u2717 EmotionsWinikoff et al. [33] \u2713 \u2717 \u2717 Values & Beliefs & Goals3 FLEURWe now discuss the schematics of Fleur agents.Figure 1 shows the architecture of Fleur. Fleur agents consists of five maincomponents: cognitive model, emotion model, world model, social model, and adecision module.3.1 Cognitive ModelCognition relates to conscious intellectual activities, such as thinking, reason-ing, or remembering, among which human values and preferences are essen-tial. Specifically, values and preferences may change how an individual evaluatesan agent, an event, or an object. In Fleur, We start with including humanpreferences. While preferences are the attitudes toward a set of objects in psy-chology [25], individual and social preferences provide intrinsic rewards. Forinstance, SVO provides agents with different preferences over resource alloca-tions between themselves and others. Figure 2 demonstrates the reward distri-bution of different SVO types. The horizontal axis measures the resources allo-cated to oneself, and the vertical axis measures the resources allocated to others.Fleur: Social Values Orientation for Robust Norm Emergence 189Fig. 1. Fleur architecture.Let\u2212\u2192R = (r1, r2, . . . , rn) represent the reward vector for a group of agents withsize n. The reward for agent i considering social aspect is:rewardi = ri \u00b7 cos \u03b8 + r\u2212i \u00b7 sin \u03b8 (1)where ri represents the reward for agent i and r\u2212i is the mean reward of all otheragents interacting with agent i. Here we adopt the reward angle in [14] and rep-resent agents\u2019 social value orientation with \u03b8. We define \u03b8 \u2208 {90\u25e6, 45\u25e6, 0\u25e6,\u221245\u25e6}as SVO \u2208 {altruistic, prosocial, individualistic, competitive}, respectively. Withthe weights provided by SVO, the presented equation enables the accommoda-tion of social preferences.In utility calculation, we consider two components: (1) extrinsic reward and(2) intrinsic reward. Whereas extrinsic rewards come from the environment,intrinsic rewards stem from internal stats, e.g., human values and preferences.We extend the Belief-Desire-Intention (BDI) architecture [20]. An agentforms beliefs based on the information from the environment. The desire ofan agent represents having dispositions to act. An agent\u2019s intention is a plan oraction to achieve a selected desire.Take Example 1 for instance. Since Felix has an intention to maximize thejoint gain with Elliot, he may choose a strategy to not increase his payoff at thecost of others\u2019 sacrifice.190 S.-T. Tzeng et al.Fig. 2. Representation of Social Value Orientation [8,14]. ri denotes outcome for oneselfand r\u2212i denotes outcomes for others.3.2 Emotion ModelWe adopt the OCC model of emotions [19]. Specifically, our emotion modelappraises an object, an action, or an event and then triggers emotions. We con-sider emotional valence and assume norm satisfaction or norm violation yieldspositive or negative emotions if self behaviors align with the norms.3.3 World ModelThe world model describes the contexts in which Fleur agents stand and repre-sents the general knowledge Fleur agents possess. A context is a scenario thatan agent faces. Knowledge in this model are facts of the world. In Example 1, thecontext is that an infected individual, Felix, seeks to maximize the collective gainof himself and a healthy individual, Elliot. In the meantime, Felix acknowledgesthat a pandemic is ongoing.3.4 Social ModelThe social model of an agent includes social values, normative reasoning, andnorm fulfillment. Social values define standards that individuals and groupsemploy to shape the form of social order [28], e.g., fairness and justice. Agentsuse the normative-reasoning component to reason over states, norms, and possi-ble outcomes of satisfying or violating norms. Norm fulfillment checks if a normFleur: Social Values Orientation for Robust Norm Emergence 191has been fulfilled or violated with the selected action. Sanctions may come afternorm fulfillments or violations.3.5 Decision ModuleThe decision module selects actions based on agents\u2019 payoffs and individualvalues. We apply Q-Learning [32], a model-free reinforcement learning algorithmthat learns from trial and error, to our agents. Q-Learning approximates theaction-state value Q(s, a) (Q value), with each state and action:Q\u2032(st, at) = Q(st, at) + \u03b1 \u2217 (Rt + \u03b3 maxa\u2032Q(st+1, a) \u2212 Q(st, at)) (2)where Q\u2032(st, at) represents the updated Q-value after performing action a at timet and st+1 represents the next state. \u03b1 denotes the learning rate in the Q-valueupdate function, and Rt represents the rewards received at time t after acting a.\u03b3 defines the reward discount rate, which characterizes the importance of futurerewards. Agents observe the environment, form their beliefs about the world,and update their state-value with rewards via interactions. By approximatingthe action-state value, the Q-Learning algorithm finds the optimal policy via theexpected and cumulative rewards.Algorithm 1 describes the agent interaction in our simulation.Algorithm 1: Decision loop of a Fleur agent1 Initialize one agent with its desires D and preference P and SVO angle \u03b8;2 Initialize action-value function Q with random weights w;3 for t=1,T do4 Pair up with another agent pn to interact with;5 Observe the environment (including the partner and its \u03b8) and form beliefsbt;6 With a probability \u03b5 select a random action atOtherwise select at = argmaxaQ(bt, a; w)7 Execute action at and observe reward rt;8 Observe the environment (including the partner) and form beliefs bt+1;9 Activate norms N with beliefs bt, bt+1, and action at;10 if N ! = \u2205 then11 Sanction the partner based on at and its behavior;12 end13 end4 ExperimentsWe now describe our experiments and discuss the results.192 S.-T. Tzeng et al.4.1 Experimental Scenario: Pandemic Mask RegulationWe build a pandemic scenario as an iterated single-shot and intertemporal socialdilemma. We assume that the authorities have announced a masking regulation.In each game, each agent selects from the following two actions: (1) wear amask, and (2) not wear a mask. Each agent has its inherent preferences andsocial value orientation. An agent forms a belief about its partner\u2019s health basedon its observation. During the interaction, the decision an agent makes affectsitself and others. The collective behaviors among agents determine the dynamicsin a society. Each agent receives the final points from its own action and effectsfrom others: Rsum = Pi self + Pi other + Sj . Pi self denotes the payoff from theaction that agent i selects considering the reward distribution in Fig. 2 and self-directed emotions. Pi other is the payoff from the action that the other agentperforms. Sj denotes the other-directed emotions from others towards agent i.Table 2. Payoff for an actor and its partner based on how the actor acts and how itsaction influence others. Column Actors show the points from the actions of the actor.Column Partners display the points from the actions to the partner.Health ActionsActor Partner Mask No maskActor Partner Actor PartnerHealthy Healthy 0.00 0.00 0.00 0.00Healthy Infected 1.00 0.00 \u22121.00 0.00Infected Healthy 0.00 1.00 0.00 \u22121.00Infected Infected 0.50 0.50 \u22120.50 \u22120.50Table 3. Payoff for decisions on preferencesType DecisionsSatisfy DissatisfyPreference 0.50 0.004.2 Experimental SetupWe develop a simulation using Mesa [12], an agent-based modeling frameworkin Python for creating, visualizing, and analyzing agent-based models. We ranthe simulations on a device with 32 GB RAM and GPU NVIDIA GTX 1070 Ti.We evaluated Fleur via a simulated pandemic scenario where agents\u2019 behav-iors influence the collective outcome of the social game. A game-theoretical set-ting may be ideal for validating the social dilemma with SVO and norms. How-ever, real-world cases are usually non-zero-sum games where one\u2019s gain does notalways lead to others\u2019 loss. In our scenario, depending on the context, the sameFleur: Social Values Orientation for Robust Norm Emergence 193Table 4. Payoff for decisions on normsActor PartnerWear Not-WearWear 0.10 \u22120.10Not-Wear 0.00 0.10action may lead to different consequences for the agent itself and its partner. Forinstance, when an agent is healthy and its partner is infected, wearing a maskgives the agent a positive payoff from the protection of the mask but no payofffor its partner. Conversely, not wearing a mask leads to a negative payoff for theagent and no payoff for its partner. The payoff given to the agent and its partnercorresponds to the X and Y axis in Fig. 2. When formalizing social interactionswith SVO in game-theoretical settings, the payoffs of actions for an agent andothers are required information.We incorporated beliefs and desires, and intentions into our agents. An agentobserves its environment and processes its perception, and forms its beliefs aboutthe world. In each episode, agents pair up to interact with one another andsanction based on their and partners\u2019 decisions (Table 4).Context. A context is composed of attributes from an agent and others and theenvironment as shown in Table 2. We frame the simulation as a non-zero-sumgame where one\u2019s gain does not necessarily lead to the other parties\u2019 loss.Preference. In psychology, preferences refer to an agent\u2019s attitudes towards aset of objects. In our simulation, we set 40% of agents to prefer to wear andprefer not to masks individually. The rest of the agents have a neutral attitudeon masks. The payoffs for following the preferences are listed in Table 3.Social Value Orientation. Social value orientation defines an agent\u2019s prefer-ence for allocating resources between itself and others. We consider altruistic,prosocial, individualistic, and competitive orientations selected from Fig. 2.4.3 Hypotheses and MetricsWe compute the following measures to address our research question RQSVO.Compliance. The percentage of agents who satisfy normsSocial Experience. The total payoff of the agents in a societyInvalidation. The percentage of agents who do not meet their preferences in asocietyTo answer our research question RQSVO, we evaluate three hypotheses thatcorrespond to the specific metric, respectively.194 S.-T. Tzeng et al.HCompliance: Preferences for others\u2019 rewards positively affect norm compliancewith prosocial normsHSocial Experience: The distribution of preferences for others\u2019 rewards positivelyaffect social experiences in a societyHInvalidation: Preferences for others\u2019 rewards negatively affect the tendency tomeet personal preferences4.4 ExperimentsWe ran a population of N = 40 agents in which we equally distributed ourtargeted SVO types: altruistic, prosocial, individualistic, and competitive. Sinceeach game is a single-shot social dilemma, we consider each game as an episode.The training last for 500,000 episodes. In evaluation, we run 100 episodes andcompute the mean values to minimize deviation from coincidence. We define ourfive societies as below.Mixed society. A society of agents with mixed social value orientation distri-butionAltruistic society. A society of agents who make decisions based on altruisticconcernsProsocial society. A society of agents who make decisions based on prosocialconcernsSelfish society. A society of agents who make decisions based on selfish concernsCompetitive society. A society of agents who make decisions based on com-petitive concernsWe assume all agents are aware of a mask-wearing norm. Agents who satisfythe norm receive positive emotions from themselves and others, as in Table 4.Conversely, norm violators receive negative emotions. Table 5 summarizes resultsof our simulation.Figure 3 displays the compliance, the percentage of agents who satisfy norms,in the mixed and baseline-agent societies. We find that the compliance in thealtruistic and prosocial-agent society, averaging at 69.70% and 70.25%, is higherthan in the mixed (63.34%) and agent societies have no positive weights onothers\u2019 payoff (65.10% and 54.08% for selfish and competitive-agent societies,respectively). The differences in the results of altruistic and prosocial-agent soci-eties are statistically significant with medium effect (p < 0.001; Glass\u2019 \u0394 > 0.5).Conversely, the competitive-agent society has the least compliance, averaging at54.08%, with p < 0.001 and Glass\u2019 \u0394 > 0.8. The results of the selfish-agent soci-ety (65.10%) shows no significant difference with p > 0.05 and Glass\u2019 \u0394 \u2248 0.2.There are 25% of agents in the mixed-agent society are competitive agents.Specifically, they prefer to minimize others\u2019 payoff. A competitive infected agentmay choose not to wear a mask when interacting with other healthy agents inthis scenario. In the meantime, the selfish agents would maximize their self utilitywithout considering others. Therefore, the behaviors of selfish and competitiveagents may decrease compliance in the mixed-agent society.Fleur: Social Values Orientation for Robust Norm Emergence 195Table 5. Comparing agent societies with different social value orientation distributionon various metrics and their statistical analysis with Glass\u2019 \u0394 and p-value. Each metricrow shows the numeric value of the metric after simulation convergence.Compliance Social experience InvalidationSmixed Results 63.40% 0.448 3 0.296 0p-value \u2212 \u2212 \u2212\u0394 \u2212 \u2212 \u2212Saltruistic Results 69.70% 0.554 3 0.3340p-value < 0.001 < 0.001 < 0.001\u0394 0.660 2 0.611 6 0.463 5Sprosocial Results 70.25% 0.5656 0.322 8p-value < 0.001 < 0.001 < 0.05\u0394 0.717 8 0.677 1 0.326 3Sselfish Results 65.10% 0.469 5 0.269 0p-value 0.218 0 0.424 5 < 0.05\u0394 0.178 1 0.122 1 0.329 3Scompetitive Results 54.08% 0.220 8 0.288 8p-value < 0.001 < 0.001 0.541 2\u0394 0.977 2 1.313 1 0.088 4Fig. 3. Compliance in training phase: The percentage of norm satisfaction in a society.Figure 4 compares the average payoff in the mixed and baseline-agent soci-eties. The social experience in the altruistic and prosocial-agent society, averag-ing at 0.5543 and 0.5656, is higher than in the mixed (0.4483) and agent societies196 S.-T. Tzeng et al.Fig. 4. Social Experience in training phase: The total payoff of the agents in a society.have no positive weights on others\u2019 payoff (46.95% and 22.08% for selfish andcompetitive-agent societies, respectively). The differences in the results of altru-istic and prosocial-agent societies are statistically significant with medium effect(p < 0.001; Glass\u2019 \u0394 > 0.5). On the contrary, the competitive-agent societyhas the least social experience, averaging at 0.2208, with p < 0.001 and Glass\u2019\u0394 > 0.8. The results of the selfish-agent society (0.4695) shows no significantdifference with p > 0.05 and Glass\u2019 \u0394 < 0.2.The mixed-agent society shows similar results as the selfish-agent society.Although 50% of the mixed-agent society agents are altruistic and prosocial,the competitive agents would choose to minimize others\u2019 payoff without hurtingtheir self-interests. Since the selfish agents do not care about others, they wouldact for the sake of their benefit. The selfish and competitive behaviors diminishthe social experiences in society.Figure 5 compares invalidation, the percentage of agents who do not meettheir preferences in the mixed and baseline-agent societies.The invalidation in the altruistic and prosocial-agent society, averaging at33.40% and 32.28%, is higher than in the mixed (29.60%) and agent societieshave no positive weights on others\u2019 payoff (26.90% and 28.88% for selfish andcompetitive-agent societies, respectively). The differences in the results of altruis-tic and prosocial-agent societies are statistically significant with small or mediumeffect (p < 0.001; Glass\u2019 \u0394 > 0.2). On the contrary, the selfish-agent society hasthe least invalidation, average at 26.90%, with p < 0.05 and Glass\u2019 \u0394 > 0.2. Theresults of the competitive-agent society (28.88%) shows no significant differencewith p > 0.05 and Glass\u2019 \u0394 < 0.2.While agents who consider others\u2019 rewards positively achieve better compli-ance and social experiences, these achievements are based on their sacrifice ofFleur: Social Values Orientation for Robust Norm Emergence 197Fig. 5. Invalidation in training phase: The percentage of agents who do not meet theirpreferences in a society.preferences. The altruistic and prosocial agent societies have the most percentageof agents who do not meet their preferences.4.5 Threats to ValidityFirst, our simulation has a limited action space. Moreover, different actions mayhave the same payoff in some contexts. Other behaviors may better describedifferent types of SVO, yet our focus is on showing how SVO influences normativedecisions.Second, we represent actual societies as simulations. While differences inpreference and SVO among people are inevitable, we focus on validating theinfluence of SVO.Third, to simplify the simulation, we assume fixed interaction, whereas real-world interactions tend to be random. An agent may interact with one anotherin the same place many times or have no interaction. We randomly pair up allagents to mitigate this threat and average out the results.5 Conclusions and DirectionsWe present an agent architecture that integrates cognitive architecture, worldmodel, and social model to investigate how social value orientation influencescompliance with norms. We simulate a pandemic scenario in which agents makedecisions based on their individual and social preferences. The simulations showthat altruistic and prosocial-agent societies comply better with the mask normand bring out higher social experiences. However, altruistic and prosocial agentstrade their personal preferences for compliance and social experiences. The198 S.-T. Tzeng et al.results between the mixed and selfish-agent societies show no considerable dif-ference. The competitive agents in the mixed-agent society may take the respon-sibility.Future DirectionsOur possible extensions include investigating an unequal distribution of SVOin Fleur and applying real-world data in the simulation. Other future direc-tions are incorporating values into agents, and revealing adequate informationto explain and convince others of inevitable normative deviations [1,18,34].Acknowledgments. STT and MPS thank the US National Science Foundation (grantIIS-2116751) for support.References1. Agrawal, R., Ajmeri, N., Singh, M.P.: Socially intelligent genetic agents for theemergence of explicit norms. In: Proceedings of the 31st International Joint Con-ference on Artificial Intelligence (IJCAI), pp. 1\u20137. IJCAI, Vienna (2022)2. Ajmeri, N., Guo, H., Murukannaiah, P.K., Singh, M.P.: Arnor: modeling socialintelligence via norms to engineer privacy-aware personal agents. In: Proceedings ofthe 16th International Conference on Autonomous Agents and MultiAgent Systems(AAMAS), pp. 230\u2013238. IFAAMAS, Sa\u0303o Paulo (2017). https://doi.org/10.5555/3091125.30911633. Ajmeri, N., Guo, H., Murukannaiah, P.K., Singh, M.P.: Robust norm emergenceby revealing and reasoning about context: Socially intelligent agents for enhanc-ing privacy. In: Proceedings of the 27th International Joint Conference on Artifi-cial Intelligence (IJCAI), pp. 28\u201334. IJCAI, Stockholm (2018). https://doi.org/10.24963/ijcai.2018/44. Ajmeri, N., Guo, H., Murukannaiah, P.K., Singh, M.P.: Elessar: ethics in norm-aware agents. In: Proceedings of the 19th International Conference on AutonomousAgents and MultiAgent Systems (AAMAS), pp. 16\u201324. IFAAMAS, Auckland(2020). https://doi.org/10.5555/3398761.33987695. Charness, G., Rabin, M.: Understanding social preferences with simple tests. Q. J.Econ. 117(3), 817\u2013869 (2002)6. Declerck, C.H., Bogaert, S.: Social value orientation: related to empathy and theability to read the mind in the eyes. J. Social Psychol. 148(6), 711\u2013726 (2008).https://doi.org/10.3200/SOCP.148.6.711-7267. Dell\u2019Anna, D., Dastani, M., Dalpiaz, F.: Runtime revision of norms and sanctionsbased on agent preferences. In: Proceedings of the 18th International Conferenceon Autonomous Agents and MultiAgent Systems (AAMAS), pp. 1609\u20131617. IFAA-MAS (2019). https://doi.org/10.5555/3306127.33318818. Griesinger, D.W., Livingston Jr., J.W.: Toward a model of interpersonal motiva-tion in experimental games. Behav. Sci. 18(3), 173\u2013188 (1973). https://doi.org/10.1002/bs.38301803059. Huhns, M.N., Singh, M.P. (eds.): Readings in Agents. Morgan Kaufmann, SanFrancisco (1998). ISBN 9780080515809Fleur: Social Values Orientation for Robust Norm Emergence 19910. Kalia, A.K., Ajmeri, N., Chan, K., Cho, J.H., Adal\u0131, S., Singh, M.P.: The interplayof emotions and norms in multiagent systems. In: Proceedings of the 28th Inter-national Joint Conference on Artificial Intelligence (IJCAI), pp. 371\u2013377. IJCAI,Macau (2019). https://doi.org/10.24963/ijcai.2019/5311. Kurtan, A.C., Yolum, P.: Assisting humans in privacy management: an agent-basedapproach. Auton. Agents Multi-Agent Syst. 35(1), 1\u201333 (2020). https://doi.org/10.1007/s10458-020-09488-112. Masad, D., Kazil, J.: MESA: an agent-based modeling framework. In: Proceedingsof the 14th PYTHON in Science Conference, pp. 53\u201360 (2015)13. Mashayekhi, M., Ajmeri, N., List, G.F., Singh, M.P.: Prosocial norm emergence inmultiagent systems. ACM Trans. Auton. Adapt. Syst. (TAAS) 17, 1\u201324 (2022)14. McKee, K.R., Gemp, I.M., McWilliams, B., Due\u0301n\u0303ez-Guzma\u0301n, E.A., Hughes, E.,Leibo, J.Z.: Social diversity and social preferences in mixed-motive reinforcementlearning. In: Proceedings of the 19th International Conference on AutonomousAgents and Multiagent Systems (AAMAS), pp. 869\u2013877. IFAAMAS, Auckland(2020). https://doi.org/10.5555/3398761.339886315. de Mooij, J., Dell\u2019Anna, D., Bhattacharya, P., Dastani, M., Logan, B., Swarup,S.: Quantifying the effects of norms on COVID-19 cases using an agent-basedsimulation. In: Van Dam, K.H., Verstaevel, N. (eds.) MABS 2021. LNCS (LNAI),vol. 13128, pp. 99\u2013112. Springer, Cham (2022). https://doi.org/10.1007/978-3-030-94548-0 816. Mosca, F., Such, J.M.: ELVIRA: an explainable agent for value and utility-driven multiuser privacy. In: Proceedings of the 20th International Conference onAutonomous Agents and Multiagent Systems (AAMAS), pp. 916\u2013924. IFAAMAS,London (2021). https://doi.org/10.5555/3463952.346406117. Murphy, R.O., Ackermann, K.A.: Social value orientation: theoretical and mea-surement issues in the study of social preferences. Pers. Social Psychol. Rev. 18(1),13\u201341 (2014). https://doi.org/10.1177/108886831350174518. Murukannaiah, P.K., Ajmeri, N., Jonker, C.M., Singh, M.P.: New foundations ofethical multiagent systems. In: Proceedings of the 19th International Conferenceon Autonomous Agents and MultiAgent Systems (AAMAS), pp. 1706\u20131710. IFAA-MAS, Auckland (2020). https://doi.org/10.5555/3398761.3398958, Blue Sky IdeasTrack19. Ortony, A., Clore, G.L., Collins, A.: The Cognitive Structure of Emo-tions. Cambridge University Press, New York (1988). https://doi.org/10.1017/CBO978051157129920. Rao, A.S., Georgeff, M.P.: Modeling rational agents within a BDI-architecture. In:Proceedings of the International Conference on Principles of Knowledge Represen-tation and Reasoning, pp. 473\u2013484 (1991). reprinted in [9]21. Rummel, R.J.: Understanding Conflict and War: Vol. 1: The Dynamic Psycholog-ical Field. Sage Publications, Thousand Oaks (1975)22. Russell, S., Norvig, P.: Artificial Intelligence: A Modern Approach, 3rd edn. Pren-tice Hall, Upper Saddle River (2010)23. Schwartz, S.H.: An overview of the schwartz theory of basic values. Online Read.Psychol. Cult. 2(1), 0919\u20132307 (2012). https://doi.org/10.9707/2307-0919.111624. Serramia, M., et al.: Moral values in norm decision making. In: Proceedings ofthe 17th Conference on Autonomous Agents and MultiAgent Systems (AAMAS),pp. 1294\u20131302. IFAAMAS, Stockholm (2018). https://doi.org/10.5555/3237383.323789125. Slovic, P.: The construction of preference. Am. Psychol. 50(5), 364 (1995). https://doi.org/10.1037/0003-066X.50.5.364200 S.-T. Tzeng et al.26. Szekely, A., et al.: Evidence from a long-term experiment that collective riskschange social norms and promote cooperation. Nat. Commun. 12, 5452:1\u20135452:7(2021). https://doi.org/10.1038/s41467-021-25734-w27. Tielman, M.L., Jonker, C.M., Van Riemsdijk, M.B.: Deriving norms from actions,values and context. In: Proceedings of the 18th International Conference onAutonomous Agents and MultiAgent Systems, pp. 2223\u20132225 (2019). https://doi.org/10.5555/3306127.333206528. Tsirogianni, S., Sammut, G., Park, E.: Social Values and Good Living. Springer,Netherlands (2014). https://doi.org/10.1007/978-94-007-0753-5 366629. Tzeng, S.T., Ajmeri, N., Singh, M.P.: Noe: norms emergence and robustness basedon emotions in multiagent systems. In: Pre-proceedings of the International Work-shop on Coordination, Organizations, Institutions, Norms and Ethics for Gover-nance of Multi-Agent Systems (COINE), London, pp. 1\u201317 (2021). https://arxiv.org/abs/2104.1503430. Van Lange, P.A.M.: The pursuit of joint outcomes and equality in outcomes: anintegrative model of social value orientation. J. Pers. Social Psychol. 77(2), 337\u2013349(1999). https://doi.org/10.1037/0022-3514.77.2.33731. Verhagen, H.J.: Norm autonomous agents. Ph.D. thesis, Stockholm Universitet(2000)32. Watkins, C.J., Dayan, P.: Q-learning. Mach. Learn. 8(3\u20134), 279\u2013292 (1992).https://doi.org/10.1007/BF0099269833. Winikoff, M., Sidorenko, G., Dignum, V., Dignum, F.: Why bad coffee? explainingBDI agent behaviour with valuings. Artif. Intell. 300, 103554 (2021). https://doi.org/10.1016/j.artint.2021.10355434. Woodgate, J., Ajmeri, N.: Macro ethics for governing equitable sociotechnical sys-tems. In: Proceedings of the 21st International Conference on Autonomous Agentsand Multiagent Systems (AAMAS), pp. 1824\u20131828. IFAAMAS, Online (2022).https://doi.org/10.5555/3535850.3536118, Blue Sky Ideas TrackReasoning About Collective Action in MarkovLogic: A Case Study from Classical AthensSriashalya Srivathsan1(B), Stephen Cranefield1(B), and Jeremy Pitt21 University of Otago, Dunedin, New Zealandashal.srivathsan@postgrad.otago.ac.nz, stephen.cranefield@otago.ac.nz2 Imperial College London, London, UKj.pitt@imperial.ac.ukAbstract. Solving the collective action problem is to understand how peopledecide to act together for the common good when individual rationality wouldlead to non-cooperative selfish behaviour. Two important features that can fostercollective action are achieving common knowledge about the problem faced andthe existence of a shared cooperative ethos. Based on the work of Ober, whoargued that the success of classical Athens was the result of its shared com-mitments, social values and specific procedural rules, we define a probabilisticmodel in Markov Logic of a specific prosecution against an Athenian trader whoneglected to contribute to the city when it was in a crisis. In order to join togetherfor a common good, our model focuses on a decision-making approach based onreasoning about common knowledge. For example, knowledge about the ethos ofthe court towards convicting traitors can be seen as common knowledge gainedfrom public monuments recording these verdicts. We expect that our computa-tional model of this case study can be generalised to other problems of reasoningabout collective action based on common knowledge in future work.Keywords: Common knowledge \u00b7 Collective action \u00b7 Markov Logic Networks1 IntroductionSolving the collective action problem is to understand how people act together for thecommon good. Collectively reducing the emission of greenhouse gases [19] and manag-ing common pool resources [17] are two examples of environmental collective actions.Solving collective action problems is important to overcome various social and environ-mental problems. Collective action requires communication, organisation, and incen-tives that motivate everyone to work together for the common good. Existing studies[17,18] introduce strategies and solutions to tackle these problems. While traditionalsolution concepts from game theory [14], such as the Nash equilibrium [9] suggestthat collective action is irrational, Holzinger [10] discusses various solutions includ-ing norms, rules and sanctions. Besides common knowledge, expectations and crediblecommitment also motivates people to join together for collective action.Political scientist Josiah Ober [16] discusses the role of common knowledge inmaking people join collective actions in classical Athens. He argues that Athens wassocially, politically and militarily successful compared to rival states because of a supe-rior ability to achieve shared commitments, shared social values and procedural rulesc\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 201\u2013212, 2022.https://doi.org/10.1007/978-3-031-20845-4_13202 S. Srivathsan et al.through common knowledge. In particular, a specific trial discussed by him has a lotof richness and information regarding the cooperation and social structure in terms ofcommon knowledge. Therefore, we adopt this as a case study of the role of commonknowledge in achieving collective action.The trial was against an Athenian trader named Leocrates. It was alleged that heabandoned the city when it needed help to defend and reconstruct it after a battle hadbeen lost with the Macedonians. Lycurgus, a famous Athenian politician, prosecutedthis trial with the intention of convincing the jurors to convict Leocrates for the capitalcharge of treason. A record exists of the narrative Lycurgus gave to persuade jurors ofthe importance of convicting Leocrates.The trial is an interesting case study in which we found the prosecutor\u2019s points con-vey the importance of common knowledge in fostering the collective goal of having asecure city and how the result of this trial will impact the security of the city. Therefore,we are interested in implementing a computational model using common knowledgeto find how agents would make decisions based on a logical encoding of some of thearguments made by the prosecutor.We consider several sources that lead to attaining common knowledge: the commu-nity acceptance of a collective goal through observation of an alignment cascade [22],measures of common knowledge about social attitudes to the collective goal throughempirical observations, and observing states of affairs that satisfy four conditions iden-tified by Lewis [13] as giving rise to common knowledge.As Markov logic networks (MLNs) [5] express knowledge explicitly, and also helprepresenting beliefs of a probabilistic nature, we use an MLN to model this trial. Forexample, a belief that a certain proportion of citizens are cooperative with city-widegoals is probabilistic in nature, based on an estimate of the percentage of cooperators.The paper is structured as follows: The concept of common knowledge is discussedin Sect. 2, along with how it will be helpful to achieve a common goal. The discussionin Sect. 3 centers on points in terms of common knowledge made by Lycurgus duringthe trial of Leocrates. As the trial is modelled using a Markov Logic Network (MLN),Sect. 4 provides an overview of MLNs. A description of how this trial was modelledas an MLN is provided in detail in Sect. 5. Section 6 discusses how the model can bequeried to inform the decision of a juror in the trial. Section 7 concludes the paper.2 Common KnowledgeA range of studies discuss the importance of knowledge alignment in bringing peopletogether. In fact, knowledge and action are intimately connected. In most situations,people act according to what they think. The term \u2018common knowledge\u2019 refers \u201cknowl-edge of what other people know about other people\u2019s knowledge\u201d [4]. According toKuhlman et al., [12] \u201cSuccessful coordination requires that people know each others\u2019willingness to participate, and that this information is common knowledge among a suf-ficient number of people\u201d. This involves infinite information transmission levels whichcan be explained [13] as:\u2013 I know something; you know something\u2013 I know that you know; you know that I knowReasoning About Collective Action in Markov Logic 203\u2013 I know that you know that I know\u2013 You know that I know that you know; and so on ...However, this infinite reflection is not how common knowledge is obtained inpractice. Achieving common knowledge requires collective awareness and collectiveattention. Social coordination revolves around the achievement of common knowledgethrough group attention. From knowing where to find your partners, to communicatingwith them, to resolving public goods dilemmas, to following social norms, success insocial interactions often depends on collective awareness [21].The emergence of common knowledge occurs when people receive informationsimultaneously and publicly, when it becomes obvious that \u201cwe are attending\u201d [20].The places and events that make maximum eye contact [4] will create common knowl-edge. Transparent information provides no reason to doubt others\u2019 awareness of anobject or event. It refers especially to the dissemination of information in public con-texts (e.g., dinner tables, amphitheaters, stadiums, and town squares), or through publictechnologies (e.g., microphones, telephones, television, and social media) [21].Ober [16] discusses how common knowledge was used in classical Athens to collectpeople for a common goal. Public rituals for honouring war heroes and monumentscontaining the list of traitors were a medium for spreading common knowledge thatevery citizen should act for the good of the city. Athenians used certain specific signsin temples to convey important messages to their citizens. Festivals were organized sothat every citizen was forced to pass through them. The assumption was that if the signswere placed in public places, everyone will be able to see them.During the construction of theaters and common halls, Athenians built circles fac-ing inward. This allows people observe both speaker and the movement of other partic-ipants. By letting people see each other clearly or creating maximum eye contact theywere better able to understand each other\u2019s opinions.In Athens, People\u2019s Courts sat frequently, and the relatively long speeches of lit-igants provided excellent opportunities for sharing knowledge. Court was one of theplaces where collective knowledge was developed and used. The jury was drawn fromthe citizens. Citizens attended the court to observe the jurors\u2019 presentations duringwhich they observed the responses of others, like facial expressions and exclamations.Prosecution points from the Leocrates trial argue for the importance of reaching collec-tive action in terms of common knowledge.Lewis [13] provided a game theoretic solution for coordination problems which con-siders the relation between common knowledge and mutual expectation. In explaininga choice of action, he says that the agent needs a reason to believe about what actionswill be chosen by others. Then an equilibrium is sustained due to mutual expectationswhich come from common knowledge.There are some properties that allow us to know when it is appropriate to recog-nize common knowledge based on a certain principles. Lewis separates the concepts ofdirectly observable states of affairs and propositions that these states of affairs providea reason to believe. This is modelled as an \u201cindicates\u201d relationship (a state of affairsindicates that a proposition holds). Lewis identified four properties that allow a state ofaffairs (s) to be recognised as a \u201creflexive common indicator\u201d of a proposition (p), i.e.that observation of the state of affairs leads to common knowledge of the proposition.204 S. Srivathsan et al.The state of affairs should be self revealing and public, everyone should be able to inferp from observing s and every one should have reason to believe they share the sameinductive standards and background information.In the context of the trial that we model, Lewis\u2019s theory explains how commonknowledge of past traitors and their convictions can be reached without explicit log-ical reasoning about infinitely nested knowledge operators. In addition, we consideranother source of common knowledge noted by Ober: a cascade of actions by citizensto help rebuild the city\u2019s walls at a time of crisis, in response to a public decree to actcollectively secure the city.3 Points of Lycurgus During The TrialDuring his time in Athens, Lycurgus, the prosecutor of the trial was a famous politicianwho performed many social services. He had successful past prosecutions of citizenswho acted against security rules. During the trial of Leocrates, who was alleged to haveabandoned the city, Lycurgus\u2019s speech focused on two main equilibria. The first oneis a shared belief that is common knowledge among the citizens that everyone shouldcooperate to secure the city. As Athens\u2019 security was viewed as a common pool resourceevery citizen should play their part in ensuring it. Unless individuals give back to thecommon pool, it leads to the tragedy of the commons [8].The second equilibrium is that jurors should penalize citizens who violate the firstequilibrium through legal sanctions. As the city had been completely destroyed and lostterritory after the war with the Macedonians. Athenian\u2019s cooperation was crucial duringthe period when Leocrates was alleged to have abandoned it. Other citizens of Athenscommitted themselves to rebuilding the city. For the common good to be achieved, therewas a need for cooperation among citizens at the time. However, it was alleged thatLeocrates had left the city by disobeying the generals and ignoring the shared interestof citizens of the city.The above points are taken from Lycurgus\u2019s preserved speech [1,3]. We are inter-ested in reconstructing the key arguments of Lycurgus as a case study in computationalreasoning about common knowledge and collective action in terms of MLNs. In partic-ular, the focus of our model is on the reasoning that must be performed by the jurors.They need to understand the effect that their decision about conviction will have on themaintenance of the citizens\u2019 cooperation with the group goal to keep the city secure.4 Markov Logic Networks (MLNs)Two important aspects of artificial intelligence (AI), expressing knowledge and uncer-tainty, can be handled with first-order logic (FOL) and probabilistic modeling, respec-tively. There are various approaches to combining probabilistic reasoning with explicitlogical knowledge encoding such as probabilistic relational models [7], Bayesian logicprograms [11], relational dependency networks [15].Richardson and Domingos [5] proposed a logic framework Markov Logic Networks(MLNs). While a first-order logic (FOL) knowledge base contains formulas that can beseen as hard constraints on the possible worlds (assignments of truth values to groundReasoning About Collective Action in Markov Logic 205atoms), in an MLN, each formula has an associated weight that reflects how stronga constraint it is. The higher the weight, the greater the difference in log probabilitybetween a world that satisfies the formula and one that does not, other things beingequal. That allows to model the probabilistic nature of the formulas.An MLN can be seen as a template to generate a Markov network (a type of undi-rected graphical model), given a finite set of constants, and this can be used to answerqueries about the conditional and unconditional probabilities of specified ground for-mulas. An MLN contains a node for each possible ground atom, and has undirectededges connecting nodes that appear together in at least one grounding of a formula inthe MLN. While MLNs are built from FOL formulas, inference is performed using thegenerated Markov network.We are motivated to use an MLN for the following reasons. It allows explicit mod-elling of background knowledge and observed knowledge while presuming the fullexpressiveness of graphical models. The undirected nature of a Markov network meansthat the joint probability of ground atoms are defined without presuming ordered depen-dencies between them.For example, Fig. 1 shows that the probability of a citizen cooperating with a groupgoal securing the city (coop(P, SC)) is interrelated with the probabilities of holdingcertain attitudes towards the group cooperation, common knowledge they have aboutthe group goal and the attitude of the court towards punishing them (its ethos). This canbe modelled by an undirected graphical model.Formally, an MLN is given by a set L of pairs (Fi, wi), where Fi is a formula infirst-order logic and wi is a real-valued weight. Given a finite domain of discourse (aset of constants) the ground Markov network generates a probability distribution overthe set of possible worlds \u03c7 as follows,P (\u03c7 = x) =1Zexp\u239b\u239d|L|\u2211i=1wini(x)\u239e\u23a0 (1)Z =\u2211x\u2032 \u2208\u03c7 exp(\u2211i wini(x\u2032)) is a normalisation constant and ni(x) denotes thenumber of groundings of Fi that are true in x.Given a formula F , abbreviating the presentation of Jain [6], we define:s(F ) =\u2211x\u2208\u03c7, x |=Fexp\u239b\u239d|L|\u2211i=1wini(x)\u239e\u23a0 (2)The outer sum is over possible worlds in which F is true and the exponentiated innersum is the unnormalized probability of the possible world x. Using s(F ) we can cal-culate the probability of any ground formula F1 given any other ground formula F2asP (F1|F2) = s(F1 \u2227 F2)s(F2)(3)206 S. Srivathsan et al.5 An MLN Model of Lycurgus\u2019s ArgumentIn this section we present an MLN model of key aspects of Lycurgus\u2019s prosecutionspeech, which is shown in Listing 1. The model shows how a jury can decide whetherto prosecute Leocrates using the following two conditional probability queries Q1 andQ2. These ask what is the likelihood of a random citizen Polites cooperating with acollective goal to secure the city when Leocrates is convicted and not convicted, respec-tively:Q1 : P (cooperate(Polites,SecureCity) | convicted(Leocrates))Q2 : P (cooperate(Polites,SecureCity) | \u00ac convicted(Leocrates))There are two levels of collective action in this scenario: the citizens securing thecity as a collective goal, and the jurors collectively agreeing to convict Leocrates. Ourmodel currently includes only the first level. Lycurgus believes that there are two equi-librium conditions. Everyone should strive to secure the city as a common objective.That is the first equilibrium. The second equilibrium is for those who violate the firstone to be punished. The jurors are responsible for maintaining the court\u2019s ethos of con-victing traitors, thereby maintaining the equilibrium of people cooperating towards acommon goal. It is specifically our concern that each juror can understand the prosecu-tor\u2019s arguments and realise that \u201cif I convict Leocrates, I\u2019m enhancing the collaborationamong citizens; otherwise I\u2019m undermining it\u201d.1There is also a set of ground atoms accompanying Listing 1 representing firmknowledge about the domain. It states that the named citizens (other than Polites) arehistoric traitors. Among them, two (Hipparchus and Callistrus) of them were prose-cuted and convicted while one (Leocrates) is prosecuted and waiting for the jurors\u2019decision. To evaluate Q1, Leocrates is declared convicted, for Q2 he is not convicted.The details of traitors in these ground atoms can be found on monuments placed inpublic places where the list of traitors are carved and hence these ground atoms arecommon knowledge.Listing 1 shows the structure of an MLN that represents the scenario, implementedusing ProbCog2 The listing uses nested function symbols, to represent a group goal as acomplex term within a common knowledge modality. However, since ProbCog does nothandle terms with nested function symbols our MLN uses a standard transformation [2]to eliminate these functional terms. For brevity we do not show the transformed versionhere.Listing 1 starts with domain declarations that allow a set of constants to be associ-ated with a named domain. Next, every predicate in the MLN is declared. A predicatedeclaration consists of the predicate name followed by a comma-separated list of thedomain names of its arguments in brackets.1 We do not attempt to model any reasoning about whether a citizen prosecuted for treacheryreally is guilty. Instead we focus on the argument for conviction (assuming guilt) based on theupholding of social order. In fact, in the real scenario, Leocrateswas not convicted, as evidenceof his guilt was not convincing to the court.2 https://github.com/opcode81/ProbCog.Reasoning About Collective Action in Markov Logic 20712 // Domain declarations3 dom_citizen = {Polites, Leocrates, Hipparchus, Callistrus}4 dom_institution = {Court}5 dom_individual_ethos = {Ethos1, Ethos2}6 dom_institutional_ethos = {Ethos3}7 group = {Citizens}8 goal = {SecureCity}910 // Predicate declarations11 individual_ethos(dom_citizen, dom_individual_ethos!)12 institutional_ethos(dom_institution, dom_institutional_ethos!)13 ck(group, goal)14 group_goal(group, goal)15 cooperate(dom_citizen, goal)16 convicted(dom_citizen)17 traitor(dom_citizen)18 prosecuted(dom_citizen)19 historic(dom_citizen)2021 // Background knowledge22 ck(Citizens, group_goal(Citizens, SecureCity)).23 ck(group, group_goal(group, goal)) => group_goal(group, goal).2425 cooperate(x, SecureCity) \u02c6 !historic(x) =>26 individual_ethos(x, Ethos1) v individual_ethos(x, Ethos2).2728 log(0.12) individual_ethos(Polites , Ethos1) \u02c629 cooperate(Polites , SecureCity)30 log(0.48) individual_ethos(Polites , Ethos2) \u02c631 cooperate(Polites , SecureCity)3233 traitor(x) <=> (EXIST g (group_goal(Citizens, g) \u02c634 !cooperate(x,g) )).3536 // Definitions37 individual_ethos(x, Ethos1) <=>38 ( !historic(x) \u02c639 ck(Citizens, group_goal(Citizen, SecureCity))40 =>41 cooperate(x, SecureCity)).4243 individual_ethos(x, Ethos2) <=>44 ( !historic(x) \u02c645 ck(Citizens, group_goal(Citizen, SecureCity)) \u02c646 institutional_ethos(Court, Ethos3)47 =>48 cooperate(x, SecureCity)).4950 institutional_ethos(Court, Ethos3) <=>51 !(EXIST x (traitor(x) \u02c6 prosecuted(x) \u02c6 !convicted(x))).Listing 1.MLN encoding of Lycurgus\u2019s argumentsWe consider there to be a prototypical citizen named Polites. The Greek word Politesrefers to a general citizen in Athens [25]. Our aim is to infer the probability of an arbi-trary current citizen (Polites) cooperating with the shared goal to secure the city, withoutthe known behaviour of a few past defectors having an undue influence on this infer-208 S. Srivathsan et al.ence. Given that Polites is a single constant representing a large number of citizensof Athens3, the past traitors (including Leocrates, who is being prosecuted in absentiasome time after leaving the city), are modelled as \u201chistoric\u201d and the MLN clauses defin-ing the current citizens\u2019 ethoses regarding cooperation with the goal explicitly excludeconsideration of historic citizens.Polites is observing the trial and he believes there is common knowledge of the exis-tence of a group goal of the citizens to secure the safety of the city (e.g. by strengtheningits defences). This is shown in line 22 of Listing 1. Lycurgus argues that this commonknowledge comes about from a cascade [22] of action in cooperation with this goalwhen the city was in danger. Line 23 express a deduction that can be made from com-mon knowledge. It declares \u201cWhen there is common knowledge that a group has a goal,then the group has that goal\u201d.The reasoning agent (a juror listening to Lycurgus\u2019s argument) needs to understandhow the group goal affects the actions of the citizens. According to Tuomela [24], whenmembers of a group are acting collectively in \u201cwe-mode\u201d, \u201cone adopts the group\u2019sconstitutive goals, values, norms, and standards-briefly its \u201cethos\u201d \u201d.4 We assume thatcitizens may follow one of two possible ethoses in regards to securing the city (line 11and lines 25 to 26). The ! in line 22 indicates a functional relationship: the indicatedargument is uniquely defined given the other arguments of the predicate. These anno-tations in lines 11 and 12 means that an individual or institution can have at most oneethos.Polites observes these two competing individual ethoses that citizens have regardingcooperation with the goal to secure the city. Ethos 1 (lines 37 to 41) is to unconditionallycooperate with a group goal. Ethos 2 (lines 43 to 48) is more selfishly to cooperate onlyif the court holds the ethos of convicting traitors.Moreover, empirical knowledge about the proportions of cooperating agents in thecity, and the proportions of agents holding Ethos 1 and 2 amongst those agents5 isencoded using weights on the mutually exclusive joint probabilities in lines 28 to 31.Polites is capable of estimating the proportion of citizens who cooperate with the groupgoal, and who hold each ethos based on the background knowledge of current statusof cooperation of the city. The background knowledge comes from the observation ofpublic interactions (building walls, public oath), shared cultural information (honoringheroic warriors, celebrating war victories) and the present shared situation which all arematter of common knowledge. We assume that Polites has observed 60% cooperationwith the group goal, a 20% incidence of Ethos 1 amongst cooperators, and an 80%holding of Ethos 2 amongst them. We assume that observations of these proportions isapproximately the same across all citizens, and can be treated as common knowledge.3 MLN inference does not scale well [23], so explicitly modelling a large number of citizens isnot feasible.4 According to Toumela [24] there is a mutual belief that, if a group has set of ethoses, all itsmembers are collectively committed and accepted to that ethoses. Essentially this is commonknowledge.5 Due to difficulties in expressing conditional probabilities in MLN clauses [6], this knowledgeis expressed in terms of joint probabilities of cooperation and holding a certain ethos.Reasoning About Collective Action in Markov Logic 209Abbreviations P: Polites;  Leo: Leocrates;  Hip: Hipparchus; Cs: Citizens;  Ct: Court;  E2: Ethos2;  E3: Ethos3; SC: SecureCity; ind_e: individual_ethos; inst_e: institutional_ethos; coop: cooperate;  gg: group_goal convicted(Hip)??F? ?ind_e(P, E2)historic(P)ck(Cs, gg(Cs, SC))inst_e(Ct, E3)coop(P, SC)traitor(Leo)prosecuted(Leo)convicted(Leo)T?TTTTprosecuted(Hip)traitor(Hip)Fig. 1. Part of the Markov network generated from Listing 1Ethos 3 is defined as \u201cNo traitor who is prosecuted will not be convicted\u201d (lines48 to 49)6. The weight of Ethos 3 is determined empirically based on historic commonknowledge, which is expressed in the set of ground atoms. From public monuments,Polites knows about some past traitors (Hipparchus, Callistrus) who were prosecuted,and the outcomes of the trials. He can infer empirically how strongly the court has theethos of convicting or acquitting traitors based on those decisions.Lines 33, 34 define the term traitor: \u201cA traitor is someone who doesn\u2019t cooperatewith the group goal\u201d. This is also common knowledge which comes from the culturalbackground and shared knowledge that everyone knows what a traitor is.All the clauses in Listing 1 come either from common knowledge, or are assumedto be common knowledge e.g., the observed proportion of cooperation and prevalenceof Ethos 1 and 2. Some clauses refer to common knowledge explicitly. In other cases,the rules themselves are common knowledge. This is also common knowledge. As thisMLN was constructed exclusively from common knowledge then the conclusions ofreasoning with it are also common knowledge. If a juror believes that all this knowl-edge is common, then the conclusions reached by the MLN queries can also be consid-ered common knowledge amongst the jurors, thus encouraging a consensus decision toconvict or not.Figure 1 shows an excerpt from the Markov network generated from the MLN andthe chosen set of constants. The left hand side shows a grounding of the clause definingEthos 2 (where x = Polites), while the right hand side is a partial depiction of thesingle grounding for the clause defining Ethos 3 (for brevity, only citizens Leocratesand Hipparchus are considered here). The nodes are annotated with F or T where theirtruth values are fixed by the set of ground atoms, and ? where the truth value is notfixed and may vary between possible worlds. The figure illustrates how the probabilityof Polites cooperating with the goal to secure the city is influenced by the probabilitiesof various other ground atoms.6 ProbCog provides an \u201cexist\u201d operator but not a \u201cfor all\u201d one.210 S. Srivathsan et al.6 Results and DiscussionFig. 2. Results obtained from ProbCog to compute queries Q1 and Q2 respectivelyWe are interested in finding the likelihood of Polites and thus the average citizencooperating due to the common knowledge he/she received from the observation of thecity. In particular, what is the probability that Polites will cooperate when Leocratesis convicted and when he is not? Using conditional probability queries, we can drawsome conclusions as common knowledge, since all the input is associated with commonknowledge. The result of convicting Leocrates, will be to reinforce knowledge of thecourt\u2019s ethos of punishing traitors, and thus to increase cooperation due to the greaterprobability of Ethos 2 holding. This will motivate a jury member to vote to convictLeocrates to uphold cooperation with the citizens\u2019 goal to keep the city secure.Using the ProbCog tool with the exact inference mechanism, we obtained results ofa random citizen\u2019s probability of cooperation (cooperate(Polites, SecureCity)) in bothsituations of conviction and non conviction of Leocrates (Fig. 2a and Fig. 2b respec-tively. When Q1 and Q2 are computed, in the case of the court convicting Leocrates,Polites will cooperate with probability 1.00 and 0.12 for when he is not convicted. Thetruth value for convicted (Leocrates) is defined differently for these two queries.Given these predictions, a jury member can validate the argument of Lycurgus usingthis reasoning and as the conclusion comes from common knowledge he can be confi-dent his opinion will align with that of other jurors.7 Conclusion and Future WorkPeople act collectively for various reasons, and we are interested in knowing whatmakes them act as a group. Common knowledge plays an important role in bringingpeople together at the social level. We provided a computational model to show howcooperation will be achieved on the basis of common knowledge by investigating a spe-cific trial of classical Athens. We used a Markov Logic Network (MLN) as it is capableof combining logical and probabilistic reasoning. Based on Lycurgus\u2019s argument weassume that the clauses in our MLN are common knowledge including ethoses, back-ground knowledge about the term traitor, and proportion of cooperation.Reasoning About Collective Action in Markov Logic 211Our future work will focus on building a simulation of this scenario in which com-mon knowledge is created and assembled to form the MLN presented in this paper.This will happen in three scenes: (1) extracting common knowledge of the existenceof the group goal from a public decree, followed by an observed cascade of action incooperation with that goal; (2) observations of information about historic convictionsof traitors on public monuments, which, due to a shared cultural and educational back-ground can be seen as reflexive common indicators in Lewis\u2019s theory; and (3) empiricalobservations of the ethoses of the citizens towards the group goal. We will use notionssuch as salience and counts-as relationships between concrete and institutional eventsto determine which simulated events are candidates for common knowledge. Combin-ing this simulation with MLN reasoning will allow us to show how Lycurgus\u2019s complexarguments about common knowledge an joint action can be realised in a computationalagent.Acknowledgements. This work was supported by the Marsden Fund Council from New ZealandGovernment funding, managed by Royal Society Te Apa\u0304rangi.References1. Allen, D.S.: Changing the authoritative voice: Lycurgus \u201cagainst Leocrates\u201d. Class. Antiq.19(1), 5\u201333 (2000)2. Baumgartner, P., Fuchs, A., de Nivelle, H., Tinelli, C.: Computing finite models by reductionto function-free clause logic. J. Appl. Logic 7(1), 58\u201374 (2009)3. Burtt, J.O. (ed.): Minor attic orators. 2: Lycurgus. Dinarchus. Demades. Hyperides/with anEnglish transl. by J. O. Burtt. No. 395 in The Loeb classical library, [u.a.] Heinemann, Lon-don, reprint edn. (1980)4. Chwe, M.S.Y.: Rational Ritual: Culture, Coordination, and Common Knowledge. PrincetonUniversity Press, Princeton (2013)5. Domingos, P., Kok, S., Lowd, D., Poon, H., Richardson, M., Singla, P.: Markov logic. In:De Raedt, L., Frasconi, P., Kersting, K., Muggleton, S. (eds.) Probabilistic Inductive LogicProgramming. LNCS (LNAI), vol. 4911, pp. 92\u2013117. Springer, Heidelberg (2008). https://doi.org/10.1007/978-3-540-78652-8 46. Jain, D.: Knowledge engineering with Markov logic networks: a review. Evol. Knowl. The-ory Appl. 16, 50\u201375 (2011)7. Friedman, N., Getoor, L., Koller, D., Pfeffer, A.: Learning probabilistic relational models.IJCAI 99, 1300\u20131309 (1999)8. Hardin, G.: The tragedy of the commons. J. Nat. Res. Policy Res. 1(3), 243\u2013253 (2009)9. Holt, C.A., Roth, A.E.: The Nash equilibrium: a perspective. Proc. Natl. Acad. Sci. 101(12),3999\u20134002 (2004)10. Holzinger, K.: The Problems of Collective Action: A New Approach. SSRN 399140 (2003)11. Kersting, K., De Raedt, L.: Towards combining inductive logic programming with Bayesiannetworks. In: Rouveirol, C., Sebag, M. (eds.) ILP 2001. LNCS (LNAI), vol. 2157, pp. 118\u2013131. Springer, Heidelberg (2001). https://doi.org/10.1007/3-540-44797-0 1012. Kuhlman, C.J., Ravi, S.S., Korkmaz, G., Vega-Redondo, F.: An agent-based model of com-mon knowledge and collective action dynamics on social networks. In: 2020 Winter Simula-tion Conference (WSC), pp. 218\u2013229 (2020)13. Lewis, D.: Convention: A Philosophical Study. Harvard University Press, Cambridge (1969)212 S. Srivathsan et al.14. Leyton-Brown, K., Shoham, Y.: Essentials of game theory: a concise multidisciplinary intro-duction. Synth. Lect. Artif. Intell. Mach. Learn. 2(1), 1\u201388 (2008)15. Neville, J., Jensen, D.: Dependency networks for relational data. In: Fourth IEEE Interna-tional Conference on Data Mining (ICDM 2004), pp. 170\u2013177. IEEE (2004)16. Ober, J.: Democracy and Knowledge: Innovation and Learning in Classical Athens. Prince-ton University Press, Princeton (2008). oCLC: ocn20254516217. Ostrom, E.: Governing the commons: The evolution of institutions for collective action. Thepolitical economy of institutions and decisions. Cambridge University Press, Cambridge;New York (1990)18. Reuben, E.: The evolution of theories of collective action. Ph.D. thesis, Tinbergen Institute(2003)19. Sandler, T.: Collective Action: Theory and Applications. University of Michigan Press, AnnArbor (1992)20. Shteynberg, G.: Shared attention. Perspect. Psychol. Sci. 10(5), 579\u2013590 (2015)21. Shteynberg, G., Hirsh, J.B., Bentley, R.A., Garthoff, J.: Shared worlds and shared minds: atheory of collective learning and a psychology of common knowledge. Psychol. Rev. 127(5),918 (2020)22. Srivathsan, S., Cranefield, S., Pitt, J.: A bayesian model of information cascades. In:Theodorou, A., Nieves, J.C., De Vos, M. (eds.) Coordination, Organizations, Institutions,Norms, and Ethics for Governance of Multi-Agent Systems XIV. COINE 2021. LNCS, vol.13239. Springer, Cham. (2022). https://doi.org/10.1007/978-3-031-16617-4 723. Sun, Z., Zhao, Y., Wei, Z., Zhang, W., Wang, J.: Scalable learning and inference in Markovlogic networks. Int. J. Approx. Reas. 82(C), 39\u201355 (2017). https://doi.org/10.1016/j.ijar.2016.12.00324. Tuomela, R.: The Philosophy of Sociality: The Shared Point of View. Oxford UniversityPress, Oxford (2007)25. Wohl, V.: Rhetoric of the Athenian Citizen, pp. 162\u2013177. Cambridge Companions to Lit-erature, Cambridge University Press (2009). https://doi.org/10.1017/CCOL9780521860543.011Design Heuristics for Ethical Online InstitutionsPablo Noriega1 , Harko Verhagen2 , Julian Padget3(B) , and Mark d\u2019Inverno41 CSIC-IIIA, 08193 Bellaterra, Spain2 Stockholm University, 114 19 Stockholm, Sweden3 University of Bath, Bath BA2 7AY, UKj.a.padget@bath.ac.uk4 Goldsmiths, University of London, London SE14 6NW, UKAbstract. Amajor challenge in AI is designing autonomous systems that capturethe values of stakeholders, and do so in such away that one can assess the extentto which that system\u2019s behaviour is aligned to those values. In this paper wediscuss our response to this challenge that is both practical and built on clearprinciples. Specifically, we propose eleven heuristics to organise the process ofmaking values operational in the design of particular class of AI systems calledonline institutions. These are governed systems of interacting communities ofhuman and autonomous artificial agents.Keywords: Online institutions \u00b7WIT design pattern \u00b7 Conscientious design \u00b7Embedding values \u00b7 Value alignment \u00b7 Value-sensitive design1 IntroductionIn the Reith Lectures broadcast by the BBC at the end of 2021 [28], Stuart Russell spokeabout the challenges Artificial Intelligence (AI) research has in ensuring that AI worksfor the benefit of human kind. There are several ways to address these challenges. Oneway is to \u201cput ethics into AI\u201d; and more precisely, focus on the challenge of the valuealignment problem (VAP): \u201cto build systems whose behaviour is provably aligned withhuman values\u201d. The VAP, in fact consists of two linked problems: how to embed humanvalues into AIS and how to assess if, or to what degree, the behaviour of the AIS isaligned with those values.We propose a principled and practical way of approaching the VAP, which wecall conscientious design, that consists of: (i) restricting the problem to one particu-lar type of Artificial Intelligence Systems (AIS) that we call online institutions (OIs);(ii) developing a conceptual framework\u2014involving terminological distinctions, formalconstructs and properties\u2014 that delimit the interpretation of the VAP;(iii) developingmethodological guidelines and heuristics to guide the embedding of values in an onlineinstitution and assessing the OI\u2019s alignment with those values; (iv) developing test caseswhich provide both a source of inspiration for the conceptual framework and to evi-dence how our approach can be put into practice.This paper is a contribution to component (ii) above. It contains some heuristics thatserve to guide the process of making values operational for an OI. The heuristics arec\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2022N. Ajmeri et al. (Eds.): COINE 2022, LNAI 13549, pp. 213\u2013230, 2022.https://doi.org/10.1007/978-3-031-20845-4_14214 P. Noriega et al.intended to be as generic as possible in order to show what are the main practical issuesinvolved in embedding values and assessing alignment. It is work in progress (ratherthan a completed design methodology) which builds on a decade long research effortinvestigating online institutions and a conscientious design approach for building themsuccessfully (e.g., [34] and see for example references in [1,20,22]). In addition to thatlong lasting interest, we draw also from experience from a different application of theframework: policy sandboxes, where some of the concepts and constructs involved inthe heuristics we present here were first devised [24,25].Online institutions (OI) are a subclass of artificial intelligent systems. They arehybrid multiagent systems (that involve human and artificial participants), where allinteractions are regulated (only those actions that comply with the OI\u2019s regulationscan have any effect within that OI), are online (interactions consist of messages\u2014orpercepts\u2014exchanged through the OI) and, finally, situated within a particular socio-technical-legal context [18]. Online institutions capture several intuitions of classicalinstitutions: Searl\u2019s notion of separate \u201ccrude\u201d and \u201cinstitutional reality\u201d [30]; North\u2019scharacterisation of institutions as artificial constraints that articulate agent interac-tions [23]; Simon\u2019s thinking of institutions as an interface between a collective objectiveand the individual decision-making of participating agents [31]; and Ostrom\u2019s criteriafor institutional persistence. Those similarities are shown as part of the WIT designpattern in Fig. 1a.Our focus on online institutions is based on two observations: first, the specificfeatures that distinguish them from other AIS provide the grounds for a principled app-roach to the VAP; second, plenty of deployed AIS which belong to the OI class andthere will be more abundant in the future.In addition to a precise characterisation of an OI, the main contributions to the con-ceptual framework of the CD approach are (i) the WIT design pattern, (ii) the (design)distinction between the isolated and the situated view of an OI; (iii) specifying threeproperties of OIs that one should aspire to achieve in their design: cohesiveness (thatthe three distinctive WIT aspects actually complement each other), integrity (that theOI is stable, not corruptible and works as intended) and compatibility (with the legal,technological and social constraints of the context where it is situated); and (iv) the pro-posal of three conscientious design value categories: thoroughness, mindfulness andresponsibility. Needless to say, appropriate terminological distinctions and some spe-cific constructs give substance to the three main contributions [18].The main contribution of this paper is to show how each of these four conceptscan be translated into methodological guidelines in the form of heuristics for the actualembedding of values. In order to achieve this, the next section provides an overviewof our contributions to date. In Sect. 3 we describe a running example to illustrate theapplicability of our heuristics. Sect. 4 presents the heuristics themselves and the paperends with some closing remarks on what we have achieved and future work.Design Heuristics for Ethical Online Institutions 2152 The Conscientious Design Story so Far2.1 The WIT Design PatternThe purpose of the WIT design pattern is to support the process of building onlineinstitutions (OIs). The most recent description [22] is a relatively high-level oneintended for a non-specialist audience,while earlier iterations at previous COIN(E)Workshops [20] and other published research [18,19,34] are more technical, and chron-icle the evolution of our ideas.The first significant difference between earlier work, before [22], and the work inthis paper is the use of the termWIT Design Pattern to refer to the range of concepts andapproaches needed for the ethical design of OIs, where we draw on the principles putforward by Alexander [2,3] to capture the idea of habitable online spaces that evolve tomeet the changing needs and values of their inhabitants. This in turn draws on value-sensitive design (VSD) [8\u201310] which provides the basis for the role of human values inthe design process of computational systems, and on Deming\u2019s underpinnings for TotalQuality Management (TQM) [4] to account for the maintenance and evolution of theonline space.The second significant difference is our use of the term \u201conline institution\u201d (OI)instead of the previously used socio-cognitive technical systems or hybrid online sys-tems. We next describe two distinct categories (or abstractions) of an OI as follows: (i)the isolated OI in Fig. 1a, which enables the design of an OI to be considered from threedifferent but related perspectives: W , the OI as seen from the world perspective; I, theinstitutional or governance perspective of the OI and T , the OI from its technologicalperspective; and (ii) the situated OI in Fig. 1b, where the isolated OI connects withthe corresponding elements of the physical and social world to establish what \u201ccounts-as\u201d [14] in both directions and to anchor the online institutions with its physical worldcounterparts.For any isolated OI it is necessary to be able to demonstrate cohesiveness, which isto say the three views work as intended, and integrity, which means it is a persistent,well-behaved online system. In order to be fit for its purpose, the situated OI needs tobe effective in the context of its use. Consequently, the OI has to be compatible with thetechnological, legal, social and economic requirements of its working environment.2.2 Conscientious Design Value Categories (CD-VCs)As part of the development of the WIT-DP framework we have developed the notion ofConscientious Design value categories: thoroughness, mindfulness, and responsibility.Here we summarise these to provide the reader with a sense of these below (the fulldefinitions can be found in [22]):\u2013 Thoroughness: this refers to conventional technological values that promote thetechnical quality of the system. It includes completeness and correctness of thespecification and implementation, reliability and efficiency of the deployed system.Concepts such as robustness, resilience, accessibility, and security are all aspects ofthoroughness.216 P. Noriega et al.Online Institution (OI)Technology(T)World(W)Institution(I)abstractgroundinputoutputimplementspecifyJ. R. SearleInstitutional RealityD. C. NorthArticulate InteractionsH. A. SimonInterface between collective goal and individual decisions(a) The Isolated OI, drawing on Searle [30],North [23] and Simon [31]OITWILegalSocialTechnologicalOwnerDesignerUsersOthers StakeholdersOther SystemsPlatformsCommunicationNegotiationsStandardsContext of Use(b) The Situated OIFig. 1. The views of an isolated online institution vs a situated online institution\u2013 Mindfulness: is about engendering a wider awareness of the range of direct andindirect needs of, and impacts on, humans (both users and non-users) which is sooften over-looked. Examples include data ownership, and the OIs accessibility andusability, and this category has much in common with Schwartz\u2019 \u201cpersonal focus\u201dvalues.\u2013 Responsibility: addresses both the effects of the system on stakeholders and thecontext in which it is situated, as well as how indirect stakeholders and that contextmay affect internal stakeholders. Examples include liability and prestige, and areakin to the \u201csocial focus\u201d values of Schwartz [29].In our work on Ethically Aligned Design [22] we have shown how these CD valuecategories can be mapped onto different ethical AI value frameworks such as the ini-tiatives from the EU [11] on Trustworthy AI and the IEEE guidelines for imbuing val-ues in AIS [32]. As meta-analyses of the multitude of frameworks show [7,17], manyhave overlapping definitions and principles. However, the CD value categories have theadvantage of supporting more than one way of looking at the principles included inthese frameworks.One final remark here concerns the stakeholders. Stakeholders are all those affectedby, or those affecting, the system during both development and deployment. Directstakeholders are those stakeholders who are responsible for the design and deployment,or are direct users of the OI. In practice, in every OI there are always three categoriesof direct stakeholders: owner, engineer and user and we will detail each of these in thenext section. Those stakeholders who are affected by the system, but are not part of thedecision-making and do not use the system directly, we call indirect stakeholders \u2014 asDesign Heuristics for Ethical Online Institutions 217is the usual term in value sensitive design. The values of direct stakeholders need to beexplicitly accounted for in the design and use of the OI.In order to identify those values of direct stakeholders and make them operational,direct stakeholders can be separated in three different groups: owner, engineer and user.This separation reflects the distinctive objectives of direct stakeholders in every OI: theowner looks to deploy an OI that supports a collective endeavour \u201cas well as possible\u201d,the users participates in the OI to achieve \u201cas well as possible\u201d their individual goalswith whatever means are provided by the OI, and the engineer builds \u201cas well as pos-sible\u201d an OI that satisfies \u201cas well as possible\u201d the owner and the user objectives. Thepoint is that each \u201cas well as possible\u201d is guided by different values. Notice that since,in every OI, those distinctive objectives of each of the direct stakeholders are similar,the values that each of them holds are similar to some extent in every OI. See below,Sect. 4.2, Heuristic 4.3 The Easyrider Online InstitutionTo support the understanding of the theoretical and practical concepts involved in theWIT-DP for ethical AIS, we introduce Easyrider, a rich enough toy example of an OIfor buying and selling train tickets online. Are we mentioned in the last section thethree categories of direct stakeholders are Owner, Engineer and Users and are detailedas follows.1. Owner: refers to the individual or organisation that commissions and operates theOI. In this case the railway company is the Owner, because it commissions andoperates the OI in order to sell tickets online through travel agencies.2. Engineer: refers to the individual or organisation responsible for ensuring therequirements of the owner are satisfied in am effectively designed and deployedOI that supports intended usage.3. User(s): refers to the users who will use the system and satisfy their goals by inter-acting with others. In Easyrider there are two categories of users: passengers (whoare human agents) that use Easyrider to buy, and possibly return train tickets, andtravel agencies (who are software agents) that buy tickets from the railway companyto re-sell them to passengers.In Easyrider, the indirect stakeholders would include the commerce and transitauthorities that regulate the railway services, the banks and payment services thatsupport purchases, phone companies and, to some extent, the population \u2014and theenvironment\u2014 of those cities served by trains and affected by the travelling of peopleback and forth.3.1 Goals and ValuesTheWIT DP approach to design we propose starts by identifying the ultimate objectivesof stakeholders \u2014the rationales for the creation, engineering, and use the particular OI.However, because we want to embed values in the OI we also need to make explicit218 P. Noriega et al.the terminal (or intrinsic) values that motivate those objectives and those instrumentalvalues that determine the means provided by the OI to reach those objectives [27].Table 2 illustrates those three elements in Easyrider. For brevity, we only include theultimate goal of the stakeholder groups, the key terminal values that guide those goalsand the most prominent instrumental values that motivate the stakeholders\u2019 decisionsand means to achieve those goals. Next to each \u201cinstrumental value\u201d we indicate thetype of CD category it belongs to (T for thoroughness, M for mindfulness, and R forresponsibility). In the next section we build on these examples to illustrate how CDvalues can be embedded in Easyrider.For example, the railway company who owns Easyrider develops an online ticketingservice in order to sell enough seats to amortize capital it has invested in the trainservice, and it wants to achieve that objective guided by three terminal values: (i) asense of good management of the company capital and its operation; (ii) the provisionof a service through travel agencies that is profitable for these travel agencies whichin turn leads to attracting both existing and new passengers to use the system; and (iii)an acknowledged positive impact because more persons travel in train instead of usingless ecological means of transportation and also because a public infrastructure is betterused.Moreover, the specification of Easyrider should also reflect the railway company\u2019scriteria for instrumenting those terminal values. So, for instance, good management isachieved by a thorough implementation of management policies and practices; respon-sibly by achieving a healthy cash-flow. Alongside, the OI promotes an occupancy ofwagons that provides that cash-flow without being uncomfortable for passengers; whileenabling profitable margins to travel agencies.We now move onto the issue of how to make values operational within our estab-lished framework for designing ethical OIs.4 Making Values OperationalThe proof of developing a value-imbued system is in the pudding of making valuesoperational as well as choosing the values in order to be able to assess if the valuesare indeed enhanced or supported by the system. According to [26], there are threepre-requisites that need to be fulfilled to assess if certain values are embodied in an AIsystem: (i) values are addressed in the design of the system, i.e., there is no such thing asaccidental value embedding;(ii) the AI system is seen as a sociotechnical system not anisolated technological artefact, i.e. it is situated; and (iii) the AI system is not ascribedany moral agency, differentiating it from human agents.Since we want to embed values in a working system, we need to translate an intuitiveunderstanding of values into precise constructs that can be specified as part of a systemand then see whether or not they are supported by the working system. This is what wecall the process of making values operational. Since this is a complex process the firstthing to do is to make things manageable.Design Heuristics for Ethical Online Institutions 219ASSESSMEASURECOMBINEMEANSENDSNORMSPROCEDURESAFFORDANCESINFORMATIONREPRESENTIMBUEINTERPRETVALUESCHOOSEProcessInputs within CycleOutputs sent outside CycleTask OUTCOMESTASKFig. 2. The process for bringing values into the design of an OI4.1 Three Heuristics for Structuring Value OperationalisationThe point of the heuristics for structuring value operationalisation is threefold: (i) todecompose the complex problem into subtasks, (ii) to facilitate the separation of designconcerns and (iii) to put design priorities in focus. We propose three design heuristicsfor this purpose:Heuristic 1. Making values operational is an iterative process.Making values operational is a process of iterative approximation that converges towhatever is \u201cjust enough\u201d for whichever stage the system has reached, from preliminaryevaluation through to decomissioning. It also functions as the means to track the movingtarget of the changing needs and value preferences of the participants. As sketched inFig. 2, the process starts with the choice of values and ends with a specification of an OIthat is aligned with those values. The first task consists of choosing a list of values thatare relevant for the OI. The task of the second stage is to make those values objectivelymeasurable, for which we use a two step process: they are interpreted by linking them toconcrete referents (\u201cmeans\u201d to support the value and \u201cends\u201d that reflect its achievement)that may then be represented within the system in readiness for the next stage. The thirdstage consists in defining the value assessment models that establish (i) the precise waysin which one can tell whether a value is being attained and to what degree, and (ii) howto resolve value conflicts . The outcome of this process is to put the representation ofthe values and the assessment into the specification of the OI.Heuristic 2. Ethical design is a participatory effortwhere all direct stakeholders havetheir say at different phases of the OI life-cycle.The cycle of making values operational is active for the lifetime of the OI. However,the involvement of stakeholders is different in different phases of that life-cycle. Thedesign of a value imbued process is started by the owner whose main goals and values220 P. Noriega et al.are passed as design requirements to the engineer. The engineer is then responsible forinterpreting these values of the owner, and to elicit and interpret the values of users.Based on these requirements, the engineer makes all the relevant values operational andspecifies and deploys the system as proficiently as possible. Although the decision todeploy rests with the owner and their values take priority, its success rests with the usersand in the implementation. Therefore, in the evaluation and updating of the system, uservalues take precedence, then the engineer takes over and the release of a new version isup to the owner\u2019s values again.In practice (as mentioned in Sect. 3.1), the process of making values operational iskick-started by the choice of terminal values (desirable end-states of existence) for theultimate goals of each stakeholder and a first take on the instrumental values (related tomodes of behaviour) [27]. In other words:Heuristic 3. Value assessment drives the iterative process of making values opera-tional.The rationale is that it is helpful to sketch which are the values that each stakeholderwants reflected in the OI and how stakeholder would assess whether the OI promotes orprotects those values before starting the detailed process of imbuing values.4.2 Heuristics for the Choice of ValuesA first heuristic is based on the acknowledgement that the choice of values needs to takeinto account three frames of reference. First, the application domain, which determinesgoals and makes some instrumental values relevant and others less so. In Easyriderfor example, values related to e-commerce and transportation become relevant, whilethose associated with, say, health services do not. Second, the role of stakeholders influ-ences the choice of values. Stakeholders choose values that are relevant for the domain,however, regardless of the application domain, engineer values always reflect the goalof developing an OI that handles a particular collective activity , owner values alwayshave to reflect the need of engaging users, and user values reflect their motivation andpreference for choosing to engage in the OI. The third frame of reference that influ-ences the choice of values is to profit form the fact that the WIT design pattern inducesa natural separation of design concerns that remain valid throughout the OI life-cycle.Regarding the use of the WIT design pattern, we argue that in order to embed theterminal and instrumental values of each stakeholder in the OI, one needs to addressthree main design requirements: (i) to enable collective interaction in a well-defined,limited part of cyber-physical reality; (ii) to set up the rules of the game so that theoutcomes of those interactions are consistent with the values of the stakeholders; and(iii) to implement these rules in such a way that the actual online system runs accord-ing to those rules. The WIT pattern facilitates the analysis of those requirements byestablishing nine design contexts where specific values are involved. These contextsare the six design concerns associated to the relationships between the W \u2212 I \u2212 Tcomponents of the isolated OI (Fig. 1a) and the three design concerns arising from thelegal, technological, and social compatibility of the situated OI (Fig. 1b). Two points areworth mentioning: first, all CD, terminal, and instrumental value labels may be localisedDesign Heuristics for Ethical Online Institutions 221as more specific labels for each stakeholder in each of the nine contexts; second, notall the nine contexts are equally important for all stakeholders, hence one can rank thedegree of involvement \u2014in the participatory design process\u2014 of the three stakeholdersfor each context and each CD value class.Table 1 illustrates value contextualisation for the OI engineer regardless of the OIdomain. The top part gives an interpretation of the CD-value categories and the bottompart declares those contexts of the WIT design pattern where the engineer has the finalword on the choice and interpretation of the contextualisation.Heuristic 4. Contextualisation: Value choice depends on the domain of the OI, theactual stakeholder and the WIT-DP context where it is meant to be applied.The second heuristic for choosing values suggests how to proceed in order to iden-tify relevant values. The idea is quite straightforward: use the goals of the stakeholdersto search for values and keep the CD value categories present to prevent overlooking asignificant value.Heuristic 5. Value selection: Define the ultimate goals of each direct stakeholder, thenassociate with each stakeholder the corresponding terminal and instrumental values andvalidate the selection of instrumental values with the CD value-categories.In practice, each stakeholder is committed to an ultimate goal which ought to belegitimised by an ultimate or intrinsic value. However, that goal needs to be decomposedinto means and ends that determine how the stakeholder may achieve its goal. In orderto choose the particular means and ends that lead to achieving that ultimate goal thestakeholder will use its instrumental values1The CD value categories serve a dual purpose, on one hand they are useful forlabelling instrumental values (something that will be essential for value assessment andfor the eventual termination of the operationalisation process); on the other hand, theintuitive understanding of the three categories (and the experience of using them inother OIs) is a practical way of validating that the instrumental values that have beenchosen truly constitute a good coverage of each of the three main categories.Table 2 is a partial contextualisation of the terminal and instrumental values of theowner and the users of Easyrider (the engineer\u2019s values are summarised in Table 1). InTable 2 we list only four instrumental values of the owner and users of Easyrider, andrefine these with more specific values; some of which are underlined because they areused in Sects. 4.3 and 4.4, and in Table 3 to illustrate the interpretation and representa-tion of value labels. Notice that each instrumental value is labelled with the CD valuecategory it more naturally belongs to.21 There are two ways of identifying ultimate and instrumental value labels. One is to ask theusers to name them [15,33]; another is to draw from available value taxonomies like [12,13,29]. Following the second path, we propose the CD value categories mentioned earlier:thoroughness, mindfulness and responsibility [20,22] that serve as intuitive catch-all labelsthat become more meaningful as they are applied to different design concerns as the design ofthe OI advances.2 Although individual passengers and travel agencies may have different value interpretations,the table stands for a consensus of what values to embed and how that is the result of theparticipatory design process.222 P. Noriega et al.Table 1. Engineer\u2019s value contextualisation (independent of OI domain). (1) The generic ultimategoal of an engineer is aligned with each of the CD-value categories, which are translated intointuitive descriptions of their most salient means and ends. (2) The engineer holds the ultimateresponsibility for value imbuing in particular WIT pattern design contexts.(1) Engineer\u2019s terminal and instrumental valuesEngineer\u2019s ultimate goal: Design and build an OI proficientlyThoroughness:(i) Do the usual stuff to do a good job during the whole life-cycle of the system;(ii) Adopt best practices and standards in the application domain;(iii) Make the OI fit for the ultimate goals of direct stakeholders;(iv) Validate cohesiveness and integrityMindfulness:(i) Engineer all values of owner and users;(ii) Be transparent about the quality and limits of the OIResponsibility:(i) Guarantee cohesiveness and integrity of the isolated OI;(ii) Guarantee compatibility of the situated OI.(2) Engineer\u2019s leadership in the WIT design pattern:(i) Integrity of isolated OI;(ii) Cohesiveness of isolated OI;(iii) Technological compatibility of situated OI;(iv) Priority design sub-contexts: specification (I\u2192T), implementation (T\u2192I) and user interface (W\u2194T\u2019)Table 2. Ultimate goals and main instrumental values of the owner and users of the Easyrider OI.Each goal is associated with four instrumental values that guide its achievement. Those instru-mental values are in turn partially refined into more specific values \u2013 labelled with their cor-responding CD-categories \u2013 that will be imbued in the system. Underlined values are used inTable 3 and examples.Railway company Passengers Travel agenciesFill trains Buy train tickets Profitable trading businessSound management Convenience Profitadequate return on investment (M),balanced cash-flow (M), ...flexibility (M), abundant offer (M),ease of use (M)increase volume (M), increasemargin (M), lower costs (M,R), ...Proficient OI Restraint Conveniencetrustworthiness, (R) effectiveness(M, R), impartiality (R), transparency(R), legal compliance (M,R), ...lower fares (M), ... easy to use (M), compatible within-house practices and systems (M),reliable support (M), ...Good customer relations Reliability Reliabilityreliable support (R), accountability(R), privacy (R), ...secure transactions (M),accountability (M), privacy (M), ...transparent rules of operation (M),fair competition (M, R),secure transactions (M,R), ...Good citizenship Pleasant travelling Good citizenshipsupport SDGs (R), corporateresponsibility (R), prestige (M), ...comfort (M), conviviality (M,T), ... prestige (M), social recognition (R),...Design Heuristics for Ethical Online Institutions 223One last remark about the choice of values. Since the process of making valuesoperational is gradual, the refinement of value labels is better served by the analysis ofonly the most salient stakeholder values in the first pass. One need only come back tothis step of the operationalisation process when the value assessment process requires animprovement of the alignment of the OI to the stakeholders\u2019 values (see Heuristics 11).4.3 Heuristics for Value ImbuingImbuing is a prerequisite for specification. Its objectives are to turn the intuitive under-standing of a relevant value into an objective understanding that may be embedded intothe OI. This task of imbuing values in a system involves two efforts: interpretationand representation of values. These two sub-processes are applied to each instrumentalvalue label and while all stakeholders are involved, the stakeholder who chooses a givenvalue leads the task.1. Interpretation: Its purposes are to obtain an objective description of the the mech-anisms and constraints that support (promote) or maintain (protect) each value, and anobjective description of how one can eventually assess whether a value is in fact beingprotected or promoted. This can be articulated with two heuristics.Heuristic 6. Value interpretation (1) is to articulate the meaning of a value as themeans and ends that are most typical of it in a given context.The leading stakeholder for a given value, with inputs from the other stakeholders,interprets it by looking at the concrete actions or objects that can afford its achievementand maintenance (the means) and identifying the states of affairs that show that thevalue is actually being promoted or protected (ends).Once the means and ends are articulated, one needs to identify what the observablefeatures of the states of affairs are involved in those means and ends in order to usethem for measuring the attainment of a value and stating along those terms the degreeof satisfaction of the different stakeholders. Consequently, this heuristic provides theessential elements for the definition of the value assessment models that we discuss inthe next section.Heuristic 7. Value interpretation (2) consists in associating with each value observ-able features involved in value means and ends, and discovering stakeholder prioritiesand thresholds of satisfaction.2. Representation: From these means and ends, and their observable features, the engi-neer with input from the other stakeholders decides how to represent the instrumentalvalues so that they can be implemented as part of the physical and governance modelof the OI (or in the decision model of an artificial agent).Heuristic 8. Value representation translates value interpretations into components ofthe abstract representation of the OI, that will be the basis for its specification.224 P. Noriega et al.Table 3. Imbuing of some instrumental values of Easyrider\u2019s owner and users. Each value isinterpreted in these examples as one typical end that leads to the stakeholders\u2019 ultimate goals inalignment with the corresponding values, and some means that are conducive to the achievementof that end. These means and ends would be represented with some instruments that embody themeans, in a way that one may objectively assess whether these values are satisfied or not in thedeployed system.Passenger Users and owner Owner OwnerValues Flexibility Accountability andtransparencySupport SDGs Adequate return on investmentEnds Allow last-minute purchases, ... proof of action, ... promote the use of train tosupport SDG 7, 9, 13, ...high occupancy of carriagesMeans Extend purchasing deadlines;install ticketing machines atstation;Reports of relevanttransactions, ...marketing campaigns, ... attractive fares, ease ofpurchasing, marketing, ...Representation Norms and affordances Procedures for issuingeach report typeBanners and messages, poll Procedure and physical action;add carriages when neededObservable Number of tickets sold close todeparture; number ofmachine-issued ticketsList of reports of eachtypePassenger and TA awareness ofthe good impact of trainsOccupancy levelThresholds more than 10% of total sales arelate purchasesat least all legallyrequired reportsincrease of awareness andacknowledged motivationbetween 60% and 80% occupiedseats in a carriageThere are essentially three ways of translating value interpretations into value rep-resentations: as norms and standard procedures, as affordances, and as information forparticipants. Table 3 illustrates the interpretation and representation of some instrumen-tal values included in Table 2).1. Some values are represented directly as norms that promote, mandate, curtail, or dis-courage behaviour; or prescribe the consequences of institutional actions. For exam-ple, passengers\u2019 flexibility may be interpreted as allowing ticket changes, whichmay be represented with a norm that allows ticket purchase and devolution up tofive minutes before departure.Sometimes a single norm is not enough and a value may have to be represented as astandard procedure. For instance, Easyrider may include protocols for issuing differ-ent reports. Such reports \u2014say, tax-valid receipts for every final sale or a refusal toaccept a devolution\u2014, are means that support the end of having evidence to achievethe value of accountability and transparency for stakeholders.2. A second way of going from interpretation to representation is through the introduc-tion of new entities in the institutional reality that afford specific actions or outcomesthat promote or protect a value like accountability. For example, passengers\u2019 valueof travel flexibility may also be supported by allowing the possibility of purchasingand printing tickets in ticket dispensers at the station. In this case the physical model(ofW) would need to include ticket dispensers and their use would be regulated withnorms that will be part of the \u201cgovernance model\u201d of Easyrider. In this example, theaffordance of using printed ticketsmay require other devices in the station or aboardtrains to validate tickets. The owner would have to decide whether the use of printedtickets is worth the extra regulations and the cost of dispensers, or not.3. The third mode of representing values is as a set of facts, recommendationsor arguments that are made available to users with the purpose of influencingDesign Heuristics for Ethical Online Institutions 225their decision-making. For example, the railway company\u2019s instrumental valuesupport sustainable development goal (SDG) can be promoted through banners ormessages that appear in the use of Easyrider or in marketing campaigns that makeusers aware of the beneficial impact of traveling by train (and eventually alsoincrease the number of trips). The achievement of the value is observable, for exam-ple, through a customer satisfaction poll and its degree of satisfaction measuredthrough the aggregate opinion users.4.4 Heuristics for Value AssessmentWe now turn our attention to the task of evaluating to what extent stakeholders val-ues are reflected and met in the OI. The imbuing step that we proposed above entailsthree claims: (i) that \u2014since ends are observable\u2014 the alignment of values can be\u201cassessed\u201d somehow (or measured); (ii) that stakeholders are capable of determiningwhether they are satisfied or not with the degree to which the system is aligned with thevalues they care about \u2014since for each value interpretation, its satisfaction thresholdscan be elicited from stakeholders; (iii) that the engineer is able to transcribe measuringand satisfaction into the specification of the OI. We make these claims operational withthe construct of value assessment models. The value assessment model of a stakeholders has three parts: a list of values, a way to measure each of those values, and a way tocombine them.Heuristic 9. Value measurement consists of mapping the observable outcomes thatstand for the value and the thresholds expressed by the stakeholder on an ordered setthat reflects the degree of satisfaction of the user with that value.We mention two extreme possibilities of value measuring to illustrate this heuristic.As we saw in the previous section, the interpretation of a value commits to an observ-able feature that stands for the value and, ideally, to some bounds or thresholds thatdetermine the degree to which the value is satisfied. one form of measuring values thatallows for a crisp assessment assumes that the observable feature is an \u201cindicator\u201d (or ascale on a totally ordered set), boundaries determine thresholds that determine not onlyif the value in question is being satisfied or not but also to what degree.3 For instance, inEasyrider, a travel agency recognises secure transactions as a mindfulness and respon-sibility value, which is being interpreted as \u201chonouring deals\u201d. This instrumental valueis interpreted, in particular, by guaranteeing that travel agencies pay all their dues tothe railway company and to other travel agencies. The means the institution has imple-mented to maintain that value, are to require of travel agencies to post a bond that coverspotential harm, and levy a fine for any mishap. The observable outcomes are the costsof the mishaps. The travel agency may use that representation of the value to measuresecure transactions and also the satisfaction of its own value of lower costs by the sumof fines it pays over the year and prefer to pay no more than a fixed amount in a year.3 Ideally, the totally ordered set is mapped onto a convex function whose range goes from -1(totally unsatisfied) to 1 (perfectly satisfied) and the mapping of thresholds define a region of\u201csatisficing\u201d scores.226 P. Noriega et al.A minimalistic way of measuring value satisfaction, on the other hand, may consistssimply in mapping all the possible observable outcomes onto a finite set of proxy scoresthat are each labelled with a degree of satisfaction that reflect the boundaries defined inthe interpretation of the value. For example, in Easyrider, the railway company wants tofill trains but not too much if it wants to keep passengers satisfied. The owner satisfac-tion depends not only on the number of unsold seats (few sold seats, not good; totallyfull trains, not good either), but also in how the empty seats are distributed in eachcarriage (few passengers but all stuck at the back, not good; groups of friends seatedtogether, good). Satisfaction of passengers\u2019 comfort and conviviality as well as affect-ing the railway company\u2019s balanced cash-flow could be measured, for example with apairwise preference combination of density vs seat configurations and the degree of sat-isfaction of each pair with a ranking, say, unacceptable, undesirable, satisfactory, verysatisfactory. Even more radical, the value accountability may be interpreted as respon-sibility by the owner and in this case, if the same bonding mechanism is afforded, itsfulfillment duly regulated and its enforcement strict \u2013 all these conditions achievable atimplementation time \u2013 its assessment is ex-ante satisfactory.The third component of the value assessment model is an aggregation function thatcombines the stakeholder\u2019s satisfaction with all and every value; and thus assess theextent to which the OI aligns with the combined set of stakeholder\u2019s values. The aggre-gation function should take into account the priorities and trade-offs between values andother features like their urgency, associated costs or expected evolution of the observ-able features involved with those values.Heuristic 10. An aggregation function combines the level of satisfaction of severalvalues into a single outcome that represents the aggregate satisfaction derived by thestakeholder from the combination of those values.4A thorough discussion of aggregation functions is beyond the scope of this paperbut one can get an idea with a simple version of the engineer\u2019s aggregation function.A top-down definition of the engineer\u2019s aggregation function may be to aggregate thedegree of satisfaction of the engineer with each of its three CD values defined in Table 1,as follows: (i) Assessment of satisfaction of thoroughness and responsibility is essen-tially technical. The first will be the result of the aggregation of the degrees of satisfac-tion of the four thoroughness goals and by assessing that mindfulness, responsibility,integrity, cohesiveness and compatibility are dully validated. (ii) Likewise responsibilityis assessed through the assessment of the (technical) soundness of integrity and com-patibility of the OI. (iii) However, satisfaction of mindfulness requires that all the val-ues of users and owner have been properly \u201cengineered\u201d (specified and implemented)but for that owner and users have to agree on the way their values are interpreted andrepresented. Thus engineer\u2019s mindfulness depends on users and owner agreeing thattheir own values of throroughness, mindfulness, and responsibility are satisfied withthe observable features and thresholds that they agree upon.4 Note that to determine the alignment of an OI with a set of values, which is the ultimate purposeof making values operational, one needs a top level aggregation function that combines thedegrees of satisfaction of all stakeholders.Design Heuristics for Ethical Online Institutions 227This very last aggregation involving the satisfaction of the other stakeholders buildson the process of participatory design of the OI and on the assessment of each separatevalue in terms of the observable feature that stands for it (which is the same for everystakeholder). The way these detailed assessment are aggregated may be different foreach stakeholder but in this case, the engineer has priority on some CD design contexts(part b in Table 1) and thus its aggregation function of non-priority context will be thatof the other stakeholders but the engineer\u2019s may be more demanding for the values inits own priority contexts. The owner, as the stakeholder who is responsible for com-missioning, deploying, updating and preserving the operation of the OI, has the lastword.Note that the purpose of the aggregation function is two-fold: first to commit to anencompassing measure of satisfaction that reflects value priorities and trade-offs for thestakeholder; second to determine if the alignment of the OI with the set of values is\u201cgood enough\u201d for the stakeholder. Consequently, if the alignment is not good enough,the aggregation function and the value assessment model in general can be used to pin-point those values that are not properly embedded in the OI. If a global assessmentmodel is not satisfactory, a compromise can usually be reached by revising the aggre-gation function, simplifying value measurement, and relaxing satisfaction thresholds.Heuristic 11. Improvement of value alignment. When a value alignment is not satis-factory, revise the steps of the operationalisation process backwards until stakeholdersare satisfied.The idea behind this heuristic is the following: from a bottom up perspective, eachstakeholder chooses its own values, how to interpret them, and the observable featuresthat are used to determine whether the value is being satisfied (and to what degree)(Heuristic 7). One underlying assumption of OIs is that there are observable featureswhich are common to all stakeholders. However, not all stakeholders will hold the samevalues in general, and therefore not all observable features will be equally relevant fordifferent stakeholders. This means that each stakeholder will combine and prioritizethe observable features in different ways. This difference, is unproblematic unless aconflict of the interpretation and assessment of values among stakeholders arises. Whenthis occurs, the conflict can be resolved by incorporating additional observable features(and the new required means to achieve them) that are relevant for the stakeholder whois unsatisfied with a specific interpretation of a value into means, ends and observablefeatures.From a top-down perspective, we can assume all stakeholders aggregate values inour three CD categories: thoroughness, mindfulness and responsibility. The aggregationfunction of each stakeholder is unlikely to be the same in general, and agreement, orsome other form of reconciliation should take place, in order to the the OI to be alignedwith each of its stakeholders values. This is unproblematic as long as the stakehold-ers agree on some trade-offs which may be reached if some stakeholders change theweighting of some values in the aggregation function, or choose to relax their levels ofsatisfaction with respect to certain values.The final trade-off agreement may be reached by moving back and forth from theaggregation at different levels of value decomposition within each category.228 P. Noriega et al.5 Closing RemarksIn this paper we propose heuristics to make stakeholder values operational in onlineinstitutions. These heuristics belong to a larger task to provide general methodologicalguidelines for a principled approach to embedding values in AI systems. It seems clearto us that any such approach requires that values are made explicit, that their interpre-tation can be translated into a machine executable representation, and that their satis-faction can be objectively assessed. We claim that while these conditions are necessary,we do not impose any further requirements to value theory.In the heuristics we propose, we remain neutral about the choice of formalismsused for representation and for the assessment of values. (Though we are consideringusing Z with its ability to capture both agent architectures, multi-agent systems anddesign methodologies [5,6,16].) However, we believe that for certain types of onlineinstitutions (and AIS in general) there are reasons to adopt specific interpretations ofeach value in terms of a means and ends decomposition that give grounds to morespecific representation and assessment conventions, whilst recognising they might notnecessarily be unique.Whilst focus of this paper has been on heuristics for making values operationalin governed multi-agent systems, we believe that heuristics could be similarly appliedto the embedding and assessment of values in the design of individual autonomousagents. Nevertheless, there are specific aspects of the design process that would needto address the role of values in designing artificial agents\u2019 architectures and behaviour.For instance, for an artificial agent that is intended to behave in an ethically-consistentmanner, the engineer may commit to some cognitive architecture that includes valuesas an explicit and necessary construct in their inference-based decision-making models,or make explicit use of value theories that explain ethical behaviour without assumingrational ethical reasoners [24].We mention elsewhere [21] that one could apply the conscientious design approachto developing tools to prevent undesirable effects of existing third party software. Theheuristics we propose in this paper can be used to determine whether the behaviours of agiven system is aligned with any explicitly stated values. This leads us to the possibilityof adding, to such existing systems, new functionality that ensure they behave withproper alignment with respect to any stated values. This is something we plan to addressin future work. In addition, our intentions include developing our approach to supportpolicy makers, evolving stronger good practices, and making use-cases readily availableto facilitate uptake.The process of making values operational that we discuss in this paper is at thecore of the Value Alignment Problem, which concerns the embedding of values in arti-ficial autonomous systems and assessing their alignment. However, our proposal canbe placed in a wider perspective of developing a theory of value with a distinctive AIflavour. The value theory we foresee would be centered on the interplay of governance,autonomy, and collective hybrid behaviour and because artificial autonomous entitiesare involved, there are meta-ethical, normative ethics, and applied ethical problems thatother theories of values do not address. In fact, unlike other theories of value, suchan \u201cartificial axiology\u201d purports to embed ethical constructs into artefacts and assessethical questions associated with them. The approach we envision shares with AI andDesign Heuristics for Ethical Online Institutions 229other sciences of the artificial a peculiar mix of science and engineering; it would drawon constructs and methods from AI and other sciences of the artificial, and require aserious interdisciplinary effort.Acknowledgements. D\u2019Inverno thanks IIIA-CSIC Barcelona for hosting him during a researchsabbatical and his host institution Goldsmiths, University of London for making that possible.Noriega\u2019s work is supported in part by the CIMBVAL project (Spanish government project#TIN2017-89758-R).References1. Aldewereld, H., Padget, J., Vasconcelos, W., V\u00e1zquez-Salceda, J., Sergeant, P., Staikopoulos,A.: Adaptable, organization-aware, service-oriented computing. IEEE Intell. Syst. 25(4), 26\u201335 (2010). http://doi.ieeecomputersociety.org/10.1109/MIS.2010.932. Alexander, C.: A Pattern Language: Towns, Buildings, Construction. OUP, New York (1977)3. Alexander, C.: The Timeless Way of Building, vol. 1. OUP, New York (1979)4. Deming, W.E.: Quality, productivity, and competitive position. MIT Press (1982). https://en.wikipedia.org/wiki/Total_quality_management, https://en.wikipedia.org/wiki/Kaizen,https://en.wikipedia.org/wiki/Eight_dimensions_of_quality5. d\u2019Inverno, M., Luck, M.: Development and application of a formal agent framework. In:First IEEE International Conference on Formal Engineering Methods, pp. 222\u2013231 (1997).https://doi.org/10.1109/ICFEM.1997.6304296. d\u2019Inverno, M., Luck, M., Noriega, P., Rodriguez-Aguilar, J.A., Sierra, C.: Communicatingopen systems. Artif. Intell. 186, 38\u201394 (2012). https://doi.org/10.1016/j.artint.2012.03.0047. Fjeld, J., Achten, N., Hilligoss, H., Nagy, A., Srikumar, M.: Principled artificial intelligence:Mapping consensus in ethical and rights-based approaches to principles for AI. TechnicalReport 2020\u20131, Berkman Klein Center Research Publication (2020)8. Friedman, B.: Value-sensitive design. Interactions 3(6), 16\u201323 (1996)9. Friedman, B.: The ethics of system design. In: Computers, Ethics and Society, pp. 55\u201363(2003)10. Friedman, B., Hendry, D.G., Borning, A.: A survey of value sensitive design methods. Found.Trends Hum.-Comput. Interact. 11(2), 63\u2013125 (2017)11. High-Level Expert Group on Artificial Intelligence (AI HLEG): Ethics Guidelinesfor Trustworthy AI (2019). https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai12. Hofstede, G., Hofstede, G.J., Minkov, M.: Cultures and Organizations - Software of theMind: Intercultural Cooperation and its Importance for Survival. McGraw-Hill, New York(2010)13. Inglehart, R.: Human beliefs and values: A cross-cultural sourcebook based on the 1999\u20132002 values surveys. Siglo XXI (2004)14. Jones, A.J.I., Sergot, M.: A formal characterisation of institutionalised power. Logic J. IGPL4(3), 427\u2013443 (1996)15. Liscio, E., van der Meer, M., Siebert, L.C., Jonker, C.M., Mouter, N., Murukannaiah, P.K.:Axies: identifying and evaluating context-specific values. In: Proceedings of the 20th interna-tional conference on autonomous agents andMultiAgent systems, pp. 799\u2013808. InternationalFoundation for Autonomous Agents and Multiagent Systems (2021)16. Luck, M., D\u2019Inverno, M.: Structuring a Z specification to provide a formal framework forautonomous agent systems. In: Bowen, J.P., Hinchey, M.G. (eds.) ZUM 1995. LNCS, vol.967, pp. 46\u201362. Springer, Heidelberg (1995). https://doi.org/10.1007/3-540-60271-2_112230 P. Noriega et al.17. Morley, J., Floridi, L., Kinsey, L., Elhalal, A.: From what to how: an initial review of pub-licly available ai ethics tools, methods and research to translate principles into practices.Science and Engineering Ethics 26(4), 2141\u20132168 (2019). https://doi.org/10.1007/s11948-019-00165-518. Noriega, P., Padget, J., Verhagen, H.: Anchoring online institutions. In: Casanovas, P.,Moreso, J.J. (eds.) Anchoring Institutions. Democracy and Regulations in a Global and Semi-automated World. Springer, Heidelberg (2022). in press19. Noriega, P., Padget, J., Verhagen, H., d\u2019Inverno, M.: Towards a framework for socio-cognitive technical systems. In: Ghose, A., Oren, N., Telang, P., Thangarajah, J. (eds.) COIN2014. LNCS (LNAI), vol. 9372, pp. 164\u2013181. Springer, Cham (2015). https://doi.org/10.1007/978-3-319-25420-3_1120. Noriega, P., Sabater-Mir, J., Verhagen, H., Padget, J., d\u2019Inverno, M.: Identifying affordancesfor modelling second-order emergent phenomena with the WIT framework. In: AutonomousAgents and Multiagent Systems - AAMAS 2017 Workshops, Visionary Papers, S\u00e3o Paulo,Brazil, 8\u201312 May 2017, Revised Selected Papers, pp. 208\u2013227 (2017)21. Noriega, P., Verhagen, H., d\u2019Inverno, M., Padget, J.: A manifesto for conscientious design ofhybrid online social systems. In: Cranefield, S., Mahmoud, S., Padget, J., Rocha, A.P. (eds.)COIN -2016. LNCS (LNAI), vol. 10315, pp. 60\u201378. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-66595-5_422. Noriega, P., Verhagen, H., Padget, J., d\u2019Inverno, M.: Ethical online AI systems through con-scientious design. IEEE Internet Comput. 25(6), 58\u201364 (2021)23. North, D.: Institutions. Institutional Change and Economic Performance, CUP (1991)24. Perello-Moragues, A., Noriega, P.: Using agent-based simulation to understand the roleof values in policy-making. In: Verhagen, H., Borit, M., Bravo, G., Wijermans, N. (eds.)Advances in Social Simulation. SPC, pp. 355\u2013369. Springer, Cham (2020). https://doi.org/10.1007/978-3-030-34127-5_3525. Perello-Moragues, A., Noriega, P., Popartan, L.A., Poch, M.: On three ethical aspectsinvolved in using agent-based social simulation for policy-making. In: Ahrweiler, P., Neu-mann, M. (eds.) ESSA 2019. SPC, pp. 415\u2013427. Springer, Cham (2021). https://doi.org/10.1007/978-3-030-61503-1_4026. van de Poel, I.: Embedding values in artificial intelligence (AI) systems. Minds Mach. 30(3),385\u2013409 (2020)27. Rokeach, M.: The Nature of Human Values. Free press (1973)28. Russell, S.: Living with artificial intelligence (2021). https://www.bbc.co.uk/programmes/b00729d9/episodes/downloads29. Schwartz, S.H.: An overview of the Schwartz theory of basic values. Online Read. Psychol.Cult. 2(1), 11 (2012)30. Searle, J.R.: The Construction of Social Reality. The Penguin Press, Allen Lane (1995)31. Simon, H.A.: Models of Man: Social and Rational. Wiley, Hoboken (1957)32. The IEEE Global Initiative on Ethics of Autonomous and Intelligent System: Ethicallyaligned design: A vision for prioritizing human well-being with autonomous and intel-ligent systems, first edition (2019). https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead1e.pdf33. Umbrello, S., Van de Poel, I.: Mapping value sensitive design onto AI for social good prin-ciples. AI Ethics 1(3), 283\u2013296 (2021)34. Verhagen, H., Noriega, P., d\u2019Inverno, M.: Towards a design framework for controlled hybridsocial games. In: Social Coordination: Principles, Artefacts and Theories, SOCIAL.PATH2013 - AISB Convention 2013, pp. 83\u201387 (2013)Author IndexAbuhaimed, Sami 167Ajmeri, Nirav 185Alechina, Natasha 38Antoniades, Andreas 54Bartelt, Christian 73Brand\u00e3o, Anarosa A. F. 121Cheang, Rafael M. 121Cranefield, Stephen 201Cunha, Rafhael R. 134d\u2019Inverno, Mark 213Dalpiaz, Fabiano 38Dastani, Mehdi 38de Brito, Maiquel 134Dell\u2019Anna, Davide 38Dignum, Frank 92Dubied, Mathieu 148Erdogan, Emre 92Fratric\u030c, Peter 109H\u00fcbner, Jomi F. 134Klous, Sander 109Kwik, Jonathan 1L\u00f6ffler, Maarten 38Logan, Brian 38L\u00fcdtke, Stefan 73Mertzani, Asimina 19Methnani, Leila 54Michalak, Tomasz 19Noriega, Pablo 213Nowak, Andrzej 19Oesterle, Michael 73Padget, Julian 213Pitt, Jeremy 19, 148, 201Scott, Matthew 148Sen, Sandip 167Sichman, Jaime S. 121Sileno, Giovanni 109Singh, Munindar P. 185Srivathsan, Sriashalya 201Stuckenschmidt, Heiner 73Theodorou, Andreas 54Tzeng, Sz-Ting 185van Engers, Tom 1, 109Verbrugge, Rineke 92Verhagen, Harko 213Yolum, P\u0131nar 92Zurek, Tomasz 1",
      "id": 149021242,
      "identifiers": [
        {
          "identifier": "581256139",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:pure.rug.nl:openaire_cris_publications/71f63924-0110-428b-bb70-c08e47286d26",
          "type": "OAI_ID"
        },
        {
          "identifier": "581187913",
          "type": "CORE_ID"
        },
        {
          "identifier": "581197414",
          "type": "CORE_ID"
        },
        {
          "identifier": "581368191",
          "type": "CORE_ID"
        },
        {
          "identifier": "581191271",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:pure.rug.nl:publications/71f63924-0110-428b-bb70-c08e47286d26",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1007/978-3-031-20845-4_6",
          "type": "DOI"
        }
      ],
      "title": "Computational Theory of\u00a0Mind for\u00a0Human-Agent Coordination",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:pure.rug.nl:publications/71f63924-0110-428b-bb70-c08e47286d26",
        "oai:pure.rug.nl:openaire_cris_publications/71f63924-0110-428b-bb70-c08e47286d26"
      ],
      "publishedDate": "2022-11-24T00:00:00",
      "publisher": "Springer Science and Business Media Deutschland GmbH",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://pure.rug.nl/ws/files/736699696/978-3-031-20845-4.pdf"
      ],
      "updatedDate": "2023-10-30T13:07:00",
      "yearPublished": 2022,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/581191271.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/581191271"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/581191271/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/581191271/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/149021242"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Catalina Gomez"
        },
        {
          "name": "Chien-Ming Huang"
        },
        {
          "name": "Mathias Unberath"
        },
        {
          "name": "Shichang Ke"
        },
        {
          "name": "Sue Min Cho"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/648140148"
      ],
      "createdDate": "2025-03-30T00:50:20",
      "dataProviders": [
        {
          "id": 645,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/645",
          "logo": "https://api.core.ac.uk/data-providers/645/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "Leveraging Artificial Intelligence (AI) in decision support systems has disproportionately focused on technological advancements, often overlooking the alignment between algorithmic outputs and human expectations. A human-centered perspective attempts to alleviate this concern by designing AI solutions for seamless integration with existing processes. Determining what information AI should provide to aid humans is vital, a concept underscored by explainable AI's efforts to justify AI predictions. However, how the information is presented, e.g., the sequence of recommendations and solicitation of interpretations, is equally crucial as complex interactions may emerge between humans and AI. While empirical studies have evaluated human-AI dynamics across domains, a common vocabulary for human-AI interaction protocols is lacking. To promote more deliberate consideration of interaction designs, we introduce a taxonomy of interaction patterns that delineate various modes of human-AI interactivity. We summarize the results of a systematic review of AI-assisted decision making literature and identify trends and opportunities in existing interactions across application domains from 105 articles. We find that current interactions are dominated by simplistic collaboration paradigms, leading to little support for truly interactive functionality. Our taxonomy offers a tool to understand interactivity with AI in decision-making and foster interaction designs for achieving clear communication, trustworthiness, and collaboration",
      "doi": "10.3389/fcomp.2024.1521066",
      "downloadUrl": "https://core.ac.uk/download/648140148.pdf",
      "fieldOfStudy": null,
      "fullText": "TYPE ReviewPUBLISHED 06 January 2025DOI 10.3389/fcomp.2024.1521066OPEN ACCESSEDITED BYStefan Kopp,Bielefeld University, GermanyREVIEWED BYStyliani Kleanthous,Open University of Cyprus, CyprusMilus\u0306e Balkov\u00e1,Institute of Technology and Business, Czechia*CORRESPONDENCEMathias Unberathunberath@jhu.eduRECEIVED 01 November 2024ACCEPTED 06 December 2024PUBLISHED 06 January 2025CITATIONGomez C, Cho SM, Ke S, Huang C-M andUnberath M (2025) Human-AI collaboration isnot very collaborative yet: a taxonomy ofinteraction patterns in AI-assisted decisionmaking from a systematic review.Front. Comput. Sci. 6:1521066.doi: 10.3389/fcomp.2024.1521066COPYRIGHT\u00a9 2025 Gomez, Cho, Ke, Huang andUnberath. This is an open-access articledistributed under the terms of the CreativeCommons Attribution License (CC BY). Theuse, distribution or reproduction in otherforums is permitted, provided the originalauthor(s) and the copyright owner(s) arecredited and that the original publication inthis journal is cited, in accordance withaccepted academic practice. No use,distribution or reproduction is permittedwhich does not comply with these terms.Human-AI collaboration is notvery collaborative yet: ataxonomy of interaction patternsin AI-assisted decision makingfrom a systematic reviewCatalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huangand Mathias Unberath*Department of Computer Science, Johns Hopkins University, Baltimore, MD, United StatesLeveraging Artificial Intelligence (AI) in decision support systems hasdisproportionately focused on technological advancements, often overlookingthe alignment between algorithmic outputs and human expectations. Ahuman-centered perspective attempts to alleviate this concern by designing AIsolutions for seamless integration with existing processes. Determining whatinformation AI should provide to aid humans is vital, a concept underscored byexplainable AI\u2019s e\u0000orts to justify AI predictions. However, how the informationis presented, e.g., the sequence of recommendations and solicitation ofinterpretations, is equally crucial as complex interactions may emerge betweenhumans and AI. While empirical studies have evaluated human-AI dynamicsacross domains, a common vocabulary for human-AI interaction protocols islacking. To promote more deliberate consideration of interaction designs, weintroduce a taxonomy of interaction patterns that delineate various modes ofhuman-AI interactivity. We summarize the results of a systematic review ofAI-assisted decision making literature and identify trends and opportunitiesin existing interactions across application domains from 105 articles. We findthat current interactions are dominated by simplistic collaboration paradigms,leading to little support for truly interactive functionality. Our taxonomy o\u0000ers atool to understand interactivity with AI in decision-making and foster interactiondesigns for achieving clear communication, trustworthiness, and collaboration.KEYWORDSartificial intelligence, human-AI interaction, decision-making, interaction patterns,interactivity1 IntroductionAdvances in Artificial Intelligence (AI) developments open new possibilities forsupporting human decision making across a wide variety of applications. Decision makingtasks in a broad range of applications share a process that starts when evidence is presentedbeforemaking a decision within discrete choices, usually with follow-up effects.Within thisframework, the decision-making process emerges as a scenario for human-AI teamworkwhere at aminimum two parties, i.e., the human and the AI, factor into finding a solution tothe decision problem. The exact dynamics of how this collaboration occurs can vary fromone situation to another, leading to multiple interaction options that range from simpleFrontiers inComputer Science 01 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066recommendations to involved exchanges (Bansal et al., 2019; Laiet al., 2023; Bertrand et al., 2023). To bridge algorithmic suggestionsand human expectations, embracing a human-centered approachin designing AI solutions is crucial to identify what information AIshould provide to aid humans while ensuring a safe and transparentoperation. It is equally crucial to understand how and when tobest communicate the information for designing successful human-AI interactions. Explainable AI (XAI) expands model capabilitiesby providing not just so-called black box recommendations butalso justifications tailored to end users\u2019 needs. The design ofjustifications from a human-centered perspective informs what AImodels should deliver and it naturally involves careful thoughton how to present this support, although it may not specificallyaddress the ensuing interactions. The presentation style (how) andthe strategic timing (when) for providing AI-generated insights areclosely related to the type and sequence of interactions betweenhumans with AI, which are ultimately enabled by the affordancesof certain assistance elements (Lai et al., 2023). Despite theimportance of and opportunities in interaction design within AI,there is not currently a common vocabulary to describe anddifferentiate these interactions.Interactivity is a familiar concept to humans and widely studiedin more specialized domains such as information visualization,interface and software design (Yi et al., 2007), and human-human interactions from a social perspective (Magnusson,2018). Understanding interactions requires delving into multipledimensions that involve subjects, modes, and purposes ofinteraction, and the context in which they take place (Schleidgenet al., 2023). Among these, interaction patterns emerge as sequencesof behaviors that occur more often than by chance betweenagents and systems or artifacts. We have learned from thesedisciplines the importance of deliberate choices in selectinginteraction types crucial for achieving specific goals, rather thanimbuing unnecessary high levels of interactivity that do notresult in better products (Sims, 1997). Likewise, finding the rightbalance of interactivity between humans and AI systems is notjust a matter of enhancing user experience but is essential forachieving clear communication, trustworthiness, and meaningfulcollaboration. While current AI systems excel in offering problem-solving capabilities, there is often a disproportionate emphasis onthe technological advancements, overlooking the critical aspects ofuser interface and experience. This oversight is apparent in manyempirical studies in diverse domains and decision tasks (Lai et al.,2023; Bertrand et al., 2023), where interactions with AI agents aretypically reduced to basic actions like menu selections or buttonclicks. However, the specific configurations needed to evaluate theeffect of different AI assistance elements (or other context-relatedfactors) on humans interacting with AI, can lead to multiple formsof collaboration or the actual interactions afforded.Which forms of interactivity to incorporate in human-AI interactions is an open question and may depend on theoverall context, emphasizing the need to deliberately studyinteraction patterns between humans and AI that can guide thedevelopment of better solutions. Psychology and social scienceshave extensively studied human-human interactions, revealingpatterns of reciprocal actions, such as \u201cQuestion-Answer\u201d and\u201cRequest-Offer\u201d (Magnusson, 2018), which can also be appliedin a setup where humans interact with AI. Likewise, the fieldof Human-Robot Interaction (HRI) has studied how humansand robots communicate, collaborate, and engage with eachother, often through the analysis of observable patterns intheir interactions (David et al., 2022; Saupp\u00e9 and Mutlu, 2014;Ma and Cao, 2019). These patterns cover aspects of socialinteractions like greetings, attention, feedback, turn-taking, socialcues, and farewell. All these elements foster a more natural andefficient communication experience, which can take place in AItechnologies that incorporate natural language abilities. Otherdomains such as information visualization and user interfacedesign have also developed taxonomies and libraries of interactionpatterns based on different criteria such as user\u2019s intent, purpose,scope, abstraction level, and granularity (Yi et al., 2007; Silva-Rodr\u00edguez et al., 2020). These categorizations serve as a baseto build on more comprehensive taxonomies grounded on andinformed by evidence from empirical studies and incorporatingknowledge from interaction design in other disciplines. In thecontext of AI, descriptions of possible interactions betweenhumans and machines or AI have grouped them by usercontrol and initiative (Van Berkel et al., 2021; Cheng et al.,2022), task nature (Parasuraman et al., 2000), and level ofautomation (Mackeprang et al., 2019). Existing classificationsof human-AI interactions are often domain-specific, lacking acomprehensive framework that spans multiple domains. Withouta shared vocabulary to describe human-AI interactions in decision-making tasks, it becomes difficult to compare approaches,aggregate findings, and synthesize knowledge across diversestudies, ultimately limiting the exploration of new interactionparadigms. This highlights the importance of a structuredframework for categorizing different interaction patterns, helpingdesigners understand and improve human-AI collaboration, andfacilitating informed decisions in interaction design to enhancepartnerships between humans and AI.To address this gap, we first conducted an extensive systematicreview on human-AI interactions that have been reportedfor human-AI decision making scenarios. We searched forrelevant articles from five databases that cover Human-ComputerInteraction (HCI) studies and related disciplines and selected 105to conduct a detailed coding and analysis of the sequences ofinteractions that exist between humans and AI. Furthermore, weconsidered the task context and AI system involved in theseempirical studies. Recent review works have characterized thedesign space in human-subject studies with AI for decision-making, providing insights about AI assistance elements (Laiet al., 2023) and methodologies to empirically evaluate humanfactors (Vereschak et al., 2021). XAI has been a main subject ofreviews as well, not only to structure existing techniques (Sheuand Pardeshi, 2022), but also to investigate human factors thatarise during decision making, including cognitive biases (Bertrandet al., 2022) and cognitive processes supported by interactiveexplanations (Bertrand et al., 2023). For our review, we selectedempirical studies involving decision tasks where users are activelyaware of the interaction and engaged in the decision-makingprocess, as this focus was crucial for studying the dynamicsof human-AI interactions. Grounded in the trends from oursystematic review, we propose a taxonomy of interaction patternsFrontiers inComputer Science 02 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066that comprises seven interaction patterns that arise betweenhumans and AI. To the best of our knowledge, there is notyet a comprehensive and structured classification of existinginteraction patterns between humans and AI. We propose ourtaxonomy of interactions as a tool to better understand existinginteraction patterns across domains and applications, allowing usto identify the occurrences of common interactions across multipledomains. We envision the use of taxonomy to foster dialogues oninteractivity in AI-assisted decision making, encourage refinementand evaluation of novel patterns, and ultimately design better andmore user-centered AI-based solutions.2 Methods2.1 Search strategy and selection criteriaThis survey focuses on Human-AI interaction paradigms forexplicit decision-making tasks, in contrast to proxy task whereusers are asked to simulate the AI outputs. Therefore, we aimto understand and evaluate the works that study human-AIinteractions during decision-making tasks under AI assistance,instead of improvements of the model. Our survey coversstudies conducted between 2013 and June 2023. Specifically,we searched within five databases: ACM Digital Library, IEEEExplore, Compendex, Scopus, and PubMed. The first fourhave extensive coverage of relevant studies in HCI coveringconference proceedings and journal publications (Compendexand Scopus included papers from more subjects), while PubMedallowed us to capture research specifically related to medicalapplications of Human-AI interaction and decision-making. Wewere particularly interested in empirical studies with AI inthe healthcare domain because of the need for human-subjectsresearch in AI\u2019s development cycle and the importance of aligningalgorithms with user needs and clinical workflows (Chen et al.,2022; van de Sande et al., 2024). The study of existing interactionsbetween humans and AI support can suggest new directions andopportunities to enhance the experience and outcomes of using AIto support decision making in healthcare. We defined the searchterms covering four dimensions: use of AI systems, human-AIinteraction or collaboration studies, decision-making tasks, andinteraction design. We included the last term since we wanted tofocus on articles that evaluate interactions with AI systems duringdecision making tasks. The complete set of keywords used in oursearch can be found in the Appendix A. We defined the followinginclusion criteria:\u2022 The tasks in consideration are those related to decision-making, and in particular, we limit the study selection tothose that implement complete decisionmaking processes andnot only evaluations of decision makers\u2019 perceptions, such asunderstanding, preferences, or judgments of AI\u2019s advice.\u2022 The paper shows an implementation of the interface that waspresented to human users to interact with AI.\u2022 The modes of interaction encompass screen-based interfaces,virtual agents, and non-embodied setups.\u2022 We have restricted our selection solely to papers featuringempirical user studies.In addition to the inclusion criteria above, our search excludedstudies in robotics and gaming by filtering out these keywordsin the title and abstract. We excluded studies that involve robotsbecause physical embodiment enables more dimensions of aninteraction and those involving gaming scenarios because theyare more complex, with less constraints to study how humanscan interact with AI assistance. However, studies that implementdecision making tasks through gamified tasks were included. Othersurvey papers or comments were also excluded by filtering outkeywords in the title and abstract.2.2 Study selectionThe initial search returned 3,770 papers, and 358 duplicateswere found and deleted automatically. This left us with a totalof 3,412 papers to screen. They were assigned to two authors tofirst go through title and abstract screening, followed by full-textscreening. The screening phase was oriented toward the exclusionof papers that were not focused on human-AI interaction, i.e.,limited to technical contributions, did not involve a completedecision-making task, were short papers (<8 pages), involve gamingor robotics, have not been peer-reviewed, and were review or surveypapers. We did not constrain our selection to works that directlymanipulate the type of interaction between the human and AI. Ourmain interest was on which were the existing/available ways forhumans to interact with AI agents in the evaluation of human-AIdecision making. The total and abstract screening excluded 2,893papers, and at the full-text review stage, 363 papers were filteredout. Lastly, 156 were considered for the information extractionstage, of which 51 were removed as a more detailed reading allowedus to identify that they did not satisfy the inclusion criteria ofsupporting actual AI-assisted decision making tasks. Appendix Bsummarizes the complete paper selection process. At the end, 105articles were included in our review.2.3 Data extraction strategy2.3.1 Analysis processThe data extraction template was developed by all authors andinformed by previous surveys of empirical studies in human-AIinteraction (Bertrand et al., 2023; Lai et al., 2023). Two authorsdistributed the final selected articles to be analyzed and codedthe assigned articles independently. Then, one author checked theindividual reports of each article to ensure consistency in the finalextraction. Further discussions with the other authors took placeto clarify discrepancies in the interactions or ambiguous cases. Forthe analysis of the interaction patterns, the authors reviewed thesequences of interactions and discussed how to group them into thedesign patterns that were repeated and are presented in this work.We iterated over the definition of each pattern to refine the actualcomponents that constitute the interaction.2.3.2 Coding of the papersThe following components comprised the extraction template:Frontiers inComputer Science 03 frontiersin.orgGomez et al. 10.3389/fcomp.2024.15210662.3.2.1 ContextWe identified general information in which the decisionmaking task takes place. This includes the domain and we adaptedthe categories initially proposed in this survey of AI-assisteddecision making (Lai et al., 2023). Furthermore, we specified thedecision making task to be completed by the human (e.g., detectionof hate speech, sleep stage classification, price estimation, amongothers) and the level of expertise required to successfully completethe task.2.3.2.2 AI systemAs we are interested in humans interactions with AI agents,we retrieved the original goal of incorporating AI assistance in thedecision making task, and briefly characterized the AI system usedin the study. In particular, we extracted the technique supportingthe AI\u2019s recommendations (whether a real model was used orthe outcomes were simulated), its performance (if any evaluationmetric was reported), and the terminology used to introduce the AIagent to participants in the user study. Further details such as datatype and source, output type were not reported as the main focus ofthis survey is on the interactions rather than the type of AI methodsas previously surveyed in Lai et al. (2023).2.3.2.3 Interaction building blocksAn interaction involves a reciprocal action or influence betweentwo agents in the context of this survey (Schleidgen et al., 2023). Tocharacterize this, we defined two elements: the action undertakenand the resulting output of that action. These two elementsconstitute the interaction building blocks that can be integratedinto more complex interactions. In the definition of our taxonomyof human-AI interactions, we considered these building blocksas the main elements that constitute the interaction patterns.Our familiarity with prior studies on human-AI interactionsserved as an initial reference to ideate the (action - output) pairsavailable for the agents involved in the interaction, namely thehuman and AI parts. We further drew inspiration from existinginteraction design patterns developed for prototyping human-robot interaction (Saupp\u00e9 and Mutlu, 2014) and a taxonomyof interactivity techniques in XAI (Bertrand et al., 2023). Weconsidered the actions listed in these works to characterize theinteractions and functionality of explanations, respectively, andhow they could be extended to agents involved in decision-makingtasks. These building blocks primarily focus on the AI assisting theuser in decision-making processes and are grouped based on themain action and specify the agent that can execute it. It is importantto highlight that these building blocks can also occur sequentially,where one may be triggered in response to another. However, wehave chosen to maintain a granular level of detail in the followingdescriptions to better capture the nuances of individual actions thatlater compose the interaction patterns.\u2022 Predict - Outcome: The agent produces a solution tothe primary decision-making task after receiving taskinformation. This action is observed to be executed by eitherthe AI or the user independently.\u2022 Decide - Outcome: The agent integrates the assistance theyreceived with the task-related information available to finalizethe decision outcome. This action is typically observed to beexecuted by the user.\u2022 Provide - Options: The agent offers solutions for a secondarytask that, while not directly resolving the primary decision-making task, are still informative. This action is typicallyobserved to be executed by the AI.\u2022 Display - Information: The agent presents supplementaryevidence (e.g., explanations, uncertainty values, alternatesolutions) supporting a solution to the primary decision-making task. This action is observed to be predominatelyexecuted by the AI.\u2022 Request - Outcome/Information: The agent actively seeksinformation or solutions from its counterpart. This action isobserved to be either mandatory or optional and is typicallyexecuted by the AI when it requires user inputs, or bythe user when they seek a direct solution or supplementaryinformation from the AI.\u2022 Collect - Inputs: The agent gathers task-related informationand provides it to the other agent. This action is observed tobe typically executed by the user when their input is neededfor the AI to provide a solution to the decision-making task.\u2022 Modify - Outcome/Information: The agent makes changes tothe solutions or supplementary information provided by itscounterpart. This action is typically observed to be optionaland executed by the user.\u2022 Delegate - Decision: The agent decides whether to retainresponsibility for the task or transfer to its counterpart. Thisaction is observed to be executed by either the AI or theuser. Events after delegation can differ, ranging from completesurrender of agency to opportunities for supervising the otheragent\u2019s decision-making process.\u2022 Other: if an action does not fit the previous types.These concepts were refined and iterated as we reviewed moreworks since there could be new actions supported for either agent,while trying to maintain the generalizability of the blocks acrossmultiple studies. For each paper, we first identified all possible(action - output) pairs as the building blocks for each agent involvedin the decision-making task and included a brief description in freetext form. Then, we defined a sequence of interactions consideringthe order in which these events take place and the agent in charge.The sequences were not preset in advance in the extraction templatesince we wanted to discover the interaction patterns here. We notethat depending on the experimental manipulation of the user study,different modes of interactivity with the user could be plausible andwe separated these into different sequences.3 Results3.1 Taxonomy of interaction patterns forAI-assisted decision makingWe present seven categories of interaction patterns that wehave identified in our corpus, illustrated in Figure 1. Interactionsinvolve changes over time and we attempted to capture thisevolution/progression in the interaction patterns presented belowand in the diagrams that illustrate them. To formulate theFrontiers inComputer Science 04 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066FIGURE 1Taxonomy of interaction patterns identified in AI-assisted decision making. The user (human) and the AI are represented as separate agents and thetemporal evolution of the interactions is illustrated from top to down. The boxes contain the building blocks (action-output) pairs that compose eachpattern. The direction of arrows denote the agent who started the action. Dashed lines represent optional operations.taxonomy, we began by reviewing previous literature containingtaxonomies of interaction techniques in other domains, suchas information visualization (Yi et al., 2007), human-robotinteraction (Saupp\u00e9 and Mutlu, 2014), multi-agent systems (Cabriet al., 2002), and educational technologies (Sims, 1997). Contrastingthe concepts in these taxonomies with a sample of studies inhuman-AI interaction that we were familiar with, we identifiedpotential ways in which the types of interactions describedpreviously could potentially apply to humans interacting with AIduring decision making. As we analyzed the articles includedin our review, we iteratively refined our taxonomy\u2019s definitionsand structure, merging similar interaction types and creating newcategories when existing ones did not adequately capture theobserved patterns. In each pattern formulation, we consideredan appropriate level of abstraction so that they can capturemultiple actions of the agents and generalize over various studiesincluded in the systematic review. The interaction patternswe defined in the taxonomy are comprised of the interactionbuilding blocks and can borrow some of the other patterncategories. Furthermore, we included a \u201cOther patterns\u201d categoryto present the interaction patterns that did not exactly fitinto the main categories. In the following descriptions, weassume that users already have some background knowledge orintuitions that can be used during the decision making task.Lastly, the classification of interaction patterns does not meanthey are mutually exclusive events, but elements that can beconsolidated and combined. After finalizing the taxonomy, wequantified the frequency of each interaction pattern across ourcorpus of 105 articles using a combination of an automatedsearch for certain action-output pairs present in sequences ofinteractions that we characterized in the data extraction stage ofthe review, followed by manual inspection and verification. Wethen analyzed the application domains where these interactionswere studied.3.1.1 AI-first assistanceThis pattern manifests when the decision-making problem andthe AI-predicted outcome are simultaneously displayed to the user.As the ultimate decision maker, the user can choose to incorporatethe AI\u2019s advice into their final decision or opt to disregard it. Whentask-related stimuli (e.g., images or case details) are presentedalongside the AI-predicted outcome, the user is provided with amore comprehensive set of information to consider. In addition,the AI\u2019s outcome can be accompanied by support information ascaptured in the Display - Information building block. This patternhas been previously observed and referred to as the\u201cconcurrentparadigm\u201d (Tejeda et al., 2022) or \u201cone-step workflow\u201d (Fogliatoet al., 2022).Frontiers inComputer Science 05 frontiersin.orgGomez et al. 10.3389/fcomp.2024.15210663.1.2 AI-follow assistanceThis pattern begins with the user forming an independentpreliminary prediction given the decision-making problem.Following this initial judgment, the AI\u2019s predicted outcomeis presented and may accompanied by support information.This procedure provides the user with a reference (their initialassessment) to compare against the AI\u2019s advice, and an opportunityto reassess their initial judgment. This approach has been identifiedas the \u201csequential paradigm\u201d (Tejeda et al., 2022) or \u201ctwo-stepworkflow\u201d (Fogliato et al., 2022) and has been commonly used toevaluate the human\u2019s reliance on the AI\u2019s advice.3.1.3 Secondary assistanceIn this pattern, the AI offers information that does not serveas direct solutions to the decision-making problem. The user mustinterpret this supplementary information as an auxiliary task todetermine its relevance and decide how to incorporate it intotheir primary decision-making process. We distinguish this as aunique interaction pattern because users may respond differentlyto direct assistance compared to more secondary assistance in theirdecision-making process. For example, machine learning modelscan predict risk values associated with certain profile informationand the human\u2019s decision problem is to make an investmentdecision (Dikmen and Burns, 2022).3.1.4 Request-driven AI assistanceIn this interaction pattern, the user has to actively seekinformation or solutions from the AI. Rather than the AI\u2019sinferences being automatically presented, the user can controlwhen they want to receive the AI assistance. Meanwhile, the usercan spend more time deliberating about the problem, a strategyknown as cognitive forcing (Bu\u00e7inca et al., 2021; Park et al., 2019).This pattern can be perceived as less intrusive to the user, as itempowers the user to \u201cask\u201d for information or solutions from theAI, and allows the user to anticipate the AI\u2019s assistance in thedecision-making process.3.1.5 AI-guided dialogic user engagementWithin this interaction pattern, the AI facilitates a dialogue-like engagement with the user. Guided by the AI\u2019s instructions, theuser responds by providing pertinent information. The iterativeexchange continues until the AI\u2019s instruction requirements aresatisfied, and is followed by the presentation of the AI\u2019s predictedoutcome for the decision-making task. This responsive exchangenot only involves retrieving and sharing information in linewith the task but also ensures that the users recognize theinfluence of their inputs on the AI\u2019s predicted outcome. While thispattern has been commonly observed in humans interacting withconversational agents (Jiang et al., 2022; Gupta et al., 2022), it is notonly limited to traditional conversational interfaces (Gomez et al.,2023).3.1.6 User-guided interactive adjustmentsInspired by the taxonomy of interactive explanations recentlyproposed from a scoping review (Bertrand et al., 2023), we includedan interaction pattern where humans can modify the outcomespace of the AI agent. Typically, information flows from the AI tothe user. However, in this pattern, the direction of flow is reversed,with humans providing the AI with feedback, corrections, orinformation to shape its inferences. While a detailed classificationof potential modifications is beyond the scope of this survey,we distinguished cases in which the changes are merely visualupdates in the interface or considered as feedback to improve theunderlying AI models, as in interactive machine learning (Amershiet al., 2014).3.1.7 DelegationIn this interaction pattern, both the user and the AI leveragetheir unique strengths and capabilities to optimize the decision-making outcome. Delegation can be a strategic choice when oneagent assesses its counterpart as better equipped for a particulartask (F\u00fcgener et al., 2022). On the other hand, if an agent feelsconfident in their ability to complete the task, they will take the lead.Studies highlight that the complementary abilities of humans andAI when synergized properly, can enhance the decision-makingoutcome (Zhang et al., 2022).3.1.8 OthersWe included within this category those patterns that involvea combination of the main interaction blocks and did not fit intothe patterns described before. More complex interaction emergeswhen the decisionmaking problemmay involvemultiple individualdecisions, agents (more than two), and continuous interactionswith an AI agent.3.2 Identification of interaction patterns inAI-assisted decision making studiesWe identified the different categories of interaction patternsin the selected 105 articles. If a study included more than oneinteraction sequence, i.e., the experimental manipulation resultedin different ways in which users can interact with the AI,we considered them separately and counted patterns in eachone. In total, we analyzed 131 sequences. The most commoninteraction pattern during empirical evaluations of AI-assisteddecision making tasks was the AI-first assistance (n= 67), followedby the AI-follow assistance (n = 28). Furthermore, the AI\u2019ssolutions to the decision making task were presented along withadditional information in the majority of the cases, 81% and68% during AI-first and AI-follow interactions, respectively. Forinstance, in the AI-first pattern for predicting student outcomes,the AI takes student-related features and predicts pass or fail witha confidence value (Rastogi et al., 2022). Participants then reviewthis AI prediction alongside the student data to make their finaldecision. Meanwhile, in the AI-follow pattern for another binarytask, participants make a initial prediction regarding the outputof speed dating events, and then a final one after seeing AI\u2019sprediction. We observed 16 instances of the Secondary assistancepattern. In particular, we noticed that most of the decisionmaking tasks required expertise (11/16). As an example, in thetask of predicting gestational diabetes mellitus (GDM), healthcareFrontiers inComputer Science 06 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066professionals are presented with various descriptive features such asa history of diabetes mellitus, age, body weight, etc. (Du et al., 2022).The AI system processes this information and outputs a categorizedrisk of GDM, labeling it as either low or high. Rather than offeringa direct solution, the AI presents this risk category alongside anexplanation, thereby serving as a form of secondary assistance.Sometimes during the decision making task, users had toactively seek support from the AI agent as specified in the Request-driven AI assistance (n = 25). More specifically, the requests couldbe for a direct a solution to the decision making task (n = 14)or for the presentation of support information (n = 13). In theformer, only in three cases the request for the AI\u2019s solution wasoptional (Kumar et al., 2021; Tolmeijer et al., 2021; Baudel et al.,2021), meaning that users could come with a solution to thedecision making task on their own. As illustrated in a house searchscenario, users could choose to use an AI system to help themfind a house that satisfies certain requirements, with the optionto directly submit the suggested house or verify (Tolmeijer et al.,2021). Meanwhile, the support information at the user\u2019s discretionwas identified in eight cases (Calisto et al., 2022; V\u00f6ssing et al.,2022; Suresh et al., 2020; van der Waa et al., 2021; Liu et al., 2021;Molina and Sundar, 2022; Prabhudesai et al., 2023), for demandingexplanations in particular. In the AI-first assistance pattern, wherethe user may not have an opportunity to form an independentassessment of the decision making problem, we observe cases (n= 10) in which users are given the ability to control when theywant to receive the AI assistance via a request (Khadpe et al., 2020;Mackeprang et al., 2019; Baudel et al., 2021; Molina and Sundar,2022; Gomez et al., 2023; Bu\u00e7inca et al., 2021).To a lesser extent, we found the interaction patterns thatinvolve more exchange components between the human and theAI agent. For the AI-guided dialogic user engagement, as thename suggests, five out of the six interactions were supportedvia conversations with the AI agent. Through conversationalinterfaces, users had to provide some constraints given in thedecision making problem for the AI to propose a candidatesolution (Khadpe et al., 2020; Jiang et al., 2022; Gupta et al., 2022).However, such exchange of information does not necessarily relyon a conversational interface, as demonstrated in the evaluationof an AI system that could constantly provide guidance ona decision sub-problem for identifying bird categories (Gomezet al., 2023). The two-way interaction occurs as the AI requestsand suggests bird attributes for description, culminating in abird category suggestion. Users can actively engage by processingthe attributes, considering the AI\u2019s input, and making decisionsregarding the bird\u2019s attributes. Ultimately, they verify the AI\u2019ssuggested bird category. Interactivity also support the adjustmentof the AI\u2019s outcome space, and we found the User-guided interactiveadjustments in nine cases that differed on the observed effect of theadjustment. For instance, manipulations of the inputs result in newAI\u2019s outcome computations for exploratory purposes (Liu et al.,2021; Gu et al., 2023; Nguyen et al., 2018; Zytek et al., 2022; Sureshet al., 2022). Such functionality can be incorporated into interactiveexplanations, where users can manipulate input values of a specificinstance and observe the change in recidivism predictions (Liuet al., 2021). When adjustments did not directly translate into anupdated AI\u2019s outcome, users\u2019 feedback was considered for futureimprovement of the model (Ashktorab et al., 2021; Molina andSundar, 2022; Smith-Renner et al., 2020; Lee et al., 2021). Manuallabeling after observing AI predictions can be leveraged to identifyincorrect intent classifications from textual samples and re-train themodels (Ashktorab et al., 2021).Opportunities to delegate decisions were observed in ninesequences of interactions, though with differences in the conditionsfor delegation. For instance, in some cases the users \u201cblindly\u201ddelegate the decision to the AI without having access to theiroutcome and not being able to supervise it later (Chiang and Yin,2021; Maier et al., 2022; Zhang et al., 2020; F\u00fcgener et al., 2022).For example, in stock investment decisions, people can chooseto invest directly in specific stocks or delegate a portion of theirfunds to the AI for future investment decisions (Maier et al., 2022).In others, the AI agent has the decision to delegate and the useris assigned some of the decision making tasks to be completedon their own (Hemmer et al., 2023; F\u00fcgener et al., 2022), orpresented with the AI\u2019s outcome as support, resulting in the AI-first pattern (Bondi et al., 2022). In addition, the user can object tothe delegation decision of the AI and take charge of the decision ifconsidered appropriate (van der Waa et al., 2021).Lastly, the articles that we included in the \u201cOthers\u201d categoryof interaction patterns can be separated into three groups. First,decision making tasks that involved more than one decisionoutcome (Porat et al., 2019; M. A. Rahman et al., 2021) andcorresponding support from the AI agent. Second, decision makingproblems where multiple instances of decision tasks can take placeand the interaction with the AI agent is continuous (Van Berkelet al., 2022; Fan et al., 2022; Nourani et al., 2021; Lindvall et al., 2021;Reverberi et al., 2022). Third, interactions that involved a thirdagent (Wu et al., 2022; Brachman et al., 2022; Banas et al., 2022). Inaddition, a different case results when independent solutions, fromthe human and the AI agent, to the decision making problem areaveraged as the final verdict (Xiong et al., 2023).3.3 Landscape over domains evaluated inAI-advised human decision making3.3.1 What domains have been defined ascontexts to evaluate AI-assisted decision making?The selected articles included in this survey cover a broadrange of different domain categories previously identified (Laiet al., 2023). Articles that included more than one experimentaldecision making task were counted toward more than one domain.Table 1 presents a summary of the major domains and the differentdecision making tasks evaluated. Overall, the majority of thestudies conducted human-AI interaction evaluations in real-worldapplications, with less than 15% formulating artificial tasks. Weincluded medical related databases in our search strategy, whichcontributes to the large representation of decision making taskson the healthcare domain (26/108). In addition to healthcare,decision making tasks that may involve high-stakes outside of anexperimental setup were identified in the finance and business(15/108), and law domains (6/108). The second most commondomain was in the context of generic tasks (20/108) that are low-effort processing for humans but have mostly been used to developAI benchmarks and demonstrate technical feasibility of algorithms.Frontiers inComputer Science 07 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066TABLE 1 Domains and corresponding decision tasks used to study AI-assisted decision making.Domain Decision making task Total tasksEducation Student performance prediction (Rastogi et al., 2022) 1Artificial Identify the category of a shape (Zhang et al., 2022); estimate quantities (Hou and Jung, 2021; Park et al., 2019); policy-verification task(Nourani et al., 2021); quality control (Yu et al., 2019); delivery method selection (Liehner et al., 2022); pipe failure prediction (Zhou et al.,2017); nutrition prediction (Bu\u00e7inca et al., 2020); object movement prediction (Kumar et al., 2021); Memorizing images (Allan et al.,2021); ranking (Kim and Song, 2023); spatial reasoning task (Cao and Huang, 2022); pumping decisions (Xiong et al., 2023); predictTitanic passenger\u2019s fate (Baudel et al., 2021)14Finance/BusinessStock market trading (Cau et al., 2023; Maier et al., 2022); lending/loan assessment (Jakubik et al., 2023; Dikmen and Burns, 2022;Appelganc et al., 2022); income prediction (Zhang et al., 2020; Alufaisan et al., 2021); revenue forecasting (V\u00f6ssing et al., 2022); housing(Prabhudesai et al., 2023; Tolmeijer et al., 2021; Gupta et al., 2022; Westphal et al., 2023; Holstein et al., 2023; Chiang and Yin, 2021, 2022)15Healthcare Medical Diagnosis and Classification (Gu et al., 2023; Calisto et al., 2022; Reverberi et al., 2022; Wang et al., 2022; Schaekermann et al.,2020; Hwang et al., 2022; Tschandl et al., 2020; Lam Shin Cheung et al., 2022; Fogliato et al., 2022; Van Berkel et al., 2022; Suresh et al.,2022; Lindvall et al., 2021; Gaube et al., 2023; Cabitza et al., 2023; Appelganc et al., 2022); Clinical Decision Support Systems andTreatment Planning (van der Waa et al., 2021; Lee et al., 2021; Jacobs et al., 2021; Matthiesen et al., 2021; Jiang et al., 2022; Panigutti et al.,2022; van den Brandt et al., 2020; Porat et al., 2019; Panigutti et al., 2022; Naiseh et al., 2023; Bhattacharya et al., 2023)26Generic Image classification (Suresh et al., 2020; Bondi et al., 2022; Vodrahalli et al., 2022; F\u00fcgener et al., 2022; Tejeda et al., 2022; Hemmer et al.,2023; Gomez et al., 2023; Cabrera et al., 2023); text classification (Smith-Renner et al., 2020; Stites et al., 2021; Cabrera et al., 2023; Cauet al., 2023; Robbemond et al., 2022; Riveiro and Thill, 2021, 2022; Lai et al., 2020; Bansal et al., 2021); question answering (Feng andBoyd-Graber, 2022; Silva et al., 2023; Bansal et al., 2021); speech classification (Tutul et al., 2021; Zhang and Lim, 2022)20Labeling Text labeling (Bernard et al., 2018; Schrills and Franke, 2020; Ashktorab et al., 2021; Desmond et al., 2021; Brachman et al., 2022;Schemmer et al., 2023; Mackeprang et al., 2019); image labeling (Cau et al., 2023)8Law Recidivism prediction (Grgic-Hlaca et al., 2019; Wang and Yin, 2021; Alufaisan et al., 2021; Liu et al., 2021); criminal referral decision(Zytek et al., 2022); penal sentence prediction (Kahr et al., 2023)6Leisure Travel planning (Khadpe et al., 2020) 1SocialmediaFriend matching (M. A. Rahman et al., 2021; Rechkemmer and Yin, 2022); content filtering (M. A. Rahman et al., 2021; Bunde, 2021; Laiet al., 2022; Molina and Sundar, 2022); fact checking (Nguyen et al., 2018; Banas et al., 2022)8Professional Human resources (Peng et al., 2022; Hofeditz et al., 2022); profession prediction (Liu et al., 2021) 3Other Environment (Morrison et al., 2023; Leichtmann et al., 2023); ethical decision-making (Wu et al., 2022; Tolmeijer et al., 2022); nutrition(Bu\u00e7inca et al., 2021); UX usability evaluation (Fan et al., 2022)6Other domains that typically include tasks targeted to non-expertusers are social media (8), labeling (8), and leisure (1). We assignedtasks with unique applications to the Other domain (6/108).Even though we identified multiple decision making tasks inapplications that require a specialized population, where recruitinglarge numbers of participants is often challenging, the majorityof human-AI interactions have been evaluated with non-expertuses (60/108). The type of AI systems behind the interactions withusers in the studies that covered these decision-making tasks weredistributed among three categories: simulated models or Wizardof Oz experiments (39/105), deep learning-based models (34/105),and shallow models (35/105).3.3.2 In what contexts were the interactionpatterns observed during AI-assisted decisionmaking processes?To better understand the existence and availability of theinteraction patterns in different domains, we quantified theoccurrence of patterns per domain and provide an overviewdescribing the trends. Figure 2 shows the distribution of interactionpatterns within our taxonomy for different domains. Values equalto zero mean that certain interaction pattern was not observed inthe studies included in this survey for a specific domain. Tables inthe Appendix C provide more details on the interactions patternsfor each paper included in this review.Human-AI interactions in AI-advised decision makings in thehealthcare domain mostly adhered to the AI-first assistance pattern(n = 14), followed by Secondary assistance (n = 7). Request-driven AI assistance was observed in a few cases (n = 4) as wellas AI-follow assistance (n = 4). We identified one interaction thatsupported AI-guided dialogic user engagement, three interactionsin the User-guided interactive adjustments, and one in whichdelegation was an option. Five sequences of interactions were in the\u201cOthers\u201d category due to the higher complexity of the interactions.In the domain of finance and business, AI-first assistance wasthe most common type of interaction (n = 6), followed by AI-follow assistance (n = 4) and Secondary assistance (n = 4).Some interactions supported Request-driven AI assistance (n =3), AI-guided dialogic user engagement (n = 2), and delegation(n = 3). We did not observe support for User-guided interactiveadjustments. We identified four types of interaction patterns inthe law and civic domain: AI-first assistance (n = 4), AI-followassistance (n = 2), Request-driven assistance (n = 2), and User-guided interactive adjustments (n = 2). Decision-making tasksthat involve professional related topics mostly followed AI-firstassistance (n = 4). Request-driven AI assistance and user-guidedinteractive adjustments were observed in one case each one. Theother interaction patterns were not observed. Interaction patternsduring decision making tasks involved in social media contextswere mostly of the AI-first (n= 4), AI-follow (n= 4), and Request-driven AI assistance types (n = 4). We identified SecondaryFrontiers inComputer Science 08 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066FIGURE 2Percentage of interaction patterns observed in each domain of AI-assisted decision making tasks included in this review. The numbers in the cellsdenote the percentage values (e.g., 17% of the patterns identified in the healthcare domain correspond to Secondary assistance). One study caninclude multiple sequences of interaction and interaction patterns are not mutually exclusive.assistance in one case, and two cases in which User-guidedinteractive adjustments were enabled, in particular, for updatingrelevant terms for content moderation purposes. No Delegationor AI-guided dialogic user engagement was observed and twocases fell into the \u201cOthers\u201d patterns category. During decisionmaking tasks in generic applications, most of the interactionswere dominated by the AI-first assistance (n = 21), while onlytwo cases involved the AI-follow assistance interaction. Regardingthe more interactive patterns, two cases supported Request-drivenAI assistance, two AI-guided dialogic user engagement, and oneUser-guided interactive adjustments. Only in one case the type ofassistance was secondary. Delegation was featured in five cases.Labeling tasks mostly included AI-first assistance patterns (n = 6),followed by Request-driven AI (n= 4) and Secondary assistance (n= 3), mostly clustering similar data points. We further identifiedAI-follow assistance and User-guided interactive adjustments onceeach one, and two types of interactions in the \u201cOthers\u201d patternscategory. Artificial decision making tasks were mostly dominatedby AI-follow follow (n = 8) and AI-first assistance (n = 7).Request-driven AI assistance was featured in four cases and fourinteractions were in the \u201cOthers\u201d patterns category. Lastly, AI-guided dialogic user engagement was the type of interaction in theleisure-related task and AI-first assistance in the task within theeducation domain. Interactions during decision-making tasks thatbelong to other domains mainly contained AI-first (n= 4) and AI-follow (n= 3) assistance types, or patterns in the \u201cOthers\u201d category(n= 3). Further, one case supported Request-driven AI assistance.4 DiscussionIn establishing the interaction patterns presented in this paper,we drew from our observations of the Human-AI interactionsused in AI-advised decision-making scenarios in prior empiricalstudies. Constructing a taxonomy is inherently challenging dueto the wide array of potential approaches that can be adopted.Specifically, in the domain of Human-AI interaction, interactionscan be examined through various lenses (e.g., system-centric,oriented around user goal/task, distinguished by varying levels ofgranularity in interaction techniques). In this work, we have takena preliminary step to structure an approach by integrating ourperspectives with observations of interaction paradigms used inexisting studies. Below, we discuss the findings from our systematicreview in combination with the taxonomy, showcasing how itallowed us to identify trends and opportunities for the study ofhuman-AI interactions.4.1 Trends in existing Human-AIinteractionsUsing our taxonomy, we characterized existing interactionsadopted in empirical studies. In general, while the most commonpatterns were AI-first, AI-follow, or Secondary assistance, in whichthe human role was limited to supervising the AI predictions,we did also note the presence of more dynamic interactionsFrontiers inComputer Science 09 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066(e.g., Request-driven AI assistance, AI-guided dialogic userengagement, User-guided interactive adjustments), although lessfrequently. Interactive elements can enhance the communicationof explanations allowing users to interpret AI predictions throughselection, mutation, and dialogue as suggested by Bertrandet al. (2023). Likewise, supporting human input and review inthe field of Interactive Machine Learning requires the designof interface elements for sample review, model inspection, orfeedback assignment (Dudley and Kristensson, 2018). Beyondsupervising AI outputs, a new paradigm arises when humans andAI co-create solutions, blending human intuition and expertisewith AI\u2019s computational strengths for more robust outcomes.Conversational interfaces play a key role in enabling this two-wayinteraction. Moreover, the concept of distributing decision-makingresponsibilities among different agents, as seen in delegationpatterns, extends the assistance beyond individual decisions (Laiet al., 2022). This leads to diverse collaborative strategies, rangingfrom working in parallel\u2014as exemplified in delegation scenarioswhere AI operates autonomously but in alignment with humanintent\u2014to more coordinated efforts, such as the turn-takingdynamic inherent in conversational AI.A finer analysis per domain revealed the limited use andsupport for diverse interaction patterns, represented by most cellvalues equal to zero in Figure 2. However, it is worth noticingthat for high-stake domains, such as healthcare and finance,multiple interaction patterns have been explored when AI providesdecision support. The choice of specific interaction patterns canbe influenced by several factors including both design choicesmade by researchers and the intrinsic nature of the problemsbeing addressed. In the former, the research intent and availableresources may affect design choices. In the later, ethical andlegal considerations play an important role, specially in high-stakes domains. In more specialized fields, domain experts havetheir unique set of capabilities that can directly influence thechoice and efficacy of interactions with the AI. For these experts,Secondary assistance can be beneficial, since they have the insightsto effectively use the supplementary AI information for the primarydecision-making task. However, for non-experts, the most suitableand beneficial choice of interaction pattern is unclear. There remainquestions about the universality of certain interaction patternsacross varied user groups and task scenarios. Furthermore, withthe common usage of the AI-first and AI-follow approaches,understanding their pros and cons is crucial in developing AIsystems that align with human cognitive processes and decision-making styles.4.2 Challenges of di\u0000erent interactionpatternsThe popularity of the AI-first assistance pattern can beattributed to the straightforwardness of demonstrating the effects ofincorporating AI assistance into a decision-making task. However,it presents challenges, notably the difficulty in measuring the actualinfluence of AI assistance on user decision-making. Since the AI\u2019ssolution is revealed before the user has had the opportunity toprocess the task independently, it can be convenient for the user toeither dismiss or follow the AI\u2019s recommendation without sufficientreflection. Interaction patterns may engender different types ofbiases and knowing them in advance may help guard against biases.For instance, the AI-first interaction interaction can make theuser susceptible to the \u201canchoring bias,\u201d a phenomenon where aperson\u2019s judgment is biased based on initial information. This biascan be avoided through the use of Secondary assistance, wherethe user must interpret supplementary information, determine itsrelevance, and decide how to incorporate it into their primarydecision-making process. Directly presenting a solution to thedecisionmaking problem can result in over-reliance (Nourani et al.,2020), whereas Secondary assistance can avoid anchoring effects,but may not satisfy user needs. In addition, direct presentationof AI inferences can lead to a lack of \u201csense of agency\u201d for theuser, which refers to the subjective feeling of controlling one\u2019sactions, and influencing external events through them (Wen andImamizu, 2022). Request-driven AI assistance can empower theuser with the choice to view AI inferences and foster a senseof agency; however, it may also introduce risks of confirmationbias or anchoring bias, especially when users seek explanationsfor decision verification or knowledge acquisition (Barda AJ et al.,2020).In contrast, in the AI-follow assistance pattern, the user isgiven a chance to solve the problem on their own, thus, potentiallyminimizing anchoring bias. Yet, whether users actually restart theirdecision making process is open to question. An article foundthat participants in this \u201ctwo-step\u201d workflow rarely revised theirprovisional diagnoses when the AI inferences differed from theirearlier assessment (Fogliato et al., 2022). This hints at confirmationbias, a person\u2019s tendency to seek supporting evidence for theircurrent hypothesis. In case the user does re-evaluate their priorassessments, the cognitive costs increase. Cognitive costs of re-examination, when new information becomes available, can beviewed as analogous to interruption and recovery on the initialtask with new information (Fogliato et al., 2022). Being the secondmost common pattern, the prevalence of the AI-follow patternlikely arises from a strong interest in disentangling the influenceof AI advice on the human\u2019s decision (Vereschak et al., 2021).We primarily focused on biases in the most common interactionpatterns, as the higher number of studies aids in identifying them.However, exploring potential biases in less frequent paradigms isalso encouraged.4.3 Gaps and opportunities for the designof interactionsFrom our thorough exploration of interaction patterns in asample of over 100 articles, several gaps and opportunities emergefor advancing the design of human-AI interactions. First, moststudies focus on single-user and single-AI interactions, overlookingthe potential of multi-agent collaboration, which could unlock newdynamics and enhance teamwork in complex tasks. Moreover, asinteraction patterns grow more complex, existing frameworks likethe Delegation pattern, where the agents can reassign decisions,could be expanded to explore how agents coordinate and allocatetasks among themselves. Lastly, much of the HCI literature on AIFrontiers inComputer Science 10 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066assistance has concentrated on intermittent scenarios (i.e., turn-taking). This is in contrast to continuous user interaction scenarios,where user input is sustained and can receive AI feedback at anygiven moment for a more realistic and organic setup. Likewise,many of the human-AI interactions took place in artificial tasksthat may not capture real-world complexities. For example, moststudies end after decisions are made, without exposing decision-makers to the full consequences of their choices (Kirkeb\u00f8en et al.,2013), which can influence user engagement even in scenarioslabeled as high stakes. We must carefully consider differencesin how users behave in experimental tasks and in equivalentreal-life scenarios to assess whether AI assistance truly addsvalue to decision problems and capitalize on the findings ofexperimental evaluations.4.4 Value of a taxonomy of interactionpatternsThe design of Human-AI interactions requires deliberatechoices informed by cross-disciplinary expertise. By establishinga shared terminology, our taxonomy can facilitate conversationsand collaboration between researchers in AI, HCI, human factorsengineering, and domain experts. This common ground canensure consistency in methodology and foster innovation inresearch, development, and user experiences, ultimately leadingto more informed and participative decision-making processes.The taxonomy captures reusable interaction components andtheir relationships, providing insights to guide concrete choicesabout enabling interactions between the agents involved and thecorresponding interface elements needed (van Bekkum et al., 2021).We illustrate how the taxonomy serves as a framework to aggregateknowledge about the interactions present in empirical studies,revealing trends about how humans and AI collaborate in decision-making processes and identifying unexplored opportunities inhuman-AI collaboration. From a design perspective, it providesa collection of repeatable solutions to problem types that can beincorporated into prototypes for faster iterations. As the field ofhuman-AI interaction continues to evolve, this taxonomy can beexpanded and refined to incorporate new interaction patterns andideas from emerging research.4.5 LimitationsThe works included in this survey are limited to publishedmanuscripts that conducted empirical evaluations of human-AIinteractions. This focus, while intentional, could have introducedcertain limitations. The terminology used in the search could haveexcluded relevant work if the interaction design was not explicitlymentioned in the title or abstract, or even in the body of thetext. Moreover, publication bias may have resulted in the exclusionof works relevant to this review. Since our search included onlya healthcare-focused database alongside more general ones, thefrequency of interactions we observed across various domainswhere AI was used for decision-making may not remain consistentif additional domain-specific libraries were included in our search.We encourage further investigations in other domains of interestto researchers to build a more comprehensive understanding ofhuman-AI interactions.We also constrained our analysis to screen-based interfaces for AI-assistance, acknowledging that embodiedAImight support additional interactions. Our strict selection criteriacentered on studies encompassing complete decision-making tasksto ensure actual Human-AI interactions. Given the diversity ofexperimental designs and factors in the papers reviewed in thissurvey, we abstracted the interactions to discern patterns across thevaried studies. While many of these studies effectively describedtheir interfaces and user study procedures, there were instanceswhere the information provided was not sufficient for a completerecreation of the interactions. Consequently, we had to carefullyinterpret and encode the interactions from these papers to thebest of our abilities. Even though we demonstrate a use caseof the taxonomy to characterize the AI-assisted decision makingliterature, further use case evaluations can help in assessing theutility of the taxonomy and refine its definition.5 ConclusionIn this paper, we presented a systematic review of human-AIinteractions in AI-advised decision making tasks that informedand grounded the formulation of a taxonomy of interactionpatterns. Our proposed taxonomy of interaction patterns providesa structured foundation for understanding and designing thesecrucial interactions. It reveals that current practices often leantoward AI-driven or human-led decision processes, with limitedemphasis on fostering interactive functionalities throughout theinteractions. Recognizing the significance of interaction design,we advocate for deliberate choices in system development toenhance collaboration between humans and AI. Moving forward,the taxonomy presented here serves as a valuable resource toinform the design and development of AI-based decision supportsystems, ultimately fostering more productive, engaging, anduser-centered collaborations.Author contributionsCG: Conceptualization, Data curation, Formal analysis,Investigation, Methodology, Visualization, Writing \u2013 originaldraft, Writing \u2013 review & editing. SC: Formal analysis,Visualization, Writing \u2013 original draft, Writing \u2013 review &editing, Investigation. SK: Data curation, Formal analysis,Investigation, Methodology, Writing \u2013 original draft. C-MH:Conceptualization, Investigation, Methodology, Supervision,Writing \u2013 review & editing. MU: Conceptualization, Fundingacquisition, Investigation, Methodology, Project administration,Resources, Supervision, Writing \u2013 review & editing.FundingThe authors declare financial support was received for theresearch, authorship, and/or publication of this article. Thisresearch was supported in part by Johns Hopkins Internal Funds.Frontiers inComputer Science 11 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066Conflict of interestThe authors declare that the research was conducted in theabsence of any commercial or financial relationships that could beconstrued as a potential conflict of interest.Generative AI statementThe author(s) declare that Gen AI was used in the creation ofthis manuscript. Generative AI (chatGPT 4.0) was used to processthe text originally produced by the author(s). The processing wasdone for improving the clarity and structure of the sentences andnot to create new content. All the generated outputs were validatedbefore using and adapting them for the manuscript.Publisher\u2019s noteAll claims expressed in this article are solely those of theauthors and do not necessarily represent those of their affiliatedorganizations, or those of the publisher, the editors and thereviewers. Any product that may be evaluated in this article, orclaim that may be made by its manufacturer, is not guaranteed orendorsed by the publisher.Supplementary materialThe Supplementary Material for this article can be foundonline at: https://www.frontiersin.org/articles/10.3389/fcomp.2024.1521066/full#supplementary-materialReferencesAllan, K., Oren, N., Hutchison, J., and Martin, D. (2021). In search of a goldilockszone for credible AI. Sci. Rep. 11:13687. doi: 10.1038/s41598-021-93109-8Alufaisan, Y., Marusich, L. R., Bakdash, J. Z., Zhou, Y., and Kantarcioglu,M. (2021). \u201cDoes explainable artificial intelligence improve human Decision-Making?\u201d in Proceedings of the AAAI Conference on Artificial Intelligence, 6618\u20136626.doi: 10.1609/aaai.v35i8.16819Amershi, S., Cakmak, M., Knox, W. B., and Kulesza, T. (2014). Power to thepeople: the role of humans in interactive machine learning. Ai Magaz. 35, 105\u2013120.doi: 10.1609/aimag.v35i4.2513Appelganc, K., Rieger, T., Roesler, E., and Manzey, D. (2022). How muchreliability is enough? A Context-Specific view on human interaction with (artificial)agents from different perspectives. J. Cogn. Eng. Decis. Mak. 16, 207\u2013221.doi: 10.1177/15553434221104615Ashktorab, Z., Desmond, M., Andres, J., Muller, M., Joshi, N. N., Brachman,M., et al. (2021). \u201cAI-Assisted human labeling: Batching for efficiency withoutoverreliance,\u201d in Proceedings of the ACM on Human-Computer Interaction, 5.doi: 10.1145/3449163Banas, J. A., Palomares, N. A., Richards, A. S., Keating, D. M., Joyce, N., and Rains,S. A. (2022). When machine and bandwagon heuristics compete: understanding users\u2019response to conflicting AI and crowdsourced fact-checking. Hum. Commun. Res. 48,430\u2013461. doi: 10.1093/hcr/hqac010Bansal, G., Nushi, B., Kamar, E., Lasecki, W. S., Weld, D. S., and Horvitz, E. (2019).\u201cBeyond accuracy: the role of mental models in human-ai team performance,\u201d inProceedings of the AAAI Conference on Human Computation and Crowdsourcing, 2\u201311.doi: 10.1609/hcomp.v7i1.5285Bansal, G., Wu, T., Zhou, J., Fok, R., Nushi, B., Kamar, E., et al. (2021). \u201cDoesthe whole exceed its parts? The effect of AI explanations on complementary teamperformance,\u201d in Proceedings of the 2021 CHI Conference on Human Factors inComputing Systems, 1\u201316. doi: 10.1145/3411764.3445717Barda, A. J., Horvat, C. M., and Hochheiser, H. (2020). A qualitative researchframework for the design of user-centered displays of explanations for machinelearning model predictions in healthcare. BMC Med. Inform. Decis. Mak. 20:257.doi: 10.1186/s12911-020-01276-xBaudel, T., Verbockhaven, M., Cousergue, V., Roy, G., and Laarach, R. (2021).\u201cObjectivAIze: Measuring performance and biases in augmented business decisionsystems,\u201d in Human-Computer Interaction INTERACT 2021: 18th IFIP TC 13International Conference, Bari, Italy, August 30 September 3, 2021, Proceedings, Part III18 (Springer International Publishing), 300\u2013320. doi: 10.1007/978-3-030-85613-7_22Bernard, J., Hutter, M., Zeppelzauer, M., Fellner, D., and Sedlmair, M. (2018).Comparing Visual-Interactive labeling with active learning: an experimental study.IEEE Trans. Vis. Comput. Graph. 24, 298\u2013308. doi: 10.1109/TVCG.2017.2744818Bertrand, A., Belloum, R., Eagan, J. R., and Maxwell, W. (2022). \u201cHowcognitive biases affect XAI-assisted decision-making: a systematic review,\u201d inProceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, 78\u201391.doi: 10.1145/3514094.3534164Bertrand, A., Viard, T., Belloum, R., Eagan, J. R., and Maxwell, W. (2023). \u201cOnselective, mutable and dialogic XAI: a review of what users say about different types ofinteractive explanations,\u201d in Proceedings of the 2023 CHI Conference on Human Factorsin Computing Systems, 1\u201321. doi: 10.1145/3544548.3581314Bhattacharya, A., Ooge, J., Stiglic, G., and Verbert, K. (2023). \u201cDirectiveexplanations for monitoring the risk of diabetes onset: Introducing directiveData-Centric explanations and combinations to support What-If explorations,\u201d inProceedings of the 28th International Conference on Intelligent User Interfaces, 204\u2013219.doi: 10.1145/3581641.3584075Bondi, E., Koster, R., Sheahan, H., Chadwick, M., Bachrach, Y., Cemgil, T., et al.(2022). \u201cRole of Human-AI interaction in selective prediction,\u201d in Proceedings of theAAAI Conference on Artificial Intelligence, 5286\u20135294. doi: 10.1609/aaai.v36i5.20465Brachman, M., Ashktorab, Z., Desmond, M., Duesterwald, E., Dugan, C., Joshi, N.N., et al. (2022). \u201cReliance and automation for Human-AI collaborative data labelingconflict resolution,\u201d in Proceedings of the ACM on Human-Computer Interaction,6(CSCW2). doi: 10.1145/3555212Bu\u00e7inca, Z., Lin, P., Gajos, K. Z., and Glassman, E. L. (2020). \u201cProxy tasks andsubjective measures can be misleading in evaluating explainable AI systems,\u201d inProceedings of the 25th International Conference on Intelligent User Interfaces, 454\u2013464.doi: 10.1145/3377325.3377498Bu\u00e7inca, Z., Malaya, M. B., and Gajos, K. Z. (2021). \u201cTo trust or to think: cognitiveforcing functions can reduce overrelianceon AI in AI-assisted decision-making,\u201d inProceedings of the ACM on Human-Computer Interaction. doi: 10.1145/3449287Bunde, E. (2021). \u201cAI-assisted and explainable hate speech detection forsocial media moderators - a design science approach,\u201d in Proceedings ofthe 54th Hawaii International Conference on System Sciences, 1264\u20131273.doi: 10.24251/HICSS.2021.154Cabitza, F., Campagner, A., Natali, C., Parimbelli, E., Ronzio, L., and Cameli, M.(2023). Painting the black box white: experimental findings from applying XAI toan ECG reading setting. Mach. Lear. Knowl. Extr. 5, 269\u2013286. doi: 10.3390/make5010017Cabrera, \u00c1. A., Perer, A., and Hong, J. I. (2023). \u201cImproving Human-AIcollaboration with descriptions of AI behavior,\u201d in Proceedings of the ACM on Human-Computer Interaction, 1\u201321. doi: 10.1145/3579612Cabri, G., Leonardi, L., Zambonelli, F., et al. (2002). \u201cModeling role-basedinteractions for agents,\u201d in TheWorkshop on Agent-OrientedMethodologies at OOPSLA(Citeseer).Calisto, F. M., Santiago, C., Nunes, N., and Nascimento, J. C. (2022).BreastScreening-AI: evaluating medical intelligent agents for human-AI interactions.Artif. Intell. Med. 127:102285. doi: 10.1016/j.artmed.2022.102285Cao, S., and Huang, C.-M. (2022). \u201cUnderstanding user reliance on AI in assistedDecision-Making,\u201d in Proceedings of the ACM on Human-Computer Interaction, 6.doi: 10.1145/3555572Cau, F. M., Hauptmann, H., Spano, L. D., and Tintarev, N. (2023). \u201cSupportinghigh-uncertainty decisions through ai and logic-style explanations,\u201d in Proceedingsof the 28th International Conference on Intelligent User Interfaces, 251\u2013263.doi: 10.1145/3581641.3584080Chen, H., Gomez, C., Huang, C.-M., and Unberath, M. (2022). Explainable medicalimaging ai needs human-centered design: guidelines and evidence from a systematicreview. NPJ Digital Med. 5:156. doi: 10.1038/s41746-022-00699-2Cheng, R., Smith-Renner, A., Zhang, K., Tetreault, J. R., and Jaimes, A. (2022).Mapping the design space of human-ai interaction in text summarization. arXivpreprint arXiv:2206.14863. doi: 10.18653/v1/2022.naacl-main.33Frontiers inComputer Science 12 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066Chiang, C.-W., and Yin, M. (2021). \u201cYou\u2019d better stop! understanding humanreliance on machine learning models under covariate shift,\u201d in Proceedings of the 13thACMWeb Science Conference 2021, 120\u2013129. doi: 10.1145/3447535.3462487Chiang, C.-W., and Yin, M. (2022). \u201cExploring the effects of machine learningliteracy interventions on laypeople\u2019s reliance on machine learning models,\u201d inProceedings of the 27th International Conference on Intelligent User Interfaces, 148\u2013161.doi: 10.1145/3490099.3511121David, P., Cakmak, M., Saupp\u00e9, A., Albarghouthi, A., and Mutlu, B. (2022).\u201cInteraction templates: a data-driven approach for authoring robot programs,\u201d inPLATEAU: 12th Annual Workshop at the Intersection of PL and HCI.Desmond, M., Muller, M., Ashktorab, Z., Dugan, C., Duesterwald, E., Brimijoin,K., et al. (2021). \u201cIncreasing the speed and accuracy of data labeling through an AIassisted interface,\u201d in Proceedings of the 26th International Conference on Intelligent UserInterfaces, 392\u2013401. doi: 10.1145/3397481.3450698Dikmen, M., and Burns, C. (2022). The effects of domain knowledge on trust inexplainable AI and task performance: a case of peer-to-peer lending. International J.Human Computer Studies 162:102792. doi: 10.1016/j.ijhcs.2022.102792Du, Y., Antoniadi, A. M., McNestry, C., McAuliffe, F. M., and Mooney,C. (2022). The role of XAI in Advice-Taking from a clinical decision supportsystem: a comparative user study of feature Contribution-Based and Example-Basedexplanations. Appl. Sci. 12:10323. doi: 10.3390/app122010323Dudley, J. J., and Kristensson, P. O. (2018). A review of user interfacedesign for interactive machine learning. ACM Trans. Inter. Intell. Syst. 8, 1\u201337.doi: 10.1145/3185517Fan, M., Yang, X., Yu, T., Liao, Q. V., and Zhao, J. (2022). \u201cHuman-AI collaborationfor UX evaluation: effects of explanation and synchronization,\u201d in Proceedings of theACM on Human-Computer Interaction, 6. doi: 10.1145/3512943Feng, S., and Boyd-Graber, J. (2022). \u201cLearning to explain selectively: a case studyon question answering,\u201d in Proceedings of the 2022 Conference on Empirical Methods inNatural Language Processing, 8372\u20138382. doi: 10.18653/v1/2022.emnlp-main.573Fogliato, R., Chappidi, S., Lungren, M., Fisher, P., Wilson, D., Fitzke, M., et al.(2022). \u201cWho goes first? Influences of human-AI workflow on decision makingin clinical imaging,\u201d in Proceedings of the 2022 ACM Conference on Fairness,Accountability, and Transparency, 1362\u20131374. doi: 10.1145/3531146.3533193F\u00fcgener, A., Grahl, J., Gupta, A., and Ketter, W. (2022). Cognitive challenges inHuman-Artificial intelligence collaboration: investigating the path toward productivedelegation. Inf. Syst. Res. 33, 678\u2013696. doi: 10.1287/isre.2021.1079Gaube, S., Suresh, H., Raue, M., Lermer, E., Koch, T. K., Hudecek, M. F. C., et al.(2023). Non-task expert physicians benefit from correct explainable AI advice whenreviewing x-rays. Sci. Rep. 13:1383. doi: 10.1038/s41598-023-28633-wGomez, C., Unberath, M., and Huang, C.-M. (2023). Mitigating knowledgeimbalance in AI-advised decision-making through collaborative user involvement. Int.J. Hum. Comput. Stud. 172:102977. doi: 10.1016/j.ijhcs.2022.102977Grgic-Hlaca, N., Engel, C., and Gummadi, K. P. (2019). \u201cHuman decision makingwith machine advice: an experiment on bailing and jailing,\u201d in Proceedings of the ACMon Human-Computer Interaction, 3(CSCW). doi: 10.2139/ssrn.3465622Gu, H., Liang, Y., Xu, Y., Williams, C. K., Magaki, S., Khanlou, N., et al. (2023).Improving workflow integration with XPath: design and evaluation of aHuman-AI diagnosis system in pathology. ACM Trans. Comput. -Hum. Interact. 30, 1\u201337.doi: 10.1145/3577011Gupta, A., Basu, D., Ghantasala, R., Qiu, S., and Gadiraju, U. (2022). \u201cTotrust or not to trust: how a conversational interface affects trust in a decisionsupport system,\u201d in Proceedings of the ACM Web Conference 2022, 3531\u20133540.doi: 10.1145/3485447.3512248Hemmer, P., Westphal, M., Schemmer, M., Vetter, S., V\u00f8ssing, M., and Satzger,G. (2023). \u201cHuman-AI collaboration: the effect of AI delegation on human taskperformance and task satisfaction,\u201d in Proceedings of the 28th International Conferenceon Intelligent User Interfaces, 453\u2013463. doi: 10.1145/3581641.3584052Hofeditz, L., Clausen, S., Rie\u00df, A., Mirbabaie, M., and Stieglitz, S.(2022). Applying XAI to an AI-based system for candidate management tomitigate bias and discrimination in hiring. Electr. Markets 32, 2207\u20132233.doi: 10.1007/s12525-022-00600-9Holstein, K., De-Arteaga, M., Tumati, L., and Cheng, Y. (2023). Towardsupporting perceptual complementarity in Human-AI collaboration via reflection onunobservables. Proc. ACM Hum. -Comput. Interact. 7, 1\u201320. doi: 10.1145/3579628Hou, Y. T.-Y., and Jung, M. F. (2021). Who is the expert? Reconciling algorithmaversion and algorithm appreciation in AI-Supported decision making. Proc. ACMHum. -Comput. Interact. 5, 1\u201325. doi: 10.1145/3479864Hwang, J., Lee, T., Lee, H., and Byun, S. (2022). A clinical decision support systemfor sleep staging tasks with explanations from artificial intelligence: User-Centereddesign and evaluation study. J. Med. Internet Res. 24:e28659. doi: 10.2196/28659Jacobs, M., Pradier, M. F., McCoy, T. H., Perlis, R. H., Doshi-Velez, F., and Gajos,K. Z. (2021). How machine-learning recommendations influence clinician treatmentselections: the example of the antidepressant selection. Transl. Psychiatry 11:108.doi: 10.1038/s41398-021-01224-xJakubik, J., Sch\u00f6ffer, J., Hoge, V., V\u00f6ssing, M., and K\u00fchl, N. (2023). \u201cAn empiricalevaluation of predicted outcomes as explanations in human-ai decision-making,\u201d inJoint European Conference on Machine Learning and Knowledge Discovery in Databases(Cham: Springer Nature Switzerland), 353\u2013368. doi: 10.1007/978-3-031-23618-1_24Jiang, J., Kahai, S., and Yang, M. (2022). Who needs explanation and when? Jugglingexplainable AI and user epistemic uncertainty. Int. J. Hum. Comput. Stud. 165:102839.doi: 10.1016/j.ijhcs.2022.102839Kahr, P. K., Rooks, G., Willemsen, M. C., and Snijders, C. C. P. (2023). \u201cIt seemssmart, but it acts stupid: development of trust in AI advice in a repeated legal Decision-Making task,\u201d in Proceedings of the 28th International Conference on Intelligent UserInterfaces, 528\u2013539. doi: 10.1145/3581641.3584058Khadpe, P., Krishna, R., Fei-Fei, L., Hancock, J. T., and Bernstein, M. S.(2020). \u201cConceptual metaphors impact perceptions of Human-AI collaboration,\u201din Proceedings of the ACM on Human-Computer Interaction, 4(CSCW2).doi: 10.1145/3415234Kim, T., and Song, H. (2023). Communicating the limitations of AI: The effect ofmessage framing and ownership on trust in artificial intelligence. Int. J. Hum. Comput.Interact. 39, 790\u2013800. doi: 10.1080/10447318.2022.2049134Kirkeb\u00f8en, G., Vasaasen, E., and Halvor Teigen, K. (2013). Revisions and regret: thecost of changing your mind. J. Behav. Decis. Mak. 26, 1\u201312. doi: 10.1002/bdm.756Kumar, A., Patel, T., Benjamin, A. S., and Steyvers, M. (2021). \u201cExplaining algorithmaversion with metacognitive bandits,\u201d in Proceedings of the Annual Meeting of theCognitive Science Society, 2780\u20132786.Lai, V., Carton, S., Bhatnagar, R., Liao, Q. V., Zhang, Y., and Tan, C. (2022).\u201cHuman-AI collaboration via conditional delegation: A case study of contentmoderation,\u201d in Proceedings of the 2022 CHI Conference on Human Factors inComputing Systems, 1\u201318. doi: 10.1145/3491102.3501999Lai, V., Chen, C., Smith-Renner, A., Liao, Q. V., and Tan, C. (2023). \u201cTowardsa science of human-AI decision making: An overview of design space in empiricalhuman-subject studies,\u201d in Proceedings of the 2023 ACM Conference on Fairness,Accountability, and Transparency, 1369\u20131385. doi: 10.1145/3593013.3594087Lai, V., Liu, H., and Tan, C. (2020). \u201c\u2018Why is \u2018chicago\u2019 deceptive?\u2019 Towards buildingmodel-driven tutorials for humans,\u201d in Proceedings of the 2020 CHI Conference onHuman Factors in Computing Systems, CHI \u201920 (New York, NY, USA: Association forComputing Machinery), 1\u201313. doi: 10.1145/3313831.3376873Lam Shin Cheung, J., Ali, A., Abdalla, M., and Fine, B. (2022). U\u201cAI\u201d testing: userinterface and usability testing of a chest x-ray AI tool in a simulated Real-Worldworkflow. Canadian Assoc. Radiol. J. 74, 314\u2013325. doi: 10.1177/08465371221131200Lee, M. H., Siewiorek, D. P., and Smailagic, A. (2021). \u201cA human-ai collaborativeapproach for clinical decision making on rehabilitation assessment,\u201d in Proceedingsof the 2021 CHI Conference on Human Factors in Computing Systems, 1\u201314.doi: 10.1145/3411764.3445472Leichtmann, B., Humer, C., Hinterreiter, A., Streit, M., and Mara, M. (2023). Effectsof explainable artificial intelligence on trust and human behavior in a high-risk decisiontask. Comput. Human Behav. 139:107539. doi: 10.1016/j.chb.2022.107539Liehner, G. L., Brauner, P., Schaar, A. K., and Ziefle, M. (2022). Delegation of moraltasks to automated Agents\u2013The impact of risk and context on trusting a machine toperform a task. IEEE Trans. Technol. Soc. 3, 46\u201357. doi: 10.1109/TTS.2021.3118355Lindvall, M., Lundstr\u00f6m, C., and L\u00f6wgren, J. (2021). \u201cRapid assisted visualsearch: Supporting digital pathologists with imperfect AI,\u201d in Proceedingsof the 26th International Conference on Intelligent User Interfaces, 504\u2013513.doi: 10.1145/3397481.3450681Liu, H., Lai, V., and Tan, C. (2021). \u201cUnderstanding the effect of out-of-distributionexamples and interactive explanations on Human-AI decision making,\u201d in Proceedingsof the ACM on Human-Computer Interaction, 5(CSCW2). doi: 10.1145/3479552Ma, K., and Cao, J. (2019). \u201cDesign pattern as a practical tool for designing adaptiveinteractions connecting human and social robots,\u201d in Intelligent Human SystemsIntegration 2019: Proceedings of the 2nd International Conference on Intelligent HumanSystems Integration (IHSI 2019): Integrating People and Intelligent Systems, February7-10, 2019, San Diego, California, USA (Springer International Publishing), 613\u2013617.doi: 10.1007/978-3-030-11051-2_93Mackeprang, M., M\u00fcller-Birn, C., and Stauss, M. (2019). \u201cDiscovering thesweet spot of human\u2013computer configurations: a case study in informationextraction,\u201d in Proceedings of the ACM on Human-Computer Interaction, 3(CSCW).doi: 10.1145/3359297Magnusson, M. S. (2018). Temporal Patterns in Interactions: T-Patterns andTheir Detection with THEMETM. Cambridge: Cambridge University Press, 323\u2013353.doi: 10.1017/9781316286302.017Maier, T., Menold, J., and McComb, C. (2022). The relationship betweenperformance and trust in AI in E-Finance. Front. Artif. Intell. 5:891529.doi: 10.3389/frai.2022.891529Matthiesen, S., Diederichsen, S. Z., Hansen, M. K. H., Villumsen, C., Lassen, M.C. H., Jacobsen, P. K., et al. (2021). Clinician preimplementation perspectives of adecision-support tool for the prediction of cardiac arrhythmia based on machinelearning: near-live feasibility and qualitative study. JMIR Hum. Factors 8:e26964.doi: 10.2196/26964Frontiers inComputer Science 13 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066Molina, M. D., and Sundar, S. S. (2022). When AI moderates online content: effectsof human collaboration and interactive transparency on user trust. J. Comput. Med.Commun. 27:zmac010. doi: 10.1093/jcmc/zmac010Morrison, K., Shin, D., Holstein, K., and Perer, A. (2023). Evaluating the impact ofhuman explanation strategies on human-AI visual decision-making. Proc. ACM Hum.-Comput. Interact. 7, 1\u201337. doi: 10.1145/3579481Naiseh,M., Al-Thani, D., Jiang, N., and Ali, R. (2023). How the different explanationclasses impact trust calibration: the case of clinical decision support systems. Int. J.Hum. Comput. Stud. 169:102941. doi: 10.1016/j.ijhcs.2022.102941Nguyen, A. T., Kharosekar, A., Krishnan, S., Tate, E., Wallace, B. C., and Lease,M. (2018). \u201cBelieve it or not: Designing a human-ai partnership for mixed-initiativefact-checking,\u201d in Proceedings of the 31st Annual ACM Symposium on User InterfaceSoftware and Technology, 189\u2013199. doi: 10.1145/3242587.3242666Nourani, M., King, J., and Ragan, E. (2020). \u201cThe role of domain expertise inuser trust and the impact of first impressions with intelligent systems,\u201d in Proceedingsof the AAAI Conference on Human Computation and Crowdsourcing, 112\u2013121.doi: 10.1609/hcomp.v8i1.7469Nourani, M., Roy, C., Block, J. E., Honeycutt, D. R., Rahman, T., Ragan, E.,et al. (2021). \u201cAnchoring bias affects mental model formation and user reliancein explainable AI systems,\u201d in Proceedings of the 26th International Conference onIntelligent User Interfaces, 340\u2013350. doi: 10.1145/3397481.3450639Panigutti, C., Beretta, A., Giannotti, F., and Pedreschi, D. (2022). \u201cUnderstandingthe impact of explanations on advice-taking: a user study for AI-based clinical decisionsupport systems,\u201d in Proceedings of the 2022 CHI Conference on Human Factors inComputing Systems, 1\u20139. doi: 10.1145/3491102.3502104Parasuraman, R., Sheridan, T. B., and Wickens, C. D. (2000). A model for typesand levels of human interaction with automation. IEEE Trans. Syst. Man Cybern. 30,286\u2013297. doi: 10.1109/3468.844354Park, J. S., Barber, R., Kirlik, A., and Karahalios, K. (2019). A slow algorithmimproves users\u2019 assessments of the algorithm\u2019s accuracy. Proc. ACM Hum. -Comput.Interact. 3, 1\u201315. doi: 10.1145/3359204Peng, A., Nushi, B., Kiciman, E., Inkpen, K., and Kamar, E. (2022). \u201cInvestigationsof performance and bias in Human-AI teamwork in hiring,\u201d in Proceedings of the AAAIConference on Artificial Intelligence, 12089\u201312097. doi: 10.1609/aaai.v36i11.21468Porat, T., Marshall, I. J., Sadler, E., Vadillo, M. A., McKevitt, C., Wolfe, C. D.A., et al. (2019). Collaborative design of a decision aid for stroke survivors withmultimorbidity: a qualitative study in the UK engaging key stakeholders. BMJ Open9:e030385. doi: 10.1136/bmjopen-2019-030385Prabhudesai, S., Yang, L., Asthana, S., Huan, X., Vera Liao, Q., and Banovic, N.(2023). \u201cUnderstanding uncertainty: how lay decision-makers perceive and interpretuncertainty in Human-AI decision making,\u201d in Proceedings of the 28th InternationalConference on Intelligent User Interfaces, 379\u2013396. doi: 10.1145/3581641.3584033Rahman, M. A., Sadat, S. N., Asyhari, A. T., Refat, N., Kabir, M. N., andArshah, R. A. (2021). A secure and sustainable framework to mitigate hazardousactivities in online social networks. IEEE Trans. Sustain. Comput. 6, 30\u201342.doi: 10.1109/TSUSC.2019.2911188Rastogi, C., Zhang, Y., Wei, D., Varshney, K. R., Dhurandhar, A., and Tomsett, R.(2022). \u201cDeciding fast and slow: the role of cognitive biases in AI-assisted decision-making,\u201d in Proceedings of the ACM on Human-Computer Interaction, 6(CSCW1).doi: 10.1145/3512930Rechkemmer, A., and Yin, M. (2022). \u201cWhen confidence meets accuracy: exploringthe effects of multiple performance indicators on trust in machine learning models,\u201d inProceedings of the 2022 Chi Conference on Human Factors in Computing Systems, 1\u201314.doi: 10.1145/3491102.3501967Reverberi, C., Rigon, T., Solari, A., Hassan, C., Cherubini, P., and Cherubini,A. (2022). Experimental evidence of effective human-AI collaboration in medicaldecision-making. Sci. Rep. 12:14952. doi: 10.1038/s41598-022-18751-2Riveiro, M., and Thill, S. (2021). \u201cThat\u2019s (not) the output I expected!\u201d on the role ofend user expectations in creating explanations of AI systems. Artif. Intell. 298:103507.doi: 10.1016/j.artint.2021.103507Riveiro, M., and Thill, S. (2022). \u201cThe challenges of providing explanationsof AI systems when they do NotBehave like users expect,\u201d in Proceedings of the30th ACM Conference on User Modeling, Adaptation and Personalization, 110\u2013120.doi: 10.1145/3503252.3531306Robbemond, V., Inel, O., and Gadiraju, U. (2022). \u201cUnderstanding the roleof explanation modality in AI-AssistedDecision-Making,\u201d in Proceedings of the30th ACM Conference on User Modeling, Adaptation and Personalization, 223\u2013233.doi: 10.1145/3503252.3531311Saupp\u00e9, A., and Mutlu, B. (2014). \u201cDesign patterns for exploring and prototypinghuman-robot interactions,\u201d in Proceedings of the SIGCHI Conference on Human Factorsin Computing Systems, 1439\u20131448. doi: 10.1145/2556288.2557057Schaekermann, M., Beaton, G., Sanoubari, E., Lim, A., Larson, K., and Law, E.(2020). \u201cAmbiguity-aware AI assistants for medical data analysis,\u201d in Proceedingsof the 2020 CHI Conference on Human Factors in Computing Systems, 1\u201314.doi: 10.1145/3313831.3376506Schemmer, M., Kuehl, N., Benz, C., Bartos, A., and Satzger, G. (2023). \u201cAppropriatereliance on AI advice: Conceptualization and the effect of explanations,\u201d inInternational Conference on Intelligent User Interfaces, inproceedings IUI, 410\u2013422.doi: 10.1145/3581641.3584066Schleidgen, S., Friedrich, O., Gerlek, S., Assadi, G., and Seifert, J. (2023). The conceptof \u201cinteraction\u201d in debates on human-machine interaction.Human. Soc. Sci. Commun.10, 1\u201313. doi: 10.1057/s41599-023-02060-8Schrills, T., and Franke, T. (2020). \u201cColor for characters - effects of visualexplanations of AI on trust and observability,\u201d in Artificial Intelligence in HCI: FirstInternational Conference, AI-HCI 2020, Held as Part of the 22nd HCI InternationalConference, HCII 2020, Copenhagen, Denmark, July 19\u201324, 2020, Proceedings 22(Springer International Publishing), 121\u2013135. doi: 10.1007/978-3-030-50334-5_8Sheu, R.-K., and Pardeshi, M. S. (2022). A survey on medical explainable AI(XAI): recent progress, explainability approach, human interaction and scoring system.Sensors 22:8068. doi: 10.3390/s22208068Silva, A., Schrum, M., Hedlund-Botti, E., Gopalan, N., and Gombolay, M. (2023).Explainable artificial intelligence: evaluating the objective and subjective impacts of xAIon Human-Agent Interaction 39, 1390\u20131404. doi: 10.1080/10447318.2022.2101698Silva-Rodr\u00edguez, V., Nava-Mu noz, S. E., Castro, L. A., Mart\u00ednez-P\u00e9rez, F. E., P\u00e9rez-Gonz\u00e1lez, H. G., and Torres-Reyes, F. (2020). Classifying design-level requirementsusing machine learning for a recommender of interaction design patterns. IET Softw.14, 544\u2013552. doi: 10.1049/iet-sen.2019.0291Sims, R. (1997). Interactivity: a forgotten art? Comput. Human Behav. 13, 157\u2013180.doi: 10.1016/S0747-5632(97)00004-6Smith-Renner, A., Fan, R., Birchfield, M., Wu, T., Boyd-Graber, J., Weld, D. S., et al.(2020). \u201cNo explainability without accountability: an empirical study of explanationsand feedback in interactive ML,\u201d in Proceedings of the 2020 CHI Conference on HumanFactors in Computing Systems, 1\u201313. doi: 10.1145/3313831.3376624Stites, M. C., Nyre-Yu, M., Moss, B., Smutz, C., and Smith, M. R. (2021).\u201cSage advice? The impacts of explanations for machine learning models on humanDecision-Making in spam detection,\u201d in International Conference on Human-ComputerInteraction (Cham: Springer International Publishing), 269\u2013284. doi: 10.2172/1878725Suresh, H., Lao, N., and Liccardi, I. (2020). \u201cMisplaced trust: Measuring theinterference of machine learning in human Decision-Making,\u201d in Proceedings of the12th ACM Conference on Web Science, 315\u2013324. doi: 10.1145/3394231.3397922Suresh, H., Lewis, K. M., Guttag, J., and Satyanarayan, A. (2022). \u201cIntuitivelyassessing ML model reliability through Example-Based explanations and editingmodel inputs,\u201d in Proceedings of the 27th International Conference on Intelligent UserInterfaces, 767\u2013781. doi: 10.1145/3490099.3511160Tejeda, H., Kumar, A., Smyth, P., and Steyvers, M. (2022). Ai-assisted decision-making: a cognitive modeling approach to infer latent reliance strategies. Comput.Brain Behav. 5, 491\u2013508. doi: 10.1007/s42113-022-00157-yTolmeijer, S., Christen,M., Kandul, S., Kneer,M., and Bernstein, A. (2022). \u201cCapablebut amoral? Comparing AI and human expert collaboration in ethical decisionmaking,\u201d in Proceedings of the 2022 CHI Conference on Human Factors in ComputingSystems, 1\u201317. doi: 10.1145/3491102.3517732Tolmeijer, S., Gadiraju, U., Ghantasala, R., Gupta, A., and Bernstein, A. (2021).\u201cSecond chance for a first impression? Trust development in intelligent systeminteraction,\u201d in Proceedings of the 29th ACM Conference on User Modeling, Adaptationand Personalization, 77\u201387. doi: 10.1145/3450613.3456817Tschandl, P., Rinner, C., Apalla, Z., Argenziano, G., Codella, N., Halpern, A., et al.(2020). Human-computer collaboration for skin cancer recognition. Nat. Med. 26,1229\u20131234. doi: 10.1038/s41591-020-0942-0Tutul, A. A., Nirjhar, E. H., and Chaspari, T. (2021). \u201cInvestigating trust in Human-Machine learning collaboration: a pilot study on estimating public anxiety fromspeech,\u201d in Proceedings of the 2021 International Conference on Multimodal Interaction,288\u2013296. doi: 10.1145/3462244.3479926van Bekkum, M., de Boer, M., van Harmelen, F., Meyer-Vitali, A., andTeije, A., t. (2021). Modular design patterns for hybrid learning and reasoningsystems: a taxonomy, patterns and use cases. Appl. Intell. 51, 6528\u20136546.doi: 10.1007/s10489-021-02394-3Van Berkel, N., Opie, J., Ahmad, O. F., Lovat, L., Stoyanov, D., and Blandford, A.(2022). \u201cInitial responses to false positives in AI-Supported continuous interactions:a colonoscopy case study,\u201d in ACM Transactions on Interactive Intelligent Systems, 12.doi: 10.1145/3480247Van Berkel, N., Skov, M. B., and Kjeldskov, J. (2021). Human-AI interaction:intermittent, continuous, and proactive. Interactions 28, 67\u201371. doi: 10.1145/3486941van de Sande, D., Chung, E. F. F., Oosterhoff, J., van Bommel, J., Gommers,D., and van Genderen, M. E. (2024). To warrant clinical adoption AI modelsrequire a multi-faceted implementation evaluation. NPJ Digital Med. 7:58.doi: 10.1038/s41746-024-01064-1van den Brandt, A., Christopher, M., Zangwill, L. M., Rezapour, J., Bowd, C., Baxter,S. L., et al. (2020). \u201cGLANCE: visual analytics for monitoring glaucoma progression,\u201din VCBM, 85\u201396.Frontiers inComputer Science 14 frontiersin.orgGomez et al. 10.3389/fcomp.2024.1521066van der Waa, J., Verdult, S., van den Bosch, K., van Diggelen, J., Haije, T., van derStigchel, B., et al. (2021). Moral decisionmaking in human-agent teams: human controland the role of explanations. Front. Robot. AI 8:640647. doi: 10.3389/frobt.2021.640647Vereschak, O., Bailly, G., and Caramiaux, B. (2021). \u201cHow to evaluate trust in ai-assisted decision making? A survey of empirical methodologies,\u201d in Proceedings of theACM on Human-Computer Interaction, 1\u201339. doi: 10.1145/3476068Vodrahalli, K., Daneshjou, R., Gerstenberg, T., and Zou, J. (2022). \u201cDo humanstrust advice more if it comes from AI? An analysis of human-AI interactions,\u201d inProceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society, 763\u2013777.doi: 10.1145/3514094.3534150V\u00f6ssing, M., K\u00fchl, N., Lind, M., and Satzger, G. (2022). Designingtransparency for effective Human-AI collaboration. Inf. Syst. Front. 24, 877\u2013895.doi: 10.1007/s10796-022-10284-3Wang, R., Fu, G., Li, J., and Pei, Y. (2022). Diagnosis after zooming in: a multilabelclassification model by imitating doctor reading habits to diagnose brain diseases.Med.Phys. 49, 7054\u20137070. doi: 10.1002/mp.15871Wang, X., and Yin, M. (2021). \u201cAre explanations helpful? A comparative studyof the effects of explanations in AI-Assisted Decision-Making,\u201d in Proceedingsof the 26th International Conference on Intelligent User Interfaces, 318\u2013328.doi: 10.1145/3397481.3450650Wen, W., and Imamizu, H. (2022). The sense of agency in perception,behaviour and human-machine interactions. Nat. Rev. Psychol. 1, 211\u2013222.doi: 10.1038/s44159-022-00030-6Westphal, M., V\u00f6ssing, M., Satzger, G., Yom-Tov, G. B., and Rafaeli,A. (2023). Decision control and explanations in human-AI collaboration:improving user perceptions and compliance. Comput. Human Behav. 144:107714.doi: 10.1016/j.chb.2023.107714Wu, Y., Kim, K. J., and Mou, Y. (2022). Minority social influence and moraldecision-making in human-AI interaction: the effects of identity and specializationcues. New Media Soc. 26, 5619\u20135637. doi: 10.1177/14614448221138072Xiong, W., Wang, C., and Ma, L. (2023). Partner or subordinate? Sequential riskydecision-making behaviors under human-machine collaboration contexts. Comput.Human Behav. 139:107556. doi: 10.1016/j.chb.2022.107556Yi, J. S., ah Kang, Y., Stasko, J., and Jacko, J. A. (2007). Toward adeeper understanding of the role of interaction in information visualization.IEEE Trans. Vis. Comput. Graph. 13, 1224\u20131231. doi: 10.1109/TVCG.2007.70515Yu, K., Berkovsky, S., Taib, R., Zhou, J., and Chen, F. (2019). \u201cDo I trust mymachine teammate? An investigation from perception to decision,\u201d in Proceedingsof the 24th International Conference on Intelligent User Interfaces, 460\u2013468.doi: 10.1145/3301275.3302277Zhang, Q., Lee, M. L., and Carter, S. (2022). \u201cYou complete me: Human-AI teamsand complementary expertise,\u201d in Proceedings of the 2022 CHI Conference on HumanFactors in Computing Systems, 1\u201328. doi: 10.1145/3491102.3517791Zhang, W., and Lim, B. Y. (2022). \u201cTowards relatable explainable AI with theperceptual process,\u201d in Proceedings of the 2022 CHI Conference on Human Factors inComputing Systems, 1\u201324. doi: 10.1145/3491102.3501826Zhang, Y., Liao, Q. V., and Bellamy, R. K. (2020). \u201cEffect of confidence andexplanation on accuracy and trust calibration in AI-assisted decision making,\u201d inProceedings of the 2020 Conference on Fairness, Accountability, and Transparency,295\u2013305. doi: 10.1145/3351095.3372852Zhou, J., Arshad, S. Z., Luo, S., and Chen, F. (2017). \u201cEffects of uncertainty andcognitive load on user trust in predictive decision making,\u201d in Human-ComputerInteraction INTERACT 2017: 16th IFIP TC 13 International Conference,Mumbai, India,September 25-29, 2017, Proceedings, Part IV 16 (Springer International Publishing),23\u201339. doi: 10.1007/978-3-319-68059-0_2Zytek, A., Liu, D., Vaithianathan, R., and Veeramachaneni, K. (2022). Sibyl:understanding and addressing the usability challenges of machine learning inHigh-Stakes decision making. IEEE Trans. Vis. Comput. Graph. 28, 1161\u20131171.doi: 10.1109/TVCG.2021.3114864Frontiers inComputer Science 15 frontiersin.org",
      "id": 171599971,
      "identifiers": [
        {
          "identifier": "648140148",
          "type": "CORE_ID"
        },
        {
          "identifier": "10.3389/fcomp.2024.1521066",
          "type": "DOI"
        },
        {
          "identifier": "oai:doaj.org/article:1a8f1b0b689c48fb8878354e1f14104d",
          "type": "OAI_ID"
        }
      ],
      "title": "Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review",
      "magId": null,
      "oaiIds": [
        "oai:doaj.org/article:1a8f1b0b689c48fb8878354e1f14104d"
      ],
      "publishedDate": "2025-01-01T00:00:00",
      "publisher": "Frontiers Media S.A.",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1521066/pdf"
      ],
      "updatedDate": "2025-03-30T00:50:20",
      "yearPublished": 2025,
      "journals": [
        {
          "title": "Frontiers in Computer Science",
          "identifiers": [
            "2624-9898",
            "issn:2624-9898"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/648140148.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/648140148"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/648140148/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/648140148/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/171599971"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Luck, M"
        },
        {
          "name": "McBurney, P"
        },
        {
          "name": "Shehory, O"
        },
        {
          "name": "Willmott, S"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/586904129",
        "https://api.core.ac.uk/v3/outputs/1505312"
      ],
      "createdDate": "2012-04-05T19:14:30",
      "dataProviders": [
        {
          "id": 34,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/34",
          "logo": "https://api.core.ac.uk/data-providers/34/logo"
        },
        {
          "id": 635,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/635",
          "logo": "https://api.core.ac.uk/data-providers/635/logo"
        }
      ],
      "depositedDate": "",
      "abstract": null,
      "documentType": "research",
      "doi": null,
      "downloadUrl": "https://core.ac.uk/download/29914283.pdf",
      "fieldOfStudy": null,
      "fullText": "Agent Technology Roadmap\nA Roadmap for Agent Based Computing\nMichael Luck, Peter McBurney, Onn Shehory, Steve Willmott and the AgentLink Community\nCompiled, written and edited by \nEconomics\nPhilosophy\nGame Theory\nBiology\nLogic\nSociology\nPolitical Science\nAnthropology\nMarketing\nOrganisation Design\nDecision\nTheory\nArtificial Life\nRobotics\nUncertainty\nin AI\nLogic\nProgramming\ng g\nMathematical\nModelling\nOrganisations\nComplex Systems\nReasoning \nand Learning\nSelf-*\nSystems\n            Grid\nComputing\nAmbient\nintelligence\nPeer-to-peer \nComputing \nService Oriented\nComputing\nSemantic Web\nTrust and Reputation\nUser \nInteraction \nDesign\nSimulation\nSoftware\nEngineering\nInteroperability Infrastructure Formal \nMethods\nProgramming\nLanguages\nCoordination Negotiation Communication\nTrends and Drivers\nTechnologies\nRelated Disciplines\nRelated Techniques2\nAgentLink Roadmap\nSupported by2\nAgentLink Roadmap\nMichael  Luck, Peter McBurney, Onn Shehory and Steven Willmott\n\u00a9 September 2005, AgentLink III\nISBN 085432 845 9\nThis roadmap has been prepared as part of the activities of AgentLink III, the European Coordination \nAction for Agent-Based Computing (IST-FP6-002006CA). It is a collaborative effort, involving numerous \ncontributors listed at the end of the report. We are grateful to all who contributed, including those not \nnamed.\nNeither the editors, authors, contributors, nor reviewers accept any responsibility for loss or damage \narising from the use of information contained in this report.\nSpecial thanks go to Catherine Atherton, Roxana Belecheanu, Rebecca Earl, Adele Maggs, Steve \nMunroe and Serena Raf\ufb01  n, who all contributed in essential ways to the production of this document.\nThe cover was produced by Serena Raf\ufb01  n, based on an original design by Magdalena Koralewska.\nEditors:\nMichael Luck\nSchool of Electronics and Computer Science\nUniversity of Southampton\nSouthampton SO17 1BJ \nUnited Kingdom\nmml@ecs.soton.ac.uk\nPeter McBurney\nDepartment of Computer Science\nUniversity of Liverpool\nLiverpool L69 3BX\nUnited Kingdom\np.j.mcburney@csc.liv.ac.uk\nOnn Shehory\nIBM - Haifa Research Labs\nHaifa University\nMount Carmel, Haifa\n31905 Israel\nonn@il.ibm.com\nSteven Willmott\nDepartament Llenguatges i Sistemes Inform\u00e0tics\nUniversitat Polit\u00e8cnica de Catalunya\nJordi-Girona 1-3E-08034\nBarcelona, Spain\nsteve@lsi.upc.edu\nThe corresponding editor of this document is Michael Luck. 3\n \nAgentLink III\nAgentLink III is an Information Society Technologies (IST) Coordination Action for Agent-\nBased Computing, funded under the European Commission\u2019s Sixth Framework Programme \n(FP6), running through 2004 and 2005. Agent-based systems are one of the most vibrant \nand  important  areas  of  research  and  development  to  have  emerged  in  information \ntechnology in recent years, underpinning many aspects of broader information society \ntechnologies.\nThe long-term goal of AgentLink is to put Europe at the leading edge of international \ncompetitiveness in this increasingly important area. AgentLink is working towards this by \nseeking to achieve the following objectives. \n\u25a0  To  gain  competitive  advantage  for  European  industry  by  promoting  and  raising \nawareness of agent systems technology.\n\u25a0  To support standardisation of agent technologies and promote interoperability.\n\u25a0  To facilitate improvement in the quality, pro\ufb01  le, and industrial relevance of European \nresearch in the area of agent-based computer systems, and draw in relevant prior \nwork from related areas and disciplines.\n\u25a0  To support student integration into the agent community and to promote excellence \nin teaching in the area of agent-based systems.\n\u25a0  To provide a widely known, high-quality European forum in which current issues, prob-\nlems, and solutions in the research, development and deployment of agent-based \ncomputer systems may be debated, discussed, and resolved.\n\u25a0  To identify areas of critical importance in agent technology for the broader IST com-\nmunity, and to focus work in agent systems and deployment in these areas.\nFurther information about AgentLink III, and its activities, is available from the AgentLink \nwebsite at www.agentlink.org\nIn  trying  to  raise  awareness  and  to  promote  take-up  of  agent  technology,  there  is  a \nneed to inform the various audiences of the current state-of-the-art and to postulate the \nlikely future directions the technology and the \ufb01  eld will take. This is needed if commercial \norganisations are to best target their investments in the technology and its deployment, \nand also for policy makers to identify and support areas of particular importance. More \nbroadly, presenting a coherent vision of the development of the \ufb01  eld, its application areas \nand likely barriers to adoption of the technology is important for all stakeholders. AgentLink \nis undertaking this technology roadmapping study in order to develop just such a strategy \nfor agent research and development.4\nAgentLink Roadmap5\n \nContents\nExecutive Summary           7\n1   What is Agent Technology?          11\n1.1  Agents as Design Metaphor         11\n1.2  Agents as a Source of Technologies       12\n1.3  Agents as Simulation           12\n2   Technological Context           15\n3   Emerging Trends and Critical Drivers       19\n3.1  Semantic Web             19 \n3.2  Web Services and Service Oriented Computing     19\n3.3  Peer-to-Peer Computing         20\n3.4  Grid Computing           21\n3.5  Ambient Intelligence           23\n3.6  Self-* Systems and Autonomic Computing     24\n3.7  Complex Systems           25\n3.8  Summary             26\n4   Agent Technologies, Tools and Techniques     29\n4.1  Organisation Level           30\n4.1.1  Organisations            30\n4.1.2  Complex Systems and Self Organisation      30\n4.1.3  Trust and Reputation          32\n4.2  Interaction Level           33\n4.2.1  Coordination            33\n4.2.2  Negotiation            34\n4.2.3  Communication           35\n4.3  Agent Level             35\n4.4  Infrastructure and Supporting Technologies     36\n4.4.1  Interoperability            37\n4.4.2  Agent Oriented Software Engineering      37\n4.4.3  Agent Programming Languages       39\n4.4.4  Formal Methods           40\n4.4.5  Simulation            41\n4.4.6  User Interaction Design          426\nAgentLink Roadmap\n5   Adoption of Agent Technologies        43\n5.1  Diffusion of Innovations            43 \n5.2  Product Life Cycles            43\n5.3  Standards and Adoption         46\n5.4  Agent Technologies            47\n5.5  Modelling Diffusion of Agent Technologies      51\n5.5.1  Model Design            51\n5.5.2  Simulation Results          52\n5.6  Activity in Europe            53\n6   Market and Deployment Analysis       57\n6.1  Deliberative Delphi Survey         57\n6.1.1  Industry Sector Penetration        57\n6.1.2  Deployment of Agent Technologies      59\n6.1.3  Technology Areas and Maturity        60\n6.1.4  Standards            63\n6.1.5  Prospects            63\n6.2  The Agent Technology Hype Cycle        65\n6.2.1  The Gartner Analysis          66\n6.2.2  The AgentLink Analysis          67\n7   Technology Roadmap            71\n7.1  Phase 1: Current            71\n7.2  Phase 2: Short-Term Future         72\n7.3  Phase 3: Medium-Term Future         72\n7.4  Phase 4: Long-Term Future         73\n7.5  Technologies and Timescales         74\n8   Challenges             77\n8.1   Broad Challenges           77\n8.2   Speci\ufb01  c Challenges           78\n8.3   Recommendations           83\n9  Conclusions             85\n  References             87\n  Glossary             91\n  Web Resources and URLs         93\n  Methodology             95\n  AgentLink Members           97\n  Acknowledgements and Information Sources     1037\nExecutive Summary\nExecutive Summary\nIn its brief history, computing has enjoyed several different metaphors for the notion of \ncomputation. From the time of Charles Babbage in the nineteenth century until the mid-\n1960s,  most  people  thought  of  computation  as  calculation,  or  operations  undertaken \non  numbers.  With  widespread  digital  storage  and  manipulation  of  non-numerical \ninformation from the 1960s onwards, computation was re-conceptualised more generally \nas information processing, or operations on text, audio or video data. With the growth \nof the Internet and the World Wide Web over the last \ufb01  fteen years, we have reached a \nposition where a new metaphor for computation is required: computation as interaction. \nIn this metaphor, computing is something that happens by and through communication \nbetween computational entities. In the current radical reconceptualisation of computing, \nthe network is the computer, to coin a phrase. \nIn this new metaphor, computing is an activity that is inherently social, rather than solitary, \nleading to new ways of conceiving, designing, developing and managing computational \nsystems. One example of the in\ufb02  uence of this viewpoint is the emerging model of software \nas a service, for example in service-oriented architectures. In this model, applications are no \nlonger monolithic, functioning on one machine (for single user applications), or distributed \napplications managed by a single organisation (such as today\u2019s Intranet applications), \nbut instead are societies of components. \n\u25a0  These components are viewed as providing services to one another. They may not \nall have been designed together or even by the same software development team; \nthey may be created, operate and be decommissioned according to different times-\ncales; they may enter and leave different societies at different times and for different \nreasons; and they may form coalitions or virtual organisations with one another to \nachieve particular temporary objectives. Examples are automated procurement sys-\ntems comprising all the companies connected along a supply chain, or service crea-\ntion and service delivery platforms for dynamic provision of value-added telecommu-\nnications services.\n\u25a0  The components and their services may be owned and managed by different organi-\nsations, and thus have access to different information sources, have different objec-\ntives, and have con\ufb02  icting preferences.  Health care management systems spanning \nmultiple hospitals or automated resource allocation systems, such as Grid systems, are \nexamples here.  8\nAgentLink Roadmap\n\u25a0  The components are not necessarily activated by human users but may also carry \nout actions in an automated and coordinated manner when certain conditions hold. \nThese preconditions may themselves be distributed across components, so that action \nby one component requires prior co-ordination and agreement with other compo-\nnents. Simple multi-party database commit protocols are examples, but signi\ufb01  cantly \nmore complex coordination and negotiation protocols have been studied and de-\nployed, for example in utility computing systems and ad hoc wireless networks.    \n\u25a0  Intelligent, automated components may even undertake self-assembly of software \nand systems, to enable adaptation or response to changing external or internal cir-\ncumstances.  An example of this is the creation of on-the-\ufb02  y coalitions in automated \nsupply-chain systems in order to exploit dynamic commercial opportunities. Such sys-\ntems resemble those of the natural world and human societies much more than they \ndo the example arithmetic programs taught in Fortran classes, so ideas from biology, \nstatistical physics, sociology and economics play an increasingly important role in \ncomputing systems.  \nHow should we exploit this new metaphor of computing as social activity, as interaction \nbetween  independent  and  sometimes  intelligent  entities,  adapting  and  co-evolving \nwith one another? The answer, many people believe, lies with agent technologies. An \nagent is a computer program capable of \ufb02  exible and autonomous action in a dynamic \nenvironment,  usually  an  environment  containing  other  agents.  In  this  abstraction,  we \nhave encapsulated autonomous and intelligent software entities, called agents, and we \nhave demarcated the society in which they operate, a multi-agent system. Agent-based \ncomputing concerns the theoretical and practical working through of the details of this \nsimple two-level abstraction. \nIn the sense that it is a new paradigm, agent-based computing is disruptive. As outlined \nabove,  it  causes  a  re-evaluation  of  the  very  nature  of  computing,  computation  and \ncomputational systems, through concepts such as autonomy, coalitions and ecosystems, \nwhich  make  no  sense  to  earlier  paradigms.  Economic  historians  have  witnessed  such \ndisruption  with  new  technologies  repeatedly,  as  new  technologies  are  created,  are \nadopted, and then mature. A model of the life-cycle of such technologies, developed \nby Perez (2002), and reproduced in Figure 0.1, suggests two major parts: an installation \nperiod  of  exploration  and  development;  and  a  deployment  period  concentrating  on \nthe use of the technology. As will be argued later in this document, agent technologies \nare still in the early stages of adoption, the stage called irruption in this life-cycle. In the \nchapters that follow, we examine the current status of agent technologies and compare \ntheir market diffusion to related innovations, such as object technologies. We also consider \nthe challenges facing continued growth and adoption of agent technologies.9\nExecutive Summary\nThis document is a strategic roadmap for agent-based computing over the next decade.   \nIt  has  been  prepared  by  AgentLink  III,  a  European  Commission-funded  coordination \naction, intended to support and facilitate European research and development in agent \ntechnologies. The contents of the roadmap are the result of an extensive, eighteen-month \neffort of consultation and dialogue with experts in agent technology from the 192 member \norganisations of AgentLink III, in addition to experts in the Americas, Japan and Australasia. \nThe roadmap presents our views of how the technology will likely develop over the decade \nto 2015, the key research and development issues involved in this development, and the \nchallenges that currently confront research, development and further adoption of agent \ntechnologies.   \nThis strategic technology roadmap is not intended as a prediction of the future. Instead, \nit  is  a  reasoned  analysis:  given  an  analysis  of  the  recent  past  and  current  state  of \nagent technologies, and of computing more generally, we present one possible future \ndevelopment path for the technology. By doing this, we aim to identify the challenges \nand obstacles that will need to be overcome for progress to be made in research and \nFigure 0.1: The phases of technology life-cycles. Source: Carlota Perez\nThe life and times of a technology  \u2013  Recurring phases of each great surge\nSYNERGY\n(Golden age)\nNext Great\nSurge\nPrevious Great\nSurge\nBig Bang Next\nBig Bang\nCash Institutional\nAdjustment\nMATURITY\nIRRUPTION\nTURNING\nPOINT\nINSTALLATION PERIOD DEPLOYMENT PERIOD\nTIME\nD\ne\ng\nr\ne\ne\n \no\nf\n \nd\ni\nf\nf\nu\ns\ni\no\nn\n \no\nf\n \nt\nh\ne\n \nt\ne\nc\nh\nn\no\nl\no\ng\ni\nc\na\nl\n \nr\ne\nv\no\nl\nu\nt\ni\no\nn\nSource: Carlota Perez\nFRENZY\n(gilded age)10\nAgentLink Roadmap\ndevelopment, and for greater commercial adoption of the technology to occur. Moreover, \nby articulating a possible future path and identifying the challenges to be found along that \npath, we hope to galvanise the attention and efforts both of the agent-based computing \ncommunity and of the IT community more generally:  these challenges and obstacles will \nonly be overcome with concerted efforts by many people. We hope the ideas presented \nhere are provocative, because a strategic roadmap should not be the end of a dialogue, \nbut the beginning.  11\nAgent Technology\n  1 What is Agent Technology? \nAgent-based systems are one of the most vibrant and important areas of research and \ndevelopment to have emerged in information technology in the 1990s. Put at its simplest, \nan agent is a computer system that is capable of \ufb02  exible autonomous action in dynamic, \nunpredictable, typically multi-agent domains. In particular, the characteristics of dynamic \nand open environments in which, for example, heterogeneous systems must interact, span \norganisational boundaries, and operate effectively within rapidly changing circumstances \nand  with  dramatically  increasing  quantities  of  available  information,  suggest  that \nimprovements on traditional computing models and paradigms are required. Thus, the \nneed  for  some  degree  of  autonomy,  to  enable  components  to  respond  dynamically \nto changing circumstances while trying to achieve over-arching objectives, is seen by \nmany as fundamental. Many observers therefore believe that agents represent the most \nimportant new paradigm for software development since object orientation. \nThe concept of an agent has found currency in a diverse range of sub-disciplines of \ninformation  technology,  including  computer  networks,  software  engineering,  arti\ufb01  cial \nintelligence,  human-computer  interaction,  distributed  and  concurrent  systems,  mobile \nsystems,  telematics,  computer-supported  cooperative  work,  control  systems,  decision \nsupport, information retrieval and management, and electronic commerce. In practical \ndevelopments, web services, for example, now offer fundamentally new ways of doing \nbusiness through a set of standardised tools, and support a service-oriented view of distinct \nand independent software components interacting to provide valuable functionality. In \nthe context of such developments, agent technologies have increasingly come to the \nforeground. Because of its horizontal nature, it is likely that the successful adoption of \nagent technology will have a profound, long-term impact both on the competitiveness \nand viability of IT industries, and on the way in which future computer systems will be \nconceptualised and implemented. Agent technologies can be considered from three \nperspectives, each outlined below, as illustrated in Figure 1.1.\n1.1  Agents as Design Metaphor\nAgents provide software designers and developers with a way of structuring an application \naround  autonomous,  communicative  components,  and  lead  to  the  construction  of \nsoftware tools and infrastructure to support the design metaphor. In this sense, they offer \na new and often more appropriate route to the development of complex computational \nsystems,  especially  in  open  and  dynamic  environments.  In  order  to  support  this  view \nof  systems  development,  particular  tools  and  techniques  need  to  be  introduced.  For \nexample, methodologies to guide analysis and design are required, agent architectures \nare needed for the design of individual software components, tools and abstractions are \nrequired to enable developers to deal with the complexity of implemented systems, and 12\nAgentLink Roadmap\nsupporting infrastructure (embracing other relevant, widely used technologies, such as \nweb services) must be integrated.\n1.2  Agents as a Source of Technologies\nAgent technologies span a range of speci\ufb01  c techniques and algorithms for dealing with \ninteractions in dynamic, open environments. These address issues such as balancing reaction \nand deliberation in individual agent architectures, learning from and about other agents \nin the environment, eliciting and acting upon user preferences, \ufb01  nding ways to negotiate \nand cooperate with other agents, and developing appropriate means of forming and \nmanaging coalitions (and other organisations). Moreover, the adoption of agent-based \napproaches is increasingly in\ufb02  uential in other domains. For example, multi-agent systems \nare already providing new and more effective methods of resource allocation in complex \nenvironments than previous approaches. \n1.3  Agents as Simulation\nMulti-agent systems offer strong models for representing complex and dynamic real-world \nenvironments. For example, simulation of economies, societies and biological environments \nare typical application areas. \nFigure 1.1: Agent-based computing spans technologies, design and simulation\nSimulation\nTechnologies\nDesign\nMetaphor13\nAgent Technology\nThe use of agent systems to simulate real-world domains may provide answers to complex \nphysical or social problems that would otherwise be unobtainable due to the complexity \ninvolved, as in the modelling of the impact of climate change on biological populations, \nor modelling the impact of public policy options on social or economic behaviour. Agent-\nbased simulation spans: social structures and institutions to develop plausible explanations \nof observed phenomena, to help in the design of organisational structures, and to inform \npolicy  or  managerial  decisions;  physical  systems,  including  intelligent  buildings,  traf\ufb01  c \nsystems and biological populations; and software systems of all types, currently including \neCommerce and information management systems. \nIn  addition,  multi-agent  models  can  be  used  to  simulate  the  behaviour  of  complex \ncomputer systems, including multi-agent computer systems. Such simulation models can \nassist designers and developers of complex computational systems and provide guidance \nto software engineers responsible for the operational control of these systems. Multi-agent \nsimulation  models  thus  effectively  provide  a  new  set  of  tools  for  the  management  of \ncomplex adaptive systems, such as large-scale online resource allocation environments.\nWe do not claim that agent systems are simply panaceas for these large problems; rather \nthey have been demonstrated to provide concrete competitive advantages such as: \n\u25a0  improving operational robustness with intelligent failure recovery;\n\u25a0  reducing sourcing costs by computing the most bene\ufb01  cial acquistion policies in online \nmarkets; and\n\u25a0  improving ef\ufb01  ciency of manufacturing processes in dynamic environments.14\nAgentLink Roadmap\nNetherlands-based Acklin BV was asked by a group of three insurance com-\npanies, from Belgium, the Netherlands and Germany, to help automate their \ninternational vehicle claims processing system. At present, European rules  \nrequire settlement of cross-border insurance claims for international motor \naccidents within 3 months of the accident. However, the back-of\ufb01  ce sys-\ntems used by insurance companies are diverse, with data stored and used \nin different ways. Because of this and because of con\ufb01  dentiality concerns, \ninformation between insurance companies is usually transferred manually, \nwith contacts between claim handlers only by phone, fax and email. Acklin \ndeveloped a multi-agent system, the KIR system, with business rules and \nlogic encoded into discrete agents representing the data sources of the dif-\nferent companies involved. This approach means the system can ensure \ncon\ufb01  dentiality, with agent access to data sources mediated through other \nagents representing the data owners. Access to data sources is only granted \nto a requesting agent when the relevant permissions are present and for \nspeci\ufb01  ed data items. Because some data sources are only accessible dur-\ning business hours, agents can also be programmed to operate only within \nagreed time windows. Moreover, structuring the system as a collection of \nintelligent components in this way also enables greater system robustness, \nso that business processes can survive system shutdowns and failures. The \ndeployment of the KIR system immediately reduced the human workload at \none of the participating companies by three people, and reduced the total \ntime of identi\ufb01  cation of client and claim from 6 months to 2 minutes! For \nreasons of security, the KIR system used email for inter-agent communica-\ntion, and the 2 minutes maximum time is mainly comprised of delays in the \nemail servers and mail communication involved.\nAcklin and International Vehicle Insurance Claims15\nTechnological Context\n  2 Technological Context\nThe  growth  of  the  World  Wide  Web  and  the  rapid  rise  of  eCommerce  have  led  to \nsigni\ufb01  cant efforts to develop standardised software models and technologies to support \nand enable the engineering of systems involving distributed computation. These efforts \nare creating a rich and sophisticated context for the development of agent technologies. \nFor example, so-called service-oriented architectures (SOAs) for distributed applications \ninvolve  the  creation  of  systems  based  on  components,  each  of  which  provides  pre-\nde\ufb01  ned  computational  services,  and  which  can  then  be  aggregated  dynamically  at \nruntime to create new applications. Other relevant efforts range from low-level wireless \ncommunications protocols such as Bluetooth to higher-level web services abstractions \nand middleware. \nThe  development  of  standard  technologies  and  infrastructure  for  distributed  and \neCommerce systems has impacted on the development of agent systems in two major \nways.\n\u25a0  Many of these technologies provide implementation methods and middleware, ena-\nbling the easy creation of infrastructures for agent-based systems, such as standard-\nised methods for discovery and communication between heterogeneous services.\n\u25a0  Applications now enabled by these technologies are becoming increasingly agent-\nlike, and address dif\ufb01  cult technical challenges similar to those that have been the \nfocus of multi-agent systems. These include issues such as trust, reputation, obligations, \ncontract management, team formation, and management of large-scale open sys-\ntems.\nIn  terms  of  providing  potential  infrastructures  for  the  development  of  agent  systems, \ntechnologies of particular relevance include the following.\n\u25a0  Base Technologies:\n\u25a0  The Extensible Markup Language (XML) is a language for de\ufb01  ning mark-up lan-\nguages and syntactic structures for data formats. Though lacking in machine- \nreadable semantics, XML has been used to de\ufb01  ne higher-level knowledge rep-\nresentations  that facilitate semantic annotation of structured documents on the \nWeb.\n\u25a0  The Resource Description Format (RDF) is a representation formalism for describ-\ning and interchanging metadata.16\nAgentLink Roadmap\n\u25a0 eBusiness:\n\u25a0 ebXML aims to standardise XML business speci\ufb01  cations by providing an open XML-\nbased infrastructure enabling the global use of electronic business information in \nan interoperable, secure and consistent manner.\n\u25a0  RosettaNet is a consortium of major technology companies working to create \nand implement industry-wide eBusiness process standards. RosettaNet standards \noffer a robust non-proprietary solution, encompassing data dictionaries, an im-\nplementation framework, and XML-based business message schemas and proc-\ness speci\ufb01  cations for eBusiness standardisation.\n\u25a0 Universal Plug & Play:\n\u25a0  Jini network technology provides simple mechanisms that enable devices to \nplug together to form an emergent community in which each device pro-\nvides services that other devices in the community may use.\n\u25a0  UPnP offers pervasive peer-to-peer network connectivity of intelligent applianc-\nes and wireless devices through a distributed, open networking architecture to \nenable seamless proximity networking in addition to control and data transfer \namong networked devices.\n\u25a0 Web Services:\n\u25a0  UDDI is an industry initiative aimed at creating a platform-independent, open \nframework for describing services and discovering businesses using the Internet. \nIt is a cross-industry effort driven by platform and software providers, marketplace \noperators and eBusiness leaders.\n\u25a0  SOAP provides a simple and lightweight mechanism for exchanging structured \nand typed information between peers in a decentralised, distributed environ-\nment using XML.\n\u25a0   WSDL/WS-CDL: WSDL provides an XML grammar for describing network services \nas collections of communication endpoints capable of exchanging messages, \nthus enabling the automation of the details involved in applications communi-\ncation. WS-CDL allows the de\ufb01  nition of abstract interfaces of web services, that \nis, the business-level conversations or public processes supported by a web \nservice.\nConversely,  agent-related  activities  are  already  beginning  to  inform  development  in  a \nnumber of these technology areas, including the Semantic Web standardisation efforts of the \nWorld Wide Web Consortium (W3C), and the Common Object Request Broker Architecture \n(CORBA) of the Object Management Group (OMG). Contributions have also come through 17\nTechnological Context\nthe Foundation for Intelligent Physical Agents (FIPA; accepted in 2005 by the IEEE as its \neleventh standards committee), which de\ufb01  nes a range of architectural elements similar to \nthose now adopted in the W3C Web Services Architecture speci\ufb01  cations and elsewhere.\nThese  developments  with  regard  to  the  technological  context  for  agent  systems  are \nillustrated  in  Figure  2.1,  which  presents  the  main  contextual  technologies  supporting \nagent systems development. While research in agent technologies has now been active \nfor over a decade, the \ufb01  gure shows that it is only from 1999, with the appearance of \neffective  service-oriented  technologies  and  pervasive  computing  technologies,  that \ntruly dynamic (ad hoc) networked systems could be built without large investments in \nestablishing the underlying infrastructure. In particular, only with the emergence of Grid \ncomputing from 2002, and calls for adaptive wide-scale web service based solutions, is \nthere now a widespread need to provide attractive solutions to the higher-level issues of \ncommunication, coordination and security.\nFigure 2.1: Agent-related technologies for infrastructure support\n2005\nCORBA\nRMI\nDCOM EJB COM+ .NET\n(ICQ) Instant Messaging Napster JXTA\nGnutella\nOGSA WSRF\nBluetooth\nWiFi\nWSDL SOAP\nBPEL4WS\nUDDI\nJini UPnP\nJava Spaces\n1990 1995 2000 2005 pre-1990\nInternet\nTechnologies\nDistributed Object \nTechnologies\nPeer-to-Peer\nGRID\nService-Oriented \nTechnologies\nWeb Services\nPervasive \nComputing\nRDF\nemail TCP\nIP\nWWW HTTP XML DAML+OIL OWL18\nAgentLink Roadmap\nIn general, it is clear that broad technological developments in distributed computation \nare increasingly addressing problems long explored within the agent research community. \nThere are two inter-related developments here. First, supporting technologies are emerging \nvery quickly. As a consequence, the primary research focus for agent technologies has \nmoved from infrastructure to the higher-level issues concerned with effective coordination \nand cooperation between disparate services. Second, large numbers of systems are being \nbuilt and designed using these emerging infrastructures, and are becoming ever more like \nmulti-agent systems; their developers therefore face the same conceptual and technical \nchallenges encountered in the \ufb01  eld of agent-based computing.\nMany companies \ufb01  nd themselves under strong pressures to deliver just-\nin-time high quality products and services, while operating in a highly \ncompetitive market. In one of SCA Packaging\u2019s corrugated box plants, \ncustomer orders often arrive simultaneously for a range of different boxes, \neach order with its own colour scheme and speci\ufb01  c printing, and often to \nbe delivered at very short notice. Because of the complexity of factory \nprocesses and the dif\ufb01  culty of predicting customer behaviour and machine \nfailure, large inventories of \ufb01  nished goods must therefore be managed. \nSCA Packaging turned to Eurobios to provide an agent-based modelling \nsolution in order to explore different strategies for reducing stock levels \nwithout compromising delivery times, as well as evaluating consequences \nof changes in the customer base. The agent-based simulation developed \nby Eurobios allowed the company to reduce warehouse levels by over \n35% while maintaining delivery commitments.\nEurobios and SCA Packaging19\nTrends and Drivers\n  3 Emerging Trends and Critical Drivers\nThe development of agent technologies has taken place within a context of wider visions \nfor  information  technology.  In  addition  to  the  speci\ufb01  c  technologies  mentioned  in  the \nprevious section, there are also several key trends and drivers that suggest that agents \nand agent technologies will be vital. The discussion is not intended to be exhaustive, but \ninstead indicative of the current impetus for use and deployment of agent systems. \n3.1  Semantic Web\nSince  it  was  \ufb01  rst  developed  in  the  early  1990s,  the  World  Wide  Web  has  rapidly  and \ndramatically become a critically important and powerful medium for communication, \nresearch and commerce. However, the Web was designed for use by humans, and its \npower is limited by the ability of humans to navigate the data of different information \nsources.\nThe Semantic Web is based on the idea that the data on the Web can be de\ufb01  ned and \nlinked  in  such  a  way  that  it  can  be  used  by  machines  for  the  automatic  processing \nand  integration  of  data  across  different  applications  (Berners-Lee  et  al.,  2001).  This  is \nmotivated by the fundamental recognition that, in order for web-based applications to \nscale, programs must be able to share and process data, particularly when they have \nbeen designed independently. The key to achieving this is by augmenting web pages \nwith descriptions of their content in such a way that it is possible for machines to reason \nautomatically about that content. \nAmong the particular requirements for the realisation of the Semantic Web vision are: rich \ndescriptions of media and content to improve search and management; rich descriptions \nof web services to enable and improve discovery and composition; common interfaces \nto simplify integration of disparate systems; and a common language for the exchange of \nsemantically-rich information between software agents.\nIt should be clear from this that the Semantic Web demands effort and involvement from \nthe \ufb01  eld of agent-based computing, and the two \ufb01  elds are intimately connected. Indeed, \nthe Semantic Web offers a rich breeding ground for both further fundamental research \nand a whole range of agent applications that can (and should) be built on top of it. \n3.2  Web Services and Service Oriented Computing\nWeb services technologies provide a standard means of interoperating between different \nsoftware applications, running on a variety of different platforms. Speci\ufb01  cations cover a \nwide range of interoperability issues, from basic messaging, security and architecture, 20\nAgentLink Roadmap\nto service discovery and the composition of individual services into structured work\ufb02  ows. \nStandards for each of these areas, produced by bodies such as W3C and OASIS, provide \na framework for the deployment of component services accessible using HTTP and XML \ninterfaces.  These  components  can  subsequently  be  combined  into  loosely  coupled \napplications that deliver increasingly sophisticated value-added services.\nIn a more general sense, web services standards serve as a potential convergence point \nfor diverse technology efforts such as eBusiness frameworks (ebXML, RosettaNet, etc), Grid \narchitectures (which are now increasingly based on web services infrastructures) and others, \ntowards a more general notion of service-oriented architectures (SOA). Here, distributed \nsystems are increasingly viewed as collections of service provider and service consumer \ncomponents, interlinked by dynamically de\ufb01  ned work\ufb02  ows. Web services can therefore \nbe realised by agents that send and receive messages, while the services themselves are \nthe resources characterised by the functionality provided. In the same way as agents may \nperform tasks on behalf of a user, a web service provides this functionality on behalf of its \nowner, a person or organisation.\nWeb  services  thus  provide  a  ready-made  infrastructure  that  is  almost  ideal  for  use  in \nsupporting  agent  interactions  in  a  multi-agent  system.  More  importantly,  perhaps,  this \ninfrastructure  is  widely  accepted,  standardised,  and  likely  to  be  the  dominant  base \ntechnology over the coming years. Conversely, an agent-oriented view of web services \nis gaining increased traction and exposure, since provider and consumer web services \nenvironments are naturally seen as a form of agent-based system (Booth et al., 2004).\n3.3  Peer-to-Peer Computing\nPeer-to-peer (P2P) computing covers a wide range of infrastructures, technologies and \napplications that share a single characteristic: they are designed to create networked \napplications in which every node (or deployed system) is in some sense equivalent to all \nothers, and application functionality is created by potentially arbitrary interconnection \nbetween  these  peers.  The  consequent  absence  of  the  need  for  centralised  server \ncomponents to manage P2P systems makes them highly attractive in terms of robustness \nagainst failure, ease of deployment, scalability and maintenance (Milojicic et al., 2002).\nThe best known P2P applications include hugely popular \ufb01  le sharing applications such as \nGnutella and Bit Torrent, Akamai content caching, groupware applications (such as Groove \nNetworks of\ufb01  ce environments) and Internet telephony applications such as Skype. While \nthe majority of these well-known systems are based on proprietary protocols and platforms, \ntoolkits such as Sun Microsystem\u2019s JXTA provide a wide array of networking features for the \ndevelopment of P2P applications, such as messaging, service advertisement and peer 21\nTrends and Drivers\nmanagement features. Standardisation for P2P technologies is also underway within the \nGlobal Grid Forum (GGF), which now includes a P2P working group established by Intel in \n2000.\nP2P  applications  display  a  range  of  agent-like  characteristics,  often  applying  self-\norganisation  techniques  in  order  to  ensure  continuous  operation  of  the  network,  and \nrelying  on  protocol  design  to  encourage  correct  behaviour  of  clients.  (For  example, \nmany commercial e-marketplace systems, such as eBay, include simple credit-reputation \nsystems to reward socially bene\ufb01  cial behaviour). As P2P systems become more complex, \nan increasing number of agent technologies may also become relevant. These include, \nfor example: auction mechanism design to provide a rigorous basis to incentivise rational \nbehaviour among clients in P2P networks; agent negotiation techniques to improve the \nlevel of automation of peers in popular applications; increasingly advanced approaches \nto trust and reputation; and the application of social norms, rules and structures, as well as \nsocial simulation, in order to better understand the dynamics of populations of independent \nagents.\n3.4  Grid Computing\nThe  Grid  is  the  high-performance  computing  infrastructure  for  supporting  large-scale \ndistributed  scienti\ufb01  c  endeavour  that  has  recently  gained  heightened  and  sustained \ninterest  from  several  communities  (Foster  and  Kesselman,  2004).  The  Grid  provides  a \nmeans of developing eScience applications such as those demanded by, for example, \nthe Large Hadron Collider facility at CERN, engineering design optimisation, bioinformatics \nand combinatorial chemistry. Yet it also provides a computing infrastructure for supporting \nmore  general  applications  that  involve  large-scale  information  handling,  knowledge \nmanagement and service provision. Typically, Grid systems are abstracted into several \nlayers,  which  might  include:  a  data-computation  layer  dealing  with  computational \nresource  allocation,  scheduling  and  execution;  an  information  layer  dealing  with  the \nrepresentation, storage and access of information; and a knowledge layer, which deals \nwith the way knowledge is acquired, retrieved, published and maintained.\nThe Grid thus refers to an infrastructure that enables the integrated, collaborative use \nof  high-end  computers,  networks,  databases,  and  scienti\ufb01  c  instruments  owned  and \nmanaged by multiple organisations. Grid applications often involve large amounts of data \nand computer processing, and often require secure resource sharing across organisational \nboundaries; they are thus not easily handled by today\u2019s Internet and Web infrastructures. \nThe key bene\ufb01  t of Grid computing more generally is \ufb02  exibility \u2013 the distributed system and \nnetwork can be recon\ufb01  gured on demand in different ways as business needs change, \nThe  UK\u2019s \neScience \nprogramme has \nallocated \u00a3230M \nto Grid-related \ncomputing, \nwhile \nGermany\u2019s             \nD-Grid \nprogramme  \nhas allocated \n\u20ac300M, and the \nFrench ACI Grid \nprogramme \nnearly \u20ac50M.22\nAgentLink Roadmap\nin principle enabling more \ufb02  exible IT deployment and more ef\ufb01  cient use of computing \nresources (Information Age Partnership, 2004). According to BAE Systems (Gould et al., \n2003), while the technology is already in a state in which it can realise these bene\ufb01  ts in a \nsingle organisational domain, the real value comes from cross-organisation use, through \nvirtual  organisations,  which  require  ownership,  management  and  accounting  to  be \nhandled within trusted partnerships. In economic terms, such virtual organisations provide \nan appropriate way to develop new products and services in high value markets; this \nfacilitates the notion of service-centric software, which is only now emerging because of \nthe constraints imposed by traditional organisations. As the Information Age Partnership \n(2004) suggests, the future of the Grid is not in the provision of computing power, but in \nthe provision of information and knowledge in a service-oriented economy. Ultimately, \nThe  Internet  has  enabled  computational  resources  to  be  accessed \nremotely. Networked resources such as digital information, specialised \nlaboratory  equipment  and  computer  processing  power  may  now  be \nshared  between  users  in  multiple  organisations,  located  at  multiple \nsites. For example, the emerging Grid networks of scienti\ufb01  c communities \nenable  shared  and  remote  access  to  advanced  equipment  such  as \nsupercomputers, telescopes and electron microscopes. Similarly, in the \ncommercial IT arena, shared access to computer processing resources \nhas recently drawn the attention of major IT vendors with companies \nsuch as HP (\u201cutility computing\u201d), IBM (\u201con-demand computing\u201d), and \nSun (\u201cN1 Strategy\u201d) announcing initiatives in this area. Sharing resources \nacross multiple users, whether commercial or scienti\ufb01  c, allows scientists \nand IT managers to access resources on a more cost-effective basis, \nand achieves a closer  match between demand and supply of resources. \nEnsuring ef\ufb01  cient use of shared resources in this way will require design, \nimplementation and management of resource-allocation mechanisms in \na computational setting.\nUtility Computing23\nTrends and Drivers\nthe success of the Grid will depend on standardisation and the creation of products, and \nefforts in this direction are already underway from a range of vendors, including Sun, IBM \nand HP.\n3.5  Ambient Intelligence\nThe notion of ambient intelligence has largely arisen through the efforts of the European \nCommission in identifying challenges for European research and development in Information \nSociety Technologies (IST Advisory Group, 2002). Aimed at seamless delivery of services and \napplications, it relies on the areas of ubiquitous computing, ubiquitous communication and \nintelligent user interfaces. The vision describes an environment of potentially thousands of \nembedded and mobile devices (or software components) interacting to support user-\ncentred  goals  and  activity,  and  suggests  a  component-oriented  view  of  the  world  in \nwhich the components are independent and distributed. The consensus is that autonomy, \ndistribution,  adaptation,  responsiveness,  and  so  on,  are  key  characteristics  of  these \ncomponents, and in this sense they share the same characteristics as agents.\nAmbient intelligence requires these agents to be able to interact with numerous other \nagents in the environment around them in order to achieve their goals. Such interactions \ntake  place  between  pairs  of  agents  (in  one-to-one  collaboration  or  competition), \nbetween groups (in reaching consensus decisions or acting as a team), and between \nagents and the infrastructure resources that comprise their environments (such as large-\nscale information repositories). Interactions like these enable the establishment of virtual \norganisations, in which groups of agents come together to form coherent groups able to \nachieve overarching objectives.\nThe environment provides the infrastructure that enables ambient intelligence scenarios to \nbe realised. On the one hand, agents offering higher-level services can be distinguished \nfrom the physical infrastructure and connectivity of sensors, actuators and networks, for \nexample. On the other hand, they can also be distinguished from the virtual infrastructure \nneeded  to  support  resource  discovery,  large-scale  distributed  and  robust  information \nrepositories (as mentioned above), and the logical connectivity needed to enable effective \ninteractions between large numbers of distributed agents and services, for example.\nIn  relation  to  pervasiveness,  it  is  important  to  note  that  scalability  (more  particularly, \ndevice scalability), or the need to ensure that large numbers of agents and services are \naccommodated, as well as heterogeneity of agents and services, is facilitated by the \nprovision of appropriate ontologies. Addressing all of these aspects will require efforts to \nprovide solutions to issues of operation, integration and visualisation of distributed sensors, \nad hoc services and network infrastructure.24\nAgentLink Roadmap\n3.6  Self-* Systems and Autonomic Computing\nComputational systems that are able to manage themselves have been part of the vision \nfor computer science since the work of Charles Babbage. With the increasing complexity \nof  advanced  information  technology  systems,  and  the  increasing  reliance  of  modern \nsociety on these systems, attention in recent years has returned to this. Such systems have \ncome to be called self-* systems and networks (pronounced \u201cself-star\u201d), with the asterisk \nindicating that a variety of attributes are under consideration. While an agreed de\ufb01  nition \nof self-* systems is still emerging, aspects of these systems include properties such as: self-\nawareness,  self-organisation,  self-con\ufb01  guration,  self-management,  self-diagnosis,  self \ncorrection, and self-repair.\nSuch systems abound in nature, from the level of ecosystems, through large primates \n(such  as  man)  and  down  to  processes  inside  single  cells.  Similarly,  many  chemical, \nphysical, economic and social systems exhibit self-* properties. Thus, the development \nof computational systems that have self-* properties is increasingly drawing on research \nin  biology,  ecology,  statistical  physics  and  the  social  sciences.  Recent  research  on \ncomputational self-* systems has tried to formalise some of the ideas from these different \ndisciplines,  and  to  identify  algorithms  and  procedures  that  could  realise  various  self-* \nattributes, for example in peer-to-peer networks. One particular approach to self-* systems \nhas become known as autonomic computing, considered below.\nComputational self-* systems and networks provide an application domain for research and \ndevelopment of agent technologies, and also a contribution to agent-based computing \ntheory and practice, because many self-* systems may be viewed as involving interactions \nbetween autonomous entities and components.\nMore speci\ufb01  cally, in response to the explosion of information, the integration of technology \ninto everyday life, and the associated problems of complexity in managing and operating \ncomputer systems, autonomic computing takes inspiration from the autonomic function \nof  the  human  central  nervous  system,  which  controls  key  functions  without  conscious \nawareness or involvement. First proposed by IBM (Kephart and Chess, 2003), autonomic \ncomputing  is  an  approach  to  self-managed  computing  systems  with  a  minimum  of \nhuman interference. Its goal is a network of sophisticated computing components that \ngives users what they need, when they need it, without a conscious mental or physical \neffort. Among the de\ufb01  ning characteristics of an autonomic system are the following: it \nmust automatically con\ufb01  gure and recon\ufb01  gure itself under varying (and unpredictable) \nconditions; it must seek to optimise its operation, monitoring its constituent parts and \ufb01  ne-\ntuning its work\ufb02  ow to achieve system goals; it must be able to discover problems and \nrecover from routine and extraordinary events that might cause malfunctions; it must act 25\nTrends and Drivers\nin accordance with its current environment, adapting to best interact with other systems, \nby negotiating for resource use; it must function in a heterogeneous world and implement \nopen standards; and it must marshal resources to reduce the gap between its (user) goals \nand their achievement, without direct user intervention. \nUltimately, the aim is to realise the promise of IT: increasing productivity while minimising \ncomplexity for users. The key message to be drawn from this vision is that it shares many of \nthe goals of agent-based computing, and agents offer a way to manage the complexity \nof self-* and autonomic systems. \n3.7  Complex Systems\nModern  software  and  technological  systems  are  among  the  most  complex  human \nartefacts,  and  are  ever-increasing  in  complexity.  Some  of  these  systems,  such  as  the \nInternet, were not designed but simply grew organically, with no central human control \nor even understanding. Other systems, such as global mobile satellite communications \nnetworks or current PC operating systems, have been designed centrally, but comprise so \nmany interacting components and so many types of interactions that no single person or \neven team of people could hope to comprehend the detailed system operations. This lack \nof understanding may explain why such systems are prone to error as, for example, in the \nlarge-scale electricity network failures in North America and in Italy in 2003. \nMoreover, many systems that affect our lives involve more than just software. For example, \nthe ecosystem of malaria involves natural entities (parasites and mosquitos), humans, human \nculture, and technological artefacts (drugs and treatments), all interacting in complex, \nsubtle and dynamic ways. Intervening in such an ecosystem, for example by providing a \nnew treatment regime for malaria, may have unintended and unforeseen consequences \ndue to the nature of these interactions being poorly understood. The science of complex \nadaptive systems is still in its infancy, and as yet provides little in the way of guidance for \ndesigners and controllers of speci\ufb01  c systems. \nWhether such complex, adaptive systems are explicitly designed or not, their management \nand control is vitally important to modern societies. Agent technologies provide a way to \nconceptualise these systems as comprising interacting autonomous entities, each acting, \nlearning or evolving separately in response to interactions in their local environments. Such \na conceptualisation provides the basis for realistic computer simulations of the operation \nand behaviour of the systems, and of design of control and intervention processes (Bullock \nand  Cliff,  2004).  For  systems  that  are  centrally  designed,  such  as  electronic  markets \noverlaid on the Internet, agent technologies also provide the basis for the design and \nimplementation of the system itself. Indeed, it has been argued that agent technologies 26\nAgentLink Roadmap\nprovide a valuable way of coping with the increasing complexity of modern software \nsystems  (Zambonelli  and  Parunak,  2002),  particularly  the  characteristics  of  pervasive \ndevices, ambient intelligence, continuous operation (allowing no downtime for upgrades \nor maintenance), and open systems. \n3.8  Summary\nIt is natural to view large systems in terms of the services they offer, and consequently in \nterms of the entities or agents providing or consuming services. The domains discussed here \nre\ufb02  ect the trends and drivers for applications in which typically many agents and services \nmay be involved, and spread widely over a geographically distributed environment. Figure \n3.1 depicts the emergence of these driver domains over time, suggesting that their maturity, \nwhich will demand the use of agent technologies, is likely to be some years away.\nMost importantly perhaps, the environments that have been identi\ufb01  ed here are open and \ndynamic so that new agents may join and existing ones leave. In this view, agents act \non behalf of service owners, managing access to services, and ensuring that contracts \nare ful\ufb01  lled. They also act on behalf of service consumers, locating services, agreeing \ncontracts, and receiving and presenting results. In these domains, agents will be required \nFigure 3.1: The emergence of agent-related domains over time.\n2000 2005 2010\nAmbient Intelligence\nAutonomic Computing\nWeb Services\nGrid Computing\nPeer-to-Peer\nSemantic Web27\nTrends and Drivers\nto  engage  in  interactions,  to  negotiate,  to  make  pro-active  run-time  decisions  while \nresponding to changing circumstances, and to allocate and schedule resources across \nthe  diverse  competing  demands  placed  on  infrastructures  and  systems.  In  particular, \nagents with different capabilities will need to collaborate and to form coalitions in support \nof new virtual organisations. \nOf course, these drivers do not cover all areas within the \ufb01  eld of agent-based computing. \nFor example, there is a need for systems that can behave intelligently and work as part \nof a community, supporting or replacing humans in environments that are dirty, dull or \ndangerous. There are also drivers relating to human-agent interfaces, learning agents, \nrobotic agents, and many others, but those identi\ufb01  ed here provide a context that is likely \nto drive forward the whole \ufb01  eld.\nNuTech and Air Liquide\nAir Liquide America LP, a Houston-based producer of lique\ufb01  ed industrial \ngases  with  more  than  8000  customers  worldwide,  turned  to  agent \ntechnology  to  reduce  production  and  distribution  costs.  The  system \nwas  developed  by  NuTech  Solutions,  using  a  multi-agent  ant  system \noptimisation approach combined with a genetic algorithm and a suite of \nexpert heuristics. The ant system optimiser discovered ef\ufb01  cient product \ndistribution  routes  from  the  plant  to  the  customer,  while  the  genetic \nalgorithm  was  implemented  to  search  for  highly  optimal  production \nlevel schedules for individual plants. As a result of using the system, Air \nLiquide America managed to reduce inef\ufb01  ciencies in the manufacturing \nprocess, adapt production schedules to changing conditions and deliver \nproducts cost-effectively, where and when the customer demands, and \nin a manner that is responsive to unexpected events. Together, these \nbene\ufb01  ts offered Air Liquide an optimal cost product with the potential of \nnew market opportunities and operational savings.28\nAgentLink Roadmap29\nTools and Techniques\n4 Agent Technologies, Tools and Techniques\nIt should be clear that there are several distinct high-level trends and drivers leading to \ninterest  in  agent  technologies,  and  low-level  computing  infrastructures  making  them \npractically feasible. In this context, we now consider the key technologies and techniques \nrequired to design and implement agent systems that are the focus of current research \nand development. Because agent technologies are mission-critical for engineering and \nfor managing certain types of information systems, such as Grid systems and systems for \nambient intelligence, the technologies and techniques discussed below will be important \nfor many applications, even those not labelled as agent systems.\nThese technologies can now be grouped into three categories, according to the scale at \nwhich they apply:\n\u25a0  Organisation-level: At the top level are technologies and techniques related to agent \nsocieties as a whole. Here, issues of organisational structure, trust, norms and obli-\ngations, and self-organisation in open agent societies are paramount. Once again, \nmany of these questions have been studied in other disciplines \u2014 for example, in soci-\nology, anthropology and biology. Drawing on this related work, research and devel-\nopment is currently focused on technologies for designing, evolving and managing \ncomplex agent societies.\n\u25a0  Interaction-level: These are technologies and techniques that concern the commu-\nnications between agents \u2014 for example, technologies related to communication \nlanguages, interaction protocols and resource allocation mechanisms. Many of the \nproblems solved by these technologies have been studied in other disciplines, includ-\ning economics, political science, philosophy and linguistics. Accordingly, research \nand development is drawing on this prior work to develop computational theories \nand technologies for agent interaction, communication and decision-making.\n\u25a0  Agent-level: These are technologies and techniques concerned only with individual \nagents \u2014 for example, procedures for agent reasoning and learning. Problems at this \nlevel have been the primary focus of arti\ufb01  cial intelligence since its inception, aiming \nto build machines that can reason and operate autonomously in the world. Agent re-\nsearch and development has drawn extensively on this prior work, and most attention \nin the \ufb01  eld of agent-based computing now focuses at the previous two higher levels.\nIn  addition  to  technologies  at  these  three  levels,  we  must  also  consider  technologies \nproviding infrastructure and supporting tools for agent systems, such as agent programming \nlanguages and software engineering methodologies. These supporting technologies and \ntechniques provide the basis for both the theoretical understanding and the practical \nimplementation of agent systems.30\nAgentLink Roadmap\n4.1  Organisation Level\n4.1.1  Organisations\nDynamic agent organisations that adjust themselves to gain advantage in their current \nenvironments are likely to become increasingly important over the next \ufb01  ve years. They \nwill  arise  in  dynamic  (or  emergent)  agent  societies,  such  as  those  suggested  by  the \nGrid, ambient intelligence and other domains in which agents come together to deliver \ncomposite services, all of which require that agents can adapt to function effectively in \nuncertain or hostile environments. Some work has already started on the development of \nsystems that can meet this challenge, which is fundamental to realising the power of the \nagent paradigm; its relevance will remain at the forefront of R&D efforts over the next 10-\n15 years, especially in relation to commercial efforts at exploitation. In particular, building \ndynamic agent organisations (including, for example, methods for teamwork, coalition \nformation, and so on) for dealing with aspects of the emerging visions of the Grid and the \nWeb, as well as aspects of ubiquitous computing, will be crucial.\nSocial  factors  in  the  organisation  of  multi-agent  systems  will  also  become  increasingly \nimportant over the next decade as we seek ways to structure interactions in an open and \ndynamic online world. This relates to the need to properly assign roles, (institutional) powers, \nrights and obligations to agents in order to control security and trust-related aspects of \nmulti-agent systems at a semantic level, as opposed to current developments, which deal \nwith them at the infrastructure level. These social factors can provide the basis on which to \ndevelop methods for access control, for example, and to ensure that behaviour is regulated \nand structured when faced with dynamic environments in which traditional techniques are \nnot viable. In addition to appropriate methods and technologies for agent team formation, \nmanagement, assessment, coordination and dissolution, technologies will also be required \nfor these processes to be undertaken automatically at runtime in dynamic environments.\n4.1.2  Complex Systems and Self Organisation\nSelf-organisation refers to the process by which a system changes its internal organisation \nto adapt to changes in its goals and environment without explicit external control. This can \noften result in emergent behaviour that may or may not be desirable. Due to the dynamism \nand openness of contemporary computing environments, understanding the mechanisms \nthat can be used to model, assess and engineer self-organisation and emergence in multi-\nagent systems is an issue of major interest.\nA self-organising system functions through contextual local interactions, without central \ncontrol. Components aim to individually achieve simple tasks, but a complex collective 31\nTools and Techniques\nbehaviour emerges from their mutual interactions. Such a system modi\ufb01  es its structure \nand functionality to adapt to changes to requirements and to the environment based \non  previous  experience.  Nature  provides  examples  of  self-organisation,  such  as  ants \nforaging for food, molecule formation, and antibody detection. Similarly, current software \napplications  involve  social  interactions  (such  as  negotiations  and  transactions)  with \nautonomous entities or agents, in highly dynamic environments. Engineering applications \nto achieve robustness and adaptability, based on the principles of self-organisation, is \nthus gaining increasing interest in the software community. This interest originates from the \nfact that current software applications need to cope with requirements and constraints \nstemming from the increased dynamism, sophisticated resource control, autonomy and \ndecentralisation inherent in contemporary business and social environments. The majority \nof these characteristics and constraints are the same as those that can be observed in \nnatural systems exhibiting self-organisation.\nSelf-organisation mechanisms provide the decision-making engines based on which system \ncomponents process input from software and hardware sensors to decide how, when and \nwhere to modify the system\u2019s structure and functionality. This enables a better \ufb01  t with the \ncurrent requirements and environment, while preventing damage or loss of service. It is \ntherefore necessary to characterise the applications in which existing mechanisms, such \nas stigmergy (or the means by which the individual parts of a system communicate with \none another by modifying their local environment, much like ants), can be used, and to \ndevelop new generic mechanisms independent of any particular application domain.\nIn  some  cases,  self-organisation  mechanisms  have  been  modelled  using  rule-based \napproaches or control theory. Furthermore, on many occasions the self-organising actions \nhave  been  inspired  by  biological  and  natural  processes,  such  as  the  human  nervous \nsystem and the behaviour observed in insect species that form colonies. Although such \napproaches to self-organisation have been effective in certain domains, environmental \ndynamics and software complexity have limited their general applicability. More extensive \nresearch  in  modelling  self-organisation  mechanisms  and  systematically  constructing \nnew ones is therefore needed. Future self-organising systems must accommodate high-\ndimensional sensory data, continue to learn from new experiences and take advantage \nof new self-organisation acts and mechanisms as they become available.\nA  phenomenon  is  characterised  as  emergent  if  it  has  not  been  exactly  prede\ufb01  ned \nin advance. Such a phenomenon can be observed at a macro system level and it is \ngenerally characterised by novelty, coherence, irreducibility of macro level properties \nto micro-level ones and non-linearity. In multi-agent systems, emergent phenomena are \nthe global system behaviours that are collective results originating from the local agent \ninteractions and individual agent behaviours. Emergent behaviours can be desirable or 32\nAgentLink Roadmap\nundesirable; building systems with desirable emergent behaviour capabilities can increase \ntheir robustness, autonomy, openness and dynamism. \nTo  achieve  desired  global  emergent  system  behaviour,  local  agent  behaviours  and \ninteractions should comply with some behavioural framework dictated by a suitable theory \nof  emergence.  Unfortunately,  too  few  theories  of  emergence  are  currently  available \nand existing ones still require improvement. In consequence, therefore, new theories of \nemergence need to be developed based on inspiration from natural or social systems, for \nexample.\nAn important open issue in self-organising systems relates to modelling the application \ncontext and environment. In this respect, a key question is the de\ufb01  nition of the relevant \nenvironmental  parameters  that  need  to  be  considered  in  determining  the  evolving \nstructure and functionality of self-organising software. Additional open questions relate \nto: how context can be captured, processed and exploited for adjusting the services \nprovided by the application in a given situation; how the self-organising effects occurring \nfrom participation of the application in different contexts can be synchronised; how to \neffectively model user preferences and intentions; and the amount of historical information \nthat should be recorded by the system and considered in determining its evolution over \ntime.\n4.1.3  Trust and Reputation\nMany applications involving multiple individuals or organisations must take into account \nthe relationships (explicit or implicit) between participants. Furthermore, individual agents \nmay also need to be aware of these relationships in order to make appropriate decisions. \nThe \ufb01  eld of trust, reputation and social structure seeks to capture human notions such as \ntrust, reputation, dependence, obligations, permissions, norms, institutions and other social \nstructures in electronic form. \n \nBy modelling these notions, engineers can borrow strategies commonly used by humans \nto resolve con\ufb02  icts that arise when creating distributed applications, such as regulating \nthe actions of large populations of agents using \ufb01  nancial disincentives for breaking social \nrules or devising market mechanisms that are proof against certain types of malicious \nmanipulation. The theories are often based on insights from different domains including \neconomics (market-based approaches), other social sciences (social laws, social power) \nor mathematics (game theory and mechanism design). \nThe complementary aspect of this social perspective relating to reputation and norms is \na traditional concern with security. Although currently deployed agent applications often 33\nTools and Techniques\nprovide good security, when considering agents autonomously acting on behalf of their \nowner several additional factors need to be addressed. In particular, collaboration of any \nkind, especially in situations in which computers act on behalf of users or organisations, will \nonly succeed if there is trust. Ensuring this trust requires, for example, the use of: reputation \nmechanisms to assess prior behaviour; norms (or social rules) and the enforcement of \nsanctions; and electronic contracts to represent agreements.\nWhereas  assurance  deals  primarily  with  system  integrity,  security  addresses  protection \nfrom malicious entities: preventing would-be attackers from exploiting self-organisation \nmechanisms that alter system structure and behaviour. In addition, to verify component \nsources,  a  self-organising  software  system  must  protect  its  core  from  attacks.  Various \nwell-studied  security  mechanisms  are  available,  such  as  strong  encryption  to  ensure \ncon\ufb01  dentiality and authenticity of messages related to self-organisation. However, the \nframeworks within which such mechanisms can be effectively applied in self-organising \nsystems still require considerable further research.\nIn addition, the results of applying self-organisation and emergence approaches over long \ntime periods lead to concerns about the privacy and trustworthiness of such systems and \nthe data they hold. The areas of security, privacy and trust are critical components for the \nnext stages of research and deployment of open distributed systems and as a result of self-\norganising systems. New approaches are required to take into account both social and \ntechnical aspects of this issue to drive the proliferation of self-organising software in a large \nrange of application domains.\n4.2  Interaction Level\n4.2.1  Coordination\nCoordination is de\ufb01  ned in many ways but in its simplest form it refers to ensuring that the \nactions of independent actors (agents) in an environment are coherent in some way. The \nchallenge therefore is to identify mechanisms that allow agents to coordinate their actions \nautomatically without the need for human supervision, a requirement found in a wide \nvariety of real applications. In turn, cooperation refers to coordination with a common \ngoal in mind.\nResearch  to  date  has  identi\ufb01  ed  a  huge  range  of  different  types  of  coordination  and \ncooperation mechanisms, ranging from emergent cooperation (which can arise without \nany explicit communication between agents), coordination protocols (which structure \ninteractions  to  reach  decisions)  and  coordination  media  (or  distributed  data  stores 34\nAgentLink Roadmap\nthat enable asynchronous communication of goals, objectives or other useful data), to \ndistributed planning (which takes into account possible and likely actions of agents in the \ndomain). \n4.2.2  Negotiation\nGoal-driven agents in a multi-agent society typically have con\ufb02  icting goals; in other words, \nnot all agents may be able to satisfy their respective goals simultaneously. This may occur, \nfor example, with regard to contested resources or with multiple demands on an agent\u2019s \ntime and attention. In such circumstances, agents will need to enter into negotiations \nwith each other to resolve con\ufb02  icts. Accordingly, considerable effort has been devoted \nto negotiation protocols, resource-allocation methods, and optimal division procedures. \nThis work has drawn on ideas from computer science and arti\ufb01  cial intelligence on the one \nhand, and the socio-economic sciences on the other. \nFor example, a typical objective in multi-agent resource allocation is to \ufb01  nd an allocation \nthat is optimal with respect to a suitable metric that depends, in one way or another, on \nthe preferences of the individual agents in the system. Many concepts studied in social \nchoice theory can be utilised to assess the quality of resource allocations. Of particular \nimportance are concepts such as envy-freeness and equitability that can be used to model \nfairness considerations (Brams & Taylor, 1996; Endriss & Maudet, 2004). These concepts are \nrelevant to a wide range of applications. A good example is the work on the fair and \nef\ufb01  cient exploitation of Earth Observation Satellite resources carried out at ONERA, the \nFrench National Aeronautics Research Centre (Lema\u00eetre et al., 2003).\nWhile  much  recent  work  on  resource  allocation  has  concentrated  on  centralised \napproaches, in particular combinatorial auctions (Cramton et al., 2006), many applications \nare more naturally modelled as truly distributed or P2P systems where allocations emerge \nas a consequence of a sequence of local negotiation steps (Chevaleyre et al., 2005). \nThe  centralised  approach  has  the  advantage  of  requiring  only  comparatively  simple \ncommunication  protocols.  Furthermore,  recent  advances  in  the  design  of  powerful \nalgorithms for combinatorial auctions have had a strong impact on the research community \n(Fujishima et al., 1999). A new challenge in the \ufb01  eld of multi-agent resource allocation is to \ntransfer these techniques to distributed resource allocation frameworks, which are not only \nimportant in cases where it may be dif\ufb01  cult to \ufb01  nd an agent that could take on the role of \nthe auctioneer (for instance, in view of its computational capabilities or its trustworthiness), \nbut which also provide a test-bed for a wide range of agent-based techniques. To reach \nits full potential, distributed resource allocation requires further fundamental research into \nagent  interaction  protocols,  negotiation  strategies,  formal  (e.g.  complexity-theoretic) \nproperties of resource allocation frameworks, and distributed algorithm design, as well as \na new perspective on what \u201coptimal\u201d means in a distributed setting.35\nTools and Techniques\nOther negotiation techniques are also likely to become increasingly prevalent. For example, \none-to-one negotiation, or bargaining, over multiple parameters or attributes to establish \nservice-level agreements between service providers and service consumers will be key in \nfuture service-oriented computing environments. In addition to approaches drawn from \neconomics and social choice theory in political science, recent efforts in argumentation-\nbased  negotiation  have  drawn  on  ideas  from  the  philosophy  of  argument  and  the \npsychology of persuasion. These efforts potentially provide a means to enable niches of \ndeeper interactions between agents than do the relatively simpler protocols of economic \nauction and negotiation mechanisms. Considerable research and development efforts \nwill be needed to create computational mechanisms and strategies for such interactions, \nand this is likely to be an important focus of agent systems research in the next decade.\n4.2.3  Communication\nAgent communication is the study of how two or more software entities may communicate \nwith each other. The research issues in the domain are long-standing and deep. One \nchallenge is the dif\ufb01  culty of assigning meaning to utterances, since the precise meaning \nof a statement depends upon: the context in which it is uttered; its position in a sequence \nof  previous  utterances;  the  nature  of  the  statement  (for  example,  a  proposition,  a \ncommitment to undertake some action, a request, etc); the objects referred to in the \nstatement (such as a real world object, a mental state, a future world-state, etc); and \nthe  identity  of  the  speaker  and  of  the  intended  hearers.  Another challenge,  perhaps \ninsurmountable, is semantic veri\ufb01  cation: how to verify that an agent means what it says \nwhen it makes an utterance. In an open agent system, one agent is not normally able to \nview the internal code of another agent in order to verify an utterance by the latter; even \nif this were possible, a suf\ufb01  ciently-clever agent could always simulate any desired mental \nstate when inspected by another agent.\nKey to this area is the need to map the relevant theories in the domain, and to develop a \nunifying framework for them. In particular, a formal theory of agent languages and protocols \nis necessary, so as to be able to study language and protocol properties comprehensively, \nand to rigorously compare one language or protocol with another. In addition, progress \ntowards understanding the applicability of different agent communication languages, \ncontent languages and protocols in different application domains is necessary for wider \nadoption of research \ufb01  ndings.\n4.3  Agent Level\nReasoning is a critical faculty of agents, but the extent to which it is needed is determined \nby context. While reasoning in general is important, in open environments there are some \nspeci\ufb01  c concerns relating to heterogeneity of agents, trust and accountability, failure 36\nAgentLink Roadmap\nhandling and recovery, and societal change. Work must be continued on the representation \nof computational concepts for the norms, legislation, authorities, enforcement, and so forth, \nwhich can underpin the development and deployment of dynamic electronic institutions \nor other open multi-agent systems. Similarly, current work on coalition formation for virtual \norganisations is limited, with such organisations largely static. The automation of coalition \nformation may be more effective at \ufb01  nding better coalitions than humans can in complex \nsettings, and is required, for example, for Grid applications.\nOne enabler for this is negotiation, yet while there have already been signi\ufb01  cant advances \nand  real-world  applications,  research  into  negotiation  mechanisms  that  are  more \ncomplex than auctions and game-theoretic mechanisms is still in its infancy. Research into \nargumentation mechanisms, for example, and the strategies appropriate for participants \nunder them, is also needed before argumentation techniques will achieve widespread \ndeployment. In addition, many virtual organisations will be required to make decisions \ncollectively, aggregating in some fashion the individual preferences or decisions of the \nparticipants. Research on the application to agent societies of social choice theory from \npolitical science and sociology is also relatively new, and considerably more work is needed \nhere. Both these topics were considered in the discussion on negotiation above.\nEven though learning technology is clearly important for open and scalable multi-agent \nsystems, it is still in early development. While there has been progress in many areas, such \nas evolutionary approaches and reinforcement learning, these have still not made the \ntransition to real-world applications. Reasons for this can be found in the fundamental \ndif\ufb01  culty of learning, but also in problems of scalability and in user trust in self-adapting \nsoftware. In the longer term, learning techniques are likely to become a central part of \nagent systems, while the shorter term offers application opportunities in areas such as \ninteractive entertainment, which are not safety-critical.\n4.4  Infrastructure and Supporting Technologies\nAny infrastructure deployed to support the execution of agent applications, such as those \nfound in ambient and ubiquitous computing must, by de\ufb01  nition, be long-lived and robust. \nIn the context of self-organising systems, this is further complicated, and new approaches \nsupporting the evolution of the infrastructures, and facilitating their upgrade and update \nat  runtime,  will  be  required.  Given  the  potentially  vast  collection  of  devices,  sensors, \nand  personalised  applications  for  which  agent  systems  and  self-organisation  may  be \napplicable, this update problem is signi\ufb01  cantly more complex than so far encountered. \nMore generally, middleware, or platforms for agent interoperability, as well as standards, \nwill be crucial for the medium-term development of agent systems. 37\nTools and Techniques\n4.4.1  Interoperability\nAt present, the majority of agent applications exist in academic and commercial \nlaboratories,  but  are  not  widely  available  in  the  real  world.  The  move  out  of  the \nlaboratory is likely to happen over the next ten years, but a much higher degree of \nautomation than is currently available in dealing with knowledge management is \nneeded for information agents. In particular, this demands new web standards that \nenable structural and semantic description of information; and services that make \nuse of these semantic representations for information access at a higher level. The \ncreation of common ontologies, thesauri or knowledge bases plays a central role here, \nand merits further work on the formal descriptions of information and, potentially, a \nreference architecture to support the higher level services mentioned above. \nDistributed agent systems that adapt to their environment must both adapt individual \nagent components and coordinate adaptation across system layers (i.e. application, \npresentation  and  middleware)  and  platforms.  In  other  words  interoperability  must \nbe maintained across possibly heterogeneous agent components during and after \nself-organisation actions and outcomes. Furthermore, agent components are likely \nto come from different vendors and hence the developer may need to integrate \ndifferent self-organisation mechanisms to meet an application\u2019s requirements. The \nproblem  is  further  complicated  by  the  diversity  of  self-organisation  approaches \napplicable at different system layers. In many cases, even solutions within the same \nlayer are often not compatible. Consequently, developers need tools and methods \nto integrate the operation of agent components across the layers of a single system, \namong multiple computing systems, as well as between different self-organisation \nframeworks.\n4.4.2  Agent Oriented Software Engineering\nDespite a number of languages, frameworks, development environments, and platforms \nthat  have  appeared  in  the  literature  (Luck  et  al.,  2004b),  implementing  multi-agent \nsystems is still a complex task. In part, to manage multi-agent systems complexity, the \nresearch community  has  produced  a  number  of  methodologies that  aim  to  structure \nagent development. However, even if practitioners follow such methodologies during the \ndesign phase, there are dif\ufb01  culties in the implementation phase, partly due to the lack \nof maturity in both methodologies and programming tools. There are also dif\ufb01  culties in \nimplementation due to: a lack of specialised debugging tools; skills needed to move from \nanalysis and design to code; the problems associated with awareness of the speci\ufb01  cs of \ndifferent agent platforms; and in understanding the nature of what is a new and distinct \napproach to systems development.38\nAgentLink Roadmap\nIn relation to open and dynamic systems, new methodologies for systematically considering \nself-organisation are required. These methodologies should be able to provide support \nfor all phases of the agent-based software engineering life-cycle, allowing the developer \nto start from requirements analysis, identify the aspects of the problem that should be \naddressed  using  self-organisation  and  design  and  implement  the  self-organisation \nmechanisms in the behaviour of the agent components. Such methodologies should also \nencompass techniques for monitoring and controlling the self-organising application or \nsystem once deployed. \nIn  general,  integrated  development  environment  (IDE)  support  for  developing  agent \nsystems is rather weak, and existing agent tools do not offer the same level of usability as \nstate-of-the-art object-oriented IDEs. One main reason for this is the previous unavoidable \ntight coupling of agent IDEs and agent platforms, which results from the variety of agent \nmodels, platforms and programming languages. This is now changing, however, with an \nincreased trend towards modelling rather than programming.\nWith  existing  tools,  multi-agent  systems  often  generate  a  huge  amount  of  information \nrelated to the internal state of agents, messages sent and actions taken, but there are not \nyet adequate methods for managing this information in the context of the development \nprocess.  This  impacts  both  dealing  with  the  information  generated  in  the  system  and \nobtaining this information without altering the design of the agents within it. Platforms like \nJADE provide general introspection facilities for the state of agents and for messages, \nbut  they  enforce  a  concrete  agent  architecture  that  may  not  be  appropriate  for  all \napplications. Thus, tools for inspecting any agent architecture, analogous to the remote \ndebugging tools in current object-oriented IDEs, are needed, and some are now starting to \nappear (Bot\u00eda et al, 2004). Extending this to address other issues related to debugging for \norganisational features, and for considering issues arising from emergence in self-organising \nsystems will also be important in the longer term. The challenge is relevant now, but will \ngrow in importance as the complexity of installed systems increases further.\nThe inherent complexity of agent applications also demands a new generation of CASE \ntools to assist application designers in harnessing the large amount of information involved. \nThis  requires  providing  reasoning  at  appropriate  levels  of  abstraction,  automating  the \ndesign and implementation process as much as possible, and allowing for the calibration \nof deployed multi-agent systems by simulation and run-time veri\ufb01  cation and control.\nMore generally, there is a need to integrate existing tools into IDEs rather than starting \nfrom  scratch.  At  present  there  are  many  research  tools,  but  little  that  integrates  with \ngeneric development environments, such as Eclipse; such advances would boost agent \ndevelopment and reduce implementation costs. Indeed, developing multi-agent systems 39\nTools and Techniques\ncurrently  involves  higher  costs  than  using  conventional  paradigms  due  to  the  lack  of \nsupporting methods and tools. \nThe next generation of computing system is likely to demand large numbers of interacting \ncomponents, be they services, agents or otherwise. Current tools work well with limited \nnumbers of agents, but are generally not yet suitable for the development of large-scale \n(and ef\ufb01  cient) agent systems, nor do they offer development, management or monitoring \nfacilities able to deal with large amounts of information or tune the behaviour of the system \nin such cases.\nMetrics for agent-oriented software are also needed: engineering always implies some \nactivity of measurement, and traditional software engineering already uses widely applied \nmeasuring methods to quantify aspects of software such as complexity, robustness and \nmean time between failures. However, the dynamic nature of agent systems, and the \ngenerally  non-deterministic  behaviour  of  self-organising  agent  applications  deem \ntraditional  techniques  for  measurement  and  evaluation  inappropriate.  Consequently, \nnew  measures  and  techniques  for  both  quantitatively  and  qualitatively  assessing  and \nclassifying multi-agent systems applications (be they self-organising or not) are needed.\n4.4.3  Agent Programming Languages\nMost  research  in  agent-oriented  programming  languages  is  based  on  declarative \napproaches, mostly logic based. Imperative languages are in essence inappropriate for \nexpressing the high-level abstractions associated with agent systems design; however, \nagent-oriented  programming  languages  should  (and  indeed  tend  to)  allow  for  easy \nintegration with (legacy) code written in imperative languages. From the technological \nperspective, the design and development of agent-based languages is also important. \nCurrently, real agent-oriented languages (such as BDI-style ones) are limited, and used \nlargely for research purposes; apart from some niche applications, they remain unused in \npractice. However, recent years have seen a signi\ufb01  cant increase in the maturity of such \nlanguages, and major improvements in the development platforms and tools that support \nthem (Bordini et al., 2005).\nCurrent research emphasises the role of multi-agent systems development environments \nto assist in the development of complex multi-agent systems, new programming principles \nto  model  and  realise  agent  features,  and  formal  semantics  for  agent  programming \nlanguages to implement speci\ufb01  c agent behaviours.\nA  programming  language  for  multi-agent  systems  should  respect  the  principle  of \nseparation of concerns and provide dedicated programming constructs for implementing 40\nAgentLink Roadmap\nindividual agents, their organisation, their coordination, and their environment. However, \ndue to the lack of dedicated agent programming languages and development tools (as \nwell as more fundamental concerns relating to the lack of clear semantics for agents, \ncoordination, etc), the construction of multi-agent systems is still a time-consuming and \ndemanding activity. \nOne key challenge in agent-oriented programming is to de\ufb01  ne and implement some truly \nagent-oriented languages that integrate concepts from both declarative and object-\noriented programming, to allow the de\ufb01  nition of agents in a declarative way, yet supported \nby serious monitoring and debugging facilities. These languages should be highly ef\ufb01  cient, \nand provide interfaces to existing mainstream languages for easy integration with code and \nlegacy packages. While existing agent languages already address some of these issues, \nfurther progress is expected in the short terrm, but thorough practical experimentation in \nreal-world settings (particularly large-scale systems) will be required before such languages \ncan be adopted by industry, in the medium to long term.\nIn  addition  to  languages  for  single  agents,  we  also  need  languages  for  high-level \nprogramming of multi-agent systems. In particular, the need for expressive, easy-to-use, \nand  ef\ufb01  cient  languages  for  coordinating  and  orchestrating  intelligent  heterogeneous \ncomponents is  already  pressing  and,  although much  research  is  already  being  done, \nthe development of an effective programming language for coordinating huge, open, \nscalable and dynamic multi-agent systems composed of heterogeneous components is \na longer term goal.\n4.4.4  Formal Methods \nWhile  the  notion  of  an  agent  acting  autonomously  in  the  world  is  intuitively  simple, \nformal analysis of systems containing multiple agents is inherently complex. In particular, \nto understand the properties of systems containing multiple actors, powerful modelling \nand reasoning techniques are needed to capture possible evolutions of the system. Such \ntechniques are required if agents and agent systems are to be modelled and analysed \ncomputationally. \n \nResearch  in  the  area  of  formal  models  for  agent  systems  attempts  to  represent  and \nunderstand properties of the systems through the use of logical formalisms describing both \nthe mental states of individual agents and the possible interactions in the system. The logics \nused are often logics of belief or other modalities, along with temporal modalities, and \nsuch logics require ef\ufb01  cient theorem-proving or model-checking algorithms when applied \nto problems of signi\ufb01  cant scale. Recent efforts have used logical formalisms to represent \nsocial properties, such as coalitions of agents, preferences and game-type properties. 41\nTools and Techniques\nIt is clear that formal techniques such as model checking are needed to test, debug and \nverify properties of implemented multi-agent systems. Despite progress, there is still a real \nneed to address the issues that arise from differences in agent systems, in relation to the \nparadigm, the programming languages used, and especially the design of self-organising \nand emergent behaviour. For the latter, a programming paradigm that supports automated \nchecking of both functional and non-functional system properties may be needed. This \nwould lead to the need to certify agent components for correctness with respect to their \nspeci\ufb01  cations. Such a certi\ufb01  cation could be obtained either by selecting components \nthat have already been veri\ufb01  ed and validated of\ufb02  ine using traditional techniques such \nas inspection, testing and model checking or by generating code automatically from \nspeci\ufb01  cations. Furthermore, techniques are needed to ensure that the system still executes \nin an acceptable, or safe, manner during the adaptation process, for example using \ntechniques such as dependency analysis or high level contracts and invariants to monitor \nsystem correctness before, during and after adaptation.\n4.4.5  Simulation \nAs  mentioned  earlier,  agent-based  computing  provides  a  means  to  simulate  both \nnatural and arti\ufb01  cial systems, including agent-based computational systems themselves. \nSuch  simulation  modelling  is  increasingly  providing  guidance  to  decision-makers  in \nareas of medicine, social policy and industrial engineering, and assisting in the design, \nimplementation and management of arti\ufb01  cial and computational systems. However, for \nthe full potential of agent-based (or individual-based) simulation models to be realised, a \nnumber of research and development challenges need to be met. First among these is \nthe development of a rigorous theory of agent-based simulation. When should one stop \nre\ufb01  ning a simulation model, for example? How many iterations of a randomised simulation \nmodel or scenarios are required in order to have con\ufb01  dence in the results? How much \ndetail is required to be simulated in a model? How much trust should be placed in the \nresults? How can we avoid over-interpretation of results with abstract or vague terms? The \nanswers to these questions are likely to depend on the application domain, so a single, \nuni\ufb01  ed theory may be impossible to achieve. But efforts towards this goal are needed, \nnot least because of the increasing reliance placed on simulation models in important \npublic policy decisions, such as those arising from the Kyoto Protocol to the UN Framework \nConvention on Climate Change.\nAnother major challenge relates to the development of agent-based simulation models \ninvolving cognitive and rational agents. In economic systems, for example, it has long \nbeen known that the expectations of individual actors may in\ufb02  uence their behaviour, \nand thus the global properties of the system. How may these anticipatory and re\ufb02  ective \naspects of real-world societies be modelled by agent based simulation models? The rapid 42\nAgentLink Roadmap\ngrowth of online resource allocation systems, such as Grid systems, makes this an important \nissue. If a computational Grid comprises intelligent computational users, many of whom \nbase their decisions on their own economic models of the Grid operation itself, then the \ntask of management is complicated immensely: statements and actions by the system \nmanager may impact the beliefs and intentions of the participants, and thus impact system \noperations and performance. The challenge of managing user expectations in this way is \nwell-known to governors of central banks, such as the European Central Bank, as they try \nto manage national monetary policy. The theory and practice of agent simulation models \nare not suf\ufb01  ciently mature to provide guidance to managers in this task.\n4.4.6  User Interaction Design \nIn  future  complex  system  environments,  human  involvement  is  likely  to  become  more \nimportant, yet this requires the exploration and understanding of several new possibilities, \nincluding: autonomy and improvisation (to deal with unforeseen events, such as those \ncaused by the behaviour of human users); a standardised agent communication language \nwith a powerful semantics to drive some of agent behaviour and facilitate integration of \nhuman users; social and organisational models for multi-agent systems, in which programs \nand humans can naturally interact (hybrid systems). In addition, as software becomes self-\norganising to \ufb01  t in a variety of contexts, a new set of issues concerning the interaction \nwith users is created. A key question here is how people can interact with continuously \nchanging software. Additional questions concern whether it would be valuable to try to \ndesign implicit interaction with applications operating on indirect sensor-based input and \nin that case how could users migrate from traditional explicit to future implicit interaction. In \naddition, questions of decision-making authority, responsibility, delegation and control arise \nwith systems of agents acting on behalf of, or in collaboration with, human decision-makers \nin mixed initiative systems. If agents or multi-agent systems are themselves responsible for \ndecisions, these issues become more problematic (see Ku\ufb02  ik, 1999).43\nTechnology Adoption\n5 Adoption of Agent Technologies\n5.1  Diffusion of Innovations \nIn order to understand the current commercial position of agent technologies it is useful to \nknow something about the diffusion of new technologies and innovations. This is a subject \nlong-studied by marketing theorists (Rogers, 1962; Midgley, 1977) drawing on mathematical \nmodels from epidemiology and hydrodynamics. We begin by considering some relevant \nconcepts.\n5.2  Product Life Cycles \nMost marketers believe that all products and services are subject to life-cycles: sales of \na new product or service begin with a small number of customers, grow to a peak at \nsome time, and then decline again, perhaps to zero, as shown in Figure 5.1 (Levitt,1965). \nGrowth occurs because increasing numbers of customers learn about the product and \nperceive that it may satisfy their needs (which may be diverse). Decline eventually occurs \nbecause  the  market  reaches  saturation,  as  potential  customers  have  either  decided \nto adopt the product or have found other means to satisfy their needs, or because the \nneeds  of  potential  customers  change  with  time.  Most  high-technology  products  are \nFigure 5.1: The technology adoption life-cycle\nInnovators Laggards Early\nAdopters\nEarly\nMajority\nLate\nMajority\nTime\nP\nr\no\np\no\nr\nt\ni\no\nn\n \no\nf\n \na\nd\no\np\nt\ne\nr\ns44\nAgentLink Roadmap\nadopted initially only by people or companies with a keen interest in that type of new \ntechnology and the disposable income to indulge their interest. Thus, early adopters are \noften technologically sophisticated, well-informed, and wealthy, and not averse to any \nrisks potentially associated with use of a new product.\nWhy does a product life-cycle exist? In other words, why is it that all the companies or people \nwho will eventually adopt the technology, product or process do not do so immediately? \nThere are several reasons for this, as follows.\n\u25a0  Potential adopters must learn about the new technology before they can consider \nadopting it. Thus, there needs to be an information diffusion process ahead of the \ntechnology diffusion process.\n\u25a0  In addition, for non-digital products and services, the supplier needs to physically dis-\ntribute the product or service. Establishing and \ufb01  lling sales channels may take consid-\nerable time and effort, and may need to be paid for from sales of the product, thus \ndelaying uptake of the product or service.\n\u25a0  Once they learn about a new technology, not all eventual adopters will have the \nsame extent of need for the product. The early adopters are likely to be those with \nthe most pressing needs, which are not currently satis\ufb01  ed by competing or alternative \ntechnologies. Early adopters of supercomputers, for instance, were organisations with \nmassively large-scale processing requirements, such as research physicists, meteorolo-\ngists, and national census bureaux; later users included companies with smaller, but \nstill large-scale, processing requirements, such as econometric forecasting \ufb01  rms and \nautomotive engineering design studios. \n\u25a0  Of those potential adopters with a need, not all will have the \ufb01  nancial resources nec-\nessary to adopt the new technology. Most new technologies, products and processes \nare expensive (relative to alternatives) when \ufb01  rst launched. But prices typically fall as \nthe base of installed customers grows, and as new suppliers enter the marketplace, \nattracted by the growing customer base. Thus, later adopters typically pay less than \ndo early adopters for any new technology. Likewise, the total costs of adoption also \ntypically fall, as complementary tools and products are developed in tandem with a \nnew technology. If a company\u2019s needs are not pressing, it may bene\ufb01  t by waiting for \nthe price and other adoption costs to fall before adopting.\n\u25a0  Similarly, not all potential adopters share the same attitudes to technological risk. The \nrisks associated with adopting a new technology also typically fall as bugs are elimi-\nnated, user-friendly features added, and complementary tools and products devel-\noped. Each subsequent release of an operating system, such as Windows or Linux, \nfor example, has entailed lower risks to users of unexpected losses of data, obscure \nhardware incompatibilities, exception conditions, etc.45\nTechnology Adoption\n\u25a0  Finally, for many advanced technologies and products, the value to any one adopter \ndepends on how many other adopters there are. These so-called network goods re-\nquire a critical mass of users to be in place for the bene\ufb01  ts of the technology to be fully \nrealisable to any one user. For example, a fax machine is not very useful if only one \ncompany purchases one; it will only become useful to that company as and when \nother companies in its business network also have them.\nThese reasons for the existence of product life-cycles mean that companies or people who \nadopt a new technology or purchase a new product later in its life-cycle may do so for \nvery different reasons than do the early adopters; later adopters may even have different \nneeds being satis\ufb01  ed by the product or technology. For example, in most countries the \ufb01  rst \nadopters of mobile communications services were mobile business and tradespeople, and \nwealthy individuals. Only as prices fell did residential consumers, non-mobile of\ufb01  ce workers, \nand teenagers become users, and their needs are very different from those earlier into \nthe market. The changing pro\ufb01  le of adopters creates particular challenges for marketers \n(Moore, 1991). This has led to the notion of a \u201cchasm\u201d between one adopter segment and \nthe next as shown in Figure 5.2, in which the gaps between segments indicate that users in \nadjacent segments are distinct.\nHow quickly do new products and technologies reach saturation? If one considers an \ninnovation such as written communication, which began several thousand years ago, \nInnovators Laggards Early\nAdopters\nEarly\nMajority\nLate\nMajority\nTime\nP\nr\no\np\no\nr\nt\ni\no\nn\n \no\nf\n \na\nd\no\np\nt\ne\nr\ns\nFigure 5.2: The revised technology adoption life-cycle46\nAgentLink Roadmap\ndiffusion has been very slow. It is unfortunate but true that perhaps as many as half the \nworld\u2019s population are still unable to read and write. In contrast, cellular mobile telephones \nare now used by almost 1.7 billion people, a position reached in just over two decades \nfrom the launch of the \ufb01  rst public cellular networks (IDC, 2005).\n5.3  Standards and Adoption\nThe fact that many technology products and processes are network goods means that the \npresence or otherwise of technology standards may greatly impact adoption. If a standard \nexists in a particular domain, a potential adopter knows that choosing it will enable access \nto a network of other users. The greater the extent of adoption of the standard, the larger \nthis network of users will be. Thus, one factor inhibiting adoption of Linux as an operating \nsystem (OS) for PCs was the fact that, until recently, most users had adopted the de facto \nstandard of Microsoft Windows; while the user of a stand-alone machine could use any \noperating system they desire, installing an uncommon OS would mean not having access \nto the professional services, software tools and applications which support or run on the \noperating system. If adopting a technology is viewed as akin to choosing a move in a multi-\nparty strategic game, where the potential adopter wishes to select the technology option \nthat will be also chosen by the majority of their peers, then the existence of a standard may \nweight the payoffs in favour of a particular option and against others (Weitzel, 2004). \nWhere do standards come from? Standards may be imposed upon a user community \nby national Governments or international organisations, as with the adoption of GSM by \nall  European  and  many  other  nations,  for  second-generation  mobile  communications \nnetworks;  the  communications  regulatory  agencies  of  the  United  States,  in  contrast, \ndecided not to impose a particular technology standard in this domain. Or, standards may \nbe strongly recommended to a user community by a voluntary standards organisation, \nas in the case of many Internet standards; two machines connected to the Internet may \nuse any interconnection protocols they themselves agree on, for example, not necessarily \nthe standard protocols, such as TCP and UDP, de\ufb01  ned by the Internet Engineering Task \nForce. Finally, standards may emerge from multiple independent choices of one particular \ntechnology  over  others  made  by  many  individual  adopters;  the  common  QWERTY \ntypewriter layout is one such bottom-up standard (Gomes, 1998). \nHowever, if standards are not imposed by some government or regulatory agency, then \nscope  exists  for  multiple  voluntary  organisations  to  recommend  competing  standards \nor for competing standards to emerge from user decisions. To some extent, this may be \noccurring in the agent technologies domain, with several organisations having developed \nor aiming to develop standards related to the interoperation and interaction of intelligent \nsoftware entities: the Foundation for Intelligent Physical Agents (FIPA, which has just been 47\nTechnology Adoption\naccepted by the IEEE as its eleventh standards committee), the Object Management \nGroup, the Global Grid Forum, and the World Wide Web Consortium. The view has even \nbeen expressed that having multiple competing standards may be in the interests of major \ntechnology development companies, none of which wishes to see a standards body \nadopt a standard favourable to a competitor\u2019s products. In this view, large development \ncompanies may actually seek to divide and conquer the various competing standards \nbodies by, for example, participating intensely in one standards organisation at one time \nand another competing organisation at another time.\nFaced with competing recommendations for standards, what will a potential adopter \ndo? One result may be decision paralysis, with a user or company deciding to postpone \nadoption of a new technology until the standards position is clearer. Thus, in this case, \nmultiple competing standards may inhibit uptake of a new technology and hence inhibit \nmarket growth. On the other hand, the proponents of competing standards have an \ninterest in promoting their particular solution, so the presence of multiple standards may \nlead to faster and more effective dissemination of information about the new technology \nthan would be the case if there was only one standard. In this view, therefore, competing \nstandards may actually encourage uptake of a new technology and hence of market \ngrowth. Which of these countervailing pressures actually dominates in any one situation \ndepends on the other factors in\ufb02  uencing the decision processes of a potential adopter, \nfor example the extent to which the proposed technology satis\ufb01  es an unmet need, the \ncriticality of the need, and the extent of network effects.\nRelated to the issue of standards and network effects in adoption decisions by potential \nusers  of  new  technologies  is  the  issue  of  business  ecologies.  Most  companies  and \norganisations are enmeshed in a network of business relationships, with customers, suppliers, \ncompetitors, and other stakeholders. If a downstream customer or an upstream supplier \ninsists on adoption of a particular technology or standard as a condition of business, then \na company may adopt it much sooner than they would otherwise. Thus, for example, the \nUS company GE has insisted that most of its suppliers, including even law \ufb01  rms providing \nlegal advice, bid for its business through online auctions. Of course, such pressure along \na supply chain or across a business network may also greatly reduce the risks and costs \nassociated with a new technology; thus, adoption decisions under such circumstances \nare not necessarily irrational. Recent research has considered the impact of networks of \nin\ufb02  uence in business ecologies on software adoption decisions (e.g., von Westarp 2003).\n5.4  Agent Technologies \nWith this marketing background , it is useful to consider the position of agent-based computer \ntechnologies. Adoption of agent technologies has not yet entered the mainstream of 48\nAgentLink Roadmap\nIn attempting to understand the likely future development of agent-\nbased computing, and its pathway to adoption, one might usefully \nconsider  the  history  of  object-oriented  technologies.  The  origins  of  object \norientation lie in early programming languages and AI technologies, \nstarting with the Simula language in 1962 (Dahl 2002, Dahl & Nygaard \n1965), predating the coining of the term \u201cobject-orientation\u201d in 1970 \nby Alan Kay. Although several further developments ensued, including \nSmalltalk at Xerox PARC in 1973 and the introduction of frames by \nMarvin Minsky in 1975, it wasn\u2019t until 1983 that C++ was formally \nestablished.  The \ufb01  rst textbook was released in 1985, the OOPSLA and \nOODBS conferences established in 1986, and the Journal of Object \nOriented Programming only started in 1988. \nThese events were followed by more rapid developments of a practical \nnature, with the Object Management Group being formed in 1989, \nthe development of Java in 1991 (though not publicly released until \n1995), and the establishment of standards that include CORBA (\ufb01  rst \nspeci\ufb01  cation in 1992, CORBA 2.0 in 1994), UML in 1994, and ANSI \nC++ in 1998. This is an extended period over which the technologies \nand techniques involved came to maturity and to wide scale adoption. \nIndeed, the time taken from the \ufb01  rst object-oriented language until \nthe ANSI C++ standard was established thus amounts to 32 years. \nAgent  and  object  technologies  are  both  essentially  disruptive \ntechnologies that provide (among other bene\ufb01  ts) more effective and \n\ufb02  exible techniques for software and its development. To understand \nAgents versus Objects49\nTechnology Adoption\nhow the future of agent-based computing may progress, we need to \nlook to the differences between these two technologies. \nFirst,  object  technology  began  in  an  era  in  which  computing  as  a  discipline \nand as an industry was relatively immature, and limited in scope. \nAlthough potential for applications certainly existed, the reality on the \nground was not as pervasive and rooted in techniques, technologies, \nstandards  and  paradigms  as  is  the  case  now.  Consequently,  the \nchanges required for the adoption of objects was far less substantial \nand challenging than it is now for agent technologies. \nSecond, while there are still many problems to be tackled in computing, \nthe degree of improvement, in terms of productivity or ef\ufb01  ciency, to \nbe  realised  from  speci\ufb01  c  advances  decreases  as  the  general  level \nof maturity in computing increases. Thus, while there was no step \nchange arising through object orientation, the gradual improvement \nin the state of software is likely to be even less marked with agent \ntechnologies. \nThird,  the  current  computing  environment  is  much  more  heterogeneous, \ndistributed and diverse than at any point previously, and it continues \nto change further in these directions. The consequence of this is a \nplethora of standards, techniques, methodologies and, importantly, \nmultiple  vested  interests  and  corporate  initiatives  that  must  be \nintegrated, overcome or otherwise addressed for broad acceptance of \nnew paradigms. Investment in new technologies at this point of the IT \nadoption cycle presents a much more challenging problem than ever \nbefore.  For all these reasons, it is likely that no technology in the near \nfuture will have anything like the impact of object orientation.50\nAgentLink Roadmap\ncommercial organisations, unlike, for example, object-oriented technologies. Indeed, the \nmajority of commercial organisations adopting agent technologies might be classi\ufb01  ed as \nearly adopters, since only a relatively small number of deployed commercial and industrial \napplications of agent technology are visible, and because considerable potential exists \nfor other organisations to apply the technology.\nWhat is the range of applications? To date, deployed applications of agent technologies \nhave been concentrated in a small number of industrial sectors, and for particular, focused, \napplications. These have included: automated trading in online marketplaces, such as \nfor \ufb01  nancial products and commodities; simulation and training applications in defence \ndomains; network management in utilities networks; user interface and local interaction \nmanagement  in  telecommunication  networks;  schedule  planning  and  optimisation  in \nlogistics and supply-chain management; control system management in industrial plants, \nsuch as steel works; and, simulation modelling to guide decision-makers in public policy \ndomains, such as transport and medicine. \nWhy are agent technologies still only in the early-adopter phase of diffusion? There are a \nnumber of reasons for this. Firstly, research in the area of agent technology is also still only \nin its infancy. Here, a reasonable comparison is with object-oriented (OO) programming   \napproaches, where the initial research commenced in 1962 (see box), more than 20 years \nbefore the advent of C++, and some 32 years before the public release of the \ufb01  rst version \nof Java, both key points for the widespread commercial adoption of OO technologies \n(and 39 years before the two original researchers, Ole-Johan Dahl and Kristen Nygaard, \nreceived a Turing Award for their work). As a consequence of this, knowledge of agent \ntechnologies is still not widespread among commercial software developers, although of \ncourse projects such as AgentLink have tried to overcome this.\nSecondly, as a result of the immaturity of research and development in agent technologies \n(discussed  earlier),  the  \ufb01  eld  lacks  proven  methodologies,  tools,  and  complementary \nproducts and services, the availability of which would act to reduce the costs and risks \nassociated with adoption.\nThirdly, the applications to which agent technologies are most suited are those involving \ninteractions between autonomous intelligent entities. While some applications of this sort \nmay  be  implemented  as  closed  systems  inside  a  single  company  or  organisation  (for \nexample, agent-based simulation for delivery schedule decision-making) many potential \napplications of agent technologies require the participation of entities from more than one \ngroup or organisation. Automated purchase decisions along a supply-chain, for example, \nrequire the participation of the companies active along that chain, so that implementing \na successful agent-based application requires agreement and coordination from multiple 51\nTechnology Adoption\ncompanies. In other words, the application domains for which agent technologies are best \nsuited typically exhibit strong network good effects, a factor that complicates technology \nadoption decisions by the companies or organisations involved.\nIt is for this reason that the agent community has expended so much effort on developing \nstandards for agent communication and interaction, such as those undertaken by FIPA, so \nthat agent systems may interoperate without the need for prior coordinated technology \nadoption decisions. However, as noted above, the agent technology standards landscape \nis  currently  one  in  which  multiple  organisations  have  developed  or  are  developing \nstandards for the interoperation and interaction of intelligent software entities. In these \ncircumstances,  adoption  of  agent  technologies  is  not  necessarily  promoted  by  the \npresence of competing, and subtly different, standards.\n5.5  Modelling Diffusion of Agent Technologies \nAgentLink  III  developed  a  simple  computer  model  to  study  the  diffusion  of  agent \ntechnologies  (McKean  et  al.,  2005).  Our  model  uses  assumptions  about  adoption \ndecision  processes  and  the  relationships  between  different  companies,  and  has  not \nbeen calibrated against any real market data. It is intended only to provide a means for \nexploration of relationships between relevant variables and to give indicative insight into \nthese relationships. We fully recognise that the results of a generic model such as this will be \nhighly dependent on the structure and assumptions used to create the model. Moreover, \nthe features of speci\ufb01  c markets, such as those for agent technologies, may result in very \ndifferent outcomes from those described here. Thus the results described here should not \nbe considered as guidance for speci\ufb01  c marketing strategies or industrial policies in the \ndomain of agent-based computing. \n5.5.1  Model Design\nOrganisations potentially adopting agent technologies were represented in the model \nas individual nodes in a graph. Directed connections (edges) between nodes were used \nto represent the in\ufb02  uence of one organisation over another in a decision to adopt or not \nadopt agent technologies. Thus, for example, a large company may be able to in\ufb02  uence \ntechnology decisions of its suppliers. Because different industries have different degrees of \nconcentration and different networks of in\ufb02  uence, our model incorporated several different \ngraphical structures \u2014 network topologies \u2014 which we believe to be representative of the \ndiversity of real-world industrial and commercial networks. These different topologies are \npresented in detail in (McKean et al., 2005).\nNodes  were  then  modelled  as  independent  and  autonomous  decision-makers,  each \nmaking decisions to move (or not) through a technology adoption life-cycle. The life-cycle 52\nAgentLink Roadmap\nbegan with non-adoption, and progressed through consideration, trial, partial adoption \nand full adoption. At each stage in the life-cycle, a node may decide to proceed to the \nnext stage, remain at the current stage, or to return to the previous stage. The mechanism \nused by each node at each stage to make these decisions depended on a number of \nrelevant factors, which were drawn from a study of the marketing literature (Lilien et al., \n1992; Mahajan et al., 1993; Urban and Hauser 1993) and the economics literature (Weitzel \n2004, von Westarp 2003). The factors included elements such as: organisational needs for \nthe technology; the costs of adoption; the presence of complementary software tools; \nand the presence of a technology standard or multiple standards. \nFor each node and for each decision, these factors were then combined through a factor-\nweighting mechanism, the outcome of which is a decision: to progress forward to the next \nstate; to remain in the current state; or to revert to the earlier state, in the technology adoption \nlife-cycle. The weighting mechanism differs across the states of the technology adoption \nlife-cycle to better represent the real-world decision processes. The weights and weighting \nmechanism used in the model were developed on what are believed to be reasonable \nassumptions regarding real-world decision processes, informed by the marketing literature. \nIt is important to recognise that the factor-weights and the decision mechanism have not \nbeen calibrated directly against any real-world agent technology adoption decisions in \ncompanies or organisations. The AgentLink III model allows the weights to be set by the user, \nso it may be possible to calibrate the model in this way in future work. Further information \nabout the design and implementation of the model can be found in (McKean et al., 2005). \n5.5.2  Simulation Results\nOne  thousand  simulation  runs  with  random  starting  values  were  undertaken  for  each \nnetwork topology, assuming different numbers of technology standards (zero, one and two). \nIn each simulation run, the diffusion model ran until all nodes had adopted the technology, \nand the number of generations required to reach this end-state was then recorded. These \nmeasurements were then averaged across the 1000 simulation runs, with results shown in \nTable 5.1.\nAs might be expected, the network topology can have a major effect on the numbers of \ngenerations needed to reach full adoption. Likewise, for any given topology, the presence \nof a single standard may reduce the time steps needed for full adoption by more than half. \nInterestingly, having two competing standards inhibits full adoption, but not as greatly as \nhaving no standard at all. Thus, the model provides indicative support for the positive impact \nof standards on technology adoption decisions. It is also noteworthy that this impact is seen \nregardless of the network topology, in other words, regardless of the industry structure, at \nleast for those topologies included in the simulations. \nThe British news \nmagazine, The \nEconomist, \nhas recently \nargued that the \nIT industry is \ncurrently in its \nthird 15-year \nwave of progress, \nin which devices \nof every kind \nare connecting \nto the Internet. \nUnlike the \ufb01  rst \nwave of the \n1970s and 1980s, \ndominated by \nlarge proprietary \nmainframes, and \nthe second wave \nof PCs hooked \nup to servers, \nwith its de facto \nstandards, this \nthird wave is \nseeing de jure \n(industry agreed) \nstandards taking \nover. [Make it \nSimple, The \nEconomist, \nLondon, 28 \nOctober 2004].53\nTechnology Adoption\n5.6  Activity in Europe \nThe European position on research and development in agent systems is healthy. There \nhave been numerous active research groups in universities and research laboratories across \nEurope since the early days of the emergence of the \ufb01  eld of agent-based computing as a \ndistinct discipline, and the quality of work done is competitive at a global level. One reason \nfor this is that since 1998, the European Commission has provided funding (albeit limited) to \nsupport the community through coordination projects, providing a focus and coherence to \nthe community that might not otherwise have been possible. The value of these AgentLink \nprojects has not just been in academia; AgentLink counts around 40% of its organisational \nmembers from industry or research institutes. Interestingly, research activity was generally \nsustained despite the bursting of the Internet bubble, and it can be argued that the efforts of \nthe Commission in supporting the agent community helped to minimise the consequences \nof this crash.\nYet, there have been consequences. According to one analysis (The Netherlands Ministry of \nEconomic Affairs, 2004), in the period before the bursting of the bubble, the ICT sector was \ncharacterised by hypercompetition, in which industries tried to outpace their competitors with \nspeed of innovation. Business innovations were implemented in a \u201cquick and dirty\u201d fashion so \nNetwork Topology No Standards Single Standard Two Standards\nA: Disaggregated industry \n(non-connected nodes)\n66.9 26.5 48.4\nB: Disaggregated industry \nwith peer relationships \n66.7 26.8 48.7\nC: Industry with shallow \nsupply chains\n25.0 17.6 22.1\nD:  Industry with deep,  \nindependent supply chains \n76.5 26.6 49.1\nE: Industry with deep, \noverlapping supply chains \n67.6 19.8 48.7\nTable 5.1: Average numbers of generations to 100% adoption (by topology and numbers of standards).54\nAgentLink Roadmap\nas to minimise time to market and achieve rapid, exponential growth, at the cost of poorly \nconceived business models, and a high cash burn rate. The collapse led to consolidation in ICT \nsectors, and the emphasis has since shifted to the e-enablement of core business processes, \nlike fully integrated supply chains and supply networks, with a focus on visible and measurable \nimpact. This shift can now also be seen in the positioning of agent technology providers, who \nnow focus more on these latter areas, and less on fundamental process change.\nIn the USA, ICT is stimulated by the cultivation of a high-tech entrepreneurial culture, providing \nready  customers  for  new  technologies  and  close  cooperation  between  industry  and \nuniversities. In addition, public R&D is oriented towards areas considered important for future \napplications and identi\ufb01  ed as national priorities. Among the USA\u2019s 16 \u201cGrand Challenges\u201d \nare the following relevant to agent technologies: knowledge environments for science and \nengineering; collaborative intelligence: integrating humans with intelligent technologies; and \nmanaging knowledge intensive organisations in dynamic environments (Interagency Working \nGroup, 2003).\nBy contrast, European innovation culture and policy are more sluggish, despite the efforts of \nthe European Commission. The grand challenges may be re\ufb02  ected in the strategic objectives \nof FP6, and in other relevant policy documents, but the ready customers for new technologies \nTankers International, which operates one of the largest oil tanker pools in \nthe world, has applied agent technology to dynamically schedule the most \npro\ufb01  table deployment of ships-to-cargo for its Very Large Crude Carrier \n\ufb02  eet. An agent-based optimiser, Ocean i-Scheduler, was developed by \nMagenta Technology for use in real-time planning of cargo assignment to \nvessels in the \ufb02  eet. The system can dynamically adapt plans in response \nto  unexpected  changes,  such  as  transportation  cost  \ufb02  uctuations  or \nchanges to vessels, ports or cargo. Agent-based optimisation techniques \nnot only provided improved responsiveness, but also reduced the human \neffort necessary to deal with the vast amounts of information required, \nthus reducing costly mistakes, and preserving the knowledge developed \nin the process of scheduling.\nMagenta Technology and Tankers International55\nTechnology Adoption\nand the close cooperation between business and universities are not always apparent. In \naddition, there is also a recognition at the level of the European presidency, in the report \npublished by The Netherlands Ministry of Economic Affairs (2004), of the need to \u201caccelerate \nthe  introduction  of  disruptive  technologies,\u201d  the  most  relevant  of  the  10  breakthroughs \nidenti\ufb01  ed  as  being  needed  to  move  towards  the  Lisbon  goals  (European  Commission, \n2000). Broad deployment and use of disruptive technologies require understanding and \nacceptance. Yet the lack of adequate and sophisticated interactions between industry, \ngovernment and society stakeholders often obstructs the process of achieving understanding \nand acceptance. \nHowever,  through  Coordination  Actions  like  AgentLink,  at  least  some  form  of  drawing \ntogether of the research and business communities has taken place in the domain of agent-\nbased computing, and there are ready channels for interaction to facilitate different models \nof cooperation. \nFigure  5.3  illustrates  activity  in  Europe,  with  AgentLink  and  Agentcities.NET  providing \ncoordination of the community through a period of intense change and innovation at \nFigure 5.3: European activity in agent-based computing in recent years.\nFIPA ACL OIL DAML+OIL\nFIPA 97 FIPA 98 FIPA 00\nICMAS AA\nRobocup\nIFMAS\nRobocup\nrescue\nJADE\nBoard\nAAMAS EUMAS\nZeus FIPA OS JADE\nZeus\nFIPA compliant\nAgentLink II AgentLink I AgentLink III\nCoordination\nSystems\nStandards\nEvents\nAgentcities\nCougaar \nopen source\nOWL\nWSMO\n1995 2000 200556\nAgentLink Roadmap\nthe  research  level.  Usable  FIPA  standards,  for  example,  were  developed  in  1998,  but \nmatured in 2000; several FIPA compliant agent platforms (JADE, Zeus and FIPA-OS) were \nalso released by 2000. Meanwhile, developments in the Semantic Web gave rise to OIL \nand then DAML+OIL. At the bottom of the \ufb01  gure, key events in the development of the \nresearch community are indicated: the International Conference on Multi-Agent Systems \n(ICMAS) \ufb01  rst appeared in 1995, the Autonomous Agents Conference (AA) in 1997, and both \nwere combined into the International Joint Conference on Autonomous Agents and Multi-\nAgent Systems (AAMAS) in 2002. In addition, the International Foundation for Multi-Agent \nSystems (IFMAS) was established in 1998, and a European initiative was launched in 2003 \nwith a European workshop, the European Workshop on Multi-Agent Systems (EUMAS).57\nMarket Analysis\n  6 Market and Deployment Analysis\n6.1  Deliberative Delphi Survey\nIn an effort to elicit an informed assessment of the current state of development of agent \ntechnologies and the likely future market penetration for different areas, AgentLink III \nundertook a Delphi survey of opinion from a selected group of experts in the \ufb01  eld. The \nDelphi method makes use of a limited panel of experts, selected on the basis of their \nexpertise, and calling on their insights and experience. The hypothesis underlying Delphi \nis  that  these  experts  are  better  equipped  to  predict  the  future  than  are  theoretical \napproaches,  extrapolation  of  trends,  or  more  general  survey  methods.  In  standard \nDelphi studies, participants are asked to give their predictions, which are aggregated \nand shown again to the participants in subsequent rounds. After seeing their peer-group \naverage, the participants are allowed to revise their predictions, with the intention that \nthe group will converge toward the \u201cbest\u201d response through this consensus process. In \nAgentLink\u2019s Deliberative Delphi study, we modi\ufb01  ed this process by asking participants to \ngive their reasons for their predictions and opinions, and circulated these reasons, as well \nas the aggregated results, in order to provide a more justi\ufb01  ed and useful exercise. The \nexperts deliberated on their projections, hence the deliberative study.\nThe study involved 23 participants, of whom 5 were senior academic experts, with the \nremaining 18 coming from industry. Of this latter group, 11 were from major, typically \nmulti-national companies, and 7 from smaller, newer companies specialising in agent \ntechnology.  The  industrial  group  included  one  major  traditional  manufacturer,  two \ntelecommunications companies, and several IT services companies. Participants were \nmostly European, but included representatives from the US, Japan and Australia. Full \nresults are available in (Munroe et al., 2005).\n6.1.1  Industry Sector Penetration\nIt is still too early to consider the penetration of different industry sectors, but in a relative \nanalysis of those domains that are likely to encourage the take-up and deployment of \nagent technologies, the Deliberative Delphi study identi\ufb01  ed telecommunications and \nnetworks, manufacturing, transport and healthcare as the most signi\ufb01  cant over the next \n5 years, 10 years and beyond. Participants were asked to select those in which they \nconsidered there would be likely deployment, with the results showing three broad classes. \nThe second tier of domains includes: wholesale and retail trade; \ufb01  nance, insurance and \nreal estate; computer software; public administration; and other utilities. The results are \nsummarised in Figure 6.1, with all industry sectors represented, showing the number of \ntimes each was selected by participants over the different time periods. It is interesting 58\nAgentLink Roadmap\nto note that computer software comes relatively low down the list, in this second tier. This \ncontrasts with much work that has focussed on eCommerce and eBusiness systems in \nrecent years, partly because of its relative currency in the light of the Internet boom, and \npartly because of its ready availability as a domain to study. One question to consider, \ntherefore, is whether the survey points beyond immediate application domains.\nLater, when asked to evaluate in which sectors agents were expected to make the \ngreatest impact, by rating each on a 1 to 5 scale (with 1 indicating no impact at all, and \n5 indicating a very large impact), responses were broadly similar. The means of these \nresponses are shown in Figure 6.2.\nMore speci\ufb01  cally in relation to computing, however, our experts were extremely con\ufb01  dent \nthat today\u2019s major software vendors will have developed products with integrated agent \ntechnologies for supply chain management by 2010. One reason for this is that there are \nalready emerging products in this space, even if just at the start of that development. For \nsome, supply chain management is part of the eBusiness domain, which will see agent-\nbased systems emerging as the most prevalent technology, as a differentiator based on \nintelligence and autonomy, to address intense competition. Other domains are less clear, \nwith little con\ufb01  dence in the view of agent technology deployment across all products. \nFigure 6.1: Manufacturing, transport, telecoms and healthcare will encourage agent deployment\n5 years\n10  years\n10+ years\n0 5 10 15 20 25 30 35\nPublic administration\nOther services\nMedia and journalism\nHealthcare\nComputer software\nComputer hardware\nFinance, insurance and real estate\nWholesale and retail trade\nOther utilities (electricity, gas, water)\nTelecommunications and networks\nTransport\nManufacturing\nConstruction\nMining\nAgriculture, foresty and fishing59\nMarket Analysis\n6.1.2  Deployment of Agent Technologies\nTurning  this  around,  the  expert  panel  considered  identi\ufb01  able  but  limited  deployment \nof agent technologies in more general applications (such as negotiation as part of e-\ncommerce  applications)  to  be  achievable  on  average  by  2006,  with  research  and \ndevelopment costs in agent technologies to be offset by revenues generated by 2009. \nAlthough some companies are already in the enviable position of generating revenue \nthat exceeds costs, the mainstream deployment of agent technologies, on average, is not \nexpected to be realised until 2010. The mean response for these issues is shown in Figure \n6.3. However, given the responses to the earlier questions, this seems optimistic, and is \ncoherent only for limited domains or applications. \nReasons for the expressed opinions varied, but some suggested that the strategic decisions \nrequired by companies in order to adopt new technologies have not yet taken place, \nleading  to  a  delay  in  the  possibilities  for  deployment.  Nevertheless,  there  have  been \ndeployments in several large commercial organisations: electronic assistants in the form \nof software agents for wireless, pervasive or so called context-aware computing, and \napplications in which speci\ufb01  c agent technologies are used (in manufacturing control, \ndiagnosis, space, and so on). Though these are limited, this number will increase over the \nnext few years, but they may not be labelled as agent-based systems. Indeed, if there is \na lack of mainstream success in the short term, at least one expert suggests that agent \ntechnology  may  need  to  rebadge  itself,  especially  in  light  of  current Grid  computing \nstandards such as web service agreements. \n0 1 2 3 4 5\nPublic administration\nOther Services\nMedia and journalism\nHealthcare\nComputer software\nComputer hardware\nFinance, insurance and real estate\nWholesale and retail trade\nOther utilities (electricity, gas, water)\nTelecommunications and networks\nTransport\nManufacturing\nConstruction\nMining\nAgriculture, forestry and fishing\nFigure 6.2: Agents will make the greatest impact in telecoms, transport and manufacturing60\nAgentLink Roadmap\nHowever, one respondent shows some insight by stating that it will be hard to calculate \nreturns, since successful products will not look as though they have any agents. A general \nproblem with software, especially in research and development, is the tendency to focus \non the technologies applied rather than on the effective solution to a problem. Yet a \nfocus on the solution, regardless of the technologies used, may obscure the explicit value \nof agent technologies through their successful use and integration. \nOther dif\ufb01  culties relate to the development of advanced reasoning capabilities that \nare needed not for the majority of systems, but only for complex problem types; until \ninfrastructure is more standardised, however, the focus can only be on deployment of \nsimple composition of services. Similarly, trust and legal issues appear to be a hindrance \nto commercial adoption. \n6.1.3  Technology Areas and Maturity\nIn relation to speci\ufb01  c technological areas, the experts were asked to assess the current \nstate, and to what extent agent technologies were ready for deployment now. Again, \nthey rated different technology areas on a 1 to 5 scale (with 1 indicating that the area \nwas not ready for deployment, and 5 indicating that the technology was ready now). \nThe means of these responses are shown in Figure 6.4. Those areas that exceeded the \naverage for deployment now include coordination techniques, runtime platforms and \ntools, simulation, and integration or combination with other technologies. Those below \naverage  include  theoretical  models,  algorithms  and  paradigms,  methodologies  for \ndevelopment,  reasoning  and  decision-making  tools,  and  agent-based  application \nframeworks. \nMainstream deployment\nR&D costs offset by revenues\nIdentifiable but limited deployment\n2004 2005 2006 2007 2008 2009 2010 2011\nFigure 6.3: Mainstream deployment of agent technologies will not appear until 201061\nMarket Analysis\nParticipants  were  also  asked  which  technology  areas  were  seen  as  strong  for  the \napplication of agent tools, models and solutions, and which were not. The areas exceeding \nthe average in terms of suitability for agent applications corresponded directly to those \nindicated above as being ready for deployment now, perhaps not surprisingly, while those \nsuitable for application of non-agent solutions included the other areas of theoretical \nmodels,  algorithms  and  paradigms,  methodologies  for  development,  reasoning  and \ndecision-making  tools,  and  agent-based  application  frameworks.  Interestingly,  runtime \nplatforms and tools were deemed appropriate for both agent and non-agent solutions.\nThe results are shown on the graphs in Figures 6.5 and 6.6, which indicate the number \nof times each area was selected by respondents as suitable for agent and non-agent \nsolutions,  respectively.  We  can  see  that  coordination  techniques  are  seen  as  being \nespecially strong for agent technologies, which are also relatively ready for deployment. \nRuntime platforms are also above average in comparison to other areas in all measures, \nbut attract the highest score for the suitability for non-agent tools. Reasoning and decision-\nmaking tools score close to the average on all issues, and simulation is similar, except that it \nis seen as being the most ready for deployment now. By contrast, agent-based application \nframeworks  are  below  average  in  comparison  to  other  areas  except  in  readiness  for \ndeployment of agent technologies, in which they reach the average. \nAt the same time, the participants were asked which problem areas were suitable for \napplication of current agent technologies now, in 5 years, in 10 years, and beyond, by \n0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0\nCombination with other technologies\nAgent-based applications frameworks\nSimulation\nReasoning and decision making tools\nRuntime platforms and tools\nMethodologies\nCoordination techniques\nTheoretical models and algorithms\nFigure 6.4: Simulation, runtime platforms and coordination techniques are more ready for deployment 62\nAgentLink Roadmap\nrating the problem areas on a 1 to 5 scale (with 1 indicating that the area was not suitable, \nand 5 indicating that it was very suitable). The results, in Figure 6.7, showed that interfaces, \nnegotiation, coordination, complex systems modelling, and simulation scored highest, with \nall problem areas showing suitability in the higher range after 10 years.\n0 5 10 15 20\nCombination with other technologies\nAgent-based applications frameworks\nSimulation\nReasoning and decision making tools\nRuntime platforms and tools\nMethodologies\nCoordination techniques\nTheoretical models and algorithms\nPhilosophical foundations\n                Figure 6.5: Coordination techniques offer the strongest agent solutions\n0 1 2 3 4 5 6 7 8\nCombination  with other technologies\nAgent-based applications frameworks\nSimulation\nReasoning and decision making tools\nRuntime platforms and  tools\nMethodologies\nCoordination techniques\nTheoretical models and algorithms\nPhilosophical foundations\n        Figure 6.6: Non agent solutions rate highly for methodologies and runtime platforms63\nMarket Analysis\n6.1.4  Standards\nSince the current technological context provides an appropriate base on which to build \nagent systems, and also suggests the use of agent technologies as never before, we \nalso asked how important different technologies and standards were to the take-up of \nagents now, in 5 years, in 10 years, and beyond. The results for each question are shown in \nFigures 6.8 and 6.9, which suggest the overriding signi\ufb01  cance of web services and other web \ntechnologies for take-up from now onwards. As time progresses, the impact of the Semantic \nWeb, Grid technologies, P2P, AI planning systems and other eBusiness technologies are likely \nto have an increasing impact. In terms of standards, web services and the Semantic Web are \nmost important, but the efforts of FIPA and the OMG are also regarded as facilitating take-up \nand deployment.\n6.1.5  Prospects\nIn relation to the issue of whether or when agent technology is likely to replace object-oriented \ntechnology, the majority (59%) of respondents do not believe that this will ever happen, \nwith most of these arguing that agent and OO technologies are complementary, and not \ncompetitive, as shown in Figure 6.10. The view is consistent with that taken in this document, \nyet it is interesting to note that the remaining 41% believe that there will come a point in time \nat which agents will replace object technologies, though it is recognised that the technologies \nmay converge rather than one supplanting the other.\nNow\n5  years\n10 years\n0 3 6 9 12 15\nSimulation\nIntelligence\nSecurity\nRobustness\nScalability across many platforms (or users)\nScalability on single platfroms or organisations\nComplex systems (modelling and dynamics)\nLarge scale distributed systems\nAutomation\nCoordination\nNegotiation\nSemantics\nDynamics\nInterfaces (human systems)\n10+ years\nFigure 6.7: Negotiation, coordination, simulation, interfaces and  complex systems are suitable \n                        for the application of current agent technologies64\nAgentLink Roadmap\nMore  generally,  the  participants  were  also  asked  what  kind  of  timeline  the  vision  and \ncommitment of the academic and research communities should take, choosing from short \nterm (1\u20133 years) medium term (4\u20136 years) and long term (7\u201310 years). Perhaps not unreasonably, \nthe results, shown in Figure 6.11, suggest that the short term is still too close, only 14% choosing \nsuch an immediate outlook, with the majority of 54% identifying the medium term as the right \ntimescale. The remaining 32% took the longer term view of 7\u201310 years or more.\nNow\n5 years\n10 years\n0 2 4 6 8 10 12\nJ2EE .NET\nedXML\nSemantic web\nWeb services\nOMG\nGGF\nFIPA\n10+ years\nFigure 6.9: Web services and semantic web standards are most important, with FIPA and OMG close behind\n \nNow\n5 years\n10 years\n0 3 6 9 12 15\nAI planning systems\nOther e-business technologies\nRosettaNET\nebXML\nP2P technologies\nGrid technologies\nSemantic web\nMultimedia technologies\nWeb technologies \nWeb services\n10+ years\nFigure 6.8: Web technologies are important now, but semantic web, Grid and P2P are catching up65\nMarket Analysis\n6.2  The Agent Technology Hype Cycle \nTechnology forecasting is a notoriously dif\ufb01  cult task. In seeking to understand patterns \nof technology development in the mid-1990s, Gartner devised a model known as the \nHype Cycle (described below), which indicates the maturity of a technology, from initial \nexcitement to disillusionment and then, for some, eventual market acceptance. \nThe Hype Cycle involves the following \ufb01  ve stages. \n\u25a0  Technology trigger: introduction of the technology to a wider audience.\n\u25a0  Peak of in\ufb02  ated expectations: the high point, at which the claims of the bene\ufb01  ts of the \ntechnology are often exaggerated.\n\u25a0  Trough of disillusionment: as the promises fail to be delivered, many observers begin to \nignore the technology.\n\u25a0  Slope of enlightenment: more is learned about the technology and, as many of the \n2010-2020\n       \nNow-2010\nNever 59%\n14%\n27%\nFigure 6.10: Most believe that agent technology will not replace object technology but complement it instead\nWhen will agent technology replace object technology?\nShort term\nMedium term \nLong term\n14%\n54%\n32%\nFigure 6.11: The vision and commitment of the academic and research communities should be medium term\nWhat timescale should be adopted for research?66\nAgentLink Roadmap\nproblems from the trough are resolved, standardisation takes place, and the technol-\nogy is adopted primarily in the areas that perceive the greatest bene\ufb01  t.\n\u25a0  Plateau of productivity: the new technology is well understood and stable, and be-\ncomes mainstream. Bene\ufb01  ts and drawbacks for adoption are also widely known.\n6.2.1  The Gartner Analysis\nGartner\u2019s July 2004 analysis of technologies and applications (Gartner 2004a\u20132004f) places \nvarious agent technologies, agent-related technologies, application domains and drivers \nat various different points in the hype cycle, as shown in Figure 6.12. \nFigure 6.12: The Gartner aggregated agent technology hype cycle\nTechnology\ntrigger\nPeak of inflated\nexpectations\nTrough of\ndisillusionment\nSlope of\nenlightenment\nPlateau of \nproductivity\nGartner\u2019s Agent Technology Hype Cycle\nWeb Services\nBusiness Models\nSemantic Web \nIntelligent Agents\nAdvanced Web Services\nWeb Agents\nChatterbots\nE-Marketplaces\nInternal Web\nServices\nAgent-Based Integration\nTrading Grid\nSwarm\nIntelligence\nBPEL\nAffective \nComputing\nMaturity\nV\ni\ns\ni\nb\ni\nl\ni\nt\ny67\nMarket Analysis\nIn terms of infrastructure, business process execution languages (BPEL) are rising on the \ntechnology trigger path, with between 1% and 5% market penetration. Basic web services \nfor service de\ufb01  nition and application integration, using SOAP and WSDL, are climbing the \nslope of enlightenment and are implemented by major software vendors, reaching 20% \nto 50% market penetration. Advanced web services for higher quality of service, which \nwill  enable  advanced  business-critical  functions  over  standards-based  networks,  using \nSOAP, WSDL, UDDI, WS-Security and WS-R, depend on the availability of standards, and \nimplementations are not yet fully delivered by vendors. \nDrivers and domains \ufb01  gure primarily through the Semantic Web, both of which are placed at \nthe peak of expectation; while the expectation is for a transformational impact, at present \nit has less than 1% market penetration. Similarly, the Trading Grid, an interconnection of \nnetworks and marketplaces to support virtual organisations, is also transformational but \njust at the very start of the cycle. With lower perceived impact, but more mature, are \neMarketplaces, now with up to 5% market penetration. Each of these is predicted to take \nup to 10 years to plateau.\nIntelligent agents as a whole are seen as being in the trough, having been overhyped in \nthe past, as synthetic characters and chatterbots were in the past. By contrast, web self-\nservice agents, which act on a customer\u2019s or business\u2019s behalf to automate transactions \nare \ufb01  nally \u201ccatching on\u201d, and have reached up to 5% penetration. In all these cases, \nhowever, these are lightweight agents, with the mainstream of agent technologies still to \nengage. For example, agent-based integration is concerned with enabling distributed \napplications that demand autonomy and \ufb02  exibility. In this area, commercial technology \nis still new, and the sector is dominated by small startups and only a small number of users, \nso agent-based integration is at the start of the cycle. Gartner estimates that market \npenetration is less than 1% of the target. Given the position of the Semantic Web, this is \nperhaps not surprising, but the time to plateau is shorter, at up to 5 years.\nAt the embryonic stage are: swarm intelligence, or emergent computing, which \ufb01  ts directly \nwith the complex systems discussed above; and affective computing, which seeks to \nrecognise human emotional states for better user interfaces. At present, these are mainly \nin the domain of research laboratories.\n6.2.2  The AgentLink Analysis\nBased  on  Gartner\u2019s  analysis,  and  a  review  from  the  AgentLink  community,  taking \ninto  account  the  analyses  reported  earlier  in  this  document,  we  have  developed  a \ncomplementary Hype Cycle for agent technologies, illustrated in Figure 6.13. Here, some 68\nAgentLink Roadmap\ntechnologies are seeing real deployed value across a range of applications. Increasingly, \nfor example, agent-based simulation is being applied to logistics and other application \ndomains, achieving clear and distinct results, with suppliers creating a space for themselves \nin this market niche. Similarly, web services are increasingly being used for the development \nof systems where there is a genuine understanding of the business bene\ufb01  ts, rather than \nin\ufb02  ated and false expectations.\nHowever, many technologies are still to mature. Intelligent and cognitive agents, with \nsophisticated architectures, such as BDI, are situated in the trough of disillusionment, as are \nnorm-based systems and electronic institutions, not yet \ufb01  nding roles in most mainstream \nbusiness applications. Similarly, eCommerce agents have much promise, but as yet have \nFigure 6.13: The AgentLink agent technology hype cycle\nSemantic web services \nIntelligent and \ncognitive agents\nAdvanced web services\nNorm-based systems\nElectronic institutions\nChatterbots\nE-Marketplaces\nVirtual organisations\nAgent-based\nintegration\nSelf-evolving\nlangugages and protocols\nSelf organisation\nand emergence\nReputation\nmechanisms\nAffective \ncomputing\nTechnology\ntrigger\nPeak of inflated\nexpectations\nTrough of\ndisillusionment\nSlope of\nenlightenment\nPlateau of \nproductivity\nAgentLink\u2019s Agent Technology Hype Cycle\nDevelopment tools\nAgent methodologies\nAgent-enabled Grid computing\nWeb services\nFormal methods for agents\nSemantic web \nAgent-based simulation\nArgumentation\nstrategies\neCommerce agents\nMaturity\nV\ni\ns\ni\nb\ni\nl\ni\nt\ny69\nMarket Analysis\nmostly  been  deployed  in  prototypes  and  demonstrators,  though  the  infrastructure  for \nenabling their operation (through electronic marketplaces) is now starting to mature.\nMore interesting, perhaps, are the early runners: self-evolving communication languages \nand protocols have promise, but it is far too early to consider them seriously. Climbing \nupwards to the peak of in\ufb02  ated expectations are self-organisation and emergence (as \ndiscussed in detail earlier in this report), methodologies, development tools and virtual \nCalico Jack and Healthcare\nCalico Jack has been working with the Chief Scientist Of\ufb01  ce, part of the \nScottish Executive Health Department, to develop prototype solutions \ntackling several key issues in primary care. The company has delivered \nan agent-based system that integrates with existing email services and \nin-practice  processes,  adding  new  functionality.  In  particular,  and  in \ncollaboration with mobile telecoms company, Orange, new services are \nbeing offered to patients by SMS and WAP. By modelling the stakeholders \nin  the  primary  care  system  as  agents,  the  system  has  been  easily \nintroduced into an already complex mix of IT processes, interpersonal \nprocesses, regulatory processes and the relationships between them. In \nworking with patients, GPs and administrators to tailor the service to their \nneeds, agent-based representation has been key in supporting \ufb02  exibility \nin  design,  implementation  and  deployment.  Among  the  new  services \ncurrently  offered  by  the  system  are  the  ability  to  coordinate  repeat \nprescriptions using SMS (reducing load on the practice administrator, and \nsimplifying the process for the patient), and to book appointments and \nhandle reminders through a combination of SMS and email (with the aim \nof reducing the expensive wasteful missed appointments and smoothing \nthe booking process for patients). The system is currently being trialled \nin a GP practice in Tayside, UK, with a view to subsequent wider rollout.70\nAgentLink Roadmap\norganisations (which have gathered much interest from the business communities, but \nare not yet so developed technologically). The drivers of the Semantic Web and Grid \ncomputing are just past the peak, but it is still early to determine how quickly they will move \ninto and out of the trough.71\nTechnology Roadmap\n  7 Technology Roadmap \nIn  any  high-technology  domain,  the  systems  deployed  in  commercial  or  industrial \napplications tend to embody research \ufb01  ndings somewhat behind the leading edge of \nacademic  and  industrial  research.  Multi-agent  systems  are  no  exception  to  this,  with \ncurrently-deployed systems having features found in published research and prototypes \nof three to \ufb01  ve years ago. By looking at current research interests and areas of focus, we \nare therefore able to extrapolate future trends in deployed systems. \nAccordingly, we have identi\ufb01  ed four broad phases of the future development of multi-\nagent systems. These phases are, of necessity, only indicative, since some companies and \norganisations will be leading users of agent technologies, pushing applications ahead of \nthese phases, while many others will not be as advanced as this. We aim to describe the \nmajority of research challenges at each time period. Note that this view on timescales \ntakes the research view rather than the development view in that typically research is \nabout three to \ufb01  ve years ahead of development in this context. This analysis is an updated \nversion of the prognosis initially undertaken in (Luck et al., 2003). \n7.1  Phase 1: Current \nMulti-agent systems are currently typically designed by one design team for one corporate \nenvironment, with participating agents sharing common high-level goals in a single domain. \nThese systems may be characterised as closed. (Of course, there is also work on individual \ncompetitive agents for automated negotiation, trading agents, and so forth, but typically \nalso constrained by closed environments.) The communication languages and interaction \nprotocols are typically in-house protocols, de\ufb01  ned by the design team prior to any agent \ninteractions. Systems are usually only scalable under controlled, or simulated, conditions. \nDesign approaches, as well as development platforms, tend to be ad hoc, inspired by the \nagent paradigm rather than using principled methodologies, tools or languages. Although \nthis is still largely true, there is now an increased focus on, for example, taking methodologies \nout of the laboratory and into development environments, with commercial work being \ndone on establishing industrial-strength development techniques and notations. As part of \nthis effort, some platforms now come with their own protocol libraries and force the use of \nstandardised messages, taking one step towards the short-term agenda.\nIt remains true that, for the foreseeable future, there will be a substantial commercial \ndemand for closed multi-agent systems, for two reasons. First, there are very many problems \nthat can be solved by multi-agent systems without needing to deal with open systems, and \nthis is where many companies are now realising business bene\ufb01  t. Second, in problems \ninvolving  multiple  organisations,  agreement  among  stakeholders  on  the  objectives  of \nthe open system may not always be readily achieved, and there may also be security 72\nAgentLink Roadmap\nconcerns that arise from consideration of open systems. While progress on technologies \nfor open systems will change the nature of agent systems, the importance of closed, well-\nprotected systems must not be underestimated.\n7.2  Phase 2: Short-Term Future\nIn the next phase of development, systems will increasingly be designed to cross corporate \nboundaries, so that the participating agents have fewer goals in common, although their \ninteractions will still concern a common domain, and the agents will be designed by the \nsame team, and will share common domain knowledge. Increasingly, standard agent \ncommunication  languages,  such  as  FIPA  ACL,  will  be  used,  but  interaction  protocols \nwill be mixed between standard and non-standard ones. These systems will be able to \nhandle large numbers of agents in pre-determined environments, such as those of Grid \napplications.  Development  methodologies,  languages  and  tools  will  have  reached  a \ndegree of maturity, and systems will be designed on top of standard infrastructures such as \nweb services or Grid services, for example. \nExample systems developed in this phase include those to enable automated scheduling \ncoordination between different departments of the same company, closed user groups \nof suppliers engaged in electronic procurement along a supply-chain, and industry-wide \ntransportation scheduling systems. Even when agents representing multiple organisations \nparticipate  in  these  systems,  the  systems  and  the  associated  templates  for  agent \nparticipants will still normally be developed by a dominant company or a consortium on \nbehalf of the entire business network. \n7.3  Phase 3: Medium-Term Future\nIn the third phase, multi-agent systems will permit participation by heterogeneous agents, \ndesigned by different designers or teams. Any agent will be able to participate in these \nsystems, provided their (observable) behaviour conforms to publicly-stated requirements \nand  standards.  However,  these  open  systems  will  typically  be  speci\ufb01  c  to  particular \napplication  domains,  such  as  B2B  eCommerce  or  bioinformatics.  The  languages  and \nprotocols used in these systems will be agreed and standardised, perhaps drawn from \npublic libraries of alternative protocols that will, nevertheless, likely differ by domain. In \nparticular, it will be important for agents and systems to master this semantic heterogeneity. \nSupporting this will be the increased use of new, commonly agreed modelling languages \n(such as Agent-UML, an extension of UML 2.0), which will promote the use of IDEs and, \nhopefully, start a harmonisation process as was the case for objects with UML.\nSystems  will  scale  to  large  numbers  of  participants,  although  typically  only  within  the \ndomains concerned, and with particular techniques (such as domain-bridging agents), 73\nTechnology Roadmap\nto translate between separate domains. System development will proceed by standard \nagent-speci\ufb01  c  methodologies,  including  templates  and  patterns  for  different  types  of \nagents  and  organisations.  Agent-speci\ufb01  c  programming  languages  and  tools  will  be \nincreasingly used, making the use of formal veri\ufb01  cation techniques possible to some extent. \nSemantic issues related to, for example, coordination between heterogeneous agents, \naccess control and trust, are of particular importance here. Also, because these systems \nwill typically be open, issues such as robustness against malicious or faulty agents, and \n\ufb01  nding an appropriate trade-off between system adaptability and system predictability, \nwill become increasingly important. \nExamples of systems in this phase will be corporate B2B electronic procurement systems \npermitting participation by any supplier (rather than closed user groups), using agents not \nconforming to a template. \n7.4  Phase 4: Long-Term Future\nThe fourth phase in this projected future will see the development of open multi-agent \nsystems spanning multiple application domains, and involving heterogeneous participants \ndeveloped by diverse design teams. Agents seeking to participate in these systems will be \nable to learn the appropriate behaviour for participation in the course of interacting, rather \nthan having to prove adherence before entry. Selection of communications protocols \nand mechanisms, and of participant strategies, will be undertaken automatically, without \nhuman intervention. Similarly, ad hoc coalitions of agents will be formed, managed and \ndissolved automatically. Although standard communication languages and interaction \nprotocols will have been available for some time, systems in this phase will enable these \nmechanisms to emerge by evolutionary means from actual participant interactions, rather \nthan being imposed at design time. Of course, such languages, protocols and behaviours \nmay be mere re\ufb01  nements of previously-developed standards, but they will be tailored \nto their particular contexts of use. In addition, agents will be able to form and re-form \ndynamic coalitions and virtual organisations on-the-\ufb02  y and pursue ever-changing goals \nthrough appropriate interaction mechanisms for distributed cognition and joint action. \nIn  these  environments,  emergent  phenomena  will  likely  appear,  with  systems  having \nproperties (both good and bad) not imagined by the initial design team. Multi-agent \nsystems will be able, adaptable and adept in the face of such dynamic, indeed turbulent, \nenvironments, and they will exhibit many of the self-aware characteristics described in the \nautonomic computing vision. Agents and organisations will be considered as high level \nsystem components, easy to customise and train, and which can be combined to provide \nnew components and services, such as in automated or self-assembling software.\nBy this phase, systems will be fully scalable in the sense that they will not be restricted to \narbitrary limits (on agents, users, interaction mechanisms, agent relationships, complexity, 74\nAgentLink Roadmap\netc). As previously, systems development will proceed by use of rigorous agent-speci\ufb01  c \ndesign methodologies, in conjunction with programming and veri\ufb01  cation techniques. \n7.5  Technologies and Timescales\nArising  from  this  picture  of  the  future  of  agent  research,  we  see  a  number  of  broad \ntechnological  areas  of  research  and  development  over  the  next  decade.  These  are \nsummarised in Figure 7.1, which shows the main research and development topics of each \narea, classi\ufb01  ed according to the timepoint at which they will attract most attention. Thus, \nfor example, in the area of Industrial Strength Software, peer-to-peer aspects are a short-\nterm focus of attention, while best practice in agent systems design, implementation and \nveri\ufb01  cation will likely only be a focus in the long term. In particular, the table suggests that \nlong-term issues are worthy of strategic investment and effort while short-term issues are \nlargely already addressed or are being addressed. A much more detailed treatment of \nmany of these issues can be found in (Luck et al., 2003; Luck et al., 2004a).\nBy considering the marketing theory of the diffusion of new technologies, together with \nthe features particular to agent technologies, such as standards, and by comparing the \nhistorical growth of object technologies and the future growth of agent technologies, we \ncan estimate an adoption curve for object technologies. Such a curve, shown in Figure 7.2, \nindicates the total proportion of adopters in a population at each moment of time, and \nis the cumulative version of a product life-cycle presented earlier. Marketers commonly \nuse an exponential function to model new product diffusion, as we have done, based on \n(McBurney et al., 2002). \nIn  the  case  of  object  and  agent  technologies,  the  relevant  population  comprises  all \norganisations and companies engaged in software development, either internally or via \ncommissioned projects. To calibrate the adoption curve, we have assumed that, in the \nlong-run, 75% of all such organisations will adopt object-oriented programming (OOP) \ntechniques. Using qualitative information about the growth in interest in OOP (from the \n\u201cAgents versus Objects\u201d box on page 48) we have estimated the rate of growth of the \ncurve, where the market grows increasingly rapidly until late 1997, after which the rate of \ngrowth in adoption slows down.\nTo calibrate the model for agent technologies, we have assumed the same curve but \nstarting later (1985, rather than 1962), and with a smaller long-run potential. Because agent \ntechnologies are appropriate for fewer application domains than are object technologies, \nit is assumed that only 35% of the population of organisations or companies engaged in \nsoftware development will ever adopt agent technologies.75\nTechnology Roadmap\nWill agent technologies be adopted faster than were object technologies? On the one \nhand, competitive pressures and the faster pace of technology change now experienced \nsuggest that agent technologies will be adopted sooner than object technologies. On the \nother hand, the greater complexity of typical agent applications, and the fact that many \napplications require inter-organisational collaboration, suggest a slower rate of adoption \nthan for object technologies. Putting together these countervailing forces, we are led to \npropose the same growth rate as for object technologies. The resulting adoption curve \nis also shown in Figure 7.2, and, as can be seen there, the rate of growth of adoption \nincreases until mid 2014, after which it slows down.\nThis adoption curve for agent technologies is consistent with the \ufb01  ndings of the previously \ndescribed Deliberative Delphi study. For instance, Figure 6.3 indicates that, on average, \nDelphi  respondents  expect  mainstream  deployment  of  agent  technologies  only  from \nFigure 7.1: Agent technology comprises areas that will be addressed over different timescales \nIndustrial Strength software\nAgreed Standards\nInfrastructure for \nOpen Communities\nReasoning in Open Environments\nLearning Technologies\nTrust and Reputation\nShort Term Medium Term Long Term\nPeer to peer FIPA ACL\nBetter development tools\nFlexible business/trading languages\nLibraries of interaction protocols\nTools for evolutions\n of communications \nlanguages and protocols\nSemantic description\nData integration and Semantic Web\nSemantic interaction Web mining\nAgent-enabled semantic web (services) Shared, improved ontologies\nNorms and \nsocial structure\nOrganisational views of agent systems\nTheory and practice \nof negotiation strategies\nEnhanced understanding\nof agent society dynamics\nTheory and practice \nof argumentation strategies\nAutomated eScience systems\nand other application domains\nAdaptation Evolving Agents\nPersonalisation\nDistributed learning Hybrid technologies\nSelf organisation Run-time reconfiguration\nand re-design\nReliability testing for agents Formal methods \nfor open agent systems\nSecurity and verifiability\n for agents\nReputation \nmechanisms\nSelf-enforcing protocols\nNorms and social structures\nElectronic contracts\nElectronic institutions\nDynamic norms, roles, laws, organisations\nPeer to peer\nService oriented computing\nAgent UML\nBetter development tools\nGeneric designs for coordination\nLibraries for \nagent-oriented development\nBest practice in agent systems design\nTrust techniques for coping\nwith malicious agents\nService oriented computing\nMetadata76\nAgentLink Roadmap\n2010. The curve in Figure 7.2 indicates a penetration level for agent technologies of 12% \nof organisations engaged in software development by 2010, or about one-third of the \nlong-run adoption level of 35%. At this level of penetration, it is reasonable to assume \nthat  applications  of  agent  technologies  have  become  mainstream.  However,  not  all \napplications of agent technologies may be labelled as such, as for example, with trust \nand reputation systems, automated auction bidding systems, or Grid systems. All of these \napplications may use agent technologies without being called agent systems.\nA similar rate of growth to that for object-oriented technologies can only be acheived if \nthe obstacles currently in the way of adoption of agent technologies are overcome, as \nindeed they were for object technologies. Thus, for example, issues of standards and the \nprovision of software development methodologies and tools are important to be resolved \nif we are to move beyond the current early adopter stage of market diffusion. \nAdoption of Technologies\n0\n10%\n20%\n30%\n40%\n50%\n60%\n70%\n80%\n90%\n100%\nAgent Technologies\nObject Technologies\n2040 2030 2020 2010 2000 1990 1980 1970 1960\nFigure 7.2: Projected penetration levels for object technologies and agent technologies 77\nChallenges\n  8 Challenges\nHardware and software have improved signi\ufb01  cantly in performance and availability over \nthe six decades of modern computing. As these changes have occurred, the objectives of \nprogrammers have also changed. Initially, most programmers sought to minimise memory \nusage and to maximise throughput or processing speeds in their applications. With increasing \navailability  and lower costs of memory, and increasing micro-processor speeds, these \nobjectives became far less important. Instead, by the 1970s and 1980s, the object-oriented \nparadigm sought to maximise the modularity and re-usability of code, and to minimise \npost-deployment  system  maintenance.  However,  these  objectives  too  have  become \ndated. Partly, this is because the development of proven OOP methods and support tools \nhave enabled the objectives to be readily achieved, and indeed, taken for granted, over \nthe last two decades. More importantly, however, the rise to prominence of the Internet \nhas led to a new understanding of the nature of computation, an understanding which \nputs interaction at its centre. In this context, the agent-oriented paradigm has sought to \nmaximise adaptability and robustness of systems in open environments.\nIt is here that one can see how a new technology may be a disruptive force. By tackling \na different set of objectives, agent technologies address different problems and different \napplications  than  do  object  technologies.  It  is  not  simply  that  the  rules  of  the  game \nhave changed, but rather that a different game is being played. In a world of millions \nof  independent  processors  interconnected  via  the  Internet  and,  through  it,  engaged \nin  distributed  cognition,  a  software  design  team  can  no  longer  assume  that  software \ncomponents  will  share  the  same  goals  or  motivations,  or  that  the  system  objectives \nwill remain static over time. Systems therefore need to be able to adapt to dynamic \nenvironments, to be able to con\ufb01  gure, manage and maintain themselves, and to cope with \nmalicious, whimsical or just plain buggy components. The power of the agent paradigm \nis that it provides the means, at the appropriate level of abstraction, to conceive, design \nand manage such systems. \n8.1 Broad Challenges\nEach of the compelling visions discussed in the context of trends and drivers above \u2014 the \nSemantic Web, ambient intelligence, the Grid, autonomic systems \u2014 will require agent \ntechnologies,  or  something  very  like  them,  before  being  realised:  agent  technologies \nare upstream of these visions and mission-critical to them. For agent-based computing \nto  support  these  visions,  considerable  challenges  remain,  both  broad,  over-arching \nchallenges across the entire domain of agent technologies, and challenges speci\ufb01  c to \nparticular aspects. The broad challenges are as follows.78\nAgentLink Roadmap\n\u25a0 Creating tools, techniques and methodologies to support agent systems develop-\ners. Compared to more mature technologies such as object-oriented programming, \nagent developers lack sophisticated software tools, techniques and methodologies \nto support the speci\ufb01  cation, development and management of agent systems. \n\u25a0  Automating  the  speci\ufb01  cation,  development  and  management  of  agent  systems. \nAgent systems and many of their features are still mostly hand-crafted. For example, \nthe design of auction mechanisms awaits automation, as does the creation and man-\nagement of agent coalitions and virtual organisations. These challenges are probably \nseveral decades from achievement, and will draw on domain-speci\ufb01  c expertise (for \nexample, economics, social psychology and arti\ufb01  cial intelligence). \n\u25a0  Integrating components and features. As is evident from Sections 2 and 4 above, \nmany different theories, technologies and infrastructures are required to specify, de-\nsign, implement and manage agent systems. Integrating these pieces coherently and \ncost-effectively is usually a major undertaking in any system development activity, a \ntask made more challenging by the absence of mature integration tools and meth-\nodologies.\n\u25a0  Establishing appropriate trade-offs between adaptability and predictability. Creating \nsystems able to adapt themselves to changing environments, and to cope with au-\ntonomous components, may well lead to systems exhibiting properties that were not \npredicted or desired. Striking a balance, appropriate to the speci\ufb01  c application do-\nmain, between adaptability and predictability is a major challenge, as yet unresolved \neither theoretically or practically. Associated with predictability is the requirement for \npractical methods and tools for veri\ufb01  cation of system properties, particularly in multi-\nagent systems that are likely to exhibit emergent behaviour.\n\u25a0  Establishing appropriate linkage with other branches of computer science and with \nother disciplines, such as economics, sociology and biology. One task here is to draw \nappropriately on prior research from these other areas and disciplines. Another task is \nto avoid reinvention of existing techniques and methods, whether by agent research-\ners or by others. Awareness-building between areas and disciplines, and coordination \nof research and development activities, are essential if the appropriate linkages are \nto be established and maintained. \n8.2 Speci\ufb01  c Challenges\nSpeci\ufb01  c technical challenges continue to change as the \ufb01  eld of agent-based computing \nadvances and matures, and as related areas (like those discussed above) emerge and \ngalvanise efforts that contribute to the general area. Inevitably, standards will continue to \nbe critical, but it is not clear whether these should come from within the agent community \nor should emerge from more general computing infrastructure progress. (Recent relevant \nstandards  efforts  are  depicted  in  Figure  8.1)  Nevertheless,  in  addition  to  the  broad 79\nChallenges\nchallenges,  there  are  challenges  speci\ufb01  c  to  different  aspects  and  features  of  agent \nsystems (Bullock and Cliff, 2004; Foster et al., 2004). \nTrust and reputation\nSophisticated  distributed  systems  are  likely  to  involve  action  in  the  absence  of  strong \nexisting trust relationships. While middleware addresses secure authentication, and there \nexist techniques for veri\ufb01  cation and validation, these do not consider the harder problems \nof establishing, monitoring, and managing trust in a dynamic, open system. As discussed \nearlier, we need new techniques for expressing and reasoning about trust and reputation, \non  both  an  individual  and  a  social  level  to  enable  interaction  in  dynamic  and  open \nenvironments. \nVirtual organisation formation and management \nVirtual organisations (VOs) have been identi\ufb01  ed as one of the key contributions of Grid \ncomputing, but principled and well-de\ufb01  ned procedures for determining when to form \nnew VOs, how to manage VOs and portfolios of VOs, how to manage competing and \nFigure 8.1: Standards activity in the area of agent-based computing\n1995 2000 2005\nKIF KQML\nKQML \nrespecified\nFIPA\nACL OIL\nDAML\n+ OIL\nANSI KIF\nproposal FIPA 97 FIPA 98 FIPA 00\nOMG\nMASIF\nRDF\nXML\ndraft\nXML\n1.0 OWL\nFIPA \nOMG WG on Agents\nW3C80\nAgentLink Roadmap\ncomplementary VOs, and ultimately how and when to disband them, are still missing. \nMoreover, the development of procedures and methods for the automation of VO creation, \nmanagement and dissolution also provide major research and development challenges. \nIn addition, once such procedures have been de\ufb01  ned, creating formal representations of \nthem to support their automated deployment by agents themselves at runtime will be a \nmajor research challenge.\nResource allocation and coordination \nThe  coordinated,  autonomic  management  of  distributed  resources  requires  new \nabstractions,  mechanisms  and  standards  in  the  face  of  multiple,  perhaps  competing, \nobjectives from different stakeholders, and different de\ufb01  nitions of individual and social \nwelfare. Most R&D effort to date has focused on allocation and coordination mechanisms \ndrawn from human societies (for example, common auction protocols), but the processing \npower and memory advantages of computational devices mean that completely new \nmechanisms and protocols may be appropriate for automated interactions, in particular \nfor multi-objective coordination and negotiation. In addition, as with VOs, the automation \nof the design, implementation and management of mechanisms is a major challenge. \nNegotiation \nTo date, work on negotiation has provided point solutions. There is a need for a solid \ntheoretical foundation for negotiation that covers algorithms and negotiation protocols, \nwhile determining which bidding or negotiation algorithms are most effective under what \ncircumstances.  From  the  system  perspective,  behaviour  arising  through  the  interplay \nof  different  negotiation  algorithms  must  be  analysed,  and  determining  what  kind  of \nnegotiation  to  consider,  and  when,  must  be  established.  Finally,  effective  negotiation \nstrategies and protocols that establish the rules of negotiation, as well as languages for \nexpressing service agreements, and mechanisms for negotiating, enforcing, and reasoning \nabout  agreements  are  also  needed.  Incorporating  capabilities  for  disagreement  and \njusti\ufb01  cations (i.e. arguments) in negotiations is also a major research challenge.\nEmergence in large-scale agent systems\nWhile  still  relatively  young,  research  in  the  area  of  emergent  properties  of  large-scale \nagent systems offers insights from natural physical processes in the real world to better \nunderstand the dynamics of the increasingly large-scale arti\ufb01  cial systems now being built. \nThis approach views large-scale multi-agent systems as examples of complex, adaptive \nsystems, which are the domain of the new discipline of complexity science. As this science \nmatures, its focus on macro-scale properties of interacting entities may impact on the \ndesign, implementation and control of large-scale multi-agent systems. Approaches from 81\nChallenges\nphysics, biology and other related \ufb01  elds provide different methods to model large scale \nsystems, but it is not clear to what extent they are equivalent, and what each approach \nprovides to software engineering or system control. \nLearning and optimisation theory\nWhile  learning  and  adaptation  has  a  long  tradition  of  research,  particular  contexts \nraise new issues. In sophisticated autonomic systems, agents continually adapt to the \nenvironment of other agents, and to each other, violating the assumptions of single-agent \nlearning theories, and potentially leading to instabilities. Here, optimisation that assumes \na stationary environment also fails pathologically, and new methods must be developed. \nThe Living Systems\u00ae Adaptive Transportation Networks (LS/ATN) ap-\nplication is a cost-based optimisation system for transport logistics. \nDeveloped by Whitestein Technologies, originally for DHL, LS/ATN is \ndesigned to provide automatic optimisation for large-scale transport \ncompanies, taking into account the many constraints on their vehicle \n\ufb02  eet,  cargo,  and  drivers.  Although  the  agent  solution  accounts  for \nonly 20% of the entire system, agent technology plays a central role \nin the optimisation. Vehicle drivers send information specifying their \nlocation and proposed route, and the system determines if that vehicle \ncan collect an additional load, or swap future loads with another vehi-\ncle in order to reduce cost. A negotiation is performed automatically \nby agents, with each agent representing one vehicle, using an auc-\ntion-like protocol. The vehicle that can provide the cheapest delivery, \nwins the auction, reducing the overall cost of cargo delivery and in \nmost cases, the combined distance travelled for all vehicles. The aim \nis to \ufb01  nd a local optimum (that is, not European-wide), so that only \nvehicles travelling in close proximity to each other will be involved in \nnegotiations.\nWhitestein Technologies and Adaptive Transportation 82\nAgentLink Roadmap\nMoreover, issues such as what is meant by learning in a multi-agent context and what \nconstitutes \u201cgood\u201d learning are also important. \nMethodologies\nMany  of  today\u2019s  challenges  in  software  design  stem  from  the  distributed,  multi-actor \nnature of new software systems and the resulting change in objectives implied for software \nengineering. The development of methodologies for the design and management of multi-\nagent systems seeks to address these problems by extending current software engineering \ntechniques  to  explicitly  address  the  autonomous  nature  of  their  components  and  the \nneed for system adaptability and robustness. A wide range of methodologies have so \nfar been developed, often addressing different elements of the modelling problem or \ntaking different inspirations as their basis, yet there is no clear means of combining them \nto  reap  the  bene\ufb01  ts  of  different  approaches.  Similarly,  agent-oriented  methodologies \nstill need to be successfully integrated with prevailing methodologies from mainstream \nsoftware engineering, while at the same time taking on board new developments in other \nchallenge areas.\nProvenance \nToday\u2019s distributed environments (including Grid, web services and agent-based systems) \nsuffer from a lack of mechanisms to trace results and a lack of infrastructures to build \nup  trusted  networks.  Provenance  enables  users  to  trace  how  a  particular  result  has \nbeen achieved by identifying the individual and aggregated services that produced a \nparticular output. From both an academic and an industrial perspective, the research \nquestion is to design, formalise and implement an open provenance architecture. Such a \nprovenance architecture should be scalable and secure; it must be open and promote \ninteroperability. \nService architecture and composition \nThere  is  a  need  for  integrated  service  architectures  providing  robust  foundations  for \nautonomous behaviour, in order to support dynamic services, and important negotiation, \nmonitoring, and management patterns. This will aid application and deployment of agent \ntechnologies  to  the  Grid  and  other  domains.  While  web  service  technologies  de\ufb01  ne \nconventions  for  describing  service  interfaces  and  work\ufb02  ows,  we  need  more  powerful \ntechniques for dynamically describing, discovering, composing, monitoring, managing, \nand adapting multiple services in support of virtual organisations, for example. This is likely \nto take the form of agent-oriented architectures based on peer-to-peer or other novel \nstructures.83\nChallenges\nSemantic integration \nIn open systems, different entities will have distinct information models, demanding that \ntechniques are developed for bridging the semantic gaps between them. Advances are \nrequired in such areas as ontology de\ufb01  nition, schema mediation, and semantic mediation. \nThe challenge here is to develop \ufb02  exible models for semantic capture and integration.\n8.3 Recommendations\nThe different challenges outlined above give rise to several distinct recommendations that \ncan be made in relation to the development of the \ufb01  eld of agent-based computing. These \nrecommendations are intended to highlight the needs of the \ufb01  eld from a technological \nstandpoint, in order to support the realisation of the vision of future computing systems \nas described throughout this roadmap. They build on the recommendations provided \npreviously in (Luck et al., 2003), which provide a complementary view of  the important \nchallenges facing the \ufb01  eld.\n1. Create tools, techniques and methodologies to support agent systems developers.\n2. Automate the speci\ufb01  cation,  development and management of agent systems and \nof key components, such as protocols and virtual organisations (VOs).\n3. Integrate agent components and features to enable the different theories, technolo-\ngies and infrastructures to come together coherently. \n4. Establish appropriate trade-offs between adaptability and predictability so that agents \ncan exhibit behaviour, emergent or otherwise, that can be supported by tools and prop-\nerty veri\ufb01  cation.\n5. Establish and enhance appropriate linkages with other branches of computer science \nand with other disciplines, such as economics, sociology and biology, to draw on prior \nresearch and avoid reinvention of existing techniques and methods. \n6. Develop techniques for expressing and reasoning about trust and reputation, on both \nan individual and a social level to enable interaction in dynamic and open environ-\nments \n7. Develop procedures and methods for the automation of virtual organisation creation, \nmanagement and dissolution, together with appropriate formal representations to \nsupport their automated deployment.\n8. Develop mechanisms and protocols for automated interactions, in particular for multi-\nobjective coordination and negotiation, as well as techniques for their automated de-\nsign, implementation and management.84\nAgentLink Roadmap\n9. Provide negotiation algorithms and protocols, including capabilities for disagreement \nand reasoned justi\ufb01  cation, and determine which are most effective under different \ncircumstances. \n10.  Establish the relevance of, and techniques for, the use of complex, adaptive systems   \nin the design, implementation and control of large-scale multi-agent systems, draw-\ning on approaches from physics, biology and other related \ufb01  elds.\n11. Develop a range of new techniques for learning and optimisation in dynamic and \nunstable multi-agent environments, together with evaluation methods.\n12. Integrate techniques from the range of existing software development methodolo-\ngies, for use with autonomous agents in open environments, while addressing new \ndevelopments in the \ufb01  eld.\n13. Develop provenance mechanisms and infrastructure to trace results and build up \ntrusted networks by identifying individual agents and aggregated services in a scal-\nable, secure, open and interoperable fashion.\n14. Develop integrated service and agent architectures for dynamic services, negotia-\ntion, monitoring, and management of autonomous  adaptable organisations.\n15. Develop \ufb02  exible models for semantic information capture and integration in support \nof interoperability.85\nConclusions\n9 Conclusions\nAs just seen, agent technologies can be distinguished from other programming technologies \non the basis of their differing objectives. For agent technologies, the objectives are to create \nsystems situated in dynamic and open environments, able to adapt to these environments \nand capable of incorporating autonomous and self-interested components. How quickly \nagent technology is adopted by software developers, therefore, will depend at least partly \non how many application domains require systems with these characteristics. Considering \nthe domains receiving attention from agent software development companies such as \nAgentis, Magenta, Lost Wax or Whitestein (among others), the main areas are currently: \nlogistics, transportation, utility management and defence. Common to many of these \ndomains are multiple stakeholders or organisations linked in a network, such as a supply-\nchain, and with mission-critical, real-time processing requirements. In other words, there \nare both functional and technical requirements for these applications, a divide that agent \ntechnologies are able to bridge. \nMost  new  software  technologies  require  supporting  tools  and  methodologies.  A \nfundamental obstacle to the take-up of agent technology is the current lack of mature \nsoftware development methodologies for agent-based systems. Clearly, basic principles \nof software and knowledge engineering need to be applied to the development and \ndeployment of multi-agent systems, as with any software. This applies equally to issues of \nscalability, security, transaction management, etc, for which there are already available \nsolutions. A key challenge with agent-based computing is to augment these existing solutions \nto suit the differing demands of the new paradigm, while taking as much as possible from \nproven methods. For example, agent software development needs to draw on insights \ngained from the design of economic systems, social systems, and complex engineering \ncontrol systems. In addition, existing middleware solutions need to be leveraged as much \nas possible, and this message has been understood: several companies have been working \non platforms based on existing and standard middleware that is known and understood in \nthe commercial domain.\nIn  application  terms,  we  are  already  seeing  the  deployment  of  agent-like  systems  (in \nthe areas of pervasive computing, the Semantic Web, P2P networks, and so on). In the \nlonger term, we expect to see the industrial development of infrastructures for building \nhighly  scalable  applications  comprising  pre-existing  agents  that  must  be  organised \nor orchestrated. However, making the transition from research laboratory to deployed \nindustrial applications is indeed a challenge, and it will be important to make scienti\ufb01  cally \nsound business cases for implementations and descriptions that work as stimulators both \nfor industry adoption and for further research.86\nAgentLink Roadmap\nFor  commercial  and  industrial  systems,  agent  technologies  must  emerge  from  the \nlaboratory with a focus on business issues, on quality and on convergence with existing \nand emerging industrial technologies rather than innovation. Here, safety, reliability and \ntraditional software quality measures are equally important, and must all be addressed to \nachieve wider adoption. In particular, we need agent solutions for distributed, enterprise-\nwide  environments  with  exacting  development  requirements.  This  might  be  achieved \nthrough  transition  approaches  by  which  existing  systems  can  be  upgraded  with  a \nsuccessively increased agent presence in a seamless fashion. Wrapping legacy systems \nwithin autonomous agents situated in a larger multi-agent system is one approach that \nis  being  tried,  for  example,  in  connecting  new  and  old  telecommunications  switches \ntogether seamlessly, allowing legacy switches to be gradually replaced without major \ndisruption to the overall system. \nMore generally, the adoption of agent technologies in business environments depends on \nhow fast and how well agent technologies can be linked to existing and proven software \nand  software  methods.  Agent  technologies  should  be  targeted  at  those  application \ndomains to which they are best suited, augmenting traditional techniques that should \nbe  used  when  agents  are  not  applicable  or  appropriate.  Ultimately,  achieving  this \naim requires a commitment on the part of both business and research communities to \ncollaborate effectively in support of more effective solutions for all. Such a dialogue is \nalready underway.87\nReferences\nReferences\nT. Berners-Lee, J. Hendler and O. Lassila, The Semantic Web, Scienti\ufb01  c American, 35-43, \nMay 2001\nR. H. Bordini, M. Dastani, J. Dix, A. El Fallah Seghrouchni (Eds.), Multi-Agent Programming: \nLanguages, Platforms and Applications, Springer, 2005.\nD. Booth, H. Haas, F. McCabe, E. Newcomer, M. Champion, C. Ferris and D. Orchard, Web \nServices Architecture, W3C Working Group Note 11 February 2004, http://www.w3.org/\nTR/ws-arch/\nJ. Bot\u00eda, A. L\u00f3pez-Acosta and A. G\u00f3mez-Skarmeta, ACLAnalyser: A Tool for Debugging \nMulti-Agent Systems. In Proceedings of the Sixteenth European Conference on Arti\ufb01  cial \nIntelligence, 967\u2013968, 2004.\nS.  J.  Brams  and  A.  D.  Taylor.  Fair  Division:  From  Cake-cutting  to  Dispute  Resolution. \nCambridge University Press, 1996.\nS. Bullock and D. Cliff, Complexity and Emergent Behaviour in ICT Systems, Foresight Report, \nDTI, UK, 2004. http://www.foresight.gov.uk/Intelligent_Infrastructure_Systems/Emergent_\nBehaviour.pdf\nY.  Chevaleyre,  U.  Endriss,  J.  Lang,  and  N.  Maudet.  Negotiating  over  small  bundles  of \nresources. In Proceedings of the Fourth International Joint Conference on Autonomous \nAgents and Multiagent Systems. ACM Press, 2005.\nP. Cramton, Y. Shoham, and R. Steinberg, editors. Combinatorial Auctions. MIT Press, 2006. \nO.-J. Dahl, The roots of object orientation: the Simula language, in M. Broy and E. Denert \n(Eds.), Software Pioneers: Contributions to Software Engineering, Heidelberg, Germany, \n79\u201390, Springer, 2002.\nO.-J.  Dahl  and  K.  Nygaard,  SIMULA:  A  language  for  programming  and  description  of \ndiscrete event systems. Introduction and user\u2019s manual. Oslo, Norway: Technical Report \n11, Norwegian Computing Centre, 1965\nU. Endriss and N. Maudet. Welfare engineering in multiagent systems, in A. Omicini, P. Petta, \nand J. Pitt, editors, Engineering Societies in the Agents World IV, Lecture Notes in Arti\ufb01  cial \nIntelligence 3071, 93\u2013106, Springer, 2004.\nEuropean Commission, The Lisbon European Council: An agenda of economic and social \nrenewal for Europe. Contribution of the European commission to the Special European \nCouncil in Lisbon, 23-24th March, DOC/00/7, 2004. \nI. Foster, N. R. Jennings and C. Kesselman, Brain meets brawn: Why Grid and agents need \neach other, in Proceedings of the Third International Conference on Autonomous Agents 88\nAgentLink Roadmap\nand Multi-Agent Systems, 8\u201315, ACM Press, 2004.\nI. Foster and C. Kesselman (Eds.), The Grid 2: Blueprint for a New Computing Infrastructure, \nMorgan Kaufmann, 2004.\nY.  Fujishima,  K.  Leyton-Brown,  and  Y.  Shoham.  Taming  the  computational  complexity \nof combinatorial auctions: Optimal and approximate approaches. In Proceedings of \nthe Sixteenth International Joint Conference on Arti\ufb01  cial Intelligence, 548\u2013553, Morgan \nKaufmann Publishers, 1999.\nGartner, Hype Cycle for Application Integration and Platform Middleware, 2004a.\nGartner, Hype Cycle for Application Development, 2004b.\nGartner, Hype Cycle for Human-Computer Interaction, 2004c.\nGartner, Hype Cycle for B2B CRM Technologies, 2004d.\nGartner, Hype Cycle for the Knowledge Workplace, 2004e.\nGartner, Hype Cycle for Supply Chain Management, 2004f.\nL. Gomes, Ventures Column. Wall Street Journal, 25 February 1998. New York City, NY, USA, \n1998.\nA. Gould, S. Barker, E. Carver, D. Golby, M. Turner, BAEgrid: From e-Science to e-Engineering, \nin Proceedings of the UK e-Science All Hands Meeting, 2003.\nIDC: Worldwide Mobile Phone 2005-2009 Forecast & Analysis Report (Report 33290), May \n2005.\nInformation Age Partnership Grid Taskforce, Unlocking the Grid, 2004. www.iapuk.org\nInteragency  Working  Group  on  Information  Technology  Research  and  Development, \nGrand Challenges: Science, Engineering, and Societal Advances Requiring Networking \nand Information Technology Research and Development, National Coordination Of\ufb01  ce \nfor Information Technology Research and Development, USA, 2003. http://www.nitrd.\ngov/pubs/200311_grand_challenges.pdf\nIST Advisory Group, Software technologies, embedded systems and distributed systems: A \nEuropean strategy towards an Ambient Intelligence environment, European Commission, \n2002.\nJ. O. Kephart and D. M. Chess, The Vision of Autonomic Computing, IEEE Computer, 36(1), \n41\u201350, 2003.\nA. Ku\ufb02  ik, Computers in control: rational transfer of authority or irresponsible abdication of \nautonomy, Ethics and Information Technology, 1(3): 173\u2013184, 1999.89\nReferences\nM. Lema\u00eetre, G. Verfaillie, H. Fargier, J. Lang, N. Bataille, and J.-M. Lachiver. Equitable \nallocation of earth observing satellites resources, in Proceedings of the 5th ONERA-DLR \nAerospace Symposium, 2003.\nT. Levitt, Exploit the Product Life Cycle. Harvard Business Review, 43(6): 81\u201394, 1965.\nG.  L.  Lilien,  P.  Kotler  and  K.  S.  Moorthy,  Marketing  Models.  Englewood  Cliffs,  NJ,  USA: \nPrentice-Hall, 1992.\nM.  Luck,  P.  McBurney  and  C.  Preist,  Agent  Technology:  Enabling  Next  Generation \nComputing (A Roadmap for Agent Based Computing), AgentLink, 2003.\nM. Luck, P. McBurney and C. Preist, A Manifesto for Agent Technology: Towards Next \nGeneration Computing, Journal of Autonomous Agents and Multi-Agent Systems, 9(3), \n203\u2013252, 2004a.\nM. Luck, R. Ashri and M. d\u2019Inverno, Agent-Based Software Development, Artech House, \n2004b.\nV. Mahajan, E. Muller and F. M. Bass, New-product diffusion models, in J. Eliashberg and G. \nL. Lilien (Eds.), in Handbooks in Operations Research and Management Science, Volume \n5: Marketing, 349\u2013408, North-Holland, 1993.\nP.  McBurney,  S.  Parsons  and  J.  Green,  Forecasting  market  demand  for  new \ntelecommunications services: an introduction, Telematics and Informatics, 19(3): 225\u2013\n249, 2002.\nJ. McKean, H. Shorter, P. McBurney and M. Luck, The AgentLink III Technology Diffusion \nModel. Technical Report ULCS-05-008, Department of Computer Science, University of \nLiverpool, UK, 2005.\nD. F. Midgley, Innovation and New Product Marketing. London, UK, Croom Helm,1977.\nD. S. Milojicic, V. Kalogeraki, R. Lukose, Rajan, K. Nagaraja, J. Pruyne, B. Richard, S. Rollins \nand Z. Xu, Peer-to-Peer Computing, HP Technical report HPL-2002-57, 2002.\nG. A. Moore, Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream \nConsumers, HarperCollins, 1991.\nS. Munroe, M. Luck and P. McBurney, The AgentLink III Deliberative Delphi Survey. Technical \nReport. Department of Electronics and Computer Science, University of Southampton, \nUK, 2005.\nThe Netherlands Ministry for Economic Affairs, Directorate-General for Telecommunications \nand Post, Rethinking the European ICT Agenda: Ten ICT-breakthroughs for Reaching \nLisbon Goals, 2004.90\nAgentLink Roadmap\nC. Perez, Technological Revolutions and Financial Capital: The Dynamics of Bubbles and \nGolden Ages, Edward Elgar, 2002.\nR. Phaal, C. Farrukh and D. Probert, Technology roadmapping\u2014a planning framework for \nevolution and revolution. Technological Forecasting and Social Change, 71: 5\u201326, 2004.\nE. M. Rogers, Diffusion of Innovations. New York City, NY, USA: The Free Press,1962.\nUK Computing Research Committee, Grand Challenges in Computing Research, The British \nComputer Society, 2004. http://www.ukcrc.org/grand_challenges/\nG. L. Urban and J. R. Hauser, Design and Marketing of New Products, Prentice-Hall, 1993\nT. Weitzel, Economics of Standards in Information Networks. Information Age Economy \nSeries. Heidelberg, Germany: Physica, 2004.\nF. von Westarp, Modeling Software Markets: Empirical Analysis, Network Simulations, and \nMarketing Implications. Information Age Economy Series, Physica, 2003.\nF. Zambonelli and H. V. Parunak, Signs of a revolution in computer science and software \nengineering, in P. Petta, R. Tolksdorf and F. Zambonelli (Eds.), Engineering Societies for the \nAgents World, Lecture Notes in Arti\ufb01  cial Intelligence 2577, 13\u201328, Springer, 2002. 91\nGlossary\nGlossary\nANSI    American National Standards Institute\nB2B    Business to business\nBDI    Belief-Desire-Intention (typically of agent architectures)\nBluetooth  Short range wireless connectivity standard\nCASE    Computer Aided Software Engineering\nCERN    European Organisation for Nuclear Research\nCORBA   Common Object Request Broker Architecture\nebXML    Electronic Business using eXtensible Markup Language\nFIPA    Foundation for Intelligent Physical Agents\nGGF    Global Grid Forum\nHTML    HyperText Markup Language\nHTTP    HyperText Transfer Protocol\nIDE    Integrated Development Environment\nJADE    Java Agent DEvelopment Framework\nJini    Open architecture enabling adaptive network-centric services \nJXTA    Open protocols allowing devices to communicate in a P2P manner\nOASIS    Organization for the Advancement of Structured Information Standards\nOMG    Object Management Group\nOOPSLA  Object-Oriented Programming, Systems, Langauges and Applications\nOODBS   Object-Oriented Database Systems\nP2P    Peer-to-Peer\nRDF    Resource Description Format\nRosettaNet  Industry consortium developing standards for collaborative commerce\nSOA    Service-oriented architecture\nSOAP    Simple Object Access Protocol\nTCP    Transmission Control Protocol\nUDDI    Universal Description, Discovery and Integration\nUDP    User Datagram Protocol\nUML    Uni\ufb01  ed Modelling Language\nUPnP    Universal Plug and Play\nWSDL    Web Service Description Language\nWS-CDL   Web Services Choreography Description Language\nWS-R    Web Services \u2014 Reliability\nW3C    World Wide Web Consortium\nXML    eXtensible Markup Language92\nAgentLink Roadmap93\nWeb Resources\nWeb Resources and URLs\nAgentLink          www.agentlink.org\nAutonomic Computing        www.ibm.com/autonomic\nBluetooth          www.bluetooth.com\nCORBA           www.corba.org\nebXML            www.ebxml.org\nEuropean Commission        www.cordis.lu\nFoundation for Intellient Physical Agents    www.\ufb01  pa.org\nGlobal Computing        www.cordis.lu/ist/fet/gc.htm\nGlobal Grid Forum        www.ggf.org\nInformation Society Technologies      www.cordis.lu/ist\nInternet Engineering Task Force      www.ietf.org\nJADE            jade.tilab.com\nJini            www.jini.org\nJXTA            www.jxta.org\nN1            www.sun.com/n1\nOASIS             www.oasis-open.org\nObject Management Group      www.omg.org\nRosettaNet          www.rosettanet.org\nUDDI            www.uddi.org\nUML            www.uml.org\nUPnP            www.upnp.org\nWorld Wide Web Consortium      www.w3c.org\nXML            www.xml.org\nCompanies Mentioned\nAcklin            www.acklin.nl\nAgentis Software Inc        www.agentissoftware.com\nCalico Jack          www.calicojack.co.uk\nMagenta Technology        www.magenta-technology.com\nEurobios          www.eurobios.com\nLost Wax          www.lostwax.com\nNutech Solutions        www.nutechsolutions.com\nWhitestein Technologies       www.whitestein.com94\nAgentLink Roadmap95\nMethodology\nMethodology\nIn January 2004, a core roadmapping group was set up within AgentLink III, including \nMichael Luck, Peter McBurney and Onn Shehory, to oversee the development of this \nroadmap. Subsequently Steven Willmott joined the core team, which aimed to lead a \nprogramme of review, discussion, consultation and debate across the \ufb01  rst 18 months of \nAgentLink III.\nThe programme established was determined by three key timepoints at which documents \nwould be produced: at 12 months with the initial Consultation Report that would be used \nfor placing a marker in the community as a means of eliciting contributions and comment; \nat 18 months with the Roadmap Draft, which would essentially be the complete document \navailable for detailed analysis and discussion, both by targeted reviewers, and by the \ngeneral community; and at 21 months, when the \ufb01  nal document would be printed and \nwidely distributed for maximum impact. These three key points delimit the three stages of \nroadmap development.\nFigure A.1: Stages of  roadmap development\nConsultation\nReport\nDecember\n2004\nJune\n2005\nSeptember\n2005\nAnalysis and Consultation\nTime\nTechnology diffusion\nModelling and \nDelphi study\nReview \nand \nRefinement \nDissemination\nA\nu\nd\ni\ne\nn\nc\ne\nRoadmap \nDraft\nFinal\nRoadmap 96\nAgentLink Roadmap\nStage 1: The initial effort on roadmapping was primarily devoted to analysing the \ufb01  eld \nof agent-based computing, as well as related \ufb01  elds, to determine the prevalent trends \nand  drivers,  and  providing  a  broad  assessment  of  the  state-of-the-art  in  the  research \nand development spheres. This involved both desk research on reports and papers, and \ndiscussion with leading thinkers at a range of important and relevant conferences, and \nculminated in the production of the consultation report, which was distributed with calls \nfor contributions and participation. In addition, initial planning for two novel exercises was \nundertaken, on the Deliberative Delphi study, and on developing the technology diffusion \nmodel.\nStage 2: After the Consultation Report was published, inputs from the AgentLink Technical \nForum Groups and the wider community were solicited, and several presentations given, \noutlining  the  roadmapping  process  and  the  need  for  further  efforts.  The  Deliberative \nDelphi study and the technology diffusion model were completed, and compiled into the \nRoadmap Draft, which is currently being distributed. \nStage 3: During the summer months, and until the end of August 2005, further speci\ufb01  c \ncomments and additions were considered, focussed by this document. By October, the \n\ufb01  nal revised document will be published, and will be widely distributed, both in print and \nelectronic form. Results and conclusions will be presented to the broader community. This \nstage is intended to re\ufb01  ne speci\ufb01  c content in relation to details of the challenges and \ntimelines presented, and represents the \ufb01  nal opportunity for the community to contribute.97\nAgentLink Members\nAgentLink Members\nFull Members\n[As of September 2005]\nSalzburg Research Forschungsgesellschaft mbH       Austria\nAustrian Research Institute for Arti\ufb01  cal Intelligence     Austria\nCETIC                Belgium\nK.U.Leuven              Belgium\nVrijie Universiteit Brussel             Belgium\nFacult\u00e9s Universitaires Notre-Dam de la Paix       Belgium\nSelf-Star Technologies             Belgium\nCzech Technical University           Czech Republic\nCertiCon AS               Czech Republic\nNeuroAgent Ltd             Finland\nUTBM                 France\nUniversity Paris Dauphine           France\nInstitut de Recherche en Infomatique de Toulouse    France\nTeam MAIA               France\nFrance Telecom SA             France\nLCIS Research Laborbatory           France\nInstitut National Polytechnique de Grenoble       France\nUniversity Toulouse 1             France\nLIRIS-CNRS, Universit\u00e9 Claude Bernard-Lyon 1       France\nLIP6 University Paris 6             France\nLIFL - University of Lille 1             France\nLIPN - CNRS UMR             France\nEADS Centre Commun de Recherche         France\nMASA-SCI               France\nUniversit\u00e9 de Pau et de A\u2019dour           France\nEcole Nationale Superieure des Mines de Saint-Etiene     France\nLIRMM - Universite de Montpellier II         France\nSiemens AG Corporate Technology         Germany\nFreie Universit\u00e4t Berlin             Germany98\nAgentLink Roadmap\nThe Agent Factory GmbH           Germany\nFriedrich-Schiller-Universit\u00e4t Jena           Germany\nTechnical University of Clausthal          Germany\nUniversit\u00e4t Hohenheim            Germany\nDeutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz     Germany\nUniversity of Hamburg             Germany\nTechnische Universit\u00e4t Dresden           Germany\nTechnische Universit\u00e4t Muenchen         Germany\nUniversity of Karlsruhe              Germany\nUniversity of Bremen,             Germany\nTechnical University of Aachen           Germany\nUniversity of Augsburg             Germany\nCadence Design Systems GmbH         Germany\nFrauhofer Institut fur Informations - und Datenverarbeitung  Germany\nUniversity of Rostock             Germany\nTechnische Universit\u00e4t Berlin          Germany\nUniversity of Bayreuth             Germany\nHumboldt University at Berlin            Germany\nUniversity of Duisburg-Essen           Germany\nDAI-Labor, Technische Universitaet Berlin        Germany\nUniversity of Applied Sciences          Germany\nCITY College, Af\ufb01  liated Institution of the University of Shef\ufb01  eld   Greece\nUniversity of Thessaly             Greece\nThe Centre for Research and Technology Hellas       Greece\nUniversity of Aegean             Greece\nTechnical University of Crete           Greece\nHungarian Academy of Sciences         Hungary\nAITIA Inc.               Hungary\nUniversity College Dublin           Ireland\nIBM Israel               Israel\nHebrew University of Jerusalem          Israel\nBar-Ilan University             Israel\nBen-Gurion University of the Negev         Israel\nUniversit\u00e0 di Bologna             Italy\nUniversity of Trento            Italy99\nAgentLink Members\nUniversity of Brescia             Italy\nIstituto di Calcolo e Reti ad Alte Prestazioni (ICAR-CNR)     Italy\nUniversity of Modena and Reggio Emilia        Italy\nDIMET, Universit\u00e0 Mediterranea di Reggio Calabria    Italy\nUniversit\u00e0 di Torino             Italy\nUniversit\u00e0 della Calabria           Italy\nUniversit\u00e0 degli Studi Di Genova          Italy\nUniversit\u00e0 degli Studi di Parma           Italy\nUniversity of Ferrara             Italy\nUniversity of Udine            Italy\nITC-irst (Istituto per la Ricerca Scienti\ufb01  ca e Technologica)    Italy\nPolitecnico di Milano             Italy\nUniversit\u00e0 degli Studi di L\u2019Aquila           Italy\nUniversit\u00e0 Politecnica delle Marche         Italy\nUniversity of Bari             Italy\nUniversity of Cagliari             Italy\nUniversit\u00e0 di Padova             Italy\nFiat Research Center             Italy\nTelecom Italia               Italy\nInstitute of Cognitive Sciences and Technology, CNR    Italy\nUniversity of Milan-Bicocca           Italy\nUniversita di Camerino             Italy\nUniversity of Catania            Italy\nInstitute of Computer Science, Polish Academy of Sciences   Poland\nInstitute of Comuter Science, Jagiellonian University    Poland\nUniversity of Warsaw            Poland\nInstituto de Desenvolvimento e Inova\u00e7\u00e4o Technol\u00f3gica     Portugal\nInstituto Superior de Engenharia do Porto       Portugal\nUniversidade Do Porto             Portugal\nUniversidade de Lisboa             Portugal\nInstituto Polit\u00e9cnico de Bragan\u00e7a         Portugal\nUniversidade Nova de Lisboa           Portugal\nUniversity Petroleum-Gas from Ploiesti         Romania\nWest University of Timisoara           Romania\nLucian Blaga University, Sibiu, Romania         Romania\nUniversity \u201c Politehnica\u201d of Burcharest         Romania\nWittmann & Partner Computer Systems S.R.L       Romania100\nAgentLink Roadmap\nTechnical University of Cluj-Napoca         Romania\nBabes-Bolyai University            Romania\nSt Petersburg Institute For Infomatics and Automation     Russia\nMoscow Institute of Physics and Technology (MIPT)    Russia\nUniversity of Maribor             Slovenia\nInstitute Jozef Stefan             Slovenia\nUniversitat Polit\u00e8cnica de Catalunya         Spain\nUniversity of Girona             Spain\nUniversidad Rey Juan Carlos           Spain\nUniversidad Complutense Madrid         Spain\nInstitut d\u2019Investigaci\u00f3 en Intel.lig\u00e8ncia Arti\ufb01  cial       Spain\nUniversidad de Murcia             Spain\nTechnical University of Madrid           Spain\nUniversidad Polit\u00e9cnica de Valencia         Spain\nUniversitat Rovira I Virgili            Spain\nAgents Inspired Technologies SA                      Spain\nUniversity of Vigo             Spain\nUniversitat Autonoma de Barcelona         Spain\nUniversity of Zaragoza             Spain\nMicroArt               Spain\nUniversity of Barcelona             Spain\nSemantic Systems, SA             Spain\nStockholm University            Sweden\nSwedish Institute of Computer Science         Sweden\nBlekinge Institute of Technology           Sweden\nOrebro University             Sweden\nRoyal Institute of Technology          Sweden\nWhitestein Technologies AG           Switzerland\nUniversity of Geneva             Switzerland\nSavannah Simulations             Switzerland\nAcklin BV              The Netherlands\nTryllian Solutions BV             The Netherlands\nNederlands Organisation for Applied Scienti\ufb01  c Research TNO   The Netherlands\nCentrum voor Wiskunde en Informatica         The Netherlands101\nAgentLink Members\nRijksunversiteit Groningen           The Netherlands\nAlmende b.v.               The Netherlands\nVrije Universiteit Amsterdam           The Netherlands\nUniversity of Amsterdam            The Netherlands\nMorpheus Software             The Netherlands\nDECIS Lab               The Netherlands\nUniversity of Twente             The Netherlands\nMP Objects               The Netherlands\nDelft University of Technology           The Netherlands\nErasmus University Rotterdam           The Netherlands\nUtrecht University             The Netherland\nINITI8                 The Netherlands\nUniversiteit Maastricht             The Netherlands\nY\u2019All                The Netherlands\nBogazici University             Turkey\nEge University               Turkey\nUniversity of Liverpool             United Kingdom\nUniversity of Southampton           United Kingdom\nBritish Telecommunications plc           United Kingdom\nUniversity of Nottingham           United Kingdom\nCity University, London             United Kingdom\nUniversity of Warwick            United Kingdom\nAgent Oriented Software Limited         United Kingdom\nMagenta Technology             United Kingdom\nUniversity of Bath             United Kingdom\nAdvanced Computation Lab, Cancer Research UK     United Kingdom\nUniversity of Surrey             United Kingdom\nManchester Metropolitan University         United Kingdom\nDe Montfort University             United Kingdom\nEurobios               United Kingdom\nUniversity of East London           United Kingdom\nCalico Jack Ltd              United Kingdom\nKing\u2019s college London             United Kingdom\nUniversity of Dundee             United Kingdom\nShef\ufb01  eld Hallam University           United Kingdom\nCardiff University             United Kingdom\nOxford Brookes University           United Kingdom\nQueen Mary & West\ufb01  eld College, University of London     United Kingdom102\nAgentLink Roadmap\nUMIST                 United Kingdom\nGeneral Dynamics (UK) Ltd           United Kingdom\nSchool of Law, Edinburgh University         United Kingdom\nUniversity of Bradford             United Kingdom\nLost Wax Media Ltd             United Kingdom\nGlaxoSmithKline             United Kingdom\nThe University of Edinburgh          United Kingdom\nAgentis Software             United Kingdom\nEDS Defense Ltd             United Kingdom\nUniversity College London           United Kingdom\nUniversity of Aberdeen             United Kingdom\nUniversity of Durham             United Kingdom\niSTRAT                 United Kingdom\nUniversity of York             United Kingdom\nThe Macaulay Institute             United Kingdom\nCambridge Consultants Ltd           United Kingdom\nVodafone Group R&D            United Kingdom\nAumega Networks            United Kingdom103\nAcknowledgements\nAcknowledgements and Information Sources\nAgentLink would like to thank all the organisations and individuals who have contributed, \ndirectly or indirectly in providing content and opinion in the development of this document \nand of the activities that will take place in the future: \nUniversity  of  Southampton;  University  of  Liverpool;  European  Commission;  Institut \nd\u2019Investigaci\u00f3  en  Intel.lig\u00e8ncia  Arti\ufb01  cial,  CSIC;  Universitat  Polit\u00e8cnica  de  Catalunya; \nInternational Joint Conference on Autonomous Agents and Multi-Agent Systems, 2004 \nand 2005; European Conference on Arti\ufb01  cial Intelligence, 2004; European Workshop on \nMulti-Agent Systems, 2004; IEEE Systems, Man and Cybernetics Conference, 2004; IEEE/\nWIC/ACM  International  Joint  Conference  on  Web  Intelligence  and  Intelligent  Agent \nTechnology, 2005. \nAgentLink Technical Forum Groups\nAgent-Oriented Software Engineering; Agents in Bioinformatics\nAgents Applied in Healthcare\nEnvironments for MAS\nIntelligent Information Agents for Web Economies\nLaw and Electronic Agents; Multi-Agent Resource Allocation\nNetworked Agents\nProgramming Multi-Agent Systems\nSelf-Organisation in Multi-Agent Systems\nTowards Semantic Web Agents\nTrust for Open Collaborative Agent Business Environments\nCoordinating Agent Standardisation Activities\nTowards a Standard Agent-to-Agent Argumentation Interchange Format.\nAgentLink Roadmap Development\nCore Team \nMichael Luck    University of Southampton, UK \nPeter McBurney   University of Liverpool, UK \nOnn Shehory    IBM, Israel \nSteven Willmott    Universitat Polit\u00e8cnica de Catalunya, Spain\nAgentLink Support \nCatherine Atherton  University of Liverpool, UK \nRebecca Earl     University of Southampton, UK\nAdele Maggs    University of Liverpool, UK \nSerena Raf\ufb01  n    University of Southampton, UK104\nAgentLink Roadmap\nAgentLink Management Committee \nMonique Calisti    Whitestein Technologies, Switzerland\nWiebe van der Hoek  University of Liverpool, UK\nMichael Luck    University of Southampton, UK \nPeter McBurney   University of Liverpool, UK\nJ\u00f6rg M\u00fcller    Siemens AG Corporate Technology, Germany\nAndrea Omicini   University di Bologna, Italy\nTerry Payne     University of Southampton, UK \nMichal P\u011bchou\u010dek  Czech Technical University, Czech Republic\nOnn Shehory    IBM, Israel\nSimon Thompson  British Telecom, UK\nSteven Willmott    Universitat Polit\u00e8cnica de Catalunya, Spain\nMike Wooldridge  University of Liverpool, UK\nOther Contributors \nChris van Aart    Y\u2019All, The Netherlands\nRonald Ashri     University of Southampton, UK\nPetr Becvar    CertiCon, Czech Republic\nRoxana Belecheanu  University of Southampton, UK\nFabio Bellifemine  Telecom Italia, Italy\nMichael Berger    Siemens AG Corporate Technology, Germany\nCarole Bernon    Universit\u00e9 Paul Sabatier, France\nRafael Bordini    University of Durham, UK\nFrancesco Buccafurri  Universit\u00e0 degli Studi Mediterranea di Reggio Calabria, Italy\nStefan Bussmann   Daimler Chrysler AG Research and Technology, Germany\nVal\u00e9rie Camps    Universit\u00e9 Paul Sabatier, France\nCarlos Carrascosa   Universidad Polit\u00e9cnica de Valencia, Spain\nCristiano Castelfranchi   University of Siena, Italy\nYann Chevaleyre   Universit\u00e9 Paris Dauphine, France\nHelder Coelho    Universitade Nova De Lisboa, Portugal\nUlises Cortes    Universitat Polit\u00e8cnica de Catalunya, Spain\nVince Darley    Eurobios, UK\nJoris Deguet     Laboratoire Leibniz, France\nMark d\u2019Inverno    University of Westminster, UK\nEd Durfee    University of Michigan, USA\nErik van Eekelen   MP Objects, The Netherlands\nUlle Endriss    Imperial College London, UK\nSylvia Estivie     Universit\u00e9 Paris Dauphine, France\nMichel Fabien    Universit\u00e9 Montpellier II, France\nMartyn Fletcher   Agent Oriented Software Ltd, UK105\nAcknowledgements\nJean-Pierre George  Universit\u00e9 Paul Sabatier, France\nMarie-Pierre Gleizes  Universit\u00e9 Paul Sabatier, France\nPierre Glize    Universit\u00e9 Paul Sabatier, France\nNathan Grif\ufb01  ths    University of Warwick, UK\nChristian Herneth  Capgemini, Austria\nJon Himoff    Magenta Technology, UK\nGabriel Hopmans  Universiteit Maastricht, The Netherlands\nNick Jennings    University of Southampton, UK\nMenno Jonkers    Tryllian, The Netherlands\nAnthony Karageorgos  University of Thessaly, Greece\nDavid Kinny    Agentis Software, USA\nStefan Kirn    University of Hohenheim, Germany\nMagdalena Koralewska Jagiellonian University of Krakow, Poland\nElfriede Krauth    Erasmus University, The Netherlands\nHabin Lee    British Telecom, UK\nMichel Lemaitre   ONERA/DCSD/CD Centre de Toulouse, France\nVictor Lesser     University of Massachusetts, USA\nBeatriz Lopez    Universitat de Girona, Spain\nVincent Louis    France Telecom, France\nVladimir Ma\u0159\u00edk    Rockwell Automation, Czech Republic\nPaul Marrow    BT Pervasive ICT Research Centre, UK\nThierry Martinez    France Telecom, France\nGiovanna Di Marzo Serugendo  University of Geneva, Switzerland\nViviana Mascardi  University of Genova, Italy\nNicolas Maudet   Universit\u00e9 Paris Dauphine, France\nJez McKean     Jazzle, UK \nAndre Meyer    TNO & DECIS, The Netherlands\nAmbra Molesini    Universit\u00e0 degli Studi di Bologna, Italy\nLuc Moreau    University of Southampton, UK\nSteve Munroe    University of Southampton, UK\nPablo Noriega    Institut d\u2019Investigaci\u00f3 en Intel.lig\u00e8ncia Arti\ufb01  cial, Spain\nTim Norman    University of Aberdeen, UK\nPeter Novak    Technical University of Clausthal, Germany\nAnn Nowe    Vrije Universiteit, Belgium\nJames Odell    Agentis Software, USA\nEug\u00e9nio Oliviera   Universidade do Porto, Portugal\nSteve Osborn    Lost Wax, UK\nSascha Ossowski  Universidad Rey Juan Carlos, Spain\nLin Padgham    RMIT, Australia\nSimon Parsons    City University of New York, USA106\nAgentLink Roadmap\nJuan Pavon    Universidad Complutense, Spain\nCarlota Perez    University of Cambridge and University of Sussex, UK\nGauthier Picard   Universit\u00e9 Paul Sabatier, France\nEric Platon    University of Tokyo, Japan\nAgostino Poggi    Universit\u00e0 degli Studi di Parma, Italy \nChris Preist    HP Laboratories, UK\nChris Reed    Calico Jack, UK\nJuan A. Rodriguez  Institut d\u2019Investigaci\u00f3 en Intel.lig\u00e8ncia Arti\ufb01  cial, Spain\nJosep Lluis de la Rosa  Universitat de Girona, Spain\nJeff Rosenschein  Hebrew University of Jerusalem, Israel\nNicolas Sabouret  Universit\u00e9 Pierre et Marie Curie, France\nCalin Sandru     West University of Timisoara, Romania\nJorge Gomez Sanz  Universidad Complutense de Madrid\nHayden Shorter    AePONA, UK\nCarles Sierra    Institut d\u2019Investigaci\u00f3 en Intel.lig\u00e8ncia Arti\ufb01  cial, Spain\nMunindar Singh    North Carolina State University, USA\nLiz Sonenberg    University of Melbourne, Australia\nPaulo Sousa    Instituto Superior de Engenharia do Porto, Portugal\nJames Spillings    General Dynamics, UK\nRebecca Steliaros  Engineering and Physical Sciences Research Council, UK\nSusan Marie Thomas  SAP, Germany\nFilip Verhaeghe   Self-Star Corporation, Belgium\nGeorge Vouros    University of the Aegean, Greece\nGeorge Weichhart  Profactor Produktionsforschungs GmbH, Austria\nDanny Weyns    Katholieke Universiteit Leuven, Belgium\nMichael Wooldridge  University of Liverpool, UK\nNadezhda Yakounina   Magenta Technology, UK\nMakoto Yokoo    University of Kyushu, Japan107\nAcknowledgements108\nAgentLink RoadmapContact Information                                                                      \nPublished by the University of Southampton on behalf of AgentLink III.\nContact:  Prof Michael Luck\nSchool of Electronics and Computer Science\nUniversity of Southampton\nSouthampton SO17 1BJ\nUnited Kingdom\nmml@ecs.soton.ac.uk\n+44 23 8059 6657\nIf your organisation would like to develop particular technology roadmaps that relates to the technologies and knowl-\nedge in this document, contact Michael Luck at the address above.\n\u00a9 2005 AgentLink. Reproduction of this publication without prior permission is forbidden. The information contained \nhere has been obtained from sources believed to be reliable. AgentLink disclaims all warranties as to the accuracy, \ncompleteness or adequacy of such information. AgentLink shall have no liability for errors, omissions or inadequacies \nin the information. The opinions expressed are subject to change without notice.\nAgentLink III is a Coordination Action funded by the European Commission in  Semantic-Based Knowledge Systems\n(Project Reference: IST 002006)\nDesigned and typeset by Serena Raf\ufb01n. ISBN 0854 328459",
      "id": 449583,
      "identifiers": [
        {
          "identifier": "oai:eprints.soton.ac.uk:261788",
          "type": "OAI_ID"
        },
        {
          "identifier": "oai:kclpure.kcl.ac.uk:publications/c0d665e0-8f2a-4dfa-8eaa-673ea861fe89",
          "type": "OAI_ID"
        },
        {
          "identifier": "586904129",
          "type": "CORE_ID"
        },
        {
          "identifier": "1505312",
          "type": "CORE_ID"
        },
        {
          "identifier": "29914283",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:pure.atira.dk:publications/c0d665e0-8f2a-4dfa-8eaa-673ea861fe89",
          "type": "OAI_ID"
        }
      ],
      "title": "Agent Technology: Computing as Interaction (A Roadmap for Agent Based Computing)",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:pure.atira.dk:publications/c0d665e0-8f2a-4dfa-8eaa-673ea861fe89",
        "oai:eprints.soton.ac.uk:261788",
        "oai:kclpure.kcl.ac.uk:publications/c0d665e0-8f2a-4dfa-8eaa-673ea861fe89"
      ],
      "publishedDate": "2005-01-01T00:00:00",
      "publisher": "'University of Southampton'",
      "pubmedId": null,
      "references": [
        {
          "id": 36125427,
          "title": "A Manifesto for Agent Technology: Towards Next Generation Computing,",
          "authors": [],
          "date": null,
          "doi": "10.1023/b:agnt.0000038027.29035.7c",
          "raw": "M. Luck, P. McBurney and C. Preist, A Manifesto for Agent Technology: Towards Next Generation Computing, Journal of Autonomous Agents and Multi-Agent Systems, 9(3), 203\u2013252, 2004a.",
          "cites": null
        },
        {
          "id": 36125426,
          "title": "Agent Technology: Enabling Next Generation Computing (A Roadmap for Agent Based Computing),",
          "authors": [],
          "date": "2003",
          "doi": "10.1023/b:agnt.0000038027.29035.7c",
          "raw": "M.  Luck,  P.  McBurney  and  C.  Preist,  Agent  Technology:  Enabling  Next  Generation Computing (A Roadmap for Agent Based Computing), AgentLink, 2003.",
          "cites": null
        },
        {
          "id": 36125428,
          "title": "Agent-Based Software Development, Artech House,",
          "authors": [],
          "date": "2004",
          "doi": "10.1007/3-540-45634-1_6",
          "raw": "M. Luck, R. Ashri and M. d\u2019Inverno, Agent-Based Software Development, Artech House, 2004b.",
          "cites": null
        },
        {
          "id": 36125434,
          "title": "Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream Consumers,",
          "authors": [],
          "date": "1991",
          "doi": null,
          "raw": "G. A. Moore, Crossing the Chasm: Marketing and Selling High-Tech Products to Mainstream Consumers, HarperCollins, 1991.",
          "cites": null
        },
        {
          "id": 36125437,
          "title": "Diffusion of Innovations.",
          "authors": [],
          "date": null,
          "doi": "10.1016/b0-08-043076-7/03094-1",
          "raw": "E. M. Rogers, Diffusion of Innovations. New York City, NY, USA: The Free Press,1962.",
          "cites": null
        },
        {
          "id": 36125423,
          "title": "Equitable allocation of earth observing satellites resources,",
          "authors": [],
          "date": "2003",
          "doi": null,
          "raw": "M. Lema\u00eetre, G. Verfaillie, H. Fargier, J. Lang, N. Bataille, and J.-M. Lachiver. Equitable allocation of earth observing satellites resources, in Proceedings of the 5th ONERA-DLR Aerospace Symposium, 2003.",
          "cites": null
        },
        {
          "id": 36125424,
          "title": "Exploit the Product Life Cycle.",
          "authors": [],
          "date": "1965",
          "doi": null,
          "raw": "T. Levitt, Exploit the Product Life Cycle. Harvard Business Review, 43(6): 81\u201394, 1965.",
          "cites": null
        },
        {
          "id": 36125430,
          "title": "Forecasting market demand for new telecommunications services: an introduction,",
          "authors": [],
          "date": "2002",
          "doi": "10.1016/s0736-5853(01)00004-1",
          "raw": "P.  McBurney,  S.  Parsons  and  J.  Green,  Forecasting  market  demand  for  new telecommunications services: an introduction, Telematics and Informatics, 19(3): 225\u2013 249, 2002.",
          "cites": null
        },
        {
          "id": 36125432,
          "title": "Innovation and New Product Marketing.",
          "authors": [],
          "date": null,
          "doi": "10.2307/1250339",
          "raw": "D. F. Midgley, Innovation and New Product Marketing. London, UK, Croom Helm,1977.",
          "cites": null
        },
        {
          "id": 36125425,
          "title": "Marketing Models. Englewood Cliffs,",
          "authors": [],
          "date": "1992",
          "doi": null,
          "raw": "G.  L.  Lilien,  P.  Kotler  and  K.  S.  Moorthy,  Marketing  Models.  Englewood  Cliffs,  NJ,  USA: Prentice-Hall, 1992.",
          "cites": null
        },
        {
          "id": 36125439,
          "title": "Modeling Software Markets: Empirical Analysis, Network Simulations, and Marketing Implications. Information Age Economy Series,",
          "authors": [],
          "date": "2003",
          "doi": "10.1007/978-3-642-57377-4_3",
          "raw": "F. von Westarp, Modeling Software Markets: Empirical Analysis, Network Simulations, and Marketing Implications. Information Age Economy Series, Physica, 2003.",
          "cites": null
        },
        {
          "id": 36125429,
          "title": "New-product diffusion models,",
          "authors": [],
          "date": "1993",
          "doi": "10.1016/s0927-0507(05)80031-3",
          "raw": "V. Mahajan, E. Muller and F. M. Bass, New-product diffusion models, in J. Eliashberg and G. L. Lilien (Eds.), in Handbooks in Operations Research and Management Science, Volume 5: Marketing, 349\u2013408, North-Holland, 1993.",
          "cites": null
        },
        {
          "id": 36125433,
          "title": "Peer-to-Peer Computing, HP",
          "authors": [],
          "date": "2002",
          "doi": null,
          "raw": "D. S. Milojicic, V. Kalogeraki, R. Lukose, Rajan, K. Nagaraja, J. Pruyne, B. Richard, S. Rollins and Z. Xu, Peer-to-Peer Computing, HP Technical report HPL-2002-57, 2002.",
          "cites": null
        },
        {
          "id": 36125438,
          "title": "Research Committee, Grand Challenges in Computing Research, The British Computer Society,",
          "authors": [],
          "date": "2004",
          "doi": null,
          "raw": "UK Computing Research Committee, Grand Challenges in Computing Research, The British Computer Society, 2004. http://www.ukcrc.org/grand_challenges/ G. L. Urban and J. R. Hauser, Design and Marketing of New Products, Prentice-Hall, 1993 T. Weitzel, Economics of Standards in Information Networks. Information Age Economy Series. Heidelberg, Germany: Physica, 2004.",
          "cites": null
        },
        {
          "id": 36125440,
          "title": "Signs of a revolution in computer science and software",
          "authors": [],
          "date": "2002",
          "doi": "10.1007/3-540-39173-8_2",
          "raw": "F. Zambonelli and H. V. Parunak, Signs of a revolution in computer science and software engineering, in P. Petta, R. Tolksdorf and F. Zambonelli (Eds.), Engineering Societies for the Agents World, Lecture Notes in Arti\ufb01  cial Intelligence 2577, 13\u201328, Springer, 2002. 91 Glossary Glossary ANSI    American National Standards Institute B2B    Business to business BDI    Belief-Desire-Intention (typically of agent architectures) Bluetooth  Short range wireless connectivity standard CASE    Computer Aided Software Engineering CERN    European Organisation for Nuclear Research CORBA   Common Object Request Broker Architecture ebXML    Electronic Business using eXtensible Markup Language FIPA    Foundation for Intelligent Physical Agents GGF    Global Grid Forum HTML    HyperText Markup Language HTTP    HyperText Transfer Protocol IDE    Integrated Development Environment JADE    Java Agent DEvelopment Framework Jini    Open architecture enabling adaptive network-centric services JXTA    Open protocols allowing devices to communicate in a P2P manner OASIS    Organization for the Advancement of Structured Information Standards OMG    Object Management Group OOPSLA  Object-Oriented Programming, Systems, Langauges and Applications OODBS   Object-Oriented Database Systems P2P    Peer-to-Peer RDF    Resource Description Format RosettaNet  Industry consortium developing standards for collaborative commerce SOA    Service-oriented architecture SOAP    Simple Object Access Protocol TCP    Transmission Control Protocol UDDI    Universal Description, Discovery and Integration UDP    User Datagram Protocol UML    Uni\ufb01  ed Modelling Language UPnP    Universal Plug and Play WSDL    Web Service Description Language WS-CDL   Web Services Choreography Description Language WS-R    Web Services \u2014 Reliability W3C    World Wide Web Consortium XML    eXtensible Markup Language92 AgentLink Roadmap93 Web Resources Web Resources and URLs AgentLink          www.agentlink.org Autonomic Computing        www.ibm.com/autonomic Bluetooth          www.bluetooth.com CORBA           www.corba.org ebXML            www.ebxml.org European Commission        www.cordis.lu Foundation for Intellient Physical Agents    www.\ufb01  pa.org Global Computing        www.cordis.lu/ist/fet/gc.htm Global Grid Forum        www.ggf.org Information Society Technologies      www.cordis.lu/ist Internet Engineering Task Force      www.ietf.org JADE            jade.tilab.com Jini            www.jini.org JXTA            www.jxta.org N1            www.sun.com/n1 OASIS             www.oasis-open.org Object Management Group      www.omg.org RosettaNet          www.rosettanet.org UDDI            www.uddi.org UML            www.uml.org UPnP            www.upnp.org World Wide Web Consortium      www.w3c.org XML            www.xml.org Companies Mentioned Acklin            www.acklin.nl Agentis Software Inc        www.agentissoftware.com Calico Jack          www.calicojack.co.uk Magenta Technology        www.magenta-technology.com Eurobios          www.eurobios.com Lost Wax          www.lostwax.com Nutech Solutions        www.nutechsolutions.com Whitestein Technologies       www.whitestein.com94 AgentLink Roadmap95 Methodology Methodology In January 2004, a core roadmapping group was set up within AgentLink III, including Michael Luck, Peter McBurney and Onn Shehory, to oversee the development of this roadmap. Subsequently Steven Willmott joined the core team, which aimed to lead a programme of review, discussion, consultation and debate across the \ufb01  rst 18 months of AgentLink III. The programme established was determined by three key timepoints at which documents would be produced: at 12 months with the initial Consultation Report that would be used for placing a marker in the community as a means of eliciting contributions and comment; at 18 months with the Roadmap Draft, which would essentially be the complete document available for detailed analysis and discussion, both by targeted reviewers, and by the general community; and at 21 months, when the \ufb01  nal document would be printed and widely distributed for maximum impact. These three key points delimit the three stages of roadmap development.",
          "cites": null
        },
        {
          "id": 36125436,
          "title": "Technology roadmapping\u2014a planning framework for evolution and revolution.",
          "authors": [],
          "date": "2004",
          "doi": "10.1016/s0040-1625(03)00072-6",
          "raw": "R. Phaal, C. Farrukh and D. Probert, Technology roadmapping\u2014a planning framework for evolution and revolution. Technological Forecasting and Social Change, 71: 5\u201326, 2004.",
          "cites": null
        },
        {
          "id": 36125435,
          "title": "The AgentLink III Deliberative Delphi Survey.",
          "authors": [],
          "date": "2005",
          "doi": null,
          "raw": "S. Munroe, M. Luck and P. McBurney, The AgentLink III Deliberative Delphi Survey. Technical Report. Department of Electronics and Computer Science, University of Southampton, UK, 2005.",
          "cites": null
        },
        {
          "id": 36125431,
          "title": "The AgentLink III Technology Diffusion Model.",
          "authors": [],
          "date": "2005",
          "doi": null,
          "raw": "J. McKean, H. Shorter, P. McBurney and M. Luck, The AgentLink III Technology Diffusion Model. Technical Report ULCS-05-008, Department of Computer Science, University of Liverpool, UK, 2005.",
          "cites": null
        }
      ],
      "sourceFulltextUrls": [
        "https://kclpure.kcl.ac.uk/portal/files/7762482/Luck_Agent_2005.pdf"
      ],
      "updatedDate": "2023-10-05T15:18:43",
      "yearPublished": 2005,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/29914283.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/29914283"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/29914283/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/29914283/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/449583"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [],
      "citationCount": 0,
      "contributors": [
        "Soldatos, John"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/637933269"
      ],
      "createdDate": "2025-02-04T22:30:43",
      "dataProviders": [
        {
          "id": 1840,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/1840",
          "logo": "https://api.core.ac.uk/data-providers/1840/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "This open access book presents a rich set of innovative solutions for artificial intelligence (AI) in manufacturing. The various chapters of the book provide a broad coverage of AI systems for state of the art flexible production lines including both cyber-physical production systems (Industry 4.0) and emerging trustworthy and human-centered manufacturing systems (Industry 5.0). From a technology perspective, the book addresses a wide range of AI paradigms such as deep learning, reinforcement learning, active learning, agent-based systems, explainable AI, industrial robots, and AI-based digital twins. Emphasis is put on system architectures and technologies that foster human-AI collaboration based on trusted interactions between workers and AI systems. From a manufacturing applications perspective, the book illustrates the deployment of these AI paradigms in a variety of use cases spanning production planning, quality control, anomaly detection, metrology, workers\u2019 training, supply chain management, as well as various production optimization scenarios. This is an open access book",
      "doi": "10.1007/978-3-031-46452-2",
      "downloadUrl": "https://core.ac.uk/download/637933269.pdf",
      "fieldOfStudy": null,
      "fullText": "John\u00a0Soldatos\u00a0\u00a0\u00a0EditorArtificial Intelligence in ManufacturingEnabling Intelligent, Flexible and Cost-Effective Production Through AIArtificial Intelligence in ManufacturingJohn Soldatos Editor Artificial Intelligence in Manufacturing Enabling Intelligent, Flexible and Cost-Effective Production Through AIEditor John Soldatos Netcompany-Intrasoft S.A M\u00e4rel Luxembourg, Luxembourg ISBN 978-3-031-46451-5 ISBN 978-3-031-46452-2 (eBook) https://doi.org/10.1007/978-3-031-46452-2 This work was supported by Netcompany-Intrasoft. \u00a9 The Editor(s) (if applicable) and The Author(s) 2024. This book is an open access publication. Open Access This book is licensed under the terms of the Creative Commons Attribution 4.0 Inter-national License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this book are included in the book\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the book\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors, and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. This Springer imprint is published by the registered company Springer Nature Switzerland AG The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland Paper in this product is recyclable.Preface For over a decade, Artificial Intelligence (AI) technologies and applications are proliferating in a rapid pace. The rise of AI is driven by a variety of factors including the unprecedented improvements in hardware and software, and the explosion in the amount of generated data. These advances enable the development of sophisticated AI models (e.g., deep learning models, deep reinforcement learning models, large language models), as well as their deployment and execution in realistic settings. This is also the reason why modern manufacturers are undertaking significant investments in AI solutions as part of their digital transformation journey. As a result, AI is rapidly transforming the manufacturing industry, through enabling tangible improvements in the efficiency, quality, and productivity of industrial organizations. A variety of AI-based use cases are nowadays deployed in Industry 4.0 pro-duction lines. Some of the most prominent examples of such AI-enabled use cases can be found in the areas of predictive maintenance, quality control, supply chain optimization, production planning, process automation, and safety monitor-ing. For instance, a variety of machine learning models are nowadays used to make quality control more practical and more intelligent, by automating product quality inspection, enabling timely detection of defects, and identifying production configurations that could lead into production problems. As another example, deep learning algorithms are commonly used to predict and anticipate machine failures before they occur, based on predictive and accurate estimations of the Remaining Useful Life (RUL) of the machinery. Likewise, there are AI systems that enable the timely detection of anomalies in products and production processes. These use cases are some of the most disruptive solutions of the Industry 4.0 era, which is transforming manufacturing enterprises by means of Cyber Physical Production Systems (CPPS). In this direction, most AI use cases for Industry 4.0 emphasize the training, development, and deployment of accurate and effective machine learning systems. The latter are integrated with Industrial Internet of Things (IIoT) systems in the scope of scalable and secure cloud/edge environments. To this end, industrial solution integrators leverage structuring principles and blueprints specified in standards-based reference architectures for Industry 4.0vvi Prefacesystems. Nevertheless, the AI\u2019s potential for manufacturing is still largely underex-ploited. State of the art systems are usually limited to the extraction of data-driven AI-based insights for improving production processes and related decision making. These insights are based on quite simple models about the production processes and hardly combine capabilities of multiple AI systems and algorithms. To alleviate these limitations, there are research initiatives that explore the integration and collaboration of multiple AI systems in the scope of production processes. In this direction, there is on-going research on: \u2022 Multi-agent systems that foster enhanced collaborative intelligence based on the interaction and the development of synergies across different autonomous AI agents. \u2022 Solutions for AI interoperability across diverse systems. These solutions leverage advanced knowledge models (e.g., Semantic Knowledge Graphs (SKGs) and embeddings that capture the relationships between different entities) to enable the development of sophisticated AI systems that span entire multi-stage production processes beyond simple ML-based state machines. During the last couple of years, Industry 4.0 is evolving to a direction where AI serves manufacturing workers, while at the same time interacting closely with them in a variety of human-in-the-loop scenarios such as human-robot collaboration (HRC) scenarios. At the same time, AI use cases are increasingly aiming at increas-ing production sustainability to ensure that the manufacturing sector contributes to strategic targets such as the European Green Deal (EGD) of the European Union (EU). Sustainability and human-centricity are driving the transition of Industry 4.0 digital manufacturing systems to the Industry 5.0 era, which emphasizes human-centricity and environmental performance. The advent of Industry 5.0 systems is increasing the functional sophistication and integration complexity of AI systems in manufacturing. It also asks for an evolution of AI in a human-centered dimension, where AI systems operate in trustworthy and reliable manner. Specifically, the evolution of AI systems toward the Industry 5.0 era asks for: \u2022 Novel AI architectures for Industry 5.0: Industry 5.0 system comprises multiple AI components (e.g., robots, machine learning models, Natural Language Pro-cessing (NLP)) that must safely and effectively interact with humans in industrial environments. The development and deployment of such systems requires novel architectures and structuring principles, beyond classical architectures of Big Data, AI, and Industrial Internet of Things (IIoT) platforms. \u2022 Knowledge Modelling and Representation: HRC use cases are usually deployed in highly dynamic environments involving humans, robots, and AI systems that interact with each other. The implementation of advanced and automated reasoning in such an environment asks for novel ways for representing processes in ways that capture the complex interrelationships between the different actors. \u2022 Models and Learning paradigms for Human-Robot Collaboration: Industry 5.0 introduces a need for deploying novel learning paradigms that foster the interplayPreface viibetween humans and AI actors. Such paradigms include, for example, active learning and intelligent Multi-Agent Systems (MAS). They enable outcomes that combine the speed of AI systems with the credibility of human judgment. Likewise, Industry 4.0 solutions like Digital Twins are currently transformed to account for the context of the human workers, i.e., they are evolving toward human-centric digital twins. \u2022 Explainability, transparency, and regulatory compliance: Industry 5.0 systems pose their own unique transparency and safety requirements. They involve humans in the loop that must be able to understand the decisions and operation of AI system. Hence, AI use cases cannot be developed based on black-box AI models. Rather, AI systems should be transparent, explainable, trusted, and understandable to humans. Manufacturers must also ensure that their AI systems adhere to the mandates of emerging AI regulations such as the AI Act in Europe. The aim of this book is to shed light on the limitations of existing solutions for AI in manufacturing and to introduce novel solutions that: \u2022 Improve the functional capabilities and technical performance of state-of-the-art AI systems for manufacturing in a variety of production processes like production scheduling and quality control \u2022 Enhance the human centricity, the trustworthiness, and the overall social perfor-mance of AI systems in line with the requirements and concepts of the Industry 5.0 era The book comprises 27 chapters that present innovative AI systems and solutions spanning both state-of-the-art Industry 4.0 use cases and emerging, human-centric Industry 5.0 use cases. The chapters are contributed by Y EU-funded projects, which are closely collaborated in the context of the AI4Manufacturing Cluster of European projects, as well as in the scope of the activities of the European Factories of the Future Research Association (EFFRA). The contributing projects focus on the development, deployment, and operation of AI systems for production lines. Each of the project addresses a set of unique challenges of AI in Industry 4.0 and/or Industry 5.0 use cases, such as the development and deployment of effective MAS systems, the development of trusted and explainable AI systems, the specification and implementation of knowledge models and semantics for Industry 5.0 applications, as well as the development of novel forms of digital twin systems and applications (e.g., human-centric digital twins). Specifically, the book is structured in the following three parts: Part I: Architectures and Knowledge Modelling for AI This part presents architectures for AI-based Industry 5.0 systems and solutions, ranging from high-level reference architecture models to architecture of specific AI platforms and solutions\u2019 marketplaces. The presented architectures illustrate the structure of both Industry 4.0 and Industry 5.0 use cases with emphasis on the structuring principles that drive the integration of AI and ML models with industrial systems. Moreover, this part of the book includes several chapters that illustrateviii Prefacesemantic modelling techniques for AI applications in manufacturing, including techniques based on semantic knowledge graphs and embeddings. Part II: Multi-agent Systems and AI-based Digital Twins for Manufacturing Applications This part of the book presents multi-agent systems and digital twin solutions for Industry 5.0. The digital twins\u2019 solutions can identify the users\u2019 context toward modeling and simulating AI-based processes with the human in the loop. In terms of multi-agent systems, the chapter presents human-AI interaction approaches based on the intelligent agents, which empower decentralized collaborative intelligence paradigms for AI in manufacturing. Part III: Trusted, Explainable, and Human-Centered AI Systems This part of the book introduces novel approaches to implementing human-centered, trusted, and explainable AI systems for digital manufacturing applications. Most of the presented solutions target human-in-the-loop scenarios such as human-robot interactions and emphasize not only the technical performance but also the social performance of AI systems. Therefore, they are suitable for applications of the Industry 5.0 era. Overall, the book provides a comprehensive overview of AI technologies and applications in manufacturing covering both Industry 4.0 and Industry 5.0 envi-ronments. The book is provided as an open access publication, which ensures that researchers and practitioners will have unlimited access to it. In essence, it is a contribution of the AI4Manufacturing cluster of projects and of various other EU programs to the Industry 4.0 and Industry 5.0 communities. I hope that researchers, practitioners, and providers of industrial automation solutions for manufacturing will find it interesting. M\u00e4rel Luxembourg, Luxembourg John Soldatos July 2023Acknowledgments This book has received funding from the European Union\u2019s Horizon 2020 research and innovation program under grant agreements No. 956573 (STAR), No. 957204 (MAS4AI), No. 957362 (XMANAI), No. 101000165 (ASSISTANT), No. 957331 (knowlEdge), and No. 957402 (Teaming. AI), which are part of the AI4Manufacturing Cluster of projects. Several contributions of the book have been also supported financially from other EU projects (e.g., No. 952119 (KITT4SME) No. 870092 (DIMOFAC), No. 869963 (MERGING)) and various national projects as indicated in the acknowledgement sections of each chapter. The editor and the chapter co-authors acknowledge valuable support from partners of the above-listed EU projects. Disclaimer: The contents of the book reflect only the contributors\u2019 and co-authors\u2019 view. The European Commission is not responsible for any use that may be made of the information it contains.ixContents Part I Architectures and Knowledge Modelling for AI in Manufacturing Reference Architecture for AI-Based Industry 5.0 Applications . . . . . . . . . . . 3 John Soldatos, Babis Ipektsidis, Nikos Kefalakis, and Angela-Maria Despotopoulou Designing a Marketplace to Exchange AI Models for Industry 5.0 . . . . . . . .  27 Alexandros Nizamis, Georg Schlake, Georgios Siachamis, Vasileios Dimitriadis, Christos Patsonakis, Christian Beecks, Dimosthenis Ioannidis, Konstantinos Votis, and Dimitrios Tzovaras Human-AI Interaction for Semantic Knowledge Enrichment of AI Model Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  43 Sisay Adugna Chala and Alexander Gra\u00df Examining the Adoption of Knowledge Graphs in the Manufacturing Industry: A Comprehensive Review . . . . . . . . . . . . . . . . . . . . . . . . .  55 Jorge Martinez-Gil, Thomas Hoch, Mario Pichler, Bernhard Heinzl, Bernhard Moser, Kabul Kurniawan, Elmar Kiesling, and Franz Krause Leveraging Semantic Representations via Knowledge Graph Embeddings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  71 Franz Krause, Kabul Kurniawan, Elmar Kiesling, Jorge Martinez-Gil, Thomas Hoch, Mario Pichler, Bernhard Heinzl, and Bernhard Moser Architecture of a Software Platform for Affordable Artificial Intelligence in Manufacturing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  87 Vincenzo Cutrona, Giuseppe Landolfi, Rub\u00e9n Alonso, Elias Montini, Andrea Falconi, and Andrea Bettoni Multisided Business Model for Platform Offering AI Services . . . . . . . . . . . . .  105 Krzysztof Ejsmont, Bartlomiej Gladysz, Natalia Roczon, Andrea Bettoni, Zeki Mert Barut, Rodolfo Haber, and Elena Miniscixixii ContentsSelf-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence: A Review and Case Study . . . . . . . . . . . . . . . . . . . . . . . . .  121 Yarens J. Cruz, Fernando Casta\u00f1o, Rodolfo E. Haber, Alberto Villalonga, Krzysztof Ejsmont, Bartlomiej Gladysz, \u00c1lvaro Flores, and Patricio Alemany Part II Multi-agent Systems and AI-Based Digital Twins for Manufacturing Applications Digital-Twin-Enabled Framework for Training and Deploying AI Agents for Production Scheduling. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  147 Emmanouil Bakopoulos, Vasilis Siatras, Panagiotis Mavrothalassitis, Nikolaos Nikolakis, and Kosmas Alexopoulos A Manufacturing Digital Twin Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  181 Victor Anaya, Enrico Alberti, and Gabriele Scivoletto Reinforcement Learning-Based Approaches in Manufacturing Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  195 Andrea Fern\u00e1ndez Mart\u00ednez, Carlos Gonz\u00e1lez-Val, Daniel Gordo Mart\u00edn, Alberto Botana L\u00f3pez, Jose Angel Segura Muros, Afra Maria Petrusa Llopis, Jawad Masood, and Santiago Mui\u00f1os-Landin A Participatory Modelling Approach to Agents in Industry Using AAS . .  217 Nikoletta Nikolova, Cornelis Bouter, Michael van Bekkum, Sjoerd Rongen, and Robert Wilterdink I4.0 Holonic Multi-agent Testbed Enabling Shared Production . . . . . . . . . . . .  231 Alexis T. Bernhard, Simon Jungbluth, Ali Karnoub, Aleksandr Sidorenko, William Motsch, Achim Wagner, and Martin Ruskowski A Multi-intelligent Agent Solution in the Automotive Component\u2013Manufacturing Industry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  251 Luis Usatorre, Sergio Clavijo, Pedro Lopez, Echeverr\u00eda Imanol, Fernando Cebrian, David Guill\u00e9n, and E. Bakopoulos Integrating Knowledge into Conversational Agents for Worker Upskilling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  265 Rub\u00e9n Alonso, Danilo Dess\u00ed, Antonello Meloni, Marco Murgia, and Reforgiato Recupero Diego Advancing Networked Production Through Decentralised Technical Intelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  281 Stefan Walter and Markku Mikkola Part III Trusted, Explainable and Human-Centered AI Systems Wearable Sensor-Based Human Activity Recognition for Worker Safety in Manufacturing Line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  303 Sungho Suh, Vitor Fortes Rey, and Paul LukowiczContents xiiiObject Detection for Human\u2013Robot Interaction and Worker Assistance Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  319 Hooman Tavakoli, Sungho Suh, Snehal Walunj, Parsha Pahlevannejad, Christiane Plociennik, and Martin Ruskowski Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  333 Marta Barroso, Daniel Hinjos, Pablo A. Martin, Marta Gonzalez-Mallo, Victor Gimenez-Abalos, and Sergio Alvarez-Napagao Anomaly Detection in Manufacturing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  351 Jona Scholz, Maike Holtkemper, Alexander Gra\u00df, and Christian Beecks Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  361 Eduardo Vyhmeister and Gabriel Gonzalez Castane Human in the AI Loop via xAI and Active Learning for Visual Inspection 381 Jo\u017ee M. Ro\u017eanec, Elias Montini, Vincenzo Cutrona, Dimitrios Papamartzivanos, Timotej Klemenc\u030cic\u030c, Bla\u017e Fortuna, Dunja Mladenic\u0301, Entso Veliou, Thanassis Giannetsos, and Christos Emmanouilidis Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  407 Thomas Hoch, Jorge Martinez-Gil, Mario Pichler, Agastya Silvina, Bernhard Heinzl, Bernhard Moser, Dimitris Eleftheriou, Hector Diego Estrada-Lugo, and Maria Chiara Leva Holistic Production Overview: Using XAI for Production Optimization . .  423 Sergi Perez-Castanos, Ausias Prieto-Roig, David Monzo, and Javier Colomer-Barbera XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  437 Fenareti Lampathaki, Enrica Bosani, Evmorfia Biliri, Erifili Ichtiaroglou, Andreas Louca, Dimitris Syrrafos, Mattia Calabresi, Michele Sesana, Veronica Antonello, and Andrea Capaccioli Process and Product Quality Optimization with Explainable Artificial Intelligence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  459 Michele Sesana, Sara Cavallaro, Mattia Calabresi, Andrea Capaccioli, Linda Napoletano, Veronica Antonello, and Fabio Grandi Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict the Pointwise Accuracy of Laser Scanning Devices in Industrial Manufacturing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  479 Eleni Lavasa, Christos Chadoulos, Athanasios Siouras, Ainhoa Etxabarri Llana, Silvia Rodr\u00edguez Del Rey, Theodore Dalamagas, and Serafeim Moustakidis Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  503Editor and Contributors About the Editor John Soldatos (http://gr.linkedin.com/in/johnsoldatos) holds a PhD in Electrical and Computer Engineering from the National Technical University of Athens (2000) and is currently Honorary Research Fellow at the University of Glasgow, UK (2014\u2013present). He was Associate Professor and Head of the Internet of Things (IoT) Group at the Athens Information Technology (AIT), Greece (2006\u2013 2019), and Adjunct Professor at the Carnegie Mellon University, Pittsburgh, PA (2007\u20132010). He has significant experience in working closely with large multi-national industries (IBM Hellas, INTRACOM S.A., INTRASOFT International S.A., Netcompany-Intrasoft S.A., and Netcompany S.A.) as R&D consultant and delivery specialist, while being scientific advisor to high-tech startup enterprises. Dr. Soldatos is an expert in Internet-of-Things (IoT) and Artificial Intelligence (AI) technologies and applications, including applications in smart cities, finance (Finance 4.0), and industry (Industry 4.0). Dr. Soldatos has played a leading role in the successful delivery of more than 70 (commercial-industrial, research, and business consulting) projects, for both private and public sector organizations, including complex integrated projects. He is co-founder of the open-source platform OpenIoT (https://github.com/OpenIotOrg/openiot). He has published more than 200 articles in international journals, books, and conference proceedings. He has also significant academic teaching experience, along with experience in executive education and corporate training. Dr. Soldatos is a regular contributor in various international magazines and blogs, on topics related to Artificial Intelligence, IoT, Industry 4.0, and cybersecurity. Moreover, he has received national and international recognition through appointments in standardization working groups, expert groups, and various boards. He has recently coedited and coauthored eight edited volumes (books) on Artificial Intelligence, BigData, and Internet of Things-related themes.xvxvi Editor and ContributorsContributors Enrico Alberti Nextworks SRL, Pisa, Italy Patricio Alemany Rovim\u00e1tica SL, C\u00f3rdoba, Spain Rub\u00e9n Alonso R2M Solution s.r.l., Pavia, Italy Programa de Doctorado, Centro de Autom\u00e1tica y Rob\u00f3tica, Universidad Polit\u00e9cnica de Madrid-CSIC, Madrid, Spain Sergio Alvarez-Napagao High Performance and Artificial Intelligence, Barcelona Supercomputing Center, Barcelona, Spain Victor Anaya Information Catalyst SL, Xativa, Spain Veronica Antonello TXT e-solutions SpA, Milan, Italy TXT e-tech, Milan, Italy E. Bakopoulos LMS, Laboratory for Manufacturing Systems, Patras, Greece Marta Barroso High Performance and Artificial Intelligence, Barcelona Super-computing Center, Barcelona, Spain Zeki Mert Barut Department of Innovative Technologies, University of Applied Science of Southern Switzerland, Manno, Switzerland Christian Beecks FernUniversity of Hagen, Hagen, Germany Alexis T. Bernhard Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI), Kaiserslautern, Germany Andrea Bettoni Department of Innovative Technologies, University of Applied Science of Southern Switzerland, Manno, Switzerland Evmorfia Biliri Suite5 Data Intelligence Solutions, Limassol, Cyprus Enrica Bosani Whirlpool Management EMEA, Milan, Italy Cornelis Bouter Data Science, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The Netherlands Mattia Calabresi TXT e-solutions SpA, Milan, Italy TXT e-tech, Milan, Italy Andrea Capaccioli Deep Blue, Rome, Italy Gabriel Gonzalez Casta\u00f1\u00e9 The Insight SFI Research Centre of Data Analytics, University College Cork, Cork, Ireland Fernando Casta\u00f1o Centro de Autom\u00e1tica y Rob\u00f3tica (CSIC-Universidad Polit\u00e9c-nica de Madrid), Madrid, Spain Sara Cavallaro CNH Industrial, Modena, ItalyEditor and Contributors xviiFernando Cebrian Fersa Bearings, Zaragoza, Spain Christos Chadoulos AIDEAS OU, Tallinn, Estonia Sisay Adugna Chala Department of Data Science and AI, Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany Sergio Clavijo Fundacion TECNALIA R&I, Madrid, Spain Javier Colomer-Barbera Ford, Valencia, Spain Yarens J. Cruz Centro de Autom\u00e1tica y Rob\u00f3tica (CSIC-Universidad Polit\u00e9cnica de Madrid), Madrid, Spain Vincenzo Cutrona University of Applied Science of Southern Switzerland, Switzerland Theodore Dalamagas Athena Research Center, Marousi, Greece Silvia Rodr\u00edguez Del Rey Asociaci\u00f3n de Empresas Tecnol\u00f3gicas Innovalia, Calle Rodr\u00edguez Arias, Bilbao, Spain Angela-Maria Despotopoulou Netcompany-Intrasoft S.A, Luxembourg, Luxem-bourg Danilo Dess\u00ed Knowledge Technologies for the Social Sciences Department, GESIS \u2013 Leibniz Institute for the Social Sciences, Cologne, Germany Vasileios Dimitriadis Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Krzysztof Ejsmont Faculty of Mechanical and Industrial Engineering, Warsaw University of Technology, Warsaw, Poland Institute of Production Systems Organization, Faculty of Mechanical and Industrial Engineering, Warsaw University of Technology, Warsaw, Poland Dimitris Eleftheriou CORE Innovation, Athens, Greece Emmanouil Bakopoulos Laboratory for Manufacturing Systems & Automation (LMS), Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece Christos Emmanouilidis University of Groningen, Groningen, The Netherlands Hector Diego Estrada-Lugo Technological University Dublin, School of Environ-mental Health, Dublin, Ireland Andrea Falconi Martel Innovate, Zurich, Switzerland \u00c1lvaro Flores Rovim\u00e1tica SL, C\u00f3rdoba, Spain Bla\u017e Fortuna Qlector d.o.o., Ljubljana, Slovenia Thanassis Giannetsos Ubitech Ltd., Athens, Greecexviii Editor and ContributorsVictor Gimenez-Abalos High Performance and Artificial Intelligence, Barcelona Supercomputing Center, Barcelona, Spain Bartlomiej Gladysz Faculty of Mechanical and Industrial Engineering, Warsaw University of Technology, Warsaw, Poland Institute of Production Systems Organization, Faculty of Mechanical and Industrial Engineering, Warsaw University of Technology, Warsaw, Poland Marta Gonzalez-Mallo High Performance and Artificial Intelligence, Barcelona Supercomputing Center, Barcelona, Spain Carlos Gonz\u00e1lez-Val AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Fabio Grandi Universit\u00e0 di Modena e Reggio Emilia, Modena, Italy Alexander Gra\u00df Department of Data Science and AI, Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany David Guill\u00e9n Fersa Bearings, Zaragoza, Spain Rodolfo Haber Centre for Automation and Robotics (CAR), Spanish National Research Council-Technical University of Madrid (CSIC-UPM), Madrid, Spain Rodolfo E. Haber Centro de Autom\u00e1tica y Rob\u00f3tica (CSIC-Universidad Polit\u00e9c-nica de Madrid), Madrid, Spain Bernhard Heinzl Software Competence Center Hagenberg GmbH, Hagenberg, Austria Daniel Hinjos High Performance and Artificial Intelligence, Barcelona Supercom-puting Center, Barcelona, Spain Thomas Hoch Software Competence Center Hagenberg GmbH, Hagenberg, Austria Maike Holtkemper FernUniversity of Hagen, Hagen, Germany Erifili Ichtiaroglou Suite5 Data Intelligence Solutions, Limassol, Cyprus Echeverr\u00eda Imanol Fundacion TECNALIA R&I, Madrid, Spain Dimosthenis Ioannidis Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Babis Ipektsidis Netcompany-Intrasoft, Brussels, Belgium Simon Jungbluth Technologie-Initiative SmartFactory KL e.V., Kaiserslautern, Germany Ali Karnoub Technologie-Initiative SmartFactory KL e.V., Kaiserslautern, Germany Nikos Kefalakis Netcompany-Intrasoft S.A, Luxembourg, LuxembourgEditor and Contributors xixElmar Kiesling WU, Institute for Data, Process and Knowledge Management, Vienna, Austria Timotej Klemenc\u030cic\u030c University of Ljubljana, Ljubljana, Slovenia Kosmas Alexopoulos Laboratory for Manufacturing Systems & Automation (LMS), Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece Franz Krause University of Mannheim, Data and Web Science Group, Mannheim, Germany Kabul Kurniawan WU, Institute for Data, Process and Knowledge Management, Vienna, Austria Austrian Center for Digital Production (CDP), Vienna, Austria Fenareti Lampathaki Suite5 Data Intelligence Solutions, Limassol, Cyprus Giuseppe Landolfi University of Applied Science of Southern Switzerland, Switzerland Eleni Lavasa Athena Research Center, Marousi, Greece Maria Chiara Leva Technological University Dublin, School of Environmental Health, Dublin, Ireland Ainhoa Etxabarri Llana UNIMETRIK S.A., Legutiano,\u00c1lava, Spain Afra Maria Petrusa Llopis AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Alberto Botana L\u00f3pez AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Pedro Lopez Fundacion TECNALIA R&I, Madrid, Spain Andreas Louca Suite5 Data Intelligence Solutions, Limassol, Cyprus Paul Lukowicz German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany Daniel Gordo Mart\u00edn AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Andrea Fern\u00e1ndez Mart\u00ednez AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Jorge Martinez-Gil Software Competence Center Hagenberg GmbH, Hagenberg, Austria Pablo A. Martin High Performance and Artificial Intelligence, Barcelona Super-computing Center, Barcelona, Spainxx Editor and ContributorsJawad Masood AIMEN Technology Centre, Smart Systems and Smart Manufac-turing Group, Pontevedra, Spain Antonello Meloni Mathematics and Computer Science Department, University of Cagliari, Cagliari, Italy Markku Mikkola VTT Technical Research Centre of Finland Ltd., Espoo, Finland Elena Minisci CRIT S.R.L., Vignola, Italy Dunja Mladenic\u0301 Jo\u017eef Stefan Institute, Ljubljana, Slovenia Elias Montini University of Applied Science of Southern Switzerland, Switzerland Politecnico di Milano, Milan, Italy David Monzo Tyris AI, Valencia, Spain Bernhard Moser Software Competence Center Hagenberg GmbH, Hagenberg, Austria William Motsch Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI), Kaiserslautern, Germany Serafeim Moustakidis AIDEAS OU, Tallinn, Estonia Santiago Mui\u00f1os-Landin AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Marco Murgia Mathematics and Computer Science Department, University of Cagliari, Cagliari, Italy Jose Angel Segura Muros AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain Linda Napoletano Deep Blue, Rome, Italy Nikolaos Nikolakis Laboratory for Manufacturing Systems & Automation (LMS), Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece Nikoletta Nikolova Data Science, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The Netherlands Alexandros Nizamis Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Parsha Pahlevannejad German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory, Kaiserslautern, Germany Panagiotis Mavrothalassitis Laboratory for Manufacturing Systems & Automa-tion (LMS), Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, GreeceEditor and Contributors xxiDimitrios Papamartzivanos Ubitech Ltd., Athens, Greece Christos Patsonakis Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Sergi Perez-Castanos Tyris AI, Valencia, Spain Mario Pichler Software Competence Center Hagenberg GmbH, Hagenberg, Austria Christiane Plociennik German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory, Kaiserslautern, Germany Ausias Prieto-Roig Tyris AI, Valencia, Spain Reforgiato Recupero Diego Mathematics and Computer Science Department, University of Cagliari, Cagliari, Italy R2M Solution s.r.l., Pavia, Italy Vitor Fortes Rey German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany Natalia Roczon Faculty of Mechanical and Industrial Engineering, Warsaw Uni-versity of Technology, Warsaw, Poland Sjoerd Rongen Data Ecosystems, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The Netherlands Jo\u017ee M. Ro\u017eanec Jo\u017eef Stefan Institute, Ljubljana, Slovenia Qlector d.o.o., Ljubljana, Slovenia Martin Ruskowski German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory KL e.V., Kaiserslautern, Germany Georg Schlake FernUniversity of Hagen, Hagen, Germany Jona Scholz FernUniversity of Hagen, Hagen, Germany Gabriele Scivoletto Nextworks SRL, Pisa, Italy Michele Sesana TXT e-solutions SpA, Milan, Italy TXT e-tech, Milan, Italy Georgios Siachamis Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Aleksandr Sidorenko Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI), Kaiserslautern, Germanyxxii Editor and ContributorsAgastya Silvina Software Competence Center Hagenberg GmbH, Hagenberg, Austria Athanasios Siouras AIDEAS OU, Tallinn, Estonia John Soldatos Netcompany-Intrasoft S.A, Luxembourg, Luxembourg Sungho Suh German Research Center for Artificial Intelligence (DFKI), Kaiser-slautern, Germany Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany Dimitris Syrrafos Suite5 Data Intelligence Solutions, Limassol, Cyprus Hooman Tavakoli German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory, Kaiserslautern, Germany Dimitrios Tzovaras Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Luis Usatorre Fundacion TECNALIA R&I, Madrid, Spain Michael van Bekkum Data Science, Netherlands Organisation for Applied Scien-tific Research (TNO), Den Haag, The Netherlands Vasilis Siatras Laboratory for Manufacturing Systems & Automation (LMS), Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece Entso Veliou University of West Attica, Aigaleo, Greece Alberto Villalonga Centro de Autom\u00e1tica y Rob\u00f3tica (CSIC-Universidad Polit\u00e9c-nica de Madrid), Madrid, Spain Konstantinos Votis Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece Eduardo Vyhmeister The Insight SFI Research Centre of Data Analytics, Univer-sity College Cork, Cork, Ireland Achim Wagner Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI), Kaiserslautern, Germany Stefan Walter VTT Technical Research Centre of Finland Ltd., Espoo, Finland Snehal Walunj German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory, Kaiserslautern, Germany Robert Wilterdink Advanced Computing Engineering, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The NetherlandsAbbreviations ACDS AI Cyber-Defence Strategies ACL Agent Communication Language ADAS Advanced Driver Assistance System AHP Analytic Hierarchy Process AI Artificial Intelligence AIaaS AI as a Service AL Active Learning ALE Accumulated Local Efforts AMG AI Model Generation AMR Automatic Mobile Robots ANOVA Analysis of Variance APaaS Application Platform as a Service API Application Programming Interface AR Augmented Reality AutoML Automated Machine Learning BM Business Model BOM Bill Of Materials CAD Computer-Aided Design CD Continuous Delivery CEAP Circular Economy Action Plan CI Continuous Integration CM Community Management CMOS Complementary Metal Oxide Semiconductor CNC Computer Numerical Control CNN Convolutional Neural Network CoAP Constrained Application Protocol CPPM Cyber-Physical Production Modules CPPS Cyber-Physical Production Systems CPS Cyber-Physical Systems CPT Capabilities Periodic Table CPU Central Processing Unitxxiiixxiv AbbreviationsCRUD Create Update Delete CSV Comma Separated Values CV Computer Vision DAIRO Data, AI, and Robotics DBFSP Distributed Blocking Flowshop Scheduling Problem DCP Data Collection Platform DES Discrete Event Simulation DL Deep Learning DLT Distributed Ledger Technologies DnDF Non-discrimination, and Fairness DNN Deep Neural Network DoS Denial of Service DP Data Type Probing DPO Data Protection Officer DRP Deep Reinforcement Learning DS Digital System DS Data Scientist DSS Decision Support System DT Digital Twin DTF Digital Twin Framework DTI Decentralised Technical Intelligence D2C Direct sales to final Customers EC European Commission EGD European Green Deal ERP Enterprise Resource Planning ESCO European Skills, Competences, and Occupations EU European Union EFFRA European Factories of the Future Research Association FMEA Failure Mode and Effects Analysis FMS Flexible Manufacturing System FGSM Fast Gradient Sign Method FT Fungible Token GAT Graph ATtention GCN Graph Convolutional Network GDPR General Data Protection Regulation GE Generic Enabler GNN Graph Neural Network GPR Gaussian Process Regression GraphML Graph Machine Learning GRPN Global Risk Priority Number GUI Graphical User Interface GW Griding Wheel HAR Human Activity Recognition HCAI Human-Centered Artificial Intelligence HDT Human Digital TwinAbbreviations xxvHITL Human In The Loop HLF Hyperledger Fabric HMI Human-Machine Interface HMS Holonic Manufacturing System HOTL Human On The Loop HR Human Resources HRC Human-Robot Collaboration HRI Human-Robot Interface HTTP HyperText Transport Protocol HTTPS Secure HyperText Transport Protocol ICT Information and Communications Technology IDTA Industrial Digital Twin Association IEEE Institute of Electrical and Electronics Engineers IEEE-SA IEEE Standards Association IDM IDentity Management and Access Control IFS Innovative Factory Systems IIAF Industrial Internet Architecture Framework IIC Industrial Internet Consortium IIoT Industrial Internet of Things IIRA Industrial Internet Reference Architecture IISF Industrial Internet Security Framework ILO International Labour Organization IMU Inertial Measurement Unit IoT Internet of Things IoU Intersection of Union ISCO International Standard Classification of Occupations ISO International Organization for Standardization IT Information Technology I4.0L I4.0 Language JSON JavaScript Object Notation JSSP Job Shop Scheduling Problem KG Knowledge Graph KPI Key Performance Indicator KQML Knowledge Query and Manipulation Language LIME Local Interpretable Model-Agnostic Explanations LLM Large Language Models LPG Labeled Property Graph LSTM Long Short-Term Memory MAP Mean Average Precision MAPE Mean Absolute Percentage Error MAS Multi-Agent System MC Malicious Control MDP Markov Decision Process MIP Mixed Integer Programming ML Machine Learningxxvi AbbreviationsMLP Multilayer Perceptron MMD Maximum Mean Discrepancy MO Malicious Operation MO Machine Operator MPMS Manufacturing Process Management System MP&L Material Planning & Logistics MQTT Message Queue Telemetry Transport MSE Mean Squared Error MSP Multi-Sided Platforms MVP Minimum Viable Platform NAICS North American Industry Classification System NFT Non-Fungible Token NLP Natural Language Processing NOC National Occupation Classification OD Object Detection OECD Organisation for Economic Cooperation and Development OEM Original Equipment Manufacturer ONNX Open Neural Network Exchange OPC-UA Open Platform Communications United Architecture OT Operational Technology OWL Web Ontology Language O*NET Occupational Information Network PBT Population-Based Training PCA Principal Component Analysis PCPSP Precedence Constrained Production Scheduling Problem PDT Platform Design Toolkit PGD Projected Gradient Descent PIAAC Programme for the International Assessment of Adult Competencies PLM Product Lifecycle Management PLM Production Line Manager PMML Predictive Model Markup Language POV Point of View PPKB Production Processes Knowledge Base PRM Process of Risk Management PS Physical System QFD Quality Function Deployment RA Reference Architecture RAME Risk Assessment and Mitigation Engine RAMI Reference Architecture Model Industry 4.0 RAMP Robotics and Automation Marketplace RASP Risk Architecture, Strategy, Protocols RCA Route Cause Analysis RDF Resource Description Framework REST Representation State Transfer RGAN Relational Graph Attention NetworkAbbreviations xxviiRGCN Relational Graph Convolutional Network RL Reinforcement Learning RMS Reconfigurable Manufacturing System RMSLE Root Mean Squared Log Error ROS Robot Operation System RPN Risk Priority Number RQ Research Question RZSG Robust Zero-Sum Game SaaS Software as a Service SC Smart Contract SHACL Shapes Constraint Language SHAP SHapley Additive exPlanations SQL Structured Query Language SME Small Medium Enterprise SNE Stochastic Neighbor Embedding SOTA State of the Art SPM Security Policies Manager SPR Security Policies Repository SS Software Scientist SSO Single Sign On STEP Skills Towards Employment and Productivity SVM Support Vector Machine SVR Support Vector Regression TAI Trustworthy AI TEER Training, Education, Experience, and Responsibilities TLS Transport Level Security UI User Interface WS Wrong Setup XAI eXplainable Artificial Intelligence YOLO You Only Look OncePart I Architectures and Knowledge Modelling for AI in ManufacturingReference Architecture for AI-Based Industry 5.0 Applications John Soldatos , Babis Ipektsidis , Nikos Kefalakis , and Angela-Maria Despotopoulou 1 Introduction For over a decade, manufacturing enterprises are heavily investing in their digital transformation based on Cyber-Physical Production Systems (CPPS) that enable the digitization of production processing such as production scheduling, products\u2019 assembly, physical assets\u2019 maintenance, and quality control. The deployment and operation of CPPS in the manufacturing shopfloor is the main enabler of the fourth industrial revolution (Industry 4.0) [1], which boosts automation and efficiency toward improving production speed and quality [2], while lowering production costs and enabling novel production models such as lot-size-one manufacturing and mass customization. Industry 4.0 applications are usually developed based on advanced digital technologies such as Big Data, Internet of Things (IoT), and Artificial Intelligence (AI), which are integrated with CPPS systems in the manufacturing shopfloor and across the manufacturing value chain. In cases of nontrivial Industry 4.0 systems, this integration can be challenging, given the number and the complexity of the systems and technology involved. For instance, sophisticated Industry 4.0 use cases are likely to comprise multiple sensors and automation devices, along with various data analytics and AI modules that are integrated in digital twins (DTs) systems and applications. To facilitate such challenging integration tasks, industrial automation solution providers are nowadays offered with access to various J. Soldatos (\u0002) \u00b7 N. Kefalakis \u00b7 A.-M. Despotopoulou Netcompany-Intrasoft S.A, Luxembourg, Luxembourg e-mail: john.soldatos@netcompany.com; nikos.kefalakis@netcompany.com; angelamaria.despotopoulou@netcompany.com B. Ipektsidis Netcompany-Intrasoft, Brussels, Belgium e-mail: babis.ipektsidis@netcompany.com \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_134 J. Soldatos et al.reference architecture models for Industry 4.0 applications. These models illustrate the functionalities and technological building blocks of Industry 4.0 applications, while at the same time documenting structuring principles that facilitate their integration and deployment in complete systems and applications. Some of these reference architecture models focus on specific aspects of Industry 4.0 such as data collection, data processing, and analytics, while others take a more holistic view that addresses multiple industrial functionalities. Moreover, several architecture models address nonfunctional requirements as well, such as the cybersecurity and safety of industrial systems. During the last couple of years, there is a surge of interest on Industry 4.0 applications that emphasize human-centered industrial processes, i.e., processes with the human in the loop, as well as the achievement of ambitious sustainability and resilience objectives. The latter are at the very top of the policy agenda of the European Union, as reflected in the European Green Deal (EGD) and Europe\u2019s Circular Economy Action Plan (CEAP). This has led to the introduction of the term Industry 5.0, which evolves Industry 4.0 in a direction that complements efficiency and productivity goals with societal targets, notably contributions to sustainability and the workers\u2019 well-being [3]. Hence, Industry 5.0 targets a sustainable, human-centric, and resilient industry [4]. In this direction, Industry 4.0 systems must be enhanced with human-centric technologies that put the worker at the center of the production process, while at the same time fostering security, safety, transparency, and trustworthiness. For instance, the shift from Industry 4.0 to Industry 5.0 asks for the deployment and use of transparent, interoperable, and explainable AI systems [5], beyond black-box systems (e.g., deep neural networks) that are typically used in Industry 4.0 deployments. As another example, Industry 5.0 applications comprise technological paradigms that foster the collaboration between humans and industrial systems (e.g., co-bots), rather than systems that aim at replacing the human toward hyper-automation (e.g., fully autonomous industrial robots). Likewise, the scope of digital twins in Industry 5.0 tends to differ from Industry 4.0, as simulations and what-if analysis account for human parameters (e.g., physical characteristics, emotional status, skills) as well. Also, Industry 5.0 pays greater emphasis on nonfunctional requirements such as data protection, security, and safety when compared to Industry 4.0 that prioritizes industrial performance and accuracy. Despite these technological differences between Industry 5.0 and Industry 4.0 systems, there is still a lack of standards, formal guidelines, and blueprints for devel-oping, deploying, and operating Industry 5.0 systems. In most cases, manufacturers and providers of industrial automation solutions make use of conventional Industry 4.0 and blueprints, which they enhance with the required features and functionalities of their Industry 5.0 use cases at hand. We argue that this is a considerable misstep in the process of designing and implementing Industry 5.0 solutions, as it deprives architects and developers of industrial systems of the opportunity to consider Industry 5.0 functionalities and features from the early stages of the industrial systems\u2019 development. State-of-the-art approaches to developing Industry 5.0 systems start from Industry 4.0 reference architectures and address human-Reference Architecture for AI-Based Industry 5.0 Applications 5centricity, sustainability, and resilience as secondary, complementary concerns rather than as indispensable requirements that must be prioritized. Motivated by the general lack of reference architecture models for Industry 5.0 systems, this chapter introduces a reference architecture for human-centric, resilient, and sustainable industrial systems, notably digital manufacturing systems that are developed based on cutting-edge technologies such as Artificial Intelligence (AI). The reference architecture highlights the main functional and nonfunctional aspects of Industry 5.0 systems and introduces technological building blocks that can support their implementation. In this direction, the present model specifies technologies that foster human-centricity and trustworthy interactions between humans and industrial systems, such as human-centered digital twins, explainable and interpretable AI, active learning, neurosymbolic learning, and more. Emphasis is also put on technological building blocks that boost cybersecurity and safety, such as technologies for ensuring the trustworthiness of data and machine learning algorithms. Along with the specification of building blocks and structuring princi-ples for the integration in end-to-end Industry 5.0 solutions, the chapter delineates various blueprints that can facilitate the development of Industry 5.0 use cases. The presented blueprints include guidelines for regulatory compliance in the European Union (EU), notably compliance to the European AI regulation proposal (i.e., the \u201cAI Act\u201d) [6]. The remainder of the chapter is structured as follows:\u2022 Section 2 presents related work on reference architectures (RAs) for Industry 4.0. Various RAs are briefly reviewed and their concepts that are relevant to Industry 5.0 solutions are highlighted.\u2022 Section 3 introduces a reference architecture for Industry 5.0 systems. A high-level model of functionalities for human-centric and resilient manufacturing is first introduced, followed by a more detailed logical architecture. Moreover, the section presents a set of technological building blocks that can support the development of real-life systems based on the presented architecture.\u2022 Section 4 presents a set of blueprints for developing Industry 5.0 solutions based on the presented architecture. The blueprints include guidelines and best practices for building solutions compliant to the European Regulation for AI systems.\u2022 Section 5 is the final and concluding section of the chapter. 2 Relevant Work A considerable number of reference architecture models have been recently intro-duced to facilitate the development, integration, and deployment of Industry 4.0 applications. These include architectural models specified by standards development organizations and research initiatives. As a prominent example, the Industrial Internet Reference Architecture (IIRA) prescribes a standards-based architecture6 J. Soldatos et al.for developing, deploying, and operating Industrial Internet of Things (IIoT) systems [7]. It is destined to boost interoperability across different IoT systems and to provide a mapping on how different technologies can be exploited toward developing IIoT systems. The IIRA is described at a high level of abstraction, as it strives to have broad applicability. Its specification has been driven by the analysis of a rich collection of industrial use cases, notably use cases prescribed in the scope of the activities of the Industrial Internet Consortium (IIC). The IIRA is described based on the ISO/IEC/IEEE 42010:2011 [8] standard, which has been adopted by IIC to define its Industrial Internet Architecture Framework (IIAF). The IIRA is defined in terms of four complementary viewpoints: (1) the \u201cbusiness viewpoint\u201d presents the functional modules that are destined to support the business goals of different stakeholders; (2) the \u201cusage viewpoint\u201d presents the way systems compliant to IIRA are used. It includes various sequences of activities involving human or logical actors, which deliver the functionality prescribed by the architecture; (3) the \u201cfunctional viewpoint\u201d presents the functional components of an IIoT system, including their structure and interrelation, as well as the interfaces and interactions between them; and (4) the \u201cimplementation viewpoint\u201d is devoted to technologies that are used to implement the various functional components and their interactions. In the scope of the IIRA, there are also cross-cutting elements, i.e., elements and functions that are applicable to all viewpoints, including connectivity, industrial analytics, distributed data management, as well as intelligent and resilient control. The functional viewpoints of the IIRA specify five sets of functionalities, including: (1) the \u201ccontrol domain,\u201d which comprises functions conducted by industrial control and automation; (2) the \u201coperations domain,\u201d which deals with the management and operation of the control domain. It comprises functions for the provisioning, management, monitoring, and optimization of control domain systems and functions; (3) the \u201cinformation domain,\u201d which focuses on managing and processing data from other domains, notably from the control domain; (4) the \u201capplication domain,\u201d which provides the application logic required to implement the various business functions; and (5) the \u201cbusiness domain,\u201d which implements business logic that supports business processes and procedural activities in the scope of an IIoT system. Overall, the IIRA provides a taxonomy of the main functional areas of industrial systems, which are relevant to Industry 5.0 systems and applications as well. The IIRA introduces a clustering of functionalities into different domains, which we will leverage in Sect. 3 toward introducing our Industry 5.0 architecture. Also, the IIRA illustrates how specific functions such as asset management and cybersecurity functions can be integrated with IIoT systems and provides insights about how to best structure the logical and implementation views of industrial architectures. The implementation view of the IIRA is based on a cloud/edge computing approach, which is also the suggested implementation approach for Industry 5.0 systems. Nevertheless, the IIRA does not include any specific provisions for human-centric industrial systems such as systems that collect and analyze information aboutReference Architecture for AI-Based Industry 5.0 Applications 7the context of the human user toward customizing the industrial functionalities accordingly. The Industrial Internet Security Framework (IISF) complements the IIRA with a security viewpoint for industrial systems [9]. One of the main objectives of the IISF is to prescribe the functions needed for the development, deployment, and operation of trusted IIoT. These functions are also essential for ensuring the trustworthiness of Industry 5.0 systems and their AI components in industrial environments. Thus, the structure and functions of IISF provided inspiration about how to support AI trustworthiness for industrial use cases. The IISF specifies functionalities that secure all the different elements of an industrial system such as the various communication endpoints of the system. Most of these functions can be used to boost the security and trustworthiness of Industry 5.0 systems as well, as they safeguard the operation of the networks, the data, and the data processing functions of Industry 5.0 systems. Specifically, the IISF is concerned with the five main characteristics that affect the trustworthiness of IIoT deployments, i.e., security, safety, reliability, resilience, and privacy. The framework specifies a functional viewpoint that is destined to secure IIoT systems compliant to the IIRA. To this end, the functional viewpoint specifies six interacting and complementary building blocks, which are organized in a layered fashion. The top layer comprises four security functions, namely endpoint protection, communications and connectivity protection, security monitoring and analysis, and security configuration management. Likewise, a data protection layer and a system-wide security model and policy layer are specified. Each one of the functional building blocks of the IISF can be further analyzed in more fine-grained functions such as monitoring functionalities, data analytics functionalities, and actuation functionalities. Each of these three types of functionalities include security-related functions. One more reference architecture for industrial systems, notably for fog comput-ing systems, was introduced by the OpenFog Consortium prior to its incorporation within the Industrial Internet Consortium in 2019 [10]. The OpenFog RA specifies the structure of large-scale fog computing system with emphasis on how fog nodes are connected to enhance the intelligence and to boost the efficiency of Industrial IoT systems. The OpenFog RA specifies some cross-cutting functionalities, which are characterized as \u201cperspectives.\u201d One of these perspectives deals with the security functionalities, which implies that security is applicable to all layers and use scenarios from the hardware device to the higher software layers of the architecture. As already outlined, such security functions are key to the development and deployment of trusted industrial systems of the Industry 5.0 era. The Big Data Value Association (BDVA) has specified the structure of big data systems based on the introduction of a reference model for big data systems [11]. The model illustrates a set of modules that are commonly used in big data systems along with structuring principles that drive their integration. The BDVA reference model consists of the following layers:\u2022 Horizontal layers that illustrate the modules and the structure of data processing chains. The modules of data processing chains support functions such as data8 J. Soldatos et al.collection, data ingestion, data analytics, and data visualization. The horizontal layers do not map to a layered architecture, where all layers must coexist in the scope of a system. For instance, it is possible to have a data processing chain that leverages data collection and visualization collection functions without necessarily using data ingestion and data analytics functionalities. Hence, the BDVA horizontal layers can be used as building blocks to construct data pipelines for AI systems.\u2022 Vertical layers that deal with cross-cutting issues such as cybersecurity and trust. The latter are applicable to all functionalities of the horizontal layers. Vertical layers can be also used to specify and address nontechnical aspects such as the ever important legal and regulatory aspects of AI systems. The horizontal and vertical layers of the reference model are used to produce concrete architectures for big data systems. There are clearly many commonalities between big data and AI systems as many AI systems (e.g., deep learning systems) are data-intensive and process large amounts of data. The BDVA RA does not, however, address functionalities that foster the development of Industry 5.0 systems, such as data quality and AI model explainability functionalities. As such it is mostly appropriate for architecting AI systems without special provisions for their trustworthiness and human centricity. Standards-based functionalities for AI systems are also specified by the ISO/IEC JTC 1/SC 42 technical committee on Artificial Intelligence [12]. The committee has produced several standards that cover different aspects of AI systems, such as data quality for analytics and machine learning (ML) (i.e., ISO/IEC DIS 5259-1), transparency taxonomy of AI systems (i.e., ISO/IEC AWI 12792), a reference architecture of knowledge engineering (i.e., ISO/IEC DIS 5392), functional safety and AI systems (i.e., ISO/IEC CD TR 5469), as well as objectives and approaches for explainability of ML models and AI systems (i.e., ISO/IEC AWI TS 6254). As evident from the above-listed descriptive titles, the ISO/IEC JTC 1/SC 42 technical committee addresses human centricity (e.g., safety, explainability) and trustworthiness (e.g., data quality, explainability) issues for Industry 5.0 systems. Nevertheless, most of the relevant standards are under development and not yet available for practical applications and use. In recent years, the IEEE (Institute of Electrical and Electronics Engineers) SA (Standards Association) is developing a suite of standards (i.e., standards of the IEEE 7000 family) that deal with the ethical aspects of AI systems. For instance, the IEEE 7000-2021 standard titled \u201cIEEE Standard Model Process for Addressing Ethical Concerns during System Design\u201d [13] specifies a process that organizations can follow to ensure that their AI systems adhere to ethical values and integrate ethical AI concepts within their systems\u2019 development lifecycle. These standards can facilitate the development of Industry 5.0. However, they are mostly focused on development, deployment, and operational processes rather on how to structure Industry 5.0 systems. Overall, there is a still a lack of standards-based architectures and blueprints for the development of Industry 5.0 systems. Hence, AI developers, deployers, andReference Architecture for AI-Based Industry 5.0 Applications 9engineers have no easy ways to structure, design, and build nontrivial trustworthy human-centric AI systems [14]. 3 Architecture for AI-Based Industry 5.0 Systems (STAR-RA) 3.1 High-Level Reference Model for AI-Based Industry 5.0 Systems 3.1.1 Overview A high-level reference model for AI-based Industry 5.0 systems is illustrated in Fig. 1. The model specifies a set of functionalities that foster trustworthiness and safety of AI systems in-line with the mandates of Industry 5.0. It clusters Industry 5.0 functionalities in three main categories or functional domains according to the terminology of the Industrial Internet Reference Architecture (IIRA). The three domains are as follows:\u2022 Cybersecurity domain: This domain includes functionalities that boost the cybersecurity and cyber resilience of AI systems in industrial settings. These functionalities ensure the reliability and security of industrial data, as well as of the AI algorithms that are trained and executed based on these data. The functionalities of this domain support and reinforce the trustworthiness of the project\u2019s functions in the other two domains.\u2022 Human\u2013robot collaboration (HRC) domain: This domain provides functionali-ties for the trusted collaboration between human and robots. It leverages cyber-security functionalities, while reinforcing functionalities in the safety domain. The specified functionalities aim at boosting trusted interactions between humans and AI systems in ways that yield better performance than humans or AI systems alone. In this direction, this domain leverages AI models that foster the collaboration between humans and AI systems such as active learning [15] and neurosymbolic learning (e.g., [16, 17]).\u2022 Safety domain: This domain comprises functionalities that ensures the safety of industrial operations, including operations that involve workers and/or automa-tion systems. For instance, functionalities in this domain reinforce worker safety, while boosting the safe operation of AMRs (automatic mobile robots). For each one of the functional domains, Fig. 1 presents a set of functionalities, notably functionalities that are actually implemented and validated in the context of the H2020 STAR project. These functionalities are illustrated in the following subparagraphs. Note, however, that they are by no means exhaustive, as it is possible to specify additional functionalities that boost the cybersecurity, HRC and safety of AI-based functionalities in AI systems.10 J. Soldatos et al.Fig. 1 STAR high-level reference model for Industry 5.0 systems Explainable AI (XAI) has a prominent role in the high-level reference model of Fig. 1. This is because XAI functionalities provide support to various functionalities of the different domains. For instance, XAI is an integral element of AI models that foster HRC such as neurosymbolic learning. Similarly, XAI can be used to identify potential attempts to tamper AI systems by altering their operations. As such XAI is positioned as a cross-cutting functionality of XAI systems. As shown in Fig. 1, machine learning platforms are among the main pillars of AI-based Industry 5.0 systems as most of the functionalities are deployed and executed over such platforms. This is, for example, the case for AI systems that implement cyber-defense strategies in the cybersecurity domain and reinforcement learning systems that detect safety zones in the safety domain. 3.1.2 Cybersecurity Domain Functionalities Cybersecurity functionalities are key to ensuring the trustworthiness of AI systems. This is because they ensure the trustworthiness and reliability of industrial data and the AI models that are trained and developed based on these data. Moreover, they protect these systems from cybersecurity attacks that could compromise their operation and break the trust on their operation. A set of indicative functionalities that have been implemented in the STAR project include:\u2022 Secure networked data collection: This refers to the implementation of secure networked protocols for accessing industrial data stemming from Cyber-Physical Systems (CPS) and enterprise applications (e.g., ERP (Enterprise Resource Planning) of an industrial site. For instance, they entail the implementation of data collection probes based on secure networked protocols such as TLS (Transport Level Security) and HTTS (Secure HyperText Transport Protocol).\u2022 Data provenance and traceability: Data provenance and traceability of industrial data is key toward ensuring industrial data reliability. Specifically, provenanceReference Architecture for AI-Based Industry 5.0 Applications 11and traceability functionalities enable AI system developers to continually access properties and characteristics of the source industrial data (e.g., hash codes, statistical properties) in order to implement tamper-proof functionalities [18]. Such functionalities can be implemented for both source data and AI models built on them to help preventing their tampering by malicious actors.\u2022 Risk assessment and mitigation: Risk assessment and mitigation functionalities are integral to most cybersecurity systems. In the case of AI-based industrial systems, they provide the means to identify, assess, and install mitigation measures against potential cybersecurity risks. Some of these risks (e.g., data falsification) can be mitigated based on other functionalities of the cybersecurity domain (e.g., provenance and traceability).\u2022 Security Policies Manager: This functionality makes provision for the specifica-tion and implementation of security policies for AI systems. It is a placeholder for a wide range of policies such as authenticated and authorized access to industrial data and AI functions.\u2022 AI cyber-defense strategies: AI systems are subject to additional vulnerabilities and cyber-resilience risks. For example, hackers can launch data poisoning attacks that alter the data that are used for training machine learning systems toward compromising their operation (e.g., [19]). Likewise, AI systems must be robust against evasion attacks that manipulate input data toward producing errors in the operation of machine learning systems (e.g., [20]). AI cyber-defense functionality aim at mitigating and confronting such attacks based on techniques such as auditing of the training data and formal verification of the input data. 3.1.3 HRC Domain Functionalities The list of HRC functionalities of the high-level reference model includes:\u2022 AI for human\u2013robot collaboration: Beyond classical machine learning models and paradigms, there are machine learning approaches that foster the interplay between humans and AI systems to enable effective HRC. This is, for example, the case with active learning systems, where robots and ML systems can consult a human expert to deal with uncertainty during data labeling processes. Active learning approaches accelerate knowledge acquisition by AI systems, facilitate HRC, and improve the overall performance and trust of AI deployments.\u2022 Knowledge management and representation: The knowledge of proper repre-sentation and management of HRC processes is key to the implementation of effective human\u2013AI interactions. In this direction, semantic modeling techniques (e.g., semantic knowledge graphs) are employed to facilitate AI systems to understand and reason over the context of the HRC process [21].\u2022 HMI for feedback collection and management: HRC systems involve interactions between humans and AI systems, including the provision of feedback from the human to the AI system. This is, for example, the case in the above-mentioned active learning systems where humans provide data labeling feedback to AI12 J. Soldatos et al.systems. To implement such feedback collection and management functionali-ties, the HRC domain includes placeholders for proper HMI (human machine interfaces) such as NLP (natural language processing) interfaces.\u2022 Simulated reality: Simulated reality systems enable the training of HRC systems in the scope of virtual simulated environments. They are usually linked to reinforcement learning systems that are trained in virtual rather than in real environments. Their inclusion in the reference model signals the importance of training humans for HRC functionalities in a safe environment. As such they are also enablers of functionalities in the safety domain of the AI-based Industry 5.0 reference model, such as functionalities for safety zones detection.\u2022 Human digital twin (HDT): This is a placeholder for human-centered digital twins, which are digital twin systems that comprise information about the characteristics and the context of the human workers [22]. HDT systems are ideal for modeling, developing, and implementing HRC systems that blend AI systems with human actors, while modeling and simulating their interactions. 3.1.4 Safety Domain Functionalities The safety domain of the reference model outlines functionalities that are key to ensuring the safe operation of AI systems (e.g., robots) in the scope of Industry 5.0 scenarios. It identifies the following indicative but important functionalities:\u2022 Object localization and tracking: This functionality aims at identifying the location of objects within industrial environments, notably of moving objects such as mobile robots. The localization and tracking of such functionalities are integral elements of applications that safeguard the safe operation of robotics and AI systems in industrial environments.\u2022 Safety zones detection: Automation systems that move within an industrial environment (e.g., shopfloor, plant floor) must follow safe trajectories that minimize the risk of collisions between automation systems, humans, and other stationary elements of the workplace. In this direction, the detection of safety zones based on AI technologies (e.g., reinforcement learning [23]) can increase the safety of the AI systems and minimize related risks.\u2022 Safe automatic mobile robots: This functionality is a placeholder for systems that ensure the safe movement of automatic mobile robots. The implementation of this functionality can benefit from other functionalities of this domain such as the detection of safety zones.\u2022 Worker safety: Apart from ensuring the safe operation and movement of robotic systems, it is important to ensure the safety of the workers. Workers\u2019 safety is at the heart of Industry 5.0 system that emphasize human centricity. The respective functionalities ensure that workers act within safe environments and that the emotional and physical context of the human is properly considered in the design, development, deployment, and operation of AI systems.Reference Architecture for AI-Based Industry 5.0 Applications 13\u2022 Fatigue monitoring system: Fatigue monitoring is a very prominent example of a human-centered functionality that can boost both the performance and the safety of industrial systems. It collects and analyzes information about the fatigue of the worker, which can then be used to drive the adaption of AI and Industry 5.0 systems toward a worker-centric direction. 3.2 Logical Architecture for AI-Based Industry 5.0 Systems 3.2.1 Driving Principles Figure 2 illustrates a specific instantiation of the reference architecture model, which has been implemented in the scope of the STAR project [25] and is conveniently called STAR-RA in the scope of this chapter. The architecture is presented in the form of a logical view, which comprises functional modules along with their structure and their interactions with other systems. It can serve as a basis for implementing, deploying, and operating AI-based Industry 5.0 systems. Systems compliant to the STAR-RA aim at securing existing AI-based CPPS systems in manufacturing production lines based on a holistic approach that pursues the following principles that are fully in-line with the earlier presented high-level architecture:\u2022 Secure and reliable data: The STAR AI systems must operate over reliable industrial data, i.e., the architecture makes provisions for alleviating the inherent unreliability of industrial data. Fig. 2 STAR reference architecture for AI-based Industry 5.0 systems14 J. Soldatos et al.\u2022 Secure and trusted AI algorithms: Systems compliant to the STAR-RA enhance the secure operation of the AI systems and algorithms that they comprise. In this direction, they make provisions for implementing cyber-defense strategies that protect and defend AI systems from malicious security attacks. STAR-RA compliant systems focus on defenses against cybersecurity attacks. Physical security attacks may be applicable to some industrial systems (e.g., robotics systems), yet they are not address by the STAR-RA.\u2022 Trusted human AI interactions: The presented architectures focus on the imple-mentation of trusted interactions between humans and AI systems. On the one hand, it ensures that AI systems are transparent and explainable to humans toward boosting their acceptance and adoption. On the other hand, it also focuses on safe and trusted interactions between humans and AI systems in HRC scenarios.\u2022 Safe AI systems: The architecture boosts the safety of autonomous AI systems such as mobile robots. For example, it focuses on the secure placement and movement of autonomous mobile robots (AMRs) within industrial plants. The above listed functionalities and the logical modules that implement them can not only work independently but also in synergy with each other. For instance, reinforcement learning (RL) algorithms can be used to ensure the safe operation of AMRs, which contributes to the trusted operation of AI systems. Such RL algorithms can operate independently from other modules. However, they can also be integrated with the industrial data reliability systems of the cybersecurity domain toward ensuring that they operate over trusted and reliable industrial data. This boosts and reinforces their trustworthiness. Moreover, they can be integrated with AI-based cyber-defense strategies to ensure that they cannot be tampered or compromised by malicious parties. This is yet another measure to strengthening the trustworthiness of AI systems for safe AMR operations. Overall, when integrating and combining multiple modules of the architecture, manufacturers and system integrators can gain a multiplicative trustworthiness benefit, as one system can reinforce the other. This architectural proposition provides the structuring principles for integrating the AI-based industrial systems of the Industry 5.0 era. However, the presented functional modules do not represent an \u201call-or-nothing\u201d value proposition. Manufac-turers and AI systems integrators can adopt and implement parts of the STAR-RA, i.e., specific modules of the logical architecture. As illustrated in Fig. 2, the architecture enables the development of AI systems that receive data from the shopfloor (i.e., digital manufacturing platforms and other AI-based CPPS systems) and provide different types of AI-based services to factory (cyber)security teams and to other factory stakeholders (e.g., industrial engineers, plant managers, factory workers). The alignment of the different modules to the high-level architecture of the previous subsection is illustrated by means of their color, i.e., blue-colored modules belong to the cybersecurity domain, red-colored modules to the safety domain and green-colored to the HRC domain.Reference Architecture for AI-Based Industry 5.0 Applications 153.2.2 Logical Modules The main modules and building blocks of the architecture are illustrated in the following subparagraphs. Digital Manufacturing Platforms and CPPS Systems The architecture enables the development of secure, safe, and trusted AI systems in production lines. To this end, systems compliant to the STAR-RA collect and process data from AI-based systems in the shopfloor, including machines, robotic cells, AMRs, and other digital manufacturing platforms. Industry 5.0 systems comprise various CPPS systems and digital manufacturing platforms that serve as data sources for other logical modules. The latter may also consume data from other data sources in the shopfloor such as business information systems (e.g., ERP (Enterprise Resource Planning)) and manufacturing databases (e.g., historian systems). Industry 5.0 Applications This building block represents different types of AI-based industrial applications such as machine learning (ML) and robotics applications. They leverage information and data sources from the shopfloor. In some cases, they are integrated with the digital manufacturing platforms as well. Other modules of the architecture collect data from them and analyze their behavior toward boosting the security and trustworthiness of their operation. AI-based Industry 5.0 applications can also be data sources that provide data to other logical modules and data-driven systems of the architecture. Secure Networked Probes (SNP) This building block provides a secure data collection solution that offers a real time data collection, transformation, filtering, and management services to facilitate data consumers (e.g., the AI cyber-defense module and the Security Policies Manager) in accessing the required data. For example, it can be used to collect security-related data (e.g., network, system, and solution proprietary) from monitored IoT systems and store them to detect patterns of abnormal behavior by applying simple (i.e., filtering) or more elaborate (i.e., deep learning) data processing mechanisms. The solution features specialized probes that may be deployed within the monitored IoT/CPPS system or poling services for acquiring data from shopfloor sources such as CPPS systems and digital manufacturing platforms. The module belongs to the cybersecurity domain of the high-level reference architecture.16 J. Soldatos et al.Data Provenance and Traceability (DPT) The DPT module belongs to the cybersecurity domain and provides the means for tracking and tracing industrial data. It interfaces to the data probes to acquire information about the industrial data of the shopfloor such as information about data types, volumes, and timestamps. Accordingly, it records this information (i.e., the metadata) about the acquired data to facilitate the detection of data abuse and data tampering attempts. Specifically, data ingested in the DPT can be queried by other modules to facilitate the validation of datasets and to ensure that the data they consume have not been falsified. In this way, the DPT module reinforces the reliability and the security of the industrial data that flow through the system. Blockchain \u2013 Distributed Ledger Infrastructure There are different ways for implementing a DPT infrastructure for industrial data. The STAR-RA promotes a decentralized approach, which leverages the benefits of distributed ledger technologies, i.e., a blockchain protocol. Distributed ledger infras-tructures offer some advantages for industrial data provenance, such as immutable and tamper-resistant records. They also provide a comprehensive and auditable trail that records the history of data transactions, including creation, modification, and transfer events. In addition, blockchains enable the implementation of Smart Contracts (SC) over the distributed ledger infrastructure, notably SCs that are used to validate the metadata of the industrial datasets that are recorded in the blockchain. SCs enable decentralized applications that provide information about the metadata to interested modules such as the cyber-defense strategies module. AI Cyber-Defense Strategies (ACDS) This module implements cyber-defense strategies for AI systems, i.e., strategies that protect AI systems against adversarial attacks. These strategies operate based on access to industrial data from:\u2022 The AI systems (including ML systems) that must be protected from cybersecu-rity attacks.\u2022 The CPPS and digital manufacturing platforms that act as data sources.\u2022 The metadata of the industrial data that are managed by the DPT module and its blockchain implementation.\u2022 The explainable AI (XAI) module, which implements explainable AI models that illustrate and interpret the operation of various AI systems and algorithms. The module materializes different strategies in response to attacks against AI sys-tems. For instance, it implements cyber-defense strategies for poisoning and evasion attacks. Nevertheless, additional cyber-defense strategies can be implemented and integrated with the rest of the modules (i.e., secure networked data probes, DPT).Reference Architecture for AI-Based Industry 5.0 Applications 17A data integration infrastructure (e.g., based on a data bus pattern) can be used as a data exchange middleware infrastructure to facilitate data transfer and data sharing across different modules involved in the detection of a cybersecurity attacks, i.e., the DPT, the ACDS, and the SNP. Risk Assessment and Mitigation Engine (RAME) This module implements the security risk assessment and mitigation service of the STAR-RA in-line with the cybersecurity domain of the high-level architecture. The module assesses risk for assets associated with AI-based systems in manufacturing lines. In this direction, it interacts with the AI cyber-defense strategies modules as follows: (1) the defense strategies communicate to the RAME information about identified risks for AI assets; and (2) the RAME consumes information from the DPT to assess risks. It also offers mitigation actions for the identified risks such as changes to the configuration of a probe via the SNP module. Security Policies Manager (SPM) \u2013 Security Policies Repository (SPR) This module defines and configures security policies that govern the operation of the DPT, AI cyber-defense, and the RAME modules. Specifically, the module specifies security policies that provide information about the probes and data sources to be integrated, the configurations of the probes, as well as the cyber-defense strategies to be deployed. By changing the applicable policies, the SPM changes the configuration and the operation of other modules of the cybersecurity domain (e.g., DPT, RAME, ACDS). The operation of the SPM is supported by a Security Policies Repository (SPR), where policy files are persisted. Furthermore, the SPM offers a GUI (graphic user interface) to the security officers of the factory (e.g., members of CERT (computer emergency response teams)). Machine Learning and Analytics Platform Several modules of the architecture are based on machine learning algorithms, including deep learning and reinforcement learning. This is, for example, the case of the ACDS module, which implements AI-based defense strategies among others. Another prominent example is the XAI module, which produces explainable ML models. The machine learning and analytics platform supports the operation of these AI systems. It enables developers and users of the STAR-RA modules (i.e., data scientists, domain experts, ML engineers) not only to specify and execute ML models but also to access their metadata and outcomes. The platform interacts with modules that provide datasets for training and executing AI algorithms such as the SDP module.18 J. Soldatos et al.Explainable Artificial Intelligence (XAI) This module provides and executes XAI models and algorithms. It provides the means for executing different types of XAI algorithms such as algorithms for explaining deep neural networks and general-purpose algorithms (e.g., LIME \u2013 Local Interpretable Model-Agnostic Explanations) [24] that explain the outcomes of AI classifiers. As such the module is a placeholder of XAI techniques. The XAI module provides its services to several other modules that leverage explainable algorithms, such as the AI cyber-defense strategies module and the simulated reality (SR) modules. Simulated Reality (SR) This module simulates production settings in a virtual world with a twofold objective: (1) producing data to be used by AI algorithms, especially in cases where real-world data are not available at adequate quantities; and (2) utilizing reinforcement learning techniques in artificial settings (i.e., simulated environments) toward accelerating their convergence. SR leverages services from the XAI module, which facilitate humans to assess the appropriateness and correctness of the simulated data that are generated by the SR. Active Learning (AL) and Neurosymbolic Learning This module provides a placeholder for machine learning paradigms that foster HRC, i.e., modules of the HRC domain of the high-level reference architecture. Such paradigms include active learning and neurosymbolic learning, which help robots and AI systems to benefit from human expertise in the context of human in the loop industrial processes. These machine learning techniques for HRC fall in the scope of the HRC domain of the high-level architecture. Production Processes Knowledge Base (PPKB) This module consolidates domain knowledge about the production processes of the manufacturing environment. It is used for inferencing by the other modules such as the AL and neurosymbolic learning modules. The latter modules can interact and update the module with knowledge acquired by the humans in the scope of human-in-the-loop processes. Therefore, it also falls in the scope of the HRC domain.Reference Architecture for AI-Based Industry 5.0 Applications 19AMR Safety This module comprises RL techniques that boost the safety of AMRs in industrial environments such as manufacturing shopfloors. It provides insights on the safe placement of robots in a manufacturing environment. To this end, it incorporates functionalities such as objective localization and safety zones detection of the safety domain of the high-level architecture of Fig. 1. Human-Centered Digital Twin This module implements a digital twin that factors human-centered parameters (e.g., fatigue, emotional status of the worker). It is a placeholder for digital twins of human-centered processes, including AI-based processes that have the human in the loop. It interacts with the analytics platforms, the workers, and the humans\u2019 digital models. The HDT offers a centralized access point to exploit a wide set of workers\u2019 related data. It leverages a digital representation of the workers, which is seamlessly integrated with production system DTs. The latter can be exploited by AI-based modules to compute complex features that, enriching the HDT, enable better decisions, and dynamically adapt automation systems behavior toward improving production performance, workers\u2019 safety, and well-being. Human Models \u2013 Human Digital Images This module persists and manages data about the human worker toward supporting the construction, deployment, and operation of HDTs. They provide the means for creating and using digital representations of the workers. Graphical User Interface (GUI) \u2013 Human Machine Interface (HMI) This module provides a GUI interaction modality between factory workers and AI systems. It comprises visualization elements (e.g., dashboards), while enabling users to interact with the AI-based modules (e.g., provide form-based input). Natural Language Processing (NLP) This module enables NLP interactions between the factory users and relevant AI modules (e.g., AL modules). It is a placeholder for different NLP implementations and interfaces.20 J. Soldatos et al.Feedback Module This module coordinates the provision of feedback from the human worker to the AI system. It is particularly important for the implementation of human\u2013AI systems interactions (e.g., HRC scenarios). The feedback module interfaces to some interaction module (e.g., GUI or NLP) that enables the transferring of user data to the feedback module and vice versa. Fatigue Monitoring System This module leverages sensors and IoT devices (e.g., electroencephalography (EEG) sensors) to collect information about the worker\u2019s fatigue. The collected information is transferred to other modules such as the human models and the HDT. 4 Solution Blueprints for Industry 5.0 Applications 4.1 The Industry 5.0 Blueprints Concept The STAR-RA for Industry 5.0 applications can be used to support the imple-mentation of popular secure and trustworthy data-driven use cases in industrial environments. In this direction, selected functional modules of the STAR-RA can be deployed and operated. The specification of the modules and the information flows that can support specific HRC, cybersecurity, and safety solutions in Industry 5.0 context can be defined as blueprints over the introduced architecture. Each blueprint provides a proven way to implement trusted data processing and AI functionalities for industrial applications. Rather than having to read, browse and understand the entire STAR-RA and its low-level technical details, interested parties (e.g., solution integrators, manufacturers, researchers in industrial automation, and digital manufacturing) could consult blueprints as practical ways for enhancing the trustworthiness and regulatory compliance of their work. Following paragraphs illustrate blueprints for popular technical solutions and for the adherence of Industry 5.0 to the AI regulation proposal of the European Parliament and the Council of Europe. 4.2 Technological Solutions Blueprints Several blueprints can be defined based on the AI cyber-defense strategies (ACDS) to support use cases for defending cybersecurity attack against AI systems. As a prominent example, Table 1 illustrates the blueprint against defending a poisoningReference Architecture for AI-Based Industry 5.0 Applications 21Table 1 Poisoning attack defense Blueprint title Poisoning attack defence Scope and purpose Detect with high accuracy a poisoning attack against an AI/ML system, i.e., cases where an attacker compromises the learning process based on adversarial examples, in ways that compromise the AI systems ability to produce correct/credible results. STAR-RA components involved Analytics platform, STAR blockchain (distributed ledger infrastructure), DPT (data provenance and traceability), risk assessment and mitigation engine, XAI module Trigger (Re-)Training Process Model check Model check response Attack Detection Module STAR Machine Learning & Analytics Platform Data Storage STAR BlockChain XAI Risk Assessment Acquire Training Data Training Data Data Provenance Request Feature Importance Scores Detection of malformed instances Analytics XAI Features request Belief Fig. 3 STAR implementation of AI cyber-defence information flow attack, where an adversary attempts to contaminate the data used to train an AI system. Figure 3 presents the information flow between the various components of this blueprint, as implemented in the STAR project. As another example, Table 2 presents a blueprint for solutions that validate the integrity of industrial data. This is crucial in the scope of Industry 5.0 applications as it is a foundation for ensuring industrial data reliability. Different types of industrial data can be protected based on this blueprint, such as CPPS data and analytics results (including AI outcomes). Figure 4 illustrates the information flow between different blockchain components that implement data integrity validation blueprint. 4.3 Regulatory Compliance Blueprints Regulatory compliance blueprints illustrate how the STAR-RA and its component could be leveraged to boost the adherence of AI solutions to the AI regulation22 J. Soldatos et al.Table 2 Validating the integrity of industrial data Blueprint title Validating the integrity of industrial data Scope and purpose Retrieve persisted critical measurements (e.g., analytics results) from the blockchain to be validated/compared with existing data to verify their authenticity based on their metadata properties STAR-RA components involved Data models, blockchain (distributed ledger infrastructure), DPT (data provenance and traceability) Fig. 4 STAR implementation of data integrity validation information flow proposal of the European Commission. In April 2021, the European Parliament and the Council of Europe presented an initial proposal for the regulation of AI systems [6]. This proposal is the first organized and structured effort to regulate AI systems worldwide. Its importance for systems deployed within Europe is particularly high, given that it lays a basis for future laws within the various EU member states. The proposal establishes a technology-neutral definition of AI systems in EU law, while presenting a risk-based classification of AI systems. The classification proposes to categorize AI systems in four general classes, ranging from unacceptable risk to no risk (i.e., risk free) systems. It also outlines the requirements and obligations associated with the deployment of systems from each one of the envisaged risk levels. For instance, \u201chigh-risk\u201d AI systems can be authorized if and only if they meet requirements spanning the areas of transparency, explainability, data quality,Reference Architecture for AI-Based Industry 5.0 Applications 23Table 3 Supporting the deployment of AI systems of minimal risk Blueprint title Supporting the deployment of AI systems of minimal risk Scope and purpose Support adherence to codes of conduct that mandate transparency of AI system STAR-RA components involved (Optional) XAI (for transparency); (optional) security policies manager (for increased cybersecurity); (optional) AI cyber-defence strategies (ACDS) (for AI cybersecurity) Table 4 Supporting the deployment of AI systems of limited risk Blueprint title Supporting the deployment of AI systems of limited risk Scope and purpose Support the mandatory transparency of AI system; provide optional support for increasing the security and safety of limited risk AI systems STAR-RA components involved (Mandatory) XAI (for transparency); (optional) blockchain (distributed ledger infrastructure) and DPT (data provenance and traceability) for data quality; (optional) security policies manager (for increased cybersecurity); (optional) AI cyber-defence strategies (ACDS) (for AI cybersecurity) and more. These obligations are significantly lower for medium- and low-risk systems. STAR-RA includes technical components that can help AI deployers and operators to meet regulatory requirements and obligations. Different components can be used to support systems belonging to the different risk classes of the AI Act. For example, the AI Act specifies that minimal-risk systems (e.g., ML-based calculations and visualization of information about physical assets) can be deployed without essential restrictions. There are no mandatory obligations for minimal risk systems. Compliance to AI code of conduct for them is recommended, yet optional. Deployers may therefore choose to deploy one or more STAR components from the different domains of the platform (cybersecurity, human\u2013robot collaboration, safety), as well as explainable AI components as illustrated in the relevant regulatory blueprint of Table 3. On the other hand, when deploying a limited risk system, AI deployers must ensure that they are meeting transparency obligations. In this direction, humans must be notified of the existence of an AI system component in the loop of the industrial process. This concerns industrial processes with the human in the loop, where AI systems and human interact. It is, for example, the case of some HDT applications where industrial systems collect information about the status of the worker and adapt their operations to it. The STAR-RA includes XAI components that can help deployers meet the requirements of limited risk deployments. Deployers can optionally use other STAR components to increase the safety, security, and overall trustworthiness of the AI system (see Table 4). Many AI systems in manufacturing and other industrial environments can be classified as being high risk. This is, for example, the case with systems involving AMRs and other types of industrial robots. In the case of high-risk systems,24 J. Soldatos et al.Table 5 Supporting the deployment of AI systems of high risk Blueprint title Supporting the deployment of AI systems of high risk Scope and purpose Support the mandatory transparency, security, data quality, and safety of high-risk AI systems STAR-RA components involved (Mandatory) XAI (for transparency); blockchain (distributed ledger infrastructure) and DPT (data provenance and traceability) for data quality; security policies manager (for increased cybersecurity); (optional) AI cyber-defence strategies (ACDS) (for AI cybersecurity) deployers and operators must comply with a longer list of requirements, including more stringent specifications regarding explainability, transparency, data quality, and more. To support the qualification, deployment and use of such high-risk systems, STAR-RA offers many relevant components that support data reliability, AI algorithms\u2019 reliability, increased cybersecurity, safe human\u2013robot collaboration, and more. The use of these systems in a high-risk AI context becomes mandatory rather than optional. This is illustrated in Table 5. 5 Conclusions Despite the rising interest in trustworthy and human-centered Artificial Intelli-gence systems for Industry 5.0 deployments, existing reference architectures and blueprints for AI applications do not adequately address the development and deployment of trusted AI solutions. This chapter has introduced an architecture model that can boost the design and development of trustworthy and human-centered AI applications. It has also described few indicative blueprints for the development of technical solutions and regulatory-compliant systems in-line with the architecture. At a high level, the presented architecture clusters functionalities in three complementary domains, including cybersecurity, human\u2013robot collaboration, and safety. The functionalities in each one of the domains reinforce functionalities in the other domains. Moreover, the XAI components of the project are used to support functionalities in all three domains. The presented architecture and its functional modules do not present an \u201call or nothing\u201d value proposition. Rather manufacturers and integrators of AI solutions in industrial environments can select subsets of components of the reference architecture to meet different sets of industrial requirements. However, the presented views of the architecture do not go down to implementation detail, but rather provide higher level structuring principles and blueprints for the implementation of trustworthy AI systems. Some of the presented blueprints provide guidance on how to use STAR-RA components to implement systems that adhere to the mandates of the AI regulation proposal of the European Parliament and the Council of Europe. This guidance isReference Architecture for AI-Based Industry 5.0 Applications 25important for companies that seek to comply with the AI Act and to demonstrate regulatory readiness. The inclusion of this chapter in this open access book aspires to raise awareness about both the technical and the regulatory aspects of trustworthy and human-centered solutions for manufacturing. Acknowledgments This work has been carried out in the H2020 STAR project, which has received funding from the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No. 956573. The authors acknowledge valuable support from all partners of the project. References 1. Soldatos, J., Lazaro, O., Cavadini, F. (eds.): The Digital Shopfloor: Industrial Automation in the Industry 4.0 Era River Publishers Series in Automation, Control and Robotics. River Publishers, Gistrup (2019) ISBN: 9788770220415, e-ISBN: 9788770220408 2. Christou, I., Kefalakis, N., Soldatos, J., Despotopoulou, A.: End-to-end industrial IoT platform for Quality 4.0 applications. Comput. Ind. 137, 103591. ISSN 0166-3615 (2022). https:// doi.org/10.1016/j.compind.2021.103591 3. European Commission.: Industry 5.0 \u2013 what this approach is focused on, how it will be achieved and how it is already being implemented. European Commission. https://research-and-innovation.ec.europa.eu/research-area/industrial-research-and-innovation/industry-50_en (2023). Last accessed 26 June 2023 4. Nahavandi, S.: Industry 5.0\u2014a human-centric solution. Sustainability. 11, 4371 (2019). https:/ /doi.org/10.3390/su11164371 5. Dwivedi R., Dave D., Naik H., Singhal S., Omer R., Patel P., Qian B., Wen Z., Shah T., Morgan G., Ranjan R.: Explainable AI (XAI): Core ideas, techniques, and solutions. ACM Comput. Surv. 55, 9 (2023), Article 194 (September 2023), 33 pages. https://doi.org/10.1145/3561048 6. Proposal for a Regulation of The European Parliament and of the Council laying down harmonized rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts, COM/2021/206 final. https://eur-lex.europa.eu/legal-content/EN/TXT/ ?uri=celex%3A52021PC0206. Last accessed 26 June 2023 7. Industrial Internet Consortium.: The Industrial Internet Reference Architecture v 1.9. Available at: https://www.iiconsortium.org/IIRA.htm. Last accessed 26 June 2023 8. ISO/IEC/IEEE.: ISO/IEC/IEEE 42010:2011 Systems and software engineering \u2013 Architec-ture description. http://www.iso.org/iso/catalogue_detail.htm?csnumber=50508 (2011). Last accessed 26 June 2023 9. Industrial Internet Consortium.: The Industrial Internet Security Framework. Available at: https://www.iiconsortium.org/IISF.htm. Last accessed 26 June 2023 10. IEEE Standard for Adoption of OpenFog Reference Architecture for Fog Computing. IEEE Std 1934-2018, 1\u2013176, 2 Aug 2018. https://doi.org/10.1109/IEEESTD.2018.8423800 11. European Big Data Value Strategic Research and Innovation Agenda, Version 4.0, October 2017. https://bdva.eu/sites/default/files/BDVA_SRIA_v4_Ed1.1.pdf. Last accessed 26 June 2023 12. ISO/IEC JTC 1/SC 42 Artificial intelligence. https://www.iso.org/committee/6794475.html. Last accessed 26 June 2023 13. IEEE Standard Model Process for Addressing Ethical Concerns during System Design. IEEE Std 7000-2021, 1\u201382, 15 Sept 2021. https://doi.org/10.1109/IEEESTD.2021.9536679 14. Ro\u017eanec, J., Novalija, I., Zajec, P., Kenda, K., Tavakoli, H., Suh, S., Veliou, E., Papamartzi-vanos, D., Giannetsos, T., Menesidou, S., Alonso, R., Cauli, N., Meloni, A., Reforgiato, R.D., Kyriazis, D., Sofianidis, G., Theodoropoulos, S., Fortuna, B., Mladenic\u0301, D., Soldatos,26 J. Soldatos et al.J.: Human-centric artificial intelligence architecture for industry 5.0 applications. Int. J. Prod. Res. (2022). https://doi.org/10.1080/00207543.2022.2138611 15. Liu, Z., Wang, J., Gong, S., Tao, D., Lu, H.: Deep reinforcement active learning for human-in-the-loop person re-identification. In: 2019 IEEE/CVF International Conference on Computer Vision (ICCV), Seoul, Korea (South), pp. 6121\u20136130 (2019). https://doi.org/ 10.1109/ICCV.2019.00622 16. Siyaev, A., Valiev, D., Jo, G.-S.: Interaction with industrial digital twin using neuro-symbolic reasoning. Sensors. 23, 1729 (2023). https://doi.org/10.3390/s23031729 17. D\u00edaz-Rodr\u00edguez, N., Lamas, A., Sanchez, J., Franchi, G., Donadello, I., Tabik, S., Filliat, D., Cruz, P., Montes, R., Herrera, F.: EXplainable Neural-Symbolic Learning (X-NeSyL) method-ology to fuse deep learning representations with expert knowledge graphs: the MonuMAI cultural heritage use case. Inf. Fusion. 79, 58\u201383., ISSN 1566-2535 (2022). https://doi.org/ 10.1016/j.inffus.2021.09.022 18. Soldatos, J., Despotopoulou, A., Kefalakis, N., Ipektsidis, B.: Blockchain based data prove-nance for trusted artificial intelligence. In: Soldatos, J., Kyriazis, D. (eds.) Trusted Artificial Intelligence in Manufacturing: A Review of the Emerging Wave of Ethical and Human Centric AI Technologies for Smart Production, pp. 1\u201329. Now Publishers, Norwell (2021). https:// doi.org/10.1561/9781680838770.ch1 19. Khurana, N., Mittal, S., Piplai, A., Joshi, A.: Preventing poisoning attacks on AI based threat intelligence systems. In: In IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP), pp. 1\u20136 (2019). https://doi.org/10.1109/MLSP.2019.8918803 20. Khorshidpour, Z., Hashemi, S., Hamzeh, A.: Learning a secure classifier against evasion attack. In: IEEE 16th International Conference on Data Mining Workshops (ICDMW), pp. 295\u2013302 (2016). https://doi.org/10.1109/ICDMW.2016.0049 21. Umbrico, A., Orlandini, A., Cesta, A.: An ontology for human-robot collaboration. Procedia CIRP. 93, 1097\u20131102 (2020) 22. Montini, E., Cutrona, V., Bonomi, N., Landolfi, G., Bettoni, A., Rocco, P., Carpanzano, E.: An IIoT platform for human-aware factory digital twins. Procedia CIRP. 107, 661\u2013667., ISSN 2212-8271 (2022). https://doi.org/10.1016/j.procir.2022.05.042 23. Andersen, P., Goodwin, M., Granmo, O.: Towards safe reinforcement-learning in industrial grid-warehousing. Inf. Sci. 537, 467\u2013484., ISSN 0020-0255 (2020). https://doi.org/10.1016/ j.ins.2020.06.010 24. Ribeiro, M., Singh, S., Guestrin, C.: \u201cWhy should I trust you?\u201d: explaining the predictions of any classifier. In: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD \u201816), pp. 1135\u20131144. Association for Computing Machinery, New York (2016). https://doi.org/10.1145/2939672.2939778 25. Soldatos, J., Kyriazis, K. (eds.): Trusted Artificial Intelligence in Manufacturing: A Review of the Emerging Wave of Ethical and Human Centric AI Technologies for Smart Production. Now Publishers, Boston-Delft (2021). https://doi.org/10.1561/9781680838770 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Designing a Marketplace to Exchange AI Models for Industry 5.0 Alexandros Nizamis, Georg Schlake, Georgios Siachamis, Vasileios Dimitriadis, Christos Patsonakis, Christian Beecks, Dimosthenis Ioannidis, Konstantinos Votis, and Dimitrios Tzovaras 1 Introduction Online marketplaces, locations on Internet where people can purchase and sale services and goods, have highly increased in the last couple of decades. Recently, various marketplaces for exchanging AI models have been introduced [1]. In these marketplaces the AI models and machine learning (ML) algorithms have been monetized and offered as products. AWS Marketplace1 by Amazon enables its customers to find a large variety of pre-built models and algorithms covering a wide range of use cases and domains related to Business Analytics, Computer Vision, Healthcare, and Text and Language Processing. A subscription-based model with charging per hour, day, etc. is primarily adopted. A monthly based subscription model is also offered by Akira.AI.2 This marketplace offers AI models especially for solutions related to Text Analysis and Computer Vision along with access to processing, storage, and network resources for enabling the execution of AI models. Pretrained models for a 1 https://aws.amazon.com/marketplace/solutions/machine-learning. 2 https://www.akira.ai. A. Nizamis (\u0002) \u00b7 G. Siachamis \u00b7 V. Dimitriadis \u00b7 C. Patsonakis \u00b7 D. Ioannidis \u00b7 K. Votis \u00b7 D. Tzovaras Centre for Research and Technology Hellas, Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece e-mail: alnizami@iti.gr; giosiach@iti.gr; dimvasdim@iti.gr; cpatsonakis@iti.gr; djoannid@iti.gr; kvotis@iti.gr; Dimitrios.Tzovaras@iti.gr G. Schlake \u00b7 C. Beecks FernUniversity of Hagen, Hagen, Germany e-mail: georg.schlake@fernuni-hagen.de; christian.beecks@fernuni-hagen.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_22728 A. Nizamis et al.wide variety of sectors are also available at the Gravity AI3 and Modelplace AI4 (specialized in Computer Vision) marketplaces. The latter enables the real-time execution of models through web\u2013browser interfaces. Other marketplaces5 move a step further from live execution to shared building of models among developers by providing software development kits (SDKs). Some specific AI marketplaces for healthcare domain are also available such as the Imaging AI Marketplace6 by IBM. It is a centralized marketplace that enables healthcare providers to discover, purchase, and manage applications that provide the latest AI-powered tools. In this marketplace, researchers and developers can reach a large community of customers for their specific AI applications for eHealth domain and take advantage of the provided infrastructure and deployment processes. To this direction, Nuance Communications7 has introduced its marketplace for Healthcare AI solutions as well providing similar functionalities as the IBM one. In addition to word-leaders\u2019 approaches and market-ready solutions, EC-funded research projects have presented various marketplaces for listing or even trading solutions including AI/ML algorithms. AI4EUROPE or AI on Demand [2] offers  a trustworthy open-source platform for the development, training, and sharing of AI/ML models. However it is considered more as an open code repository as it lacks business logic in comparison with commercial marketplaces. MARKET4.0 project [3] develops a multi-sided business platform for plug and produce industrial product service systems. The European Factory Foundation and EFPF project [4] offers a  Portal/Marketplace as part of its interoperable Data Spine that includes solutions coming from previous EU projects and third-parties\u2019 initiatives. However the solutions are a mix of software solutions, products, and services. Other marketplaces related to manufacturing domain and Industry 4.0 were provided by projects like v-fos [5] (which offers an application marketplace with an embedded SDK) and NIMBLE [6] that has introduced a federated interoperable eco-system for B2B connectivity. Some other approaches [7] coming from research introduced AI as enablers for marketplaces by combining virtual agents with semantics [8, 9] for  automated negotiations in manufacturing marketplaces [10]. In Boost 4.0 project a common European Data Space for manufacturing was introduced instead of a Marketplace. However, it contains AI services connected to available data sources based on IDSA8 architecture. The latter supports also the establishment of AI Marketplace9 that is a meeting place for AI providers and consumers. Recently,3 https://www.gravity-ai.com. 4 https://modelplace.ai/. 5 https://c3.ai/c3-ai-application-platform/c3-ai-integrated-development-studio/c3-ai-marketplace. 6 https://www.ibm.com/downloads/cas/6BWYDLDO. 7 https://www.nuance.com/healthcare.html. 8 https://internationaldataspaces.org/. 9 https://ki-marktplatz.com/en/. Designing a Marketplace to Exchange AI Models for Industry 5.0 29PoP-Machina project10 proposed a collaboration platform for makers that provides a marketplace based on a blockchain network infrastructure. However, it is focused more on collaborative design and not on AI model exchange. A blockchain approach for building marketplaces for AI was also introduced by IBM [11]. It was a back-end implementation regarding trusted transactions and not a full operational marketplace. As it is perceived there are market-ready solutions in the field of AI marketplaces, however they are focused on cases related to health, text recognition, computer vision, etc. and not to manufacturing and Industry 4.0/5.0 domains. On the contrary, there are marketplaces coming from research field that are related to Industry 4.0/5.0 domain, but either they lack some business logic or they collect heterogeneous solutions and even physical products, so they cannot be considered as marketplaces for exchanging of AI/ML models. In the current work, we are introducing the knowlEdge project\u2019s [12, 13] Marketplace that aims to deliver a marketplace for exchanging AI models for smart manufacturing using blockchain services and smart contracts as the core of its business logic. The introduced marketplace can act as an enabler for intelligent production as it collects and offers AI solutions related to manufacturing domain able to solve various kinds of problems in factories. Following this introductory section, the next section presents the knowlEdge AI Marketplace\u2019s main functionalities and its high-level architecture. Section 3 presents the core technical parts and interfaces of the knowlEdge Marketplace. The conclusions are drawn in Sect. 4. 2 Functionalities and Proposed System Architecture of knowlEdge Marketplace The introduced marketplace for AI models regarding smart manufacturing offers a series of functionalities common to normal marketplaces and stores for services and products. In particular, it offers: \u2022 A user-friendly web-based interface to enable trading of AI algorithms and models \u2022 Trusted trades among the stakeholders, protection of Intellectual Property Rights (IPR) and security \u2022 Profiles and role management functionalities \u2022 Search functionalities based on various features \u2022 Reviews and ratings regarding users and AI models To support the abovementioned functionalities, the knowlEdge Marketplace incorporates a series of technologies and components in its architecture as it is depicted in Fig. 1. They are distinguished in three main categories: the back-end part related to AI models description and management, the back-end part related10 https://pop-machina.eu. 30 A. Nizamis et al.Fig. 1 High-level architecture of the knowlEdge AI model Marketplace to business logic and transactions, and the front-end part related to user-centric services such as interfaces. In particular, the User-Centric Services module provides a series of function-alities related to user experience such as UIs, search functionalities, user profile management, etc. NFT-Based Monetization Framework for AI Models based on Smart Contracts provides all the functionalities related to business logic based on blockchain. It offers smart contracts (or chaincode) for fungible and non-fungible Tokens (FTs and NFTs), marketplace, and mint notary. Furthermore, secure access services are also part of this module. AI Model Repository is responsible for the modeling of AI/ML algorithms, their storage, and the provision of management services such as CRUD (Create, Read, Update, and Delete) operations. Various APIs have also been developed to enable the different module communi-cation based on HTTP protocol. All the core modules of the introduced marketplace are presented in the following section. 3 Implementation of knowlEdge Marketplace for Exchanging AI Models in Industry 5.0 In this section, the core modules of the knowlEdge Marketplace are described. We start with the way, the data is stored in the knowlEdge AI Model RepositoryDesigning a Marketplace to Exchange AI Models for Industry 5.0 31Fig. 2 The internal architecture of the knowlEdge AI Model Repository (Sect. 3.1), before we discuss the Monetization Framework (Sect. 3.2) and conclude it with the User Interfaces (Sect. 3.3). 3.1 knowlEdge AI Model Repository The knowlEdge AI Model Repository is a central cloud-hosted component, which manages a database of AI models and their corresponding meta-information. For these purposes, it consists of four main components: the knowlEdge Repository Management, the  Model Database, the  Metadata Database, and the Historical Data Store (see Fig. 2). In general, the AI Model Repository provides all the necessary functionality to Marketplace regarding the modeling of the AI and the management of data and metadata in the Marketplace that are related to AI models. So, besides the four aforementioned components, an Ontology that enables the modeling of Marketplace\u2019s metadata is a core part of the Repository as well. 3.1.1 Overview of Key Components The knowlEdge Repository Management is the central component connecting the other components and offering services over a REST API, which follows the OpenAPI [14] specification and is the single interface of the knowlEdge Repository. It offers a feature-rich possibility to query for AI models and datasets to identify similarities between different problems and solutions.32 A. Nizamis et al.The Metadata Database is a MongoDB [15], which stores the metadata of the knowlEdge Repository. This metadata follows the knowlEdge Ontology (see Sect. 3.1.2) to ensure a high level of usable information for all datasets and models present in the repository. The Model Database is used to store the actual model specification files in a Hadoop [16] Distributed File System. The model files can be presented in ONNX11 or PMML [17] format to make sure that as many different models as possible can be described for the knowlEdge Repository. The Historical Data Store is used to store the datasets a model is trained on. With these datasets also present, it is possible to benchmark new models on the same datasets and directly compare the performance of models. 3.1.2 Ontology The knowlEdge Ontology has been developed to ensure that a wide variety of metadata are available for the knowlEdge repository. The Ontology consists of 12 different types of entities (see Fig. 3). In this entity\u2013relationship diagram, the most Fig. 3 The technical structure of the knowlEdge Ontology11 https://onnx.ai. Designing a Marketplace to Exchange AI Models for Industry 5.0 33important entities and relationships of the knowlEdge Ontology are given and show the possibilities of the hierarchical structure of this Ontology. It shows the technical ways the knowlEdge Repository stores the data according to it. These entities can be split into user-related (User), model-related (Model, IO Vector, Model Specification and Model Type), data-related (Task, Analysis Type, Application, Data, Property and Property Type), and performance-related (Performance Evaluation) Entities. The main entities/classes are as follows: \u2022 User: A User is identified by its unique name and email address. Furthermore, the timestamp of the time it was created is stored. A User can be owner of several Models and creator of several Application, Data, and Property Type entities. \u2022 Model: A Model contains its name, a description, and the timestamp of its creation as well as a link to a Model Specification and the Model Type it instantiates. It can have hierarchical children and a parent as well as multiple IO Vectors as input and output. \u2022 IO Vector: An IO Vector contains its name, dimensionality, and data type, which can be of type integer, float, Boolean, or categorical. It can be input and output to several Models. \u2022 Model Specification: A Model Specification contains the actual model file, i.e., an ONNX or PMML file describing the model. \u2022 Model Type: A Model Type has its name. It can be child to another Model Type and parent to several Model Types. It can be instantiated by several Models. \u2022 Task: A Task consists of its name, the timestamp of its creation, its Analysis Type, Application, and Data. It is created by a single User, can have multiple Tasks as children, and can have several Models trained for it. It may be child of another Task. \u2022 Analysis Type: An Analysis Type has a name and the timestamp of its creation. It is part of a Task and can be child to one and parent to many Analysis Types. \u2022 Application: An Application has a name, a description, and the timestamp of its creation. It is part of a Task, created by a User, and can be child to one and parent to many Applications. \u2022 Data: A Data entity consists of its name and description, the Task it is part of, and the timespan it was gathered during. It is created by a User, consists of several Properties, and may inherit from one and be parent for several Data entities. \u2022 Property: A Property consist of its name, the Property Type it instantiates, and the Data entity it belongs to. \u2022 Property Type: A Property Type consists of its name, creation time, and type, which may be Boolean, integer, float, or categorical. It is created by a User and may be instantiated by several Properties. A Property Type can be based on one Property Type, and there can be multiple Property Types based on one Property Type. \u2022 Performance Evaluation: A Performance Evaluation represents the actual performance of an AI Model on a Task. It is linked to both these entities and contains the performance measurement as well as the information which measure this represents.34 A. Nizamis et al.The model specifications in the Model Database will be stored in the ONNX or PMML Format. These two formats offer compatibility with a wide range of different machine learning techniques and frameworks to boost interoperability regarding AI models in the proposed marketplace. While PMML focuses on traditional machine learning methods, ONNX is specialized for exchanging deep neural networks. The combination of both formats makes it possible to store a wide range of machine learning models in an easy to use and deploy way. 3.2 NFT-Based Monetization Framework for AI Models Besides the Ontology for describing the Marketplace metadata and the reposi-tory services for the management of AI models, a set of services regarding the monetization-, security-, and business-related concepts was required for the delivery of the proposed AI Model Marketplace. Therefore, in the context of the knowlEdgeMarketplace, a number of blockchain-based services have been developed and deployed. An end-to-end decentralized AI Model Marketplace that enables the monetization of AI models while ensuring security, auditability, and verifiability has been implemented based on blockchain technology. To guarantee ownership of AI models, each model is treated as a unique asset on the distributed ledger, represented as non-fungible tokens (NFTs). The use of NFTs provides additional functionalities, including ownership transfer. The marketplace is based on the presupposition that participants share a common value system, and fungible tokens are used as the equivalent of real-world fiat currency. In Table 1, we provide the various actor roles and the means under which they engage with the marketplace platform, i.e., their capabilities. Note that the terms \u201cAI Model Producer,\u201d \u201cAI Model Researcher,\u201d and \u201cAI Model Developer\u201d are used interchangeably to refer to the same actor. Similarly, the terms \u201cAI Model Consumer\u201d and \u201cMarketplace Customer\u201d refer to the same actor. Lastly, note that the same real-world entity can potentially enact in all of the aforementioned roles, e.g., an AI model producer can also act as a consumer, or marketplace customer for AI models produced by others. The following functionalities are available in the DLT-based AI Model Market-place, building on the core set of functionalities that were previously outlined. The functionalities are as follows: \u2022 AI model producers, represented as NFT owners, can advertise their willingness to sell access to individual AI model binary files at a price of their choice. \u2022 Each AI model producer can query the AI models they have advertised on the marketplace. \u2022 Each AI model producer can retract advertised AI models at any time. \u2022 Any entity can query all AI models advertised on the marketplace. \u2022 Interested AI model consumers can purchase access to any advertised AI model, provided they have sufficient coin balance.Designing a Marketplace to Exchange AI Models for Industry 5.0 35Table 1 Roles and capabilities of users in the system Role Capabilities Admin Entities that have access to privileged functionalities, such as: . \u2022 Anything related to Identity and access management (IAM) . \u2022 Acting as principals of notarized functionalities wherever and if deemed necessary. For instance, approving the minting of fungible tokens (coins) AI Model Producer Entities that produce or develop new AI models. Their engagement with the platform is as follows: . \u2022 Querying the platform for a complete list of all the AI models that they own . \u2022 Uploading AI models to the repository . \u2022 Minting AI models (NFTs) on the DLT (Distributed Ledger Technology) and storing the corresponding metadata file on the off-chain metadata store . \u2022 Publishing their willingness to sell access to AI models (NFTs) that they own on the marketplace . \u2022 Retracting from the marketplace selling access to AI models (NFTs) . \u2022 Creating (bank) accounts, transferring coins to accounts of other users, and so on AI Model Consumer These are the main clients of the marketplace, i.e., the ones that purchase access to AI models. Their engagement with the platform is as follows: . \u2022 Retrieve a list of all (or even individual) AI models for which they can buy access to. . \u2022 Query the NFT metadata store to obtain additional information of an AI model, such as the URL of the corresponding repository on which it is stored. . \u2022 Create (bank) accounts, transferring coins to accounts of other users, and so on. . \u2022 Purchase access to AI models that are advertised by specifying the fungible token account that will be used for the payment. Obviously, the specified account must have a sufficient coin balance. . \u2022 Once a purchase has been completed, these entities retain indefinitely their right to access the AI model, regardless of whether the corresponding producer has retracted it. . \u2022 Query the platform for a complete list of all the purchases that they have performed in the marketplace. \u2022 AI model consumers retain access rights to purchased AI model binary files, even if the models are later retracted from the marketplace. \u2022 Each consumer can query the marketplace for a list of all successful purchases. \u2022 External entities, such as an AI Model repository, can securely verify that an actor requesting access to an AI model binary file is a legitimate consumer who has previously performed a successful purchase.36 A. Nizamis et al.Fig. 4 High-level overview of the AI model monetization framework\u2019s architecture A detailed diagram of the architecture can be found in Fig. 4. The diagram depicts the involved users, the components of the blockchain infrastructure, and intuitive descriptions of their interactions. There are also several off-chain components that play different roles. For example, we need to account for the physical storage of AI model files and provide an identity and access management infrastructure for the actors and the services they consume. Additionally, we need to include various integration and deployment-related components such as API gateways and dashboards (user interfaces) for the involved actors. The list of components along with a succinct description of their function can be found below: \u2022 Hyperledger Fabric (henceforth, HLF) Community Management (CM) API: A federated identity authorization service that, apart from supporting all standard OAuth 2.0 and OpenID Connect flows, encompasses, as part of the user registration (onboarding) process, private key and X.509 digital certificate generation, which are subsequently stored in an HLF-compliant secure wallet store. \u2022 HLF Wallet: Implementation of HLF\u2019s Wallet interface employing MongoDB as a storage medium for Hyperledger Fabric\u2019s Go SDK. This is employed internally by the HLF SC Gateway component (see below). \u2022 HLF Smart Contract (SC) Gateway: a configurable microservice that exposes functions of any smart contract deployed on any arbitrary Hyperledger Fabric channel as HTTP endpointsDesigning a Marketplace to Exchange AI Models for Industry 5.0 37\u2022 NFT Metadata Store: a REST API that exposes endpoints for storing and retrieving metadata files associated with NFTs \u2022 NFT Chaincode: the smart contract that implements the entire non-fungible token-related functionality \u2022 FT Chaincode: the smart contract that implements the entire fungible token-related functionality 3.3 User Interfaces and Functionalities Besides the core back-end services and the corresponding modules that were presented in the previous section, a module focused on the delivery of front-end-related services is also included in knowlEdge Marketplace. This module does not only include interfaces but also supports some user-related functionalities such as search capabilities and user\u2019s profile management. They are considered in the same building block as they are strictly connected to a front-end theme that was used and their functionality is derived from them. Regarding the interfaces design, best practices were used. The design pillars that were followed were the esthetic and minimalistic design, the use of common and consistent UI elements, the adoption of widely used input controls and navigational elements, the error prevention and good error messaging, etc. The UIs were imple-mented as web-based interfaces using technologies such as Angular, Bootstrap, and Nebular. The ngx-admin template was used to enable faster implementation as it is a popular admin dashboard based on Angular and it is free and open source. It is efficient as it is packed with a huge number of UI components and it is highly customizable. The UIs enable the exploration of various available AI models in different views (see Fig. 5) based on the user\u2019s preferences (grid view and list view). The search functionalities provide various filters such as AI models owner, category of the algorithm, price range, rating, etc. Text-based search is also supported, so the user can type text related to the model\u2019s name, keywords, and other metadata. By selecting a model, the user is able to read details (see Fig. 6) such as description, specifications of the model, and metadata such as rating, price, and owner. Furthermore, any datasets connected to a model are also visible. All the data available to UI are dynamically retrieved from Repository and Monetization modules. The user can also select to add to cart a model in order to purchase it based on the NFT monetization module. Besides exploring and purchasing AI models, a user can act as a provider and deploy his/her own AI model by using corresponding interfaces (Fig. 7) that are available in a kind of a step wizard form. First, the user adds the dataset details that were used for training a model. Then the general details regarding the task/application that the model is related to (e.g., predictive maintenance) are added. After that, the user adds AI model details such as the type, input and output, model38 A. Nizamis et al.Fig. 5 List of AI models Fig. 6 AI model details format, and connections with other models and deploys the model itself (e.g., an ONNX file, etc.). 4 Conclusions The design and the implementation of a marketplace for exchanging AI models related to Industry 5.0 and smart manufacturing are introduced. The knowlEdge Marketplace highlights the main components that a marketplace for AI models should include. A component to enable the modeling of AI models/algorithmsDesigning a Marketplace to Exchange AI Models for Industry 5.0 39Fig. 7 Uploading an AI model and their metadata based on standards has been defined as a necessity. Moreover, AI developers should be able to provide their models based on widely used formats and standards in such marketplaces. Furthermore, services to enable trusted transactions and sharing, along with security and protection of ownership in AI marketplaces, have been found as core concepts that should be covered as well. The use of blockchain technology for this kind of services has been proved as an ideal candidate as it provides all the necessary concepts regarding monetization and secure and trusted transactions. Moreover, user-friendly and easy-to-use interfaces were another important factor that should be considered as in the end, as any other marketplace, it is focused to end-users. Regarding the next steps, the knowlEdge Marketplace focuses on further testing and evaluation by domain experts targeting to final improvements so to be con-sidered as a completely market-ready solution. The plan is for this marketplace to be one of the core AI marketplaces in Europe related to AI models exchanged in Industry 5.0 era. Acknowledgments This work has received funding from the European Union\u2019s Horizon 2020 research and innovation program under Grant Agreement No. 957331\u2014KNOWLEDGE. References 1. Kumar, A., Finley, B., Braud, T., Tarkoma, S., Hui, P.: Sketching an ai marketplace: Tech, economic, and regulatory aspects. IEEE Access 9, 13761\u201313774 (2021) 2. Cort\u00e9s, U., Cort\u00e9s, A., Barru\u00e9, C.: Trustworthy AI. The AI4EU approach. In: Proceedings of Science (2019)40 A. Nizamis et al.3. Mourtzis, D., Angelopoulos, J., Panopoulos, N.: A survey of digital B2B platforms and marketplaces for purchasing industrial product service systems: a conceptual framework. Procedia CIRP 97, 331\u2013336 (2021) 4. Deshmukh, R.A., Jayakody, D., Schneider, A., Damjanovic-Behrendt, V.: Data spine: a federated interoperability enabler for heterogeneous IoT platform ecosystems. Sensors 21(12), 4010 (2021) 5. Anaya, V., Moalla, N., Stellingwerff, L., Flores, J.L., Fraile, F.: vf-OS IO Toolkit. Enterprise Interoperability: Smart Services and Business Impact of Enterprise Interoperability, pp. 91\u201397 (2018) 6. G\u00f6n\u00fcl, S., \u00c7avdarog\u0306lu, D., Kabak, Y., Glachs, D., Gigante, F., Deng, Q.: A B2B marketplace eCommerce platform approach integrating purchasing and transport processes. In: Interna-tional Conference on Interoperability for Enterprise Systems and Applications, pp. 105\u2013121. Springer, Cham (2023) 7. Bonino, D., Vergori, P.: Agent marketplaces and deep learning in enterprises: the composition project. In: 2017 IEEE 41st Annual Computer Software and Applications Conference (COMP-SAC), vol. 1, pp. 749\u2013754. IEEE, New York (2017) 8. Nizamis, A.G., Ioannidis, D.K., Kaklanis, N.T., Tzovaras, D.K.: A semantic framework for agent-based collaborative manufacturing eco-systems. IFAC-PapersOnLine 51(11), 382\u2013387 (2018) 9. Nizamis, A., Vergori, P., Ioannidis, D., Tzovaras, D.: Semantic framework and deep learning toolkit collaboration for the enhancement of the decision making in agent-based marketplaces. In: 2018 5th International Conference on Mathematics and Computers in Sciences and Industry (MCSI), pp. 135\u2013140. IEEE, New York (2018) 10. Mertens, C., Alonso, J., L\u00e1zaro, O., Palansuriya, C., B\u00f6ge, G., . . . ,  Poulakidas,  A.:  A  framework for big data sovereignty: the European industrial data space (EIDS). In: Data Spaces: Design, Deployment and Future Directions. pp. 201\u2013226. Springer International Publishing, Cham (2022) 11. Sarpatwar, K., Sitaramagiridharganesh Ganapavarapu, V., Shanmugam, K., Rahman, A., Vaculin, R.: Blockchain enabled AI marketplace: the price you pay for trust. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (2019) 12. Alvarez-Napagao, S., Ashmore, B., Barroso, M., Barru\u00e9, C., Beecks, C., Berns, F., Bosi, I., Chala, S.A., Ciulli, N., Garcia-Gasulla, M., Grass, A., Ioannidis, D., Jakubiak, N., K\u00f6pke, K., L\u00e4ms\u00e4, V., Megias, P., Nizamis, A., Pastrone, C., Rossini, R., S\u00e0nchez-Marr\u00e8, M., Ziliotti, L.: knowlEdge Project\u2013Concept, methodology and innovations for artificial intelligence in industry 4.0. In: 2021 IEEE 19th International Conference on Industrial Informatics (INDIN), pp. 1\u20137. IEEE, New York (2021) 13. Wajid, U., Nizamis, A., Anaya, V.: Towards Industry 5.0\u2013A Trustworthy AI Framework for Digital Manufacturing with Humans in Control. Proceedings https://ceur-ws. org ISSN, 1613, 0073 (2022) 14. Tzavaras, A., Mainas, N., Petrakis, E.G.M.: OpenAPI framework for the Web of Things. Internet of Things 21, 100675 (2023) 15. Banker, K., Garrett, D., Bakkum, P., Verch, S.: MongoDB in action: covers MongoDB version 3.0. Simon and Schuster, New York (2016) 16. White, T.: Hadoop: the definitive guide. O\u2019Reilly Media Inc., California (2012) 17. Guazzelli, A., Zeller M., Lin, W., Williams, G., et al.: PMML: an open standard for sharing models. R J. 1(1), 60 (2009)Designing a Marketplace to Exchange AI Models for Industry 5.0 41Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Human-AI Interaction for Semantic Knowledge Enrichment of AI Model Output Sisay Adugna Chala and Alexander Gra\u00df 1 Introduction Modern day agile manufacturing [6] requires developing a framework of AI solutions that capture and process data from various sources including from human-AI collaboration [1]. Enhancing a manufacturing process by (semi-)automatized AI solutions that can support different stages in a production process that involves inter-company data infrastructure is one of the challenges in data-intensive AI for manufacturing. This challenge is exacerbated by the lack of contextual information and nontransparent AI models. In this chapter, we describe the concept of domain knowledge fusion in human-AI collaboration for manufacturing. Human interaction with AI is enabled in such a way that the domain expert not only inspects the output of the AI model but also injects engineered knowledge in order to retrain for iterative improvement of the AI model. It discusses domain knowledge fusion, the process to augment learned knowledge of AI models with knowledge frommultiple domains or sources to produce a more complete solution. More specifically, a domain expert can interact with AI systems to observe and decide the accuracy of learned knowledge and correct it if needed. The purpose of a domain ontology is to serve as a repository for domain-specific knowledge. Ontology enrichment system, as a part of human-AI collaboration, enables domain experts to contribute their expertise with the goal of enhancing the knowledge learned by the AI models from the patterns in the data. This enables the integration of domain-specific knowledge to enrich the data for further improvement of the models through retraining. S. A. Chala (\u0002) \u00b7 A. Gra\u00df Department of Data Science and AI, Fraunhofer Institute for Applied Information Technology (FIT), Sankt Augustin, Germany e-mail: sisay.adugna.chala@fit.fraunhofer.de; alexander.grass@fit.fraunhofer.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_34344 S. A. Chala and A. Gra\u00dfDomain knowledge fusion is a technique that involves combining knowledge from multiple domains or sources to produce a more complete solution by augment-ing learned knowledge of AI models. It is used to improve the accuracy of predictive models, e.g., to guide feature selection in a machine learning model, resulting in better predictive performance [16]. Domain knowledge fusion also helps improve effectiveness of predictive models by supporting efficient dimension reduction techniques that are able to capture semantic relationships between concepts [17]. After reviewing prior research, we describe our concept domain knowledge fusion in agile manufacturing use case scenarios for human-AI interaction. We iden-tify two kinds of knowledge: (i) learned knowledge, i.e., the knowledge generated by the AI model and (ii) engineered knowledge, i.e., the knowledge provided by the domain expert. We identify three aspects of domain expert interaction with our AI systems to observe and (a) reject if the learned knowledge is incorrect, (b) accept if the learned knowledge is correct, (c) adapt if the learned knowledge is correct but needs modification. We demonstrate these concepts for researchers and practitioners to apply human-AI interaction in agile manufacturing. The rest of this chapter is organized as follows: in the Related Works section, we examine related works in order to identify research gaps of human-AI interaction in agile manufacturing. In the Human Feedback into AI Model section, we discuss the methodology (sub-components and interfaces) developed in the human-AI collaboration to enhance agile manufacturing. The Interaction for Model Selection and Parameter Optimization section covers the implementation of the proposed system and presents the preliminary results. Finally, in the Conclusion and Future Works section, we summarize the results and outline the future research works of the chapter. 2 Related Works Fact-checking, a task to evaluating the accuracy of AI models, is a crucial, pressing, and difficult task. Despite the emergence of numerous automated fact-checking solutions, the human aspect of this collaboration has received minimal attention [13], though some advancement is being observed in conversational AI [8]. Specifically, it remains unclear how end users can comprehend, engage with, and build confidence in AI-powered agile manufacturing systems. In other words, enabling interaction of domain experts to AI model outputs, in order that they inspect the output and provide their feedback, helps fix errors that could lead to undesirable outcomes in production process. Existing studies on human-AI collaboration predominantly focus on user inter-face (UI) and user experience (UX) aspects, i.e., whether (and how) the AI systems provide an intuitive user interface. A number of them assessed human-AI collaboration with respect to human-AI interaction guidelines as opposed to features that enable human actor to provide feedback to the AI model [4, 9]. Regarding itsHuman-AI Interaction for Semantic Knowledge Enrichment of AI Model Output 45effect on decision-making of users has been studied using different eXplainable AI (XAI) interface designs [12]. Apart from data fact-checking and UI/UX, human-AI interaction can be done for data labeling. For example, data such as time series measurements are not intuitive for users to understand, and AI is used to generate descriptive labels [10] for  a  given data. Expert knowledge can augment the result of AI models by inspecting the output and complementing it. Ontology enrichment is being studied in areas of knowledge management [7], natural language processing [14], medical [3], and energy [5]. Although manufacturing with human in the loop is recently getting traction, studies on ontology enrichment have minimal attention for manufacturing. There are several existing human-AI collaboration solutions that aim to leverage the strengths of both humans and AI systems through human-AI collaboration. Advanced applications like virtual assistants like Google Assistant [11] and Apple Siri [2] are common examples of human-AI collaboration systems. These AI-powered voice-activated assistants interact with humans to perform tasks, answer questions, and control connected devices. Most of these advancements concentrate in natural language processing, healthcare, and energy. However, the role of AI in manufacturing is mainly focused on automation and control. This chapter focuses on data analytics and insights generation through AI models that had minimal attention despite the fact that manufacturing domain generates massive amount of sensor data. Processing and analyzing the large volumes of data can help identify patterns, trends, and anomalies, providing valuable insights to support decision-making. The chapter develops a tool that enables humans to collaborate with AI systems through intuitive interfaces that help domain experts in interpreting insights, validating the findings, and applying domain knowledge to gain a deeper understanding of the data. 3 Human Feedback into AI Model The purpose of human feedback into AI model is enabling domain experts to inject their knowledge via predefined interfaces allowing for collaboration with the system in order to connotate previous knowledge with semantics, as for instance with a description of a specific process or data. It helps better understanding of the data, as it also provides the possibility for a better evaluation of the whole AI pipeline. In other words, human-AI collaboration is a component that offers interfaces between domain expert and AI system. The functionalities offered by the human-AI collaboration are to enable human feedback for domain experts, i.e., machine operators and managers without the need to understand the intricacies of AI models. As shown in Fig. 1, the human-AI collaboration is composed of multiple sub-components and interfaces that enable communication with external systems such as data sources, model repositories, machine configurations, and decision support systems. The main sub-components described below are interface abstraction,46 S. A. Chala and A. Gra\u00dfFig. 1 Human-AI collaboration components and interfaces model and data selection, parameter optimization, configuration adaptation, domain knowledge enrichment, and domain knowledge repository. 3.1 Interface Abstraction Interface abstraction component is a container for configuration adaptation, mod-el/data selection, parameter optimization and adaptation, and domain ontology enrichment components. It provides an interface to the domain expert through the decision support system through intuitive and user-friendly interfaces that enable effective communication and cooperation between humans and AI. Interface abstraction is beneficial for human-AI collaboration by playing a crucial role in enabling seamless cooperation and enhancing the productivity and usability of AI technologies. The goal of interface abstraction is to bridge the gap between the capabilities of AI systems and the understanding and expertise of human users. It allows users to interact with complex AI technologies without requiring them to have in-depth knowledge of the underlying algorithms of AI models. In effect, it empowers users to leverage the capabilities of AI systems while focusing on their own areas of expertise. By abstracting the complexities of AI algorithms and technologies, interface abstraction facilitates effective communication and collaboration between humans and AI.Human-AI Interaction for Semantic Knowledge Enrichment of AI Model Output 473.2 Model and Data Selection The human-AI collaboration system offers features for data and model selection. Operators select models and data from the available list of options in order to execute them for a specific scenario. Model and data selection are critical factors in human-AI collaboration. Because the choice of model and data significantly influences the performance, accuracy, and overall effectiveness of the AI system. When considering human-AI collaboration, several key considerations come into play. One aspect is determining the specific requirements of the task at hand, understanding the problem domain, the type of input data, and the desired output. This knowledge helps guide the selection of an appropriate model for the dataset. Another aspect is understanding capabilities of the AI model because different AI models and algorithms are suitable for the task. Considering factors such as the model\u2019s architecture, complexity, interpretability, and scalability affect the choice of a model that aligns with the task requirements. 3.3 Parameter Optimization Parameter optimization is an important step in human-AI collaboration to ensure optimal performance and effective interaction between humans and AI systems. Operators and managers perform the optimization of parameters that offer the best outcome for the given scenario. The system provides them with an interface where the operators can select the parameters, try various values, and observe the results. It involves continuous evaluation of the performance of the system and collecting feedback from the human collaborator. This feedback can be used to identify areas for improvement and guide the parameter optimization process to iteratively refine and fine-tune the parameters based on the evaluation results and feedback. The parameter optimization is necessary for the domain expert to deal with trade-offs between different performance metrics or constraints that need to be satisfied. For example, optimizing for accuracy may lead to longer response times, which may impact the user experience. The first step in parameter optimization is to identify the metrics or criteria that will be used to measure success. This will help guide the parameter optimization process. Once the parameters are identified, the next step is to determine the metrics that evaluate the performance of AI model, such as efficiency and accuracy. In this chapter, an example implementation of parameter optimization is shown in Fig. 4. 3.4 Configuration Adaptation Configuration adaptation is the process of adjusting or fine-tuning the configuration settings of AI systems to better align with the needs, preferences, and context of human users. It involves customizing the equipment, parameters, or policies of AI48 S. A. Chala and A. Gra\u00dfmodels to optimize their performance. Feedback of domain expert plays a vital role in configuration adaptation as it provides valuable insights into the effectiveness and suitability of the AI model\u2019s behavior in that the AI system can learn and adjust its configuration settings to improve its performance and align more closely with the user\u2019s requirements in response to incorporating domain expert feedback. Moreover, when a model offers a need for specific configurations of machines that need to be modified, operators/managers can adapt the configurations of machines so that it suits to the model under consideration, for example, if new machines need to be added to the human-AI collaboration system, their configuration should be extracted and stored in such a way that they are accessible and usable to the modules. 3.5 Domain Knowledge Enrichment Enriching learned knowledge with engineered knowledge describes the scenario where the AI model analyzes the given data for a task (e.g., outlier detection) and produces its result (e.g., that a given data point is an outlier), the domain expert realizes that the output of the model is not right (e.g., that the data point is not an outlier), and the information provided by the domain expert (i.e., the data point is not an outlier) is stored in the repository of ground truth and sent back to the AI model for retraining. It is used by operators and managers to enrich the knowledge repository with new entries obtained from the execution of the system using diverse setting of models, parameters, and configurations. The key challenge of this approach is that it relies on the availability of domain experts. Scarcity of domain experts (that most of them spend their time on machine monitoring, operation, and management), limited availability of domain expertise, rapidly evolving AI landscape, and its demand for interdisciplinary skills make this challenge difficult to handle. Developing AI models often requires deep domain expertise in specific fields, e.g., manufacturing in this case, and experts who possess both domain expertise and a solid understanding of AI techniques are difficult to find. Moreover, effective collaboration between domain experts and AI practitioners often necessitates interdisciplinary skills. Domain experts need to understand AI concepts and methodologies, while AI practitioners need to comprehend the nuances and complexities of the specific domain. The scarcity of individuals with expertise in both areas makes the task of domain knowledge enrichment challenging. In this chapter, the limitation of AI model development knowledge of domain expert is taken into account. Having listed these challenges, this research assumes that the involvement of humans in enriching knowledge will potentially reduce over time. As such, an initial set of AI models are trained and made available for the domain expert to experiment with them before trying to perform parameter optimization and feedback provision. At the beginning of a collaboration between humans and AI, there will be a significant effort to optimize parameters and transfer human knowledge and expertise to the AI models by providing more data, defining rules, and setting up the initial knowledge base. However, through retraining, the AIHuman-AI Interaction for Semantic Knowledge Enrichment of AI Model Output 49model learns and accumulates more data that it can gradually require less feedback from the domain expert. Organizations can benefit from this system despite these challenges by defining feasible objectives of the human-AI collaboration in the manufacturing setting whereby they identify the specific areas where AI can enhance manufacturing pro-cesses, such as quality control, predictive maintenance, or supply chain optimization and establish key performance indicators (KPIs) to measure success. For example, companies can utilize this approach to perform what-if analysis in order to explore the potential implications of different scenarios and make more informed decisions by combining the analytical capabilities of AI models with human judgment, expertise, and contextual understanding. Domain experts can modify the input parameters, adjust variables, or introduce new constraints to observe the potential changes in the outcomes. The AI system then performs the simulations and presents the results to the human collaborator. 3.6 Domain Knowledge Repository Domain Knowledge is the repository of knowledge (both learned knowledge generated by the AI model and engineered knowledge curated by the domain expert. Machines and production processes are undergoing a rapid digital transformation, opening up a wide range of possibilities. This digitalization enables various opportunities, including early detection of faults and pricing models based on actual usage. By leveraging sensor data analytics, it becomes possible to monitor machine operations in real time, providing valuable insights and applications. This is better achieved if the domain experts assist in improving the quality of AI model output by providing domain knowledge, for which this component is responsible to store. 4 Interaction for Model Selection and Parameter Optimization Improving the effectiveness of AI model requires a comprehensive understanding of the model\u2019s design and implementation and it can be achieved in a number of ways: (i) reviewing the input data, including the quality, completeness, and relevance, to determine if it can be modified to improve the output, (ii) analyzing the output data of the interaction model can help identify patterns and trends that can be used to modify the model\u2019s output and identify areas for improvement or optimization, and (iii) modifying the algorithms used in the interaction model can help improve the output. In this chapter, the second method is used, i.e., the domain expert provides feedback on the output of the AI model.50 S. A. Chala and A. Gra\u00dfAn example scenario that shows the procedure for the human-AI interaction is shown below: \u2022 Fetch predicted labels form the output of automatic label detection of models. \u2022 Present the data with predicted label to the domain expert. \u2022 Present the domain expert with choices to (i) accept the predicted label and (a) confirm the predicted label or (b) offer an alternative label or (ii) reject the predicted label and offer the correct label. \u2013 If the domain expert accepts and confirms the label, the process ends. \u2013 If the domain expert accepts the predicted label and offers an alternative label or a refinement of the label or rejects the predicted label altogether and offers the correct label, the domain expert\u2019s input will be sent as input to retrain the model. \u2022 Visualization of behavior of the model with/without the domain expert\u2019s input will be shown for comparison of the effect of the domain fusion. \u2022 Human-AI collaboration system will expose an API of the visualization to the DSS component through which the user will inspect the outputs of the model. Figure 3 shows the process of data/model selection and parameter optimization including data flow and UI mockup for model selection and parameter optimization user interface through which the domain expert selects the model and parameter and optimizes the parameter values. The UI presents visualization of processing results for the selected model, parameter, and values. Once the domain expert determines the model, parameter, and values, the UI then enables the domain expert to export the result which will then be consumed by the Decision Support System (DSS). The domain expert selects a section of the visualization and provides engineered knowledge, i.e., manual labeling of data points. This helps the user to visually inspect the dataset and enrich it with domain knowledge to boost the quality of the data to be used as training dataset for better performance of the ML model. For example, for an AI model built for anomaly detection, this is achieved by enabling the user to select the data point on the visualization plot in order to display and review (and when applicable, modify) the data that are marked by the system as anomalies. This is implemented by providing point, box, or lasso [15] selection where the user can select a single (or multiple data points on the graphs) and get the corresponding data points back, to provide the domain knowledge. As depicted in Figs. 2 and 3, the domain expert will load data and models from the model repository, run the models on the data, observe the visualization, and adjust parameters in order to achieve the desired behavior of the AI model. Once the domain expert obtains satisfactory output from the model, she/he can then provide feedback. The algorithm shown in Fig. 4 shows the detailed operations during the domain knowledge enrichment.Human-AI Interaction for Semantic Knowledge Enrichment of AI Model Output 51Fig. 2 Human-AI collaboration flow diagram 5 Conclusion and Future Works This chapter discusses the concept of a framework of human-AI collaboration in manufacturing for injecting domain knowledge provided by human experts into AI models, as provided by machine learning processes in order to iteratively improve AI models. It explores the importance of human feedback in enhancing the effectiveness of AI models and improving usefulness of their outputs through incorporating human feedback. It describes a use case scenario to showcase the implementation of human-AI interaction where human feedback is utilized to enrich learned knowledge. There are a number of future works in this chapter. An implementation of a full-fledged human-AI software prototype should be implemented and deployed so as to measure its effectiveness and also to experiment on the varied use cases to measure its actual usability in the real world. For this, the questions such as how the introduction of human-AI interaction affects the performance and effectiveness of the AI model, and for the given test, how much of the output of the AI model is rejected, accepted, and modified need to be answered. Another aspect of the future research is to analyze whether AI model produces erroneous results even after retraining using expert feedback, i.e., whether the accuracy of the retrained AI model shows any improvement. Yet another aspect is a study on scaling human-AI collaboration that takes into account the scarcity of domain experts who have understanding of intricacies of AI modeling or AI developers who have sufficient knowledge of the domain of52 S. A. Chala and A. Gra\u00dfFig. 3 Human-AI collaboration main interface Fig. 4 Pseudocode showing high-level process of human-AI collaboration manufacturing. Long-term studies of how to scale human-AI collaboration are of paramount importance because scaling up the human-AI collaboration approach to large-scale manufacturing settings presents challenges in maintaining consistent collaboration and effectively incorporating human feedback across various use cases, domains, and data volumes. Therefore, it is important to further research scaling up human-AI collaboration in large-scale manufacturing settings throughHuman-AI Interaction for Semantic Knowledge Enrichment of AI Model Output 53a well-planned approach that involves aligning technology, data, technical/domain expertise, and processes to create a seamless integration of human and AI capa-bilities, ultimately enhancing productivity, quality, and efficiency in manufacturing operations. Acknowledgments The research leading to these results has received funding from the Horizon 2020 Program of the European Commission under Grant Agreement No. 957331. References 1. Arinez, J.F., Chang, Q., Gao, R.X., Xu, C., Zhang, J.: Artificial intelligence in advanced manufacturing: current status and future outlook. J. Manuf. Sci. Eng. 142(11), 110804 (2020) 2. Aron, J.: How Innovative is Apple\u2019s New Voice Assistant, Siri? (2011) 3. Baghernezhad-Tabasi, S., Druette, L., Jouanot, F., Meurger, C., Rousset, M.-C.: IOPE: interactive ontology population and enrichment. In: Workshop on Ontology-Driven Conceptual Modelling of Digital Twins co-located with Semantics 2021 (2021) 4. Fan, M., Yang, X., Yu, T., Liao, Q.V., Zhao, J.: Human-ai collaboration for UX evaluation: effects of explanation and synchronization. Proc. ACM Hum.-Comput. Interact. 6(CSCW1), 1\u201332 (2022) 5. Fern\u00e1ndez-Izquierdo, A., Cimmino, A., Patsonakis, C., Tsolakis, A.C., Garc\u00eda-Castro, R., Ioannidis, D., Tzovaras, D.: OpenADR ontology: semantic enrichment of demand response strategies in smart grids. In: International Conference on Smart Energy Systems and Technolo-gies (SEST), pp. 1\u20136. IEEE, New York (2020) 6. Gunasekaran, A., Yusuf, Y.Y., Adeleye, E.O., Papadopoulos, T., Kovvuri, D., Geyi, D.G.: Agile manufacturing: an evolutionary review of practices. Int. J. Prod. Res. 57(15\u201316), 5154\u20135174 (2019) 7. Idoudi, R., Ettabaa, K.S., Solaiman, B., Hamrouni, K.: Ontology knowledge mining for ontology conceptual enrichment. Knowl. Manag. Res. Pract. 17(2), 151\u2013160 (2019) 8. Khadpe, P., Krishna, R., Fei-Fei, L., Hancock, J.T., Bernstein, M.S.: Conceptual metaphors impact perceptions of human-ai collaboration. Proc. ACMHum.-Comput. Interact. 4(CSCW2), 1\u201326 (2020) 9. Li, T., Vorvoreanu, M., DeBellis, D., Amershi, S.: Assessing human-AI interaction early through factorial surveys: a study on the guidelines for human-AI interaction. ACM Trans. Comput.-Hum. Interact. 30(5), 45 (2023). https://doi.org/10.1145/3511605 10. LLC, C.T.: Time Series Data Labeling: A Complete Know-how for Efficient AI Implemen-tation (2022). https://www.cogitotech.com/blog/time-series-data-labeling-a-complete-know-how-for-efficient-ai-implementation/. Last accessed: November 16, 2023 11. L\u00f3pez, G., Quesada, L., Guerrero, L.A.: Alexa vs. Siri vs. Cortana vs. Google assistant: a comparison of speech-based natural user interfaces. In: Advances in Human Factors and Systems Interaction: Proceedings of the AHFE 2017 International Conference on Human Factors and Systems Interaction, July 17\u201321, 2017, The Westin Bonaventure Hotel, Los Angeles, California, USA 8, pp. 241\u2013250. Springer, Berlin (2018) 12. Mucha, H., Robert, S., Breitschwerdt, R., Fellmann, M.: Interfaces for explanations in human-ai interaction: proposing a design evaluation approach. In: Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, CHI EA \u201921, New York, NY, USA. Association for Computing Machinery, New York (2021) 13. Nguyen, A.T., Kharosekar, A., Krishnan, S., Krishnan, S., Tate, E., Wallace, B.C., Lease, M.: Believe it or not: designing a human-ai partnership for mixed-initiative fact-checking. In: Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology, UIST \u201918, pp. 189\u2013199. Association for Computing Machinery, New York (2018)54 S. A. Chala and A. Gra\u00df14. Stratogiannis, G., Kouris, P., Alexandridis, G., Siolas, G., Stamou, G., Stafylopatis, A.: Semantic enrichment of documents: a classification perspective for ontology-based imbalanced semantic descriptions. Knowl. Inf. Syst. 63(11), 3001\u20133039 (2021) 15. Tsang, M., Enouen, J., Liu, Y.: Interpretable artificial intelligence through the lens of feature interaction. arXiv preprint arXiv:2103.03103 (2021) 16. Urbanowicz, R.J., Moore, J.H.: Exstracs 2.0: description and evaluation of a scalable learning classifier system. Evol. Intell. 8, 89\u2013116 (2015) 17. Wang, W., Barnaghi, P.M., Bargiela, A.: Probabilistic topic models for learning terminological ontologies. IEEE Trans. Knowl. Data Eng. 22(7), 1028\u20131040 (2009) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Examining the Adoption of Knowledge Graphs in the Manufacturing Industry: A Comprehensive Review Jorge Martinez-Gil, Thomas Hoch, Mario Pichler, Bernhard Heinzl, Bernhard Moser, Kabul Kurniawan, Elmar Kiesling, and Franz Krause 1 Introduction Advancements in Artificial Intelligence (AI) have enabled automation, prediction, and problem-solving, leading to increased productivity, adaptability, and efficiency in both the service and industrial sectors. In the latter, the fourth industrial revolution, commonly referred to as Industry 4.0 [19], represents a significant shift in industrial production. Driven by the integration of digital technology, industrial advancements increasingly hinge on data, which has opened up new possibilities beyond traditional applications. A key goal toward Industry 5.0 is to combine human adaptability with machine scalability. Knowledge Graphs (KGs) provide a foundation for developing frame-works that enable such integration because they facilitate to dynamically integrate human decision-making with AI-generated recommendations and decisions [34]. KGs represent knowledge in a graph-based structure which connect entities and J. Martinez-Gil (\u0002) \u00b7 T. Hoch \u00b7 M. Pichler \u00b7 B. Heinzl \u00b7 B. Moser Software Competence Center Hagenberg GmbH, Hagenberg, Austria e-mail: Jorge.Martinez-Gil@scch.at; thomas.hoch@scch.at; mario.pichler@scch.at; bernhard.heinzl@scch.at; bernhard.moser@scch.at K. Kurniawan WU, Institute for Data, Process and Knowledge Management, Vienna, Austria Austrian Center for Digital Production (CDP), Vienna, Austria e-mail: kabul.kurniawan@wu.ac.at E. Kiesling WU, Institute for Data, Process and Knowledge Management, Vienna, Austria e-mail: elmar.kiesling@ai.wu.ac.at F. Krause University of Mannheim, Data and Web Science Group, Mannheim, Germany e-mail: franz.krause@uni-mannheim.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_45556 J. Martinez-Gil et al.their relationships. In the context of hybrid human-AI intelligence, KGs can represent shared conceptualizations between humans and AI components, providing a foundation that facilitates their collaboration in dynamically integrating human decision-making. Furthermore, KGs provide a critical abstraction for organizing semi-structured domain information. By utilizing KGs, decision-making can be improved, knowl-edge management can be enhanced, personalized interactions can be enabled, predictive maintenance can be supported, and supply chain operations can be optimized. Therefore, KGs serve as a foundation for creating a shared knowledge space for AI components and humans, an environment for the representation of policies that govern the interactions between agents, and a view of real-world physical processes on the shop floor by extracting and integrating relevant events. Thus, KGs hold enormous potential for facilitating collaboration in this field, making production lines more efficient and flexible while producing higher quality products. As such, companies seeking to achieve the goals of Industry 5.0 find that KGs can realize their vision [20]. However, research in this area is still in its early stages, and further studies are required to analyze how KGs might be implemented. This overview aims to provide a review of the current state of research in this field, as well as the challenges that remain open. The rest of this work is structured in the following way: Sect. 2 reviews the current usage scenarios of KGs in industrial settings, Sect. 3 outlines the research questions and search strategy, Sect. 4 presents the major findings that can be extracted when analyzing the previously mentioned research questions, and Sect. 5 discusses the lessons learned and future research directions. 2 Antecedents and Motivation The industrial landscape has been revolutionized by the emergence of collaborative paradigms between human\u2013machine systems, such as the Internet of Things (IoT), Internet of Services (IoS), and Cyber-Physical Systems (CPS), resulting in the so-called Industry 5.0. This has led to a shift in focus toward enhancing collaboration between humans and machines [13]. The creation and connection of newly available devices generate enormous data with significant potential value, which can be used to extend the product\u2019s life cycle, on-demand manufacturing, resource optimization, machine maintenance, and other logistical arrangements [8]. KGs have recently gained much attention due to their potential to boost productivity across various sectors. KG can primarily empower industrial goods and services and their development process in two areas. First, they may save time and labor costs while enhancing accuracy and efficiency in domain information retrieval for requirements gathering, design and implementation, and service and maintenance management, by offering a semantic-based and in-depth knowledge management approach. Second, the development of KG has made it possible to build a data architecture suitable for corporate use by combining intelligent discovery andKnowledge Graphs in the Manufacturing Industry 57knowledge storage, utilizing KG embedding techniques to gather more information from KGs. KGs are most employed to model a particular and frequently complex domain semantically, explicitly modeling domain knowledge used to support and increase the accuracy of tasks performed further down the pipeline. Furthermore, advanced methodologies founded on KGs have become essential for knowledge representation and business process modeling. In recent years, there has been a rise in interest in analyzing KGs using Machine Learning (ML) techniques, such as predicting missing edges or classifying nodes. To input feature vectors into most ML models, much research has been devoted to developing methods to build embeddings from KG. The transformation of nodes and, depending on the technique, edges into a numerical representation via KG embedding enables direct input into an ML model [2]. Furthermore, KG is widely assumed to be a tool for optimizing supply chain operations, reducing costs, and improving overall efficiency. Manufacturers can model their supply chain using KGs to fully understand how their suppliers, customers, and operations depend on one another, enabling them to make real-time data-based decisions. In summary, many KGs have been built, both open to the public and closed for internal company use. Enterprise KGs are closed applications that can only be used by authorized personnel, while Open KGs are usually academic or open-source projects available for use by anyone on the Web. By using modeling and ML organizations can gain insights and make data-based decisions thanks to the creation of these KGs. This research work describes the current state of Open KGs. 3 Research Questions and Search Strategy KGs serve as semantic representations of various aspects involved in the manu-facturing process. These aspects include all phases of system engineering, such as the phases of development (e.g., layouts), organizational development (e.g., collaboration and worker roles), and operational development (e.g., user stories). These KGs can improve the processes by considering the data coming from the industrial monitoring and the human work themselves and additional contextual data and knowledge sources. Some examples include technical documentation about the process, questionnaires about maintenance cases, constraints, and rules for representing standards and policies for safety or ethical issues, protocols about teaming workflows, logging about process states, and user feedback. This chapter investigates the present state of KGs in manufacturing. In this chapter, potential areas are identified, and chances for future works are highlighted. The following are the primary research questions that guided this study.58 J. Martinez-Gil et al.3.1 Research Questions We propose some research questions to provide specific insights into how KGs are used in manufacturing. These Research Questions (RQs) consider that the two most popular KG types are Resource Description Framework (RDFs) and Labeled Property Graph (LPG). Our RQs are designed to cover the essential aspects of bibliometric facts and application scenarios. RQ1: Which areas within manufacturing are most interested in KGs? The purpose of RQ1 is to demonstrate the significance and relevance of the topic by providing an overview of bibliometric facts from previously published studies on the applications of KGs in manufacturing. RQ2: Which manufacturing domains commonly employ KGs? RQ2 investigates KG application scenarios within manufacturing. Specifically, we will examine the manufacturing domains in which KGs have been used, the specific use cases, and the types of systems developed. RQ3: What is the popularity of RDF and LPG as KG types? RQ3 aims to evaluate the degree to which KG applications have matured by investigating some research aspects such as the format and standards used. RQ4: How are industrial KGs currently used? RQ4 discusses which building, exploitation, and maintenance procedures are commonly followed in manufacturing-related KGs. This provides insight into the structure of KGs that is vital for researchers and practitioners.Knowledge Graphs in the Manufacturing Industry 593.2 Dataset To address these RQs, we analyze a significant sample of literature published in recent years. The search scope considers gray literature such as professional forums and publications as well as academic publications published in journals or academic conferences or in books that have been peer-reviewed. In total, we have identified 40 items of publication using KG published between 2016 and 2022. The authors of these items come from a diverse range of academic disciplines and represent institutions from various parts of the world. Overall, the sample of publications provides a comprehensive and diverse set of perspectives on the research questions at hand. The following is an analysis of the main characteristics of these sources. 3.3 Subject Area KG in manufacturing is an emerging field that has drawn considerable attention from both industry and academic communities. The current body of research primarily originates from Computer Science. Conversely, there is a significant gap in research output from the fields of Engineering and Business, which are the other two most represented areas of knowledge. The scope of research in other areas, such as Chemistry, Physics, and Astronomy, as well as Materials Science, remains limited, with only a marginal number of proposals. Figure 1 presents a comprehensive categorization of the research venues considered in this chapter. The classification scheme is based on the self-description provided by each venue where the research works have been published. 3.4 Manufacturing Domain The presented findings illustrate the prevailing domains explored in the literature on applying KGs in manufacturing, as summarized in Fig. 2. To determine whether a given paper pertains to the manufacturing domain, the North American Industry Classification System (NAICS1 ) was employed. However, most of the examined literature does not specify any particular application domain. Machinery is identified as the second most frequently represented domain, after which Materials, Chemistry, and Automotive follow. Furthermore, Additive Manufacturing, Aerospace, Mining, Operations, and Textile, albeit less frequently1 https://www.census.gov/naics/. 60 J. Martinez-Gil et al.0 10 20 30 40 50 Physics and Astronomy Materials Science Engineering Computer Science Chemistry Business Percentage of papers published Fig. 1 Research communities that have published the most research on KGs in manufacturing investigated, are also observed in the literature. The identified domains highlight the diverse industries that benefit from leveraging KGs. Most reviewed works employ knowledge fusion techniques in general scenarios where KGs combine data from multiple sources. Additionally, KGs are applied to automate the merging of isolated production processes, generate digital twins based on KGs, and utilize them for automated source code development. These findings demonstrate the versatility of KGs in manufacturing and their potential to revolutionize various aspects of industrial production. 3.5 Kinds of KGs A KG may be modeled as either an RDF graph or an LPG, depending on the data requirements. As shown in Fig. 3, RDF-based solutions currently dominate the field. However, a considerable proportion of solutions are also represented by LPGs. RDF is a recommended standard from the World Wide Web Consortium2 that provides a language for defining resources on the Web. The representation of resources is accomplished using triples that consist of a subject, predicate, and object. RDF Schema, commonly referred to as RDFS, defines the vocabulary used in RDF descriptions. The RDF data model is specifically designed for knowledge representation and is used to encode a graph as a set of statements. By standardizing data publication and sharing on the Web, RDF seeks to ensure2 https://www.w3.org/. Knowledge Graphs in the Manufacturing Industry 610 10 20 30 40 50 Additive Aerospace Automotive Chemistry General Machinery Materials Mining Operations Textile Percentage of papers published Fig. 2 Manufacturing domains that have carried out the most research work around KGs 0 20 40 60 80 100 LPG RDF Percentage of papers published Fig. 3 Knowledge Graph adoption in the manufacturing industry by representation paradigm semantic interoperability. The semantic layer of the available statements, along with the reasoning applied to it, forms the foundation of intelligent systems in the RDF domain. On the other hand, LPG representation primarily emphasizes the graph\u2019s struc-ture, properties, and relationships. This highlights the unique characteristics of graph data, opening new opportunities for data analysis and visualization. It also brings a window of opportunity for developing ML systems that use graphs to infer additional information.62 J. Martinez-Gil et al.Different approaches to KG have a significant impact on the user experience. When developers and analysts work with RDF data, they use statements and SPARQL query language to make changes. On the other hand, LPG use the Cypher query language, which provides a more intuitive way to interact with nodes, edges, and related properties within the graph structure. 3.6 Different Approaches for KG Creation Compared to the broader scope of research on KGs, the development of KGs in an industrial context often employs a knowledge-driven approach. Consequently, knowledge-driven KGs are more used in the industry. This trend may stem from the practical advantages of a more closed-world approach, which is better suited to the constraints and contingencies inherent in a production environment. It also suggests that the manufacturing industry remains cautious about adopting the latest advancements in KG embeddings to enhance their analytical capabilities. Figure 4 depicts the distribution of popularity between the two distinct approaches for building KGs. Currently, the knowledge-driven approach prevails, but recent years have witnessed a significant surge in the number of data-driven solutions. These solutions are better equipped to deal with ML and other computational intelligence techniques. 0 20 40 60 80 100 Data-Driven Knowledge-Driven Percentage of papers published Fig. 4 Manufacturing industry Knowledge Graphs by form of creationKnowledge Graphs in the Manufacturing Industry 634 Insights This section summarizes the results obtained from our analysis and highlights potential areas for future research on the use KGs in the manufacturing domain. The findings are structured according to the RQs addressed earlier in the study. 4.1 Answers to the Research Questions Based on our study, we can deduce the most active research communities in the field of KGs. The answer to RQ1 (AQ1) is as follows: AQ1. The majority of primary research in the field of KGs is conducted in the discipline of Computer Science. Research in KGs is less common in other areas of knowledge. This could be because computer scientists have been developing new representa-tion models since the beginning. Today, KGs are considered the natural progression of such models to make them more adaptable to new platforms and emerging methods for managing large amounts of data. Regarding the answer to RQ2 (AQ2), it is unsurprising that the most common case is the preference for proposing generic models that can be easily adapted to various domains. AQ2. The literature primarily covers the manufacturing industry as a general concept. In most of the works examined, no specific application domain was provided. The domains related to machinery and materials are the next most represented, followed by chemistry and material. Finally, some KGs have also been developed in the aerospace, additive manufacturing, mining, operations, and textile fields. Regarding the representation of KGs, the two most commonly used data models are RDF and LPG. However, in answering RQ3 (AQ3), we seek to identify the current prevailing choice for representing KGs.64 J. Martinez-Gil et al.AQ3. In the industrial domain, RDF is the preferred format for building. KGs. This is due to RDF\u2019s ability to represent complex data and relationships in a structured and interoperable manner, which allows for the building of integrated knowledge spaces for both humans and AI components. RDF is beneficial for industrial applications as it facilitates the integration of diverse sources and a more comprehensive understanding of the data. Moreover, the ability to query across multiple sources makes it easier for people to analyze relevant information for their specific needs. Regarding the question of the predominant approach to constructing industrial KGs, it has been observed that knowledge-driven approaches are most commonly used, as stated in Answer to RQ4 (AQ4): AQ4. Knowledge-driven approaches are predominant. However, new devel-opments using data-driven approaches are expected to be increasingly incor-porated into the existing body of literature as new solutions are proposed in combination with more mature techniques. It is worth noting that existing knowledge-driven methods still encounter several general challenges, such as the interoperability and heterogeneity of data, incom-pleteness, and other specific challenges that arise from the goal of integrating them as active components rather than passive artifacts or mere data stores. 4.2 Additional Lessons Learned In light of our study, the utilization of KGs within the manufacturing industry has experienced substantial growth in recent years as manufacturers seek to enhance their operational efficiency and decision-making capabilities. The structural design of KGs facilitates a more intuitive and comprehensive representation of data than traditional database models, rendering KGs well suited for the manufacturing industry. Additional Lesson Learned #1. Although still nascent, the application of KGs within the manufacturing industry has garnered substantial interest from academia and industry.Knowledge Graphs in the Manufacturing Industry 65One of the primary reasons for this keen interest is that by modeling relationships between suppliers, manufacturers, and customers, organizations can better under-stand the flow of goods, services, and information through their supply chain. This, in turn, can assist them in identifying bottlenecks, optimizing production processes, and ensuring product delivery to customers. Additional Lesson Learned #2. The majority of the studies examined have been published in conference proceedings. In many instances, this indicates that the subject of investigation is still in the developmental stages. The state of the art is gradually maturing in almost every research area, leading to more journal publications with archival significance. KGs can aid manufacturers in enhancing their ability to predict and respond to shifts in demand. This can help reduce waste, optimize production processes, and boost efficiency. However, most of the research is a work in progress, and there is still a long way to go to consolidate the results of archival value. 4.3 Open Problems As a result of our study, we have identified several issues that limit the adoption of KGs in manufacturing and production environments. Some of the most critical issues are described below. The first issue concerns tabular data. This kind of data is frequently represented in values separated by commas. It is typically one of the most common input methods in industrial environments because it enables modeling a wide variety of data associated with temporal aspects (timestamps) and spatial aspects (coordinates). However, more optimal solutions still need to be proposed. Problem 1 (Dealing with Tabular Data) Most solutions today are created to deal with information that is predominately textual in its presentation. Although this information category is crucial in the sector, it is not domi-nant in manufacturing settings, which involve working with machinery and equipment that generate numerical data in tabular form. Another fact that is taken for granted by both researchers and practitioners is that it is possible for KGs to effectively deal with information of varying types that may arrive via a variety of channels and sources. However, our research has not found a large number of papers concerned with the temporal component of processing KGs.66 J. Martinez-Gil et al.Problem 2 (Real-time and Synchronization) Because many of the processes involved in manufacturing are automated and must have a high degree of synchronization, the manufacturing industry demands solutions that can perform adequately in environments with substantial time constraints and synchronization needs. Last but not least, according to the results of our investigation, work still needs to be done in compiling the best practices for manufacturing KGs. In this sense, we miss work in the direction of design and proposal of best practices for the sector. Problem 3 (Lack of Standardized Procedures) A substantial obstacle still exists in identifying reference architectures to build, implement, and use KGs in industrial and production settings. A compilation of best practices can be of genuine benefit in several ways, including high standards of quality results and resource saving while developing new systems or making changes to existing ones. KGs are suitable for the manufacturing industry because they can provide systems with contextual data to achieve efficient and effective solutions. This contextual data includes human experience, environmental knowledge, technical conventions, etc. Creating such solutions becomes critical when the influence on human life is essential, as in the case of a factory that employs human workers. 5 Conclusion In this chapter, we have seen how the amount of data generated in the industrial sector at a high velocity is bringing new challenges. For example, this data emanates from multiple sources, each utilizing distinct formats and standards. Consequently, integrating these divergent pieces of information is not only essential but also critical. Contextualizing data elements utilizing relevant relationships is imperative to ensure consistency and high-quality data. The study also examines KGs as multifaceted knowledge bases that capture interlinked descriptions of entities. KGs facilitate the smooth integration and structuring of information at large scale, even from heterogeneous sources. Unlike other knowledge bases, KGs are not homogeneous and do not require rigid schemas. This makes KGs highly scalable and suitable for integrating and connecting diverse data representations.Knowledge Graphs in the Manufacturing Industry 67Semiautomatic methods, employing available data sources and manual effort, are used to construct manufacturing KGs. However, manual KGs construction is only practical for small-scale KGs, and automated methods are necessary for large-scale KGs. Therefore, automating the construction and maintenance of KGs in the manufacturing domain is essential for successful implementation. In conclusion, utilizing KGs in the manufacturing industry can offer several advantages, including better decision-making processes and the ability to predict and respond to changes in demand. With the manufacturing industry evolving at an unprecedented rate, KGs will likely play an increasingly critical role in driving operational efficiency and competitiveness. Acknowledgments We would like to thank the anonymous reviewers for their constructive comments to improve this work. Our study is based on a sample of literature on KGs in manufacturing. The primary sources used in the study are not cited in the text, but are listed in the References section. SCCH co-authors have been partially funded by the Federal Ministry for Climate Action, Environment, Energy, Mobility, Innovation, and Technology (BMK), the Federal Ministry for Digital and Economic Affairs (BMDW), and the State of Upper Austria in the frame of SCCH, a center in the COMET Program managed by Austrian FFG. All co-authors have also received funding from Teaming.AI, a project supported by the European Union\u2019s Horizon 2020 program, under Grant Agreement No. 957402. References 1. Aggour, K.S., Kumar, V.S., Cuddihy, P., Williams, J.W., Gupta, V., Dial, L., Hanlon, T., Gambone, J., Vinciquerra, J.: Federated multimodal big data storage & analytics platform for additive manufacturing. In: 2019 IEEE International Conference on Big Data (Big Data), pp. 1729\u20131738. IEEE, New York (2019) 2. Alam, M., Fensel, A., Martinez-Gil, J., Moser, B., Recupero, D.R., Sack, H.: Special issue on machine learning and knowledge graphs. Future Gener. Comput. Syst. 129, 50\u201353 (2022). https://doi.org/10.1016/j.future.2021.11.022 3. Bachhofner, S., Kiesling, E., Kurniawan, K., Sallinger, E., Waibel, P.: Knowledge graph modularization for cyber-physical production systems. In: Seneviratne, O., Pesquita, C., Sequeda, J., Etcheverry, L. (eds.) Proceedings of the ISWC 2021 Posters, Demos and Industry Tracks: From Novel Ideas to Industrial Practice co-located with 20th International Semantic Web Conference (ISWC 2021), Virtual Conference, October 24\u201328, 2021. CEUR Workshop Proceedings, vol. 2980. CEUR-WS.org (2021). https://ceur-ws.org/Vol-2980/paper333.pdf 4. Bachhofner, S., Kiesling, E., Revoredo, K., Waibel, P., Polleres, A.: Automated process knowledge graph construction from BPMN models. In: Strauss, C., Cuzzocrea, A., Kotsis, G., Tjoa, A.M., Khalil, I. (eds.) Database and Expert Systems Applications\u201433rd International Conference, DEXA 2022, Vienna, Austria, August 22\u201324, 2022, Proceedings, Part I. Lecture Notes in Computer Science, vol. 13426, pp. 32\u201347. Springer, Berlin (2022). https://doi.org/10. 1007/978-3-031-12423-5_3 5. Bachhofner, S., Kurniawan, K., Kiesling, E., Revoredo, K., Bayomie, D.: Knowledge graph supported machine parameterization for the injection moulding industry. In: Villaz\u00f3n-Terrazas, B., Ortiz-Rodr\u00edguez, F., Tiwari, S., Sicilia, M., Mart\u00edn-Moncunill, D. (eds.) Knowledge Graphs and Semantic Web\u20144th Iberoamerican Conference and Third Indo-American Conference, KGSWC 2022, Madrid, Spain, November 21\u201323, 2022, Proceedings. Communications in Computer and Information Science, vol. 1686, pp. 106\u2013120. Springer, Berlin (2022). https:// doi.org/10.1007/978-3-031-21422-6_868 J. Martinez-Gil et al.6. Bader, S.R., Grangel-Gonzalez, I., Nanjappa, P., Vidal, M.E., Maleshkova, M.: A knowledge graph for industry 4.0. In: The Semantic Web: 17th International Conference, ESWC 2020, Heraklion, Crete, Greece, May 31\u2013June 4, 2020, Proceedings 17, pp. 465\u2013480. Springer, Berlin (2020) 7. Banerjee, A., Dalal, R., Mittal, S., Joshi, K.P.: Generating digital twin models using knowledge graphs for industrial production lines. In: Proceedings of the 2017 ACM on Web Science Conference, pp. 425\u2013430 (2017) 8. Buchgeher, G., Gabauer, D., Martinez-Gil, J., Ehrlinger, L.: Knowledge graphs in manufac-turing and production: a systematic literature review. IEEE Access 9, 55537\u201355554 (2021). https://doi.org/10.1109/ACCESS.2021.3070395 9. Chhetri, T.R., Aghaei, S., Fensel, A., G\u00f6hner, U., G\u00fcl-Ficici, S., Martinez-Gil, J.: Optimising manufacturing process with Bayesian structure learning and knowledge graphs. In: Computer Aided Systems Theory\u2014EUROCAST 2022\u201418th International Conference, Las Palmas de Gran Canaria, Spain, February 20\u201325, 2022, Revised Selected Papers. Lecture Notes in Computer Science, vol. 13789, pp. 594\u2013602. Springer, Berlin (2022). https://doi.org/10.1007/ 978-3-031-25312-6_70 10. Dombrowski, U., Reiswich, A., Imdahl, C.: Knowledge graphs for an automated information provision in the factory planning. In: 2019 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM). pp. 1074\u20131078. IEEE, New York (2019) 11. Duan, W., Chiang, Y.Y.: Building knowledge graph from public data for predictive analysis: a case study on predicting technology future in space and time. In: Proceedings of the 5th ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data, pp. 7\u201313 (2016) 12. Eibeck, A., Lim, M.Q., Kraft, M.: J-park simulator: an ontology-based platform for cross-domain scenarios in process industry. Comput. Chem. Eng. 131, 106586 (2019) 13. Freudenthaler, B., Martinez-Gil, J., Fensel, A., H\u00f6fig, K., Huber, S., Jacob, D.: Ki-net: Ai-based optimization in industrial manufacturing\u2014A project overview. In: Computer Aided Systems Theory\u2014EUROCAST 2022\u201418th International Conference, Las Palmas de Gran Canaria, Spain, February 20\u201325, 2022, Revised Selected Papers. Lecture Notes in Computer Science, vol. 13789, pp. 554\u2013561. Springer, Berlin (2022). https://doi.org/10.1007/978-3-031-25312-6_65 14. Garofalo, M., Pellegrino, M.A., Altabba, A., Cochez, M.: Leveraging knowledge graph embedding techniques for industry 4.0 use cases. In: Cyber Defence in Industry 4.0 Systems and Related Logistics and IT Infrastructures, pp. 10\u201326. IOS Press, New York (2018) 15. Grangel-Gonz\u00e1lez, I., Halilaj, L., Vidal, M.E., Lohmann, S., Auer, S., M\u00fcller, A.W.: Seamless integration of cyber-physical systems in knowledge graphs. In: Proceedings of the 33rd Annual ACM Symposium on Applied Computing, pp. 2000\u20132003 (2018) 16. Grangel-Gonz\u00e1lez, I., Halilaj, L., Vidal, M.E., Rana, O., Lohmann, S., Auer, S., M\u00fcller, A.W.: Knowledge graphs for semantically integrating cyber-physical systems. In: International Conference on Database and Expert Systems Applications, pp. 184\u2013199. Springer, Berlin (2018) 17. Haase, P., Herzig, D.M., Kozlov, A., Nikolov, A., Trame, J.: metaphactory: a platform for knowledge graph management. Semantic Web 10(6), 1109\u20131125 (2019) 18. He, L., Jiang, P.: Manufacturing knowledge graph: a connectivism to answer production problems query with knowledge reuse. IEEE Access 7, 101231\u2013101244 (2019) 19. Hermann, M., Pentek, T., Otto, B.: Design principles for Industrie 4.0 scenarios. In: 2016 49th Hawaii International Conference on System Sciences (HICSS), pp. 3928\u20133937. IEEE, New York (2016) 20. Hoch, T., Heinzl, B., Czech, G., Khan, M., Waibel, P., Bachhofner, S., Kiesling, E., Moser, B.: Teaming.ai: enabling human-ai teaming intelligence in manufacturing. In: Zelm, M., Boza, A., Le\u00f3n, R.D., Rodr\u00edguez-Rodr\u00edguez, R. (eds.) Proceedings of Interoperability for Enterprise Systems and Applications Workshops co-located with 11th International Conference on Interoperability for Enterprise Systems and Applications (I-ESA 2022), Valencia, Spain, March 23\u201325, 2022. CEUR Workshop Proceedings, vol. 3214. CEUR-WS.org (2022). https://ceur-ws. org/Vol-3214/WS5Paper6.pdfKnowledge Graphs in the Manufacturing Industry 6921. Kalayc\u0131, E.G., Grangel Gonz\u00e1lez, I., L\u00f6sch, F., Xiao, G., ul Mehdi, A., Kharlamov, E., Calvanese, D.: Semantic integration of Bosch manufacturing data using virtual knowledge graphs. In: The Semantic Web\u2013ISWC 2020: 19th International Semantic Web Conference, Athens, Greece, November 2\u20136, 2020, Proceedings, Part II 19, pp. 464\u2013481. Springer, Berlin (2020) 22. Kattepur, A.: Roboplanner: autonomous robotic action planning via knowledge graph queries. In: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, pp. 953\u2013956 (2019) 23. Ko, H., Witherell, P., Lu, Y., Kim, S., Rosen, D.W.: Machine learning and knowledge graph based design rule construction for additive manufacturing. Addit. Manuf. 37, 101620 (2021) 24. Kumar, A., Bharadwaj, A.G., Starly, B., Lynch, C.: FabKG: a knowledge graph of manufac-turing science domain utilizing structured and unconventional unstructured knowledge source. arXiv preprint arXiv:2206.10318 (2022) 25. Leijie, F., Yv, B., Zhenyuan, Z.: Constructing a vertical knowledge graph for non-traditional machining industry. In: 2018 IEEE 15th International Conference on Networking, Sensing and Control (ICNSC), pp. 1\u20135. IEEE, New York (2018) 26. Li, R., Dai, W., He, S., Chen, X., Yang, G.: A knowledge graph framework for software-defined industrial cyber-physical systems. In: IECON 2019-45th Annual Conference of the IEEE Industrial Electronics Society, vol. 1, pp. 2877\u20132882. IEEE, New York (2019) 27. Li, X., Chen, C.H., Zheng, P., Wang, Z., Jiang, Z., Jiang, Z.: A knowledge graph-aided concept\u2013 knowledge approach for evolutionary smart product\u2013service system development. J. Mech. Des. 142(10), 101403 (2020) 28. Li, X., Zhang, S., Huang, R., Huang, B., Xu, C., Kuang, B.: Structured modeling of heterogeneous cam model based on process knowledge graph. Int. J. Adv. Manuf. Technol. 96(9\u201312), 4173\u20134193 (2018) 29. Liebig, T., Maisenbacher, A., Opitz, M., Seyler, J.R., Sudra, G., Wissmann, J.: Building a Knowledge Graph for Products and Solutions in the Automation Industry (2019) 30. Liu, M., Li, X., Li, J., Liu, Y., Zhou, B., Bao, J.: A knowledge graph-based data representation approach for IIoT-enabled cognitive manufacturing. Adv. Eng. Inform. 51, 101515 (2022) 31. Martinez-Gil, J., Buchgeher, G., Gabauer, D., Freudenthaler, B., Filipiak, D., Fensel, A.: Root cause analysis in the industrial domain using knowledge graphs: a case study on power transformers. In: Longo, F., Affenzeller, M., Padovano, A. (eds.) Proceedings of the 3rd International Conference on Industry 4.0 and Smart Manufacturing (ISM 2022), Virtual Event/Upper Austria University of Applied Sciences\u2014Hagenberg Campus\u2014Linz, Austria, 17\u201319 November 2021. Procedia Computer Science, vol. 200, pp. 944\u2013953. Elsevier, Amsterdam (2021). https://doi.org/10.1016/j.procs.2022.01.292 32. Meckler, S., Steinm\u00fcller, H., Harth, A.: Building a knowledge graph with inference for a production machine using the web of things standard. In: Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineer-ing and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Kuala Lumpur, Malaysia, July 26\u201329, 2021, Proceedings, Part II 34, pp. 240\u2013251. Springer, Berlin (2021) 33. Nayak, A., Kesri, V., Dubey, R.K.: Knowledge graph based automated generation of test cases in software engineering. In: Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, pp. 289\u2013295 (2020) 34. Noy, N.F., Gao, Y., Jain, A., Narayanan, A., Patterson, A., Taylor, J.: Industry-scale knowledge graphs: lessons and challenges. Commun. ACM 62(8), 36\u201343 (2019). https://doi.org/10.1145/ 3331166 35. Peroni, S., Vitali, F.: Interfacing fast-fashion design industries with semantic web technologies: the case of imperial fashion. J. Web Semant. 44, 37\u201353 (2017) 36. Ringsquandl, M., Kharlamov, E., Stepanova, D., Lamparter, S., Lepratti, R., Horrocks, I., Kr\u00f6ger, P.: On event-driven knowledge graph completion in digital factories. In: 2017 IEEE International Conference on Big Data (Big Data), pp. 1676\u20131681. IEEE, New York (2017)70 J. Martinez-Gil et al.37. Ringsquandl, M., Lamparter, S., Lepratti, R., Kr\u00f6ger, P.: Knowledge fusion of manufacturing operations data using representation learning. In: IFIP International Conference on Advances in Production Management Systems, pp. 302\u2013310. Springer, Berlin (2017) 38. Ro\u017eanec, J.M., Zajec, P., Kenda, K., Novalija, I., Fortuna, B., Mladenic\u0301, D.: XAI-KG: knowledge graph to support XAI and decision-making in manufacturing. In: Proceedings of the Advanced Information Systems Engineering Workshops: CAiSE 2021 International Workshops, Melbourne, VIC, Australia, June 28\u2013July 2, 2021, pp. 167\u2013172. Springer, Berlin (2021) 39. Tushkanova, O., Samoylov, V.: Knowledge net: model and system for accumulation, represen-tation, and use of knowledge. IFAC-PapersOnLine 52(13), 1150\u20131155 (2019) 40. Wang, Z., Zhang, B., Gao, D.: A novel knowledge graph development for industry design: a case study on indirect coal liquefaction process. Comput. Ind. 139, 103647 (2022) 41. Yan, H., Yang, J., Wan, J.: KnowIME: a system to construct a knowledge graph for intelligent manufacturing equipment. IEEE Access 8, 41805\u201341813 (2020) 42. Zhang, X., Liu, X., Li, X., Pan, D.: MMKG: an approach to generate metallic materials knowledge graph based on DBpedia and Wikipedia. Comput. Phys. Commun. 211, 98\u2013112 (2017) 43. Zhao, M., Wang, H., Guo, J., Liu, D., Xie, C., Liu, Q., Cheng, Z.: Construction of an industrial knowledge graph for unstructured Chinese text learning. Appl. Sci. 9(13), 2720 (2019) 44. Zhao, Y., Liu, Q., Xu, W.: Open industrial knowledge graph development for intelligent man-ufacturing service matchmaking. In: 2017 International Conference on Industrial Informatics-Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII), pp. 194\u2013198. IEEE, New York (2017) 45. Zhou, B., Bao, J., Li, J., Lu, Y., Liu, T., Zhang, Q.: A novel knowledge graph-based optimization approach for resource allocation in discrete manufacturing workshops. Robot. Comput. Integr. Manuf. 71, 102160 (2021) 46. Zhou, X., Lim, M.Q., Kraft, M.: A Smart Contract-Based Agent Marketplace for the j-park Simulator\u2013a Knowledge Graph for the Process Industry (2020) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Leveraging Semantic Representations via Knowledge Graph Embeddings Franz Krause, Kabul Kurniawan, Elmar Kiesling, Jorge Martinez-Gil, Thomas Hoch, Mario Pichler, Bernhard Heinzl, and Bernhard Moser 1 Introduction Knowledge graphs are becoming increasingly recognized as a valuable tool in data-driven domains like healthcare [1], finance [2], and manufacturing [3], where they have gained considerable popularity in recent research. They are commonly employed to represent and integrate both structured and unstructured data, providing a standardized approach to encode domain knowledge [4]. Built on ontologies that conceptualize domain classes, relations, and logical inference rules, KGs represent specific instantiations of ontological models and their inherent semantic characteristics. Typically, KGs are divided into two modules: a terminological TBox containing concepts (such as the class of a manufacturing process) and an assertive ABox containing real-world instances (such as unique executions of a manufacturing process). F. Krause (\u0002) University of Mannheim, Data and Web Science Group, Mannheim, Germany e-mail: franz.krause@uni-mannheim.de K. Kurniawan WU, Institute for Data, Process and Knowledge Management, Vienna, Austria Austrian Center for Digital Production (CDP), Vienna, Austria e-mail: kabul.kurniawan@wu.ac.at E. Kiesling WU, Institute for Data, Process and Knowledge Management, Vienna, Austria e-mail: elmar.kiesling@wu.ac.at J. Martinez-Gil \u00b7 T. Hoch \u00b7 M. Pichler \u00b7 B. Heinzl \u00b7 B. Moser Software Competence Center Hagenberg GmbH, Hagenberg, Austria e-mail: Jorge.Martinez-Gil@scch.at; thomas.hoch@scch.at; Mario.Pichler@scch.at; bernhard.heinzl@scch.at; Bernhard.Moser@scch.at \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_57172 F. Krause et al.We adopt the notion of a (standard) KG .G = (V ,E) as described in [5], which is represented by a set of nodes V (also referred to as vertices) and a set of triples .E \u2286 V \u00d7 R \u00d7 V consisting of directed and labeled edges. Here, R denotes the set of valid relation types defined in the underlying ontology. Thus, an edge in the form of a triple .(s, p, o) \u2208 E implies an outgoing relation from the subject .s \u2208 V to the object .o \u2208 V via the predicate .p \u2208 R. Given such a KG, embedding techniques aim to exploit the topology of the graph to generate latent feature representations .\u03b3 : V \u2192 \ud835\udeaa (1) of its nodes V in a latent representation space . \ud835\udeaa, e.g., .\ud835\udeaa = Rd with .d \u2208 N, thereby enabling their utilization in downstream applications, e.g., graph-based machine learning (ML). However, the findings of this work can be applied almost analogously to the most well-known KG extensions, such as labeled property graphs like Neo4j [6]. In addition to the improved applicability of graph-based data in tasks like recommendation systems [7] or question answering [8], embedding formalisms have also proven to be valuable as intrinsic complements to graph-structured data. This is due to their ability to provide an empirical approach for enhancing the expressivity of graph topologies by means of downstream tasks like entity linking [9] and link prediction [10]. Consequently, related areas such as relational ML are receiving significant attention in both literature and applications [11]. In this chapter, we first provide a brief overview of representation learning as the enabler of KG embeddings, addressing state-of-the-art embedding formalisms for generating lean feature representations and describing their functionalities. An analysis of the advantages and drawbacks of employing KG embeddings is provided, along with a discussion of associated open research questions. We focus specifically on potential challenges and risks that may hinder the usage of KG embeddings in the highly dynamic manufacturing domain. Accordingly, we present the methodologies developed within the Teaming. AI project to address those problems. In this context, we describe the applicability and potential benefits of KG embeddings in the human\u2013AI-based manufacturing use cases of the project. Furthermore, we showcase the Navi approach as an enabler of dynamic KG embeddings that allows for real-time and structure-preserving computations of new or updated node representations. 2 Knowledge Graph Embeddings The generation of KG embeddings as per Eq. (1) denotes a subdiscipline of representation learning. In the context of KGs, representation learning is applied to determine lean feature representations that are able to capture inherent semanticLeveraging Semantic Representations via Knowledge Graph Embeddings 73relationships between KG elements. Thus, we first provide a general overview of representation learning to subsequently describe its application in KG embeddings. 3 Representation Learning Representation learning comprises techniques for the automatic detection of appro-priate feature representations that can be employed by downstream models or tasks, such as machine learning models [12]. Thus, the main objective of representation learning is to eliminate the need for preprocessing raw input data. Given a set of observable variables V with semantic representations .\u03c0 : V \u2192 \u03a0 within an inherent representation space . \u03a0 (which is not necessarily compatible with the downstream model), these techniques aim to generate an alternative feature mapping .\u03b3 : V \u2192 \ud835\udeaa into a representation space . \ud835\udeaa that satisfies the requirements of the desired task. Representation learning can be performed in a supervised, unsupervised, or self-supervised manner. One example of a supervised approach for learning latent feature representations is the training of deep neural networks on labeled input data. Namely, given an input feature .\u03c0(v) for some .v \u2208 V , the hidden layer outputs (and also the output layer) obtained from the forward pass of the network can be considered as alternative representations .\u03b3 (v), as illustrated in Fig. 1. Contrarily, unsupervised representation learning techniques can be utilized for unlabeled representations .\u03c0(v). Methods like principal component analysis or auto-encoders intend to reduce the dimensionality of high-dimensional input features. Accordingly, the goal of these algorithms is to determine alternative, low-dimensional representations without the consideration of any target feature except the input feature .\u03c0(v) itself. For example, auto-encoders feed a representation .\u03c0(v) \u2208 Rd ' into a deep neural network and attempt to reconstruct it, i.e., . \u03c0(v)also serves as the output feature. However, the hidden layers are assumed to be low-dimensional to serve as alternative representations .\u03b3 (v) \u2208 Rd of .v \u2208 V with . d \u2aa1 d 'as depicted in Fig. 2. Fig. 1 Deep neural networks as supervised representation learning formalisms74 F. Krause et al.Fig. 2 Auto-encoders as unsupervised representation learning formalisms Fig. 3 Extract from the abstract in [15]. The semantics of the word products is encoded within the sentences that contain it Finally, self-supervised representation learning aims to leverage the underlying structure .SV of unlabeled data that contains the variables .v \u2208 V and which allows for deriving meaningful initial representations .\u03c0(v). For example, a word .v \u2208 V may appear in a set of sentences .\u03c0(v) within a shared text corpus . SV , as  exemplified in Fig. 3. While state-of-the-art NLP models like BERT [13] usually split words into frequently occurring subword tokens via subword segmentation algorithms such asWordpiece [14], the inherent methods can be applied analogously to sets of complete words. In the course of training such NLP models, numerical embeddings .\u03b3 (v) \u2208 Rd are assigned to the domain variables .v \u2208 V with respect to their original representations .\u03c0(v). These alternative representations are optimized by backpropagating the output of the LLM for at least one element of its initial representation .\u03c0(v). Analogously, most NLP techniques can be applied to KG structures . G = (V ,E)by characterizing directed graph walks .(v1, p1, v2, p2, v3, . . . , vl\u22121, pl\u22121, vl) of depth .l \u2212 1 \u2208 N as sentences that are composed of edges .(vi, pi, vi+1) \u2208 E. For  instance, the sample manufacturing KG depicted in Fig. 4 contains the 4-hop walk (John, executes, Task 1, output, Product 1, input, Task 2, output, Product 2). One of these transfer approaches is RDF2Vec [16], which utilizes random graph walks to generate input data for the NLP-based Word2Vec algorithm [17]. By doing so, a mapping .\u03b3 : V \u222a R \u2192 Rd is trained and thus, alternative representations of the graph nodes in V , but also for the relation types in R as well. Therefore,Leveraging Semantic Representations via Knowledge Graph Embeddings 75Fig. 4 Sample KG containing process flows within a production process node embeddings can be derived via .\u03b3 (v) := \u03b3 (v). Besides transfer approaches like RDF2Vec, various embedding algorithms exist, which are specifically tailored toward KG structures. These are further discussed in the following. 3.1 Representation Learning for Knowledge Graphs KG embedding techniques denote a subdiscipline of representation learning, taking into account KG structures as initial input data. Given a KG .G = (V ,E), these approaches intend to provide numerical representations .\u03b3 : V \u2192 \ud835\udeaa as per Eq. (1). However, as exemplified by RDF2Vec, KG embeddings may contain alternative representations of graph elements .y /\u2208 V as well, such as embeddings of relations, but also edges or subgraphs. Thus, in general, a KG embedding is a mapping .\u03b3 : \u03a9 \u2192 \ud835\udeaa, where . \u03a9 represents a collection of KG elements pertaining to . G. The node embedding of some .v \u2208 V is accordingly obtained by restricting . \u03b3 to V , i.e., .\u03b3 (v) = \u03b3 (v). Based on the research conducted in [10], KG embedding methods can be cate-gorized into three model families, namely tensor decomposition models, geometric models, and deep learning models. We adopt this subdivision in the following. 3.1.1 Tensor Decomposition Models Tensor decomposition models for KG embeddings are based on the concept of tensor decompositions within the area of multilinear algebra [18]. These attempt76 F. Krause et al.Fig. 5 Sample KG with .n = 4 nodes and .k = 2 relations . r1 (blue) and . r2 (red), including their respective adjacency matrices . A1 and . A2to characterize tensors via sequences of simplified tensor operations. For a KG . G, this approach is applied to its unique adjacency tensor .A \u2208 {0, 1}k\u00d7n\u00d7n, defined as . Ah,i,j = 1 \u21d0\u21d2(vi, rh, vj) \u2208 E.Here, .k \u2208 N denotes the cardinality of the underlying relation set R and .n \u2208 N is the number of nodes in V . Accordingly, without loss of generality, we may assume labeled sets .R = {r1, . . . , rk} and .V = {v1, . . . , vn}, as exemplified in Fig. 5. Accordingly, tensor decomposition-based KG embedding methods intend to approximate . A by a sequence of lower dimensional tensor operations. Among these methods, RESCAL [19] is considered to be the first work to apply this methodology for determining KG embeddings. Regarding . A, it proposes a rank-d factorization . Ah \u2248 X \u00b7 Rh \u00b7 XTof its h-th slice .Ah \u2208 {0, 1}n\u00d7n by means of matrices .X \u2208 Rn\u00d7d and . Rh \u2208 Rd\u00d7dwith .d \u2aa1 n. Therefore, the i-th row of the matrix . X contains an alternative representation .\u03b3 (vi) :=(Xi,1, . . . ,Xi,d) \u2208 Rd of .vi \u2208 V . The optimization of the matrices . X and .(Rh)1\u2264h\u2264k is accordingly achieved by solving the minimization problems . minX,Rh f (X,Rh) for f (X,Rh) =12(\u2211kh=1 \u2016Ah \u2212 X \u00b7 Rh \u00b7 XT \u20162F),with the Frobenius norm .\u2016 \u00b7 \u2016F and the corresponding element-wise operations . f (h, i, j) = 12(Ah,i,j \u2212 \u03b3 (vi)T \u00b7 Rh \u00b7 \u03b3 (vj ))2.To reduce the complexity of these optimizations, DistMult proposes to use diagonal matrices .(Rh)1\u2264h\u2264k [20]. However, by doing so, DistMult is limited to symmet-ric relations. ComplEx solves this problem by employing .C-valued embedding spaces [21]. In addition to the mentioned models, numerous other tensor decompo-Leveraging Semantic Representations via Knowledge Graph Embeddings 77sition models for KG embeddings exist, including ANALOGY [22], SimplE [23], and HolE [24]. 3.1.2 Geometric Models Geometric KG embedding models represent semantic relations as geometric trans-formations within a corresponding embedding space. In contrast to tensor decompo-sition models, embeddings are not determined based on characteristics of the unique adjacency tensor . A, but with respect to individual facts .(s, p, o) \u2208 E. As outlined in [10], transformations .\u03c4p(s) := \u03c4 (\u03b3 (s), \u03b3 (p)) \u2208 \ud835\udeaa are applied for subject nodes .s \u2208 V regarding predicates .p \u2208 R. Accordingly, based on a distance measure .\u03b4 : \ud835\udeaa \u00d7 \ud835\udeaa \u2192 R\u22650, KG embeddings are computed via score functions . f (s, p, o) := \u03b4 (\u03c4p(s), \u03b3 (o)).Among the family of geometric KG embedding methods, TransE [25] constitutes the most famous approach. As a translational model, it approximates object representations .\u03b3 (o) via .\u03b3 (o) \u2248 \u03c4p(s) = \u03b3 (s) + \u03b3 (p). Various geometric KG embedding models build upon the idea of TransE, improving the representation of nodes and relations by introducing additional components or transformations, such as \u2022 Relationship-specific hyperplanes to capture complex interactions between nodes and relationships more effectively (TransH) [26] \u2022 Relationship-specific node projection matrices to handle entities and relation-ships with different characteristics more flexibly (TransR) [27] \u2022 Adaptive projection matrices regarding differing node-relation-pairs (TransD) [28] \u2022 Relationship clustering to group similar relations (TransG) [29] For a comprehensive overview of these methods, we refer to [10]. This work also introduces negative sampling as a common obstacle of KG embedding formalisms. Due to the open-world assumption of KGs, .(s, p, o) /\u2208 E does not necessarily imply that the fact is false. Rather, it means that the KG does not contain information about its validity. Thus, negative sampling is applied to create a set of false facts .Eneg \u2286 V \u00d7R \u00d7V with .E \u2229Eneg = \u2205 to train the embeddings in a supervised way. 3.1.3 Deep Learning Models Graph-based deep learning (DL) approaches, also referred to as Graph Neural Networks (GNNs), exist for some time already, especially in the context of complex network systems and their underlying undirected graph structures [30]. However, the application of such algorithms on directed and labeled KGs may lead to a loss of relevant information. To address this issue, Graph Convolutional Networks78 F. Krause et al.(GCNs) were first introduced to account for directed edges [31]. Furthermore, to accommodate different relation types, Relational Graph Convolutional Networks (RGCNs) were elaborated as extensions of GCNs [32], which were subsequently extended by means of attention mechanisms [33] in Relational Graph Attention Networks (RGATs) [34]. In contrast to geometric KG embedding models that apply score functions to individual triples and tensor decomposition models that intend to reduce the dimensionality of the adjacency tensor . A, DL-based models perform predictions for labeled nodes .v \u2208 V , taking into account itself and its outgoing neighbors . N(v) := {y \u2208 V | \u2203(s, p, o) \u2208 E : (s = y \u2227 o = v) \u2228 (s = v \u2227 o = y)} .These labels can be derived from the KG itself via node assertions or link assignments, or they can be external, such as numerical or nominal node attributes. Adjacent node representations are meant to be aggregated to receive a composite node representation of v. By backpropagating a suitable loss, initial embeddings of v and its neighbors are optimized. This process is repeated for each labeled training node to generate latent feature representations for all .v \u2208 V \u222a {N(v) : v \u2208 V }. The  formalism proposed in [32] subdivides .N(v) into relation-specific neighborhoods . Nr(v) := {y \u2208 V | \u2203(s, p, o) \u2208 E : (s = y \u2227 o = v) \u2228 (s = v \u2227 o = y) \u2227 p = r} ,regarding relation types .r \u2208 R. Thus, given a matrix of (initial) feature representa-tions .X \u2208 Rn\u00d7d (i.e., the i-th row of . X is an embedding of .vi \u2208 V ), embeddings of outgoing neighbors can be incorporated in the forward pass of a GNN via . Ah \u00b7 X \u2208 Rn\u00d7d ,where . Ah denotes the h-th slice of  .A. For instance, in the context of the KG from Fig. 5, the composite representation of . v1 regarding the relation . r1 equals the sum of the initial embeddings of . v2 and . v3. To account for differing impacts of incoming and outgoing edges, R is typically extended via inverse relations . r ' for each .r \u2208 R. Some works also consider a self-relation . r0. Accordingly, by taking into account the adjacency matrices .A0 = Id and .A2h = ATh for .1 \u2264 h \u2264 k, we extend the set R via . \u0302R := R \u222a {r ' | r \u2208 R} \u222a {r0} with r 'h = r2h.By doing so, GNN models capture the semantics of directed and labeled graphs by summing up weighted composite representations to receive a convoluted matrix .2k\u2211h=0A\u0302h \u00b7 X \u00b7Wh \u2208 Rn\u00d7d ',Leveraging Semantic Representations via Knowledge Graph Embeddings 79including relation-specific weight matrices .Wh \u2208 Rd\u00d7d ' . Moreover, the extended adjacency tensor .A\u0302 \u2208 R(2k+1)\u00d7n\u00d7n is not necessarily .{0, 1}-valued. Rather, it is intended to contain normalization constants or attention scores to encode the significance of individual nodes and relations to the forward pass of a GNN. However, . (vi, rh, vj) /\u2208 E \u21d2 A\u0302h,i,j = 0still holds. If no normalization constants or attention mechanisms are to be implemented, this tensor can be directly derived from .A \u2208 {0, 1}k\u00d7n\u00d7n by means of matrix transpositions and the insertion of an additional identity matrix. Finally, by introducing an activation function .\u03c3 : R \u2192 R such as ReLu, the generalized forward pass of a GNN layer (including RGCNs and RGATs) can be defined as .\u03c3(2k\u2211h=0A\u0302h \u00b7 X \u00b7Wh)=: X' \u2208 Rn\u00d7d ' . (2) 4 Industrial Applications of Knowledge Graph Embeddings The lack of use case scenarios poses a significant challenge to the application of KGs and corresponding KG embeddings in the manufacturing domain. Without specific applications, it becomes difficult to identify the relevant data sources, design appropriate KG structures, and create meaningful embeddings that capture the intricate relationships within manufacturing processes. Thus, the absence of concrete use cases hinders the exploration of the full potential of KGs and KG embeddings in improving efficiency, decision-making, and knowledge sharing within this domain. As a result of the research conducted within the Teaming.AI project, which aims to enhance flexibility in Industry 4.0, while prioritizing human involvement and collaboration in maintaining and advancing AI systems, we identified several application scenarios within the manufacturing domain that can be leveraged by introducing industrial KGs and KG embeddings. These are introduced in the following. Data Integration and Fusion Manufacturing involves diverse and complex data from various sources, such as sensors, process logs, or maintenance records. While KGs can integrate these heterogeneous data sources, KG embeddings map them into a shared representation space. By representing KG nodes and their relationships in this shared embedding space, it becomes easier to combine and analyze data from different sources, leading to enhanced data fusion capabilities.80 F. Krause et al.Semantic Similarity and Recommendation KG embeddings allow for quantify-ing the semantic similarity between nodes. In the manufacturing domain, this can be useful for recommending similar products, materials, or processes based on their embeddings. For example, embeddings can help to identify alternative materials with desired properties or characteristics, thereby aiding in material selection. Supply Chain Management Effective supply chain management is crucial for manufacturing. KGs and corresponding KG embeddings can help model and analyze complex supply chain networks by representing suppliers, products, trans-portation routes, and inventory levels as graph entities. By considering their semantic relations, embeddings can facilitate supply chain optimization, demand forecasting, and identifying potential risks in the supply chain. Decision Support Systems KG embeddings and relational ML techniques can serve as a foundation for developing decision support systems in manufacturing. By learning from empirical semantic observations, these systems can provide recommendations, insights, and decision-making support to operators, engineers, and managers. For example, based on the current state of the manufacturing environment, the system can suggest optimal operating conditions or maintenance actions. Moreover, models can be learned to recommend ML models for AI activities, given the current manufacturing environment. Fault Detection and Diagnosis KG embeddings combined with relational ML techniques can aid in fault detection and diagnosis in manufacturing systems. By analyzing historical data and capturing the relationships between machines, process variables, and failure events, embeddings can be used to build systems that identify faults or failures in advance. This facilitates proactive maintenance, reduces downtime, and improves overall effectiveness. In conclusion, KGs allow for representing manufacturing concepts and entities (such as processes, machines, and human workers) and their semantic relationships. KG embeddings, on the other hand, capture inherent semantics in lean numerical representations which facilitate (i) the analysis of existing manufacturing knowledge and (ii) the extraction of new manufacturing knowledge based on empirical observations. As a powerful tool for representing domain knowledge in a human-and machine-interpretable way, KGs enable the combination of human comprehen-sibility with the computational capabilities of machines. This synergy of human and machine intelligence enables effective collaboration, decision-making, and efficient problem solving in the manufacturing domain. Moreover, it represents a step toward optimized human-in-the-loop scenarios [35] and human-centric Industry 5.0 [36]. However, the manufacturing domain is inherently dynamic, with continuous changes in its processes, equipment, materials, and market demands. Therefore, it is crucial to incorporate these dynamics into KG embeddings, which are typically designed for static snapshots of a domain (cf. Sect. 3.1). In the end, KG embeddings should be able to capture the evolving relationships, dependencies, and contextual information, preferably in real time. By incorporating dynamics, the embeddingsLeveraging Semantic Representations via Knowledge Graph Embeddings 81can adapt to changes in manufacturing operations, such as process modifications, equipment upgrades, or variations in product requirements. This enables the repre-sentations to accurately reflect the current state of the manufacturing system and to capture the evolving aspects of runtime observations and data. 5 The Navi Approach: Dynamic Knowledge Graph Embeddings via Local Embedding Reconstructions Most of the existing works on dynamic graph embeddings do not account for directed and labeled graphs. Rather, they are designed to be applicable to undirected and/or unlabeled graphs [37, 38], or they aim to embed temporally enhanced snapshots of non-dynamic graphs [39, 40]. Moreover, approaches like the one proposed in [41] exist that intend to perform an online training of KG embeddings by focusing on regions of the graph which were actually affected by KG updates. However, the overall embedding structure is still affected, leading to a need for continuous adjustments of embedding-based downstream tasks, such as graph-based ML models. Thus, we require a dynamic KG embedding formalism that (i) can produce real-time embeddings for dynamic KGs and (ii) is able to preserve the original structure of KG embeddings to allow for consistent downstream applications. We propose to utilize the dynamic Navi approach [42], which is based on the core idea of GNNs as per Eq. (2). Given an initial KG .Gt0 = (Vt0 , Et0) at timestamp . t0, we assume an embedding .\u03b3\u0303t0 : Vt0 \u2192 Rd based on some state-of-the-art KG embedding method from Sect. 3.1. Accordingly, a dynamic KG is defined as a family of stationary snapshots .(Gt )t\u2208T with respect to some time set . T. Given  a future timestamp .t > t0, the Navi approach provides a consistent embedding .\u03b3t : Vt \u2192 Rd so that previously trained downstream models can still be employed. Since we leverage the idea of GNNs to reconstruct .\u03b3\u0303t0(v) through local neighbor-hoods, these reconstructions are based on the unique adjacency tensors . (A(t))t\u2208Twith .A(t) \u2208 Rk\u00d7nt\u00d7nt . Here, .nt =\u2223\u2223\u22c3\u03c4\u2264t V\u03c4\u2223\u2223 denotes the number of nodes that were known to exist since the graph\u2019s initialization and thus .nt \u2265 nt0 holds. Thus, we assume an initial embedding matrix .X\u0303t0 \u2208 Rnt0\u00d7d that contains the initial embeddings as per . \u0303\u03b3t0 . This matrix is then reconstructed based on itself via a single-layer GNN . \u03c3(A\u0302(t0)0 \u00b7 \u0398t0 \u00b7W0 +\u22112kh=1 A\u0302(t0)h \u00b7 X\u0303t0 \u00b7Wh)=: Xt0 \u2248 X\u0303t0by taking into account the extended adjacency tensor .A\u0302(t0) (cf. Sect. 3.1.3). During the training process, a global embedding .\u03b3r0 \u2208 Rd is implemented regarding the self-relation . r0 so that .\u0398t0 \u2208 Rnt0\u00d7d contains . nt0 copies of . \u03b3r0 . Moreover, instead of zero-value dropouts, overfitting is prevented by randomly replacing node embed-82 F. Krause et al.dings with . \u03b3r0 in the input layer, simulating the semantic impact of nodes that are not known at time . t0. It is also used to represent self-loops, enabling reconstructions that are independent of the (potentially unknown) initial representations. A detailed overview, including training settings and benchmark evaluation results, can be found in [42]. The evaluation implies that, given a timestamp .t > t0, this approach allows for high-qualitative and consistent embeddings .\u03b3t : Vt \u2192 Rd that are computed via . \u03c3(A\u0302(t)0 \u00b7 \u0398t \u00b7W0 +\u22112kh=1 A\u0302(t)h \u00b7 X\u0303t \u00b7Wh)=: Xt ,i.e., the i-th row of . Xt represents the embedding .\u03b3t (vi) of the node .vi \u2208 Vt . In the  case of new nodes, . \u0303Xt and . \u0398t are the extensions of . \u0303Xt0 and . \u0398t0 by inserting copies of . \u03b3r0 , respectively. Moreover, the update of the adjacency tensor can be performed via . A(t)h = I (t0, t)T \u00b7A(t0)h \u00b7 I (t0, t) + B(t0, t)h.First, the matrix .I (t0, t) \u2208 {0, 1}nt0\u00d7nt accounts for newly inserted nodes, i.e., . I (t0, t)i,j = 1 \u21d0\u21d2 i = j.Second, the update matrices .B(t0, t)h \u2208 {\u22121, 0, 1}nt\u00d7nt identify KG updates . B(t0, t)i,j =={1 \u21d0\u21d2 the edge (vi, rh, vj ) was inserted between t0 and t\u22121 \u21d0\u21d2 the edge (vi, rh, vj ) was deleted between t0 and t.After the KG update, a synchronizing assistant is to provide (i) the number of nodes . nt and (ii) the update tensor .B(t0, t) \u2208 {\u22121, 0, 1}k\u00d7nt\u00d7nt . For instance, given an Apache Jena Fuseki1 KG, existing logging tools like rdf-delta2 can be extended to use them as synchronizing assistants. Moreover, while we focus on a single update at time .t \u2208 T, transitions between arbitrary timestamps can be handled as well, i.e., . A(t ')h = I (t, t ')T \u00b7A(t)h \u00b7 I (t, t ') + B(t, t ')h for t0 < t < t '.In conclusion, the late shaping of KG embeddings via Navi reconstructions rep-resents a promising approach for incorporating dynamic KG updates and semantic evolutions into KG embeddings as lean feature representations of domain concepts and instances. Besides the ability to allow for consistent embeddings, the results in [42] even showed that the reconstruction of existing embeddings often leads to an improved performance in downstream tasks like link predictions and entity classifications as key enablers of the industrial use case applications outlined in Sect. 4.1 Apache Software Foundation, 2021. Apache Jena, Available at https://jena.apache.org/. 2 https://afs.github.io/rdf-delta/. Leveraging Semantic Representations via Knowledge Graph Embeddings 836 Conclusions In this work, we highlighted the increasing importance of representing and exploit-ing semantics, with a specific emphasis on the manufacturing domain. While industrial KGs are already employed and utilized to integrate and standardize domain knowledge, the generation and application of KG embeddings as lean feature representations of graph elements have been largely overlooked. Existing KGs lack either domain dynamics or contextuality, limiting the applicability of context-dependent embedding algorithms. Thus, we provide an overview of state-of-the-art KG embedding techniques, including their characteristics and prerequisites. In this context, we emphasized the need for dynamic embedding methods and their implementation in concrete manufacturing scenarios, describing potential KG embedding applications in industrial environments, which were identified as a result of the Teaming.AI project. Furthermore, we introduced the concept of Navi reconstructions as a real-time and structure-preserving approach for generating dynamic KG embeddings. To summarize, KGs and KG embeddings offer significant advantages for the manufacturing domain. The structured representation of complex relationships in KGs enables context-awareness, dynamic analysis, and efficient information retrieval. Furthermore, the utilization of KG embeddings promotes process opti-mization, leading to improved product quality, reduced errors, and an increased overall productivity. Acknowledgments This work is part of the TEAMING.AI project which receives funding in the European Commission\u2019s Horizon 2020 Research Program under Grant Agreement Number 957402 (www.teamingai-project.eu). References 1. Mohamed, S.K., Nov\u00e1c\u030cek, V., Nounu, A.: Discovering protein drug targets using knowledge graph embeddings. Bioinformatics 36(2), 603\u2013610 (2020) 2. Fu, X., Ren, X., et al.: Stochastic optimization for market return prediction using financial knowledge graph. In: IEEE International Conference on Big Knowledge, ICBK, pp. 25\u201332. IEEE Computer Society, New York (2018) 3. Buchgeher, G., Gabauer, D., et al.: Knowledge graphs in manufacturing and production: a systematic literature review. IEEE Access 9, 55537\u201355554 (2021) 4. Hogan, A., Blomqvist, E., et al.: Knowledge graphs. ACM Comput. Surv. (CSUR) 54(4), 1\u201337 (2021) 5. Krause, F., Weller, T., Paulheim, H.: On a generalized framework for time-aware knowledge graphs. In: Towards a Knowledge-Aware AI\u2014Proceedings of the 18th International Confer-ence on Semantic Systems, vol. 55, pp. 69\u201374. IOS Press, New York (2022) 6. Neo4j: Neo4j\u2014the world\u2019s leading graph database (2012) 7. Palumbo, E., Rizzo, G., et al.: Knowledge graph embeddings with node2vec for item recommendation, In: The Semantic Web: ESWC Satellite Events, pp. 117\u2013120 (2018)84 F. Krause et al.8. Diefenbach, D., Gim\u00e9nez-Garc\u00eda, J., et al.: Qanswer KG: designing a portable question answering system over RDF data. In: The Semantic Web: ESWC 2020, pp. 429\u2013445 (2020) 9. Sun, Z., Hu, W., et al.: Bootstrapping entity alignment with knowledge graph embedding. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence, pp. 4396\u2013 4402. AAAI Press, New York (2018) 10. Rossi, A., Barbosa, D., et al.: Knowledge graph embedding for link prediction: a comparative analysis. ACM Trans. Knowl. Discov. Data 15(2), 1\u201349 (2021) 11. Nickel, M., Murphy, K., et al.: A review of relational machine learning for knowledge graphs. Proc. IEEE 104(1), 11\u201333 (2016) 12. Bengio, Y., Courville, A., Vincent, P.: Representation learning: A review and new perspectives. IEEE Trans. Pattern Anal. Mach. Intell. 35(8), 1798\u20131828 (2013) 13. Devlin, J., Chang, M.-W., et al.: BERT: Pre-training of deep bidirectional transformers for language understanding. In: Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171\u2013 4186. Association for Computational Linguistics, Kerrville (2019) 14. Schuster, M., Nakajima, K.: Japanese and Korean voice search. In ICASSP, pp. 5149\u20135152. IEEE, New York (2012) 15. Lu, Y., Xu, X., Wang, L.: Smart manufacturing process and system automation\u2014a critical review of the standards and envisioned scenarios. J. Manuf. Syst. 56, 312\u2013325 (2020) 16. Ristoski, P., Rosati, J., et al.: Rdf2vec: RDF graph embeddings and their applications. Semantic Web 10, 721\u2013752 (2019) 17. Mikolov, T., Sutskever, I., et al.: Distributed representations of words and phrases and their compositionality. In: Advances in Neural Information Processing Systems, vol. 26. Curran Associates, Inc., New York (2013) 18. Kolda, T.G., Bader, B.W.: Tensor decompositions and applications. SIAM Rev. 51(3), 455\u2013500 (2009) 19. Nickel, M., Tresp, V., Kriegel, H.-P.: A three-way model for collective learning on multi-relational data. In: Proceedings of the 28th International Conference on International Con-ference on Machine Learning, pp. 809\u2013816. Omnipress, New York (2011) 20. Yang, B., Yih, W.-T., et al.: Embedding entities and relations for learning and inference in knowledge bases. In: 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7\u20139, 2015, Conference Track Proceedings (2015) 21. Trouillon, T., Welbl, J., et al.: Complex embeddings for simple link prediction. In: Proceedings of The 33rd International Conference on Machine Learning, vol. 48, pp. 2071\u20132080. PMLR, New York (2016) 22. Liu, H., Wu, Y., Yang, Y.: Analogical inference for multi-relational embeddings. In: Proceed-ings of the 34th International Conference on Machine Learning, vol. 70, pp. 2168\u20132178 (2017). JMLR.org 23. Kazemi, S.M., Poole, D.: Simple embedding for link prediction in knowledge graphs. In: NeurIPS, pp. 4289\u20134300. Curran Associates Inc., New York (2018) 24. Nickel, M., Rosasco, L., Poggio, T.: Holographic embeddings of knowledge graphs. In: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pp. 1955\u20131961. AAAI Press, New York (2016) 25. Bordes, A., Usunier, N., et al.: Translating embeddings for modeling multi-relational data. In: Proceedings of the 26th International Conference on Neural Information Processing Systems, vol. 2, pp. 2787\u20132795. Curran Associates Inc., New York (2013) 26. Wang, Z., Zhang, J., et al.: Knowledge graph embedding by translating on hyperplanes. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol. 28(1) (2014) 27. Lin, Y., Liu, Z., et al.: Learning entity and relation embeddings for knowledge graph completion. In: Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 2181\u20132187. AAAI Press, New York (2015) 28. Ji, G., He, S., et al.: Knowledge graph embedding via dynamic mapping matrix. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, pages 687\u2013696. Association for Computational Linguistics, New York (2015)Leveraging Semantic Representations via Knowledge Graph Embeddings 8529. Xiao, H., Huang, M., Zhu, X.: TransG: a generative model for knowledge graph embedding. In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pp. 2316\u20132325. Association for Computational Linguistics, New York (2016) 30. Wu, Z., Pan, S., et al.: A comprehensive survey on graph neural networks. IEEE Trans. Neural Networks Learn. Syst. 32(1), 4\u201324 (2021) 31. Kipf, T.N., Welling, M.: Semi-supervised classification with graph convolutional networks. In: ICLR (2017) 32. Schlichtkrull, M., Kipf, T.N., et al.: Modeling relational data with graph convolutional networks. In: The Semantic Web ESWC, pp. 593\u2013607. Springer, Berlin (2018) 33. Vaswani, A., Shazeer, N., et al.: Attention is all you need. In: Advances in Neural Information Processing Systems, pp. 5998\u20136008 (2017) 34. Busbridge, D., Sherburn, D., et al.: Relational Graph Attention Networks (2019) 35. Schirner, G., Erdogmus, D., et al.: The future of human-in-the-loop cyber-physical systems. Computer 46(1), 36\u201345 (2013) 36. Leng, J., Sha, W., et al.: Industry 5.0: prospect and retrospect. J. Manuf. Syst. 65, 279\u2013295 (2022) 37. Pareja, A., Domeniconi, G., et al.: EvolveGCN: Evolving graph convolutional networks for dynamic graphs. In: The Thirty-Fourth AAAI Conference on Artificial Intelligence AAAI, The Thirty-Second Innovative Applications of Artificial Intelligence Conference IAAI, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence EAAI, pp. 5363\u20135370. AAAI Press, New York (2020) 38. Trivedi, R., Farajtabar, M., Biswal, P., Zha, H.: DyRep: learning representations over dynamic graphs. In: International Conference on Learning Representations (2019) 39. Dasgupta, S.S., Ray, S.N., Talukdar, P.: HyTE: hyperplane-based temporally aware knowledge graph embedding. In: Proceedings of the Conference on Empirical Methods in Natural Language Processing, pp. 2001\u20132011. Association for Computational Linguistics, Belgium (2018) 40. Liao, S., Liang, S., et al.: Learning dynamic embeddings for temporal knowledge graphs. In: Proceedings of the 14th ACM International Conference on Web Search and Data Mining, pp. 535\u2013543. Association for Computing Machinery, New York (2021) 41. Wewer, C., Lemmerich, F., Cochez, M.: Updating embeddings for dynamic knowledge graphs. CoRR, abs/2109.10896 (2021) 42. Krause, F.: Dynamic knowledge graph embeddings via local embedding reconstructions. In: The Semantic Web: ESWC Satellite Events, pp. 215\u2013223. Springer, Berlin (2022) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Architecture of a Software Platform for Affordable Artificial Intelligence in Manufacturing Vincenzo Cutrona , Giuseppe Landolfi , Rub\u00e9n Alonso , Elias Montini , Andrea Falconi , and Andrea Bettoni 1 Introduction The huge transformation brought by the fourth industrial revolution into the manufacturing world has forced any company to take on the digitalization journey, regardless of its size, sector, or location. In this context, Artificial Intelligence (AI) technologies are ready to take off as a new approach to solve business issues, and, recently, AI tools are proliferating [1]. Forward-thinking results can be obtained by analyzing huge amounts of data from a wide range of sources in the production system and by identifying deviations and trends in real time for making decisions [2]. The greater intelligence brought by AI embedded in production systems can not only bring advantages for large companies but also support Small-Medium Enterprises (SMEs) and mid-caps in achieving better operational performance. Yet V. Cutrona \u00b7 G. Landolfi \u00b7 A. Bettoni University of Applied Science of Southern Switzerland, Viganello, Switzerland e-mail: vincenzo.cutrona@supsi.ch; giuseppe.landolfi@supsi.ch; andrea.bettoni@supsi.ch R. Alonso R2M Solution s.r.l., Pavia, Italy Programa de Doctorado, Centro de Autom\u00e1tica y Rob\u00f3tica, Universidad Polit\u00e9cnica de Madrid-CSIC, Madrid, Spain e-mail: ruben.alonso@r2msolution.com E. Montini (\u0002) University of Applied Science of Southern Switzerland, Viganello, Switzerland Politecnico di Milano, Milan, Italy e-mail: elias.montini@supsi.ch A. Falconi Martel Innovate, Zurich, Switzerland e-mail: andrea.falconi@martel-innovate.com \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_68788 V. Cutrona et al.several challenges are still preventing them from embracing AI on a large scale. To reduce the barriers, two conditions have to be satisfied: the technology has to be affordable and accessible enough for mass use, and the level of awareness of individuals and companies should be high enough to be able to understand how and where to use it. The first condition can be tackled by democratizing AI tools: by exploiting the \u201cas-a-service-model,\u201d technologies can be made available to SMEs at an affordable price and on-demand, thus reducing the financial gap with large companies and avoiding SMEs getting lost in the hype around AI [3]. This is the best solution since, on the one hand, the adoption of ad hoc solutions for specific company requirements leads to integration problems, long implementation times, and flexibility limits. On the other hand, adopting an all-in-one solution requires big investments for complex systems, which exceed the effective needs and strictly depend on legacy providers. The second condition is more difficult to be satisfied at the level of single companies since, often, SMEs lack the skills and knowledge needed to turn AI into a major boost for their business, thus lagging behind larger organizations in the uptake level [4]. Successful implementation of AI requires identifying the right tools to be chosen among a plethora of solutions and their harmonization with existing IT systems and processes from both a technical and a strategic point of view so that they can become real enablers for performance improvement. Upskilling workers is essential to both empower a mutually supportive human\u2013machine interaction and lower adoption barriers, but building internal competences requires time. Support is needed now to accompany European SMEs in their digitization journey so that they can keep the pace with their larger counterparts and be key players in their value chains. An innovation ecosystem should be created around SMEs so that they can easily find locally the needed support to draw customized AI adoption plans and be immersed in a vibrant and stimulating environment that makes them progress across the digital innovation flow. At the European level, initiatives have been launched to promote the development of platforms that could support SMEs in the digital uptake, and the creation of local Digital Innovation Hubs (DIHs) is promoted to create an innovation ecosystem providing services to lower the entry barriers for SMEs. The AI uptake has to pivot on digital platforms that act as one-stop shop for SMEs, showcasing advances brought forward by synergistic efforts of DIHs, research centers, and technologies providers and offering services to smooth the adoption. Being able to offer to SMEs solutions tailored to their specific needs, built on modular kits, at a reasonable cost, easy and fast to implement is a must to strengthen the European economy\u2019s competitiveness. KITT4SME recognizes that SMEs are among the companies that could benefit the most from the opportunities brought by AI solutions while, at the same time, being the ones with the least capabilities and resources to embrace them. KITT4SME specifically targets European SMEs and mid-caps to provide them with scope-tailored and industry-ready hardware, software, and organizational kits, delivered as a modularly customizable digital platform that seamlessly introduces AI in their production systems. Uptake of the resulting packages and of the providedArchitecture of a Software Platform for Affordable AI in Manufacturing 89services is strongly supported by the clear characterization and market readiness of the individual components and by the platform grounding on the already established RAMP marketplace. Seamless adoption of the customized kits is made possible by a Powered by FIWARE infrastructure,1 which flawlessly combine factory systems (such as Manufacturing Execution System (MES) and Enterprise Resource Planning (ERP)), Internet of Things (IoT) sensors and wearable devices, robots, collaborative robots, and other factory data sources with functional modules capable of triggering data-driven value creation. The rest of the chapter is structured as follows: Sect. 2 examines existing plat-forms and alternative methods for delivering AI services to manufacturing SMEs; Sect. 3 introduces the concept underlying the proposed platform, its architecture, and the provided functionalities for supporting AI developers; in Sect. 4, a real-world use case illustrating the advantages of the proposed platform for an SME is presented; and Sect. 5 concludes with a discussion of limitations and related future work. 2 Platforms in the AI Ecosystem The KITT4SME platform aims to assist SMEs in adopting AI-based solutions by offering various services. These services, ranging from analyzing clients\u2019 requirements and implementing technical solutions to developing AI applications and training AI algorithms, coexist in an environment with platforms providing AI solutions, technology providers, AI consulting firms, and DIHs. Platform-based services and aPaas are cloud computing services that allow customers to provide, instantiate, run, and manage modular software solutions com-prising a core infrastructure and one or more applications without the complexity of building and maintaining the whole system, typically associated with developing and launching the applications [5]. These solutions allow also developers to create, develop, and package such software bundles. Gartner sees AI Platform as a Service (AI PaaS) as a set of separate AI services. However, it is possible to consider the concept of AI PaaS from the perspective of the classic Platform as a Service (PaaS) model. Such an environment usually includes two main components required for application development: hardware infrastructure (computing power, data storage, networking infrastructure, and virtual machines) and software solutions (tools and services). The key hurdle to generalize a similar scheme for the AI PaaS architecture is that there is no general model for AI PaaS yet. The market is still forming, and different vendors offer completely different services under the same umbrella term. Yet many elements are common to the majority of today\u2019s AI PaaS and AI service1 https://www.fiware.org/. 90 V. Cutrona et al.platforms: infrastructure, data storage, pre-trained AI models, and Application Program Interfaces (APIs). AI as a Service (AIaaS) allows individuals and companies to experiment with AI for various purposes without a large initial investment and with lower risk [6]. In this market, different AI providers offer several styles of Machine Learning (ML) and AI. These variations can be more or less suited to an organization\u2019s AI needs since organizations must evaluate features and pricing to see what works for them. To date, there are two kinds of platforms, depending on how they offer the service: \u2022 Platforms to develop code to build AI programs: comparable to an open-source solution that allows users to create and configure applications through a graphical user interface instead of a traditional hand-coding computer program \u2022 Platforms providing already developed applications: similarly to KITT4SME, these platforms allow users to deploy and implement ready-to-use solutions that do not require users to have advanced technology and IT skills. Since KITT4SME addresses SMEs, and very few of them have in-house competencies (data scientists, analysts, and developers) or a specialized team able to develop AI models and applications [4], the following paragraphs focus on the platforms providing already developed applications. Acumos AI Acumos AI2 is an open-source platform that enables the training, integration, and deployment of AI models. It was launched in 2018 by the LF AI Foundation,3 which supports open-source innovation in AI, ML, and Deep Learning (DL), making these technologies available to developers and data scientists. The platform provides a marketplace for AI solutions that are not tied to any specific infrastructure or cloud service. It aims to create a flexible mechanism for packaging, sharing, licensing, and deploying AI models securely through a distributed catalog among peer systems. Acumos AI aims to make AI and machine learning accessible to a broad audience by creating a marketplace of reusable solutions from various AI toolkits and languages. This way, ordinary developers who are not machine learning experts or data scientists can easily create their applications [7]. Bonseyes Bonseyes4 was a H2020 project that ended in 2020. It was led by NVISO SA,5 based in Lausanne, and aimed to create a platform with a Data Marketplace, DL Toolbox, and Developer Reference Platforms. The platform was designed for organizations that wanted to implement AI in low-power IoT devices, embedded computing systems, or data center servers. The platform had an engagement strategy where platform experts published challenges and requests for AI solutions that met specific technical requirements based on real industrial problems faced by companies. Data scientists proposed their own AI applications to be deployed on the2 https://www.acumos.org/. 3 https://lfaidata.foundation/. 4 https://www.bonseyes.eu/. 5 https://www.nviso.ai. Architecture of a Software Platform for Affordable AI in Manufacturing 91platform. Companies evaluated and paid the winners after the call ended. Bonseyes used a collaborative AI Marketplace to provide real-world solutions to the industry, supporting scenarios where data must remain on the data provider\u2019s premises and online learning with distributed Cyber-Physical Systems (CPSs). The platform allowed continuous feedback from human actors to evaluate model performance and obtain metadata about context and users\u2019 perspectives [8, 9]. GRACE AI Grace AI6 is an AI platform launched by 2021.AI in 2018, with the mission to help customers in realizing their vision of AI by identifying innovative business opportunities in key processes and functions. Grace AI Platform and the AIaaS portfolio are the company\u2019s main assets. The Grace platform is built for both organizations at the beginning of their AI and ML journey and organizations that have already established a data science team but are looking for ways to infuse continuous intelligence into their business. Grace AI aims to provide any organization access to AI implementation, includ-ing automated documentation, validation, and certification through data exploration, AI development, deployment, and operation. PTC Inc. PTC Inc.7 is a software and services company founded in 1985, based in Boston. It offers a range of products and services that support innovation and Industry 4.0. It is a platform for developing IoT and Augmented Reality (AR) solutions. PTC Marketplace is a digital space where customers and partners can access IoT apps, market-ready solutions, and innovative technologies. PTC has made recent enhancements to its marketplace, making it easier for solution builders to find market-ready solutions and customized accelerators. It also provides a platform for PTC partners to showcase their technologies, solutions, services, and industry expertise to customers and prospects. The platform offers a rich set of capabilities that enable solutions for design, man-ufacturing, service, and industrial operations and incorporates modular functionality that simplifies development. These include pre-built applications for the fast, easy implementation of Industrial Internet of Things (IIoT) solutions for common use cases in various industries. 3 KITT4SME: A Platform Delivering AI to SMEs The KITT4SME project aims to provide AI solutions to SMEs in the manufacturing domain through a five-step workflow. This workflow consists of interconnected activities designed to facilitate the adoption of AI technologies on the shop floor. The activities are detailed as follows:6 https://2021.ai/offerings/grace-ai-platform/. 7 https://www.ptc.com/. 92 V. Cutrona et al.\u2022 Diagnose: In this step, the KITT4SME platform utilizes a smart questionnaire to identify how AI can be beneficial in transitioning the shop floor. The questionnaire helps assess the specific needs and challenges of the SMEs, enabling a better understanding of where AI technologies can be applied effectively. \u2022 Compose: The platform recommends a minimal set of AI tools from a market-place catalog based on the diagnosis obtained in the previous step. It considers the unique requirements and constraints of each SME, aiming to maximize the benefits derived from the AI technologies. The platform provides guidance on the wiring and configuration of these AI tools, ensuring their seamless integration into the existing workflow. \u2022 Sense: This activity focuses on establishing the connection between the shop floor and the cloud platform. By enabling this connection, new data become available to AI services. The KITT4SME platform provides a tailor-made kit that can output insights about the status of the shop floor (e.g., to detect and explain anomalies). Additionally, it offers visualization of Key Performance Indicators (KPIs), allowing SMEs to gain valuable insights into their operations. \u2022 Intervene: In this step, the platform suggests corrective actions to address ongoing issues and anomalies identified on the shop floor. Leveraging the power of AI, the platform provides recommendations for resolving problems and improving the overall performance of the manufacturing processes. \u2022 Evolve: The final step involves analyzing the outcomes and feedback generated from the previous steps. The platform uses this information to continuously improve the Diagnose and Compose steps. It also provides personalized staff training recommendations to further enhance the adoption and utilization of AI technologies within the SME. The underlying concepts of the KITT4SME platform revolve around understand-ing the specific needs of SMEs, recommending tailored AI solutions, establishing seamless connections between the shop floor and the cloud platform, providing real-time analyses and KPI visualization, offering intervention recommendations, and continuously improving the overall workflow based on feedback and outcomes. By following this five-step workflow, the KITT4SME platform aims to empower SMEs in the manufacturing domain to harness the potential of AI technologies, enhance their operational efficiency, and drive growth and innovation in their businesses. This section reports on the basic concepts underlying the platform and explains its main functionalities. 3.1 High-Level Concept and Architecture The KITT4SME architecture is designed to address the challenges associated with deploying and utilizing AI models developed by data scientists or AI developers in SMEs. One of the key challenges is the discrepancy between the pace of AI modelArchitecture of a Software Platform for Affordable AI in Manufacturing 93Fig. 1 KITT4SME platform three-tier architecture development and the capabilities of SMEs\u2019 IT systems. This often leads to situations where models are not deployed or where the deployment and update process is time-consuming. To tackle these challenges, KITT4SME proposes a conceptual pipeline consist-ing of six steps, which cover the process from data preparation to the practical use of the model. The steps (presented in Fig. 1) are as follows: 1. Prepare data: This step involves collecting and preparing the data required for training the AI model. It includes tasks such as data cleaning, transformation, and feature engineering to ensure the data are suitable for model development. 2. Develop the model: In this step, AI researchers and developers focus on building and training the AI model using the prepared data. This is where the core value of the AI solution is generated. 3. Package the model: Once the model is developed, it needs to be packaged in a way that it can be easily deployed and integrated into the existing systems of the SME. Packaging involves encapsulating the model and its associated dependencies into a deployable form. 4. Validate the model: Before deployment, it is crucial to validate the model to ensure its accuracy, reliability, and suitability for the intended use. Validation may involve testing the model\u2019s performance on a separate dataset or using techniques like cross-validation.94 V. Cutrona et al.5. Deploy the model: This step focuses on deploying the validated model into the SME\u2019s IT infrastructure. It involves integrating the model with the existing systems, ensuring compatibility, and addressing any technical requirements or constraints. 6. Use the model: The final step is when the SME can actively utilize the deployed model in its operations. This includes making predictions, generating insights, and incorporating the model\u2019s outputs into decision-making processes. The three intermediate steps, namely packaging, validating, and deploying the model, are often complex and time-consuming. KITT4SME aims to simplify and automate these steps, reducing the overall time and effort required to deploy and update the AI model. By streamlining these processes, the platform enhances the repeatability and efficiency of the entire pipeline, making it easier for SMEs to  leverage AI technologies effectively. The software platform implementing the KITT4SME workflow is based on a service mesh, multi-tenant cloud architecture. It provides a means to assemble various AI components from a marketplace and facilitates their connection to the shop floor while ensuring interoperability, security, and privacy-preserving data exchange. The platform consists of loosely coupled web services running in a cluster environment and relies on a dedicated cluster software infrastructure. Several key concepts and guiding principles underpin the architecture of the KITT4SME platform: \u2022 Leveraging state-of-the-art technology and standards: The platform utilizes a dedicated cluster software infrastructure, referred to as mesh infrastructure. This infrastructure is built on industry-standard technologies such as Kuber-netes8 and Istio9 . The platform reuses open communication and data standards as much as possible to foster service interoperability (e.g., REST principles for services interaction and NGSI standard for data exchange). \u2022 Platform services: The platform comprises two types of services: application services, which are integral to the KITT4SME workflow and provide the func-tionality required for the platform\u2019s core activities, and infrastructure services, which consist of a network of intermediaries within the mesh infrastructure. These intermediaries handle essential operational aspects such as routing, security, and monitoring. By separating these concerns, AI developers can focus on implementing service-specific features while relying on the platform for operational support. \u2022 Multi-tenancy: The platform is designed to support multiple SMEs sharing the same instance. Each company is associated with a security protection domain, referred to as a tenant, which isolates its data and users from other tenants. The platform also allows for explicit sharing policies that enable companies to selectively share data and resources if desired.8 https://kubernetes.io/. 9 https://istio.io/. Architecture of a Software Platform for Affordable AI in Manufacturing 95\u2022 Containerized deployment and orchestration: The platform adopts a container-based virtualization approach for service deployment and orchestration. Ser-vices are packaged and executed within containers, enabling independent development using appropriate technology stacks. This containerization allows for the decoupling of services and facilitates their independent deployment, potentially through automated release processes such as Continuous Integration (CI) and Continuous Delivery (CD). By adhering to these principles and utilizing modern technologies, the KITT4SME platform ensures efficient and scalable execution of the AI workflow. It promotes service interoperability, simplifies deployment and management, and provides a secure and isolated environment for SMEs to leverage AI capabilities within their manufacturing processes. The KITT4SME high-level architecture provides the ecosystem enabling the streamlined AI packaging, validation, and deployment while also fostering and facilitating the composability and integration of AI solutions. As depicted in Fig. 1, the architecture is organized into a three-tier structure on top of the hardware layer. Each layer comes with a set of components dealing with certain operational functionalities, as follows: 1. Mesh Infrastructure Layer: This layer, depicted as \u201cmesh infra\u201d in Fig. 1, is responsible for managing computational resources, network proxies, and interconnection networks. It utilizes Kubernetes for containerized workloads and services, while Istio acts as a service mesh for traffic management, observability, and security. The tasks performed by the mesh infrastructure layer include: \u2022 Managing computational resources (e.g., CPU, memory, storage) and allocating them to processes in the upper layers, acting as the Cluster Orchestration Plane \u2022 Handling the network of proxies for transparent routing, load balancing, and securing communication, which represents the Control Plane \u2022 Managing proxies and interconnection networks for capturing and process-ing application traffic, serving as the Data Plane of the mesh infrastructure 2. Platform Services Infrastructure Layer: This layer, labeled as \u201cplat infra services\u201d in Fig. 1, comprises processes that support the operation of appli-cation services in the upper layer. It includes components such as IoT sensor connectors, context brokers, databases, and software for creating dashboards and visualizations. These components rely on well-known software and IoT middlewares like FIWARE [10]. Each component exposes interfaces for use by higher layers while utilizing the lower layer for interconnection. 3. Application Layer: This layer, represented as \u201capps\u201d in Fig. 1, hosts services and components that provide functionality to the manufacturing SME. Examples include anomaly detection, data augmentation components, and dashboards. The application layer focuses on application-specific concerns while leveraging96 V. Cutrona et al.the security, traceability, scalability, integration, and communication mecha-nisms provided by the lower layers. Additionally, the KITT4SME platform benefits from its connection to an applica-tion marketplace. This marketplace, facilitated by discovery solutions like adaptive questionnaires, enables the identification of new applications and components, supporting the Compose activity in the KITT4SME workflow. A detailed description of the components and their functionality in each layer is provided in Sect. 3.2. 3.2 Functionalities and Component Description Pursuing the idea of an open-source platform for the uptake of AI solutions in manufacturing SME, KITT4SME has chosen FIWARE10 as the underlying open-source platform for its AI solutions in manufacturing SMEs. FIWARE is renowned as a top-quality open-source platform for IoT [10]. By leveraging FIWARE, the KITT4SME platform, branded as \u201cPowered by FIWARE,\u201d inherits a range of capabilities that are beneficial for managing context information and data in the manufacturing domain. These capabilities include: \u2022 Handling and managing context information: The KITT4SME platform can efficiently handle and manage context information from diverse data sources. This allows for the collection and aggregation of data from various sensors, machines, and other sources in the manufacturing environment. \u2022 Distributing and streaming data: The platform is equipped with mechanisms for distributing and streaming data to external components. This enables the seamless transfer of data to external systems for various purposes, such as persistence or AI-based processing. \u2022 Integration with AI-based processing: The KITT4SME platform can integrate with AI-based processing components, leveraging the capabilities of FIWARE. This integration facilitates the application of AI algorithms and techniques to analyze and derive insights from manufacturing data. The results obtained from AI processing can be seamlessly integrated back into the platform, enriching the current context and enabling data-driven decision-making. Overall, by utilizing FIWARE as the foundation, the KITT4SME platform gains powerful tools and features that are instrumental in the management of IoT data and seamless integration of AI-based processing capabilities. Figure 2 depicts the logical architecture of the platform, illustrating the hierarchical layout in which intelligent services and AI applications are placed on top of the FIWARE ecosystem. In the subsequent discussion, we present a comprehensive overview of the platform\u2019s functionalities, accentuating the advantages derived from harnessing FIWARE as the bedrock of its technological infrastructure.10 https://www.fiware.org/. Architecture of a Software Platform for Affordable AI in Manufacturing 97Fig. 2 Powered by FIWARE KITT4SME architecture. Components represented as blue boxes are from the FIWARE reference architecture [10, 11] Data Gathering The data gathering aspect of the KITT4SME architecture encom-passes the collection of data from diverse devices, situated at the lowest layer of the architecture (as depicted in Fig. 2). These devices, deployed within the factory, serve to enrich the system\u2019s knowledge base with both raw and preprocessed data. The following categories of devices contribute to the data gathering process: \u2022 Wearable Sensors: These sensors are specifically designed to monitor the health and well-being of workers within the factory setting. They provide valuable insights into various physiological parameters and indicators. \u2022 Environmental Sensors: Scattered throughout the factory, environmental sensors play a vital role in monitoring and capturing data related to the prevailing environmental conditions. This includes parameters such as air pollution levels, temperature, and humidity. \u2022 CPSs: The architecture also incorporates CPSs, with a particular emphasis on those commonly involved in the manufacturing processes, such as machining equipment and collaborative robots. These CPSs facilitate the capture of relevant data pertaining to the operational aspects of the production line. \u2022 Information Systems: Information systems represent a valuable source of raw and value-added data, which contribute to update the contextual information of the platform also with aggregated data. \u2022 Cameras and IoT sensors: Together with environmental sensors, cameras and IoT sensors are needed to monitor the production, usually requiring a real-time processing to extract valuable knowledge from data streams. Communication Interfaces In the subsequent layer, the FIWARE framework encompasses a collection of Generic Enablers (GEs) that serve as interfaces between devices, enabling the retrieval of contextual information and the initiation of98 V. Cutrona et al.actuations in response to context updates. Examples of FIWARE GEs available in the catalog11 include: \u2022 Connectors and IoT agents: These modules facilitate the interaction with devices utilizing widely adopted IoT protocols, including LWM2M over CoaP, OneM2M, and OPC-UA. It provides a standardized approach to interface and communicate with diverse IoT devices. Also, connector supporting FAST Real-Time Publish\u2013Subscribe (RTPS) for efficient and real-time processing of data streams is provided, based on the ROS 2 [12] framework.  \u2022 Real-Time Media Processing: These GEs are designed to support real-time processing and manipulation of media streams (e.g., to transform video cameras into sensor-like devices) to extract valuable information from visual data streams. Data Broker In the layer above, the FIWARE Orion Context Broker represents the fundamental component of any solution powered by FIWARE. This context broker facilitates the decentralized and scalable management of context information, allowing data to be accessed through a RESTful API. Serving as the authoritative source of information, the Context Broker stores the latest update status of all devices, components, and processes that contribute data to the platform. However, for the purpose of training and fine-tuning AI tools, it is often necessary to access historical data. To address this requirement, FIWARE offers dedicated GEs called QuantumLeap that automatically generate time series data from the evolving context information, enabling AI tools to leverage the valuable insights gained from historical data analysis. Smart Industry Management Services The topmost layer of the architecture encompasses analytical services and profilers that leverage the knowledge base within the system. These services include Big Data applications and components utilizing AI-based detection and optimization tools. It is in this layer that AI developers and researchers can greatly benefit from the historical data and up-to-date context information made available by the Powered by FIWARE platform. Additionally, the KITT4SME architecture incorporates utility components in this layer to extract additional knowledge from persistent information and provide insights to human actors regarding the factory\u2019s status. These components include: \u2022 Human Description Database, which stores a comprehensive representation of factory workers derived from physiological parameters, worker information, machine parameters, and environmental data \u2022 External IDS Connector, a component from the IDSA reference architecture12 that ensures a trustworthy interface between internal data sources and external data consumers. This connector plays a critical role in enabling the integration11 https://www.fiware.org/catalogue/. 12 https://docs.internationaldataspaces.org/ids-ram-4/. Architecture of a Software Platform for Affordable AI in Manufacturing 99of external value-added services, where data exchange is governed by IDS policies The outputs of analytical models, such as anomaly detection, can be fed back into the FIWARE Context Broker. This triggers decision-making mechanisms, whose logic can be modeled and managed during execution by decision support systems, such as the Manufacturing Process Management System (MPMS). The activation processes of the platform can involve human-in-the-loop interactions, such as collective intelligence, or rely on behavioral updates for groups of involved CPSs. The decisions thus triggered must be identified by IDAS IoT Agents through the FIWARE Context Broker to effectively enable feedback to the CPSs. Marketplace and Identity Management and Access Control To facilitate the widespread adoption of AI applications and enhance their discoverability, the KITT4SME platform leverages an existing marketplace called Robotics and Automation MarketPlace (RAMP). RAMP enables the Software as a Service (SaaS) provision of these applications, making them easily accessible to users. By incorporating FIWARE-compatible equipment (e.g., robots, machines, sensors) on the production floor, businesses can directly utilize the various tools offered by KITT4SME without the need for complex software deployments and extensive IT expertise. This allows manufacturing SMEs to focus on their core business activities and adds value to their operations. Furthermore, the distributed nature of the architecture promotes collaborative usage of tools and production data between manufacturing SMEs and technology providers. It facilitates online co-creation and minimizes the necessity for contin-uous on-site inspections and system installations. Access to platform resources is facilitated by an IDentity Management and Access Control (IDM) GE. This  IDM GE provides robust support for secure and private OAuth2-based authentication of users and devices. It also offers features such as user profile management, privacy-preserving handling of personal data, Single Sign-On (SSO), and Identity Federation across multiple administrative domains. These capabilities ensure secure access to the platform\u2019s resources while maintaining user privacy and data protection. 4 KITT4SME to Bring AI to an Injection Molding Use Case The KITT4SME platform has been applied in 4 use cases within the KITT4SME project and 18 external demonstrators made via Open Calls.13 In this section, we discuss how the KITT4SME platform has been exploited to create an AI kit supporting one of the internal use cases. This use case is from the injection molding industry, and it aims at facilitating an assembly task mainly composed of screwdriving operations. The assembly task starts with a molding13 https://kitt4sme.eu/open-call/. 100 V. Cutrona et al.Fig. 3 The KITT4SME solution for the use case in the injection molding sector press producing a molded piece every 90 seconds. Then, the task foresees a gantry robot that automatically extracts the molded piece from the injection molding machine and places it onto a conveyor belt. Subsequently, a human operator works at a designated workstation to perform the assembly operations while also being responsible for periodic quality checks on the molded pieces or quick maintenance operations on the injection molding machine. The KITT4SME platform has introduced an AI solution to mitigate workers\u2019 physical stress caused by heavy workloads and the injection molding machine\u2019s demanding pace during operations. In particular, the use case relies on the concept of human digital twin [13]. A dynamic task assignment between the collaborative robot and the operator is performed by creating a digital representation of the operator and the production system. The Kit used for this use case, represented with its whole architecture in Fig. 3, includes: \u2022 Sensing Layer: This module supports the collection and use of IoT sensor data to be used by data analysis and decision-making modules to take decisions or to be visualized on dashboards. It provides a solution including the interoperability elements (APIs and broker client) for bidirectional data exchange between sensors and the KITT4SME\u2019s Orion Context Broker. Data are also preprocessed if needed. \u2022 Fatigue Monitoring System: It is an  AI model that estimates the perceived fatigue of the workers based on physiological data (e.g., heart rate) from wearable devices and on quasi-static characteristics (e.g., age). The estimation is made using physiological data collected from wearable devices selected by applying an Analytic Hierarchy Process (AHP)-based methodology [14] and operator\u2019s characteristics, including age, sex, handedness, exercise/healthy habits, and routines, collected via interviews. \u2022 Intervention Manager: It monitors the real-time status of the worker\u2013factory ecosystem, elaborating data from sensors, machines, workers monitoring sys-Architecture of a Software Platform for Affordable AI in Manufacturing 101tems, and ERP, and it knows what interventions can be applied and which are the rules to decide which is the best one given a particular situation. It applies AI models specifically developed to support decision-making. The kit has been deployed to the platform to support the task assignment in a screwdriving process in the following process: 1. The operator retrieves two molded parts from a conveyor belt and positions them on the working bench. 2. The operator inserts six nuts into each part, flips one part, and places it on top of the other. 3. The operator positions nine screws on one side of the assembled parts. 4. The Intervention Manager assigns each screw to the operator or the cobot. The operator and a cobot simultaneously perform the screwdriving process. Depending on the number of screws assigned to the operator, they may also engage in other support activities, such as monitoring other machines, conducting short maintenance operations, or removing the pallet. 5. The operator flips the assembled parts and repeats steps 3 and 4. 6. The assembled parts are stacked on a pallet. The task assignment, performed by the Intervention Manager and confirmed by the operator, consists of the allocation of the screwing operations (9x2 for each assembled part), and it is made considering the following parameters: \u2022 Current perceived fatigue of the operator as estimated by the FatigueMonitoring System. \u2022 Work In Progress level. \u2022 Cobot state (idle, current operation, and error). Discussion The above use case exemplifies how the KITT4SME platform can actu-ally ease AI adoption by SMEs, compared to other platforms in the AI ecosystems. Indeed, compared to platforms to develop AI solutions, the SME from the use case did not spend any effort on developing AI, given that they exploited the existing application available on the platform. Also, the platform helped the company compose the best kit to solve a real need, i.e., to facilitate an assembly task mainly composed of screwdriving operations. The proposed kit already included all the components needed to be implemented in the factory, i.e., data acquisition (Sensing Layer), AI solution to derive data-driven knowledge (Fatigue Monitoring System), and a reasoning engine (Intervention Manager), relieving the company from extra development activities needed to connect the shop floor to the platform. Instead, by considering platforms providing already developed applications, a similar use case has been successfully tested in a laboratory environment [15], exploiting a different IIoT platform [16]. This kind of platform enables the handling of third-party applications, with no guarantees about the interoperability of components in terms of application interfaces and data models, which are covered within the KITT4SME platform by the FIWARE components. Also, while this kind of platform comes with a ready-to-use solution, integrating and deploying such solutions is often a burden solely on the developers. Again, the KITT4SME platform offers a102 V. Cutrona et al.distinct advantage since it effortlessly facilitated the integration and deployment of three distinct modules, two of which leverage AI, resulting in a smooth and reliable operation. 5 Conclusion In this chapter, we discussed the potential of AI solutions in increasing the profitability of SMEs (e.g., by improving product quality or optimizing production line configurations), and we presented a new platform, namely the KITT4SME platform, intended to deliver affordable, tailor-made AI kits to the manufacturing industry. The cloud platform presented in this chapter supports the KITT4SME workflow by relying on widely adopted platforms, e.g., FIWARE, in such a way to ease the development of new AI services, as well as their deployment in real industrial settings. Specifically, the platform is capable of composing AI components from a marketplace (i.e., the RAMP marketplace) into a tailor-made service offering for a factory, a functionality that is not provided by any of the existing AI platforms. Once the factory shop floor is connected to the AI services, the platform enables data storage and exchange in an interoperable, secure, privacy-preserving, and scalable way. The architecture has been designed by leveraging state-of-the-art technology and standards, reusing open-source software and technologies whenever possible, thus promoting both its adoption by small manufacturing companies on a budget and further extensions by other researchers and practitioners in the reference community. The exploitation of the platform has been demonstrated with real-world use cases, which have been conducted as part of the KITT4SME project thanks to a platform prototype publicly available in the KITT4SME online repository.14 Future work will be focused on further increasing the interoperability of platform services, also relying on semantic data interoperability, to better define the com-posability of different AI components, possibly available in different marketplaces, enabling cross-platform service composition. Acknowledgments This work has been partly supported by EU H2020 research and innovation program project KITT4SME (grant no. 952119). References 1. Wu, S.-Y.: Key technology enablers of innovations in the ai and 5g era. In: 2019 IEEE International Electron Devices Meeting (IEDM), pp. 36\u20133. IEEE (2019) 2. Alexopoulos, K., Nikolakis, N., Chryssolouris, G.: Digital twin-driven supervised machine learning for the development of artificial intelligence applications in manufacturing. Int. J. Comput. Integr. Manuf. 33(5), 429\u2013439 (2020)14 https://github.com/c0c0n3/kitt4sme. Architecture of a Software Platform for Affordable AI in Manufacturing 1033. Elger, P., Shanaghy, E.: AI as a Service: Serverless Machine Learning with AWS. Manning Publications (2020) 4. Bettoni, A., Matteri, D., Montini, E., Gladysz, B., Carpanzano, E.: An ai adoption model for SMEs: a conceptual framework. IFAC-PapersOnLine 54(1), 702\u2013708 (2021). 17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021 5. IBM: What is platform-as-a-service (PaaS)? https://www.ibm.com/topics/paas (2021). Accessed 08 Aug 2023 6. Lins, S., Pandl, K.D., Teigeler, H., Thiebes, S., Bayer, C., Sunyaev, A.: Artificial intelligence as a service. Bus. Inf. Syst. Eng. 63(4), 441\u2013456 (2021) 7. Zhao, S., Talasila, M., Jacobson, G., Borcea, C., Aftab, S.A., Murray, J.F.: Packaging and sharing machine learning models via the Acumos AI open platform. In: 2018 17th IEEE International Conference onMachine Learning and Applications (ICMLA), pp. 841\u2013846. IEEE (2018) 8. Llewellynn, T., Fern\u00e1ndez-Carrobles, M.M., Deniz, O., Fricker, S., Storkey, A., Pazos, N., Velikic, G., Leufgen, K., Dahyot, R., Koller, S., et al.: Bonseyes: platform for open development of systems of artificial intelligence. In: Proceedings of the Computing Frontiers Conference, pp. 299\u2013304, 2017 9. Prado, M.D., Su, J., Saeed, R., Keller, L., Vallez, N., Anderson, A., Gregg, D., Benini, L., Llewellynn, T., Ouerhani, N., et al.: Bonseyes ai pipeline\u2014bringing ai to you: End-to-end integration of data, algorithms, and deployment tools. ACM Trans. Internet Things 1(4), 1\u201325 (2020) 10. Ahle, U., Hierro, J.J.: Fiware for data spaces. In: Otto, B., ten Hompel, M., Wrobel, S. (eds.), Designing Data Spaces: The Ecosystem Approach to Competitive Advantage, pp. 395\u2013417. Springer International Publishing (2022) 11. Fiware Smart Industry Reference Architecture: https://www.fiware.org/about-us/smart-industry/ (2022). Access 08 Aug 2023 12. Macenski, S., Foote, T., Gerkey, B., Lalancette, C., Woodall, W.: Robot operating system 2: Design, architecture, and uses in the wild. Sci. Robot. 7(66), eabm6074 (2022) 13. Montini, E., Bettoni, A., Ciavotta, M., Carpanzano, E., Pedrazzoli, P.: A meta-model for modular composition of tailored human digital twins in production. Procedia CIRP 104, 689\u2013 695 (2021) 14. Montini, E., Cutrona, V., Gladysz, B., Dell\u2019Oca, S., Landolfi, G., Bettoni, A.: A methodology to select wearable devices for industry 5.0 applications. In: 2022 IEEE 27th International Conference on Emerging Technologies and Factory Automation (ETFA), pp. 1\u20134. IEEE (2022) 15. Montini, E., Cutrona, V., Dell\u2019Oca, S., Landolfi, G., Bettoni, A., Rocco, P., Carpan-zano, E.: A framework for human-aware collaborative robotics systems development. Procedia CIRP 120, 1083\u20131088 (2023). 56th CIRP Conference on Manufacturing Systems 2023. https://doi.org/10.1016/j.procir.2023.09.129. https://www.sciencedirect.com/ science/article/pii/S2212827123008612 16. Montini, E., Cutrona, V., Bonomi, N., Landolfi, G., Bettoni, A., Rocco, P., Carpanzano, E.: An IIoT platform for human-aware factory digital twins. Procedia CIRP 107, 661\u2013667 (2022) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Multisided Business Model for Platform Offering AI Services Krzysztof Ejsmont , Bartlomiej Gladysz , Natalia Roczon, Andrea Bettoni , Zeki Mert Barut, Rodolfo Haber , and Elena Minisci 1 Introduction Platform businesses have become one of the latest research topics in various management disciplines [10]. A platform is an interface that facilitates interac-tions between different parties, usually complementors and customers [9]. In the platform business, the platforms and their complementors have a strong one-way complementarity, where the total value of the platform and its complementors is more than the sum of the two combined [18], and this complementarity requires the interdependencies between the platforms and the complementarities to be managed in an ecosystem level. There are two basic types of platforms: innovation platforms (as an intermediary for direct exchange or transactions) and transaction platforms (as a technological foundation upon which other firms develop complementary innovations). Some K. Ejsmont (\u0002) \u00b7 B. Gladysz \u00b7 N. Roczon Faculty of Mechanical and Industrial Engineering, Warsaw University of Technology, Warsaw, Poland e-mail: krzysztof.ejsmont@pw.edu.pl; bartlomiej.gladysz@pw.edu.pl A. Bettoni \u00b7 Z. M. Barut Department of Innovative Technologies, University of Applied Science of Southern Switzerland, Manno, Switzerland e-mail: andrea.bettoni@supsi.ch; zekimert.barut@supsi.ch R. Haber Centre for Automation and Robotics (CAR), Spanish National Research Council-Technical University of Madrid (CSIC-UPM), Madrid, Spain e-mail: rodolfo.haber@car.upm-csic.es E. Minisci CRIT S.R.L., Vignola, Italy e-mail: minisci.e@crit-research.it \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_7105106 K. Ejsmont et al.companies combine the features of the two and create \u201chybrid platforms\u201d [13]. Mul-tisided platforms (MSPs) allow direct interactions between two or more different entities, where each entity is associated with the platform [17]. Examples of well-known MSPs include Facebook, Uber, PayPal, Airbnb, Alibaba, eBay. The growing interest in MSPs is due to two key factors: their essential role in minimizing the transaction costs between sides [15] and the power of the business models (BM) in the digital economy because of their ability to adapt and cope with complexity, rapid scaling, and value capture [1]. Although many companies are opting for MSP BMs, only a few have been successful. MSPs should strive to attract users and must achieve direct and indirect network effects to be successful. More importantly, they ought to solve the chicken-or-egg problem, which refers to a network effect meaning \u201cone side of the market realizes the value only if another side is fully engaged\u201d [13]. 2 Methodologies for MSPs Business Modeling The pioneering models of MSPs were introduced by Armstrong, Valillaud and Jullien, Parker and Van Alstyne, Rochet and Tirol, as described in more detail in Hagiu and Wright [17]. Allweins et al. [2] proposed a Business Model Canvas [21] to illustrate the MSP businesses. As a result, the cited paper proposed Platform Canvas. The focus of this study was not on the definition of individual entities (having different value propositions) but on the modeling of MSPs\u2019 business transactions. For this purpose, only methodologies dedicated to MSPs\u2019 business models were considered. The Business Model Kit is proposed by the Board of Innovation.1 It consists of 16 blocks filled with details on various stakeholders and value propositions, resulting in a marketing tool for communicating the BM to different entities. Leanstack2 offers a Lean Canvas, adjusted from the Business Model Canvas, with procedures to complete the nine blocks starting with problem definition, modeling customer segments, and finally, the derived unique value proposition. Lean Canvas introduces a phase of finding the solution, identifying channels to reach customer segments, estimating revenue and cost structure, and defining crucial metrics and unfair advantages. Most papers develop analytical models focusing on a specific characteristic of the MSPs business model, such as pricing structure, network externalities, or competition (i.e., [3, 6, 14, 16]), while a holistic approach to building a business model for MSPs is lacking. Therefore, a methodology that seems to meet the expectations of MSPs in the context of business model development is the Platform Design Toolkit (PDT). This methodology is the first codified platform design method, released in 2013.3 The PDT was developed by a team led by S. Cicero1 https://www.boardofinnovation.com/tools/business-model-kit/ 2 https://leanstack.com/lean-canvas 3 https://www.boundaryless.io/pdt-toolkit/ Multisided Business Model for Platform Offering AI Services 107to provide companies with support in describing the platform\u2019s vision, the core and ancillary value propositions, the platform\u2019s infrastructure and core components, and the characteristics of the platform ecosystem expressed through transaction dynamics [5, 11]. It was optimized to support the development of multisided, transformative platform strategies to empower ecosystems to create shared value. It is an open-source method adopted worldwide by global Fortune 500 leaders, leading institutions, start-ups, and scale-ups. The PDT covers all stages, from exploration to design, validation, and growth. The core of the PDT methodology in developing a business model is the design stage: an extensive and proven step-by-step process that helps move from contextualizing entities in the ecosystem, their role and relationships, detailing possible transactions between entities, to designing the platform experience. PDT, in the design stage, contains eight templates (canvases) to be completed, considering as many aspects of the business. The steps are as follows: 1. Mapping the ecosystem: entities present in the ecosystem are mapped onto the canvas, allowing us to understand the role they may play and identify possible clusters. 2. Portraying ecosystem\u2019s entities roles: a coherent and deep picture of the role of each of the entities identified in step 1 is created by defining what their context is, what they want to achieve, with whom and how they want to integrate, what potential they can represent and what kind of experience gains they are looking for, and what the platform shaper can provide them with. 3. Analyzing the potential to exchange value: using the so-called \u201cecosystem\u2019s motivation matrix,\u201d entities\u2019 potential to exchange value flows is analyzed. This is a mapping of what type of value exchange is already being performed (or attempted to be performed) by the entities and what additional value they could exchange if adequately enabled. 4. Choosing the core relationships you want to focus on: the platform shaper needs to identify which entities in the ecosystem they want to focus on and which relationships will form the core of the platform design. 5. Identifying the elementary transactions: the \u201ctransaction board\u201d tool is used to map how the ecosystem currently exchanges value (focusing on the entities and relationships prioritized in step 4) and how the platform\u2019s strategy is to help them make value transactions more manageable, faster, and cheaper by providing and curating channels and contexts that increase the likelihood of interactions and transactions. 6. Designing the learning engine: through the \u201clearning engine canvas,\u201d a step-by-step process has been designed to support/enable services that will support entities to adopt the platform strategy. These services will not only help them evolve and become better producers and consumers but also radically evolve and discover new opportunities and behaviors that were not initially intended. 7. Assembling the platform experiences: with the \u201cplatform experience canvas,\u201d the elements emerged from the transaction board (step 5) and those from the learning engine canvas (step 6) are combined to create an experience persistence108 K. Ejsmont et al.model that summarizes the key value propositions arising from the strategy being developed. This allows consideration of what resources and components need to be put in place and managed to deliver these experiences and derive value from them. 8. Setting up the minimum viable platform (MVP): this allows us to test in the natural environment (market) whether the design assumptions are suitable for the future. By analyzing design products, in particular the compiled \u201cplatform experience canvases\u201d (step 7), the riskiest assumptions of the strategy are iso-lated, as well as experiments and indicators to validate them with the ecosystem are identified. The resulting business model is then summarized in the platform design canvas, which is the final output of this reference methodology. According to the author\u2019s knowledge and experience, by far, the most essential element of business models for MSPs is to identify the value that can be transferred to the different entities through the platform [12]. Taking this into account, it was decided to focus on the first five steps of the PDT methodology. 3 Application of PDT for the Design of AI Platform as a Service Business Model \u2013 KITT4SME Case Study 3.1 Introduction to the KITT4SME Project KITT4SME (platform-enabled KITs of arTificial intelligence FOR an easy uptake by SMEs) is a Horizon 2020 project (GA 952119). It is explicitly aimed at European SMEs and mid-caps to provide them with scope-tailored and industry-ready hardware, software, and organizational bundles, delivered as modularly customizable digital platform that seamlessly introduce AI into their production systems.4 Among the main objectives of the KITT4SME project that need to be included in the business model are [20]: \u2022 to provide SMEs with ready-to-use, customized digital packages to harness the capabilities of AI at an affordable price and a proper scale, \u2022 seamlessly combine AI and human problem-solving expertise (know-how) into a single digital platform with unparalleled shop floor orchestration capabilities, and \u2022 expanding the local ecosystem offerings so that entities with different competen-cies can grow by collaborating on customizable AI kits.4 https://kitt4sme.eu/ Multisided Business Model for Platform Offering AI Services 1093.2 Needs Elicitation The process of creating a BM for AI platform as a service was initiated by identifying the main stakeholders (manufacturing SMEs, AI developers, DIHs) and their needs. The needs elicitation process was conducted by adhering to iterative stakeholder engagement based on interviews and workshops, as proposed by Azade-gan et al. [4] and confirmed by Bettoni et al. [8]. To identify needs/expectations, 29 interviews were conducted with samples of different types of stakeholders. AI developers (13 respondents) and SMEs (10 respondents) are the most represented entities [7], as they will be the primary and direct users of the KITT4SME platform (supply and demand side). Entities of different sizes, from different EU countries, and with different scopes of activity (from national to global) were involved (for more details about this analysis, see [19]). The following needs were identified: \u2022 modularity of solutions, \u2022 the possibility of integrating implemented AI solutions with already existing ones, \u2022 increased data transparency and traceability, \u2022 identification of hidden problems to improve processes, \u2022 defining solutions to the identified problems, \u2022 personalizing the platform, allowing to tailor solutions to individual needs, \u2022 matching potential partners, \u2022 access to multilevel knowledge transfer, \u2022 simplified AI implementation algorithms, \u2022 generalization of implementation middleware, \u2022 integration of modules to facilitate deployments, \u2022 ability to integrate with low-digitized infrastructure, \u2022 introduction of preventive maintenance, \u2022 improved analytics and a better understanding of customer behavior and purchase decisions, and \u2022 personalization of actions in real-time. 3.3 KITT4SME Business Model The first step in developing the KITT4SME platform BM consisted of identifying the crucial entities that will form the platform ecosystem and have a significant impact (direct or indirect) on the functioning of the platform. These entities have been mapped into a unique canvas, as shown in Fig. 1. The idea behind the canvas is to divide the entities in the ecosystem into three main groups: impact entities (platform owners, external stakeholders) \u2013 they are not involved in the continuous interactions happening in the ecosystem; demand entities (peer consumers) \u2013 they are interested in \u201cconsuming\u201d the value produced110 K. Ejsmont et al.Fig. 1 KITT4SME ecosystem canvas (step 1) + core relationships (step 4) in the ecosystem; supply entities (partners, peer producers) \u2013 they are interested in \u201cproducing\u201d the value consumed in the ecosystem. Considering a single entity, its position in this framework may vary. For example, an AI developer (peer producer) may become a partner after a certain period of time if it provides many AI solutions and takes an active part in the development of the platform. An entity may also have a dual role, as access to the platform may create new opportunities: a company initially interested in offering its products (peer producer) may later be interested in using its belonging to the ecosystem to seek ideas for improving manufacturing processes in SMEs (peer consumer). In the second step, the aim is to develop a portrait of the leading entities accessing the platform from both the demand and supply sides. It should be noted that this second step aims to map what the entities are currently looking for rather than what the idea behind the platform service is. Thus, it is possibly better to characterize the value from their point of view. In the KITT4SME ecosystem, six different entities have been identified (Fig. 1). Figure 2 shows a portrait of AI developers, as they appear to be the most important in the initial lifecycle of the platform \u2013 they will be responsible for delivering AI solutions/services that can be transacted. Similarly, portraits should be taken for all other identified entities. The ecosystem motivation matrix (step 3) maps the values exchanged between pairs of entities through the KITT4SME platform. Money is undoubtedly exchanged as a consequence of interactions through the platform, but even more important for shaping the KITT4SME BM is the identification of intangible values resulting from the opportunities the platform brings. The matrix shown in Fig. 3 details the centralMultisided Business Model for Platform Offering AI Services 111Fig. 2 Portrait of the entity \u201cAI developers\u201d (step 2) Fig. 3 KITT4SME ecosystem motivation matrix (step 3) values exchanged between peer consumers (PC), peer producers (PP), and partners (Pa) \u2013 previously mapped in the ecosystem canvas (Fig. 1). The cells report what the entity in the first column from the left can \u201cgive to\u201d the entities on the upper axis. The goal of the fourth step is to decide which subset of relationships to focus on to ensure that enough attention is paid to defining and implementing the core112 K. Ejsmont et al.experience. The value flows identified in the ecosystem motivation matrix (Fig. 3) were transferred to the ecosystem map (Fig. 1). Figure 1 shows the division of relationships into those relating to resource sharing (brown lines) and those supporting AI solution implementation (blue lines). In the first case, entities contact each other to share resources. Manufacturing SMEs in this context seek dedicated AI solutions to develop and improve their production capabilities. The remaining entities, i.e., AI developers, cloud providers and platform components providers, are identified as suppliers and partners, offering their knowledge, expertise, and AI solutions through the platform. Supporting AI solution implementation is a relationship that involves entities seeking to collaborate on creating and improving AI solutions. The identification of the underlying transactions and channels serves to illustrate how the ecosystem exchanges value (step 5) and highlights the role of the KITT4SME platform as an intermediary in this process. Most of the interactions take place through the platform itself, which creates value from the exchange of information, while the three interactions involving the exchange of software (AI solution/module), AI service (e.g., support to solving problems using AI, implementation AI solution, consultation), and payment are realized outside the platform. The transaction matrix helps analyze the relationship between the demand side (entity 1) and supply side (entity 2). It helps identify all transactions/interactions and their channels that are already taking place or may take place. In addition, for each transaction/interaction is assigned what is the unit of value. One of the key roles of the platform (owner) is to create channels that can reduce coordination/transaction costs. The transaction matrix (Table 1) confirms that the KITT4SME platform is the main channel of interaction and, to be successful during each interaction, the exchange of information must add value for the stakeholders. A crucial role of the platform is to participate in the facilitation of the communication process actively and the interaction between stakeholders, thereby reducing transaction costs and facilitating transactions. 3.4 Business Model Design Canvas The analyses conducted in the previous chapters were finally aggregated into the platform design canvas and structured as follows: \u2022 Enabling services (platform to partners): focused on helping partners gener-ate/create value from their assets and capabilities, access to potential consumers, increasing competitiveness and visibility, and decisively improving as profes-sional entities (reputation). For KITT4SME, these are designed services to facilitate the implementation of technical specifications and core service stan-Multisided Business Model for Platform Offering AI Services 113Table 1 KITT4SME transaction board for core relationships Entity 1Transaction/ interactionEntity 2 Currency/value unitChannel or context Mfg. SMEs Request for support to solve a problem/implement a solution High level of request Request or complete NDA Sending enquiry Communication/interaction Sending offer Reply to the offer AI developers Cloud providers Platform components providers Multipliers Know-how providers InformationKITT4SME platform Mfg. SMEs Development/tailored of an AI solution Problem-solving/implementation of AI solution AI developers Cloud providers Platform components providers Know-how providers AI solution AI module AI service Companies developing AI solutions Software houses Companies implementing AI solutions AI consulting firms Mfg. SMEs Testing/validation of the AI solutionAI developers Cloud providers Platform components providers InformationKITT4SME platform Mfg. SMEs Corrections/elimination of errorsAI developers Cloud providers Platform components providers AI solution AI module Companies developing AI solutions Software houses Mfg. SMEs Reply to the AI solution Replytothe problem-solving/implementation of the AI solution AI developers Cloud providers Platform components providers Know-how providers InformationKITT4SME platform Mfg. SMEs PaymentAI developers Cloud providers Platform components providers Know-how providers Information Money Independent channel Mfg. SMEs Feedback/reputationAI developers Cloud providers Platform components providers Multipliers Know-how providers InformationKITT4SME platform114 K. Ejsmont et al.dards for AI developers providing solutions for KITT4SME and disseminating KITT4SME in the AI field. \u2022 Empowering services (platform to peer producers): aimed at helping peer producers start executing transactions, improve their capabilities, improve on the platform, and enter the development stage (growth phase). The KITT4SME platform aims to support the development of EU-compliant applications, mod-ules and services for AI solutions through dedicated consulting, training, success stories, and best practices. \u2022 Other services (platform to peer consumers): there are many cases in which platforms provide more classical industrialized services to users. They are com-plementary to the value exchanged, experiences provided by the ecosystem, and they provide powerful, robust usability for the individual user. Like empowering services, support and training will also be provided for those consumers who intend to use other AI platforms or switch to solutions offered by other AI vendors. \u2022 Core value proposition: stands for the core value that the platform is trying to create for the main purpose of its operation. It usually targets consumers, as they usually represent the broadest market segment of peers and are the customers who buy products or services. Particularly, in dynamic market networks and in more niche contexts, where transaction value is higher and transaction volume is lower, partners or peer producers may be the basic recipients of the core value proposition. \u2022 Ancillary value propositions: these are ancillary values offered by the platform. Ancillary value propositions can be aimed at the same market segment as the core value proposition or at others. It is common for MSPs to supplement the core value proposition for the demand side of the platform (manufacturing SMEs) with a proposition aimed at the supply side (AI developers, know-how providers). KITT4SME provides an entire environment (infrastructure) that enables not only real interaction between entities in a multisided ecosystem but also the resources necessary to increase their visibility in the AI field. Ancillary value propositions for the KITT4SME platform could be SME issues assessment, modules combination and kit composition, kit deployment and maintenance, shop floor data acquisition, extraction, synthetization and reporting of data, generation of real-time interventions, workforce assessment and upskilling, best practices, and knowledge creation. Most of them can be assigned dedicated assistance, and these services can be the basis of the membership fee. Advertising services can also be considered as ancillary values. With the development of the platform, the growth of the number of users and increasing platform reach \u2013 it will be possible to provide advertising services to interested entities (e.g., advertising AI services), which may be the basis of advertiser fees. At the beginning of the platform\u2019s life, the platform will charge mostly transaction fees for the transfer of AI solutions and apply membership fees only for some services while the rest will be offered for free. In the future, when a critical mass of consumers is reached, the platform will charge mostly membership fees.Multisided Business Model for Platform Offering AI Services 115\u2022 Infrastructure and core components: these are assets owned and controlled by the platform owner. They are managed according to the platform\u2019s governance rules. Assets can be tangible (e.g., server or venue) or intangible (e.g., common standard \u2013 FIWARE). They guarantee the platform\u2019s operation and use by the ecosystem. KITT4SME identifies the critical elements of the platform\u2019s IT environment as the core components of the platform BM, namely the AI module standards, protocols, the standard enablers (CPS-izers, runtime), codes, and the functionalities and channels that enable its dissemination (such as RAMP). \u2022 Transactions: are part of a more complex \u201cexperience.\u201d They should be under-stood as a sub-activity during which value is created, delivered, exchanged, or transferred between typically two (or more) platform users. KITT4SME assumes two main types of transactions: the first is intangibles (information), which the platform completes by providing it through the systems typically used in such kinds of platforms; the second is monetary and related to AI services that are exchanged through the platform (AI solutions, applications, modules, services, runtime). \u2022 Channels and contexts: enable exchanges within the platform and are the platform\u2019s interface with users. Channels are user touch points that play an essential role in the user experience. They are crucial in creating added value: they should be actively created and continuously improved by the platform owner. The marketplace should be considered the principal channel provided by the KITT4SME ecosystem, where AI solutions, applications, modules, and services are purchased, exchanged, transferred, and downloaded, respectively. Channels for exchanging/obtaining information and processing payments are also important. 3.5 Revenue Model for the KITT4SME Platform After a literature analysis of MSPs\u2019 pricing strategies, a review of the monetization strategies of other platforms offering AI services, and an internal workshop of the partners involved in developing the KITT4SME revenue model, it seems possible for the platform to generate revenue through all three main streams [22]: \u2022 subscriptions (membership fee), \u2022 advertising (advertisers fee), and \u2022 transactions (transaction fee). For the KITT4SME platform, several revenue streams can be combined and different models can be adopted at different stages of the platform lifecycle. When designing a business model that assumes revenue from all three main streams, a fundamental issue to have in mind is the evolving network effects. These are generated from the interaction of user pairs and strongly influence the level of interest in the platform. Given the resource-sharing scenario of the platform, network effects are generated when the availability of more resource providers116 K. Ejsmont et al.(AI developers, know-how providers) attracts more entities seeking resources (manufacturing SMEs), which in turn causes more providers (peer producers) to join the platform. Finding the right balance at the outset is problematic because if there are not so many providers, there is a risk that the peer consumers may not find what they are looking for and will use a competitor\u2019s platform. The same consumer could abandon the KITT4SME platform and not return when it is upgraded with updated versions of its services, such as an advanced matchmaking mechanism or new AI solutions/modules. On the other hand, a provider that does not receive contacts may choose to post its offer in multiple places (e.g., AI platforms) if the cost of staying on the platform is affordable. The first effort should be to build a good peer producers base, while the right message needs to be sent to potential peer consumers. In order to support the creation of this kind of dynamics while generating revenue for the platform, the following approach can be used, especially in the initial lifecycle stage of the platform: \u2022 A free trial period is offered to each type of entity. This gives access to a primary or all set of services. The KITT4SME platform owner has to decide whether to keep the free access with no time limits forever; \u2022 After the trial period, a peer producer (AI developer, know-how provider) and peer consumer (manufacturing SME) access fee is required; \u2022 A transaction fee is charged and paid by the peer producer, who will set the final price offered to the peer consumer. For the solution implementation scenario, a different revenue mode should be used. Most likely also, in this case, the initial access will be free of charge for each type of entity. Then a lead fee model is considered more appropriate than the one based on commissions, as the final exchange value may be differently related to creating and improving customized AI solutions. For both scenarios, some incentives can be offered to active entities of the KITT4SME platform ecosystem. For example, an opportunity can be created for a platform member to invite some of their contacts (e.g., suppliers or customers) to the KITT4SME platform; if onboarding is achieved, the platform member may receive some benefits (e.g., discounts on the transaction fee, extension of the trial period, special rates). It can also be more complex and linked to the actual activity of the invited new members. For example, a platform member may receive the first set of benefits when their contacts are onboard and the second when their contacts start transacting on the platform. This can also be valuable for partners who can use the platform to gain benefits by including their network in the KITT4SME ecosystem. All the considerations so far have allowed the construction of an initial revenue streams model to determine the pricing strategy for the KITT4SME platform and to assess the financial sustainability of the KITT4SME platform (Fig. 4). Figure 4 illustrates the different revenue streams of the KITT4SME platform, which include several interdependent groups of entities (manufacturing SMEs, AI developers, know-how providers, cloud providers, platform components providers, consultants, multipliers), the KITT4SME platform owner, and their interactions. For instance, a usage externality exists when peer producers and peer consumersMultisided Business Model for Platform Offering AI Services 117Fig. 4 Revenue streams in the platform within the KITT4SME ecosystem entities defined in PDT need to work together to generate value using the KITT4SME platform (enhancing the quality of the match). Interactions can also occur between peer consumers and advertisers (very often advertisers will be peer producers, but not only, e.g., consultants). In this case, no transaction is taking place. Furthermore, the KITT4SME platform can enable advertising services or matching offers and charge an advertising fee for this and charge a premium fee for continued access to all KITT4SME services (i.e., a membership fee).118 K. Ejsmont et al.4 Conclusions and Next Steps In addition to most traditional strategies for defining business models, this study allowed us to understand better the users\u2019 needs of the platform offering AI services, to identify the values that can be exchanged through the platform, and to formalize the relationships and partnership mechanisms between entities accessing the MSP. This was done using the platform business model developed for the KITT4SME ecosystem as a case study. The adoption of the PDT method has shown that this tool provides a relevant methodological approach to define business model scenarios dedicated to MSPs qualitatively. Dividing the development of a business model into a few canvases allows one to focus on the different steps and to go deeper into the details of their design. The first five stages of the PDT have made it possible to define which entities can exchange values through which transaction channels. Although the completion of the canvases still does not allow a quantitative approach to assess the extent to which the elaborated BM can remain sustainable under the dynamic evolution of the boundary conditions. The following steps should be setting up the MVP and determining the value of the different fees charged for using the platform. The KITT4SME project will be used as a case study for these steps. In this way, the canvases proposed by Cicero [11] will be expanded by developing a methodology that guides the user to quantify the BM elements required for economic feasibility. Acknowledgments The work presented in this chapter was developed within the project \u201cKITT4SME \u2013 platform-enabled KITs of arTificial intelligence FOR an easy uptake by SMEs\u201d and received funding from the European Union\u2019s Horizon 2020 research and innovation program under grant agreements No. 952119. References 1. Abdelkafi, N., Raasch, C., Roth, A., Srinivasan, R.: Multi-sided platforms. Electr. Mark. 29, 553\u2013559 (2019). https://doi.org/10.1007/s12525-019-00385-4 2. Allweins, M.M., Proesch, M., Ladd, T.: The platform canvas\u2014conceptualization of a design framework for multi-sided platform businesses. Entrepren. Educ. Pedagogy. 4(3), 455\u2013477 (2021). https://doi.org/10.1177/2515127420959051 3. Armstrong, M.: Competition in two-sided markets. Rand J. Econ. 37, 668\u2013691 (2006) 4. Azadegan, A., Papamichail, K.N., Sampaio, P.: Applying collaborative process design to user requirements elicitation: a case study. Comput. Ind. 64(7), 798\u2013812 (2013). https://doi.org/ 10.1016/j.compind.2013.05.001 5. Barni, A., Montini, E., Menato, S., Sorlini, M., Anaya, V., Poler, R.: Integrating agent based simulation in the design of multi-sided platform business model: a methodological approach. In: 2018 IEEE International Conference on Engineering, Technology and Inno-vation (ICE/ITMC), Stuttgart, Germany, 17\u201320 June 2018 (2018) https://doi.org/10.1109/ ICE.2018.8436360Multisided Business Model for Platform Offering AI Services 1196. Belleflamme, P., Peitz, M.: Platform competition and seller investment incentives. Eur. Econ. Rev. 54, 1059\u20131076 (2010). https://doi.org/10.1016/j.euroecorev.2010.03.001 7. Bettoni, A., Corti, D., Matteri, D., Montini, E., Fiorello, M., Masiero, S., Barut, Z.M., Gretenkord, S., Gladysz, B., Ejsmont, K.: KITT4SME report 2021: Artificial Intelligence adoption in European Small Medium Enterprises (2021). https://kitt4sme.eu/wp-content/ uploads/2021/09/AI-readinessSurvey_resultstorespondentsV8.1.pdf. Accessed 12 July 2023 8. Bettoni, A., Matteri, D., Montini, E., G\u0142adysz, B., Carpanzano, E.: An AI adoption model for SMEs: a conceptual framework. IFAC-Papers OnLine. 54(1), 702\u2013708 (2021). https://doi.org/ 10.1016/j.ifacol.2021.08.082 9. Boudreau, K., Hagiu, A.: Platform rules: multi-sided platforms as regulators. SSRN Electron. J. (2008). https://doi.org/10.2139/ssrn.1269966 10. Chen, L., Tong, T.W., Tang, S., Han, N.: Governance and design of digital platforms: a review and future research directions on a meta-organization. J. Manag. 48(1), 147\u2013184 (2022). https:/ /doi.org/10.1177/01492063211045023 11. Cicero, S.: That\u2019s cognitive capitalism (2015). https://medium.com/@meedabyte/that-s-cognitivecapitalism-baby-ee82d1966c72. Accessed 12 July 2023 12. Corti, D., Bettoni, A., Montini, E., Barni, A., Arica, E.: Empirical evidence from the design of a MaaS platform. IFAC Papers OnLine. 54(1), 73\u201379 (2021). https://doi.org/10.1016/ j.ifacol.2021.08.008 13. Cusumano, M.A., Gawer, A., Yoffie, D.B.: The Business of Platforms: Strategy in the Age of Digital Competition, Innovation, and Power. Harper Business, New York (2019) 14. De Matta, R., Lowe, T.J., Zhang, D.: Competition in the multi-sided platform market channel. Int. J. Prod. Econ. 189, 40\u201351 (2017). https://doi.org/10.1016/j.ijpe.2017.03.022 15. Hagiu, A.: Pricing and commitment by two-sided platforms. Rand J. Econ. 37(3), 720\u2013737 (2006) http://www.jstor.org/stable/25046268 16. Hagiu, A., Wright, J.: Marketplace or reseller? Manag. Sci. 61, 184\u2013203 (2015). https://doi.org/ 10.2139/ssrn.2794585 17. Hagiu, A., Wright, J.: Multi-sided platforms. Int. J. Ind. Organ. 43 (2015). https://doi.org/ 10.2139/ssrn.2794582 18. Holgersson, M., Baldwin, C.Y., Chesbrough, H., Bogers, M.L.A.M.: The forces of ecosystem evolution. Calif. Manag. Rev. 64(3), 5\u201323 (2022). https://doi.org/10.1177/ 00081256221086038 19. KITT4SME D1.1 Stakeholder analysis: (2021) https://kitt4sme.eu/wp-content/uploads/2021/ 09/kitt4sme-d1.1-stakeholder-analysis.pdf. Accessed 12 July 2023 20. KITT4SME Trifold-brochure: (2021) https://kitt4sme.eu/wp-content/uploads/2021/03/Trifold-brochure-KITT4SME.pdf.pdf. Accessed 12 July 2023 21. Osterwalder, A., Pigneur, Y.: Business Model Generation: a Handbook for Visionaries, Game Changers, and Challengers. Wiley, New Jersey (2010) 22. Wang, Y., Tang, J., Jin, Q., Ma, J.: On studying business models in mobile social networks based on two-sided market (TSM). J. Supercomput. 70, 1297\u20131317 (2014). https://doi.org/ 10.1007/s11227-014-1228-4 23. Zhao, Y., von Delft, S., Morgan-Thomas, A., Buck, T.: The evolution of platform business models: exploring competitive battles in the world of platforms. Long Range Plan. 53(4), 101892 (2020). https://doi.org/10.1016/j.lrp.2019.101892120 K. Ejsmont et al.Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence: A Review and Case Study Yarens J. Cruz , Fernando Casta\u00f1o , Rodolfo E. Haber , Alberto Villalonga , Krzysztof Ejsmont , Bartlomiej Gladysz , \u00c1lvaro Flores , and Patricio Alemany 1 Introduction In the context of manufacturing systems, reconfiguration refers to the practice of changing a production system or process to meet new needs or to improve its performance. This might involve varying the structure of the production process, the order of the steps in which operations are executed, or the manufacturing process itself to make a different product. Reconfiguration may be necessary for several reasons, including changes in raw material availability or price, changes in consumer demand for a product, the need to boost productivity, save costs, or improve product quality, among others. It is a complex process that requires careful planning and coordination to ensure that production is not disrupted and that the changes result in the desired outcomes. In return, it may offer substantial advantages including enhanced product quality, reduction of waste, and greater productivity, making it a crucial strategy for enterprises trying to maintain their competitiveness in a rapidly changing market. Y. J. Cruz (\u0002) \u00b7 F. Casta\u00f1o \u00b7 R. E. Haber \u00b7 A. Villalonga Centro de Autom\u00e1tica y Rob\u00f3tica (CSIC-Universidad Polit\u00e9cnica de Madrid), Madrid, Spain e-mail: y.cruz@car.upm-csic.es; fernando.castano@car.upm-csic.es; rodolfo.haber@car.upm-csic.es; alberto.villalonga@car.upm-csic.es K. Ejsmont \u00b7 B. Gladysz Institute of Production Systems Organization, Faculty of Mechanical and Industrial Engineering, Warsaw University of Technology, Warsaw, Poland e-mail: krzysztof.ejsmont@pw.edu.pl; bartlomiej.gladysz@pw.edu.pl \u00c1.  Flores  \u00b7 P. Alemany  Rovim\u00e1tica SL, C\u00f3rdoba, Spain e-mail: alvaro.flores@rovimatica.eu; patricio.alemany@rovimatica.eu \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_8121122 Y. J. Cruz et al.Self-reconfiguration is the capacity of a manufacturing system to autonomously modify its configuration or structure to respond to dynamic requirements. This concept is frequently linked to the development of modular and adaptive manufac-turing systems. These systems exhibit high flexibility, efficiency, and adaptability by allowing the self-reconfiguration of their assets. However, self-reconfiguration is not directly applicable to all manufacturing systems. To implement self-reconfiguration, a particular level of technological maturity is required, including the following requirements [1]: \u2022 Modularity: The system is made up of a collection of standalone components. \u2022 Integrability: The components have standard interfaces that facilitate their integration into the system. \u2022 Convertibility: The structure of the system can be modified by adding, deleting, or replacing individual components. \u2022 Diagnosability: The system has a mechanism for identifying the status of the components. \u2022 Customizability: The structure of the system can be changed to fit specific requirements. \u2022 Automatability: The system operation and modifications can be carried out without human intervention. Additionally, self-reconfiguration may involve a variety of techniques and technologies, including IT infrastructure, robotic systems, intelligent sensors, and advanced control algorithms. These technologies enable machines to automatically identify and select the appropriate components or configurations needed to complete a given task, without requiring manual intervention or reprogramming. However, in some practical scenarios, human validation is still required before executing the reconfiguration. Self-reconfiguration in manufacturing typically focuses on process reconfigura-tion and capacity reconfiguration with success stories in the automotive industry. Process reconfiguration involves changes in the manufacturing process itself, such as changing the sequence of operations or the layout of the production line, as well as modifications to the equipment. On the other hand, capacity reconfiguration involves adjusting the capacity of the manufacturing system to meet changes in demand. This may involve adding or removing production lines, or modifying the parameters of machines. It should be noted that modifying the parameters of existing equipment can increase production throughput without requiring significant capital investment; however, it may also require changes to the production process, such as modifying the material flow or introducing new quality control measures.Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 1232 Reconfiguration in Manufacturing 2.1 Precursors of Reconfigurable Systems: Flexible Manufacturing Systems Current self-reconfigurable manufacturing systems are the result of the evolution of ideas that emerged more than 50 years ago. During the 1960s and 1970s, the production methods were primarily intended for mass production of a limited range of products [2]. Due to their rigidity, these systems needed a significant investment of time and resources to be reconfigured for a different product. During that period, supported by the rapid advancements and affordability of computer technology, the concept of flexible manufacturing system (FMS) emerged as a solution to address this scenario [3]. FMSs are versatile manufacturing systems, capable of producing a diverse array of products utilizing shared production equipment. These systems are characterized by high levels of automation and computer control, enabling seamless adaptation for manufacturing different goods or products. FMSs typically consist of a series of integrated workstations, each containing a combination of assets. These workstations are connected by computer-controlled transport systems that can move raw materials, workpieces, and finished products between workstations. When FMSs were introduced, they were primarily focused on achieving reconfigurability through the use of programmable controllers and interchangeable tooling. These systems may be configured to carry out a variety of manufacturing operations such as milling, drilling, turning, and welding. FMSs can also incorporate technologies such as computer-aided design/manufacturing (CAD/CAM) and computer numerical control (CNC) to improve efficiency and quality. This paradigm has been widely adopted in industries such as automotive [4], aerospace [5], and electronics [6] and continues to evolve with advances in technology. However, despite the adaptability to produce different products, the implemen-tation of FMSs has encountered certain drawbacks such as lower throughput, high equipment cost due to redundant flexibility, and complex design [7]. In addition, they have fixed hardware and fixed (although programmable) software, resulting in limited capabilities for updating, add-ons, customization, and changes in production capacity [3]. 2.2 Reconfigurable Manufacturing Systems Although FMSs can deal with the market exigence for new products or modifica-tions of existing products, they cannot efficiently adjust their production capacity. This means that if a manufacturing system was designed to produce a maximum number of products annually and, after 2 years, the market demand for the product is reduced to half, the factory will be idle 50% of the time, creating a big financial loss.124 Y. J. Cruz et al.On the other hand, if the market demand for the product surpasses design capability and the system is unable to handle it, the financial loss can be even greater [8]. To handle such scenarios, during the 1990s, a new type of manufacturing system known as reconfigurable manufacturing system (RMS) was introduced. RMSs adhere to the typical goals of production systems: to produce with high quality and low cost. However, additionally, they also aim to respond quickly to market demand, allowing for changes in production capacity. In other words, they strive to provide the capability and functionality required at the right time [3]. This goal is achieved by enabling the addition or removal of components from production lines on demand. Design principles such as modularity, integrability, and open architecture control systems started to take more significance with the emergence of RMSs, given the relevance of dynamic equipment interconnection in these systems [9]. Consider-ing their advantages, RMSs have been applied to the manufacturing of medical equipment [10], automobiles [11], food and beverage [12], and so on. Because they require less investments in equipment and infrastructure, these systems often offer a more cost-effective alternative to FMSs. Although these systems can adapt to changing production requirements, the reconfiguration decisions are usually made or supervised by a human, which means the systems cannot autonomously reconfigure themselves. This gives more control to the plant supervisor or operator, but the downside is that it limits the response speed. 2.3 Evolution Towards Self-Reconfiguration As technology advanced and the demands of manufacturing increased, production systems began to incorporate more sophisticated sensing, control, and robotics capabilities. This allowed them to monitor and adjust production processes in real time, adapt to changes in the manufacturing environment, and even reconfigure themselves without human intervention. This shift from reconfigurable to self-reconfigurable systems was driven by several technological advancements: \u2022 Intelligent sensors: sensors that are capable of not only detecting a particular physical quantity or phenomenon but also processing and analyzing the data collected to provide additional information about the system being monitored [13]. \u2022 Adaptive control: control systems that can automatically adjust the manufactur-ing process to handle changes in the production environment while maintaining optimal performance [14]. \u2022 Autonomous robots: robots that can move and manipulate objects, work collabo-ratively, and self-reconfigure. These robots can be used to assemble components, perform quality control checks, and generate useful data for reconfiguring production lines [15].Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 125\u2022 Additive manufacturing: 3D printing and additive manufacturing techniques allow to create complex and customized parts and structures on demand, without the need for extensive changes in the production system. Additionally, this technique is very useful for quick prototyping [16]. Compared to conventional RMSs, self-reconfigurable manufacturing systems enable to carry out modifications to the production process in a faster and more autonomous way [17]. Today, these systems are at the cutting edge of advanced manufacturing, allowing the development of extremely complex, specialized, and efficient production systems that require little to no human involvement. Self-reconfiguration is receiving significant attention in the context of Industry 4.0, where the goal is to create smart factories that can communicate, analyze data, and optimize production processes in real time [18]. 3 Current Approaches Currently, there are several approaches for designing self-reconfiguration solutions including computer simulation, which is one of the most reported in the literature with proof-of-concepts based on simulation results. Other alternative techniques include those based on artificial intelligence (AI), which provide powerful methods and tools to deal with uncertainty, such as fuzzy and neuro-fuzzy approaches, machine learning and reinforcement learning strategies. These approaches are not mutually exclusive and, in many cases, are used in a complementary way. 3.1 Computer Simulation Computer simulation is a particularly valuable tool for the design and optimization of self-reconfigurable manufacturing systems. In this context, these tools aim to enhance the system\u2019s responsiveness to changes in production requirements. The recent increase in computational capacities has enabled the testing of various configurations and scenarios before their actual implementation [19]. Currently, commercial applications such as AutoMod, FlexSim, Arena, Simio, and AnyLogic, among others, allow to create high-fidelity simulations of industrial processes [20], that even include three-dimensional recreations of factories for use in augment-ed/virtual reality applications. Computer simulation becomes a powerful tool when integrated with the production process it represents. Based on this idea, digital twins have gained significant attention in both industry and academia [21]. Digital twins enable real-time data integration from the production process into the simulation, replicating the actual production environment. By evaluating different options and identifying the optimal configuration for the new scenarios, digital twins provide feedback to the production process, facilitating real-time modifications.126 Y. J. Cruz et al.3.2 Fuzzy Systems Fuzzy logic is a mathematical framework that can be used to model and reason with imprecise or uncertain data. This capability makes fuzzy logic particularly useful in situations where the system may not have access to precise data or where the data may be subject to noise or other sources of uncertainty. In the context of self-reconfiguration, fuzzy systems can be used to model the behavior of the physical processes and make decisions about how to reconfigure them based on imprecise data. For instance, it is often very complex to assign a precise value to indicators such as expected market demand, product quality, or energy consumption [22]. These variables can be assigned to fuzzy membership functions and then, following predefined rules, combined using fuzzy operators to determine how the production system should be optimally reconfigured depending on the available data. 3.3 Data-Driven Methods Data-driven methods deal with the collection and analysis of data, the creation of models, and their use for decision-making. This approach is extensively applied when historical data of the production process is available. By using data ana-lytics, it is possible to identify bottlenecks or the inefficient use of assets in the production process. Also, data-driven methods make extensive use of machine learning algorithms for modeling the production process behavior [23]. Machine learning methods can be trained with datasets containing a large number of features and samples, learning to identify correlations, patterns, and anomalies that are beyond human perception [24]. Moreover, by collecting new data of the production process, machine learning models can be retrained or fine-tuned to improve their performance over time. Once the machine learning model has been trained with production data, it can be used as an objective function of an optimization algorithm to make decisions about how to reconfigure the manufacturing process to optimize desired indicators. 3.4 Reinforcement Learning Reinforcement learning is a subfield of machine learning that has shown great capacity in the development of algorithms for autonomous decision-making in dynamic and complex environments. In reinforcement learning, an agent learns to make decisions based on feedback from the environment. The agent performs actions in the environment and receives feedback in the form of rewards or penalties. The goal of the agent is to maximize the cumulative reward over time by learning which actions are most likely to lead to positive outcomes. Self-Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 127reconfigurable manufacturing systems present a unique challenge for reinforcement learning algorithms because the environment is constantly changing [25]. The agent should be able to adapt to changes in the production environment, such as changes in demand or changes in the availability of resources. The agent can learn which modules are more effective for specific tasks and reconfigure itself accordingly [18]. Another important benefit of using reinforcement learning is the ability to learn from experience. These algorithms can learn from mistakes and errors and try to avoid repeating them. 4 Lighthouse Demonstrator: GAMHE 5.0 Pilot Line To evaluate how AI tools can be applied for self-reconfiguration in manufacturing processes and how they can be integrated with one another, an Industry 4.0 pilot line was chosen for demonstration. The selected pilot line was the GAMHE 5.0 laboratory, which simulates the slotting and engraving stages of the production process of thermal insulation panels. Figure 1 illustrates the typical workflow of the process. Initially, a robot picks up a panel and positions it in a machining center to create slots on all four sides. Subsequently, the same robot transfers the panel to a conveyor belt system that transports it to a designated location, where a second robot takes over the handling of the panel. Next, the panel is positioned in a visual inspection area by the robot. If the slotting is deemed correct, the panel is then moved to a second machining center for the engraving process. Finally, the robot transfers the panel to a stack of processed panels. Occasionally, due to poor positioning in the slotting process, some sides of the panels are not slotted or the depth of the slot is smaller than required. In those cases, the visual inspection system should detect the irregularity and the workflow of the process should be modified to repeat the slotting process. Figure 2 illustrates this Fig. 1 Normal workflow of the pilot line128 Y. J. Cruz et al.Fig. 2 Workflow for reprocessing in the pilot line Fig. 3 Workflow for defective panels in the pilot line situation. Once the slotting irregularities are corrected, the system continues with the normal workflow. In some cases, the slotting process may cause damage to the panels. This can happen when working with new materials or previously unverified machining configurations. In those cases, the visual inspection system should detect that the panel is damaged and it should be sent directly to a stack of damaged parts. Figure 3 shows this situation. Making accurate decisions about the process workflow depending on the quality of products, specifically on the result of the slotting process, has a direct impact on the productivity of the pilot line. For instance, in cases where a panel is damaged during slotting, it is crucial to remove it from the production line to prevent unnecessary time and resources from being spent on machining it during the engraving stage. To achieve this, the presence of a reliable visual inspection system becomes essential. Although a deep learning classifier could be used for this task, one drawback is that it is very hard to understand how the decision is made. For this reason, it is proposed a deep learning segmentation model, whose function is to separate the desired areas of the images from the unwanted regions.Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 129The output of a segmentation model provides a pixel-level understanding of objects and their boundaries in an image, enabling a detailed visual interpretation of the model prediction. Then, using the segmentation result, a reasoned decision can be made, making the outcome of the system more interpretable. Section 4.1 deals with this situation. On the other hand, a common situation is that the pilot line should deal with small batches of panels made of different materials and with different dimensions. Thus, the configuration of the assets for reaching an optimal performance varies frequently. For dealing with this situation a self-reconfiguration approach based on automated machine learning (AutoML) and fuzzy logic is proposed. Although the approach proposed in this work is generalizable to multiple objectives, for the sake of simplicity, the improvement of only one key performance indicator (KPI) will be considered. Sections 4.2 and 4.3 cover this topic. 4.1 Deep Learning-Based Visual Inspection The segmentation model developed for application in the pilot line intends to separate the side surface of the panel from other elements within an image, allowing for later decisions on the panel quality and modifications of the process workflow. This model is based on a U-net architecture, which consists of an encoder path that gradually downsamples the input image and a corresponding decoder path that upsamples the feature maps to produce a segmentation map of the same size as the input image. This network also includes skip connections between the encoder and decoder paths that allow to retain and fuse both high-level and low-level features, facilitating accurate segmentation and object localization [26]. A dataset containing 490 images with their corresponding masks was prepared for training and evaluating the model. The image dataset was split into three subsets: training (70% of the data), validation (15% of the data), and testing (15% of the data). In this case, the validation subset serves the objective of facilitating early stopping during training. This means that if the model\u2019s performance evaluated on the validation subset fails to improve after a predetermined number of epochs, the training process is halted. By employing this technique, overfitting can be effectively mitigated and the training time can be significantly reduced. A second version of the dataset was prepared by applying data augmentation to the training set while keeping the validation and test sets unchanged. The dataset was augmented using four transformations: horizontal flip, coarse dropout, random brightness, and random contrast. This helps increase the number of training examples, improving the model\u2019s prediction capability and making it more robust to noise. Using the two versions of the dataset, two models with the same architecture were trained. Table 1 presents the output of the two models for three examples taken from the test set. As can be observed, the predictions obtained with the model trained on the augmented dataset are significantly better than those obtained with the model130 Y. J. Cruz et al.Table 1 Segmentation results for sample images Sample Original imageGround truth Prediction of the model trained on the original dataset Prediction of the model trained on the augmented dataset 1 2 3Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 131Table 2 Metric values obtained by segmentation models on the test set Model Accuracy F1 score Jaccard index Precision Recall Trained on the original dataset 0.892 0.639 0.563 0.997 0.564 Trained on the augmented dataset 0.995 0.992 0.984 0.99 0.993 Fig. 4 Squared contours detection for a compliant panel, a panel without slot, and a damaged panel, respectively trained on the original dataset. This is also confirmed by the values obtained in several metrics, which are shown in Table 2. After the image is segmented by the deep learning model, a second algorithm is used. Here, a convex hull is adjusted to each separate contour in the segmented image. Then, a polygonal curve is generated for each convex hull with a precision smaller than 1.5% of the perimeter of the segmented contour. Finally, if the polygonal curve has four sides, it is drawn over the original image. After this procedure, if two rectangles were drawn over the image it is assumed that the slotting was correct and the panel did not suffer any significative damage; thus, it can be sent to the next stage of the line. On the other hand, if only one rectangle was drawn, it is assumed that the slotting was not carried out or the panel was damaged during this process. Figure 4 shows the results obtained for illustrative cases of a compliant panel, a panel with missing slots, and a damaged panel, respectively. If only one rectangle was drawn, depending on its size and location, the panel will be sent to the slotting stage again or removed from the line. This method was applied to the test set images and in all the cases the output produced matched the expected output. 4.2 Automating the Machine Learning Workflow As outlined in the previous sections, the working conditions of the pilot line are subject to rapid variations. To effectively address these variations and generate132 Y. J. Cruz et al.Fig. 5 General machine learning steps optimal parametrizations for the assets, machine learning emerges as a promising tool. The usual machine learning workflow is composed of a series of steps that are executed one by one by a team of specialists. However, this workflow can be auto-mated. This research area is known as AutoML and recently has gained considerable attention. AutoML plays a crucial role in streamlining workflows, saving time, and reducing the effort required for repetitive tasks, thereby enabling the creation of solutions even for nonexperts. Noteworthy tools in this domain include Google Cloud AutoML, auto-sklearn, Auto-Keras, and Azure AutoML, among others. Typically, these tools encompass various stages, from data preprocessing to model selection. Moreover, in line with the automation philosophy of these systems, the process optimization step can also be integrated. This way the system would receive a dataset and return the parameter values that make the process work in a desired regime. Considering this idea, an end-to-end AutoML solution has been developed to be applied to GAMHE 5.0 pilot line. The following subsections describe the typical machine learning workflow, as well as the specificities of its different steps and how AutoML can be used for optimizing the production process. 4.2.1 Typical Machine Learning Workflow Machine learning aims to create accurate and reliable models capable of identifying complex patterns in data. The creation and exploitation of these models is typically achieved through a series of steps that involve preparing the dataset, transforming the data to enhance its quality and relevance, selecting and training an appropriate machine learning model, evaluating the model\u2019s performance, and deploying the model in a real-world setting. Figure 5 depicts these steps. By following this workflow, machine learning practitioners can build models that harness the power of data-driven learning, enabling them to effectively derive meaningful insights and make accurate predictions in practical applications. Data Preprocessing Data preprocessing is the initial step in the creation of a machine learning system. The data to be used may have a variety of sources and formats, thus it should be prepared before being used by any algorithm. If data are originated from different sources, it must be merged into a single dataset. Furthermore, most methods areSelf-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 133not designed to work with missing data, so it is very common to remove samples with missing information. Preprocessing may also include filtering data to remove noise, which can result later in more robust models. In this stage, the data may be transformed to a format that is suitable for analysis, which can include operations such as normalization, bucketizing, and encoding. Finally, one common operation carried out in this stage is splitting. This refers to the partition of the dataset into two subsets, which will be used for training and evaluation purposes. Additionally, a third subset can be created if it is planned to carry out a hyperparameter optimization or neural architecture search over the model. Feature Engineering The goal of the feature engineering stage is to convert raw data into relevant features that contain the necessary information to create high-quality models. One of the most interesting techniques that can be used in this stage is feature selection. Feature selection aims to determine which features are the best predictors for a certain output variable. Then, when these features are selected, they can be extracted from the original dataset to build a lower dimensional dataset, allowing to build more compact models with better generalization ability and reduced computational time [27, 28]. Typically, for problems with numerical input and output variables, Pearson\u2019s [29] or Spearman\u2019s correlation coefficients [30] are used. If the input is numerical but the output is categorical, then the analysis of variance (ANOVA) [31] or Kendall\u2019s rank coefficient [32] are employed. Other situations may require the use Chi-squared test or mutual information measure [33]. Other techniques that can be applied in the feature engineering stage include feature creation and dimensionality reduction. Feature creation implies creating new features either by combining the existing ones or by using domain knowledge [34]. On the other hand, dimensionality reduction techniques such as principal component analysis (PCA) or t-distributed stochastic neighbor embedding (t-SNE) algorithms are used to map the current data in lower dimensional space while retaining as much information as possible [35]. Model Selection The model selection step implies the creation, training, and evaluation of different types of models to, in the end, select the most suitable for the current situation. This practice is carried out since it does not exist a methodology for determining a priori which algorithm is better for solving a problem [36]. Therefore, the most adequate model may vary from one application to another as in the following cases: long short-term memory network (LSTM) [37], multilayer perceptron (MLP) [38], support vector regression (SVR) [39], Gaussian process regression (GPR) [40], convolutional neural network (CNN) [41], gradient boosted trees (GBT) [42]. The number and types of models to explore in this stage will depend on134 Y. J. Cruz et al.the characteristics of the problem and the available computational resources. The selection of the model is carried out taking into consideration one or more metrics. For regression problems is common to rely on the coefficient of determination (R2), mean squared error (MSE), and mean absolute percentage error (MAPE), among other metrics [43]. On the other hand, for classification problems, typical metrics are accuracy, recall, precision, F1-score,and so on. Optionally, this stage can also include hyperparameter optimization. Hyperpa-rameters determine a model\u2019s behavior during training and, in some cases, also how its internal structure is built. They are set before a model is trained and cannot be modified during training. The selection of these values can greatly affect a model\u2019s performance. However, finding an optimal or near-optimal combination of hyperparameters is not a trivial task and, usually, it is computationally intensive. The most commonly used techniques for this task include grid search, random search, Bayesian optimization, and so on. 4.2.2 Process Optimization Once a model has been created for representing a process, it can be used for optimizing it. Assuming the model exhibits robust predictive capabilities and the constraints are accurately defined, various input values can be evaluated in the model to determine how the system would respond, eliminating the need for conducting exhaustive tests on the actual system. In other words, the model created can be embedded as the objective function of an optimization algorithm for finding the input values that would make the production process work in a desired regime. In this context, popular strategies such as particle swarm optimization [44], simulated annealing [45], evolutionary computation [46], and Nelder-Mead [47], among others, are commonly employed. 4.2.3 Application of AutoML to the Pilot Line To apply an AutoML methodology to the selected pilot line, it is essential to collect operational data from the runtime system under varying asset parametrization. This data should include recorded measurements of variables and KPIs. Since not all the collected data have to be necessarily recorded using the same rate, it is necessary to transform the data to the same time base. This is commonly done by downsampling or averaging the data recorded with a higher rate to match the time base of the data recorded with a lower rate. In this case, averaging was used. Once the historical dataset has been prepared, an AutoML methodology can be applied. While typical AutoML methodologies automate the steps shown in Fig. 5, the proposed methodology also includes the process optimization procedure by embedding the selected model as objective function of an optimization algorithm for automatically finding the assets\u2019 configuration as depicted in Fig. 6.Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 135Fig. 6 Overall description of the proposed AutoML methodology First, in the data preprocessing step, the dataset is inspected searching for missing values. If any are found, the corresponding sample is eliminated. Next, the features\u2019 values are standardized and the dataset is divided into training and validation sets. In this case, hyperparameter optimization was not implemented for making the methodology applicable in scenarios with low computational resources. For this reason, a test set is not required. Following that, feature selection is carried out by computing the Pearson\u2019s correlation coefficient (r) individually between each feature and the output variable on the training set, using the following equation: . r =\u2211ni=1 (xi \u2212 x) (yi \u2212 y)\u221a\u2211ni=1 (xi \u2212 x)2\u221a\u2211ni=1 (yi \u2212 y)2where n is the number of samples, xi represents the value of the i-th sample of feature x, yi represents the value of the i-th sample of the output variable, and . x and . y represent the mean of the respective variables. Pearson\u2019s correlation coefficient is a univariate feature selection method com-monly used when the inputs and outputs of the dataset to be processed are numerical [48]. By using this method, it is possible to select the features with higher predictive capacity, resulting not only in a reduction of the dimensionality of data but also leads to more compact models with better generalization ability and reduced computational time [27, 28]. In the proposed approach, the features for which |r| > 0.3 are selected as relevant predictors, and the rest are discarded from both, the training and validation sets. Typically, a value below the 0.3 threshold is considered an indicator of low correlation [49]. During the application of the AutoML methodology to the data of the pilot line for improving the throughput, the number of features was reduced from 12 to 7. This intermediate result is important to guide the technicians on which parameters they should focus on while looking for a certain outcome. The next step involves model selection. Among the different models to evaluate in the proposed approach are MLP, SVR, GPR, and CNN, which have been previously used for modeling industrial KPIs [40, 50\u201352]. Table 3 presents details of these models. Each one of these models is trained on the training set and then136 Y. J. Cruz et al.Table 3 Details of the evaluated models Model Details MLP Architecture: Fully connected layer (128 units, ReLU activation) + Fully connected layer (64 units, ReLU activation) + Fully connected layer (1 unit, linear activation), Optimizer: RMSprop, Learning rate: 0.001, Epochs: 5000 SVR Kernel: rbf, C: 1.0, Epsilon: 0.2, Tolerance: 0.001 GPR Kernel: Dot Product + White Kernel, Alpha: 1e-10 CNN Architecture: 1-D Convolution layer (64 filters, kernel size: 3, strides: 1, padding: same) + 1-D Max pooling layer (pool size: 2, strides: 1, padding: valid) + Flatten layer + Fully connected layer (64 units, ReLU activation) + Dropout layer (dropout rate: 0.1) + Fully connected layer (32 units, ReLU activation) + Fully connected layer (1 unit, linear activation), Optimizer: RMSprop, Learning rate: 0.001, Epochs: 5000 they are evaluated on the validation set. The metric used for comparison was the coefficient of determination (R2). After this process is finished, the model that produced the best result is selected. The model selected during the application of the methodology to the pilot line was MLP with R2 = 0.963 during validation. The R2 value for the remaining candidate models was 0.958 for GPR, 0.955 for CNN, and 0.947 for SVR. One of the enablers of these results was the feature selection process, which allowed to retain the relevant predictors. Finally, an optimization method is applied for determining the most favorable parametrization of the production process to minimize or maximize the desired KPI using the selected model as the objective function. In this case, the goal is to maximize throughput. The optimization is carried out using random search, which is a simple, low-complexity, and straightforward optimization method [53]. This method can be applied to optimizing diverse types of functions, even those that are not continuous or differentiable. It has been proven that random search is asymptot-ically complete, meaning that it converges to the global minimum/maximum with probability one after indefinitely run-time computation and, for this reason, it has been applied for solving many complex problems [54]. One aspect to consider before executing the optimization is that the feasible range of the parameters must be carefully decided to prevent the result of the optimization from being invalid. In the case analyzed, where the objective is to maximize the throughput of the pilot line, the obvious choice is to make the assets work at the maximum speed within the recommended ranges. To evaluate if the proposed methodology was capable of inferring this parametrization, during the preparation of the dataset the samples where all the assets were parametrized with the maximum speed were intentionally eliminated. As desired, the result of the methodology was a parametrization where all the assets were set to the maximum speed, yielding an expected throughput value of 163.37 panels per hour, which represents an expected improvement of 55.1% with respect to the higher throughput value present in the dataset. It is noticeable that the higher throughput value of the samples that were intentionally eliminated from the dataset is 158.52. The reason why the proposed methodology slightly overestimates this value is that the model is not perfectly accurate.Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 1374.3 Fuzzy Logic-Based Reconfigurator Once the parametrization of the assets has been determined by the AutoML methodology to meet a desired KPI performance, it is important to ensure that the system will continue to work as desired. Unfortunately, some situations may prevent the system from functioning as intended. For instance, a degradation in one of the assets may result in a slower operation, reducing the productivity of the entire line. For such cases, a fuzzy logic-based reconfigurator is developed. The intuition behind this component is that if the behavior of some assets varies from their expected performance, the reconfigurator can modify the parameters of the assets to make them work in the desired regime again, as long as the modification of the parameters is within a predefined safety range. Additionally, if the deviation from the expected performance is significant, the component should be able to detect it and inform the specialists that a problem needs to be addressed. The proposed reconfigurator has two inputs and generates three outputs using the Mamdani inference method [55]. These variables are generic, so the reconfigurator can use them without any modification to try to keep each asset\u2019s throughput level constant. The first input is the deviation from nominal production time (\u0394T) and its safety range was defined as \u00b150% of the nominal production time. The second input is the change in the trend of the deviation from nominal production time (\u0394T2) and its safety range was defined as \u00b120% of the nominal production time. There is an instance of these two variables for each asset in the line and they are updated whenever a panel is processed. These values are normalized in the interval [\u22121, 1] before being used by the reconfigurator. Figure 7 presents the membership functions defined for the two inputs. On the other hand, the first output is the operation that the reconfigurator must apply to the current asset\u2019s working speed (Reco1). If the operation is Increase or Decrease, the values in the interval [\u22121, 1] are denormalized to a range comprising \u00b150% of the nominal asset speed. The second output represents the timing when the modifications should be applied (Reco2), and the third output represents the operation mode (Reco3), which specifies if the previous reconfigurator outputs Fig. 7 Membership functions for inputs \u0394T and \u0394T2138 Y. J. Cruz et al.Fig. 8 Membership functions for outputs Reco1, Reco2, and  Reco3 should be applied automatically, presented as recommendations for the operators, or ignored. Figure 8 shows the membership functions of the three outputs. Once the membership functions of the input and output variables were defined, a rule base was created for each output variable. Each rule base is formed by nine If\u2013Then rules that associate a combination of the input membership functions with an output membership function, as in the following example: If \u0394T is Negative And \u0394T2 is Negative Then Reco1 is Increase The defined rule bases allow to obtain the output surfaces illustrated in Fig. 9 for the fuzzy inference systems corresponding to each output variable. To evaluate the reconfigurator, the nominal speed of each asset was set to 70% of its maximum speed and several disturbances were emulated. The first one was reducing the speed of all assets to 50% of their maximum speed, the second increasing the speed of all assets to their maximum speed, and finally, the speed of all assets was set to 30% of their maximum speed. As expected after the first disturbance the system recommended increasing the speed, after the second it recommended decreasing the speed, and after the third it recommended stopping the production. The results are shown in Table 4. 5 Conclusions This work has addressed self-reconfigurable manufacturing systems from both theoretical and practical points of view, emphasizing how AI is applied to them. The emergence and evolution until the current state of these systems have beenSelf-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 139Fig. 9 Output surfaces of Reco1, Reco2, and  Reco3 presented. Likewise, their potential benefits such as improved responsiveness, flex-ibility, and adaptability have been analyzed. Current approaches for implementing self-reconfiguration in manufacturing have also been discussed. Additionally, the application of self-reconfiguration and AI techniques to a pilot line was tested. First, the integration in the pilot line of an AI-based solution for visual inspection was evaluated. This component has a direct relation with the workflow of the pilot line, thus influencing the productivity. Two segmentation models were trained for the visual inspection task and the best one, with an accuracy of 0.995 and a F1 score of 0.992, was deployed in the pilot line, enabling the correct handling of products. Furthermore, an AutoML approach that includes generating the models and optimizing the production process was used for determining the optimal parametrization of the line. This way, a model with R2 = 0.963 was obtained and the expected improvement in throughput with respect to the data seen during training is 55.1%, which matches the values reached in real production at maximum capacity. Then, a fuzzy logic-based reconfigurator was used for dealing with the degradation in performance. This component demonstrated a correct behavior and showed robustness when tested against three different perturbations. The findings of this study suggest that self-reconfiguration is a key area of research and development in the field of advanced manufacturing. Future research will explore additional applications of self-reconfiguration in different manufacturing contexts.140 Y. J. Cruz et al.Table 4 Fuzzy logic reconfigurator results for disturbances AssetNominal speedDisturbanceReco1Reco2Reco3 St\u00e4ubli RX907.7 m/s1Increase to 7.05 m/sMedium termKeep configuration 2Decrease to 8.94 m/sMedium termKeep configuration 3StopShort termOperator assistance Deckel Maho7200 mm/min1Increase to 7027.8 mm/minMedium termKeep configuration 2Decrease to 8132.68 mm/minMedium termKeep configuration 3StopShort termOperator assistance Conveyor belts5040 rpm1Increase to 4013.6 rpmMedium termKeep configuration 2Decrease to 5904 rpmMedium termKeep configuration 3StopShort termOperator assistance UR5e126\u25e6/s1Increase to 115.28\u25e6/sMedium termKeep configuration 2Decrease to 146.1\u25e6 /sMedium termKeep configuration 3StopShort termOperator assistance Kern EVO11,200 mm/min1Increase to 10,250.2 mm/minMedium termKeep configuration 2Decrease to 12,992 mm/minMedium termKeep configuration 3StopShort termOperator assistanceSelf-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 141Acknowledgments This work was partially supported by the H2020 project \u201cplatform-enabled KITs of arTificial intelligence FOR an easy uptake by SMEs (KITT4SME),\u201d grant ID 952119. The work is also funded by the project \u201cSelf-reconfiguration for Industrial Cyber-Physical Systems based on digital twins and Artificial Intelligence. Methods and application in Indus-try 4.0 pilot line,\u201d Spain, grant ID PID2021-127763OB-100, and supported by MICINN and NextGenerationEU/PRTR. This result is also part of the TED2021-131921A-I00 project, funded by MCIN/AEI/10.13039/501100011033 and by the European Union \u201cNextGenerationEU/PRTR.\u201d References 1. Hees, A., Reinhart, G.: Approach for production planning in reconfigurable manufacturing systems. Proc. CIRP. 33, 70\u201375 (2015). https://doi.org/10.1016/j.procir.2015.06.014 2. Yin, Y., Stecke, K.E., Li, D.: The evolution of production systems from Industry 2.0 through Industry 4.0. Int. J. Prod. Res. 56, 848\u2013861 (2018). https://doi.org/10.1080/ 00207543.2017.1403664 3. Mehrabi, M.G., Ulsoy, A.G., Koren, Y., Heytler, P.: Trends and perspectives in flexible and reconfigurable manufacturing systems. J. Intell. Manuf. 13, 135\u2013146 (2002). https://doi.org/ 10.1023/A:1014536330551 4. Cronin, C., Conway, A., Walsh, J.: Flexible manufacturing systems using IIoT in the automo-tive sector. Proc. Manuf. 38, 1652\u20131659 (2019). https://doi.org/10.1016/j.promfg.2020.01.119 5. Parhi, S., Srivastava, S.C.: Responsiveness of decision-making approaches towards the per-formance of FMS. In: 2017 International Conference of Electronics, Communication and Aerospace Technology (ICECA), pp. 276\u2013281 (2017) 6. Bennett, D., Forrester, P., Hassard, J.: Market-driven strategies and the design of flexible production systems: evidence from the electronics industry. Int. J. Oper. Prod. Manag. 12, 25\u201337 (1992). https://doi.org/10.1108/01443579210009032 7. Singh, R.K., Khilwani, N., Tiwari, M.K.: Justification for the selection of a reconfigurable manufacturing system: a fuzzy analytical hierarchy based approach. Int. J. Prod. Res. 45, 3165\u2013 3190 (2007). https://doi.org/10.1080/00207540600844043 8. Koren, Y.: The emergence of reconfigurable manufacturing systems (RMSs) BT - reconfig-urable manufacturing systems: from design to implementation. In: Benyoucef, L. (ed.) , pp. 1\u20139. Springer International Publishing, Cham (2020) 9. Koren, Y., Shpitalni, M.: Design of reconfigurable manufacturing systems. J. Manuf. Syst. 29, 130\u2013141 (2010). https://doi.org/10.1016/j.jmsy.2011.01.001 10. Epureanu, B.I., Li, X., Nassehi, A., Koren, Y.: An agile production network enabled by recon-figurable manufacturing systems. CIRP Ann. 70, 403\u2013406 (2021). https://doi.org/10.1016/ j.cirp.2021.04.085 11. Koren, Y., Gu, X., Guo, W.: Reconfigurable manufacturing systems: principles, design, and future trends. Front. Mech. Eng. 13, 121\u2013136 (2018). https://doi.org/10.1007/s11465-018-0483-0 12. Gould, O., Colwill, J.: A framework for material flow assessment in manufacturing systems. J. Ind. Prod. Eng. 32, 55\u201366 (2015). https://doi.org/10.1080/21681015.2014.1000403 13. Shin, K.-Y., Park, H.-C.: Smart manufacturing systems engineering for designing smart product-quality monitoring system in the Industry 4.0. In: 2019 19th International Conference on Control, Automation and Systems (ICCAS), pp. 1693\u20131698 (2019) 14. Ar\u0131c\u0131, M., Kara, T.: Robust adaptive fault tolerant control for a process with actuator faults. J. Process Control. 92, 169\u2013184 (2020). https://doi.org/10.1016/j.jprocont.2020.05.005 15. Ghofrani, J., Deutschmann, B., Soorati, M.D., et al.: Cognitive production systems: a mapping study. In: 2020 IEEE 18th International Conference on Industrial Informatics (INDIN), pp. 15\u201322 (2020)142 Y. J. Cruz et al.16. Scholz, S., Mueller, T., Plasch, M., et al.: Amodular flexible scalable and reconfigurable system for manufacturing of microsystems based on additive manufacturing and e-printing. Robot. Comput. Integr. Manuf. 40, 14\u201323 (2016). https://doi.org/10.1016/j.rcim.2015.12.006 17. Cedeno-Campos, V.M., Trodden, P.A., Dodd, T.J., Heley, J.: Highly flexible self-reconfigurable systems for rapid layout formation to offer manufacturing services. In: 2013 IEEE International Conference on Systems, Man, and Cybernetics, pp. 4819\u20134824 (2013) 18. Lee, S., Ryu, K.: Development of the architecture and reconfiguration methods for the smart, self-reconfigurable manufacturing system. Appl. Sci. 12 (2022). https://doi.org/10.3390/ app12105172 19. Mourtzis, D.: Simulation in the design and operation of manufacturing systems: state of the art and new trends. Int. J. Prod. Res. 58, 1927\u20131949 (2020). https://doi.org/10.1080/ 00207543.2019.1636321 20. dos Santos, C.H., Montevechi, J.A.B., de Queiroz, J.A., et al.: Decision support in productive processes through DES and ABS in the Digital Twin era: a systematic literature review. Int. J. Prod. Res. 60, 2662\u20132681 (2022). https://doi.org/10.1080/00207543.2021.1898691 21. Guo, H., Zhu, Y., Zhang, Y., et al.: A digital twin-based layout optimization method for discrete manufacturing workshop. Int. J. Adv. Manuf. Technol. 112, 1307\u20131318 (2021). https://doi.org/ 10.1007/s00170-020-06568-0 22. Abdi, M.R., Labib, A.W.: Feasibility study of the tactical design justification for reconfigurable manufacturing systems using the fuzzy analytical hierarchical process. Int. J. Prod. Res. 42, 3055\u20133076 (2004). https://doi.org/10.1080/00207540410001696041 23. Lee, S., Kurniadi, K.A., Shin, M., Ryu, K.: Development of goal model mechanism for self-reconfigurable manufacturing systems in the mold industry. Proc. Manuf. 51, 1275\u20131282 (2020). https://doi.org/10.1016/j.promfg.2020.10.178 24. Panetto, H., Iung, B., Ivanov, D., et al.: Challenges for the cyber-physical manufacturing enterprises of the future. Annu. Rev. Control. 47, 200\u2013213 (2019). https://doi.org/10.1016/ j.arcontrol.2019.02.002 25. Schwung, D., Modali, M., Schwung, A.: Self -optimization in smart production systems using distributed reinforcement learning. In: 2019 IEEE International Conference on Systems, Man and Cybernetics (SMC), pp. 4063\u20134068 (2019) 26. Ronneberger, O., Fischer, P., Brox, T.: U-net: convolutional networks for biomedical image segmentation BT - medical image computing and computer-assisted intervention \u2013 MICCAI 2015. In: Navab, N., Hornegger, J., Wells, W.M., Frangi, A.F. (eds.) , pp. 234\u2013241. Springer International Publishing, Cham (2015) 27. Al-Tashi, Q., Abdulkadir, S.J., Rais, H.M., et al.: Approaches to multi-objective feature selection: a systematic literature review. IEEE Access. 8, 125076\u2013125096 (2020). https:// doi.org/10.1109/ACCESS.2020.3007291 28. Solorio-Fern\u00e1ndez, S., Carrasco-Ochoa, J.A., Mart\u00ednez-Trinidad, J.F.: A review of unsuper-vised feature selection methods. Artif. Intell. Rev. 53, 907\u2013948 (2020). https://doi.org/10.1007/ s10462-019-09682-y 29. Jebli, I., Belouadha, F.-Z., Kabbaj, M.I., Tilioua, A.: Prediction of solar energy guided by Pearson correlation using machine learning. Energy. 224, 120109 (2021). https://doi.org/ 10.1016/j.energy.2021.120109 30. Gonz\u00e1lez, J., Ortega, J., Damas, M., et al.: A new multi-objective wrapper method for feature selection \u2013 accuracy and stability analysis for BCI. Neurocomputing. 333, 407\u2013418 (2019). https://doi.org/10.1016/j.neucom.2019.01.017 31. Alassaf, M., Qamar, A.M.: Improving sentiment analysis of Arabic Tweets by One-way ANOVA. J. King Saud Univ. Comput. Inf. Sci. 34, 2849\u20132859 (2022). https://doi.org/10.1016/ j.jksuci.2020.10.023 32. Urkullu, A., P\u00e9rez, A., Calvo, B.: Statistical model for reproducibility in ranking-based feature selection. Knowl. Inf. Syst. 63, 379\u2013410 (2021). https://doi.org/10.1007/s10115-020-01519-3 33. Bahassine, S., Madani, A., Al-Sarem, M., Kissi, M.: Feature selection using an improved Chi-square for Arabic text classification. J. King Saud Univ. Comput. Inf. Sci. 32, 225\u2013231 (2020). https://doi.org/10.1016/j.jksuci.2018.05.010Self-Reconfiguration for Smart Manufacturing Based on Artificial Intelligence:. . . 14334. Lu, Z., Si, S., He, K., et al.: Prediction of Mg alloy corrosion based on machine learning models. Adv. Mater. Sci. Eng. 2022, 9597155 (2022). https://doi.org/10.1155/2022/9597155 35. Anowar, F., Sadaoui, S., Selim, B.: Conceptual and empirical comparison of dimensionality reduction algorithms (PCA, KPCA, LDA, MDS, SVD, LLE, ISOMAP, LE, ICA, t-SNE). Comput. Sci. Rev. 40, 100378 (2021). https://doi.org/10.1016/j.cosrev.2021.100378 36. Cruz, Y.J., Rivas, M., Quiza, R., et al.: A two-step machine learning approach for dynamic model selection: a case study on a micro milling process. Comput. Ind. 143, 103764 (2022). https://doi.org/10.1016/j.compind.2022.103764 37. Castano, F., Cruz, Y.J., Villalonga, A., Haber, R.E.: Data-driven insights on time-to-failure of electromechanical manufacturing devices: a procedure and case study. IEEE Trans. Ind. Inform, 1\u201311 (2022). https://doi.org/10.1109/TII.2022.3216629 38. Mezzogori, D., Romagnoli, G., Zammori, F.: Defining accurate delivery dates in make to order job-shops managed by workload control. Flex. Serv. Manuf. J. 33, 956\u2013991 (2021). https:// doi.org/10.1007/s10696-020-09396-2 39. Luo, J., Hong, T., Gao, Z., Fang, S.-C.: A robust support vector regression model for electric load forecasting. Int. J. Forecast. 39, 1005\u20131020 (2023). https://doi.org/10.1016/ j.ijforecast.2022.04.001 40. Pai, K.N., Prasad, V., Rajendran, A.: Experimentally validated machine learning frame-works for accelerated prediction of cyclic steady state and optimization of pressure swing adsorption processes. Sep. Purif. Technol. 241, 116651 (2020). https://doi.org/10.1016/ j.seppur.2020.116651 41. Cruz, Y.J., Rivas, M., Quiza, R., et al.: Computer vision system for welding inspection of liquefied petroleum gas pressure vessels based on combined digital image processing and deep learning techniques. Sensors. 20 (2020). https://doi.org/10.3390/s20164505 42. Pan, Y., Chen, S., Qiao, F., et al.: Estimation of real-driving emissions for buses fueled with liquefied natural gas based on gradient boosted regression trees. Sci. Total Environ. 660, 741\u2013 750 (2019). https://doi.org/10.1016/j.scitotenv.2019.01.054 43. Chicco, D., Warrens, M.J., Jurman, G.: The coefficient of determination R-squared is more informative than SMAPE, MAE, MAPE, MSE and RMSE in regression analysis evaluation. PeerJ. Comput. Sci. 7, e623 (2021). https://doi.org/10.7717/peerj-cs.623 44. Eltamaly, A.M.: A novel strategy for optimal PSO control parameters determination for PV energy systems. Sustainability. 13 (2021). https://doi.org/10.3390/su13021008 45. Karagul, K., Sahin, Y., Aydemir, E., Oral, A.: A simulated annealing algorithm based solution method for a green vehicle routing problem with fuel consumption BT - lean and green supply chain management: optimization models and algorithms. In: Weber, G.-W., Huber, S. (eds.) Paksoy T, pp. 161\u2013187. Springer International Publishing, Cham (2019) 46. Cruz, Y.J., Rivas, M., Quiza, R., et al.: Ensemble of convolutional neural networks based on an evolutionary algorithm applied to an industrial welding process. Comput. Ind. 133, 103530 (2021). https://doi.org/10.1016/j.compind.2021.103530 47. Yildiz, A.R.: A novel hybrid whale\u2013Nelder\u2013Mead algorithm for optimization of design and manufacturing problems. Int. J. Adv. Manuf. Technol. 105, 5091\u20135104 (2019). https://doi.org/ 10.1007/s00170-019-04532-1 48. Gao, X., Li, X., Zhao, B., et al.: Short-term electricity load forecasting model based on EMD-GRU with feature selection. Energies. 12 (2019). https://doi.org/10.3390/en12061140 49. Mu, C., Xing, Q., Zhai, Y.: Psychometric properties of the Chinese version of the Hypo-glycemia Fear SurveyII for patients with type 2 diabetes mellitus in a Chinese metropolis. PLoS One. 15, e0229562 (2020). https://doi.org/10.1371/journal.pone.0229562 50. Schaefer, J.L., Nara, E.O.B., Siluk, J.C.M., et al.: Competitiveness metrics for small and medium-sized enterprises through multi-criteria decision making methods and neural networks. Int. J. Proc. Manag. Benchmark. 12, 184\u2013207 (2022). https://doi.org/10.1504/ IJPMB.2022.121599 51. Manimuthu, A., Venkatesh, V.G., Shi, Y., et al.: Design and development of automobile assembly model using federated artificial intelligence with smart contract. Int. J. Prod. Res. 60, 111\u2013135 (2022). https://doi.org/10.1080/00207543.2021.1988750144 Y. J. Cruz et al.52. Zagumennov, F., Bystrov, A., Radaykin, A.: In-firm planning and business processes manage-ment using deep neural network. GATR J. Bus. Econ. Rev. 6, 203\u2013211 (2021). https://doi.org/ 10.35609/jber.2021.6.3(4) 53. Ozbey, N., Yeroglu, C., Alagoz, B.B., et al.: 2DOF multi-objective optimal tuning of disturbance reject fractional order PIDA controllers according to improved consensus ori-ented random search method. J. Adv. Res. 25, 159\u2013170 (2020). https://doi.org/10.1016/ j.jare.2020.03.008 54. Do, B., Ohsaki, M.: A random search for discrete robust design optimization of linear-elastic steel frames under interval parametric uncertainty. Comput. Struct. 249, 106506 (2021). https:/ /doi.org/10.1016/j.compstruc.2021.106506 55. Mamdani, E.H.: Application of fuzzy algorithms for control of simple dynamic plant. Proc. Inst. Electr. Eng. 121, 1585\u20131588 (1974). https://doi.org/10.1049/piee.1974.0328 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Part II Multi-agent Systems and AI-Based Digital Twins for Manufacturing ApplicationsDigital-Twin-Enabled Framework for Training and Deploying AI Agents for Production Scheduling Emmanouil Bakopoulos , Vasilis Siatras , Panagiotis Mavrothalassitis , Nikolaos Nikolakis , and Kosmas Alexopoulos 1 Introduction Production scheduling problems are essential for optimizing manufacturing pro-cesses and ensuring effective resource utilization. In other words, scheduling defines where and when production operations will be performed [1]. The production scheduling aims to optimize resource utilization, minimize the makespan, reduce global setup time, and satisfy customer demands [2]. According to Lawler et al. [3], in the majority of the time, scheduling falls under the category of non-deterministically polynomial (NP) time problems. To address the complex nature of production scheduling problem, advanced techniques have been developed. Some of these techniques are the mathematical optimization models, heuristic algorithms, and machine learning (ML) approaches. Important inputs that the methods above take into account is information as setup matrices, processing times, quantities to be produced, material availability, due dates, technical information, production capabilities of the production lines that such a technique is modelled. Additionally, the use of real-time data from the shop floor and the use of artificial intelligence (AI) techniques can improve adaptability in dynamic manufacturing environments. Moreover, using AI techniques in parallel with real-time data from the shop floor arises new challenges, i.e., real-time decision-making. Digital twin (DT) is a technology that allows real-time monitoring and opti-mization of the physical environment, prosses, or assets [4]. DT is a technology that enables the user to gain insights on the model\u2019s accuracy [5]. Using data from sensors and Internet of Thing (IoT) devices, DT creates a digital replica of the physical environment sharing the same characteristics and interactions of the E. Bakopoulos \u00b7 V. Siatras \u00b7 P. Mavrothalassitis \u00b7 N. Nikolakis \u00b7 K. Alexopoulos (\u0002) Laboratory for Manufacturing Systems & Automation (LMS), Department of Mechanical Engineering & Aeronautics, University of Patras, Rio-Patras, Greece e-mail: alexokos@lms.mech.upatras.gr \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_9147148 E. Bakopoulos et al.physical counterpart [6]. DT have been used in many different domains, including healthcare, urban planning and manufacturing [7]. In a variety of industries, the combination of real-time data and the digital replica of the physical environment promotes the decision-making and allow the industries to continuously improve their performance [8, 9]. Asset Administration Shell (AAS) technology was introduced within the Ref-erence Architecture Model Industry 4.0 (RAMI4. 0) [10] and has become a ground-breaking idea in manufacturing of how assets are managed and used [11]. AAS are standardized models that allow industries to combine the physical assets with their digital counterparts (i.e., machines, production systems, or tools), where AASs provide a framework to control and monitor the physical assets. AI scheduling agents have been used coupled with AAS concept in the literature [9, 12, 13]. Additionally, AI scheduling agents are intelligent autonomous systems that take as an input production system information to plan resource allocation tasks [14]. The AI scheduling agents play an important role due to the fact that they can generate a real-time efficient schedule. Coupled with the AAS and DT technologies, AI scheduling agents can be used for the real-time decision-making or for predictions [14, 15]. Multi-agent system (MAS) are systems that are used to compose many autonomous agents, where these agents interact to each other [15]. MAS provides decentralized and collaborative decision-making, where it allows the collaboration of different agents. Each agent in the MAS has some capabilities, decision-making abilities and takes decisions. MAS is used in order to solve complex problems where one agent is impossible to solve. The idea of dived and conquer is used to divide the problem into subproblems, where each agent solves a subproblem, and provides solutions that are adaptable, robust, and able to handle real-time uncertainties. MAS is also combined with DT, AAS, and AI scheduling agents. In a further analysis, AASs can enable interaction between different agents, where the agents can be models as different assets. The contributions of this work are the use of the DT in order to accurately simulate and validate the AI agents that have been developed, as well as training some of the agents. Moreover, the use of the AAS technology to exchange data between the DT and AI agents within the MAS and finally the developed AI scheduling agents that were developed and modeled based on the bicycle industry\u2019s requirements and challenges. This chapter is organized in four sections, where the first section introduces the concepts of digital twins (DT), Asset Administration Shells (AAS), scheduling problem, and artificial intelligence (AI) applications. In second section are discussed related works. In the third section is explained the proposed MAS framework and explain the optimization tools that have been developed. In the fourth section is described the case study that the proposed framework is implemented. Finally, the last section is the conclusion of this work, where some future works are discussed.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 1492 Related Works The manufacturing sector has experienced an evolution thanks to Artificial Intel-ligence (AI). AI offers innovative methods for increasing productivity, quality, and efficiency [16]. Due to its capacity to handle complicated issues, evaluate big amount of information, and make precise predictions, AI approaches have become utilized more and more in manufacturing. Numerous manufacturing processes, including quality assurance, preventative maintenance, supply chain management, and production scheduling, have benefited from the application of AI approaches [17]. Two of the most important tasks in the industrial sector are production planning and scheduling. For creating effective and efficient production plan or schedule, a variety of strategies, methods, and technologies have been developed and deployed. Production planning comprises considering what to do and how to do something in advance. Scheduling, on the other hand, entails allocating resources or manu-facturing facilities to handle work orders. Effective production scheduling lowers production costs, boosts productivity, and lastly improves customer satisfaction. Due to their capacity to handle complicated scheduling issues and offer precise solutions, artificial intelligence (AI) systems have been gaining prominence in production scheduling. Machine learning (ML) is one of the most frequently used AI approaches [5]. More effective production planning and scheduling algorithms have been created using genetic algorithms, artificial neural networks, and reinforcement learning. Heuristics is one of the approaches to solve the dynamic flexible job-shop scheduling problem [18]. Another popular technique, genetic algorithms, has been utilized in several research to improve production scheduling by describing the issue as a combinatorial optimization issue [19]. Nevertheless, the rise of Industry 4.0 has made ML techniques an attractive alternative to address manufacturing difficulties, due to the availability of data, powerful processing, and plenty of storage capacity. Neural networks and deep learning have gained more attention in recent years [20]. Additionally, reinforcement learning (RL), which uses experience to improve scheduling policies, has been proposed for production scheduling. The scheduling policy is represented in RL as a function that connects the state of the system at the moment with an action [21]. In conclusion, future research may concentrate on combining several AI techniques to develop production scheduling algorithms that are more potent and effective. The digital twin (DT) interest is growing from both an academic and an industry perspective. However, the definition of that concept in the scientific literature lacks distinctiveness. DT provides virtual representations of systems along their lifecycle. Then, decisions and optimizations would be based on the same data, which is updated in parallel with the physical system [22]. DT can be briefly described as a framework or concept that combines the physical and real environment with the digital and virtual one, with the use of novel interconnection methods and technological innovations [23]. This physical to virtual connection for addressing150 E. Bakopoulos et al.real processes and assets to their digital representative ones can be characterized as twinning. One of the main technologies used, in order to realize most of DT implementation approaches, is simulation [24]. As already mentioned, the idea of DT is to build a virtual version of a real system. This replica can be used to simulate and forecast how the physical system will respond to certain situations. Thus, one of the best methods to construct a virtual representation of the physical system seems to be simulation, which enables engineers to test and improve the system before it is built, lowering costs and increasing efficiency. Digital twin and simulation technology are being used more and more frequently in sectors such as manufacturing and aerospace, exhibiting their ability to completely change how complex systems are created and optimized [25]. Furthermore, digital twin implementation methods can support decision-making related to the scheduling task for a production system with potential uncertainties [26]. A crucial aspect for the development of a digital twin is the achievement of a high level of standardization and interoperability with systems outside the digital environment. The digital twin simulates some of the behaviors of the physical environment, and thus requires some kind of seamless information exchange with the physical entities and the information they provide. OPC UA is a standard that can provide standardization in the data exchange between the digital twin and production hardware, achieving real-time monitoring and control, interconnectivity, security, access control, while also data modelling and semantics [27]. The Asset Administration Shell (AAS) could be also used in order to standardize the description and management of assets. The digital twin technology can exchange information with the asset via the establishment of a common information language [28]. In addition, the AAS and OPC UA are complementary standards that can be both used to define the framework and protocol for that communication [29]; it is worth noticing that AAS is a collection of standards, namely IEC 62875, DIN SPEC 91345, IEC 62541 (OPC UA), and RAMI 4.0. In cases where the digital twin composes a higher level system such as a production line, a station, or a production system, it is usually composed of multiple assets and thus AAS models. From the digital twin side, the AAS can be the middleware for exchanging information with the assets or managing their behavior. It is important, however, to highlight that there is no standard way for describing an asset using the AAS; although the metamodel will always be the same, there is a freedom to the different submodels and submodel elements that will be selected in order to describe any different asset. It is thus usual to exploit additional information modelling standards or framework to define the specific components and information structures within the AAS metamodel \u2013 e.g., ISA-88, ISO 22400, and ISA-95. Digital twin is not only about simulating the environment but also taking decisions over the next actions, which can then be used on the physical environment. Simulation on its own cannot address this issue, and AI agents is a way that this challenge can be solved. Multi-agent systems are preferred over centralized software components in cases where the problem is hard enough to be solved from a mono-lithic software component. It is a decentralized approach that breaks the problemDigital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 151into subproblems and each agent has access only to the subproblems compatible with its skills. In the case of production scheduling, this is a useful approach as it enables different types of scheduling problems being solved by different AI methods based on which method best satisfies the requirements. AI is a broad term and in scheduling in particular the most common methods are heuristic, metaheuristic, mathematical optimization, machine learning, reinforcement learning, and policy-making. Mathematical optimization, also referred as mathematical programming, is an optimization model consisted of input sets and parameters, decision variables, constraints/expressions, and the objective function. Based on the constraints and the objectives, the model may be classified as linear, nonlinear, convex, integer, and mixed-integer problem, with different type of algorithms to optimize the objectives. As such, as important as the model, the algorithm that is used in order to find a both feasible and accurate solution is also crucial for the quality of the solution. The algorithms may be exact or heuristic-based, while metaheuristic methods are also popular for various optimization problems. Heuristics have been deployed to solve various production scheduling opti-mization problems. A combination of constructive heuristics and iterated greedy algorithm was used to solve the distributed blocking flowshop scheduling problem (DBFSP) and lead to makespan minimization [30]. Montiel et al. (2017) proposed an approach for the stochastic optimization of mine production schedules with the use of heuristics, implementing iterative improvement by swapping periods and destinations of the mining blocks to create the final solution [31]. Heuristics can also be successfully deployed to optimize the scheduling task, aiming at reducing total energy consumption [32]. J\u00e9lvez et al. (2020) worked for a new hybrid heuristic algorithm to solve the Precedence Constrained Production Scheduling Problem (PCPSP) for an open-pit mining industry [33]. Heuristic and metaheuristic algorithms focus on an intelligent search along the solution space, which does not ensure the quality of the solution, and in complex optimization problems require flexible time delays. Deep learning methods, on the other hand, do not depend on searching the solution space, but rather predicting the solution based on patterns from historical information. Although in most cases the results are guaranteed to be fast, it is not necessarily of high quality. In reality it depends on the deep learning model that was used, the dataset quality and quantity. In some cases, there is also a dataset shortage which makes the problem even more difficult to solve. In practice, researchers may address this problem via the utilization of a system digital replica which is able to simulate the behaviors of the actual system in a realistic manner. This can support the development of either reinforcement learning methods that use the simulation as a reward retrieval plugin or for extracting artificial dataset that can then be used in supervised learning models to learn and adapt to the actual system implementation. Especially, deep reinforcement learning has showed great potential in recent years in dealing with complex scheduling optimization problems. Researchers have focused on the implementation of deep reinforcement learning techniques for production scheduling-related problems where there is lack of data, and the problem appears152 E. Bakopoulos et al.high complexity. The Job-Shop Scheduling Problem (JSSP) is one of the most common optimization problems related to production scheduling that the scientific community has tried to solve with the application of deep reinforcement learning. Zhang et al. (2020) developed a deep reinforcement learning agent, able to select priority dispatch rules to solve the JSSP [19]. Liu et al. (2020) followed a similar deep reinforcement learning approach to solve both the static and dynamic JSSP [34]. Rather than only solving the JSSP, there have been also solutions for the optimization of the whole production system with the use of deep Q-learning, a very popular deep reinforcement learning technique in the last decade [35]. While all the technologically innovative techniques have helped to develop smarter and more efficient systems and tools, these solutions could also be integrated in an efficient way in the actual production system through a digital twins (DT) and can help in integrating such solution to increase productivity. Villalonga et al. (2021) proposed a framework for dynamic scheduling with the use of digital twins to represent actual production assets in order to enhance decision-making [36]. Zhang et al. (2021) use the digital twin concept to gather real-time data from the shop floor and realize an effective dynamic production scheduling [37]. To achieve real-time decision-making, the implementation of a digital twin appears a great potential, since uncertain and dynamic events are addressed effectively. Dynamic interactive scheduling method can be enhanced and strengthened by the use of DT [26, 38]. However, digital twin concept can also be implemented to support production scheduling in an offline mode, such as the offline simulation of a production system. This gives the ability to train scheduling agents in more dynamic environments and respond to uncertainties even when they have not yet been identified. Nevertheless, a main challenge in implementing production scheduling solutions and digital twins is the lack of a well-defined data model. A solution to this issue can be offered by the Asset Administration Shell (AAS) concept. AAS is basically a method to represent data in a defined architecture [13, 39]. While in other problems there is some effort made by the literature to implement AAS concept, in production scheduling it is not explored. The need to explore and address well-defined standards for production opti-mization agents is clearly revealed when there is a need for cooperation between different production agents, in order to formulate a multi-agent system. Researchers from a variety of fields have given multi-agent systems (MASs) a great deal of attention as a way to break down complicated problems into smaller jobs. Individual tasks are assigned to agents, which are autonomous entities. Using a variety but well-defined inputs, each agent chooses the most appropriate plan of action to complete the task [40]. Agents make decisions based on the information provided in the environment they are integrated and choose their actions proactively or reactively [41]. In manufacturing, multi-agent systems have gathered attention of many researchers during recent years. MAS can limit the complexity of order scheduling in production systems through a cooperative multi-agent system for production control optimization [42]. A similar approach was followed for the implementation decentralized scheduling algorithms in a test-bed environment [43]. A scheduling strategy to assist a manufacturing system experiencing learning andDigital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 153forgetting was supported by a multi-agent system to carry out the scheduling tasks in conventional production systems in close to real-time, and a simulation was utilized for validation [44]. While the multi-agent systems implementation methods have been explored in recent years, further investigation to address challenges is required. For example, the use of standards in a scheduling multi-agent system is something crucial, in order to develop systems that could be easily transformed to a \u201cplug & play\u201d application. In addition, agents that control or implement different applications and software should follow a hierarchical implementation to achieve better multi-agent system utilization and agents\u2019 distribution. Lastly, if external applications are controlled through a multi-agent system functionality, Application Programming Interface (API) and standards are almost inevitable for the proper scheduling MAS integration for the actual production system. The implementation of the scheduling multi-agent system proposed in this work addresses the aforementioned issues and gives the opportunity for a more flexible implementation of scheduling algorithms, with different functionalities and heterogenous optimization techniques. 3 Multi-Agent System Framework 3.1 System Architecture The architecture presented in Fig. 1 merges numerous Industry 4.0 technologies within a single framework with the goal of creating quality decision-making support for the production manager in his/her daily tasks. Specifically, there is used a (1) user interface for production manager interaction, (2) a multi-agent system for decentralized production scheduling, (3) a production digital twin for performance validation, and (4) Asset Administration Shell concept for the description of production information and agents as assets within the I4.0 environment. The first aspect of the proposed framework is defining the information exchange mechanisms and the corresponding information model to pass data over the different components. This is one of the interoperability issues associated with enterprise software as it is usual to utilize different information format and structures for the same information context. In this architecture the AAS is used in order to represent production information, such as work orders, process plan, and production resources. However, AAS is a metamodel, and although it may specify some abstract modelling objects and interaction mechanisms, it does not specify the detailed model to be used for the description of the asset. In other words, there could be more than one AAS descriptions for the same asset, structuring differently the same asset components and behaviors. To this end, there is a whole other topic of choosing the \u201cright\u201d information model for describing the production data so that it is achieved standardization over the information exchange. However, this is not within the154 E. Bakopoulos et al.Fig. 1 Framework Architecture of all modules and their interactions scope of this framework, and although the AAS is used for exchanging information between ERP software and the agents, the underlying model is not standardized. As displayed in Fig. 1, information from the enterprise resource planning (ERP) are described within AASs for the corresponding work orders that the manager is called to satisfy within the following production period. This type of information is restored from the user interface (UI), allowing the user (in this case the production manager) review the workload of the upcoming days. The connection between the AAS and the ERP is performed via an ERP-to-AAS connector so that the proposed UI platform depends on the AAS model rather than the specific ERP information model structure. The UI rather than visualization of production information, it is also an enabler for interaction of the user with the MAS as well as the production digital twin. It is important to highlight that, unlike other systems, the integration of decision-making results to the actual system is not a trivial task. In practice human interferences is required to review and apply the production plan. The exchange of information between the UI and the MAS is achieved via a MAS API, which is in practice a way of passing and receiving data regarding the production workload and status. The MAS is responsible for handling the data and provide scheduling decisions for the user given the current production scenario. There are multiple AI agents that were developed to address this problem each one giving its own benefits for the user. The reason for using more than one agent for a scheduling problem arises due to complexity of the problem, the user requirements, as well as the problem itself. Scheduling problems are widely diverse with respect to the environment, constraints, objectives, and equivalently the optimization methods are usually compatible with a small portion of the overall set of scheduling problems available. To this end, there cannot be a monolithic approach capable of addressing all production scheduling problems without lacking on satisfying the user requirements. In order to address this issue, there was proposed the concept of a meta-scheduling agent, which in practice was a compound of multiple AI scheduling agents each one providing different optimization attributes.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 155Fig. 2 MAS implementation based on the AAS description for the agent, showing interaction between agents and services/schedulers as well as the agent spawn procedure The AAS was developed for the description of agent, which was retrieved by the MAS framework in order to deploy the corresponding entities and bring the algorithms to life. The AAS model for the meta-agent was consisted of a toolbox of optimization methods, with the description of connection dependencies as well as capabilities and skills provided by the specific method. During the initialization, there were spawned individual entities within the MAS, each one carrying a specific set of skills (operations) corresponding to the AAS operations. It is important to highlight though that the deployment of the agent within the MAS with the actual algorithm runtime may differ. Specifically, the MAS is operating within a single framework, which is usually a local installation of all the partial components, and in this case the deployment of the algorithms is better to be remote. Figure 2 illustrates this aspect for an example case of a scheduling agent. It can be displayed that a scheduling agent AAS may contain more than one scheduling methods, which are spawned as individual agents within the MAS framework. On top of that a meta-scheduling agent is spawned within this framework in order to support the scheduler selection and orchestration process within the MAS. The scheduling algorithms, however, may be deployed in different remote servers depending on the case. While a scheduling operation is requested from one of the schedulers, the AAS interfaces support the communication between the agent installation and the actual algorithm. In the previous architecture, it is important to clarify the need for the meta-agent as well as the requirement for generating multiple agent entities within the MAS framework. In essence, the notion of an agent, as an independent156 E. Bakopoulos et al.entity, is useful when there is achieved some kind of communication within a network of agents. This type of communication is achieved usually via a MAS framework implementation, which allows all the messages exchange and events to be broadcasted between the inner entities seamlessly. As such, a MAS framework facilitates the interaction between the agents; however, the implementation of the agent logic does not have to be within the same software component as the MAS. This is because, usually the MAS is a unique software component with all of its agents and events operating within the same software container. It thus makes sense not to include complex computational process (such as scheduling) within the same resources. To this end, the actual optimization processes are kept aside from the agent interfaces within the MAS. However, the reason that the scheduling agent AAS that contains multiple scheduling methods is not spawned within the single agent in the MAS is dues to easier management of the different scheduling operations. Although this is most of a design decision, it is easier to distribute a network of agents, each one responsible for a specific scheduling method, because on the contrary side, all scheduling requests independent of method selection would flow through the same agent, making it less efficient to work with two different scheduling requests in parallel. The meta-agent is thus present to support the selection of the algorithm based on the scheduling problem and allocate the optimization process to the different agents. In practice, this specific agent is aware of the different scheduling methods available within the system and is capable to analyze the request before selection. In order to accurately assign the scheduling problems to the scheduling algo-rithms, there were used a problem classification method based on three notations: environment, constraints, and objectives. This notation method is widely used in the description of scheduling problems and has the ability to classify any type of problem. The environment expresses the production system equipment and process flow, the constraints express the job-related characteristics or specific equipment/buffer requirements, while the objectives have to do with the criteria that the scheduler need to optimize. The following are some examples for each case: \u2022 Environment: job shop, flexible job shop, parallel machines, single machine, flow shop, flexible flow shop, conveyor line, batch machine (e.g., oven), and so on. \u2022 Constraints: job release time, block (no buffer capacity before the machine), deadline, sequence-dependent setup time, recirculation, stochastic processing time, and so on. \u2022 Objectives: makespan, flowtime, tardiness, energy consumption, and so on. In order to classify the problem based on these notations in an automatic way, the meta-agent was enriched with different rules (per characteristic per notation) in order to check whether the specific type of problem complies with these conditions. For example, identifying a Job Shop schedule has to contain exactly one route per product and no alternatives. As a results, in cases that the agent was given with a schedule request that did not specify the type of scheduler to use, these rules were applied and the scheduler that complied with the rules was selected. In some cases,Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 157Fig. 3 Simulation model of the wheels assembly department utilized as a digital twin to apply the schedule outcome from the MAS and observe performance more than one scheduler would comply with the rules and more than one responses may be produced. It is also important to highlight that within a request there was used a specific information structure for providing the production data and similarly the scheduling outputs were contained within a specific scheduling response. The structure of the information may vary based on the implementation and thus it was not specified within this section. There are different alternative standards also to be used, while in some cases a specific ERP data model could be also utilized. In any case, this is another important aspect that is not specified within the chapter. However, the methodology remains the same, with the exception that the problem classification should be applied to a different model. The digital twin was the final component of the architecture and ensured that information is validated in a close-to-reality scenario and the system performance is approved by the user. The production schedule was received by the MAS and then sent (on-demand) to the digital twin in order to calculate its performance (see Figs. 3 and 4). This step was executed before the schedule was displayed in detail to the user as there could be one of multiple competitive schedules available for a single case from different schedulers. The reason for using a digital representation of the production system was to give the ability to the user to evaluate the resulted schedule.158 E. Bakopoulos et al.Fig. 4 Simulation model of the painting department utilized as a digital twin to apply the schedule outcome from the MAS and observe performance 3.2 Paint Shop Scheduling Agents 3.2.1 Mathematical Optimization The paint shop scheduling agents were designed in order to be able to give solution to the Paint Shop Scheduling Problem (PSSP) as it can be found in the literature. This problem addresses the sequence of the items entering the painting line of the factory in order to optimize the performance indicators. This problem is different from other scheduling problems as it usually encounters higher detail in the combination of items and sorting before entering the line. The line itself is usually a moving conveyor of carriers with some specific spatial constraints, setup delays due to color, and a constant speed. The objective is to find the optimal combination of the items within the \u201cbill of material\u201d of the products and sequence them in order to comply with the desired performance. Figure 5 illustrates the PSSP in a simplistic way. As it can be seen the goal is to create a schedule \u2013 sequence and combination of items \u2013 for entering the painting line so as to create the maximum utilization of the line, which will reflect in reducing the makespan for the system. There are some requirements, however, that the decision-making system needs to comply with in order to be in line with the physical characteristics of the system. The following aspects were taken into consideration: \u2022 The conveyor speed is constant and the carriers are equally spaced along the line. This ensures that the input and output rate of the line is also constant.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 159Fig. 5 PSSP graphical representation \u2022 Each carrier has a unique capacity (100%) similar of all the carriers that cannot be exceeded. \u2022 Items with different color cannot be placed within the same carrier. This is because in most cases the items are painting all together within the painting cabins. \u2022 In cases where two consecutive colors are placed within the line there should be a setup delay, expressed in empty carriers so that the operators have the time to setup the new color. \u2022 Each item type occupies a specific percentage of the carrier and can be mixed with others as long as the max capacity is not violated. \u2022 In cases where an item cannot fit into one container/carrier, then it will be used the next consecutive carrier in order to hold the remaining capacity of the item. It is made the exception, however, that no item needs more capacity than two carriers. Based on the proposed conversions, the following mathematical formulation can be created: Sets: P Set of production orders that need to be painted I Set of different items (types) that need to be painted C Set of color codes Parameters: qp, i Quantity of items i \u2208 I included in production order p \u2208 P, qp, i \u2208 Z\u22650 ci Capacity a carrier required in order to carry item i \u2208 I; ci \u2208 R>0 dp, p\u2019 Setup delay required between the items of two different production orders (p, p\u2019 ) \u2208 P, dp, p\u2019 \u2208 Z\u22650 Auxiliary variables: si Defines whether item i \u2208 I has a size higher than one carrier, si \u2208 {0, 1} ac, t Defines whether this color c \u2208 C has entered the line on time t \u2208 Z\u22650, ac, t \u2208 {0, 1} ep, t Defines whether this item i \u2208 I has entered the line on time t \u2208 Z\u22650, ep, t \u2208 {0, 1} Decision variable:160 E. Bakopoulos et al.xp, i, t The number of items i \u2208 I from product p \u2208 P that will enter the line on time t, xp, i, t \u2208 Z\u22650, Counters: nt Number of timesteps available in the schedule ni Number of item types in I-set np Number of products in P-set nc Number of colors in C-set Constrains: First, in a feasible schedule, we need to ensure that all items enter the resource exactly once at some point during production time. This can be covered from the following linear equality: . \u221e\u2211t=0xp,i,t = qp,i \u2022 (1 + si) ,\u2200p \u2208 P,\u2200i \u2208 I. Number of constrains : np\u2217 niLimitation for not allocating into the same carrier more than the items that can hold based on its capacity can be achieved via the following inequality: . \u2211\u2200p\u2208P\u2211\u2200i\u2208Ici \u2022(1 \u2212 si 12)\u2022 xp,i,t \u2264 1,\u2200t \u2208 Z\u22650. Number of constrains : ntIn addition, for cases when items require more than one carrier, it needs to be placed in two consecutive carriers. This can be ensured by the following nonlinear expression: . N\u2211t=0\u2211\u2200p\u2208P\u2211\u2200i\u2208Isi(xp,i,t \u2022 xp,i,t+1) \u2265 1. Number of constrains : 1In order to transition to the linear version of the above expression, we start from the logical expression: . (xp,i,t > 0) \u2227 (xp,i,t+1 > 0) \u2228 (xp,i,t\u22121 > 0)Then, we define two auxiliary variables to carry the outputs of the above logical expressions:Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 161. zp,i,t =(xp,i,t+1 > 0) \u2228 (xp,i,t\u22121 > 0). yp,i,t =(xp,i,t > 0) \u2227 zp,i,tThen, we use the linear expressions for \u2227 and \u2228 operators: . zp,i,t \u2265 xp,i,t+1zp,i,t \u2265 xp,i,t\u22121zp,i,t \u2264 xp,i,t+1 + xp,i,t\u22121yp,i,t \u2264 xp,i,typ,i,t \u2264 zp,i,typ,i,t \u2265 xp,i,t + zp,i,t \u2212 1\u23ab\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ac\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23aa\u23ad\u2200p \u2208 P,\u2200i \u2208 I,\u2200t \u2208 Z\u22650 | si > 0. Number of constrains : 6nt\u2217 np\u2217 niIn addition, when changing color between subsequence items the setup delay must be applied. This can be achieved by the following linear inequalities: . ac,t \u2265\u2211\u2200p\u2211\u2200i(xp,i,t \u2022 fp,c)\u2211\u2200p\u2211\u2200i qp,i,\u2200t \u2208 [0,Z\u22650],\u2200c \u2208 C. ac,t + ac\u2019,t\u2019 \u2264 1 +\u2223\u2223t \u2212 t '\u2223\u2223dc,c' + 1\u2200(c, c') \u2208 C,\u2200t \u2208 Z\u22650,\u2200t ' \u2208[t, t + dc,c'] | c /= c'. Number of constrains : nc\u2217 nt + nt\u2217 (delay)\u2217 (nc \u2013 1)2The same constraint can be achieved via the following nonlinear equation: . N\u2211t=0\u239b\u239dac,t \u2022t+dc,c'\u2211t\u2019=t(1 \u2212 ac\u2019,t\u2019)\u239e\u23a0 = 0,\u2200 (c, c') \u2208 C | c /= c'. Number of constrains : (nc \u2013 1)2Objective function: Ltotal The total flowtime of the production: . Ltotal =\u221e\u2211t=0(t \u2022 ac,t)Lweighted The total weighted flowtime of the painting line:162 E. Bakopoulos et al.. Lweighted =\u221e\u2211t=0\u2211\u2200i\u2208I(t \u2022 wp \u2022 ep,t). where xp,i,t \u2264 qp,i \u2022 ep,t ,\u2200p \u2208 P,\u2200i \u2208 I,\u2200t \u2208 Z\u22650\u03bbi, k The output (production) rate for an item type in a specific interval can be defined as a moving average in the series of allocations for an item: . \u03bbi,k =\u2211(k+1)Lt=k L\u2211\u2200p\u2208P xp,i,tL, k = 0, 1, 2, .., ntFigure 5 shows where the requirements for this objective come from, and what implications could come from missing to apply this objective. It is clear that in this example, missing to produce the items at the average rates that are departed from the buffer afterwards will cause an overflow, and in this case it is illustrated that the circle needs to be at a much slower output rate than the cube item. The ways that this can be applied are more than one, specifically the user may require this to be a constrain to the scheduler, by means that at no times this rate is exceeded, which can be applied by the next inequality, or via the objective function trying to approach a specific value, yet this does not necessarily ensure that this value will not deviate in the final results. . \u03bbi,k \u2264 \u03bbdesiredi , k = 0, 1, 2, .., N,\u2200i \u2208 I. min{\u2211\u2200i\u2208I\u221e\u2211k=0(\u03bbi,k \u2212 \u03bbdesiredi)2}The above mathematical formulation is a very complex optimization problem to solve for a real-scale production problem. As shown in the results section, real-scale industrial problems may require scheduling up to 20,000 items from different orders, colors, and types, making the problem extremely difficult to solve in a considerably short time frame. Thus, following the previous mathematical formulation, three different versions were formed, each utilizing the expressions presented above differently. \u2022 The first model is the nonlinear version (MINLP) of the problem, which applies the nonlinear inequality constraints presented above. This allows lower number of constrains (thus lower memory utilization), but a very complex solution space that most of the times requires more sophisticated optimization algorithms and more demanding computational delay.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 163Fig. 6 Actual diagram from example case displaying the CPU delay differences of the modeling approaches as the number of orders increase \u2022 The linear version (MILP) was also considered where only the linear constrains are utilized, improving the computational demand but increasing the require-ments for memory utilization in computational resources. \u2022 The last one was a simpler form of the linear version (two-stage MILP) in which constrain #4 is removed from the model, running the optimization only for mixing the items of order that acquire the same color. This allows a much faster response horizon, since there were no setup constrains to apply in the schedule. In a second stage, once the allocation of items is achieved, the optimization process is repeated, but this time it schedules the sequence of colors as a function of minimizing the setup delay. In this way, the model manages to reduce the solutions space and the constrains limitations. The problem with this model, however, is that it decreases the flexibility of the solution as a trade-off for lower CPU time because it is not capable of providing good solutions for the production rate issue. In Fig. 6, the implications of the different models on the CPU duration of the computational resources is clearly shown. The graphs are in a logarithmic scale in the Y-axis and is clearly shown that both MILP and MINLP cannot outperform the simplified-MILP, which can cover up to a very high number of items (100 orders are usually 18,000 items) in a relatively short period of time (20 min). Indices: Discrete sets: np, ni, nc, nt Decision variables: np 2 + ni (np + 1) Input variables: np 2 + ni (np + 1)164 E. Bakopoulos et al.Fig. 7 Input layer (vector) encoding mechanism displaying an example for how the tables are reshaped into a single dimensional vector Fig. 8 Output layer (vector) encoding mechanism displaying the output can be encoded into the allocation per product per item type per timestep Auxiliary variables: ni + nt (ni + nc) Constrains: np ni + 6nt ni np + nc nt + nt d (nc + 1) 3.2.2 Data-Driven Optimization In order to avoid this long CPU delays and demanding RAM utilization, the utilization of data-driven (i.e., ML) approaches was investigated in order to rather predict the output of the scheduler. First, a feed-forward neural network (FFNN) was developed, which uses as an input information over the workload data (i.e., orders, items, colors, and sizes), as well as produces the sequence of orders/items allocated into the painting line. The input layer to the model was based on the same parameters that were used for the mathematical formulation of MIP models, resulting in the following encoded input vector (. x), while also the decision variable xp,i,t was described the output vector (. y) (Figs. 7 and 8):Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 165. x = [(( (q [p] [i] \u2200i \u2208 I ) , (f [p] [c] \u2200c \u2208 C) )\u2200p \u2208 P) , c [i] , d [c] [c']]. y = [x [\u2200p] [\u2200i] [\u2200t]]. Lx = pmaximax + pmaxcmax + imax + (cmax)2. Ly = imax tmax pmax. Lx and . Ly shown in the above equation represent the dimensions of the input and output layers, respectively. In contrast to the model-based methodologies, neural networks are consisted of a static number of I/O parameters, which contradicts to the arbitrary scale of the scheduling problems. In order to address this issue, the encoded input considers a prefixed maximum number of orders (pmax), items (imax), color codes (cmax), and production duration (tmax). For cases where less than this maximum number is provided as an input, the encoder generates additional orders so as to fulfil the I/O layers of the neural network (NN) although sets the items quantity to zero, which will have no effect on the allocation process; for cases with more than the maximum numbers, the model is unable to encode the input. The number of neurons per layer and the total number of trainable parameters for the whole NN model are provided by the following formula: . neurons# = 2kLx. params# =\u2211\u2200k:layer[2kLx(2k\u22121Ly + 1)]Another data-driven approach has been developed that treats the scheduling output as a time series from which the next allocations can be predicted based on known previous values of the sequence. As such, the whole production schedule can be generated in a recursive manner, reducing the model\u2019s prediction variables which improves the accuracy as well as avoiding any limitations regarding the problem\u2019s scalability. Similar to the above-mentioned approach, the ultimate objective is the prediction of xp,i,t, for all the given orders, items, and timesteps; however, in this model a prediction is only applied for one timestep and is repeated for all the output sequence. The input features of the LSTM neural network consist of a dynamic and a static part. The dynamic part as presented below are the features that change as moving in the time axis. The allocation of all items over a specific timestep (carrier) is given by the following vector: .x [ti] = [x [\u2200p] [\u2200i] [ti]] , ti \u2208 N166 E. Bakopoulos et al.Fig. 9 Overview of LSTM RNN I/O layers design and how the specific input is derived as well as how the output is represented The following defines a variable that provides the number of remaining items of an order at that given timestep, given the sequence of previous allocation selections: . Q [p] [i] [ti] = q [p] [i] \u2212ti\u2211t=0x [p] [i] [t]Given the above formula, the following vector is defined: . Q [ti] = [Q [\u2200p] [\u2200i] [ti]] , ti \u2208 NMoreover, similar to the feed-forward NN model, some static information of the workload revealing the colors, sizes, and setup delays must also be provided. The final configuration of the input layer is shown in Fig. 9. Figure 9 presents the format of the I/O model, which is required for the LSTM model. Unlike MIP models, this method arises a problem in defining the first allocations (.x [0 : L]) as it requires historical information of a window (L), which are not defined as the face a totally new schedule request. This problem is more apparent in the training procedure as multiple scheduling results from different workloads merged together into a single sequence to train the LSTM model. This issue was addressed by adding L number of timesteps in the beginning of each schedule, where L is the window of previous allocations that the model is using for the prediction. These timesteps contained zero allocations of items and were responsible only for fulfilling the input layer of the LSTM neural network model (Fig. 10).Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 167Fig. 10 Each graph (row) shows the total number of allocations from a product over time. Each graph contains two lines for display purposes 3.3 Deep Reinforcement Learning Scheduling Agent The deep reinforcement learning (DRL) agent was selected to solve the dynamic scheduling problem (DSP). According to Chien and Lan [45], the DSP is susceptible to a number of uncertainties, including machine failures, the arrival of new, urgent jobs, and changes to job due dates. In the literature there are several articles on the DSP [46\u201349]. DRL agent is also combined with DNNs and deep Q-network to approximate of a state action value function [50, 51]. The proposed DRL agent is combined with a discrete event simulator in order for training and testing the DRL model. In details, the DES that was used is the Witness Horizon from Lanner [52]. The DRL and DES communicated via API, where the API is provided by Witness Horizon. In addition, except from API files, text files were used to exchange data among the DES and DRL (see Fig. 11). The concept that was used for the DRL agent is to purpose task allocation to resources via the use of dispatch rules. In the literature there are several research works that study the use of RL agent combined with dispatch rules [53].168 E. Bakopoulos et al.Fig. 11 DRL agent operation architecture The Q-learning is an off-policy temporal difference algorithm and is based on the idea of Q-function [54]. In the following equation, the Q\u03c0 (st, at) is the expected return of the discounted sum of rewards at state st by taking action at: . Q\u03c0 (st , at ) = max\u03c0E[rt+1 + \u03b3 rt+2 + \u03b3 2 rt+3 + . . . |st = s, at = a, \u03c0]The main concept of the Q-learning is to use the Bellman equation as a value iteration update. The agent in a decision point t in a state st \u2208 S selects an action at \u2208 A according to a policy \u03c0 . Taking the action at the agent gets to a state st + 1 with transition probability p(st + 1|st, at) \u2208 P(S \u00d7 A \u2192 S) and reward rt \u2208 R. Additionally, \u03b3 is a discount factor at each timestep t. Also,  a is a learning rate, where 0 < a \u2264 1. The objective for the agent is to find the optimal policy \u03c0 \u2217 that maximizes the expected sum of rewards. The Q-leaning has some limitations when the environment is huge. For that reason, the deep Q-network (DQN) concept was used. Coupled RL with deep learning techniques Q-tables can be replaced with Q-function approximator with weights [55]. In order to solve the DSP problem, due to the fact that the environment is huge, DRL DQN concept was used. Let us denote as Q(s, a; \u03b8 i) the approximate value using deep convolutional neural network. Additionally, the \u03c8 i are the weights at iteration i of the Q-network. The experiences are denoted as et = (st, at, rt, st + 1) where each time t are stored to a  dataset Dt = {e1, . . . , et}. Chosen uniformly at random an instance from the pool of stored instances, a Q-learning update is applied of each experience (s, a, r, s')~U(D). . Li (\u03b8i) = E(s,a,r,s')\u223cU(D)[(r + \u03b3 maxa'Q(s', a'; \u03b8\u2212i) \u2212 Q(s, a; \u03b8i))2]\u03b8 i are the weights of the Q-network at the iteration i and .\u03b8\u2212i are the network weights used to compute the target in iteration i. Target network parameters (. \u03b8\u2212i ) are  updated with the Q-network parameters every c step, where c is a constant number.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 169The state is a tuple of feature that characterizes a given input. This chapter contains the stats of the resources (down, busy, and available), the stats of the tasks (waiting, pending, on-going, and finished), and finally a list with the quantities or the product orders. Moreover, an action describes the dispatch rule that is selected by the DRL agent to propose the task allocation over resources. 3.4 Heuristic Optimization The hierarchical scheduler is a decision-making module for extracting an efficient order of required tasks [56]. The problem that the scheduler solves is the resource allocation problem [57], where the problem seeks to find an optimal allocation of a discrete resource units to a set of tasks. The heuristic algorithm is based on the scientific research of [58]. It is based on the depth of search concept, except the number of layers for which the search method looks ahead. The main control parameters are the decision horizon (DH), the sampling rate (SR), and the maximum number of alternatives (MNA). In each decision point, a decision tree is created based on the DH, SR, and MNA. Figure 12 shows the nodes A1 . . .  . AN that represents decision point where a task is assigned to an operator. The proper selection of MNA, DH, and SR allows the identification of a good solution. For example, it is proven in [59] that the probability of identifying an alternative of good quality (i.e., utility value within a range \u0394 with respect to the highest utility value) is increasing with the MNA and \u0394. The pseudocode of the algorithm is defined as follows [60]: Fig. 12 Search methodology example in tree-diagram showing the generation of different branches and layers based on the MNA, DH, and SR170 E. Bakopoulos et al.Algorithm: Three adjustable parameters, MNA, SR, DH Initialize: MNA, SR, DH while full schedule is not generated Generate MNA-alternative-branches of allocations for DH-steps in the future. for each branch in alternatives: Generate SR sub-branches of allocations from DH-step and for-ward. Calculate average score of SR sub-branches on each MNA branch. Select alternative with the highest score. Store allocations of the alternative for up to DH-steps return: best alternative For each decision tree, the algorithm returns a list with valid task-resource allocations [61\u201364]. MNA and DH control the breadth and DH the depth of the search, respectively. On the other hand, SR is used to direct the search toward alternatives that can provide better quality solutions. Thus, the quality of the solution depends on the selection of the MNA, DH, and SR. 4 Case Study The proposed multi-agent scheduling framework was implemented, validated, and evaluated for a case study from the bicycle production industry. For this work and the deployment of AI scheduling agents in a production environment capable of producing optimized long- or short-term scheduling, two departments were chosen: painting and wheels assembly department. As already mentioned, there were different types of scheduling agents. The purpose of using a multi-agent system for the deployment of various scheduling applications is twofold. The first reason is that with the realization of a multi-agent system, one can use an integrated solution without affecting the other entities of the production system. An algorithm can be developed separately, as a stand-alone application in a multi-agent system. The second reason is that with a multi-agent system, there is the possibility for automated cooperation between different applications to coordinate multiple assets or functionalities. To combine both benefits of a multi-agent system capable of solving different scheduling problems and combine its assets to solve more than one scheduling problems at one, the implementation method proposed in this work follows the deployment of different scheduling algorithms integrated in a multi-agent system.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 171The multi-agent system for the scheduling agents was developed with the use of JANUS, an efficient and flexible agent-oriented programming framework that gives the opportunity for easy and fast deployment of virtual assets. JANUS multi-agent system framework is compatible with the programming language SARL and also with JAVA. In this multi-agent system, there are four main concepts that need to be defined before the deployment of any agent: agents, events, capacities, and skills. The agent instance stands for all the operating sequences required for a specific batch of functionalities and operations to happen when the agent needs to operate. Agents\u2019 communication and behavior is controlled by events, which are predefined patterns that allow all the agents in the framework to interact one with another. The term capacity refers to an abstract description for an implementation in skills, which is used to define reusable capabilities of agent patterns without defining implementation details. Lastly, the concept of skills is a manner of implementing a capability, which allows exchange and modification of implementations based on own or adapted skills without modifying the agent\u2019s behavior or the template agent\u2019s characteristics. To address the scheduling multi-agent system using the JANUS framework, the scheduling agents are modeled as agents in the JANUS framework, capable of spawning and operating under the control of a meta-agent, which is the orchestrator agent inside the multi-agent system. The scheduling agents have specific skills, related to the problem-solving algorithm and the meta-agent concept was integrated, in order to realize an automated and distributed cooperation of the different agents inside the multi-agent system, when there is a scheduling request. The user is able to interact with the multi-agent system in the backend of a UI, developed for the scheduling tasks visualization. In practice, the meta-agent receives the scheduling request from the UI. This scheduling request is modeled in an AAS, as already described in previous sections, and the meta-agent is able to spawn the corresponding scheduling agent to solve a particular scheduling problem. A scheduling agent is the parent \u201cclass\u201d in JANUS that implements events, skills, and methods, and can also consist of local variables. Each one of the scheduling agents accommodated three MAS events: \u2022 \u201cInitialization,\u201d where the scheduling agent has been spawned by the meta-agent during the initialization of the framework and waits for a scheduling request notification from the meta-agent. During the initialization of the agent, specific scheduling agent parameters are defined and initialized, able to serve a specific scheduling request type in the future. \u2022 \u201cScheduling request,\u201d where the meta-agent is requested to notify the corre-sponding scheduling agent in order for the required scheduling computation to be performed. After this event call, specific skills and operations are performed by a scheduling agent in order for the scheduling algorithm to calculate the schedule. \u2022 \u201cSchedule response,\u201d where the output of the scheduling task is emitted to all other agents of the multi-agent system. When the scheduling agent finishes its operation, the event notices every other agent in the framework that can listen to this event.172 E. Bakopoulos et al.When a scheduling request reaches the multi-agent system, the meta-agent is responsible for identifying the correct scheduler based on the request from AAS. This AAS also contains information that, in addition to the scheduling task infor-mation, will indicate the required scheduling agent, which is capable of performing the scheduling task based on some predefined characteristics. After the scheduling request, the meta-agent performs simple filtering in the provided information in the AAS to choose the corresponding scheduling agent. Each scheduling agent has its own input format. Since the JANUS meta-agent is responsible for the orchestration of the scheduling task, it will pass the information to the appropriate scheduling agent capable of performing the correct algorithm to compute the schedule. As it was mentioned above, the reason for realizing a multi-agent system is that a scheduler can be developed as a stand-alone application. Hence, to give the ability to each scheduling agent to perform its scheduling skills without the development of the algorithmic part inside the multi-agent system framework, interfaces were utilized to perform the scheduling algorithms through the scheduling agents\u2019 skills. Moreover, a REST API was used for the agents to be able to reach out the scheduler\u2019s endpoint and pass information to the algorithm. On the other hand, since there is not a certain point in time that the resulted response is expected, RabbitMQ message exchange channel was utilized for the scheduler\u2019s responses. Of course, this is a design decision, and other protocols can be used to pass information around the different entities. In the case study, three different scheduling agents were implemented in the multi-agent system, each one with its own characteristics and functionalities. To validate the aforementioned multi-agent system implementation, the schedulers developed and utilized were the following: (1) heuristic multi-objective scheduling framework, (2) mixed integer programming (MIP) model optimizer for production scheduling [65], and (3) a deep reinforcement learning (DRL) scheduler for dynamic production scheduling. The first two agents were utilized to solve the scheduling problem for the painting department of the bicycle industry, while the third one was utilized to solve the scheduling problem of the wheels assembly department. The first two agents were deployed with the goal of optimizing the scheduling sequence of a painting line. The DRL agent was deployed with the goal of solving the dynamic scheduling problem of a production system with uncertainties included. The scheduling agents were deployed in the multi-agent system to support the scheduling task of the bicycle production system. Nevertheless, since the application should be used by a production manager in an industrial environment, a UI was required. The UI was developed with the scope to showcase the scheduling task with all the mandatory assets in an efficient and user-friendly manner. The UI consists of the scheduling task formulation tab, where the production manager selects the orders that need to be scheduled and chooses the corresponding scheduler. There is also a feature where the user can run all the supported schedulers and compare the results before one actually can apply the schedule in the real production system. Results are shown in another tab, and this is a common table for the scheduled production orders. In addition, there is the opportunity for the user to show some productionDigital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 173Fig. 13 UI multi-agent system tab KPIs through the digital twin tab where a DES run of the resulted scheduling is performed. To validate the whole framework performance, discrete event simulation (DES) was utilized. Two DES models were developed, representing the production envi-ronments of the two departments from a bicycle production system. These DES models were used to showcase the results of the scheduling request that the multi-agent framework handled, as well as for the actual operation of the agent for solving the dynamic scheduling problem. The heuristic and the MIP schedulers were deployed for the painting department whereas the DRL scheduler was deployed for the wheels assembly department. JANUS multi-agent system spawned all three scheduling agents when the necessary information for accessing them is provided within the AAS definition after the scheduling request formulated in the UI. As such, the user could choose any of the scheduling agents and, using the toolbox of schedulers provided in the UI, address similar or different kinds of problems. The user sent scheduling operations to the multi-agent system in an abstract manner without the need to specify the corresponding problem. After the scheduling request arrival, the meta-agent was responsible to spawn the required scheduling agent. Seamless integration between the SARL software and the individual schedulers was achieved. The resulted framework implementation showed great potential in achieving multi-agent scheduling optimization. The UI (Figs. 13 and 14) allows the user to evaluate the resulted scheduling through the use of DES. Production KPIs are presented and through the evaluation of the system performance on each occasion, one can decide if the resulting schedule is efficient. Manual tests were made in collaboration with the production manager, and the results were validated for their accuracy and precision. Hence, the proposed scheduling multi-agent system implementation for the bicycle production industrial environment can effectively handle the workload distribution among its different scheduling agents in order to propose the most appropriate production sequence. Table 1 summarizes the agent results from testing the framework over some real-life examples of the industrial use-case. The results do not directly translate on174 E. Bakopoulos et al.Fig. 14 UI digital twin tab business KPIs and are the log from the schedulers. This is why the digital twin component is necessary to reflect how these solutions fit into the overall production scenario and inspect the performance. 5 Conclusion In conclusion, the multi-agent system (MAS), digital twin (DT), Asset Administra-tion Shell (AAS) concept, and artificial intelligence (AI) technology are part of the Industry 4.0, and more and more researchers and industrial experts aim to combine these technologies. Digital manufacturing is an important step for industries and researchers, where there are many gaps and challenges to overcome. Digitalization will enable automation, increase efficiency, real-time decision-making, flexibility, and adaptability in industries. This work proposes a MAS framework that was developed for the bicycle industry using the concept of AAS, DT, and MAS for the production scheduling problem. A mathematical optimization, deep reinforcement learning, heuristic algorithm, and deep learning algorithm have been developed to address the identified problems. The key contribution of this work is the use of the DT to accurately simulate the production environment and increase the efficiency of the developed AI agents. The AAS concept is also used to guarantee interoperable data transfer within MAS. Future research directions could be considered the continuous exploitation of the DT and AI integrations. Moreover, the AAS technology was used to fully parameterize the agents and the production environment on the simulator. Acknowledgments This work has received funding from the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No. 957204 MAS4AI. The dissemination of results herein reflects only the authors\u2019 view, and the Commission is not responsible for any use that may be made of the information it contains.Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 175Table 1 Table with results from the different agents used to solve the use-case scheduling problems Assignments no. (average) LevelOptimization plugin OrdersItems Reaction time (min) (average)Options Performance (average) Resource (painting line) Conveyor scheduler (simple MILP, Gurobi) 9818,500222[Cores] 12 [Threads] 5% [MIP Gap] 8000 [Hangers] Resource (painting line) Conveyor scheduler (MILP, Gurobi) 121500712[Cores] 32 [Threads] 7% [MIP Gap] 700 [Hangers] Resource (painting line) Conveyor scheduler (MINLP, Gurobi) 1215001802[Cores] 32 [Threads] 7% [MIP Gap] 700 [Hangers] Resource (painting line) Conveyor scheduler (FFNN) 202000020 [p max], 16 [imax], 1000 [tmax], 20 [cmax] 1000 [Hangers] 27 [Constrain Violations] Resource (painting line) Conveyor scheduler (LSTM RNN) 509000050 [p max], 16 [imax], 50[c max] 5000 [Hangers] 5 [Constrain Violations] Resource (preparation) Factory scheduler8000 [Tasks]700.4% [MNA], 0.15% [SR], 2 [DH] 70% [Utility] Resources (assembly lines) Department scheduler 50 [Orders], 1000 [Jobs], 2500 [Tasks]21 shift [DH]\u22127% [Makespan] 70\u201375% [Utilization]176 E. Bakopoulos et al.References 1. Chryssolouris, G.: The design of manufacturing systems. In: Manufacturing Systems: Theory and Practice, pp. 329\u2013463 (2006). https://doi.org/10.1007/0-387-28431-1_5 2. Rodammer, F.A., White, K.P.: A recent survey of production scheduling. IEEE Trans. Syst. Man Cybern. 18(6), 841\u2013851 (1988). https://doi.org/10.1109/21.23085 3. Lawler, E.L., Lenstra, J.K., Rinnooy Kan, A.H.G., Shmoys, D.B.: Chapter 9 Sequencing and scheduling: algorithms and complexity. In: Handbooks in Operations Research and Management Science, vol. 4, no. C, pp. 445\u2013522 (1993). https://doi.org/10.1016/S0927-0507(05)80189-6 4. Tao, F., Zhang, H., Liu, A., Nee, A.Y.C.: Digital twin in industry: state-of-the-art. IEEE Trans. Industr. Inform. 15(4), 2405\u20132415 (2019). https://doi.org/10.1109/TII.2018.2873186 5. Alexopoulos, K., Nikolakis, N., Chryssolouris, G.: Digital twin-driven supervised machine learning for the development of artificial intelligence applications in manufactur-ing. Int. J. Comput. Integr. Manuf. 33(5), 429\u2013439 (2020). https://doi.org/10.1080/ 0951192X.2020.1747642 6. Jiang, Y., Yin, S., Li, K., Luo, H., Kaynak, O.: Industrial applications of digital twins. Phil. Trans. R. Soc. A. 379(2207) (2021). https://doi.org/10.1098/RSTA.2020.0360 7. Enders, M., Enders, M.R., Ho\u00dfbach, N.: Dimensions of digital twin applications-a lit-erature review completed research. Accessed 16 June 2023. [Online]. Available: https:// www.researchgate.net/publication/359715537 8. Rasheed, A., San, O., Kvamsdal, T.: Digital twin: values, challenges and enablers from a modeling perspective. IEEE Access. 8, 21980\u201322012 (2020). https://doi.org/10.1109/ ACCESS.2020.2970143 9. Park, K.T., Son, Y.H., Ko, S.W., Do Noh, S.: Digital twin and reinforcement learning-based resilient production control for micro smart factory. Appl. Sci. 11(7), 2977 (2021). https:// doi.org/10.3390/APP11072977 10. Plattform Industrie 4.0 - Reference Architectural Model Industrie 4.0 (RAMI4.0) - an introduction. https://www.plattform-i40.de/IP/Redaktion/EN/Downloads/Publikation/rami40-an-introduction.html. Accessed 16 June 2023. 11. Wei, K., Sun, J.Z., Liu, R.J.: A review of Asset Administration Shell. In: IEEE International Conference on Industrial Engineering and Engineering Management, pp. 1460\u20131465 (2019). https://doi.org/10.1109/IEEM44572.2019.8978536 12. Arm, J., et al.: Automated design and integration of Asset Administration Shells in components of Industry 4.0. Sensors. 21(6), 2004 (2021). https://doi.org/10.3390/S21062004 13. Wagner, C., et al.: The role of the Industry 4.0 asset administration shell and the digital twin during the life cycle of a plant. In: IEEE International Conference on Emerging Technologies and Factory Automation, ETFA, pp. 1\u20138 (2017). https://doi.org/10.1109/ETFA.2017.8247583 14. Cavalieri, S., Salafia, M.G.: A model for predictive maintenance based on Asset Administration Shell. Sensors. 20(21), 6028 (2020). https://doi.org/10.3390/S20216028 15. Ocker, F., Urban, C., Vogel-Heuser, B., Diedrich, C.: Leveraging the Asset Administration Shell for agent-based production systems. IFAC-PapersOnLine. 54(1), 837\u2013844 (2021). https:/ /doi.org/10.1016/J.IFACOL.2021.08.186 16. Chryssolouris, G., Alexopoulos, K., Arkouli, Z.: Artificial intelligence in manufacturing systems. Stud. Syst. Decis. Control. 436, 79\u2013135 (2023). https://doi.org/10.1007/978-3-031-21828-6_4/COVER 17. De Simone, V., Di Pasquale, V., Miranda, S.: An overview on the use of AI/ML in manufactur-ing MSMEs: solved issues, limits, and challenges. Proc. Comput. Sci. 217, 1820\u20131829 (2023). https://doi.org/10.1016/J.PROCS.2022.12.382 18. Shahgholi Zadeh, M., Katebi, Y., Doniavi, A.: A heuristic model for dynamic flexible job shop scheduling problem considering variable processing times. Int. J. Prod. Res. 57(10), 3020\u2013 3035 (2018). https://doi.org/10.1080/00207543.2018.1524165Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 17719. Chen, X., An, Y., Zhang, Z., Li, Y.: An approximate nondominated sorting genetic algorithm to integrate optimization of production scheduling and accurate maintenance based on reliability intervals. J. Manuf. Syst. 54, 227\u2013241 (2020). https://doi.org/10.1016/J.JMSY.2019.12.004 20. Essien, A., Giannetti, C.: A deep learning model for smart manufacturing using convolutional LSTM neural network autoencoders. IEEE Trans. Industr. Inform. 16(9), 6069\u20136078 (2020). https://doi.org/10.1109/TII.2020.2967556 21. Wang, L., Pan, Z., Wang, J.: A review of reinforcement learning based intelligent optimization for manufacturing scheduling. Compl. Syst. Model. Simul. 1(4), 257\u2013270 (2022). https:// doi.org/10.23919/CSMS.2021.0027 22. Negri, E., Fumagalli, L., Macchi, M.: A review of the roles of digital twin in CPS-based production systems. Proc. Manuf. 11, 939\u2013948 (2017). https://doi.org/10.1016/ J.PROMFG.2017.07.198 23. Jones, D., Snider, C., Nassehi, A., Yon, J., Hicks, B.: Characterising the digital twin: a systematic literature review. CIRP J. Manuf. Sci. Technol. 29, 36\u201352 (2020). https://doi.org/ 10.1016/J.CIRPJ.2020.02.002 24. Boschert, S., Rosen, R.: Digital twin-the simulation aspect. In: Mechatronic Futures: Chal-lenges and Solutions for Mechatronic Systems and Their Designers, pp. 59\u201374 (2016). https:// doi.org/10.1007/978-3-319-32156-1_5/COVER 25. Bot\u00edn-Sanabria, D.M., Mihaita, S., Peimbert-Garc\u00eda, R.E., Ram\u00edrez-Moreno, M.A., Ram\u00edrez-Mendoza, R.A., de Lozoya-Santos, J.: Digital twin technology challenges and applica-tions: a comprehensive review. Remote Sens. 14(6), 1335 (2022). https://doi.org/10.3390/ RS14061335 26. Negri, E., Pandhare, V., Cattaneo, L., Singh, J., Macchi, M., Lee, J.: Field-synchronized digital twin framework for production scheduling with uncertainty. J. Intell. Manuf. 32(4), 1207\u20131228 (2021). https://doi.org/10.1007/S10845-020-01685-9/FIGURES/16 27. Jhunjhunwala, P., Atmojo, U.D., Vyatkin, V.: Applying skill-based engineering using OPC-UA in production system with a digital twin. In: IEEE International Symposium on Industrial Electronics (2021, June). https://doi.org/10.1109/ISIE45552.2021.9576342 28. Fuchs, J., Schmidt, J., Franke, J., Rehman, K., Sauer, M., Karnouskos, S.: I4.0-compliant inte-gration of assets utilizing the Asset Administration Shell. In: IEEE International Conference on Emerging Technologies and Factory Automation, ETFA, pp. 1243\u20131247 (2019, Sept). https:// doi.org/10.1109/ETFA.2019.8869255 29. Pribi\u0161, R., Ben\u030co, L., Draho\u0161, P.: Asset Administration Shell design methodology using embedded OPC unified architecture server. Electronics. 10(20), 2520 (2021). https://doi.org/ 10.3390/ELECTRONICS10202520 30. Chen, S., Pan, Q.K., Gao, L.: Production scheduling for blocking flowshop in distributed environment using effective heuristics and iterated greedy algorithm. Robot. Comput. Integr. Manuf. 71, 102155 (2021). https://doi.org/10.1016/J.RCIM.2021.102155 31. Montiel, L., Dimitrakopoulos, R.: A heuristic approach for the stochastic optimization of mine production schedules. J. Heuristics. 23(5), 397\u2013415 (2017). https://doi.org/10.1007/S10732-017-9349-6/FIGURES/17 32. Aghelinejad, M.M., Ouazene, Y., Yalaoui, A.: Production scheduling optimisation with machine state and time-dependent energy costs. Int. J. Prod. Res. 56(16), 5558\u20135575 (2017). https://doi.org/10.1080/00207543.2017.1414969 33. J\u00e9lvez, E., Morales, N., Nancel-Penard, P., Cornillier, F.: A new hybrid heuristic algorithm for the precedence constrained production scheduling problem: a mining application. Omega (Westport). 94, 102046 (2020). https://doi.org/10.1016/J.OMEGA.2019.03.004 34. Liu, C.L., Chang, C.C., Tseng, C.J.: Actor-critic deep reinforcement learning for solving job shop scheduling problems. IEEE Access. 8, 71752\u201371762 (2020). https://doi.org/10.1109/ ACCESS.2020.2987820 35. Waschneck, B., et al.: Optimization of global production scheduling with deep reinforcement learning. Proc. CIRP. 72, 1264\u20131269 (2018). https://doi.org/10.1016/J.PROCIR.2018.03.212 36. Villalonga, A., et al.: A decision-making framework for dynamic scheduling of cyber-physical production systems based on digital twins. Annu. Rev. Control. 51, 357\u2013373 (2021). https:// doi.org/10.1016/J.ARCONTROL.2021.04.008178 E. Bakopoulos et al.37. Zhang, M., Tao, F., Nee, A.Y.C.: Digital twin enhanced dynamic job-shop scheduling. J. Manuf. Syst. 58, 146\u2013156 (2021). https://doi.org/10.1016/J.JMSY.2020.04.008 38. Fang, Y., Peng, C., Lou, P., Zhou, Z., Hu, J., Yan, J.: Digital-twin-based job shop scheduling toward smart manufacturing. IEEE Trans. Industr. Inform. 15(12), 6425\u20136435 (2019). https:// doi.org/10.1109/TII.2019.2938572 39. Inigo, M.A., Porto, A., Kremer, B., Perez, A., Larrinaga, F., Cuenca, J.: Towards an Asset Administration Shell scenario: a use case for interoperability and standardization in industry 4.0. In: Proceedings of IEEE/IFIP Network Operations and Management Symposium 2020: management in the Age of Softwarization and Artificial Intelligence, NOMS 2020 (2020, April). https://doi.org/10.1109/NOMS47738.2020.9110410 40. Dorri, A., Kanhere, S.S., Jurdak, R.: Multi-agent systems: a survey. IEEE Access. 6, 28573\u2013 28593 (2018). https://doi.org/10.1109/ACCESS.2018.2831228 41. Cardoso, R.C., Ferrando, A.: A review of agent-based programming for multi-agent systems. Computers. 10(2), 16 (2021). https://doi.org/10.3390/COMPUTERS10020016 42. Dittrich, M.A., Fohlmeister, S.: Cooperative multi-agent system for production control using reinforcement learning. CIRP Ann. 69(1), 389\u2013392 (2020). https://doi.org/10.1016/ J.CIRP.2020.04.005 43. Egger, G., Chaltsev, D., Giusti, A., Matt, D.T.: A deployment-friendly decentralized scheduling approach for cooperative multi-agent systems in production systems. Proc. Manuf. 52, 127\u2013132 (2020). https://doi.org/10.1016/J.PROMFG.2020.11.023 44. Renna, P.: Flexible job-shop scheduling with learning and forgetting effect by multi-agent system. Int. J. Ind. Eng. Comput. 10(4), 521\u2013534 (2019). https://doi.org/10.5267/ J.IJIEC.2019.3.003 45. Chien, C.F., Bin Lan, Y.: Agent-based approach integrating deep reinforcement learning and hybrid genetic algorithm for dynamic scheduling for industry 3.5 smart production. Comput. Ind. Eng. 162, 107782 (2021). https://doi.org/10.1016/J.CIE.2021.107782 46. Mohan, J., Lanka, K., Rao, A.N.: A review of dynamic job shop scheduling techniques. Proc. Manuf. 30, 34\u201339 (2019). https://doi.org/10.1016/J.PROMFG.2019.02.006 47. Wen, X., Lian, X., Qian, Y., Zhang, Y., Wang, H., Li, H.: Dynamic scheduling method for integrated process planning and scheduling problem with machine fault. Robot. Comput. Integr. Manuf. 77, 102334 (2022). https://doi.org/10.1016/J.RCIM.2022.102334 48. Yan, Y., Wang, Z.: A two-layer dynamic scheduling method for minimising the earliness and tardiness of a re-entrant production line. Int. J. Prod. Res. 50(2), 499\u2013515 (2011). https:// doi.org/10.1080/00207543.2010.543171 49. Muhamadin, K., Bukkur, M.A., Shukri, M.I., Osama, Elmardi, M.: A review for dynamic scheduling in manufacturing. Type: Double Blind Peer Reviewed Int. Res. J. Publ. Glob. J. Online. 18, 25 (2018) 50. Hu, L., Liu, Z., Hu, W., Wang, Y., Tan, J., Wu, F.: Petri-net-based dynamic scheduling of flexible manufacturing system via deep reinforcement learning with graph convolutional network. J. Manuf. Syst. 55, 1\u201314 (2020). https://doi.org/10.1016/J.JMSY.2020.02.004 51. Chang, K., Park, S.H., Baek, J.G.: AGV dispatching algorithm based on deep Q-network in CNC machines environment. Int. J. Comput. Integr. Manuf. 35(6), 662\u2013677 (2021). https:// doi.org/10.1080/0951192X.2021.1992669 52. WITNESS Simulation Modeling Software | Lanner. https://www.lanner.com/en-gb/ technology/witness-simulation-software.html. Accessed 16 Jun 2023. 53. Zhang, C., Song, W., Cao, Z., Zhang, J., Tan, P.S., Chi, X.: Learning to dispatch for job shop scheduling via deep reinforcement learning. Adv. Neural. Inf. Proc. Syst. 33, 1621\u20131632 (2020) 54. Mnih, V., et al.: Asynchronous methods for deep reinforcement learning. PMLR, 1928\u2013 1937 (2016) Accessed 16 June 2023. [Online]. Available: https://proceedings.mlr.press/v48/ mniha16.html 55. Mnih, V., et al.: Human-level control through deep reinforcement learning. Nature. 518(7540), 529\u2013533 (2015). https://doi.org/10.1038/nature14236Digital-Twin-Enabled Framework for Training and Deploying AI Agents for. . . 17956. Kousi, N., Koukas, S., Michalos, G., Makris, S.: Scheduling of smart intra \u2013 factory material supply operations using mobile robots. Int. J. Prod. Res. 57(3), 801\u2013814 (Feb. 2018). https:// doi.org/10.1080/00207543.2018.1483587 57. Katoh, N., Ibaraki, T.: Resource allocation problems. In: Handbook of Combinatorial Opti-mization, pp. 905\u20131006 (1998). https://doi.org/10.1007/978-1-4613-0303-9_14 58. Chryssolouris, G., Dicke, K., Lee, M.: On the resources allocation problem. Int. J. Prod. Res. 30(12), 2773\u20132795 (2007). https://doi.org/10.1080/00207549208948190 59. Chryssolouris, G., Papakostas, N., Mourtzis, D.: A decision-making approach for nesting scheduling: a textile case. Int. J. Prod. Res. 38(17), 4555\u20134564 (2010). https://doi.org/10.1080/ 00207540050205299 60. Michalos, G., Makris, S., Mourtzis, D.: A web based tool for dynamic job rotation scheduling using multiple criteria. CIRP Ann. 60(1), 453\u2013456 (2011). https://doi.org/10.1016/ J.CIRP.2011.03.037 61. Lalas, C., Mourtzis, D., Papakostas, N., Chryssolouris, G.: A simulation-based hybrid back-wards scheduling framework for manufacturing systems. Int. J. Comput. Integr. Manuf. 19(8), 762\u2013774 (2007). https://doi.org/10.1080/09511920600678827 62. Kousi, N., Michalos, G., Makris, S., Chryssolouris, G.: Short \u2013 term planning for part supply in assembly lines using mobile robots. Proc. CIRP. 44, 371\u2013376 (2016). https://doi.org/10.1016/ J.PROCIR.2016.02.131 63. Michalos, G., Fysikopoulos, A., Makris, S., Mourtzis, D., Chryssolouris, G.: Multi criteria assembly line design and configuration \u2013 An automotive case study. CIRP J. Manuf. Sci. Technol. 9, 69\u201387 (2015). https://doi.org/10.1016/J.CIRPJ.2015.01.002 64. Alexopoulos, K., Koukas, S., Boli, N., Mourtzis, D.: Resource planning for the installation of industrial product service systems. IFIP Adv. Inf. Commun. Technol. 514, 205\u2013213 (2017). https://doi.org/10.1007/978-3-319-66926-7_24/FIGURES/5 65. Siatras, V., Nikolakis, N., Alexopoulos, K., Mourtzis, D.: A toolbox of agents for scheduling the paint shop in bicycle industry. Proc. CIRP. 107, 1156\u20131161 (2022). https://doi.org/10.1016/ j.procir.2022.05.124 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.A Manufacturing Digital Twin Framework Victor Anaya, Enrico Alberti, and Gabriele Scivoletto 1 Introduction 1.1 Definition, Usages, and Types of Digital Twins The manufacturing industry is continuously evolving, and digital twin (DT) technol-ogy has become a prominent driving force in this transformation. DTs play a crucial role in optimizing manufacturing processes, increasing productivity, and enhancing product quality. A digital twin (DT) is a digital representation of a physical entity or process modeled with the purpose to improve the decision-making process in a safe and cost-efficient environment where different alternatives can be evaluated before implementing them. The digital twin framework (DTF) for manufacturing is a set of components for making and maintaining DTs, which describe the current state of a product, process, or resource. DTs have pace momentum due to their seamless integration and collaboration with technologies such as IoT, machine learning (ML) algorithms, and analytics solutions. DTs and ML solutions benefit in a bidirectional way, as DTs simulate real environments, being a source of data for training the always data-eager ML algorithms. DTs are a source of data that would be costly to acquire in other conditions such as private data tied to legal and ethical implications, data labeling, complex data cleaning, abnormal data, or data gathering that require intrusive V. Anaya (\u0002) Information Catalyst SL, Xativa, Spain e-mail: victor.anaya@informationcatalyst.com E. Alberti \u00b7 G. Scivoletto Nextworks SRL, Pisa, Italy e-mail: e.alberti@nextworks.it; g.scivoletto@nextworks.it \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_10181182 V. Anaya et al.processes. In the other direction, ML models are a type of simulation technique that can be used to simulate processes and other entity behaviors for the DT. Some of the algorithms that can be used for simulation are deep learning neural networks, time-series-based algorithms, and reinforcement learning. DTs are not specific software solutions, but they are a range of solutions that support the improvement of physical products, assets, and processes at different levels and different stages of the lifecycle of those physical assets [3]. Therefore, in the manufacturing domain, DTs can have different scopes such as [1] the  following: 1. Process level\u2014recreates the entire manufacturing process. Plant managers use process twins to understand how the elements in a plant work together. Process DT can detect interaction problems between processes at different departments of a company. 2. System level\u2014monitors and improves an entire production line. System-level DTs cover different groups of assets in a specific unit and can be used for understanding and optimizing assets and processes involved in the production of a specific product [12]. 3. Asset level\u2014focuses on a single piece of equipment or product within the production line. Asset DTs can cover cases such as the optimization of energy consumption, the management of fleet performance, and the improvement of personnel assignment based on skills and performance. 4. Component level\u2014focuses on a single component of the manufacturing process, such as an item of a product or a machine. Component-level twins help to understand the evolution and characteristics of the modeled component, such as the durability of a drill or the dynamics of a fan. The creation of a digital copy of a physical object offers significant advantages throughout its entire life cycle [4]. This includes the design phase, such as product design and resource planning, as well as the manufacturing phase, such as production process planning and equipment maintenance. Additionally, during the service phase, benefits include performance monitoring and control, maintenance of fielded products, and path planning. Finally, during the disposal phase, the digital replica can facilitate end-of-life reuse, remanufacturing, and recycling efforts. A DL framework is a toolkit that allows developers the creation of specific DT instances, and as such is a complex system composed of several tools such as data gathering and synchronization platforms, multi-view modelers, simulator engines, what-if analytic reporting, and vast integration capabilities. Data collection is a crucial aspect of feeding a digital twin in the manufacturing industry. To ensure the accuracy and reliability of the DT\u2019s representation, a robust and efficient data collection platform is essential. Such platforms must possess certain characteristics to meet the requirements of flexibility, availability, and support manufacturing communication protocols, while also ensuring efficiency and security. The data collection platformmust have the ability to adapt to different types of data inputs, including sensor readings, machine data, process parameters, and environmental variables. This adaptability enables comprehensive data gathering,A Manufacturing Digital Twin Framework 183capturing a holistic view of the manufacturing process and all its interconnected elements. Ensuring availability is essential for a data collection platform to be effective. Manufacturing operations typically operate continuously, demanding a constant flow of real-time data. The platform should guarantee uninterrupted data acquisition, seamlessly handling substantial data volumes promptly. It should offer dependable connectivity and resilient infrastructure to prevent data gaps or delays, thereby maintaining synchronization between the DT and its physical counterpart. To connect to a range of devices, machines, and systems, support for manufactur-ing communication protocols is crucial. Networked devices that adhere to specific protocols are often utilized in production environments. The data collection platform should therefore be able to interact via well-established protocols like OPC-UA1 , MQTT2 , or Modbus3 . Rapid data transfer, synchronization, and seamless integration are all made possible by this interoperability throughout the production ecosystem. Finally, security is of utmost importance in data collection for DTs. Manu-facturing data often includes sensitive information, trade secrets, or intellectual property. The data collection platform must implement robust security measures, including encryption, access controls, and data anonymization techniques, to protect the confidentiality, integrity, and availability of the collected data. This ensures that valuable manufacturing knowledge and insights remain protected from unauthorized access or malicious activities. The rest of this chapter is organized as follows: in the next subsection, we explain DT usages in the manufacturing sector. In Sect. 2, we present the digital twin framework. In Sect. 3, we present the case study and the methodology to experimentally evaluate the proposed method. In Sect. 4, we discuss the conclusion. 1.2 Digital Twin in Manufacturing Digital twin technology has a wide range of applications in manufacturing, includ-ing predictive maintenance, quality management, supply chain management, and customer experience. This technology can help predictive maintenance break-through data fatigue and turn data into a competitive advantage [7]. By monitoring equipment data in real time, the DT can predict equipment failures before they occur, reducing downtime and increasing productivity. In a study, DTs of well-functioning machines were used for predictive maintenance, and the discrepancies between each physical unit and its DT were analyzed to identify potential issues before they become critical [8].1 OPC Unified Architecture. https://opcfoundation.org/about/opc-technologies/opc-ua/ 2 MQTT. https://mqtt.org/ 3 Modbus. https://modbus.org/ 184 V. Anaya et al.\u2022 Predictive Maintenance and Process Optimization: DTs enable manufacturers to monitor equipment performance and predict potential failures or malfunctions, leading to timely maintenance and reduced downtime. Additionally, DTs can optimize manufacturing processes by simulating different scenarios and identi-fying bottlenecks and inefficiencies [9]. \u2022 Quality Control and Inspection: DTs can play a critical role in quality control and inspection processes in manufacturing. By creating a virtual replica of the manufactured product, DTs can detect deviations from the desired specifications and suggest corrective actions to ensure optimal quality [10]. Additionally, DTs can help in automating inspection processes, reducing human error, and increasing efficiency [11]. \u2022 Production Planning and Scheduling: By simulating the production environment, DTs can assist in creating optimized production schedules and plans, considering various constraints such as resource availability, lead times, and capacity utiliza-tion [13]. DTs can also support real-time adjustments to the production plan, allowing manufacturers to adapt to unforeseen events or disruptions [14]. \u2022 Workforce Training and Skill Development: The integration of DT technology in manufacturing can facilitate workforce training and skill development. By simulating the production environment and processes, DTs enable workers to practice and enhance their skills in a virtual setting, reducing the learning curve and minimizing the risk of errors during real-world operations. Furthermore, DTs can provide personalized training and feedback based on individual performance, promoting continuous improvement [15]. \u2022 Supply Chain Integration and Visibility: DTs can enhance supply chain inte-gration and visibility in manufacturing by providing real-time information and analytics about various aspects of the supply chain, such as inventory levels, lead times, and supplier performance [16]. This increased visibility enables better decision-making and collaboration among supply chain partners, ultimately improving the overall efficiency and responsiveness of the supply chain. 2 knowlEdge Manufacturing Digital Twin Framework 2.1 Digital Twin Standardization Initiatives There are many articles referencing potential DT architectures, which provide different forms of naming for the main components and layers of the DT architecture [2, 5, 6]. Most of those DT architectures summarize a DT from a mathematical point of view as a five-dimensional model defined as follows [4]: .DT = F (PS,DS,P2V,V2P,OPT) (1)A Manufacturing Digital Twin Framework 185where DT refers to digital twin, that is expressed as a function (F) aggregating: the physical system (PS), the digital system (DS), an updating engine that synchronizes the two words (P2V), a prediction engine that runs prediction algorithms (V2P), and an optimization dimension containing optimizers (OPT). One of the most relevant initiatives to standardize a DT\u2019s main building blocks is the one proposed by ISO 23247 [17] comprising a DT framework that partitions a digital twinning system into layers defined by standards. The framework is based on the Internet of Things (IoT) and consists of four main layers: \u2022 Observable Manufacturing Elements: This layer describes the items on the manufacturing floor that need to be modeled. Officially, it is not part of the framework, as it already exists. \u2022 Device Communication Entity: This layer collates all state changes of the observable manufacturing elements and sends control programs to those elements when adjustments become necessary. \u2022 Digital Twin Entity: This layer models the DTs, reading the data collated by the device communication entity and using the information to update its models. \u2022 User Entities: User entities are applications that use DTs to make manufacturing processes more efficient. They include legacy applications like ERP and PLM, as well as new applications that speed up processes. On the other hand, the Digital Twin Capabilities Periodic Table (CPT) [16] is a  framework developed by the Digital Twin Consortium to help organizations design, develop, deploy, and operate DTs based on use case capability requirements. The CPT is architecture and technology agnostic, meaning it can be used with any DT platform or technology solution. The framework clusters capabilities around common characteristics using a periodic-table approach: The CPT framework clusters capabilities into the following main clusters: \u2022 Data Management: This cluster includes capabilities related to data access, ingestion, and management across the DT platform from the edge to the cloud. \u2022 Modeling and Simulation: This cluster includes capabilities related to the creation of virtual models and simulations of real-world entities and processes. \u2022 Analytics and Artificial Intelligence: This cluster includes capabilities related to the use of analytics and artificial intelligence to analyze data and generate insights. \u2022 Visualization and User Interface: This cluster includes capabilities related to the visualization of digital twin data and the user interface used to interact with the DT \u2022 Security and Privacy: This cluster includes capabilities related to the security and privacy of DT data and systems \u2022 Interoperability and Integration: This cluster includes capabilities related to the integration of DT systems with other systems and the interoperability of DT data with other data sources. ISO 23247 and the Digital Twin Capabilities Periodic Table are generic frame-works that are worth taking into consideration when developing a digital twin186 V. Anaya et al.framework because they provide a consistent and structured approach to digital twin implementation. Section 2.3 presents the alignment carried out between the knowlEdge Digital Twin Framework and the ISO 23247. 2.2 knowlEdge Digital Twin Framework The knowlEdge DT framework is a toolkit solution composed of a set of modeling, scheduling, visualization, analysis, and data gathering and synchronization compo-nents that is capable to create instances of manufacturing digital twins at different scopes and phases of the product, process and asset lifecycle. The components composing the solution (see Fig. 1) are described as follows: \u2022 Sensor Reader Interface: This interface is composed of the set of field protocols needed for connecting the pilots\u2019 sensors to the knowlEdge Data Collection Platform [18]. The interface has to be aware of the details of the protocols in terms of networking, configuration, and specific data model. \u2022 Sensor Protocol Adapter: Once one data has been read, the sensor protocol adapter can distinguish whether the data is meaningful for the Data Collection Platform or has to be collected and presented as raw data. \u2022 Unified Data Collector: The module is responsible to add the semantic to the lower-level object and make them available to the upper level. \u2022 Data Model Abstractor: The Data Model Abstractor unifies the different infor-mation models that depend on the specific field protocol to hide that information when the data is presented to the real-time broker. \u2022 Data Ingestion: This interface is responsible for offering different mechanisms to communicate with the DTs\u2019 framework, such as MQTT or REST API services. \u2022 Platform Configurator: The platform configurator exposes a REST API for the configuration of all the internal and external modules. Examples of configura-tions are the topic where the platform publishes the data, the configuration of the platform when a new sensor is been plugged into the system, its information model, etc. \u2022 DT Designer UI Interface: \u2013 DT Domain Model UI: this is the UI interface that allows an IT person or a skilled operator to define the DT domain data model, that is, the digital assets containing the model, with their features and to assign to them their behavior and its graphical representation. This UI will provide subsections to specify simulation services. \u2013 DT Visual Editor: this component allows to edit 3D elements that will be used to animate 3D visualization when needed. \u2022 DT UI Interface: It is the end-user UI set of interfaces used for running simulations and visualizing results through reports.A Manufacturing Digital Twin Framework 187Fig. 1 Digital twin framework architecture \u2022 DT User View Backend: It is the backend engine that according to the decision view of the digital twin can represent the different widgets (indicators, tables, 3D view) that were defined in design time. \u2022 Digital Domain Model Manager: This is the main backend of the DT. It is in charge to create new DT instances based on data model definitions and connect them to existing simulators and other AI algorithms (such as reinforcement learning for production scheduling, neural networks for simulating the energy consumption of manufacturing machines). Domain Data Models contain the digital entities that will be part of the digital twin model, that is, the machines, resources, places, and people. The Digital Domain Model Manager will support the decomposition of digital elements in their parts through trees, and their connection with the physical objects through the knowlEdge real-time brokering component. \u2022 DT Data Aggregator: It is the backend component in charge of maintaining the DT model synchronized with the physical counterparts and offering APIs with188 V. Anaya et al.the rest of the components of the architecture. One of its components is the context broker, which is based on the FIWARE Stellio Context Broker4 . \u2022 3D Visualization Engine: This component can render 3D scenes of the simula-tions when a design is provided. Their results can be embedded into dashboards used by the operators when running simulations. \u2022 Behavior Manager: This component is in charge of keeping a linkage with endpoints of the algorithms that define the behavior of digital things, for instance, a linkage to the knowlEdge HP AI component that provides a REST API to the repository of knowledge AI algorithms that are to be tested using the DT. This subcomponent is also in charge of keeping a repository of linkages to simulators and other algorithms through a REST API that can be third-party solutions provided by external providers. The behavior manager has a scheduler engine that runs simulations according to time events or data condition rules that are executed against the DT model that is being filled with data from the IoT devices. 2.3 knowlEdge Digital Twin Framework Alignment with Current Initiatives The importance of aligning the knowlEdge DT framework to the ISO 23247 standard on DTs cannot be overstated. The ISO 23247 series defines a framework to support the creation of DTs of observable manufacturing elements, including personnel, equipment, materials, manufacturing processes, facilities, environment, products, and supporting documents. Aligning the knowlEdge DT framework to the ISO 23247 standard can help ensure that the framework follows recognized guidelines and principles for creating DTs in the manufacturing industry. The following are the specific blocks of the ISO 23247 standard that have been aligned to the knowlEdge DT framework: \u2022 The knowlEdge DT has considered the terms and definitions provided by ISO 23247 standard to ensure that the framework is consistent with the standard. \u2022 The knowlEdge DT provides many of the ISO 23247\u2019s functional entities (see Fig. 2, where the different colors are used to emphasize which functional entity from the ISO 23247 is covered by each functional block of the knowlEdge DT). It supports all the ISO 23247 functional entities based on the rest of the components provided by the knowlEdge project. This ensures that the framework meets the needs of the manufacturing industry. \u2022 The knowlEdge DT provides a Graphical DT Domain Data Modeler Editor that has been customized with the ISO 2347 Observable Manufacturing Elements, so users define the digital things using the exact terminology of the standard,4 https://stellio.readthedocs.io/en/latest/index.html A Manufacturing Digital Twin Framework 189Fig. 2 ISO 2347 vs. digital twin framework architecture alignment190 V. Anaya et al.such as Personnel, Equipment, Material, Manufacturing Processes, Facilities, Environment, Products, and Supporting Documents. \u2022 The knowlEdge DT provides integration mechanisms that make its usage in the application and services described in ISO 2347 possible. 3 knowlEdge Digital Twin for Process Improvement DTs have become an essential tool for improving shop floor processes in the manufacturing industry. One specific application of a DT is for scheduling process improvement. By using a DT, manufacturers can optimize their production sched-ules to improve efficiency and reduce costs. The following is a description of how the DT framework was applied to a dairy company within the knowlEdge project to improve the management, control their processes, and automatize the scheduling of the weekly production of yoghurt. The knowlEdge Data Collection Platform (DCP) is used to connect to the shop floor for gathering production and demand data. The platform was integrated with various sensors and devices to collect data in real time. The DCP was also used to collect data from various sources, such as the company\u2019s ERP5 . By collecting data from various sources, manufacturers can get a complete picture of their production and demand data. The data was passed through the data collection platform for filtering, formatting and normalization. This assured the proper quality of data and ensured that the DT is accurate and reliable (see Fig. 3). Fig. 3 Standard format for exchanging information among knowledge components5 Enterprise Resource Planning. A Manufacturing Digital Twin Framework 191Fig. 4 Digital twin framework model editor Fig. 5 Digital twin dashboard generated with the framework The processed data is pushed through an MQTT broker to the DT framework. The DT uses the data to model the behavior and performance of the manufacturing process. The DT framework was used to model the plant using ISO 2347 Observable Manufacturing Elements concepts (see Fig. 4). The DT framework was also used to simulate different mechanics of scenarios to identify opportunities for process improvement, specifically for computing a production schedule based on metaheuristic rules provided by the company and for simulating the execution of the schedules based on what-if scenarios, allowing the manufacturing operators to select the optimal production plan according to a192 V. Anaya et al.range of aspects such as timestamp, resource occupation, uncertainty resilience, or customer satisfaction. Figure 5 shows a partial view of the dashboard generated using the DT Decision View and populated with the information and the results of the DT simulators. 4 Conclusions Digital twin technology has the potential to revolutionize the manufacturing industry by optimizing processes, increasing productivity, and enhancing product quality. By leveraging advanced digital techniques, simulations, and hybrid learning-based modeling strategies, DT technology can help overcome the challenges faced by traditional manufacturing methods and pave the way for the next generation of smart manufacturing. This chapter has presented the knowlEdge DT framework, an open-source toolkit of DT modules supporting the modeling of physical assets and processes, and the execution of functional and AI-based simulators for the execution of what-if scenarios for improving the decision-making process. The tool has been used to also for the generation of synthetic data for training AI algorithms. It is composed of a set of modules as a DT Data Modeler, 3D twin modeler, IoT Ingestion Connector, Simulator/AI Manager and Repository, Event Scheduler, DT Live Dashboard, and the Data Collection Platform. The DT Framework proposed was successfully used for creating a manufacturing DT instance for generating weekly manufacturing schedules based on a rule-based simulator and a discrete event simulator. The company where it was applied has improved their reactiveness to incidents occurring on the shop floor, optimizing the rescheduling process accordingly. As more case studies and practical implementations emerge, the true potential of DT technology in manufacturing will become increasingly apparent, driving further transformation and innovation in the industry. Acknowledgment This work has received funding from the European Union\u2019s Horizon 2020 research and innovation programs under grant agreement No. 957331\u2014KNOWLEDGE. This paper reflects only the authors\u2019 views, and the Commission is not responsible for any use that may be made of the information it contains. References 1. Stavropoulos, P., Mourtzis, D.: Digital twins in industry 4.0. In: Design and Operation of Production Networks for Mass Personalization in the Era of Cloud Technology, pp. 277\u2013316. Elsevier, Amsterdam (2022) 2. Ogunsakin, R., Mehandjiev, N., Marin, C.A.: Towards adaptive digital twins architecture. Comput. Ind. 149, 103920 (2023)A Manufacturing Digital Twin Framework 1933. He, B., Bai, K.J.: Digital twin-based sustainable intelligent manufacturing: a review. Adv. Manuf. 9, 1\u201321 (2021) 4. Thelen, A., Zhang, X., Fink, O., Lu, Y., Ghosh, S., Youn, B.D., et al.: A comprehensive review of digital twin\u2014part 1: modeling and twinning enabling technologies. Struct. Multidiscip. Optim. 65(12), 354 (2022) 5. Kim, D.B., Shao, G., Jo, G.: A digital twin implementation architecture for wire+ arc additive manufacturing based on ISO 23247. Manuf. Lett. 34, 1\u20135 (2022) 6. Shao, G., Helu, M.: Framework for a digital twin in manufacturing: Scope and requirements. Manuf. Lett. 24, 105\u2013107 (2020) 7. Farhadi, A., Lee, S.K., Hinchy, E.P., O\u2019Dowd, N.P., McCarthy, C.T.: The development of a digital twin framework for an industrial robotic drilling process. Sensors. 22(19), 7232 (2022) 8. Zhong, D., Xia, Z., Zhu, Y., Duan, J.: Overview of predictive maintenance based on digital twin technology. Heliyon (2023) 9. Hassan, M., Svadling, M., Bj\u00f6rsell, N.: Experience from implementing digital twins for maintenance in industrial processes. J. Intell. Manuf., 1\u201310 (2023) 10. Lee, J., Lapira, E., Bagheri, B., Kao, H.A.: Recent advances and trends in predictive manufacturing systems in big data environment. Manuf. Lett. 1(1), 38\u201341 (2013) 11. Rodionov, N., Tatarnikova, L.: Digital twin technology as a modern approach to quality management. In: E3S Web of Conferences, vol. 284, p. 04013. EDP Sciences (2021) 12. Fang, Y., Peng, C., Lou, P., Zhou, Z., Hu, J., Yan, J.: Digital-twin-based job shop scheduling toward smart manufacturing. IEEE Trans. Ind. Inf. 15(12), 6425\u20136435 (2019) 13. Lu, Y., Liu, C., Kevin, I., Wang, K., Huang, H., Xu, X.: Digital twin-driven smart manufac-turing: connotation, reference model, applications and research issues. Robot. Comput. Integr. Manuf. 61, 101837 (2020) 14. Ogunseiju, O.R., Olayiwola, J., Akanmu, A.A., Nnaji, C.: Digital twin-driven framework for improving self-management of ergonomic risks. Smart Sustain. Built Environ. 10(3), 403\u2013419 (2021) 15. Ivanov, D., Dolgui, A., Sokolov, B.: The impact of digital technology and Industry 4.0 on the ripple effect and supply chain risk analytics. Int. J. Prod. Res. 57(3), 829\u2013846 (2019) 16. Capabilities Periodic Table \u2013 Digital Twin Consortium. Digital Twin Consortium. Published August 8, 2022. https://www.digitaltwinconsortium.org/initiatives/capabilities-periodic-table/. Accessed 2 June 2023 17. ISO 23247-2: ISO 23247-2: Automation Systems and Integration \u2013 Digital Twin Framework for Manufacturing \u2013 Part 2: Reference Architecture. International Organization for Standard-ization, Geneva (2021) 18. Wajid, U., Nizamis, A., Anaya, V.: Towards Industry 5.0\u2013A Trustworthy AI Framework for Digital Manufacturing with Humans in Control. Proceedings http://ceur-ws.org. ISSN, 1613, 0073 (2022) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Reinforcement Learning-Based Approaches in Manufacturing Environments Andrea Fern\u00e1ndez Mart\u00ednez, Carlos Gonz\u00e1lez-Val, Daniel Gordo Mart\u00edn, Alberto Botana L\u00f3pez, Jose Angel Segura Muros, Afra Maria Petrusa Llopis, Jawad Masood, and Santiago Mui\u00f1os-Landin 1 Introduction Over the past few decades, there has been a significant surge in the digitalization and automation of industrial settings, primarily driven by the adoption of Industry 4.0 principles. At its essence, Industry 4.0 aims to establish a world of interconnected, streamlined, and secure industries, built upon fundamental concepts such as the advancement of cyber-physical systems (CPS) [1\u20133], the Internet of Things (IoT) [4\u20136], and cognitive computing [7]. Computer numerical control machines (CNCs) play a pivotal role in aligning with the principles of Industry 4.0 [8\u201310], facilitating automated and efficient manufacturing of intricate and high-quality products. They have revolutionized various industries such as woodworking, automotive, and aerospace by enhanc-ing automation and precision. By automating industrial processes, CNCs reduce the need for manual labor in repetitive and non-value-added activities, fostering collaboration between machine centers and human operators in factory settings [11]. Moreover, CNCs\u2019 modular design and operational flexibility empower them to perform a wide range of applications with minimal human intervention, ensuring the creation of secure workspaces through built-in security measures. These machines often incorporate advanced sensing and control technologies, optimizing their performance and minimizing downtime. In parallel with the rapid adoption of CNCs in the market, simulation techniques have evolved to meet the industry\u2019s latest requirements. The emergence of the digital A. Fern\u00e1ndez Mart\u00ednez \u00b7 C. Gonz\u00e1lez-Val \u00b7 D. G. Mart\u00edn \u00b7 A. B. L\u00f3pez \u00b7 J. A. S. Muros A. M. P. Llopis \u00b7 J. Masood \u00b7 S. Mui\u00f1os-Landin (\u0002) AIMEN Technology Centre, Smart Systems and Smart Manufacturing Group, Pontevedra, Spain e-mail: andrea.fernandez@aimen.es; carlos.gonzalez@aimen.es; daniel.gordo@aimen.es; alberto.botana@aimen.es; jose.segura@aimen.es; afra.pertusa@aimen.es; jawad.masood@aimen.es; santiago.muinos@aimen.es \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_11195196 A. Fern\u00e1ndez Mart\u00ednez et al.twin (DT) [3] concept has particularly contributed to advancing cyber-physical systems (CPS) by establishing seamless coordination and control between the cyber and physical components of a system [12]. While there is no universally accepted definition of digital twin, it can be understood as a virtual representation of a physical machine or system. DTs offer numerous advantages for controlling and analyzing the performance of physical machines without the need for direct physical intervention. By conducting research and testing on virtual representations instead of physical machines, specialists can experiment and evaluate process performance from technological and operational perspectives, conserving physical resources and avoiding associated costs such as energy consumption, operational expenses, and potential safety risks during the research and development stages [13, 14]. The exponential growth of data generated by machines, coupled with the inte-gration of information from their digital twins [3], has opened up new possibilities for data-driven advancements [12]. These developments leverage state-of-the-art analysis techniques to optimize processes in an adaptive manner. In the realm of robotics and automation, reinforcement learning has emerged as a foundational technology for studying optimal control. Reinforcement learning [15\u201317], a branch of Artificial Intelligence (AI), revolves around analyzing how intelligent agents should behave within a given environment based on a reward function. The underlying principle of RL draws inspiration from various fields of knowledge, including social psychology. In RL algorithms, intelligent agents interact with their environment, transitioning between states to discover an optimal policy that maximizes the expected value of their total reward function. These algorithms hold tremendous potential for overcoming existing limitations in the control of robotic systems at different length scales [18], offering new avenues for advancements in this field. A significant challenge in the realm of mobile industrial machinery lies in designing path trajectories that effectively control robot movement [19\u201322]. Tradi-tionally, computer-aided design (CAD) and computer-aided manufacturing (CAM) systems are utilized to generate these trajectories, ensuring adherence to security specifications such as maintaining a safe distance between the robot-head and the working piece to prevent product damage. However, these path trajectories often exhibit discontinuities and encounter issues in corners and curves due to the mechanical limitations of the physical machinery. Moreover, factors such as overall distance or the number of movements between two points, as well as the possibility of collisions among the robot\u2019s moving parts, are not efficiently optimized by these systems. The optimization of path trajectories becomes increasingly complex as the number of movement dimensions and potential options for movement increases. In this context, reinforcement learning emerges as a promising solution for addressing high-dimensional spaces in an automated manner [23, 24], enabling the discovery of optimal policies for controlling robotic systems with a goal-oriented approach. Reinforcement learning algorithms offer the potential to tackle the challenges associated with path trajectory optimization, providing a framework for finding efficient and effective movement strategies for robotic systems [25]. By leverag-Reinforcement Learning-Based Approaches in Manufacturing Environments 197ing reinforcement learning techniques, mobile industrial machinery can navigate complex environments and optimize their trajectories, taking into account multiple dimensions of movement and achieving superior control and performance through an enhanced perception that represents the knowledge developed by reinforcement learning systems. 2 Reinforcement Learning Reinforcement learning (RL) [15, 16] is widely recognized as the third paradigm of Artificial Intelligence (AI), alongside supervised learning [26, 27] and unsupervised learning [28]. RL focuses on the concept of learning through interactive experiences while aiming to maximize a cumulative reward function. The RL agent achieves this by mapping states to actions within a given environment, with the objective of finding an optimal policy that yields the highest cumulative reward as defined in the value function. Two fundamental concepts underpin RL: trial-and-error search and the notion of delayed rewards. Trial-and-error search involves the agent\u2019s process of selecting and trying different actions within an initially uncertain environment. Through this iterative exploration, the agent gradually discovers which actions lead to the maximum reward at each state, learning from the outcomes of its interactions. The concept of delayed rewards [15, 26] emphasizes the consideration of not only immediate rewards but also the expected total reward, taking into account subse-quent rewards starting from the current state. RL agents recognize the importance of long-term consequences and make decisions that maximize the cumulative reward over time, even if it means sacrificing immediate gains for greater overall rewards. By incorporating trial-and-error search and the notion of delayed rewards, RL enables agents to learn effective policies by actively interacting with their environment, continuously adapting their actions based on the feedback received, and ultimately maximizing cumulative rewards. Reinforcement learning (RL) problems consist of several key elements that work together to enable the learning process. These elements include a learning agent, an environment, a policy, a reward signal, a value function, and, in some cases, a model of the environment. Let\u2019s explore each of these elements: 1. Learning agent: The learning agent is an active decision-making entity that interacts with the environment. It aims to find the optimal policy that maximizes the long-term value function through its interactions. The specific approach and logic employed by the learning agent depend on the RL algorithm being used. 2. Environment: The environment is where the learning agent operates and interacts. It can represent a physical or virtual world with its own dynamics and rules. The environment remains unchanged by the actions of the agent, and the agent must navigate and adapt to its dynamics to maximize rewards.198 A. Fern\u00e1ndez Mart\u00ednez et al.3. Policy: The policy determines the behavior of the learning agent by mapping states in the environment to the actions taken by the agent. It can be either stochastic (probabilistic) or deterministic (fixed), guiding the agent\u2019s decision-making process. 4. Reward signal: The reward signal is a numerical value that the agent receives as feedback after performing a specific action in the environment. It represents the immediate feedback obtained during state transitions. The goal of the agent is to maximize the cumulative rewards over time by selecting actions that yield higher rewards. 5. Value function: The value function represents the expected total reward obtained by the agent in the long run, starting from a specific state. It takes into account the sequence of expected rewards by considering the future states and their corresponding rewards. The value function guides the agent in estimating the desirability of different states and helps in decision-making. 6. Model (optional): In some cases, RL algorithms incorporate a model of the environment. The model mimics the behavior of the environment, enabling the agent to make inferences about how the environment will respond to its actions. However, in model-free RL algorithms, a model is not utilized. In a typical reinforcement learning (RL) problem, the learning agent interacts with the environment based on its policy. The agent receives immediate rewards from the environment and updates its value function accordingly. This RL frame-work is rooted in the Markov decision process (MDP) [28], which is a specific approach used in process control. RL has been proposed as a modeling tool for decision-making in both biological [29] and artificial systems [18]. It has found applications in various domains such as robotic manipulation, natural language processing, and energy management. RL enables agents to learn optimal strategies by exploring and exploiting the environment\u2019s feedback. Inverse RL, which is based on hidden Markov models, is another extensively studied topic in the field. Inverse RL aims to extract information about the underlying rules followed by a system that generate observable behavioral sequences. This approach has been applied in diverse fields including genomics, protein dynamics in biology, speech and gesture recognition, and music structure analysis. The broad applicability of RL and its ability to address different problem domains make it a powerful tool for understanding and optimizing complex systems in various disciplines. Through iterative interactions, the agent adjusts its policy and value function to optimize its decision-making process and maximize cumulative rewards. Figure 1 illustrates the common interaction flow in an RL problem. As previously mentioned, the learning agent is situated within and interacts with its environment. The environment\u2019s state reflects the current situation or condition, defined along a set of possible states denoted as S. The agent moves between states by taking actions from a set of available actions, denoted as A. Whenever the agent chooses and performs an action \u03b1 from A, the environment E undergoes a transformation, causing the agent to transition from one state S to another S', whereReinforcement Learning-Based Approaches in Manufacturing Environments 199Fig. 1 Reinforcement learning classic feedback loop (S, S')\u03f5S. Additionally, the agent receives a reward \u03b3 based on the chosen action \u03b1. The ultimate objective of the agent is to maximize the expected cumulative reward Rt over the long term, which can be estimated and reestimated through the learning process of the agent to include and adapt to the new knowledge acquired. A significant challenge in RL is striking the right balance between exploration and exploitation. On one hand, it is advantageous for the agent to exploit its existing knowledge gained from past experiences. By selecting actions that have previously yielded high rewards, the agent aims to maximize the cumulative reward over time. On the other hand, exploration is crucial to enable the agent to discover new states and potentially identify better actions, thus avoiding suboptimal policies. Different RL algorithms employ various approaches to address this trade-off. A fundamental characteristic of MDPs and RL is their ability to handle stochastic influences in the state\u2013action relationship. This stochasticity is typically quantified by a transition function, which represents a family of probability distributions that describe the potential outcomes resulting from an action taken in a particular state. By knowing the transition function, the agent can estimate the expected outcomes of applying an action in a state by considering all possible transitions and their corresponding probabilities. This analysis allows the agent to assess the desirability or undesirability of certain actions. To formalize this process, a value function U is defined [16]. The value function assigns a numerical value to each state, representing the expected cumulative reward the agent can achieve starting from that state and following a specific policy. It serves as a measure of the desirability or utility of being in a particular state. The value function helps guide the agent\u2019s decision-making process by allowing it to compare the potential outcomes and make informed choices based on maximiz-ing the expected cumulative reward over time. . U\u2217(s) = max\u03c0E( \u221e\u2211t=0\u03b3t rt)Indeed, the parameter \u03b3 in the value function equation is widely referred to as the discount factor. It plays a pivotal role in regulating the importance of future events during the decision-making process, considering the delayed nature of rewards. By adjusting the discount factor, one can determine the relative significance of200 A. Fern\u00e1ndez Mart\u00ednez et al.immediate rewards compared to future rewards. In the optimal value function equation, the discount factor appears to discount future rewards geometrically [15, 16]. This means that rewards obtained in the future are typically weighted less compared to immediate rewards. However, it\u2019s important to note that the specific value and impact of the discount factor depend on the chosen model of optimality. There are three main models of optimality that can be considered: finite horizon, infinite horizon, and average reward. In the infinite horizon model, which we are focusing on here, the discount factor is used to discount future rewards geometrically. In the equation, the policy function \u03c0 represents the mapping from states to actions and serves as the primary focus of optimization for the RL agent. It determines the action to be taken in each state based on the agent\u2019s acquired knowledge. The asterisk (*) symbol signifies the \u201coptimal\u201d property of the function being discussed, indicating that the equation represents the value function associated with the optimal policy. One can extend the expression of the optimal value by writing the expected value of the reward using the transition function T as . U\u2217(s) = maxa[r (s, a) + \u03b3\u2211s\u2208ST(s, a, s')U\u2217(s')]This is the Bellman equation, which is a fundamental concept in dynamic programming. It encompasses the maximization operation, highlighting the non-linearity inherent in the problem. The solution to the Bellman equation yields the policy function, which determines the optimal actions to be taken in different states. . \u03c0\u2217(s) = argmaxa[r (s, a) + \u03b3\u2211s\u2208ST(s, a, s')U\u2217(s')]As mentioned above, it returns the action to be applied on each state so that once converged it returns the best action to be applied on each state. The value function within a MDP can be also expressed or summarized in a matrix that stores the value associated with an action a in a given state s. This matrix is typically called Q-matrix and is represented by . U\u2217(s) = maxaQ\u2217 (s, a)so that the Bellman equation results .Q\u2217 (s, a) = r (s, a) + \u03b3\u2211s\u2208ST(s, a, s')maxaQ\u2217(s', a')Reinforcement Learning-Based Approaches in Manufacturing Environments 201The opening to what is commonly known as Q-learning is generally facilitated by this approach. It is important to note that the system\u2019s model, also known as the transition function, may either be known or unknown. In the case of model-based Q-learning, the model is known, while in model-free Q-learning, it is not. When dealing with an unknown model, the temporal differences approach has proven to be an effective tool for tackling strategy search problems in actual systems. In this approach, the agent is not required to possess prior knowledge of the system\u2019s model. Instead, information is propagated after each step, eliminating the need to wait until the conclusion of a learning episode. This characteristic renders the implementation of this method more feasible in real robotic systems. 2.1 Toward Reinforcement Learning in Manufacturing Teaching agents to control themselves directly from high-dimensional sensory inputs, such as vision and speech, has long been a significant challenge in RL. In many successful RL applications in these domains, a combination of hand-crafted features and linear value functions or policy representations has been utilized. It is evident that the performance of such systems is heavily dependent on the quality of the feature representation employed. In recent years, deep learning has witnessed significant progress, enabling the extraction of high-level features directly from raw sensory data. This break-through has had a transformative impact on fields such as computer vision and speech recognition. Deep learning (DL) techniques leverage various neural network architectures such as convolutional networks, multilayer perceptrons, restricted Boltzmann machines, and recurrent neural networks. These architectures have successfully employed both supervised and unsupervised learning approaches. Given these advancements, it is reasonable to inquire whether similar techniques can also benefit reinforcement learning (RL) when dealing with sensory data. The advancements in deep learning (DL) [30] have paved the way for deep neural networks (DNNs) to automatically extract compact high-dimensional rep-resentations (features). This capability is particularly useful for overcoming the dimensional catastrophe, commonly encountered in domains such as images, text, and audio. DNNs possess powerful representation learning properties, enabling them to learn meaningful features from raw data. Deep reinforcement learning (DRL) [31] refers to a class of RL algorithms that leverage the representation learning capabilities of DNNs to enhance decision-making abilities. The algorithm framework for DNN-based RL is illustrated in Fig. 2. In DRL, the DNN plays a crucial role in extracting relevant information from the environment and inferring the optimal policy \u03c0\u2217 in an end-to-end manner. Depending on the specific algorithm employed, the DNN can be responsible for outputting the Q-value (value-based) for each state\u2013action pair or the probability distribution of the output action (policy-based). The integration of DNNs into RL enables more efficient and effective decision-making by leveraging the power of representation learning.202 A. Fern\u00e1ndez Mart\u00ednez et al.Fig. 2 Representation of the deep reinforcement learning (DRL) feedback loop Such scenario made much more accessible or tractable classic problems in manufacturing frameworks to RL approaches. In the following section we present two cases where RL has migrated to DRL to address specific problems within manufacturing environments. 3 Deep Reinforcement Learning in Virtual Manufacturing Environments In this section, we present two distinct examples that demonstrate the advancements made in RL, specifically in the context of deep reinforcement learning (DRL). These examples involve the application of RL within a virtual environment, which allows for the development of strategies that can later be translated to real systems. This approach opens up the possibility of deploying this technology in manufacturing environments. One key advantage of utilizing virtual environments is that it mitigates the significant amount of learning episodes typically required by RL agents to develop an optimal policy. In a real manufacturing system, the time needed to explore numer-ous strategies would make the process highly inefficient for reaching an optimal solution. Moreover, certain strategies may introduce risks, such as safety concerns, that cannot be easily managed or assumed in a manufacturing environment. For instance, in the second example, robotic systems operating collaboratively may pose safety risks, while in the first example, machines with high power consumption may introduce operational risks. By leveraging virtual environments [32, 33], RL techniques can be effectively applied to develop optimal strategies while minimizing risks and reducing the time and costs associated with experimentation in real systems. This approach enablesReinforcement Learning-Based Approaches in Manufacturing Environments 203the integration of RL technology into manufacturing environments, paving the way for enhanced efficiency, productivity, and safety [34\u201336]. Considering these issues, the development of digital environments (such as simulation platforms or digital twins) has been taken as the ideal scenario to train RL agents until the systems reach certain level of convergency or, in other words, trustworthiness. Once, certain strategies have reached a reasonable point, they can be tested in real scenario, and even a reduced optimization process can take place at that point to finally find the optimal strategy in the real context. In this sense, the quality of the virtual context or the divergency with respect to the real process, becomes critical for the achievement of an optimal strategy later in the real world. However, the optimal digitalization of processes is out of the scope of this chapter. The two scenarios presented in this section address the optimization of two different systems. The first one is the optimization of trajectories in a CNC cutting machine designed for different operations over large wood panels. The problem in this case is the optimization of the path between two different operations (cutting, drilling, milling, etc.). The second scenario faces the robotic manipulation of a complex material. In particular, the problem is the manipulation of fabric by two robotic arms in order to reduce wrinkles. These problems have been addressed within specifically developed digital environments to deliver optimal strategies that are later tested in the real system. 3.1 CNC Cutting Machine The digital twin (DT) of the physical CNC presented here was developed and shared by one of the partners along the MAS4AI Project (GA 957204) within the ICT-38 AI for manufacturing cluster for the development of the RL framework. The DT is built on X-Sim, and it incorporates the dynamics of the machine, its parts, and the effects on the working piece, simulating the physical behavior of the CNC. The CNC of our study was a machining center for woodworking processes, more specifically for cutting, routing, and drilling. The machine considered (not shown for confidentiality issues) consists of a work-ing table in which wood pieces are located and held throughout the woodworking process and a robot-head of the CNC, which is responsible for performing the required actions to transform the raw wood piece into the wood product (Fig. 3). The model-based machine learning (ML) agent developed in this context aims at optimizing the path trajectories of the five-axes head of a CNC within a digital twin environment. Currently, the DT CNC enables the 3D design of the wood pieces by users, creating all the necessary code to control the physical CNC. Controlling a five-axes head automatically in an optimized way is yet an engineering challenge. The CNC must not only perform the operation required to transform the wood piece into the desired product, but it must also avoid potential collisions with other parts of the machine, control the tools required by the head204 A. Fern\u00e1ndez Mart\u00ednez et al.Fig. 3 Movements of the robot head in its five-axes of the robot, and keep times short reducing unnecessary movements to enhance productivity and save energy, while ensuring the machine integrity and safety of operators throughout the process, as well as high-quality products. In this context, a model-based ML agent based on a DRL framework was trained to optimize the path trajectories of the five-axes head of the CNC in order to avoid potential collisions while optimizing the overall time operation. The difficulty of working in a five-dimensional space (due to the five-axis robot head) is increased by the dimensions of the working table of the CNC, which goes up to 3110 \u00d7 1320 mm. In the DT environment, the measurement scale is micrometers, resulting in more than 4,105,200 million states to be explored by the agent in a discrete state\u2013action space only in the plane XY of the board, without considering the extra three-axes of the robot head. This complex applicability of discrete approaches is the reason why only a continuous action space using Deep Deterministic Policy Gradient (DDPG) [37] is shown here. The model-based AI CNC agent was trained to work considering different operations. The ultimate goal of the agent is to optimize the path trajectories between two jobs in a coordinated basis considering the five-axes of the CNC head. For this reason, the inputs of the model are the coordinates of the initial location, i.e., state of the five-axes head, and the destination location or a label representing the desired operation to be performed by the CNC. The agent returns the optimized path trajectory to reach the goal destination by means of a set of coordinates representing the required movements of the five-axes head. Currently, the agent has been trained separately to perform each operation independently. In a future stage, a multi-goal DRL framework was explored in order to enhance generalization. Different operations and different learning algorithms were explored during the development of the deep RL framework, including 2-D, 3-D, and 5-D movements of the five-axes head of the CNC, different path trajectories to be optimized, and different learning algorithms including Q-learning [15, 38], deep Q-learning (DQL) [39], and DDPG. As seen previously, Q-learning is a model-free, off-policy RL algorithm that seeks to find an optimal policy by maximizing a cost function that represents the expected value of the total reward over a sequence of steps. It is used in finite Markov decision processes (stochastic, discrete), and it learns an optimal action-selection policy by addressing the set of optimal actions that the agent should take in order to maximize the total reward (Rt). The algorithm is based on an agent, a setReinforcement Learning-Based Approaches in Manufacturing Environments 205Fig. 4 Actor\u2013critic architecture workflow [41] of actions A, a set of states  S, and an environment E. Every time the agent selects and executes an action a \u03f5 A, the environment E is transformed, and the agent transitions from one state, s, to another, s\u2019, with (s, s\u2019) \u03f5 S, receiving a reward r according to the action selected. DDPG is an off-policy algorithm that simultaneously learns a Q-function and a policy based on the Bellman equation in continuous action spaces. DDPG makes use of four neural networks, namely an actor, a critic, a target actor, and a target critic. The algorithm is based on the standard \u201cactor\u201d and \u201ccritic\u201d architecture [40], although the actor directly maps states to actions instead of a probability distribution across discrete action spaces. In order to solve the problem of exhaustively evaluating all possible actions from a continuous action space, DDPG learns an approximator to Q(s, a) by means of a neural network, the critic Q\u03b8 (s, a), with \u03b8 corresponding to the parameters of the network (Fig. 4). Q\u03b8 learns from an experience replay buffer that serves as a memory for storing previous experiences. This replay buffer contains a set D of transitions, which includes the initial state (s), the action taken (a), the obtained reward (r), the new state reached (s\u2019), and whether the state is terminal or not (d). In other words, each206 A. Fern\u00e1ndez Mart\u00ednez et al.transition is represented as (s, a, r, s\u2019, d), where s, a, r, s\u2019, and d are elements of the set D. In order to evaluate the performance of Q\u03b8 in relation to the Bellman equation, the mean-squared Bellman error (MSBE) can be computed. The MSBE quantifies the discrepancy between the estimated Q-values produced by Q\u03b8 and the values predicted by the Bellman equation. It is typically calculated by taking the mean squared difference between the Q-value estimate and the expected Q-value, using the current parameters \u03b8 . The MSBE provides a measure of how well the Q-function approximated by Q\u03b8 aligns with the optimal Q-values as defined by the Bellman equation. Minimizing the MSBE during training helps the DRL algorithm converge toward an optimal Q-function approximation. . L = 1N\u2211 (Q\u03b8 (s, a) \u2212 y(r, s', d)2. y(r, s', d) = r + \u03b3 (1 \u2212 d) Q\u03b8 target(s', \u03bc\u03c6target(s'))where the Q\u03b8 target and \u03bc\u03c6target networks are lagged versions of the Q\u03b8 (critic) and \u03bc\u03c6 (actor) networks to solve the instability of the minimization of the MSBE due to interdependences among parameters. Hence, the critic network is updated by performing gradient descent considering loss L. Regarding the actor policy, it is updated using sampled policy gradient ascent with respect to the policy parameters by means of: . \u2207\u03c6 1N\u2211s\u2208DQ\u03b8(s, \u03bc\u03c6(s))Finally, the target networks are updated by Poliak averaging their parameters over the course of training: . \u03b8Qtarget \u2190 \u03c1\u03b8Q + (1 \u2212 \u03c1) \u03b8Qtarget\u03c6\u03bctarget \u2190 \u03c1\u03c6\u03bc + (1 \u2212 \u03c1) \u03c6\u03bctargetDuring training, uncorrelated, mean-zero Gaussian noise is added to actions to enhance exploration of the agent. The pseudocode for training a DDPG algorithm would be as in Table 1. The CNC AI agent has a multi-goal nature within the environment. First, the agent shall learn not to collide with other machine parts. Collisions correspond to a penalty of \u22121000 and the reset of the environment. Second, the agent shall learn how to reach a goal destination by exploring the environment, which has an associated reward of +500 and causes the reset of the environment as well. Third, the agentReinforcement Learning-Based Approaches in Manufacturing Environments 207Table 1 Pseudocode for training a DDPG algorithm 1. Randomly initialize critic Q\u03b8 (s, a) and actor \u03bc\u03c6(s) with weights \u03b8Q and \u03c6\u03bc. 2. Initialize target networks Q\u03b8 target and \u03bc\u03c6target with \u03b8Qtarget \u2190 \u03b8Q, \u03c6\u03bctarget \u2190 \u03c6\u03bc 3. Initialize replay buffer D 4. For episode=1, M do 5. Initialize random process N for action exploration 6. Receive initial state s 7. For t=1, max-episode-length do 8. Observe state s and select action a =\u03bc\u03c6(s)+N according to current policy and exploration noise 9. Execute action a in environment E and observe reward r, new states\u2019, and done signal d 10. Store (s, a, r, s\u2019, d) in replay buffer D and set s \u2190 s\u2019 11. If s\u2019 is terminal (done=True), reset environment E 12. If update network, then 13. For i=1, G updates do 14. Sample a random minibatch of B samples (s, a, r, s\u2019, d) from D 15. Compute targets [2] 16. Update critic by minimizing L [3] 17. Update policy by gradient ascent [4] 18. Update target networks [5, 6] 19. End for 20. End if 21. End for shall optimize its policy considering the operational time and quality of the path. The operational time is calculated based on the distance that the robot head needs to travel to reach the goal destination following the proposed path. The quality of the path is calculated based on the number of actions needed to reach the destination. The former two aspects are favored by an extra reward of +100 to the agent (Fig. 5). Figure 6 shows four exemplary paths found by the agent in a 2-D movement for visualization. In this problem, the agent needs to learn how to move from right to left without colliding with any machine parts. Since the action space is continuous, the goal destination does not correspond to a specific coordinate but to a subspace of the environment. The circles draw on the paths represent the subgoal coordinates proposed by the agent (each action correspond to a new coordinate to which the robot head is moved). From the figure, it can be seen that the yellow and pink trajectories comprise more actions and a longer path than the blue and green trajectories. Although these latter contain the same number of actions (three movements), the green trajectory requires a shorter path, and thus is preferred.208 A. Fern\u00e1ndez Mart\u00ednez et al.Fig. 5 Information flow in the DDPG framework during training phase Fig. 6 Exemplary trajectories for simplicity in a 2-D movement. Circles in the path correspond to set of coordinates obtained after performing the action proposed by the framework in the environment. The total length of the trajectory and the number of actions are considered in the reward function. The red square corresponds with the starting point, while the red rectangle corresponds to the final region (target) 3.2 Robotic Manipulation of Complex Materials The challenge of manipulating complex materials involves the identification of measurable quantities that offer insights into the system, which can then be utilized to make informed decisions and take appropriate actions [42, 43]. ThisReinforcement Learning-Based Approaches in Manufacturing Environments 209essentially involves combining a perception system with a decision-making process. The Markov decision process (MDP) framework, as described earlier, is well-suited to address the task of defining optimal strategies for material manipulation. RL is particularly suitable for this purpose due to its probabilistic nature. RL accommodates the inherent uncertainty associated with characterizing the state of complex materials, which often presents challenges in traditional approaches. The first step for the robotic manipulation of a fabric is the definition of the information required to perform the optimal actions for the manipulation of a material [44\u201346]. For that purpose, the state of the system needs to be characterized, a prediction needs to be done to infer what is the next state of the system under the application of a given action, and a criterium to decide what action to take for a given target needs to be chosen. To address these points, on the one hand, a procedure for the generation of synthetic data has been deployed to generate automatically thousands of synthetic representations of a fabric and their transitions under the application of certain actions. On the other hand, in order to exploit such tool and build a solution based on data, a neural network has been developed and trained. Given that in a real system, in the real scenario for this work, a point cloud camera was used to detect the fabric, the entropy of the cloud has been calculated and taken as a reference magnitude to evaluate the goodness of a transition in terms of wrinkledness reduction. In order to quantify the amount of knowledge in the system, we use entropy as a measurement of the information of the system. Using entropy maps, the wrinkledness of the fabric has been characterized. This entropy maps are calculated from the distributions of normal vectors within local regions using the classic form of information entropy for a distribution as follows: . H(X) = \u2212n\u2211i=1p (xi) log p (xi)Entropy is usually thought as a measurement of how much information a message or distribution holds. In other words, how predictable such a distribution is. In the context of the work presented here, entropy gives an idea about the orientation of the normal vectors of a given area of points taken from a reference one. In order to address the massive complex manipulation of fabrics to reduce wrinkles over the surface, a specific digital environment has been developed as it is the clothsim environment made available as open access as part of the results of the MERGING Project. The detailed description of the simulation can be found on its own repository and is out of the scope of this chapter. The clothsim environment has been used for the cloth initial random config-uration and later the training of the system. The learning routine has suggested different actions considering the Q-values (Q-matrix) by an argmax function. After the application of the actions, clothsim returned the transition of the fabric and the values of the Q-matrix have been updated following a Q-learning update rule where a reward function stablishes how good or bad the action was attending to210 A. Fern\u00e1ndez Mart\u00ednez et al.Fig. 7 Example of fabric manipulation using the developed environment for training under a complex manipulation task. The red and blue points indicate grab and pull points, respectively the calculated entropy for each state. The DQL procedure has been trained built on a ResNet18 architecture as a backbone with an input shape (224, 224, 4) and the RL has been set with the following characteristic parameters: the gamma factor has been initially set as 0.75 and epsilon has variated from 1 to 0.3 in 8000 steps. During the whole learning process, a log file captures the global status of the knowledge acquired by the system. Figure 7 shows a large example of the fabric manipulation in such a virtual environment (clothsim) in order to reduce the wrinkledness represented the entropy, which is estimated based on phi, theta, and z coordinates of the normal vectors of the points. The images show the status of the fabric during the application of actions selected based on the values of the Q-matrix. These values are developed during the training procedure where the system tries to stablish, for given state, which action drives the maximum entropy reduction. This means that the entropy is the metric used during the whole process for the wrinkle minimization in the fabric (Fig. 8). In order to select the actions, the knowledge of the system is encoded in the classic Q-matrix, which is inferred by the system for a given state. Such codification is done using a 6 \u00d7 6 matrix that considers corners to manipulate and directions that can be taken within the fabric manipulation. The final outcome of the procedure is a set of three points: one static point to fix the fabric, a second point that representsReinforcement Learning-Based Approaches in Manufacturing Environments 211Fig. 8 Different examples of Q-matrix which is estimated for each state in order to drive an action attending at the position of its maximum value. The minimum values a very small displacement of the corners, meaning a very low reduction of the entropy so that they show low Q-values the corner to be manipulated, and a third point that represents the point where this last corner has to be placed (grab point, pull point initial coordinates, pull point final coordinates). To decide what action to take, the system evaluates the Q-matrix and selects the action that corresponds with the maximum value on the matrix through an argmax function. The Q-values are updated to include a reward function that becomes positive as entropy decreases and remains negative otherwise. So, the Q-values hold the information of the reduction of the entropy that the system expects by the application of a given action. In a way that through the application of the action that corresponds with the maximum Q-value, the entropy reduction is also expected to be maximum in the long run (considering a whole episode). To quantify the solution, we validate the use of the entropy as a metric for the wrinkledness of the fabric and its minimization as the target of the algorithm for the development of a strategy to reduce such wrinkledness. Fig. 9 shows how the entropy is reduced through the actions followed attending at the Q-matrix toward an acceptance distance from the target (plane). The action-selection method, which serves as the system\u2019s plan to efficiently eliminate wrinkles from fabric, relies on a knowledge structure. This knowledge structure can be validated by evaluating the entropy variation resulting from the application of different actions, taking into account the information stored in the Q-matrix. In this process, various actions are applied to a given initial state, ordered based on their optimality as determined by the Q-matrix. By examining the entropy212 A. Fern\u00e1ndez Mart\u00ednez et al.Fig. 9 Example of entropy evolution during synthetic fabric manipulation. The figure shows the initial state of the fabric and the final after different actions are applied. The red arrow (top-left corner) indicates the action suggested by the system. The right side of the figure shows the entropy evolution during the application of the actions. It can be seen how it decreases until a certain threshold (orange horizontal line) is crossed, meaning that the fabric is close to an ideal (plane) state Fig. 10 Optimal path. Comparison of the entropy evolution when always the maximum of the Q-matrix is taken as optimal actions (blue curve) with entropy evolution under the selection of suboptimal actions (green and orange curves). The starting point for each transition is always considered as the state achieved by the application of the optimal (argmax from Q-values). Suboptimal actions drive more irregular behavior variation, one can assess the effectiveness of the selected actions and validate the underlying knowledge structure. Furthermore, the entropy\u2019s evolution along the optimal path can be compared with a scenario where suboptimal actions are taken, disregarding the Q-matrix. This comparison allows us to observe how the selection of the maximum Q-value drives a more robust curve toward entropy minimization. In Fig. 10, we can see that the entropy follows a decreasing curve toward the minimum entropy when the optimal actions are taken, considering the evolving state of the fabric. However, when suboptimal actions are consistently chosen for the same fabric state, the entropyReinforcement Learning-Based Approaches in Manufacturing Environments 213Fig. 11 Example of real fabric manipulation results. The figure shows three different steps during the manipulation following the actions suggested by the system. The sample manipulated is one from the real Use Case of the MERGING Project. In the figure, it can be clearly appreciated how the wrinkledness is reduced as the actions are applied exhibits a more erratic behavior. This demonstration highlights how the developed solution offers a long-term optimal solution, ensuring a continuous reduction in entropy along the optimal path. The strategies have been also tested in a real scenario, exploiting the information captured through a point cloud and following the outcomes suggested by the analysis of the Q-matrix associated with the given state. However, a complete description of the entire work behind this demonstration in terms of hardware is out of the scope of this chapter. Nevertheless, Fig. 11 shows the state of a fabric from an initial configuration to a final (ordered) state after the application of two actions to reduce the wrinkles. 4 Conclusions We have provided an introduction to reinforcement learning as a robust AI technol-ogy for the development of complex strategies to be exploited by active agents. For its deployment in manufacturing environments, RL applicability depends strongly on the digitalization of the process or its correct modeling. This is in order to provide a learning scenario to develop complex strategies to be demonstrated first under such digital strategy to be tested later in the real situation. We have shown, as part of the results of two projects, examples of the application of RL in manufacturing. First, the application of Deep Deterministic Policy Gradient methods for the path optimization of a CNC machine in a digital twin. Second, deep Q-learning has been shown as a method for the development of optimal strategies related to the manipulation of fabric in a manufacturing environment. Showing results in a dedicated digital environment, as well as providing examples of the performance of the system, results in reducing the wrinkles on the fabric. By utilizing reinforcement learning in a digital context, we have shown how to overcome the limitations posed by restricted training phases in manufacturing industries. Our research contributes to the development of effective strategies that can be tested and refined in digital environments before being applied to real-world214 A. Fern\u00e1ndez Mart\u00ednez et al.systems. This approach allows for safer and more efficient exploration, enabling the optimization of manufacturing processes and performance. The two manufacturing scenarios presented in this chapter highlight the potential and applicability of reinforcement learning in improving industrial processes. By bridging the gap between digital and real environments, we strive to advance the field of manufacturing and drive innovation in these sectors. Overall, this research sheds light on the benefits of applying reinforcement learning in a digital context for manufacturing industries. It underscores the importance of leveraging digital environments to enhance training and strategy development, ultimately leading to improved performance and efficiency in real-world systems. Acknowledgments This work has received funding from the European Union\u2019s Horizon 2020 research and innovation program under the MAS4AI Project (GA 957204) under the ICT-38 2020 \u2013 Artificial Intelligence for Manufacturing Topic. This work has also received funding from the MERGING Project (GA 869963). References 1. Qi, Q., Tao, F.: Digital twin and big data towards smart manufacturing and industry 4.0: 360 degree comparison. IEEE Access. 6, 3585\u20133593 (2018) 2. Fuller, A., Fan, Z., Day, C., Barlow, C.: Digital twin: enabling technologies, challenges and open research. IEEE Access. 8 (2020). https://doi.org/10.1109/ACCESS.2020.2998358 3. Wang, Z.: Digital twin technology. In: B\u00e1nyai, T., Petrilloand, A., De Felice, F. (eds.) Industry 4.0 \u2013 Impact on Intelligent Logistics and Manufacturing. IntechOpen (2020) 4. Alexopoulos, K., Sipsas, K., Xanthakis, E., Makris, S., Mourtzis, D.: An industrial internet of things based platform for context-aware information Services in Manufacturing. Int. J. Comput. Integr. Manuf. 31(11), 1111\u20131123 (2018). https://doi.org/10.1080/0951192X.2018.1500716 5. Kumar, S., Tiwari, P., Zymbler, M.: Internet of Things is a revolutionary approach for future technology enhancement: a review. J. Big Data. 6, 111 (2019). https://doi.org/10.1186/s40537-019-0268-2 6. Saad, A., Faddel, S., Mohammed, O.: IoT-based digital twin for energy cyber-physical systems: design and implementation. Energies. 13(18), 4762 (2020) 7. Wang, Y.: A cognitive informatics reference model of autonomous agent systems (AAS). Int. J. Cogn. Inform. Nat. Intell. 3(1), 1\u201316 (2009c) 8. Usl\u00e4nder, T., Epple, U.: Reference model of Industrie 4.0 service architectures: basic concepts and approach. Automatisierungstechnik. 63(10), 858\u2013866 (2015). https://doi.org/10.1515/auto-2015-0017 9. Phuyal, S., Bista, D., Bista, R.: Challenges, opportunities and future directions of smart manufacturing: a state of art review. Sustainable Futures. 2, 100023 (2020). https://doi.org/ 10.1016/j.sftr.2020.100023. ISSN 2666-1888 10. Ahuett-Garzaa, H., Kurfess, T.: A brief discussion on the trends of habilitating Technologies for Industry 4.0 and smart manufacturing. Manuf. Lett. 15(Part B), 60\u201363 (2018). https://doi.org/ 10.1016/j.mfglet.2018.02.011 11. Martins, A., Lucas, J., Costelha, H., Neves, C.: CNC machines integration in smart factories using OPC UA. J. Ind. Inf. Integr. 34, 100482 (2023) 12. Alexopoulos, K., Nikolakis, N., Chryssolouris, G.: Digital twin-driven supervised machine learning for the development of artificial intelligence applications in manufacturing. Int. J. Comput. Integr. Manuf. 33(5), 429\u2013439 (2020)Reinforcement Learning-Based Approaches in Manufacturing Environments 21513. Grieves, M., Vickers, J.: Digital twin: mitigating unpredictable, undesirable emergent behavior in complex systems. In: Kahlen, F.-J., Flumerfelt, S., Alves, A. (eds.) Transdisciplinary Perspectives on Complex Systems, pp. 85\u2013113. Springer, Cham (2017) 14. He, B., Bai, K.J.: Digital twin-based sustainable intelligent manufacturing: a review. Adv. Manuf. 9(1), 1\u201321 (2021) 15. Sutton, R.S., Barto, A.G.: Reinforcement learning: an introduction, 2nd edn. The MIT Press (2014) 16. Kaelbling, L.P., Littman, M.L., Moore, A.W.: Reinforcement learning: a survey. J. Artif. Intell. Res. 4, 237\u2013285 (1996). https://doi.org/10.1613/JAIR.301 17. Jang, B., Kim, M., Harerimana, G., Kim, J.W.: Q-Learning algorithms: a comprehensive clas-sification and applications. IEEE Access. 7, 133653\u2013133667 (2019). https://doi.org/10.1109/ ACCESS.2019.2941229 18. Mui\u00f1os-Landin, S., Fischer, A., Holubec, V., Cichos, F.: Reinforcement learning with artificial microswimmers. Sci. Rob. 6(52), eabd9285 (2021) 19. Chen, G., Luo, N., Liu, D., Zhao, Z., Liang, C.: Path planning for manipulators based on an improved probabilistic roadmap method. Robot. Comput. Integr. Manuf. 72 (2021). https:// doi.org/10.1016/j.rcim.2021.102196 20. Pohan, M.A.R., Trilaksono, B.R., Santosa, S.P., Rohman, A.S.: Path planning algorithm using the hybridization of the rapidly-exploring random tree and ant Colony systems. IEEE Access. 9 (2021). https://doi.org/10.1109/ACCESS.2021.3127635 21. Wei, K., Ren, B.: A method on dynamic path planning for robotic manipulator autonomous obstacle avoidance based on an improved RRT algorithm. Sensors (Switzerland). 18(2) (2018). https://doi.org/10.3390/s18020571 22. Kang, J.G., Choi, Y.S., Jung, J.W.: A method of enhancing rapidly-exploring random tree robot path planning using midpoint interpolation. Appl. Sci. 11(18) (2021). https://doi.org/10.3390/ app11188483 23. Wawrzynski, P.: Control policy with autocorrelated noise in reinforcement learning for robotics. Int. J. Mach. Learn. Comput. 5, 91\u201395 (2015) 24. Wawrzynski, P., Tanwani, A.K.: Autonomous reinforcement learning with experience replay. Neural Netw. 41, 156\u2013167 (2013).; Xie, J., Shao, Z., Li, Y., Guan, Y., Tan, J.: Deep reinforcement learning with optimized reward functions for robotic trajectory planning. IEEE Access. 7, 105669\u2013105679 (2019). https://doi.org/10.1109/ACCESS.2019.2932257; Watkins, J.C.H.: Learning from Delayed Rewards. King\u2019s College, Cambridge (1989) 25. Damen, T., Trampert, P., Boughobel, F., Sprenger, J., Klusch, M., Fischer, K., K\u00fcbel, C., Slusallek, P. et al.: Digital reality: a model-based approach to supervised Learning from synthetic data. AI Perspect Adv. 1(1), 2 (2019). https://doi.org/10.1186/s42467-019-0002-0 26. Liu, Q., Wu, Y.: Supervised learning. In: Encyclopedia of the Sciences of Learning, pp. 3243\u2013 3245 (2012). https://doi.org/10.1007/978-1-4419-1428-6_451 27. Hinton, G., Sejnowski, T.: Unsupervised Learning: Foundations of Neural Computation. MIT Press, Cambridge (1999). https://doi.org/10.7551/MITPRESS/7011.001.0001 28. White, D.J.: A survey of applications of Markov decision processes. J. Oper. Res. Soc. 44(11), 1073\u20131096 (1993). https://doi.org/10.2307/2583870 29. Gustavsson, K., Biferale, L., Celani, A., Colabrese, S.: Finding efficient swimming strategies in a three-dimensional chaotic flow by reinforcement learning. Eur. Phys. J. E. 40, 110 (2017) 30. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., Riedmiller, M.: Playing Atari with deep reinforcement learning. arXiv preprint arXiv, 1312.5602 (2013) 31. Sewak, M.: Deep Reinforcement Learning: Frontiers of Artificial Intelligence. Springer (2019). https://doi.org/10.1007/978-981-13-8285-7 32. Dr\u00f6der, K., Bobka, P., Germann, T., Gabriela, F., Dietrich, F.: A machine learning-enhanced digital twin approach for human-robot-collaboration. In: 7th CIRP Conference on Assembly Technologies and Systems, vol. 76, pp. 187\u2013192 (2018). https://doi.org/10.1016/ j.procir.2018.02.010 33. Zayed, S.M., Attiya, G.M., El-Sayed, A., et al.: A review study on digital twins with artificial intelligence and internet of things: concepts, opportunities, challenges, tools and future scope. Multimed. Tools Appl. (2023). https://doi.org/10.1007/s11042-023-15611-7216 A. Fern\u00e1ndez Mart\u00ednez et al.34. Jazdi, N., Ashtari Talkhestani, B., Maschler, B., Weyrich, M.: Realization of AI-enhanced industrial automation systems using intelligent Digital Twins. Procedia CIRP. 97, 396\u2013400 (2020) 35. Hofmann, W., Branding, F.: Implementation of an IoT- And cloud-based digital twin for real-time decision support in port operations. IFAC-PapersOnLine. 52(13), 2104\u20132109 (2019) 36. Bilberg, A., Malik, A.A.: Digital twin driven human\u2013robot collaborative assembly. CIRP Ann. (2019). https://doi.org/10.1016/j.cirp.2019.04.011 37. Lillicrap, T.P., et al.: Continuous control with deep reinforcement learning. arXiv:1509.02971. (2016). https://doi.org/10.48550/arXiv.1509.02971 38. Maoudj, A., Hentout, A.: Optimal path planning approach based on Q-learning algo-rithm for mobile robots. Appl. Soft Comput. 97, 106796 (2020). https://doi.org/10.1016/ J.ASOC.2020.106796 39. Chen, X., 5-axis coverage path planning with deep reinforcement learning and fast parallel col-lision detection (2020). Available: https://smartech.gatech.edu/handle/1853/62825. Accessed 28 Aug 2022 40. Grondman, I., Busoniu, L., Lopes, G.A.D., Babu\u0161ka, R.: A survey of actor-critic reinforcement learning: standard and natural policy gradients. IEEE Trans. Syst. Man Cybern. Part C Appl. Rev. 42(6), 1291\u20131307 (2012). https://doi.org/10.1109/TSMCC.2012.2218595 41. Chen, L., Jiang, Z., Cheng, L., Knoll, A.C., Zhou, M.: Deep reinforcement learning based trajectory planning under uncertain constraints. Front. Neurorobot. 16, 80 (2022). https:// doi.org/10.3389/FNBOT.2022.883562 42. Jim\u00e9nez, P., Torras, C.: Perception of cloth in assistive robotic manipulation tasks. Nat. Comput. 19, 409\u2013431 (2020). https://doi.org/10.1007/s11047-020-09784-5 43. Colom\u00e9, A., Torras, C.: Dimensionality reduction for dynamic movement primitives and application to bimanual manipulation of clothes. IEEE Trans. Robot. 34(3), 602\u2013615 (2018). https://doi.org/10.1109/TRO.2018.2808924 44. Cusumano-Towner, M., Singh, A., Miller, S., O\u2019Brien, J.F., Abbeel, P.: Bringing clothing into desired configurations with limited perception. In: Proceedings of IEEE Interna-tional Conference on Robotics and Automation (ICRA), vol. 2011, pp. 1\u20138 (2011) http:// graphics.berkeley.edu/papers/CusumanoTowner-BCD-2011-05/ 45. Hamajima, K., Kakikura, M.: Planning strategy for task of unfolding clothes. Robot. Auton. Syst. 32(2\u20133), 145\u2013152 (2000). https://doi.org/10.1016/S0921-8890(99)00115-3 46. Hou, Y.C., Sahari, K.S.M.: Self-generated dataset for category and pose estimation of deformable object. J. Rob. Netw. Artif Life. 5, 217\u2013222 (2019). https://doi.org/10.2991/ jrnal.k.190220.001 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.A Participatory Modelling Approach to Agents in Industry Using AAS Nikoletta Nikolova, Cornelis Bouter, Michael van Bekkum, Sjoerd Rongen, and Robert Wilterdink 1 Introduction With the increasing number of assets being digitized, all of which are expected to be interoperable with each other, the need for well-designed information models grows. Such models describe a given entity in a machine-readable way and enable interpreting, usage and reasoning with data from previously unknown devices. The usual approach to make these information models is through a heavy standardization process in which a large number of organizations all have to come to a common understanding of definitions and approaches, after which all parties implement this understanding in their systems [17]. These standards are usually well-scoped and documented, making them easier to use. For developers, this provides a steady base to build upon without fear of the implementation becoming outdated quickly due to a newly released version of a standard. Unfortunately, these standardization Cornelis Bouter, Michael van Bekkum, and Sjoerd Rongen contributed equally to this work. N. Nikolova \u00b7 C. Bouter \u00b7 M. van Bekkum (\u0002) Data Science, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The Netherlands e-mail: nikoletta.nikolova@tno.nl; cornelis.bouter@tno.nl; michael.vanbekkum@tno.nl; sjoerd.rongen@tno.nl; robert.wilterdink@tno.nl S. Rongen Data Ecosystems, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The Netherlands R. Wilterdink Advanced Computing Engineering, Netherlands Organisation for Applied Scientific Research (TNO), Den Haag, The Netherlands \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_12217218 N. Nikolova et al.efforts tend to be slow, often taking multiple years before agreement is reached, for example, ISO standards take 18 to 36 months to be developed [8]. Because of their slow development nature, formal standardization processes are not universally suitable for all applications. For example, when developing a new product, it is not feasible to delay the product launch by months, or even years, because an agreement needs to be reached on the information model. As such, currently, during development, there is little alignment done. Instead, the product developer creates a model with the information that they consider necessary. This is similar to what has been happening in the development of linked data ontologies, where there are few formal standards standardized by W3C (RDF, OWL, SHACL) defining the metamodel. A large number of common use case-specific models made by institutions unrelated to W3C have become de facto standards, such as Friend of a Friend,1 Prov-o,2 Schema.org.3 These de facto standards are commonly used by individuals designing their models and enable easier alignment between a large number of use case-specific models. This results in a large number of datasets that mostly use domain-specific ontologies, while they can still be related to each other as done with the Linked Open Data Cloud.4 We believe these de facto standards are vital to quickly defining the semantic model. This belief appears to be shared with organizations in the manufacturing industry, as they have developed their own metamodel to ensure domain models can be aligned with each other. The standardized Asset Administration Shell (AAS) defines how to structure the information model of your asset without specifying what your asset is or what its information model is, cf. [2]. This provides a structure for various organizations to express interoperable models, which may become de factoo standards. However, in the Asset Administration Shell community, we detect a lack of tools and methodologies that allow these bottom-up developed AAS submodels to rise to the level of de facto standards. This leaves us with formal standards (such as those published by the Industrial Digital Twin Association (IDTA) [7]) and lots of use case-specific models which lack the reuse of domain-relevant models which aids their interoperability. In this paper, we build upon earlier work for AAS modelling practices [3] and agent modelling approaches [10] to present a set of tools, aiming to help inter-operability and standardization. We build on lessons learned from the MAS4AI5 European project in which software agents were described using an AAS utilizing a reusable model of describing software agents. The methodology referred to in this paper was developed within the European DIMOFAC6 project. In this work, we aim1 http://xmlns.com/foaf/0.1/. 2 https://www.w3.org/TR/prov-o/. 3 https://schema.org/. 4 https://lod-cloud.net/. 5 https://www.mas4ai.eu. 6 https://dimofac.eu/. A Participatory Modelling Approach to Agents in Industry Using AAS 219to aid in developing better bottom-up models of sufficient quality to become de facto standards and can then be adopted. For this, we present tooling and a methodology. The rest of the paper starts with an overview of the relevant background and previous research. Afterward, we explain in three consecutive sections the model, methodology, and software tools we developed. Lastly, we provide an analysis of how our work can be used, what its limitations are, and what the next steps are. 2 Background To achieve interoperability between collaborating parties, an agreement on seman-tics is needed. An information standard is required to effectively connect systems, organizations, and work. Commonly this is done via formal standardization pro-cesses such as those facilitated by ISO, governments, or large sector organizations. It can also be done on a meta-level with a higher level of abstraction. An example is the usage of RDF [15], OWL [12], and SHACL [14] as a standardized way to express domain language in a machine-readable format. In these cases, the metamodel has gone through a strict extensive standardization procedure, but the domain models based on it can be freely published by their authors. Industry 4.0 introduced the meta-language AAS [13]. It is a semantic model, which provides a structure to describe assets in a machine-readable way including a standardized interaction interface. The standard is young, resulting in a lack of an established community, which actively implements it, or a uniform process for designing, defining, or implementing an AAS. To enable such a task, it is important to consider three main elements: (1) what the models represent; (2) how can they be created; (3) how can they be standardized. When cogitating on what information models represent, we consider not only physical but also digital assets. Particularly, as agents are becoming more widely adopted in industrial applications, it is imperative to have an AAS modelling strategy. Recent works, such as the one by [11] propose a way to model two types of agents\u2014product and resource agents. Our previous work [10] provides a more general solution to this by presenting a use case-agnostic general agent model structure, which we further extend in this paper. When developing AAS models, the current approach is focused on using the AAS library provided by the IDTA [7], as it contains the set of the currently standardized AAS models available. As such, this is the first place many AAS users will check when looking for a model. However, the available library is not a complete overview of all AAS submodels that have been made and introducing a new submodel to it is time-consuming. Although the IDTA\u2019s contribution to standardization is indispensable for the development of a thriving AAS ecosystem, its approach is top-down. That is to say, when having developed a domain-specific AAS submodel it goes through multiple checks and reviews before being published [1]. While this brings the advantage of high-quality models and a steady base for developers to build their solutions, it is a slow process which is bottlenecked220 N. Nikolova et al.by the speed at which information models can be reviewed and consensus can be reached. To be able to achieve widely adopted semantic interoperability, it is needed to facilitate also a bottom-up approach. Currently, there is a lack of common standardization, which is universally used, as shown in the work of [9]. To tackle this, there are multiple different approaches employed toward developing a common method\u2014[5] proposes a solution using OPC-UA, [4] defines an interoperability framework for digital twins, and [6] offer  a solution using ontologies. We tackle interoperability from the perspective of what is needed for a standardization approach to happen and how can it be implemented. Specifically, we look at the topic of agents and how their AAS modelling process can be standardized. We develop a set of tools, which can be used to simplify and streamline the process of modelling with AAS. To the best of our knowledge, there is no current common process. We place all those developments in the context of real Industry 4.0 applications. 3 AAS Model for an Agent Standardization and interoperability require a common approach toward informa-tion representation and more particularly modelling. When modelling manufactur-ing environments, it is important to consider not only physical but also digital assets. More specifically, one may consider these digital assets to be agents responsible for a piece of logic, as such it is essential to have a way to model such an asset. To address this, we provide a general model structure, which can be used when creating a model of an agent using the asset administration shell. 3.1 General Model Structure The general model structure follows the work we presented in [10]. We provide a set of general and standard submodels which aim to provide a structure, which can be followed when creating any agent model. The model is shown in Fig. 1, in which we add the Parameterization and Configuration submodels to replace the Communication submodel from earlier work. The purpose of this change is to address the difference between the information locally needed for an agent to be defined, and the data, defined by the framework where it is deployed. This creates a concrete distinction between what type of information is needed in the submodels and where it comes from.A Participatory Modelling Approach to Agents in Industry Using AAS 221Fig. 1 General agent structure, which contains seven different distinct submodels, split into two categories 3.2 Generic Submodels The set of generic submodels contains information, which is considered task agnostic and is needed for correct tracking and connection of the developed agent. The definitions follow from the work of [10]. \u2022 Documentation: The Documentation submodel contains information, which is relevant for describing any background and specifications for the agent. Example properties for this would be details about the developer, version, required software, language, algorithms, etc. \u2022 Configuration: The Configuration submodel contains information, which is needed/provided by the framework or agent management system, where the agent will live. It provides information such as where the proper interface connections can be found, how to configure, etc. This is information which is determined by the framework and is usually shared between multiple agents. \u2022 Parameterization: The Parameterization submodel contains information regard-ing the exact parameters that an agent needs to be able to initialize. Those parameters are determined by the exact algorithm and construction of the agent and are specific for a particular agent type. \u2022 Capabilities: The Capabilities submodel contains information about what the agent can do. This can be done in various ways, including in combination with RDF [16].222 N. Nikolova et al.3.3 Specific Submodels Specific Submodels [10] are those, which depend on the use case. They contain information, which is determined by the exact situation and setting where the agent is to execute its work. \u2022 Task: The task submodel provides a description of the exact task that the agent has to execute. Depending on the case there can be a single task such as \u201cMoving,\u201d but it can also be a set of multiple sub-tasks. \u2022 Resources: The resources submodel aims to wrap in one place the connections to all resources and corresponding relevant information from them, which the agent would need. This would, for example, contain properties such as \u201cMachine Capability\u201d and \u201cOperator Availability.\u201d \u2022 Results: The results submodel presents the type of results and corresponding details that the agent provides after its task is executed. There can be multiple results such as \u201cAnalysis,\u201d \u201cPlan,\u201d etc. 3.4 Usage The concept of the general agent structure is to serve as a base skeleton model, which provides a clear split and indication regarding what type of information needs to be contained in an agent model. The aim is to use the structure, when creating models of new agents, starting from concretely specifying the submodels to filling them in. To provide an approach for this, we have defined a methodology based on the work of [3], described in the next section. 4 Methodology for Developing an AAS When creating a rich semantic information model there are several aspects to consider. To support proper modelling practices, we suggest the usage of a well-defined process which ensures no steps are missed. We propose a methodology based on earlier work by [3], which we extend to make it more applicable when modelling not only physical assets but also software assets. The methodology is additionally extended by identifying four phases, described below and visually represented in Fig. 2.A Participatory Modelling Approach to Agents in Industry Using AAS 223Fig. 2 Updated AAS Development Methodology, visualizing the four separate steps\u2014design, define, align, deploy 4.1 Phases The methodology is separated into four phases covering the implementation of a set of AAS models. The methodology starts with the Design phase which covers the knowledge representation necessary to describe the factory concepts underlying this problem. This phase requires no special knowledge about the AAS or other Industry 4.0 technologies. It is an application-independent phase of modelling the relevant factory assets and their properties. The domain expert is safeguarded from having to consider Industry 4.0 requirements. A further specification of the consideration of the four sub-steps is described in [3]. The methodology concludes with an evaluation phase separated into two parts: (1) the alignment of the existing data models being used in the factory with the developed AAS models and (2) the deployment of the tooling for which the AAS interoperability was established. The former is called verification since it is a process we can formally check: if the factory data elements have been aligned with the AAS data elements, both are aligned. The deployment is the validation step because it cannot be formally verified. We consider the AAS model validated when the tool the user had in mind at the start of the process can be built using the AAS models. 4.2 Agent Modelling In the case of agent modelling, the standard process described above is directly applicable thanks to the two added states\u2014provisioning and instantiation. Further-more, the process can be split into four distinct stages, referring to the different implementation stages of agent development. 1. Design: The design stage is the use case specification moment. This is, for example, the point in time when we aim to identify the types of agents which224 N. Nikolova et al.would be relevant/useful to the particular situation, such as product agent, resource agent, planning agent, etc.  2. Define: The define stage is the template generation phase. At this moment the developers can create/choose standard submodels, which can be used to provide a skeleton structure for the developed agents. More particularly, the aim is to fill the general agent structure, which was described in Fig. 1. For the General Agent Submodels, this would mean identifying the template structure to be used, whereas, for the Specific Agent Submodels, it would require identifying their exact definition and expected content. 3. Align: The align stage focuses on filling in the submodels in the created templates with any needed properties, mainly details such as exact parameters needed for the agent to operate properly. At the end of this stage, it is expected that the Agent templates contain all the relevant information. 4. Deploy: Lastly, the deployment stage takes care of the spawning of the agent. That includes filling all properties (such as Agent ID, Task ID, etc.) through the framework or agent management system, which is used. Since multiple entities of a single type of agent can be active, this is the phase where they are created and the corresponding models are filled. 5 AAS Model Repository One of the key components of interoperability is enabling seamless sharing and distribution of developments. In the case of AAS models, there is currently no offi-cial software, which provides a simple and user-friendly interface for visualization and sharing. This is important since the correct handling of this process can enable collaboration between different parties and support the smooth distribution of work. Therefore, to close the loop, we developed an online public repository (https:// admin-shell-library.eu/). It focuses on providing a way to share models between parties and visualize them in a user-friendly manner. 5.1 Functionality The main functionalities of the repository are (1) visualization and (2) distribution, both focusing on making the AAS models\u2019 development and cooperation easier. Currently, the majority of development happens behind closed doors in silos, with distribution and information sharing only happening at the last step of the process. It is very important to enable ways for cooperation, especially since the increased interest in the AASs also creates accidental duplication of work. One of the main challenges for distribution is the lack of direct sharing possibilities when it comes to AAS models. Presently, the standard process requires downloading from a source (such as GitHub) and running an extra program (such as AAS package explorer) to open and view a model. This can hinder the developmentA Participatory Modelling Approach to Agents in Industry Using AAS 225process, since more steps are required and hence more time and focus are needed to review a model. What the AAS repository enables is direct link sharing. Once a developer uploads their model online, it is possible to get a link, which leads to a web page visualization of the AAS. The link can be shared with other parties and removes the need for any software installation, which can significantly simplify the sharing and collaboration process, which are key for creating general and reusable models. In general, a full AAS contains multiple Submodels, which each contain several (nested) SubmodelElements. For each of these Submodels and SubmodelElements, semanticIds, descriptions and Concept Descriptions should be maintained. Moreover, multi-language SubmodelElements exists, which can have several values attached for the various supported languages. Because of this size and complexity, a model can have, working collaboratively on an AAS template should be supported with proper visualization. Currently, the most commonly used tool is also the one used for model creation\u2014the package explorer. While this is useful software, it can be unintuitive for non-accustomed users and increase complexity when looking at a model (especially for external parties, who do not work with this program). The repository provides a web interface, which removes the need for separate software tooling for viewers. 5.2 Working Principle The working principle of the repository is visualized in Fig. 3. The figure visualizes the different interactions that a user can have with the repository and the high-level corresponding processing steps. \u2022 Upload: A user can upload a model to the repository by filling in the metadata and providing the corresponding .aasx file. This model will be checked for errors by the system and if no errors are found, it would be uploaded to the repository. \u2022 Modify: A user can modify the metadata of a model or upload a newer .aasx version at any point. \u2022 Visualize: The model visualizes multiple details of the .aasx model. It provides collapsible submodels, each containing the corresponding elements. There is a possibility to show concept description and most importantly example data. This makes it easier for a viewer to understand the whole process of the models. If example data contains references to other models included in the repository, they can easily be followed via Web links. Especially for complex composite models, this can make a significant difference. \u2022 Share: Any of the models can be shared via a link, which directly links to the relevant AAS file. \u2022 Access: Model access is managed by a combination of groups/users and roles. Each model can have several groups or individual users assigned. Additionally,226 N. Nikolova et al.Fig. 3 Repository working principle, where black arrows represent interaction with the user and grey represent internal connections for each user or group a role must be specified, i.e., guest, member, or editor. The combination of group/user and role then determines the effective access level. This ensures that during each step in the development process, the models can be shared with appropriate access levels and no sensitive information is publicly available. 6 Discussion In this paper, we presented three ways of improving the creation of bottom-up standards which may rise to the level of de facto standards. Firstly, we presented the notion of a generic asset structure, such as for software agents, consisting of multiple submodels. Secondly, we presented a methodology on how to create your AAS models, and finally, we propose a repository for these templates which may in the findability and adoption of good AAS submodels. 6.1 Maturity of the AAS Although we have presented a number of ways to improve the usage of the AAS and to ensure semantic interoperability we do not believe this will on its own lead to wide-spread adoption and an active ecosystem of AAS users. We believeA Participatory Modelling Approach to Agents in Industry Using AAS 227it is important to nurture an environment in which proper AAS modelling can thrive. However, before this technology blossoms, we believe there are still several improvements that may be made. This is to be expected given the immaturity of the AAS technology but that does not make them less pressing to tackle. Models To construct reusable and interoperable models, it is essential to provide clear templates and corresponding specifications. Currently, the AAS implementations do not allow for specifying what components are needed for a minimal implementation. This is especially important for future uses, as it would provide a way for users to know what is the least information they need to fill in for their model to be viable. Model Constraints To make the usage of semantic models more beneficial to business users and give implementers more guidance on what parts of the AAS model are mandatory and which are optional, it would be beneficial to add the ability to constrain the instantiation of the AAS model. A basic implementation of this would support defining cardinality constraints to the AAS model, defining which properties are mandatory, and which are optional. This could then be extended with value contents and potentially even some simple reasoning, to implement basic business logic in the model. For example, the intended use of a creation date and maintenance date of an asset may make it impossible to maintain the asset before it was created. However, the current AAS standard does not allow for a way to express such constraints. In semantic modelling, we have been in a similar situation not that long ago with the adoption of the Web Ontology Language (OWL), a powerful modelling language which did not get adopted as quickly in business as it could have been due to a lack of easily implemented value constraints. The creation of the Shape Constraint Language (Shacl) largely solved this problem and has increased the adoption of RDF in business contexts. Standardization The methodology and the repository synergetically combine to improve the bottom-up standardization of the AAS. The methodology facilitates the identification of additional submodels that are lacking among what is currently available, as well as aiding the user in following the AAS paradigm. The repository facilitates the sharing of work-in-progress submodels with other users, such that the community can swiftly adopt new work. This approach complements the top-down approach of a comprehensive IDTA standardization procedure. In top-down standardization, the authority of the standardization body ensures the quality of the approved models. When adopting a free-for-all approach of submitting submodels to the repository, the quality should be ensured differently. Firstly, the methodology functions as a way to increase the shared knowledge of the modelling paradigm. Secondly, statistics about the usage of the various models can indicate which models turn into de facto standards, thereby giving a measure of their quality. Additional research and implementation work may be needed to tailor the repository for this purpose.228 N. Nikolova et al.The increased accessibility of the repository can aid the various groups who can be expected to share their models. The methodology is primarily intended for user integrators leveraging the AAS for improved interoperability to support a factory application. Another audience that may use the repository is the machine manufacturer who wants to share instantiated and specialized templates for their machines. These submodels similarly benefit from a bottom-up approach without a mandatory procedure. Collaborative Modelling Currently, the process of making an AAS model is primarily a solitary effort in which the modeller still needs to actively try to reach out for input. However, the whole point of standards is that they align between different parties. As such, adding more tools to facilitate collaborative modelling would be beneficial for the creation of a proper AAS. The presented repository and development methodology already aid in this, but we believe further steps could be taken to support a shared model discussion and increase iteration speed during the development process. 7 Conclusion The methodology and the repository described in this paper provide us with means to develop AAS models as de facto standards for non-physical assets from bottom-up, community-based efforts. The MAS4AI project has shown that the methodology can easily accommodate particular use case requirements by allowing for straightforward bottom-up extensions to the models. An industry use case in MAS4AI on implementing planning agent software based on ISA-95 models has shown that bottom-up standardization is instrumental. The required models were created by applying the aforementioned methodology in a collaborative effort by modelling experts, domain experts, and software developers and have led to successful integration and deployment in the use case. The use of the repository has similarly led to clear benefits in both the MAS4AI and the DIMOFAC project: sharing the AAS model templates with all stakeholders in an easy-to-use, intuitive way has made them more accessible to all parties and has promoted discussion and feedback on their contents, thus ensuring more wide-spread support for the models. Acknowledgments The research leading to these results has been funded by the European Commission in the H2020 research and innovation program, under Grant agreement no. 957204, the \u201cMAS4AI\u201d project (Multi-Agent Systems for Pervasive Artificial Intelligence for Assisting Humans in Modular Production Environments) and under grant agreement No. 870092, the DIMOFAC project (Digital & Intelligent MOdular FACtories).A Participatory Modelling Approach to Agents in Industry Using AAS 229References 1. 4.0 PI: Structure of the asset administration shell. continuation of the development of the ref-erence model for the Industrie 4.0 component (2016) . Tech. rep. https://industrialdigitaltwin. org/wp-content/uploads/2021/09/01_structure_of_the_administration_shell_en_2016.pdf 2. Bader, S., Barnstedt, E., Bedenbender, H., et al.: Details of the Asset Administration Shell. Part 1\u2014The exchange of information between partners in the value chain of Industrie 4.0 (Version 3.0RC02) (2022) 3. Bouter, C., Pourjafarian, M., Simar, L., et al.: Towards a comprehensive methodology for modelling submodels in the industry 4.0 asset administration shell. In: 2021 IEEE 23rd Conference on Business Informatics (CBI), vol. 02, pp. 10\u201319 (2021) 4. Budiardjo, A., Migliori, D.: Digital twin system interoperability framework. Tech. rep. Digital Twin Consortium, East Lansing, Michigan (2021). https://www.digitaltwinconsortium.org/pdf/ Digital-Twin-System-Interoperability-Framework-12072021.pdf 5. Cavalieri, S.: A proposal to improve interoperability in the industry 4.0 based on the open platform communications unified architecture standard. Computers 10(6), 70 (2021). https:// doi.org/10.3390/computers10060070, https://www.mdpi.com/2073-431X/10/6/70, number: 6 Publisher: Multidisciplinary Digital Publishing Institute 6. Huang, Y., Dhouib, S., Medinacelli, L.P., et al.: Enabling semantic interoperability of asset administration shells through an ontology-based modeling method. In: Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings. Association for Computing Machinery, New York, NY, USA, MODELS \u201922, pp. 497\u2013502 (2022). https://doi.org/10.1145/3550356.3561606 7. IDTA: Industrial digital twin association (2023). https://industrialdigitaltwin.org/en/ 8. ISO: Target date planner (2023). https://www.iso.org/files/live/sites/isoorg/files/developing_ standards/resources/docs/std%20dev%20target%20date%20planner.pdf 9. Melluso, N., Grangel-Gonz\u00e1lez, I., Fantoni, G.: Enhancing industry 4.0 standards inter-operability via knowledge graphs with natural language processing. Comput. Ind. 140, 103676 (2022). https://doi.org/10.1016/j.compind.2022.103676, https://www.sciencedirect. com/science/article/pii/S0166361522000732 10. Nikolova, N., Rongen, S.: Modelling agents in industry 4.0 applications using asset admin-istration shell. In: Proceedings of the 15th International Conference on Agents and Artificial Intelligence (2023). https://doi.org/DOI:10.5220/0011746100003393 11. Ocker, F., Urban, C., Vogel-Heuser, B., et al.: Leveraging the asset administra-tion shell for agent-based production systems. IFAC-PapersOnLine 54(1), 837\u2013844 (2021). https://doi.org/https://doi.org/10.1016/j.ifacol.2021.08.186, https://www.sciencedirect. com/science/article/pii/S2405896321009563. 17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021 12. OWL Working Group: Owl 2 web ontology language document overview (2012). Tech. rep., W3C. https://www.w3.org/TR/owl2-overview/ 13. Plattform Industrie 4.0: Details of the asset administration shell from idea to implemen-tation (2019). https://www.plattform-i40.de/IP/Redaktion/EN/Downloads/Publikation/vws-in-detail-presentation.pdf 14. RDF Data Shapes Working Group: Shapes constraint language (SHACL) (2017). Tech. rep., W3C. https://www.w3.org/TR/shacl/ 15. RDF Working Group: RDF 1.1 primer (2014). Tech. rep., W3C. https://www.w3.org/TR/rdf11-primer/ 16. Rongen, S., Nikolova, N., van der Pas, M.: Modelling with AAS and RDF in industry 4.0. Comput. Ind. 148, 103910 (2023). https://doi.org/https://doi.org/10.1016/j.compind.2023. 103910, https://www.sciencedirect.com/science/article/pii/S016636152300060X230 N. Nikolova et al.17. Toussaint, M., Krima, S., Feeney, A.B., et al.: Requirement elicitation for adaptive standards development. IFAC-PapersOnLine 54(1), 863\u2013868 (2021). https://doi.org/ https://doi.org/10.1016/j.ifacol.2021.08.101, https://www.sciencedirect.com/science/article/ pii/S2405896321008508. 17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.I4.0 Holonic Multi-agent Testbed Enabling Shared Production Alexis T. Bernhard, Simon Jungbluth, Ali Karnoub, Aleksandr Sidorenko, William Motsch, Achim Wagner, and Martin Ruskowski 1 Introduction Nowadays, globalization changes the manufacturing environment significantly. Global business signifies global competition and intends a need for shorter product life cycles, whereas consumer-oriented businesses foster customized products. However, rigidly connected supply chains have proven vulnerable to disruptions. Therefore, requirements are changing focusing on adaptability, agility, responsive-ness, robustness, flexibility, reconfigurability, dynamic optimization and openness to innovations. Isolated and proprietary manufacturing systems need to move ahead with decentralized, distributed, and networked manufacturing system architectures [20]. Cloud Manufacturing could be a solution for highly diversified and recon-figurable supply chains. Liu et al. define it as \u201c[. . .] a model for enabling the aggregation of distributed manufacturing resources [. . .] and ubiquitous, convenient, on-demand network access to a shared pool of configurable manufacturing services A. T. Bernhard (\u0002) \u00b7 A. Sidorenko \u00b7 W. Motsch \u00b7 A. Wagner Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI), Kaiserslautern, Germany e-mail: alexis.bernhard@dfki.de; aleksandr.sidorenko@dfki.de; william.motsch@dfki.de; achim.wagner@dfki.de S. Jungbluth \u00b7 A. Karnoub Technologie-Initiative SmartFactory KL e.V., Kaiserslautern, Germany e-mail: simon.jungbluth@smartfactory.de; ali.karnoub@smartfactory.de M. Ruskowski Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory KL e.V., Kaiserslautern, Germany e-mail: martin.ruskowski@smartfactory.de; martin.ruskowski@dfki.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_13231232 A. T. Bernhard et al.that can be rapidly provisioned and released with minimal management effort or interaction between service operators and providers\u201d [22]. SmartFactoryKL shares their vision with the terminology Production Level 4 and Shared Production (SP) [2] that represents reconfigurable supply chains in a federation of trusted partners that dynamically share manufacturing services over a product lifecycle through standardized Digital Twins. Hence, it represents an extension of Cloud Manufacturing. This vision requires sharing data on products and resources. Production data contains sensitive information, leading to fear of data misuse. Thus, additionally to interoperability and standardization, data sovereignty is one major aspect when building a manufacturing ecosystem. In [15], a technology-dependent solution is presented. The authors propose using Asset Administration Shells (AAS) and the concepts of Gaia-X to exchange data in a self-sovereign interoperable way. In this sense, AAS aims to implement a vendor-independent Digital Twin [10], while Gaia-X creates a data infrastructure meeting the highest standards in terms of digital sovereignty to make data and services available. Key elements are compliance with European Values regarding European Data Protection, transparency and trustability [3]. Nevertheless, the authors of [15] focus more on the business layer and the data exchange process rather than intelligent decision-making processes. Due to their characteristics, Multi-Agent System (MAS) seems to be a promising natural choice for implementing the logic and interactions among different entities. In our contribution, we present the structure of MAS for a modern production system to cope with the upper mentioned challenges. We focus on the intra-organizational resilience of the shop-floor layer to provide the necessary flexibility to enable an SP scenario. In Sect. 2, the considered concepts for the usage of MAS in industrial applications are described. Section 3 describes the architecture of the applied MAS and Sect. 4 gives an overview about the characteristics of a plant specific holonic MAS and implements a prototype in the demonstrator testbed at SmartFactoryKL. 2 State of the Art To use MAS in modern production environments, MAS needs to manage the complexity of fractal control structures of the shop-floor layer. Therefore, we elab-orate on the control structures of industrial manufacturing systems (see Sect. 2.1). In Sect. 2.2, terminology like skill-based approach and cyber-physical production systems (CPPS) are mentioned to deal with the encapsulation of production environment and separate the implementation from the functionality. Section 2.3 compares Agents and Holons and relates the upper mentioned concepts with the holonic paradigm.I4.0 Holonic Multi-agent Testbed Enabling Shared Production 2332.1 Control Architectures in the Manufacturing Domain Recently, computerization of industrial machines and tools led to hardware equipped with some kind of software-controlled intelligence. Digitalization trends enable and empower flexibility, shifting static to dynamic optimization. Contributions like [15, 23, 30] list the need for common information models, standardized interfaces, real-time and non-real-time cross-layer communication, separation of concern, flexibility, semantics, intelligence, scalability, inter-enterprise data exchange, collaborative style of works, privacy and self-sovereignty. Leit\u00e3o and Karnouskos [20] identify three principal types of control struc-tures in industrial manufacturing systems: centralized, (modified) hierarchical and (semi-)heterarchical architectures. A centralized architecture has only one decision-making entity at the root of the system. It handles all planning and control issues, and the other entities have no decision power. The centralized architecture works best in small systems where short paths lead to effective optimization in a short amount of time. A hierarchical organization of control distributes the decision-making overall hierarchical levels. Higher levels make strategic-oriented decisions, and lower levels focus on simple tasks. Such architectures can be efficient in static production environments and are more robust to failures than centralized control structures. The hierarchical architectures are typical for the computer-integrated manufacturing paradigm. In contrast to the master-slave flow of control in the hierarchical structures, the heterarchical architectures rely on cooperation and collaboration for decision-making. In fully heterarchical architectures, there are no hierarchies at all and each entity is simultaneously master and slave. Such an organization is typical for default MASs. These control structures are highly flexible, but the global optimization goals are hard to achieve because knowledge and decisions are localized by each agent and require a number of interactions between the agents to make them global. This was one of the major criticism of classical MAS architectures. This led to the invention of semi-heterarchical control structures, which are also called loose or flexible hierarchies. Lower levels of such architectures should react quickly to disturbances and make fast decisions. These levels are characterized by hierarchical organization and mostly reactive agents. The higher levels appreciate the flexibility of heterarchical structures and intelligent decision-making by deliberative agents. Semi-heterarchical control structures are typical for so-called holonic architectures. 2.2 Cyber-Physical Production Systems A flexible and modular production environment manifests in the concept of Cyber-Physical Production Modules (CPPMs), which provide standardized interfaces to offer different functionalities as a service [17]. Therefore, the skill-based approach aims to encapsulate the production module\u2019s functionalities and decouples them234 A. T. Bernhard et al.Fig. 1 Representation of a cyber-physical production system from the specific implementation with the aim of increasing the flexibility. As visualized in Fig. 1, CPPMs can be combined into a CPPS to perform control tasks and react to information independently. CPPS connects the physical and digital worlds and react to information from the environment and environmental influences [8]. CPPMs require a need for a vendor-independent self-description to perform production planning and control. AAS represents an approach to achieve this standardized digital representation, where submodels (SM) are used to describe domain-specific knowledge [10]. The Plattform Industrie 4.0 proposes an infor-mation model composing the concepts of capabilities, skills and services as machine-readable description of manufacturing functions to foster adaptive produc-tion of mass-customizable products, product variability, decreasing batch size, and planning efficiency. The Capability can be seen as an \u201cimplementation-independent specification of a function [. . .] to achieve an effect in the physical or virtual world\u201d [25]. Capabilities are meant to be implemented as skills and offered as services in a broader supply chain. From the business layer, the service represents a \u201cdescription of the commercial aspects and means of provision of offered capabilities\u201d [25]. From the control layer, Plattform Industrie 4.0 defines a Production Skill as \u201cexecutable implementation of an encapsulated (automation) function specified by a capability\u201d [25] that provides standardized interfaces and the means for parametrization to support their composition and reuse in a wide range of scenarios. The skill interface is mostly realized with OPC UA, since it has proven itself in automation technology. Topics such as OPC UA and AAS can lead to confusion regarding the separation of concerns. AAS is used as linkage to the connected world and lifecycle management in adherence to yellow pages, whereas OPC UA is applied for operative usage.I4.0 Holonic Multi-agent Testbed Enabling Shared Production 2352.3 Agents and Holons The study of MAS began within the field of Distributed Artificial Intelligence. It investigates the global behavior based on the agent\u2019s fixed behavior. The studies compromise coordination and distribution of knowledge. In this context, Leit\u00e3o and Karnouskos define an agent as \u201c[. . .] an autonomous, problem-solving, and goal-driven computational entity with social abilities that is capable of effective, maybe even proactive, behavior in an open and dynamic environment in the sense that it is observing and acting upon it in order to achieve its goals\u201d [20]. MAS is a federation of (semi-)autonomous problem solvers that cooperate to achieve their individual, as well as global system\u2019s goals. To succeed, they rely on communication, collaboration, negotiation, and responsibility delegation [20]. MAS was motivated by subjects like autonomy and cooperation as a general software technology, while the emergence in the manufacturing domain has been growing recently. The holonic concept was proposed by Koestler to describe natural beings that consist of semi-autonomous sub-wholes that are interconnected to form a whole [16]. Holonic Manufacturing System (HMS) is a manufacturing paradigm proposed at the beginning of the 1990s as an attempt to improve the ability of manufacturing systems to deal with the evolution of products and make them more adaptable to abnormal operating conditions [7]. Holonic production systems are fundamen-tally described in the reference architecture PROSA, with the aim of providing production systems with greater flexibility and reconfigurability [32]. A Holon is an autonomous, intelligent, and cooperative building block of a manufacturing system for transformation, transportation, storing and / or validating information and physical objects [33]. As shown in Fig. 2, a Manufacturing Holon always has an information processing part and often a physical processing part [4]. Holons join holarchies that define the rules for interaction between them. Each Holon can be simultaneously a part of several holarchies and as well as a holarchy itself. This enables very complex and flexible control structures, also called flexible hierarchies. It is important to note that the cooperation process also involves humans, who might enter or exit the Holon\u2019s context [4]. In summary, HMS can be seen as an analogy to CPPS, where skills provide the control interface to the physical processing parts. Human Interface Inter-Holon Interface Physical Control Decision Making Physical Processing Information Processing Physical Processing Fig. 2 General Architecture of a Holon in accordance to [7]236 A. T. Bernhard et al.Previous research investigated the terminology between Agents and Holons. Giretti and Botti [7] perform a comparative study between the concepts of Agents and Holons. The authors explain that both approaches differ mainly in motivation but are very closely related, and a Holon can be treated as a special type of agent with the property of recursiveness and connection to the hardware. Subsequently, the authors define a recursive agent. One form of a MAS can be a holonic MAS, where there is a need for negotiation to optimize the utility of individual agents as well as the utility of their Holons [1]. The choice is more determined by the point of view. On the other hand, Valckenaers [31] explains that HMS and MAS frequently are seen as similar concepts, but it is important to be aware of contrasting views. In the author\u2019s opinion, it no longer holds to see MAS as a manner to implement HMS. HMS researches\u2019 key achievement is the absence of goal-seeking. The authors explicit distinguish between intelligent beings (Holons) to shadow the real-world counterpart and intelligent agents as decision makers. We want to sharpen the view and raise awareness of the different wording. Nevertheless, we treat a Holon as a special type of Agent. The ADACOR architecture presents an example of a holonic MAS that provides a multi-layer approach for a distributed production and balancing between central-ized and decentralized structures to combine global production optimization with flexible responses to disturbances [19]. Regarding modular production systems, the concept of Production Skills of CPPMs is important for usage in a multi-agent architecture to interact with a hardware layer [28]. To interact in a dynamic environment, agents furthermore need an environment model to describe the agent\u2019s knowledge and a standardized communication. The former serves to describe the respective domain of the agent, to configure the agent\u2019s behavior and aggregate information from external knowledge basis or other agents [20]. It requires a standardized information model to ensure autonomous access. In adherence to CPPS, AAS is suitable to describe the agents\u2019 properties, i.e., communication channels, physical connection, identification and topology. The latter might be direct or indirect. Direct communication means an exchange of messages. Known communication languages like Knowledge Query and Manipulation Language (KQML) or Agent Communication Language (ACL) rely on speech acts that are defined by a set of performative (agree, propose). Indirect communication relies on pheromone trails of ants, swarm intelligence, the concept of a blackboard, or auctions [20]. Interactions between AAS is mentioned as I4.0 Language (I4.0L) that is specified in VDI/VDE 2193. It defines a set of rules compromising the vocabulary, the message structure and the semantic interaction protocols to organize the message sequences to the meaningful dialogues. I4.0L implements the bidding protocol based on the contract network protocol [29].I4.0 Holonic Multi-agent Testbed Enabling Shared Production 2372.4 Agent Framework Agent Frameworks ease development and the operation of large-scale, distributed applications and services. For us, it is especially important that the framework is open, modular, extensible and fosters the holonic concept. [21] and [24] list and discuss a number of agent platforms, while the work of [5] evaluates five different agent languages and frameworks. The results imply that especially SARL language running on Janus platform is superior to other systems in aspects concerning the communication between agents, modularity and extensibility. The biggest advan-tage to other languages is that there are no restrictions regarding the interactions between agents. These positive effects are balanced by the fact that debugging is limited to local applications and, above all, the transfer between the design to the implementation is very complicated. SARL supports dynamic creation of agent hierarchies and implements holonic architecture patterns. Finally, SARL is chosen to implement our MAS. In [27], the authors explain that SARL Agents represent Holons. In the following, we prefer using the notation of a Holon. SARL uses the concepts of Behaviors and Holon Skills to define the entities. As explained in [27], a \u201c[. . .] Behavior maps a collection of perceptions [. . .] to a sequence of Actions\u201d, whereas a Holon Skill implements a specification of a collection of Actions to make some change in the environment. A Capacity provides an interface for the collection of all actions. Though, the focus lies on reusability and lowering of complexity. To avoid confusion with the different meanings of the term skill, the following explicitly refers to Holon Skill or Production Skill. Through the usage of Holon Capacities and Skills, SARL follows modularization in analogy to Capabilities and Production Skill of resources. 3 Towards an Architecture for Modern Industrial Manufacturing Systems The challenge for SP is represented in a need for an architecture that enables flexibility, customizability and copes with dynamic optimization and decision-making. The information model of Capabilities-Skills-Services of the Plattform Industrie 4.0 [25] promises standardization to foster shop-floor-level reconfiguration and dynamic planning. Hence, AAS proves strength regarding the interoperability of system elements. The work of [14] demonstrates a way to use AAS to (re)plan and execute the production and make production resources interchangeable. The authors use AAS as Digital Twin for assets like products and resources. MAS controls the production modules of a work center. This interconnection follows the idea of encapsulation and modularity to enable flexible and technology-independent access to production resources. Encapsulation intends to increase reconfigurability at the shop-floor level. Resources should not perform rigid operations but be assigned tasks that they can process themselves. In [15], an SP network is presented that238 A. T. Bernhard et al.enables data exchange in a self-sovereign interoperable manner. We implement that by combining concepts like Gaia-X, AAS and I4.0L. These technologies seem promising to enable a cross-company supply chain. In [15], we focus on the business layer communication to share data and explain the necessary components to build a data ecosystem. Nevertheless, there needs to be a component that enables logic to connect the shop floor to the connected world. Thus, [15] is our basis to realize inter-organizational communication and the following focuses on the intra-organizational resilience of the shop-floor. 3.1 Multi-agent System Manufacturing Architecture Holonic MAS seems a promising pattern to wrap the factory\u2019s granularity and build complex and resilient systems. It is important to note that the technology to communicate with a customer and other factories might change over time or might differ for individual customers or factories. Consequently, to be technology-independent, our MAS does not include an explicit connection technology. MAS accumulates some of its resource capabilities into services and provides these services to the external world following the principles of service-oriented systems [9]. Besides, the holonic MAS supervises a production system to plan and execute the production and connects a factory to an SP network. Inspired by the upper mentioned concepts, a modern factory is represented in Fig. 3. With reference to the described aspects, the system consists of three main Holons as displayed in Fig. 3. The basic structure follows the general idea of PROSA as described in Sect. 2. The difference between the presented MAS and their architecture is three-fold. First, the tasks of the management of the products are fulfilled by AAS instead of having a Product Holon in PROSA. A more detailed discussion about this change is discussed in 5. Second, the management of orders by Service Holon Product Holon Resource Holon Asset Administration Shell Identification Capabilities Bill Of Material Asset Administration Shell Identification Assured Services Shared Production Network CPPM Drilling  Skills OPC UA Asset Administration Shell Identification Required Service Production Plan Production Logs Fig. 3 The structure of the multi-agent systemI4.0 Holonic Multi-agent Testbed Enabling Shared Production 239the Order Holon is shifted from the Order Holon to the Product Holon. The reason for the new name is that our Product Holon takes care of orders and connects to Product AAS and thus encapsulates two tasks. Third, another Holon called Service Holon is added as an external representation of the factory layer as additional use case to PROSA which does not examine a SP scenario in detail and represents the factory as centralized HMS which spawns Order Holons based on the requests. However, we prefer to decouple the task of spawning Holons and the representation of the factory to achieve a higher resilience and flexibility. Besides these changes, all three Holons are equipped with their own AAS to expose their self-description. This includes an SM Identification to identify the Holon in the MAS and an SM towards the interfaces of the Holon to be able to communicate with different communication technologies and to implement the communication technology independence. In addition, the SM Topology of each Holon describes the internal structure. Part of the structure are all aggregated Sub-Holons of the Holon. This SM eases the initialization of each Holon, especially in case of a restart. In the following two subsections, we present details about the Service Holon in Sect. 3.2 and about the Product Holon in Sect. 3.3. For the Resource Holon, we will give a more detailed description in Sect. 4. The Resource Holon executes production steps by controlling and managing all resources. Each resource is via OPC UA connected to one Resource Holon, which controls its execution. For that purpose, the Resource Holon uses the Resource AAS to store information about the resource. This includes an SM Identification, the provided capabilities of the resource and the SM Bill of Material. In addition, the Resource Holon deals with tasks like lifecycle management of resources, human-machine interaction, resource monitoring and handling multiple communication technologies between the resources. 3.2 Service Holon The Service Holon displayed on the left side of Fig. 3 manages and provides the services of the factory to the connected world. One example of a service is the 3D-printing service, which offers the capability of producing customized products using a fused deposition modeling process. Besides offering services, the Service Holon enables the MAS to process external tasks like ordering a specific product or executing a provided service. Besides that, the Service Holon takes care of the disposition of external services, products or substitutes. Therefore, the Service Holon has the ability to communicate with the SP network via an asynchronous event-based communication based on I4.0L. This implements VDI/VDE 2193 [34, 35] as the chosen communication standard. A more detailed use case for the connection to SP networks is applied in [15]. In the context of external SP Networks, the Service Holon represents the interface to the factory. For this reason, the Service Holon takes care of the Factory AAS. This AAS uses a unique identifier, a name and other general information to identify the240 A. T. Bernhard et al.factory. Furthermore, it contains a description of all assured services, the factory has to offer. Based on this service catalog, other network members can request an offered service. In case of incoming production requests, the Service Holon processes these requests and requests the Product Holon to handle the request. The communication to the Product Holon is like the overall communication between all Holons in the present architecture, asynchronous and event-based. 3.3 Product Holon The Product Holon takes care of the production process and subdivides production tasks into different subtasks. In this context, the holonic approach takes effect. Each Holon is responsible for one task and spawns for every subtask a Sub-Holon. Together, they display the production process in a tree-like manner. To handle these incoming tasks or derived subtasks, each Holon triggers an internal execution at the Resource Holon or requests an external execution from the Service Holon. In the case of an internal execution, each Holon needs to check if the execution is feasible. Therefore, the Product Holon first matches the capabilities given by the resources to the desired capability to fulfill the (sub-)task. If both capabilities fit together, a feasibility check on the resources is triggered to simulate if a resource is able to perform the task under posed conditions (e.g., if the process can supply the desired product quality and evaluate estimated time, costs and consumption). After a successful feasibility check, the Product Holon spawns an AAS as Digital Twin for the product. The Product AAS contains information towards the product identification like a name and a unique identifier. If the AAS contains some subtasks, which require an external execution, the Product AAS contains a description of all required external services to execute the subtask. After starting the production process, the Product Holon further controls the process by triggering production steps or monitoring the current production state. To monitor the process, the Product Holon updates the corresponding Product AAS by adding logging data to the production log. To illustrate the execution of the Product Holon, a model truck as sample product is ordered via the Service Holon. The truck is assembled out of two different semitrailers. The semitrailer_truck consists of a 3D-printed cabin pressed on a brick chassis called cab_chassis. Similar to the semitrailer_truck, the other semitrailer is built by mounting a 3D-printed or milled trailer onto a semitrailer_chassis. Figure 4 shows the corresponding product structure tree. Each of the displayed components and component assemblies relates to a production step to produce the respective component. First, the components need to be manufactured, then the semitrailers are assembled from the components and at the end, the trailer is mounted on the cab_chassis to assemble the full truck. For each of the given components, an own Product AAS is spawned. For example, the truck Holon spawns on the highest level of the Bill of Material two semitrailer Holons.I4.0 Holonic Multi-agent Testbed Enabling Shared Production 241Fig. 4 The product tree of the model truck Both Holons independently produce their related semitrailers and after completion, they report back to the truck Holon, which then controls the production of the full truck by controlling the assembly step of both semitrailers. 4 Execution System: Resource Holon The Resource Holon takes care of the management of CPPMs. As visualized in Fig. 1, the Resource Holon serves as a proactive entity using the APIs of OPC UA as well as AAS and enables dynamic interactions. All AASs are deployed using the BaSyx middleware (v1.3) [18]. BaSyx is an open-source tool targeting to implement the specification of the AAS [10, 11] and provides additional services like storing AAS in databases, authorization and notifying the user with data change events. Holons collaboration fosters flexible execution and planning, while AAS and Production Skills provide interoperability. Next to these aspects, we want to emphasize resilience on the software layer. Resource Holons are deployed as Docker containers and managed by a GitLab repository that automatically creates container images and allows continuous deployment. Modern industrial environments need applications that are isolated and separated from the runtime environment to switch the underlying hardware and balance the load. Our Resource Holon consists of an arbitrary number of Holons, where we distinguish between a Resource Holon of type Island and CPPM. The former is used to emphasize the existence of Sub-Holons, while the latter type is used to highlight the smallest possible entity that cannot be further partitioned. For interactions, it is not significant whether the Sub-Holon is an Island or a CPPM. We use this differentiation to separate the modules to build the Holons, i.e., to classify the Behaviors and Holon Skills for each type. Island Resource Holons are more responsible for lifecycle management and coordination, while CPPM Resource242 A. T. Bernhard et al.Asset Administration Shell Skill Update Behavior Inter-Holon Behavior Negotiation Behavior Human Behavior Lifecycle Management Skill I4.0 Message Skill Island Resource Holon Fig. 5 The behaviors and skills of an Island resource Holon Holons schedule and perform the concrete tasks. Furthermore, Island Resource Holons encapsulate the sum of all Sub-Holons, by providing proxy functionality. 4.1 Behaviors and Skills of a Holon SARL Holons consist of a collection of Behaviors and Holon Skills. Island Resource Holons provide hierarchies and coordinate Sub-Holons, whereas CPPM Holons, as the smallest entity, are connected to physical assets. Figure 5 summarizes Island Resource Holon\u2019s Behaviors and Skills. Each Island Resource Holon has an AAS that describes the Holon\u2019s properties, configures and parametrize the system. The key aspects of AAS are to provide information on how to find a Holon, how a Holon is constructed, and how the Holon\u2019s interfaces are defined. This information is available in the SM Topology and Interface (see Sect. 3.1) and is also provided to Sub-Holons. The AAS Skill extracts the Holons\u2019 information as well as the environmental information. The Update Behavior is used to gather information about the contained Holons\u2019 states, update the topology when MAS changes, and synchronize this information with AAS. Since the Island Resource Holon manages Sub-Holons, the Lifecycle Skill allows to dynamically create, destroy or reboot Holons in its own holonic context. As SARL Janus provides message channels for all Holons in runtime, the communication with other Holons requires an external communication interface. The Inter-Holon Behavior allows the external communication to Holons in other runtimes, e.g., message exchange between the Resource Holon and the Product Holon via the open standard communication middleware Apache Kafka. For communication and understanding, an I4.0 Message Skill supports accordance with a standardized message model according to theI4.0 Holonic Multi-agent Testbed Enabling Shared Production 243Asset Administration Shell Skill Bidding Behavior Human Behavior I4.0 Message Skill OPC UA Skill Bidding Skill Monitoring Behavior Execution Behavior Neighbor Behavior Requirement Check Behavior Cyber-Physical Production Module Resource Holon Fig. 6 The behaviors and skills of a CPPM resource Holon VDI/VDE 2193-1 [35]. Communication, collaboration and negotiation are the key components for a successful process. Island Resource Holon responds to produc-tion requests of the Product Holon, initialize negotiations and sends production requests to Sub-Holons. In Negotiation Behavior, the Island Resource Holon verifies incoming messages. Depending on the request, Island Resource Holon forces Sub-Holons to follow a task or request the possible execution. The former is used when static optimization is applied, i.e., a global schedule shall be executed. An example of global scheduling is demonstrated in [13], in which we schedule value-adding as well as non-value-adding processes. The latter implements the bidding protocol to foster dynamic optimization. Negotiation behavior defines the duration of auctions and chooses incoming offers o based on max operator, i.e., for nincoming offers, the chosen offer calculates with oi = max (o1, . . . , on). Next to  software systems, Holons may interact with humans, intending a special treatment in terms of prioritization. Therefore, Human Behavior considers human knowledge and adjustments. We are not trying to accomplish fully automated plants and exclude humans from production. Instead, we want to support human decisions to benefit from experiences and intuition, as well as building factories for humans [36]. For CPPM Resource Holons some building blocks like the Asset Administration Shell Skill, the I4.0 Message Skill and the Human Behavior overlap (see Fig. 6). For interactions, the CPPM Resource Holon provides three Behaviors: Requirement Check, Bidding and Neighbor. Requirement Check acts in loose adherence to a method call to achieve control structures in a hierarchy. In case, Island Resource Holon fosters execution, the CPPM Resource Holon verifies if it can follow the call and starts or queues the task. In Bidding Behavior, the Bidding Skill is used to calculate a bid in the range between 0 and 1. The bid determines the desire to perform the job. This fosters dynamic optimization, while taking processing time, changeover times, deadlines, availability and resource\u2019s possible operations into account. The calculation process is achieved using a Reinforcement Learning algo-rithm. The basis of the Reinforcement Learning algorithm is described in [26], while244 A. T. Bernhard et al.a modified variant will be published in future work. The last interaction pattern is the neighbor behavior. CPPMs sense their environment, thus, CPPM Resource Holon can omit hierarchies and directly communicate with their physical neighbor to perform a complex task in a collaborative way. An example is a Pick&Place operation that usually requires the supply by transportation means. The CPPM Resource Holon has additional functions regarding the control and monitoring of Production Skills. The Execution Behavior builds an event-based sequence to reliably execute a Production Skill. In this context, it represents pipelines to set the Production Skill\u2019s parameters, verify compliance of all preconditions, tracks the execution state and manages postconditions. Therefore, the CPPM Resource Holon uses the OPC UA Skill, which allows access to a Production Skill interface directly deployed on the CPPM. Furthermore, CPPM Resource Holon has a Monitoring Behavior, which is used to check relevant sensor data, track the system status and update system-critical information. In the future, anomaly detection and supervision will also be implemented in this behavior. 4.2 Demonstrator Use Case To demonstrate the application of the Resource Holon in a production environment, Produktionsinsel_KUBA of a real-world factory at SmartFactoryKL is used (see Fig. 7). Produktionsinsel_KUBA consists of three CPPMs named Connector Module, Quality Control Module and Conveyor Module as well as a Produktionsinsel_SYLT Quality Module Connector Module Conveyor Module Assembly ModuleRobot Module 3D-Printer Module Produktionsinsel_SYLT Fig. 7 SmartFactoryKL real-world demonstration factory: Produktionsinsel_KUBAI4.0 Holonic Multi-agent Testbed Enabling Shared Production 245enclosing a 3D Printer, a Robot and a Hand Assembly. The Connector Module serves as a supply and storage station for components parts. The Connector Module transfers the delivered components onto the Conveyor Module. The Conveyor Module transports the components to the Produktionsinsel_SYLT, where individual parts are mounted into a higher order assembly. Afterward, the quality of the product is checked, and the assembly is ejected at the Connector Module. Our exemplary production assembles a model truck shown in Fig. 4. In this context, Produktionsinsel_KUBA is incapable of producing all the components of the model truck on its own. Therefore, our scenario assumes that the required components of the model truck have already been manufactured in the sense of SP as explained in [15] and delivered to the Connector Module. The CPPMs can be positioned in an arbitrary layout. As a result, Produktionsinsel_KUBA offers different services depending on connected modules and increases flexibility. To provide a safe workspace, the CPPMs are mechanical locked. In this context, we refer to two or more mechanical connected CPPMs as neighbors. In [12], we present the development of our Conveyor Module to enable on-demand transportation. We mention five different coupling points on which CPPMs can be locked. The mechanism is realized with magnets and RFID sensors. Hence, the Connector Module, the Quality Control Module and the Produktionsinsel_SYLT are physically locked to the Conveyor Module, building a connected neighborhood. The RFID tag contains the CPPM\u2019s ID that allows to identify the locked module. Therefore, the self-description is accessible and CPPM Resource Holons can build peer-to-peer connections. Our production process starts when the Resource Holons gets the request to execute a production step from the Product Holon. The production step is described in a production plan following the metamodel of AAS. An example of a production plan is visualized in [14]. Based on the idea to encapsulate the manufacturing logic of production modules in Resource Holons, the interaction between the Island Resource Holon and the responding Sub-Holons is described. Our instantiated Produktionsinsel_KUBA Holon is visualized in Fig. 8. During the request to execute a production step, the Produktionsinsel_KUBA Resource Holon verifies the query in Negotiation Behavior and asks the Sub-Holons if they can perform the required effect. Since we omit global scheduling, dynamic optimization through collaboration takes place. The Sub-Holons compete to perform the effect while calculating a bid using the Bidding Skill. If the underlying CPPM is incapable of performing the action, the bid results in 0. Otherwise, the bid is calculated through Reinforcement Learning methods with a maximum value of 1. The Produktionsinsel_KUBA Resource Holon verifies the bids, by ignoring all offers .o < 0.2 and distributes the steps. The CPPM Resource Holons\u2019 local decision leads to a global behavior, where the global allocation of resources is optimized by the bidding system. This procedure ensures local CPPM Resource Holon utilization and realizes on-demand scheduling. To perform a required effect, the CPPM Holons access Production Skills via the Execution Behavior to perform a change in the environment. During the execution of a task, Holons may cooperate to perform tasks they are unable to do on their own. As an example of the communication between different Holons, the Connector Holon246 A. T. Bernhard et al.Response Request Response Request ExecutionStep Quality Control Holon Request Response GetProduct Request Response Request Response Request Response Request Response GetProduct Produktionsinsel_KUBA Resource Holon Connector Holon Produktionsinsel_SYLT Resource Holon Printer Holon Assembly Holon Robot HolonTransport Holon Fig. 8 Instantiation of Produktionsinsel_KUBA resource Holon and the Produktionsinsel_SYLT Resource Holon communicate with the Conveyor Holon to order transportation means for a specified product. Conveyor Holon manages the orchestration of the transportation means by routing and queuing. This communication relies more on a call, since Conveyor Holon encapsulates on-demand transport. This sequence describes the demonstration scenario at Produktionsinsel_KUBA. The combination of requesting and calling Holon\u2019s abilities leads to flexible control structures that allow manufacturing in a resilience way. As a result, we can handle static and dynamic requirements. Additionally, the modular structure in combination with usage of AAS and Production Skills foster interoperability and interchangeability at different layers of the factory, from the shop-floor to the connected world. 5 Conclusion This chapter presents a MAS approach in the manufacturing domain, which enables a factory to control its resources, to define and manage products and to provide services to other SP participants. The MAS is based on a holonic approach and is subdivided into Holons, each taking care of one of these tasks. For us, a Holon is treated as a special type of Agent with additional characteristics regarding recursiveness and connection to the hardware. The MAS collaborates with and uses modern Industry 4.0 technologies such as Production Skills, AAS or OPC UA. The presented MAS is enrolled on a demonstrator testbed at SmartFactoryKL, which is part of an SP scenario to produce model trucks. We divide our manufac-I4.0 Holonic Multi-agent Testbed Enabling Shared Production 247turing system into three Holons. The Service Holon provides and retrieves services from the connected world. The Product Holon deals with modular encapsulated products to manage dependencies between individual parts and assemblies as well as controlling the production process. The Resource Holon encapsulates the layer of the production testbed and connects the virtual with the physical world. To guarantee autonomy, our Resource Holons use descriptions of AAS to gain knowledge about the environment and use CPPM\u2019s Production Skills to perform an effect in the physical world. We achieve a flexible and resilient system by providing communication patterns that allow hierarchical and heterarchical modularization. However, the current state of our MAS is subject to different limitations. This means that it will be extended in the future to fulfill different other features and will solve different topics. One topic is to put more emphasize on product\u2019s lifecycle, while providing more complex planning systems to extract product\u2019s features, match capabilities and trace tender criteria. Another extension is planned on the monitoring system to embed a factory wide monitoring system to combine a supervision of the production process, factory level information like assured services and resource data. The last topic is to provide more generalized holonic patterns and give more insights about the Service Holon and the Product Holon. As a result, we want to compare our architecture to other MAS systems, with a special focus on the applied technologies in our systems. One of these technologies is AAS. In comparison to full agent-based solutions, we typically replace one Holon (e.g., in PROSA the Product Holon). As a downside, this leads to more applied technologies in the system (due to the different technology stack) and thus to a more complex architecture. However, the AAS as manufacturing standard supports the interoperability between other factories and a simple data exchange format. Furthermore, we use one standardized data format to express all our knowledge to ease the internal usage of data via a system-wide interface. Besides AAS as data format, we use SARL as Agent Framework. SARL itself is a domain-specific language, which leads to a couple of general advantages and disadvantages, as explained in [6]. We want to take up some of the listed problems and advantages and add a few more SARL language-specific arguments. First, SARL is especially designed to build MAS and includes an own metamodel to define the structure of a Holon. Besides that, SARL offers concepts to encapsulate certain functionality in Behaviors and Skills and leads to a modular system. One special feature of SARL is that Holons are able to control the lifecycle of other Holons, which is quite close to our applied concept of the MAS. Although SARL is functional suitable for us, SARL also has different disadvantages. For example, it is hard to find a documentation and help in the community if SARL specific problems occur. Unfortunately, developing SARL code is exhausting since general supported development environments do not always react in our desired response time. Another difference between our MAS concept and other MAS concepts is the granularity of applied Holons. In many cases, each device (e.g., a robot or even in a smaller granularity like a sensor) has an own Holon. In our approach, a Holon connects to one CPPM, which encapsulates single resources like robot arms or 3D-printers. In this approach, a Holon accesses each CPPM by calling248 A. T. Bernhard et al.their provided skills. Having Holons on the device level leads to more holonic communication, and thus more resources and effort is required to handle the holonic communication. Moreover, MAS does not need to operate in real-time to perform actions without a delay. This is why, we decided to encapsulate internal communication inside a CPPM and keep time-critical and safety-critical tasks in the physical processing parts. Furthermore, Holons are independent of machine-specific control technologies, which increase the flexibility of the system towards resource-specific technologies. Finally, we want to mention that even for small holonic MAS, communication quickly becomes complex and lacks transparency. Using standardized technologies like OPC UA and AAS regains this transparency and supports application in the factory. Acknowledgments This work has been supported by the European Union\u2019s Horizon 2020 research and innovation program under the grant agreement No 957204, the project MAS4AI (Multi-agent Systems for Pervasive Artificial Intelligence for Assisting Humans in Modular Production Environments). References 1. Beheshti, R., Barmaki, R., Mozayani, N.: Negotiations in holonic multi-agent systems. Recent Advances in Agent-Based Complex Automated Negotiation pp. 107\u2013118 (2016). https://doi. org/10.1007/978-3-319-30307-9_7 2. Bergweiler, S., Hamm, S., Hermann, J., Plociennik, C., Ruskowski, M., Wagner, A.: Production Level 4\u201d Der Weg zur zukunftssicheren und verl\u00e4sslichen Produk-tion (2022), https://smartfactory.de/wp-content/uploads/2022/05/SF_Whitepaper-Production-Level-4_WEB.pdf, (Visited on 18.05.2023) 3. Braud, A., Fromentoux, G., Radier, B., Le Grand, O.: The road to European digital sovereignty with Gaia-X and IDSA. IEEE network 35(2), 4\u20135 (2021). https://doi.org/10.1109/MNET.2021. 9387709 4. Christensen, J.: Holonic Manufacturing Systems: Initial Architecture and Standards Directions. In: First European Conference on Holonic Manufacturing Systems, Hannover, Germany, 1 December 1994 (1994) 5. Feraud, M., Galland, S.: First comparison of SARL to other agent-programming languages and frameworks. Procedia Computer Science 109, 1080\u20131085 (2017). https://doi.org/10.1016/ j.procs.2017.05.389 6. Fowler, M.: Domain-specific languages. Pearson Education (2010) 7. Giret, A., Botti, V.: Holons and agents. Journal of Intelligent Manufacturing 15(5), 645\u2013659 (2004). https://doi.org/10.1023/B:JIMS.0000037714.56201.a3 8. Hermann, J., R\u00fcbel, P., Birtel, M., Mohr, F., Wagner, A., Ruskowski, M.: Self-description of cyber-physical production modules for a product-driven manufacturing system. Procedia manufacturing 38, 291\u2013298 (2019). https://doi.org/10.1016/j.promfg.2020.01.038 9. Huhns, M.N., Singh, M.P.: Service-oriented computing: Key concepts and principles. IEEE Internet computing 9(1), 75\u201381 (2005). https://doi.org/10.1109/MIC.2005.21 10. Industrial Digital Twin Association: Specification of the Asset Administration Shell Part 1: Metamodel, https://industrialdigitaltwin.org/wp-content/uploads/2023/06/IDTA-01001-3-0_SpecificationAssetAdministrationShell_Part1_Metamodel.pdf, (Visited on 28.06.2023) 11. Industrial Digital Twin Association: Specification of the Asset Administration Shell Part 2: Application Programming Interface, https://industrialdigitaltwin.org/wp-content/uploads/I4.0 Holonic Multi-agent Testbed Enabling Shared Production 2492023/06/IDTA-01002-3-0_SpecificationAssetAdministrationShell_Part2_API_.pdf, (Visited on 28.06.2023) 12. Jungbluth, S., Barth, T., Nu\u00dfbaum, J., Hermann, J., Ruskowski, M.: Developing a skill-based flexible transport system using OPC UA. at-Automatisierungstechnik 71(2), 163\u2013175 (2023). https://doi.org/10.1515/auto-2022-0115 13. Jungbluth, S., Gafur, N., Popper, J., Yfantis, V., Ruskowski, M.: Reinforcement Learning-based Scheduling of a Job-Shop Process with Distributedly Controlled Robotic Manipulators for Transport Operations. IFAC-PapersOnLine 55(2), 156\u2013162 (2022). https://doi.org/10.1016/ j.ifacol.2022.04.186, https://www.sciencedirect.com/science/article/pii/S2405896322001872, 14th IFAC Workshop on Intelligent Manufacturing Systems IMS 2022 14. Jungbluth, S., Hermann, J., Motsch, W., Pourjafarian, M., Sidorenko, A., Volkmann, M., Zoltner, K., Plociennik, C., Ruskowski, M.: Dynamic Replanning Using Multi-agent Systems and Asset Administration Shells. In: 2022 IEEE 27th International Conference on Emerg-ing Technologies and Factory Automation (ETFA). pp. 1\u20138 (2022). https://doi.org/10.1109/ ETFA52439.2022.9921716 15. Jungbluth, S., Witton, A., Hermann, J., Ruskowski, M.: Architecture for Shared Production Leveraging Asset Administration Shell and Gaia-X (2023), unpublished 16. Koestler, A.: The ghost in the machine. Macmillan (1968) 17. Kolberg, D., Hermann, J., Mohr, F., Bertelsmeier, F., Engler, F., Franken, R., Kiradjiev, P., Pfeifer, M., Richter, D., Salleem, M., et al.: SmartFactoryKL System Architecture for Industrie 4.0 Production Plants. SmartFactoryKL, Whitepaper SF-1.2 4 (2018) 18. Kuhn, T., Schnicke, F.: BaSyx, https://wiki.eclipse.org/BaSyx, (Visited on 07.07.2022) 19. Leit\u00e3o, P., Colombo, A.W., Restivo, F.J.: ADACOR: A collaborative production automation and control architecture. IEEE Intelligent Systems 20(1), 58\u201366 (2005). https://doi.org/10. 1109/MIS.2005.2 20. Leitao, P., Karnouskos, S. (eds.): Industrial Agents: Emerging Applications of Software Agents in Industry. Kaufmann, Morgan, Boston (2015). https://doi.org/10.1016/C2013-0-15269-5 21. Leon, F., Paprzycki, M., Ganzha, M.: A review of agent platforms. Multi-paradigm Modelling for Cyber-Physical Systems (MPM4CPS), ICT COST Action IC1404 pp. 1\u201315 (2015) 22. Liu, Y., Wang, L., Wang, X.V., Xu, X., Jiang, P.: Cloud manufacturing: key issues and future perspectives. International Journal of Computer Integrated Manufacturing 32(9), 858\u2013874 (2019). https://doi.org/10.1080/0951192X.2019.1639217 23. Neubauer, M., Reiff, C., Walker, M., Oechsle, S., Lechler, A., Verl, A.: Cloud-based evalu-ation platform for software-defined manufacturing: Cloud-basierte Evaluierungsplattform f\u00fcr Software-defined Manufacturing. at-Automatisierungstechnik 71(5), 351\u2013363 (2023). https:// doi.org/10.1515/auto-2022-0137 24. Pal, C.V., Leon, F., Paprzycki, M., Ganzha, M.: A review of platforms for the development of agent systems. arXiv preprint arXiv:2007.08961 (2020). https://doi.org/10.48550/arXiv.2007. 08961 25. Plattform Industrie 4.0: Information Model for Capabilities, Skills & Services, https://www. plattform-i40.de/IP/Redaktion/EN/Downloads/Publikation/CapabilitiesSkillsServices.html, (Visited on 06.06.2023) 26. Popper, J., Ruskowski, M.: Using Multi-agent Deep Reinforcement Learning for Flexible Job Shop Scheduling Problems. Procedia CIRP 112, 63\u201367 (2022). https://doi.org/10.1016/j.procir. 2022.09.039 27. Rodriguez, S., Gaud, N., Galland, S.: SARL: a general-purpose agent-oriented programming language. In: 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT). vol. 3, pp. 103\u2013110. IEEE (2014). https://doi.org/ 10.1109/WI-IAT.2014.156 28. Ruskowski, M., Herget, A., Hermann, J., Motsch, W., Pahlevannejad, P., Sidorenko, A., Bergweiler, S., David, A., Plociennik, C., Popper, J., et al.: Production bots f\u00fcr production level 4: Skill-basierte systeme f\u00fcr die produktion der zukunft. atp magazin 62(9), 62\u201371 (2020). https://doi.org/10.17560/atp.v62i9.2505250 A. T. Bernhard et al.29. Smith, R.G.: The contract net protocol: High-level communication and control in a distributed problem solver. IEEE Transactions on computers 29(12), 1104\u20131113 (1980). https://doi.org/ 10.1109/TC.1980.1675516 30. Trunzer, E., Cal\u00e0, A., Leit\u00e3o, P., Gepp, M., Kinghorst, J., L\u00fcder, A., Schauerte, H., Reiffer-scheid, M., Vogel-Heuser, B.: System architectures for Industrie 4.0 applications: Derivation of a generic architecture proposal. Production Engineering 13, 247\u2013257 (2019). https://doi.org/ 10.1007/s11740-019-00902-6 31. Valckenaers, P.: Perspective on holonic manufacturing systems: PROSA becomes ARTI. Computers in Industry 120, 103226 (2020). https://doi.org/10.1016/j.compind.2020.103226 32. Van Brussel, H., Wyns, J., Valckenaers, P., Bongaerts, L., Peeters, P.: Reference archi-tecture for holonic manufacturing systems: PROSA. Computers in Industry 37(3), 255\u2013 274 (1998). https://doi.org/10.1016/S0166-3615(98)00102-X, https://www.sciencedirect.com/ science/article/pii/S016636159800102X 33. Van Leeuwen, E., Norrie, D.: Holons and holarchies. Manufacturing Engineer 76(2), 86\u201388 (1997). https://doi.org/10.1049/me:19970203 34. VDI/VDE-Gesellschaft Mess- und Automatisierungstechnik: Language for I4.0 components- Interaction protocol for bidding procedures, https://www.vdi.de/en/home/vdi-standards/ details/vdivde-2193-blatt-2-language-for-i40-components-interaction-protocol-for-bidding-procedures, (Visited on 01.06.2023) 35. VDI/VDE-Gesellschaft Mess- und Automatisierungstechnik: Language for I4.0 Components- Structure of messages, https://www.vdi.de/en/home/vdi-standards/details/vdivde-2193-blatt-1-language-for-i40-components-structure-of-messages, (Visited on 01.06.2023) 36. Zuehlke, D.: SmartFactory\u2013Towards a factory-of-things. Annual reviews in control 34(1), 129\u2013 138 (2010). https://doi.org/10.1016/j.arcontrol.2010.02.008 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.A Multi-intelligent Agent Solution in the Automotive Component\u2013Manufacturing Industry Luis Usatorre, Sergio Clavijo, Pedro Lopez, Echeverr\u00eda Imanol, Fernando Cebrian, David Guill\u00e9n, and E. Bakopoulos 1 Introduction The manufacturing industry is an ecosystem full of changes and variations where production conditions are never the same. As an example, the raw materials received from suppliers differ from one another, though within tolerances. Because of these differences, using the Asset Administration Shell1 (AAS) [1] for each component/-part is not feasible. And similar variations appear in all areas of manufacturing, such as tool wearing, the statuses of production machines, and even operator decisions (Fig. 1). On top of that, operator decisions are, most of the time, based on intuition and experience, not based on data analysis. One of the reasons is that manufacturing industry data are stored locally in departments and in silos, so the operator does not have access to them. Some of these data and their storage locations are as follows: 1. Scheduling data related to production orders, quantities, delivery times, etc. are usually stored in the enterprise resource-planning (ERP) system. 1 Platform Industry 4.0\u2014asset administration shell specifications (plattform-i40.de) L. Usatorre (\u0002) \u00b7 S. Clavijo \u00b7 P. Lopez \u00b7 E. Imanol Fundacion TECNALIA R&I, Madrid, Spain e-mail: Luis.usatorre@tecnalia.com; sergio.clavijo@tecnalia.com; pedro.lopez@tecnalia.com; imanol.echeverria@tecnalia.com F. Cebrian \u00b7 D. Guill\u00e9n Fersa Bearings, Zaragoza, Spain e-mail: fernando.cebrian@fersa.com; david.guillen@fersa.com E. Bakopoulos LMS, Laboratory for Manufacturing Systems, Patras, Greece e-mail: bakopoulos@lms.mech.upatras.gr \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_14251252 L. Usatorre et al.Fig. 1 Variables affecting operator decisions 2. Raw material suppliers, their characteristics, their arrival times, their quantities, etc. are usually stored in the suppliers\u2019 departmental repositories. 3. Nominal product characteristics can be found in the engineering department\u2019s drawings and repositories. 4. Quality-control results are usually stored either in the quality-control machine\u2019s memory or in the quality-control department\u2019s repositories. This paper suggests that an improvement to production must balance various choices, not only technical but also economic. In existing production environments, several criteria are included and considered as part of determining the best solution to problems like storage size (e.g., economic costs, logistic costs), operator costs, production time, energy consumption, and more. When applying artificial intel-ligence (AI) in the manufacturing process, the criteria should be similar: Several agents with different goals should interact to determine the most holistic solution. To this end, this paper illustrates that the multiagent method, based on a framework of distributed examples, leads to interactions between these agents in ways that improve the entire plant production system. Although the agents could work in isolation, the MAS4AI (the multiagent system for AI) is tasked with making them work together seamlessly and providing a better solution than they would produce by working separately. The second goal is to address scalability in the implementation of AI solutions in the manufacturing industry: Agents need to be customized and specific to each manufacturing process (i.e., grinding) yet at the same time be generic enough for all machines and industries using this manufacturing process (i.e., all grinding machines in all shop floors). The MAS4AI proposal is for an agent-based Asset Administration Shell (AAS) approach to be deployed in every industry that wants to use a particular agent. In this way, an agent is composed of agent logic and the AAS. See the specifics for a case of using it at the Fersa plant, as depicted in Fig. 2.A Multi-intelligent Agent Solution in the Automotive Component... 253Fig. 2 Implementation of the agent-based AAS 1.1 Fersa\u2019s Pilot Plant Fersa Bearings is a company that specializes in the design, manufacturing, and commercialization of bearings, mainly for the automotive market, but a minor percentage is dedicated to the industrial market. For the automotive market, Fersa Bearings manufactures bearings both for new vehicles (few references and production cases in long batches) and as spare parts, which implies many references and production cases in much-shorter batches. The use case implemented at the Fersa plant focuses on the Z0 line, which is fully dedicated to manufacturing spare parts (short batches). In this line, one reference is composed of two sections manufactured in parallel that have to be assembled into one part. Therefore, quality is critical in these processes to ensure that the different parts perfectly match, meeting the final requirements. The multiagent system improves Fersa\u2019s control over the processes in this manufacturing line, which improves end quality, communication and process coor-dination despite the variability among raw materials, tooling, and processes. Today, different actors interact in the physical world to optimize production holistically. The goal has been to apply AI in the manufacturing process\u2014in a virtual world where several agents with different goals interact to determine the most holistic solution, as depicted in Fig 3. At Fersa\u2019s pilot plant, we are considering having three agents interact: a tooling agent that optimizes the tooling selection, a machine agent that improves the machine parameters, and a scheduling agent that evaluates the manufacturing time for a production batch under certain circumstances, such tooling selection and machine parameters. This is presented in Fig. 4.254 L. Usatorre et al.Fig. 3 Relationship between physical and virtual worlds at Fersa Fig. 4 Relation among agents at FersaA Multi-intelligent Agent Solution in the Automotive Component... 2552 Experimental Development 2.1 Data Aggregation The challenge was that the Fersa use case generated a wide variety of heterogeneous data from different data sources. The decisions must take the following factors, among others, into consideration:\u2022 Raw material characteristics\u2022 BEAIN12 and RIFA6 machine parameters and historical data\u2022 Quality-control stations\u2019 data\u2022 Assembly stations\u2019 data\u2022 Sensors\u2019 data\u2022 Scheduling plans These data sources also appear in different types of formats:\u2022 Portable data formats (PDFs)\u2022 Comma-separated values (CSVs)\u2022 Tabular data formats such as Extensible Markup Language (XML) and Excel (XLS) On top of that, the data come from various locations:\u2022 Shop floors (e.g., machine parameters)\u2022 Suppliers (e.g., raw material characteristics)\u2022 Management tools (e.g., ERPs and scheduling tools) The first step in implementing Fersa\u2019s MAS4AI is to ensure that the data are properly connected, aggregated, and filtered. Figure 5 presents the proposed solution to aggregating all the data sources: a\u2014 machine data, including ranges and grinding-wheel parameters; b\u2014raw material data, including nominal and real data; c\u2014other agents\u2019 data; and d\u2014assembly and control stations\u2019 data. The central part shows the repositories where the aggregation takes place in MAS4AI for Fersa. 2.2 Tooling Agent One of the main challenges is to find the most suitable griding wheel (GW) for a certain production process (reference and quantity). On one hand, a too-big GW will not be completely used; it will return to the warehouse as partially worn and be difficult to reuse. On the other hand, a too-small GW will stop functioning before the production cycle has finished, forcing a GW change, which stops production. Our solution is to have the tooling agent check the Fersa GW warehouse in order to select the most suitable GW for the current production cycle (see selection criteria in 2.4). Most of the information needed by the agent is provided by the grinding256 L. Usatorre et al.Fig. 5 Data aggregation machine agent, which receives and optimizes the machine parameters of the current production cycle. Figure 6 shows the current workflow of this part of the Fersa system. The reference for the production order and the suggested machine parameters for that production should be followed to determine the optimal grinding wheels. The length of change time for the GWs should always be minimized. The AAS type for the Fersa system was the resource one. The main content of this agent can be found in the AAS of the GW agent, specifically in the submodel\u2019s production information. Figure 7 illustrates the reference for the production, the inputs used for the execution of the agent, and the list of GWs obtained for the tooling agent ASS.A Multi-intelligent Agent Solution in the Automotive Component... 257Fig. 6 Agent interaction logic 2.3 Machine Agent Another challenge is manufacturing the highest number of good-quality parts (i.e., without burns; without derivatives; without conicity, ovality, or obliquity problems; and with Ha-T-12 diameters within tolerances) in the shortest amount of time. To accomplish this objective, the proposed solution takes into account the following actions that illustrate the agent\u2019s logic:\u2022 It determines the GW diameter by taking into account the current parameters of the production. This determination is made in the short term, over periods of seven, fifteen, and thirty minutes.\u2022 It provides critical values from the production cycle. These values are provided in the short term, over periods of seven, fifteen, and thirty minutes.\u2022 It optimizes the initial machine parameters according to the batch reference.\u2022 It detects deviations from the machine parameters during the execution of production. All these objectives contribute in different ways to minimizing the time that a batch needs to be finished. During the pilot operations at Fersa, assembly and quality stations fed the agent with information such as nominal and real values and the tolerances of the raw materials. The Fersa use case features two machine agents. While the real-time agent is related to the BEAIN12 machine, this machine agent relies on the RIFA6 machine. This agent calculates by using a series of machine-learning and deep-learning models. At the time when this chapter was written, the testing process involved three neural network structures with different numbers of hidden layers (two, three, and four), different numbers of neurons per layer (20, 15, and 10), and different optimization algorithms (Adam and Stochastic gradient descent (SGD)). The metrics used were mean absolute error (MAE) and mean squared error (MSE). For example, while deep-learning short-term prediction models for the Grinding2 Ha-T-1 is a process parameter (Axial tolerance). 258 L. Usatorre et al.Fig. 7 Tooling agent AAS Wheel (GW) diameter and positions have been fully developed and are in a testing phase, the optimization model for the initial parameters is still undergoing testing because it still needs historical data for past batch references that were not collected by Fersa before the project started. For the same reason, the model that predicts deviations from the machine parameters for a fixed batch is also still undergoing testing. Data are currently being collected to enable new models to be added and tested over the following months. The main content of this agent can be found in the machine agent\u2019s AAS, specif-ically in the submodel\u2019s production information. Figure 8 presents the referenceA Multi-intelligent Agent Solution in the Automotive Component... 259Fig. 8 Machine agent AAS260 L. Usatorre et al.for the production, the inputs used for the execution of the agent, and the outputs obtained for the machine agent ASS. 2.4 Prescheduling Agent In this case, the challenge is to determine the time required to produce a certain batch by factoring in the material, the tooling, and the machine parameters. Additional parameters to be considered include the number of wheel changes needed and the estimated time to complete these changes. The proposed solution considers all these inputs. Such inputs refer to item information: the item number and the catalog reference for the batch, the number of pieces to make (included in the production table from the Microsoft SQL Server (MSSQL) repository), Fersa\u2019s current inventory, the batch schedule, and information on the production once the item has entered the machine. The agent applies two logics: one in real time featuring the current status of the machine and another that was calculated before production. The output of the agent is based on the estimated time required to finish a production. The AAS for preschedule agent is the production-planning type. The main content of this agent can be found in the prescheduling agent\u2019s AAS, in the submodel\u2019s production information. Figure 9 presents the reference of the production order, the inputs used for the execution of the agent (e.g., the cone reference and the quantity), and the outputs obtained (e.g., the number of GW changes or the estimated time required to produce the batch) for the prescheduling agent ASS. 2.5 Holon The complete implementation of MAS4AI architecture is based on the concept of a holon as an abstraction in that it groups multiple agents and coordinates both control and information flow. A holon is also used in JANUS3 [2]. The theoretical presentation of a holon is illustrated in Fig. 3, while its practical implementation at Fersa is presented in Fig 10. 3 Conclusion This paper presents the ontology, semantics, and data architecture that permits multiagent interaction, and the RAMI 4.0 model was selected as the basis for designing and implementing the presented approach.3 Janus Agent and Holonic Platform (sarl.io) A Multi-intelligent Agent Solution in the Automotive Component... 261Fig. 9 Prescheduling agent AAS Fig. 10 Holon implementation at Fersa The presented data architecture, depicted in Fig 11, permits the data analysis of raw materials, finished products, tooling characteristics and statuses, machine parameters, and external conditions, to minimize the influence of intuition and262 L. Usatorre et al.Fig. 11 MAS4AI FW and RA Fig. 12 MAS4AI FW and RA in Fersa personal bias on decision-making in manufacturing and to improve production quality, throughput, and efficiency. Figure 12 presents the generic MAS4AI Framework (FW) and Reference Architecture (RA) adapted for the Fersa pilot. The pilot is scalable to many other sectors: From its use in the grinding process, MAS4AI RA and its framework can be easily moved and applied to manufacturing processes such as stamping, machining, compounding, and extruding, where the decisions are based on balancing factors such as tooling, machines, and scheduling requirements.A Multi-intelligent Agent Solution in the Automotive Component... 263Acknowledgments This work received funding from the European Union\u2019s Horizon 2020 research and innovation program under grant agreement number 957204 (H2020-ICT-38-2020) (MAS4AI). References 1. Sakurada, L., Leitao, P., De la Prieta, F.: Agent-based asset administration shell approach for digitizing industrial assets. IFAC-PapersOnLine. 55(2), 193\u2013198, ISSN 2405-8963, (2022). https://doi.org/10.1016/j.ifacol.2022.04.192 2. Galland S, Gaud N, Rodriguez S, et al.: Janus: another yet general-purpose multiagent platform. In: Proceedings of 7th Agent-Oriented Software Engineering Technical Forum (TFGASOSE-10); 2010 Dec; Paris, France Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Integrating Knowledge into Conversational Agents for Worker Upskilling Rub\u00e9n Alonso, Danilo Dess\u00ed, Antonello Meloni, Marco Murgia, and Reforgiato Recupero Diego 1 Introduction The supply and demand for labor, wherein employees give the supply and employers provide the demand, are referred to as the labor market or job market. They are a crucial part of every economy and are closely connected to the markets for capital, goods, and services. According to a recent International Labour Organization (ILO) R. Alonso (\u0002) R2M Solution s.r.l., Pavia, Italy Programa de Doctorado, Centro de Autom\u00e1tica y Rob\u00f3tica, Universidad Polit\u00e9cnica de Madrid-CSIC, Madrid, Spain e-mail: ruben.alonso@r2msolution.com D. Dess\u00ed Knowledge Technologies for the Social Sciences Department, GESIS \u2013 Leibniz Institute for the Social Sciences, Cologne, Germany e-mail: danilo.dessi@gesis.org A. Meloni \u00b7 M. Murgia Mathematics and Computer Science Department, University of Cagliari, Cagliari, Italy e-mail: antonello.meloni@unica.it; m.murgia98@studenti.unica.it R. R. Diego Mathematics and Computer Science Department, University of Cagliari, Cagliari, Italy R2M Solution s.r.l., Pavia, Italy e-mail: diego.reforgiato@unica.it; diego.reforgiato@r2msolution.com \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_15265266 R. Alonso et al.assessment1 , the present global economic slump is likely to drive more employees to take poorer quality, poorly paid employment that lack job security and social safety, exasperating disparities that have already been made worse by the COVID-19 crisis. According to the same report, only 1.0% of the world\u2019s employment is expected to expand in 2023, which is less than half of the rate in 2022. The number of unemployed people worldwide is projected to increase by almost 3 million to 208 million in 2023, representing a 5.8% global unemployment rate. The limited labor supply in high-income nations is partly to blame for the moderate extent of this predicted increase. This would reverse the drop in unemployment seen globally between 2020 and 2022. The COVID-19 epidemic has, therefore, recently had a significant effect on the world labor market. Additionally, new difficulties have arisen that are also negatively affecting the workplace, such as rapid increases in inflation, disruptions in the supply chain, and the conflict in Ukraine.2 It is vital to take action to advance social justice by tackling issues like young employment, informality, productivity, and gender parity. To create a lasting and inclusive recovery that leaves no one behind, policymakers, companies, employees, and civil society must collaborate. This entails spending money on education and training, enhancing social safety nets, encouraging good work, and moving forward. The industrial sector, and in particular the manufacturing sector, is not immune to this situation, since it is a very competitive labor market in which it is difficult to recruit top talents that are experienced with new technologies such as robotics or AI. The sector also suffers the fast pace of innovative technologies, making it difficult for both companies and employees, without adequate training and practice, to be up-to-date and competitive. The manufacturing sector needs to retain talent and adapt to new needs, through professional development activities and investment in employee growth, and at the same time be able to find quick solutions, such as cross-training, to be able to cover leaves of absence or production peaks. This calls for new training, retention, and recruitment strategies. Since 2021, several industries and jobs have been predicted to grow by Career-Builder,3 a 1995-founded employment website with operations in 23 countries and a presence in over 60 markets. CareerBuilder offers labor market information, talent management software, and other recruitment-related services. The listed employment spans a variety of industries, including leisure, arts, renewable energy, personal services, healthcare, and information technology. It is possible to upload and build a resume and look for one of many jobs posted by different organizations.1 https://www.ilo.org/wcmsp5/groups/public/---dgreports/---inst/documents/publication/ wcms_865332.pdf 2 https://ilostat.ilo.org/assessing-the-current-state-of-the-global-labour-market-implications-for-achieving-the-global-goals/. 3 https://www.careerbuilder.com/. Integrating Knowledge into Conversational Agents for Worker Upskilling 267Other systems providing similar services are Monster.com,4 OfferZen,5 LinkedIn,6 Glassdoor,7 JobStreet,8 ZipRecruiter,9 Dice,10 G2 Deals,11 Indeed Hiring Plat-form,12 Hired,13 Cord,14 Circa,15 Naukri,16 to name a few. Using these platforms to hunt for a job is simple, but getting chosen for the top chances is often a challenge. For instance, if the position requires a computer science specialist with fund-raising skills, a candidate with only computer science skills is unlikely to be chosen because they lack crucial qualifications like proposal writing experience or start-up development. For the aforementioned example, one should be aware that writing innovation proposals is a crucial skill for fulfilling fund-raising needs. It can be not easy to find answers to queries like these and information on how to develop the necessary skills. One possibility that has recently been exploited is the use of conversational agents [15]. Impressive outcomes have been seen in chats across a variety of areas since ChatGPT\u2019s release. Although ChatGPT claims to respond to follow-up queries, acknowledge mistakes, challenge false premises, and reject unsuitable requests, it frequently generates responses that are false and may deceive the user who interacts with it. Authors in [12] have further demonstrated this issue by pointing out related ChatGPT problems in the academic community. Even in this situation, ChatGPT partially made up some of the response\u2019s components, and the user was left in the dark as to which components are correct and which are incorrect. Therefore, even though ChatGPT occasionally offers accurate responses, it cannot be relied entirely upon and a different technique should be investigated. The use of external domain knowledge can be the solution to the aforementioned issues. There are several lexical databases or online taxonomies that have been collected and designed by different organizations that can be relied on when asking for information in such a sense. As such, in this chapter, we will first list the most important existing conversational agents which can be leveraged within the labor domain for worker upskilling. Then, we illustrate and describe all the resources related to the labor domain. We will also provide a solution that integrates conversational agents with the information provided by one of such resources showing the benefits and impact that can be attained. The idea is to leverage such4 https://www.monster.com/. 5 https://www.offerzen.com. 6 https://www.linkedin.com/. 7 https://www.glassdoor.com/. 8 https://www.jobstreet.com/. 9 https://www.ziprecruiter.co.uk. 10 https://www.dice.com/. 11 https://www.g2.com/deals. 12 https://www.indeed.com/employers/hiring-platform. 13 https://hired.com/. 14 https://cord.co/. 15 https://circaworks.com/. 16 https://www.naukri.com/. 268 R. Alonso et al.resources to boost existing conversational agents when asking questions in the underlying domain and overcoming their limitations. The remainder of this chapter is organized as follows. Section 2 lists the scientific papers that have been published related to conversational agent technologies for the labor domain and worker upskilling. Section 3 will describe in depth the identified conversational agent systems and will illustrate the details of their functionalities and their main limitations, whereas lexical resources within the labor market domain that can be used to provide reliable domain knowledge are included in Sect. 4. A  possible solution of a conversational agent integrated with one of such resources is presented in Sect. 5. Expected benefits and impact of the proposed solution are reported in Sect. 6. Section 7 ends the paper with conclusions and outlines future directions. 2 Related Work Conversational agents can be found in a variety of domains such as mental health [9], lifestyle [5], and customer service [17] to support users of online platforms to cope with daily tasks and challenges. They make use of natural language as a personalization enabler, i.e., they allow a user to interact with complex systems using his/her own language rather than using a limited number of predefined options (e.g., command line, buttons in a web interface, etc.) [7]; this makes the interaction with the conversational agents similar to person-to-person interaction. Recently, conversational agents have been released for the labor domain to support employers to find new employees as well as candidates who are looking for a job and are interested to improve their skills to be eligible. The reason is that the use of conversational agents can make the recruitment process and interviews more inclusive and efficient, and interviewees seem to be willing to trust the conversational agents in confiding information and listening to their words [18]. Conversational agents can support people during each stage of their career path starting from their early studies (e.g., in choosing a university or study path), through the search for a job (e.g., conversational agents that perform preliminary interviews), and during their employment (e.g., a conversational agent that guides employees in learning a new technology). For example, the conversational agent built on top of the IBM Watson suite17 proposed in [10] presents a system to support new college students in the decision-making process to choose the right major on the basis of necessary skills and employment opportunities. Another recent conversational agent relevant to the labor domain is GuApp. It supports candidates to find a job in specific geographical areas using the content of the Gazzetta Ufficiale, the Italian public sector\u2019s official journal of records, and a knowledge graph built on top of the17 IBM Watson: https://www.itechbm.com/watson. Integrating Knowledge into Conversational Agents for Worker Upskilling 269ISTAT website,18 which provides a taxonomy of professions organized by sector, and DBpedia.19 In line with these advancements, the research community looked into the use of knowledge resources to inject knowledge into such systems and provide tools to support candidates in self-evaluating their CVs, and workers to improve their skills. For example, these novel tools can identify which skills a candidate should acquire to become eligible for a specific job. An example of such technologies is described in [16], where the authors looked into which tech skills are taught in colleges and which skills are truly required by the job market. They used Natural Language Processing (NLP) for detecting entities and keywords from computer science courses and job descriptions and provide recommendations for tech courses or topics for tech career development. In [2] a novel method to match the content of CVs with the O*NET database, a large database of work and worker characteristics and skill requirements, is proposed. The authors used advanced NLP technologies to automatically parse the content of CVs, state-of-the-art transformer models based on the SentenceTransformers framework [14] to encode the extracted information into latent representations, and a semantic layer to match the information from CVs to the O*NET database. This novel technology is provided to the public through a demo [3]. The same technology is also employed by the same authors to provide STAR-BOT [1], a conversational agent that can help explore the O*NET database using a novel grammar and transformer model to understand the user request and deliver information about jobs. In addition to this, STAR-BOT can also suggest educational online courses that can help the upskilling of workers if successfully passed. 3 Existing Conversational Agents In this section, we will describe some state-of-the-art conversational agents that can be employed, among others, also within the labor domain. ChatGPT Released in November 2022, ChatGPT20 is an artificial intelligence (AI) chatbot created by OpenAI. It is a form of generative AI that allows users to enter prompts to receive humanlike images, text, and videos created by the AI. It is constructed on top of the foundational large language models (LLMs) GPT-3.5 and GPT-4 and has been fine-tuned utilizing both supervised and reinforcement learning strategies. OpenAI claims that \u201cReinforcement Learning from Human Feedback\u201d (RLHF) was used to train ChatGPT. The model initially underwent supervised fine-tuning, in which OpenAI trainers acted as both a human user and an AI bot. To18 ISTAT: https://www.istat.it/en/. 19 https://www.dbpedia.org/. 20 https://openai.com/blog/chatgpt. 270 R. Alonso et al.fine-tune the model for conversational usage, the trainers used this to develop a dialogue sequence that mimicked how people converse in real life. Later, ChatGPT was enhanced by developing a reward model to be used for the following phase of reinforcing learning. In order to produce responses, this entailed AI trainers engaged with the tool. Afterward, the responses were ranked according to their quality. With this information, there was a further fine-tuning phase called Proximal Policy Optimization. ChatGPT employs deep learning algorithms to assess incoming text prompts and produce responses based on patterns in the data it has been trained on. It can comprehend subtle language differences and deliver responses of the highest caliber because it has been trained on a huge corpus of literature, including books, papers, and websites. Users can give the chatbot feedback by clicking the \u201cthumbs up\u201d or \u201cthumbs down\u201d icons next to each response in order to help it learn. Users can also offer more textual comments to enhance and perfect upcoming dialogue. Users can ask a wide range of topics on ChatGPT, from straightforward inquiries to more difficult ones like, \u201cWhat is the meaning of life?\u201d. ChatGPT is skilled in STEM fields and has the ability to troubleshoot or write code. There is no restriction on the kinds of queries that can be asked to ChatGPT. ChatGPT uses data only through 2021; therefore, it is unaware of events and data after that point. Additionally, because it is a conversational chatbot, users can request additional details or ask that it try again when producing content. A list of limitations of ChatGPT is described in the following. It does not properly comprehend how intricate human language is. Words are generated using ChatGPT based on input. As a result, comments could come off as superficial and lacking in profundity. Moreover, ChatGPT could respond incorrectly if it does not fully comprehend the question. On top of that, responses may come off as artificial and robotic. The training data covers up to 2021 and, therefore, ChatGPT has no knowledge of what happened later. As ChatGPT is still being trained, providing comments when a response is erroneous is advised. ChatGPT may misuse terms like \u201cthe\u201d or \u201cand.\u201d Due to this, information must still be reviewed and edited by humans in order to make it read more naturally and sound more like human writing. ChatGPT does not cite sources and does not offer interpretation or analysis of any data or statistics. It is unable to comprehend irony and sarcasm. It can focus on the incorrect portion of a question and be unable to shift. For instance, if we ask, \u201cDoes a horse make a good pet based on its size?\u201d and then we ask \u201cWhat about a cat?\u201d. Instead of providing information regarding keeping the animal as a pet, ChatGPT might only concentrate on the animal\u2019s size. Because ChatGPT is not divergent, it cannot shift its response to address several questions in one. Bing It is a chatbot created by Microsoft. Bing is integrated with Microsoft\u2019s Bing search engine and is made to respond to users\u2019 inquiries in a way that is specific to their search history and preferences.21 The Bing AI chatbot may help with a variety of tasks, including question answering, providing recommendations,21 https://www.bing.com/?/ai. Integrating Knowledge into Conversational Agents for Worker Upskilling 271presenting pertinent search results, and having casual conversations. Similar to ChatGPT, the new AI-powered application on Bing responds to user requests using a selection of words determined by an algorithm that has learned from scanning billions of text documents on the Internet. Bing AI indexes the entire web in order to produce a response. Because of this, the chatbot has access to the most recent news, information, and studies at the time the user submitted his/her query. As an AI model capable of error, OpenAI has already acknowledged that ChatGPT is prone to hallucinations and incorrect responses. Bing AI has made some efforts to address this problem. When the user asks a question in Bing AI, it will respond with footnotes that will take the user directly to the original source of the answer. Bing works on top of GPT4, the newest version of OpenAI\u2019s language model systems. It has also been integrated into Skype chat. Through a straightforward chat interface, this new experience is intended to give the user access to a rich and imaginative source of knowledge, inspiration, and solutions to user queries. Microsoft published in a blog post22 that Bing was prone to getting off track, especially after \u201cextended chat sessions\u201d of 15 or more inquiries, but claimed that user feedback was helping it to make the chat tool better and safer. Bard Google created the conversational generative AI chatbot and is still working on its release. It was created to compete with ChatGPT and other language models. Bard is based on the LaMDA (Language Model for Dialogue Applications) family of large language models. It was built on top of Google\u2019s Transformer neural network architecture, which was also the basis for ChatGPT\u2019s GPT-3.5 language model. Eventually, it will be employed to augment Google\u2019s own search tools as well as provide support and interaction for businesses. Differently from ChatGPT, Google Bard can use up-to-date information for its responses. Bard may occasionally provide inaccurate, misleading, or false information while presenting it confidently. For instance, Bard might provide developers with working code that is incomplete or fails to produce the correct output. Google Bard is already accessible via a waitlist, but it is difficult to predict when it will be accessible to everyone. However, Google\u2019s CEO stated that Google Bard would soon be used to improve Google Search, thus Bard might become more widely accessible shortly. Chatsonic Chatsonic23 is a GPT-4 based chatbot that tries to solve the main limitations of ChatGPT. Chatsonic uses Google to grasp information about the latest events. This makes this chatbot able to support users with timely answers and information about events that take place at any moment. It also provides a few sources harvested from the Internet used to generate the answer which can have a relevant impact on the trust that a user can give to the conversational agent. Chatsonic can generate images and can be integrated within the Chrome browser for efficiently working with everyday tools and web platforms such as Gmail, LinkedIn,22 https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Learning-from-our-first-week. 23 https://writesonic.com/chat. 272 R. Alonso et al.Twitter, etc. In the context of worker upskilling, it can be used to find online courses that can be attended to learn or improve specific skills. One of its main limitations is that each user has a budget of 10k words, and when finished, a premium account needs to be activated. Copilot Copilot24 is a language model that slightly differs from the others because it targets computer scientists and developers and their daily task of writing new source code. In fact, this model is trained on billions of lines of code. It allows one to write code faster, suggests more lines of code, proposes implementations of methods, and enables developers to focus on the overall approach instead of dispersing energies on trivial tasks. However, this tool is not perfect and it has several limitations; it often delivers code and method implementations that do not make sense and, additionally, it does not test the code that is written. Therefore, the developer has to verify that the automatically generated code is functional, as well as the quality of the delivered results. This is a crucial aspect for the accountability of the work, and for ensuring the quality of the developed software to customers. Nevertheless, Copilot is an interesting tool for the labor domain considering computer science-related areas and might be a plus in a large variety of companies in which software is mostly used for simple tasks. ELSA-Speak English Language Speech Assistant25 (ELSA) is an application based on artificial intelligence and speech recognition technologies designed to support users in learning English. It can be used to improve English pronunciation and provides lessons and exercises. The application provides real-time feedback to the users to enhance their speaking skills. ELSA-Speak can be employed within the labor market to prepare for job interviews (for example, candidates might be more confident to have an interview in English), to help non-native English speakers in their work, and to improve their English skills in order to increase opportunities for career advancement. 4 Skills, Competences, and Occupations For some time now, different initiatives have been presented to help students, the workforce, and companies to meet the needs of the labor market. All of them have in common that they are initiatives supported by government agencies, are updated periodically, and offer the data in a public and open way. In this section, we will focus on three of the most relevant databases and information systems on occupations and competencies.24 https://github.com/features/copilot. 25 https://elsaspeak.com/en/. Integrating Knowledge into Conversational Agents for Worker Upskilling 273O*NET O*NET26 (Occupational Information Network) is a program sponsored by the U.S. Department of Labor/Employment and Training Administration, which brings together occupational information to understand how the changing labor environment impacts the workforce. One of the main outputs of the program is the O*NET database, a collection of hundreds of standardized descriptions related to more than 1000 occupations found in the USA. This collection is updated periodically through worker surveys supplemented by information from occupation experts. Each occupation in the O*NET database is associated with a set of skills, abilities, and knowledge and is linked to a variety of tasks and activities. The version 26.2 (February 2023) includes 35 Skills, 33 Knowledge, 52  Abilities, 41  Work Activities, 4127 Tools Used, 17,975 Task Ratings, and 8761 Technology Skills. Each of these entities allows for the categorization of each occupation, its compatibility, and the specific detection of the needs of the occupation. O*NET is based on a conceptual model that provides a framework to identify the most relevant information about occupations even across jobs and industries. This is useful to link titles referring to the same occupation or to search for intersectoral relationships. ESCO ESCO27 (European Skills, Competences, and Occupations) is the European reference terminology describing and classifying occupations and relates them to the most relevant skills and competencies. In addition to being freely and openly available, it is translated into 27 languages (including the 24 official EU languages) and connects to several international frameworks and classifications, such as the International Standard Classification of Occupations (ISCO)28 or the European Qualifications Framework. ESCO v1.1.1 includes more than 3000 occupations, categorized into 10 groups, mapped with ISCO, and more than 13000 skills, subclassified into 4 types of concepts: knowledge, skills, attitudes and values, and language skills and knowledge. This hierarchy is partially based on the entities and elements of O*NET and NOC (another occupational resource described in the next section). This partial link with other databases, the mapping with ISCO, the connection with qualification levels, and above all, its multilingual support make it particularly attractive for applications that require adaptation to the languages that ESCO supports and especially for linking students and job seekers with employers and employment services. NOC NOC29 (National Occupation Classification) is the national system for the description of occupations, in French and English, and aligned with the Canadian labor market situation. This open database is updated annually with major revisions every 10 years and is based on data from censuses, employment services, labor regulations, and public consultations among others, which are then analyzed and26 O*NET OnLine, National Center for O*NET Development, www.onetonline.org/. 27 https://esco.ec.europa.eu/. 28 https://www.ilo.org/public/english/bureau/stat/isco/isco08/. 29 https://noc.esdc.gc.ca/. 274 R. Alonso et al.processed, and discussed by working groups. Like the aforementioned resources, NOC also includes a hierarchy and structure of occupations and is linked to the Occupational and Skills Information System (OaSIS),30 the Canadian database with detailed information on more than 900 occupations. It includes, among other information, the main duties of each occupation, together with the skills, abilities, and even the most common interests among the people who hold those occupations. Among the most interesting functionalities of NOC and OaSIS are the comparison between occupations, the link with Training, Education, Experience, and Responsibilities (TEER)31 to understand the training and education required to perform the main duties of an occupation, and the search occupations by interests (e.g., investigative, artistic, or social). In addition to the above, it is important to mention other international and national classifications that are either of reference or are applicable in other countries and are inspired by or refer to the above. The International Standard Classification of Occupations [6] (ISCO) is an international classification developed by the International Labor Organization of the United Nations. This classification and, in particular, its publications ISCO-88 and ISCO-08 define groups and titles of occupations associated with tasks. In general, these database and associated documents are less comprehensive than the three previous ones, but in certain occupational databases, connections with ISCO allow occupations to be linked between databases in different countries. One of the most common criticisms of these classifications is that they are created and adapted in high-income countries. For this reason, initiatives to map competencies in other low/middle-income countries are also being undertaken. Two examples of these initiatives are STEP (Skills towards Employment and Productivity) and PIAAC (Programme for the International Assessment of Adult Competencies). STEP is a World Bank program to improve the understanding of skills (cognitive, non-cognitive, and technical) in the labor market and relates skills to education, through household surveys and employer-based surveys. It is a program of the Organisation for Economic Cooperation and Development (OECD) that analyzes socio-labor and educational characteristics and links them to competencies at different cognitive levels such as literacy, numeracy, and problem-solving. The first cycle of PIAAC started in 2011 analyzing 42 countries and its second cycle will run until at least 2029 covering 30 countries. All these initiatives and databases provide a stable and updated background, based on reliable sources and in many cases that can be linked together, which allows us to propose ideas and proofs of concept such as the one mentioned in the following section.30 https://noc.esdc.gc.ca/Oasis/OasisWelcome. 31 https://www.statcan.gc.ca/en/subjects/standard/noc/2021/introductionV1. Integrating Knowledge into Conversational Agents for Worker Upskilling 2755 Proposed Solution The goal of the solution we have proposed in recent papers [1\u20133] is to make available to users, who are not always technologically prepared, the information contained within any of the resources described in Sect. 4 in the form of natural language and to help them analyze which skills and personal knowledge are most useful for their application in any job. One of the worker upskilling resources covered in Sect. 4, the O*NET database, contains many types of information. Our system uses the titles of the principal job categories that cover all the jobs in the North American job market, their descriptions, and the alternative titles for each one. Abilities, Skills, Knowledge, Work Activities, Tasks, Technology Skills, and Tools are the information that characterizes each job category. The number of elements for each job is constant for the first four categories and variable for the last three. The items in the first five present a score relative to their importance to the job they refer to, while the last two are lists of tools or technologies commonly used in each job category. More in detail, the system we propose performs the following tasks: 1. Determine how much the user\u2019s resume is appropriate for the chosen job category. The system uses NLP techniques to analyze the user\u2019s resume and to extract its most important information. The database entities and the extracted content from the CV are compared using semantic similarity. The resume score for a job is the sum of the scores of the discovered elements divided by the maximum score obtainable for the job itself and a corrective factor required to avoid penalizing jobs with few items in the entities with a variable number of elements. The system draws attention to the lacking aspects of the CV and suggests ways for users to increase their knowledge of each one. 2. Determine the user\u2019s suitability for the selected job. The system prompts the user to enter his/her self-assessed level (none, little, medium, good, excellent) in terms of Abilities, Knowledge, Skills, Work Activities, and Tasks entities taken from the database and associated with the selected job. The system returns a percentage score, where 60% is the suitability threshold and a list of lacking knowledge or abilities that the user might improve to raise his/her score. 3. Determine what occupation the user is best suited for. The system prompts the user to enter his/her self-assessed level (none, little, medium, good, excellent) in terms of Abilities, Knowledge, Skills, and Work Activities entities taken from the database and returns a list with five suggested job categories. 4. Perform conversation with the user. To integrate the knowledge provided by O-NET into the conversational agent, we first chose a reduced set of questions that it must be able to answer. The base question templates are:276 R. Alonso et al.\u2022 Alternate names of jobs\u2022 . [Abilities . | Knowledge . | Skills . | Tasks . | Tech-Skills . | Tools used . | Work activities. ] that are important or necessary in any job\u2022 Description of a job\u2022 The similarities between a couple of jobs\u2022 Which jobs require a specific . [Ability . | Knowledge . | Skill . | Task . | Tech-Skill . | Tool . | Work activity.]\u2022 Recommendations on how to improve one . [Ability . | Knowledge . | Skill . | Task . | Tech-Skill . | Tool . | Work activity. ]Then we implemented the query models necessary to retrieve the data to generate the answers. When the conversational agent recognizes a question in the user\u2019s input that is part of the set of known questions, it requests the database for the data necessary to prepare the answer in natural language. The system uses semantic similarity to match user input with one of the predefined question templates. If the similarity value is not high enough, the system will answer without the database knowledge, returning a default answer, or using a generative pre-trained model. More details of our system can be found in [1\u20133]. 6 Expected Challenges, Benefits, and Impact In terms of challenges, employee engagement in training activities and work commitments is one of the key elements. Knowing the information about their job and potential growth paths, while reducing doubts about the stability of their job, allows their adaptation and evolution, and thus engagement. Interactive chatbots and conversational tools can simplify the task of obtaining this information, for example, through informal interactions and by simply relying on the chatbot as a companion that offers relevant and appropriate information, focused on the characteristics of each occupation. As far as technical challenges are concerned, it is still necessary to reach an adequate balance between the use of large language models (e.g., ChatGPT) and models trained with concrete content based on validated or accepted reference information. One of the main problems of LLMs is the lack of determinism in the results [11] and the potential failures in the recommendations [13]. Both can be compensated by relying on databases such as the ones mentioned above and prioritizing the results based on the information in those databases. It is important to also mention and consider the challenges of conversational agents related to privacy. While many of the ideas mentioned in this article do not require storing worker information, and in our use cases we have demonstrated this, there are several cases, such as group data discovery or candidate analysis, where the handling of worker data could end up in the processing of private data, aggregationIntegrating Knowledge into Conversational Agents for Worker Upskilling 277of personal data and in some cases in profiling. The topic related to the concerns about user data\u2019s inappropriate use in user-chatbot interactions is being researched and surveyed [4, 8], and still there are several debates about it at the international level (e.g., in April 2023 Italy was the first Western country to block ChatGPT32 ). This calls for a critical analysis of the different uses of chatbots for upskilling and, above all, an alignment with the initiatives for the maintenance of the privacy of workers and users, from the General Data Protection Regulation to the Artificial Intelligence Act. Regarding benefits and impact, at the scientific and technical level, and as can be seen in the state of the art, advances in conversational agents and language models are clear. All these advances have an impact on the development of solutions such as the one we present, for example, by providing better interaction capabilities or even the possibility of answering open-domain questions. At the economic level, as also discussed in the introduction, there is a demand for workers and a demand for knowledge for specific activities, and upskilling agents can facilitate this task. At the social level, it impacts workers and the unemployed, in terms of analyzing their strengths, detecting training or internship needs, and adapting their CVs to fit specific jobs. From the worker\u2019s perspective, conversational AI agents based on standardized and reliable databases of occupational information have direct impacts and benefits. On the one hand, these conversational solutions have a direct impact on workers\u2019 knowledge of their work activity. The workers themselves can at any time obtain reliable information about their job and learn about skills, activities, and knowledge relevant to the task they are carrying out. Moreover, the worker can ask the conversational agent which are the usual technical skills for a certain occupation or activity to imagine where they might be oriented. On the other hand, it is beneficial for their training and career. The employees can detect points in which their profile would benefit from training and at the same time detect training needs and create training plans to adapt to the needs of their position, or to another position they plan to move to. This is one of the other benefits of these conversational agents since the workers can compare themselves with professions and positions in which they would be interested in changing or being promoted. From a more organizational and business point of view, there are also a couple of areas where AI-based conversational agents such as the ones mentioned in this article can be beneficial. The part of assistance in hiring processes is a point in which these agents will have a direct impact: from providing candidates with information about the position, to pre-screening or determining the suitability of a candidate by using conversational agents to compare the candidate\u2019s CV with the baseline of the occupational reference database. Conversational agents are also beneficial in the detection of training needs for specific positions or the creation of group training plans, based on the needs of multiple workers.32 https://www.bbc.com/news/technology-65139406. 278 R. Alonso et al.Therefore, the impact on the HR area is clear: talent management, discovery of training paths, HR resources, growth programs, etc. All of them benefit in the short term from conversational agents like the ones mentioned above. Proofs of concept and use cases conducted with conversational agents, based in our proposed solution, acting as virtual interviewers, skills gap detectors or as supporters for the selection of better training, demonstrate the potential of these technologies. Not only at the level of large technology companies but the aforementioned solutions can also make a difference at the level of SMEs in industrial and manufacturing environments. Where they may not have large HR departments but need reliable, objective, and consistent feedback for resource upskilling and solutions based on standardized information, starting from the same baseline and with clear and repeatable criteria. 7 Conclusions This chapter explores the potential uses, benefits, and limitations of conversa-tional agents within the labor market. The chapter guides the reader through the state-of-the-art research on this topic and presents which technologies are currently employed. Furthermore, the chapter analyzes conversational agents that are disrupting the labor market, where AI tools are expected to be employed for a large variety of tasks such as learning new skills, supporting document writing, code development, language skills improvement, and so on. Along with these conversational agents, we also introduce the reader to valuable sources of information which can be leveraged to build AI systems on top. Finally, we present how potential solutions can be used for specific use cases and discuss how all these technologies can impact the labor market. As main lessons, we would like to mention the need for both the workforce and companies to adapt to the rapidly changing world of new technologies and how this can be beneficial, for example, by taking advantage of it to better understand occupations, retain talent, hire, gain job knowledge, or adapt to new activities. It is also important to consider the need to efficiently integrate large language models and validated and reliable databases. Finally, it is essential to consider and analyze the privacy implications of these solutions. It is possible to develop privacy-aware conversational systems for the upskilling of workers, but there is a possibility that certain solutions may abuse data. For this reason, it is critical to provide these systems with consideration of Human Centricity aspects and all the factors that compose it, including privacy. In the medium term, it is expected that these technologies will be integrated into the regular workflow of employees and will have a positive impact on employee engagement and professional development. For this reason, we expect that this chapter will foster several visions to the reader about the role of AI-based conversational agents in the labor domain and worker upskilling which might bring unprecedented development in the field.Integrating Knowledge into Conversational Agents for Worker Upskilling 279Acknowledgments This work has been partly supported by EU H2020 research and innovation programme project STAR\u2014Safe and Trusted Human Centric Artificial Intelligence in Future Manufacturing Lines (Grant n. 956573). We acknowledge financial support under the National Recovery and Resilience Plan (NRRP), Mission 4 Component 2 Investment 1.5\u2014Call for tender No.3277 published on December 30, 2021 by the Italian Ministry of University and Research (MUR) funded by the European Union\u2014 NextGenerationEU. Project Code ECS0000038\u2014Project Title eINS Ecosystem of Innovation for Next Generation Sardinia\u2014CUP F53C22000430001\u2014Grant Assignment Decree No. 1056 adopted on June 23, 2022 by the Italian Ministry of University and Research (MUR) References 1. Alonso, R., Dess\u00ed, D., Meloni, A., Recupero, D.R.: Incorporating knowledge about employa-bility into conversational agent. Appl. Intelligence submitted (2023) 2. Alonso, R., Dess\u00ed, D., Meloni, A., Recupero, D.R.: A novel approach for job matching and skill recommendation using transformers and the o*net database. Big Data Res. submitted (2023) 3. Alonso, R., Dess\u00ed, D., Meloni, A., Reforgiato Recupero, D.: A general and NLP-based archi-tecture to perform recommendation: A use case for online job search and skills acquisition. In: Proceedings of the 38th ACM/SIGAPP Symposium On Applied Computing. ACM Special Interest Group on Applied Computing (SIGAPP) (2023) 4. Belen Saglam, R., Nurse, J.R.C., Hodges, D.: Privacy concerns in chatbot interactions: When to trust and when to worry. In: Stephanidis, C., Antona, M., Ntoa, S. (eds.) HCI International 2021 - Posters, pp. 391\u2013399. Springer International Publishing, Cham (2021) 5. Fadhil, A., Gabrielli, S.: Addressing challenges in promoting healthy lifestyles: the al-chatbot approach. In: Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare, pp. 261\u2013265 (2017) 6. Hoffmann, E.: International Statistical Comparisons of Occupational and Social Structures, pp. 137\u2013158. Springer US, Boston, MA (2003). https://doi.org/10.1007/978-1-4419-9186-7_ 8 7. Hussain, S., Ameri Sianaki, O., Ababneh, N.: A survey on conversational agents/chatbots classification and design techniques. In: Web, Artificial Intelligence and Network Applications: Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019) 33, pp. 946\u2013956. Springer (2019) 8. Ischen, C., Araujo, T., Voorveld, H., van Noort, G., Smit, E.: Privacy concerns in chatbot interactions. In: F\u00f8lstad, A., Araujo, T., Papadopoulos, S., Law, E.L.C., Granmo, O.C., Luger, E., Brandtzaeg, P.B. (eds.) Chatbot Research and Design, pp. 34\u201348. Springer International Publishing, Cham (2020) 9. Lee, M., Ackermans, S., Van As, N., Chang, H., Lucas, E., IJsselsteijn, W.: Caring for Vincent: a chatbot for self-compassion. In: Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, pp. 1\u201313 (2019) 10. Lee, T., Zhu, T., Liu, S., Trac, L., Huang, Z., Chen, Y.: CASExplorer: A conversational academic and career advisor for college students. In: The Ninth International Symposium of Chinese CHI, pp. 112\u2013116 (2021) 11. Maddigan, P., Susnjak, T.: Chat2vis: Generating data visualisations via natural language using ChatGPT, codex and gpt-3 large language models. IEEE Access (2023) 12. Meloni, A., Angioni, S., Salatino, A., Osborne, F., Reforgiato Recupero, D., Motta, E.: Integrating conversational agents and knowledge graphs within the scholarly domain. IEEE Access 11, 22468\u201322489 (2023). https://doi.org/10.1109/ACCESS.2023.3253388 13. Oviedo-Trespalacios, O., Peden, A.E., Cole-Hunter, T., Costantini, A., Haghani, M., Kelly, S., Torkamaan, H., Tariq, A., Newton, J.D.A., Gallagher, T., et al.: The risks of using ChatGPT to obtain common safety-related information and advice. Available at SSRN 4346827 (2023)280 R. Alonso et al.14. Reimers, N., Gurevych, I.: Sentence-Bert: Sentence embeddings using Siamese Bert-networks. In: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Process-ing. Association for Computational Linguistics (2019). https://arxiv.org/abs/1908.10084 15. Singh, S., Beniwal, H.: A survey on near-human conversational agents. Journal of King Saud University - Computer and Information Sciences 34(10, Part A), 8852\u20138866 (2022). https://doi.org/10.1016/j.jksuci.2021.10.013. https://www.sciencedirect.com/science/article/ pii/S1319157821003001 16. Vo, N.N., Vu, Q.T., Vu, N.H., Vu, T.A., Mach, B.D., Xu, G.: Domain-specific NLP system to support learning path and curriculum design at tech universities. Comput. Educ. Artif. Intell. 3, 100042 (2022) 17. Xu, A., Liu, Z., Guo, Y., Sinha, V., Akkiraju, R.: A new chatbot for customer service on social media. In: Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, pp. 3506\u20133510 (2017) 18. Zhou, M.X., Mark, G., Li, J., Yang, H.: Trusting virtual agents: The effect of personality. ACM Trans. Interact. Intell. Syst. (TiiS) 9(2-3), 1\u201336 (2019) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Advancing Networked Production Through Decentralised Technical Intelligence Stefan Walter and Markku Mikkola 1 Introduction Networked production has been increasingly important for companies looking to stay competitive in today\u2019s global marketplace [1, 2]. Initially undertaken due to the requirements of profitability, many manufacturers have been focusing on their core competencies and outsourcing non-core functions to specialised suppliers [1, 3, 4]. The resulting fragmentation made increased digitalisation necessary. By leveraging technology and digital platforms, companies can connect their manufacturing activities with other organisations, suppliers, customers, and resources, both domestically and globally, to achieve a competitive advantage [5\u20138]. Companies do so by accessing a broader range of suppliers and customers, reducing costs, increasing efficiency, and improving the quality of their products when networking. This also allows for greater flexibility in responding to changes in demand, supply chain disruptions, or market conditions and provides the required agility that is so important to counter economic volatility or political instability [9\u201311]. In addition, networked production can create opportunities for innovation and value creation, as companies can work with partners to develop new products or improve existing ones. By sharing expertise, knowledge, and resources, companies can capitalise on each other\u2019s strengths and capabilities to create new business opportunities and improve their competitive position [12, 13]. Companies can thus speed up the product development process and improve time-to-market. This position is also reflected in the concepts of networking in engineering, networked product/service engineering, and collaborative design, respectively [14]. S. Walter (\u0002) \u00b7 M. Mikkola VTT Technical Research Centre of Finland Ltd., Espoo, Finland e-mail: stefan.walter@vtt.fi; markku.mikkola@vtt.fi \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_16281282 S. Walter and M. MikkolaThus, a significant benefit of networked production is the possibility for compa-nies to move away from traditional sequential or linear process chains and adopt a more dynamic approach to manufacturing and support processes [15, 16]. By connecting their operations with other organisations and resources through digital platforms, companies can access a broader range of manufacturing capabilities, materials, and services. For example, companies can dynamically arrange and release manufacturing and support processes in case production requires a quick scale-up to meet a sudden increase in demand. Additionally, networked production allows and virtually demands that companies share information and collaborate with partners, suppliers, and customers in real-time. This enhances transparency and visibility across the supply chain, which can help to identify and mitigate potential bottlenecks or delays [17]. The functioning of networked production is bound to the management capa-bilities of the companies involved. Typically, effective management in networked production has required strong leadership and management expertise to ensure that the partners involved work together seamlessly and effectively. Companies needed to establish clear communication channels and protocols, define roles and responsibilities, and establish processes for monitoring and managing performance. Moreover, the success of networked production depends on the compatibility of integrated, cross-organisational information chains [4]. Network partners need to ensure that they can exchange information seamlessly and securely with their partners, suppliers, and customers. This necessitated the adoption of common standards for data exchange [18]. In addition, data exchange must take place on a trusted basis and therefore requires corresponding communication security measures to protect sensitive information [19]. All this will become even more difficult with a wider expanding network. The increasing complexity of networked production presents a significant challenge to management, which requires new and intelligent approaches to effectively manage and optimise the manufacturing process. While managing networked production would require a holistic understanding of the entire value network involved, including suppliers, customers, internal operations, and other stakeholders, it is hardly possible with traditional corporate management methods based on hierar-chical structures [20, 21]. This is also true for the increasingly demanded agile management involving the flexibility and adaptability to respond quickly to changes in customer demand, market conditions, or supply chain disruptions. To effectively manage networked production, companies can leverage advanced technologies, such as artificial intelligence and data analytics, to develop new management approaches and enhance decision-making. Decentralised Technical Intelligence (DTI) is a new management approach that involves the integration of human and machine intelligence in decision-making processes. DTI allows for the creation of a network of interconnected systems, devices, and agents that operate in a decentralised and autonomous manner, reducing the need for leadership through hierarchy and potentially leading to increased efficiency and productivity [22]. The role of the workforce in this integrated system is crucial, and the human dimension adds a unique quality to the process [23].Advancing Networked Production Through Decentralised Technical Intelligence 283To achieve advanced networked production with the help of DTI, a roadmap is necessary, which involves several elements linked to a vision, value promise, and development pathway. The roadmap should include major building blocks, major capabilities, characteristics, and processes typical for the effective implementation of DTI in networked production. By implementing this roadmap, companies can maintain a leadership position in future networked production, which will be crucial for maintaining a competitive edge in the global market. The technological advancements in networked and self-controlling production can offer new opportunities for creating value, but it is important to ensure that these opportunities align with business goals and are economically viable. The business perspective provides a real-world corrective, meaning that any new technological solutions must also make sense from a business standpoint, considering factors such as profitability and feasibility. Thus, it is important to balance technological possi-bilities with business realities to ensure the long-term success of any innovation. This article explores the concept of Decentralised Technical Intelligence and its meaning for advancing networked production as a competitive factor. It will also discuss possible building blocks for implementing an effective roadmap for advanced networked production through DTI. Finally, this article will emphasise the need for a business perspective to ensure that any technological advancements align with the economic viability and create real value. 2 Decentralised Technical Intelligence Decentralised Technical Intelligence (DTI) is a concept that aims to support the deployment of decentralised, autonomous systems with embedded intelligence in manufacturing. It is a response to the management requirements of networked manufacturing and aims to enable decentralised decision-making and autonomous action while reducing centralised planning or making it redundant. It arose from a demand by the ManuFuture European Technology Platform to increase productivity and efficiency in future manufacturing [22, 24]. DTI focuses on several areas to leapfrog performance gains in terms of high performance, high quality, high resource efficiency, high speed, high flexibility, self-optimisation and self-control, to name just a few (Fig. 1). These performance gains stretch over different areas, including ICT technologies, architectures, platforms and standards, high-performance engineering, high-performance manufacturing systems, and high value-added networked production [22, 24]. According to the Plattform Industrie 4.0 [25], decentralised intelligence is grounded on the recognition that the European industry\u2019s strength is derived from a system of innovation and commerce fuelled by diversity, heterogeneity, and specialisation. These elements are integral to the European industrial society. A decentralised regime of open and adaptable systems creates optimal conditions for shaping the digital economy while adhering to the principles of a free and socially-oriented market economy [25].284 S. Walter and M. MikkolaFig. 1 Utilising technologies to enhance universal impact (adapted from Sautter [22]) Table 1 DTI as the next evolutionary step in industry performance (adapted from Sautter [22]) Control theory, systems engineering Agent-based/holonic manufacturing Decentralised technical intelligence Artificial Cyber-physical intelligence systems Closed-loop control system incorporating sensors, actuators and controllers Computer-enabled simulation of human-like cognitive abilities Convergence of software systems and interconnected mechanical/elec-tronic components enabled by a data infrastructure such as the Internet-of-Things Independent and coordinated agents deliver flexibility, adaptability, agility and dynamic reconfigurability to manufacturing systems Next transformative phase to revolutionise industry performance\u2014 exceeding current limitations through an interdisciplinary framework, including self-X capabilities DTI is adopting this position and is developed as a systemic and interdisci-plinary approach that represents a key factor for the macro- and multidimensional transformation of manufacturing systems. It builds on previous developments in systematic and automated manufacturing and can be seen as an evolutionary step towards more advanced manufacturing systems (Table 1). Earlier steps included for example control theory and systems engineering, involving feedback loops, artificial intelligence, cyber-physical systems as a connection of informational and electromechanical components, and holonic manufacturing, which incorporates autonomous and collaborative agents creating an adaptive and flexible manufac-turing system [22].Advancing Networked Production Through Decentralised Technical Intelligence 285By integrating human knowledge and experience with artificial intelligence and other advanced technologies, DTI aims to create a more intelligent and adaptable manufacturing system that can respond quickly to changing conditions and optimise performance. The concept recognises that humans and machines each have unique strengths and limitations, and that by combining their abilities and expertise, a more effective and efficient system can be created. This requires a multi-agent architecture, where different agents (including humans and machines) work together in a coordinated manner to achieve common goals. The goal is to create a system where each agent contributes to the overall intelligence of the system and helps to create a more efficient and effective manufacturing process. Consequently, DTI consciously aims for holism and recognises the importance of humans in industrial manufacturing, which puts the concept in contrast to the earlier conceptualisations that were strictly technological in their orientation. DTI recognises that humans play a crucial role in manufacturing and seeks to empower them with the necessary tools and technologies to make informed and effective decisions. By integrating humans into the manufacturing process, DTI enables them to work alongside machines and systems more collaboratively and efficiently. Sautter [22] compares DTI as being similar to our nervous system. The body\u2019s nerves make up part of the main control structure, which provides information on the environment and inner body functioning. This way, the autonomic nervous system controls many body functions and processes in a seemingly automatic way with little or no conscious involvement. Similarly, DTI ensures the smooth functioning and good performance of complex technical systems such as produc-tion systems. It allows the production system to execute tasks autonomously in interaction with the environment and keeps the system in optimal condition. DTI components can be used to make the system perform tasks autonomously and optimise its performance without central or conscious control. Therefore, DTI is concerned with self-organisation and self-steering aspects in production systems. Mere artificial intelligence, in turn, is a simulation of human intelligence processes by machines based on advanced data analytics and algorithms that emulate and simulate processes and systems. It is often used as a tool to support human decision-making. The DTI concept can also be considered a forerunner or prerequisite for the industrial metaverse. The industrial metaverse, as a comprehensive digital twin of every relevant process or artefact in a factory or production network and including the human workforce, will make use of existing and developing technologies such as artificial intelligence and machine learning, extended reality, advanced data management structures and cloud and edge computing. These technologies create an interface between the real and digital worlds. This interface aims at offering fully immersive, real-time, interactive, persistent, and synchronous representations and simulations of complex systems such as machines, factories, cities, and logistics286 S. Walter and M. Mikkolanetworks in a decentralised way [26]. While specific applications in the networked production realm are still to be explored, possibilities include interactive assem-bling, involving, for example, network partners such as suppliers and customers, collaborative development of products and services, their design, engineering and testing, product presentations and evaluations and product-related services, sales activities and tracking of material flows, and training of personnel [27]. 3 Implications for Networked Production Management Traditionally, the objectives of networked production included the cutting of logistics costs and high inventories, in particular, by improving the coordination and integration of production and logistics activities across the network, the shortening of lead times, especially by improving the availability of information and the flow of materials across the network to generate quick responses, the enhancement of service levels, for example by improving the coordination, collaboration and understanding between companies and of companies\u2019 needs in the network, and enhancing competitiveness, in particular, by increasing the capacity of industrial companies to operate globally in an agile manner through the network [1, 2, 4, 28, 29]. All of these remain true, and these aspects are joined by more recent perspectives on collaborative design and engineering and the management of services. Achieving these goals requires collaboration among the companies involved. Therefore, all participants need to see benefits from their effort in collaborat-ing. Although companies will try to maintain their autonomy as actors in the network, emerging technologies enabling DTI are likely to dilute the perception of organisational boundaries in the future. Hence, production will largely take place in non-hierarchical networks where decision-making is decentralised [30, 31]. This requires the development of methods and tools for collaborative planning, management, and optimisation of production resources, as well as distributed planning and scheduling [32\u201334]. Other important tools for management include monitoring production and equipment and their maintenance. Increasingly, tools also need to support the requirements of the circular economy. It is essential to ensure interoperability between the different technologies and software solutions, business and production processes, and organisational structures [35]. All new methods and tools should follow the principle behind DTI, which allows operating in a decentralised manner so that companies can operate in several production networks simultaneously. Conventionally, these functions have been relying on regular updates to a central database with limited learning capacity built-in and neither with consideration of external data. For advanced management of networked production and its monitoring, decentralised ICT systems are neededAdvancing Networked Production Through Decentralised Technical Intelligence 287[36, 37]. These systems use distributed knowledge and integrate heterogeneous data sources to evaluate the state of monitored systems [14]. Competitiveness is based on various performance objectives such as quality, price, delivery service, responsiveness, and flexibility. With shorter product life cycles and a greater variety of models, manufacturers need to respond quickly to customers\u2019 needs and handle capacities flexibly. The technologies driving DTI allow companies to move towards decentralised operations, take advantage of available resources and, for example, be closer to their markets. Taking advantage of available resources via decentralised operations and intense network interactions offers, in particular, opportunities to run make-to-order and engineer-to-order strategies [38, 39]. Both strategies begin their specific operations only after a customer has placed an order. It represents in some way an orientation towards lean management because it consequently aims at saving resources while avoiding producing to stock. On the other hand, the close customer relationship targets customer wishes, flexibility and responsiveness to individual needs and, therefore, reflects the need for customisation [4, 40]. The mentioned strategies will help companies maintain profitability whilst operating with smaller batch sizes and shorter lead times for customer benefit [14]. The technologies associated with decentralisation enable coordination and syn-chronisation of production and decision-making processes, which are required in non-hierarchical networks [41\u201344]. The production strategies mentioned above are most effective when typical production functions such as engineering, capacity planning, order management, manufacturing, and logistics are integrated com-prehensively. DTI technologies allow the inclusion of network partners in all information flows and enable sharing of appropriate resources. When leveraging advanced technologies such as AI, machine learning and edge computing to enable decentralised decision-making and coordination of production processes, humans contribute their domain expertise, intuition, and creativity. They possess contextual knowledge and problem-solving abilities and can provide oversight, make strategic decisions and handle complex and non-routine tasks that require creativity, adaptability and critical thinking. AI, on the other hand, can assist humans by automating routine tasks, analysing large datasets, identifying patterns and anomalies and providing recommendations for optimised decision-making. DTI, thus, facilitates the integration of humans and AI through technologies like edge computing, where AI algorithms can be deployed on edge devices, and cloud computing, where AI models can be trained and deployed centrally. This allows for real-time decision-making at the edge and enables seamless coordination and synchronisation across the production network.288 S. Walter and M. MikkolaCase Study: Production Scheduling Pilot In the context of production and supply chain management, coordination of processes and their consequences is crucial for maintaining robustness and resilience. The EU research project knowlEdge - Towards Artificial Intelligence powered manufacturing services, processes, and products in an edge-to-cloud-knowledge continuum for humans [in-the-loop] [45] aims to unlock the full potential of AI in manufacturing by developing AI methods, systems and data management infrastructure, with a focus on edge-cloud computing and collaboration between humans and AI. In a production scheduling use case, the project optimises supply chain planning, demand forecasting and production batch optimisation in an industrial environment. DTI technologies are integral to the solution. Real-time data from production facilities is collected using sensors and data interfaces at the edge, enabling monitoring, analysis and informed decision-making. Machine learning algorithms analyse historical and real-time data to predict demand, optimise production schedules and identify bottlenecks. Process simulation and digital twins are used to simulate and predict future scenarios, allowing proactive adjustments to production schedules. The integration of AI and data analytics empowers employees to make informed decisions, reducing errors and saving time. The AI system con-tinuously learns and improves, leveraging insights from documented devia-tions, errors and solutions. User-friendly interfaces facilitate human-centred interaction and visualisation, enabling monitoring, process adjustments and coordination at the edge. This holistic approach enhances production, facili-tates proactive decision-making and improves coordination and collaboration between humans and AI agents. Essentially, this points to smart and collaborative manufacturing, which involves collaborative planning, management and operation of networked production. The approach deliberately utilises the network as a resource for distributing tasks and acquiring means of production and could also be seen as in line with what Jovane et al. call a plug-and-produce network of production services [14]. This way, the net-work can respond to immediate challenges in a much better way than under a regime of hierarchical planning and management. Thus, the resulting inter-organisational integration of companies reflects the regime of networked production of the future. This becomes particularly obvious when considering the self-organisational and autonomous operations of DTI agents, which, based on predefined process targets, can easily transect organisational boundaries to carry out tasks. Consequently, in a resource constraint world, the focus on networked production and the potential to expand the network when opportunities arise, companies can leverage the strengths of different network partners and achieve a more robust and resilient production, whilst unlocking new opportunities for growth and innovation [46\u201348].Advancing Networked Production Through Decentralised Technical Intelligence 289Following the DTI logic, future production networks will be following a self-organising and self-forming paradigm [22]. Rather than being pure manufacturers of goods, companies will be more and more providers of service, which solve a problem for a user of the manufactured product [49\u201351]. The shift towards a self-forming and decentralised supply chain requires the development of a conceptual framework for a manufacturing-as-a-service (MaaS) approach. This approach involves the provision of value-added services throughout the entire life cycle of a product, including planning, installation, operation, and alterations as well as the recirculation of used product and associated raw materials [52, 53]. In line with the principles of decentralisation and networked production, manu-facturing capabilities and resources are provided as on-demand services to compa-nies or individuals. Essentially, MaaS can be facilitated through the integration of technologies such as edge computing, cloud computing and IoT. These technologies enable the connection and coordination of manufacturing resources across a network of distributed nodes. The decentralisation of activities allows companies to define and execute self-contained service packages independently, supporting the flexibility and adaptabil-ity of the network [14]. This means that manufacturing tasks can be outsourced to specialised service providers who offer specific capabilities or expertise. These providers can be in different geographical locations, allowing for flexibility in production and leveraging the strengths of each partner. MaaS may include the integration and coordination of typical manufacturing processes, such as design and engineering, production planning, procurement, assembly, quality control and logis-tics. Additionally, DTI enables continuous monitoring and control of manufacturing operations, ensuring general visibility, heightened transparency and adaptability throughout the production process. Additionally, there is a growing demand for \u201call-inclusive\u201d solutions that incor-porate both products and related services, which presents an opportunity for collaboration between larger and smaller companies to design and offer specialised services for new markets [54]. Maas in this context also enables smaller companies or individuals to access manufacturing capabilities that were traditionally available only to larger organisations. 4 Building Blocks and Implementation Roadmap A technology roadmap is a strategic planning tool that helps organisations to align their technology development efforts with their business goals and objectives [55, 56]. It can also serve as a research agenda for continuous research. This way, the elements of the roadmap, building blocks, required intermediate steps and envisioned outcomes, can be further refined and adapted to new insights. Thus, through the roadmap the major capabilities, characteristics, and processes that are needed to create a successful DTI-enabled and networked production can be understood.290 S. Walter and M. MikkolaThe roadmap for realising advanced networked production with the help of DTI is comprehensive and involves several building blocks, each with its vision, value promise and development pathway. To achieve the desired goals, it is important to have a clear pathway for each building block, divided into near-term (0\u20135 years), mid-term (5\u201310 years) and long-term (over 10 years) goals and performances (Fig. 2). The first building block, Universal Transparency, aims to enable end-to-end transparency and accountability across value networks, generating added value through comprehensive information available for all involved. The goal is to enable end-to-end transparency and visibility in networked production. An increase in coordination can help to ensure that the different activities within the network are better aligned, which can lead to greater efficiency and better results [57, 58]. This is achieved using various technologies and tools that enable comprehensive availability of information and real-time monitoring of the network\u2019s performance. Universal transparency also promotes customer value by providing more visibility and transparency in the production process, which can help build trust [59]. By building trust, the different partners within the network can better collaborate and achieve their goals together. It also enables social sustainability by promoting accountability and compliance with legal requirements and ensuring that all partic-ipants in the network act ethically and responsibly [4]. The near-term goals include progress against sustainability and compliance goals, data management protocols, and information security protocols. Mid-term goals include data analysis for transparency goals involving x-tier suppliers, while the long-term goal is to achieve end-to-end transparency in value chains that extends beyond legal requirements. Cooperate to Compete is another building block that involves knowledge-based continuous development and network innovation. It involves co-design, co-engineering, and co-production of customised products and services. This building block generates added value by capturing the benefits of collaboration, such as sharing knowledge and resources [60]. The integration of product development into the network is especially important during the early phases of development when collaboration between different actors in the production network can have a decisive influence on competitive factors, such as reducing costs, shorten time-to-market, improve product quality, increase flexibility in production, promote innovation, and develop sustainable solutions [4]. Near-term goals include hybrid systems for knowledge-based engineering and process development, while mid-term goals include inter-factory organisation for enhanced collaborative design and engineer-ing. Long-term goals involve advanced interfaces and methodologies for domain knowledge capturing and situation/context-dependent systems for engineering and process development across factory boundaries. Sustainable and Circular Operations is a building block that focuses on closed-loop cycles, greater efficiencies, and new ways of sourcing materials. The added value is particularly produced through resource efficiency, extended machine operation, and securing new resources. In terms of resource efficiency, the focus is on optimising the utilisation rate of machines and equipment, avoiding downtime and production disruptions and reducing waste and energy consumption [4, 14].Advancing Networked Production Through Decentralised Technical Intelligence 291Building blocksNear-Term Goals (0 to 5 years) Mid-Term Goals (5 to 10 years) Long-Term Goals (over 10 years) Timeline, goals & performanceVision Universal transparency Cooperate to compete Sustainable and circular operations Intelligent control of value networks Integration with (new) network partners From performance\u2026\u2026 to resilience Machinergy & equipment designed and engineered for long service life Emphasis on secondary raw materials Minimal manufacturing and maximal servicing paradigm for sustainability Machinergy & equipment to design and engineer products for a circular economy Decentralised management reduces risks and increases resilience Hybrid systems for knowledge-based efficiency gains Domain knowledge to improve process efficiency Hybrid systems for knowledge-based engineering and process development, using human work and largely isolated IT support systems Inter-factory organization for enhanced collaborative design, engineering, product and process development Situation/context-dependent systems for engineering and process development across factory boundaries Advanced interfaces and methodologies for domain knowledge capturing Transparency beyond legal requirements is competitive advantage Data management protocols, privacy, information security and cybersecurity protocols implemented Network partners value transparency as a form of trust Progress against sustainability and compliance goals part of management reporting Data analysis for transparency goals involving x-tier suppliers End-to-end transparency in value chains functional Widespread merging of human domain knowledge to AI systems AI solutions applied in various parts of the network Limited and isolated design efforts for human-AI interaction Integrated platforms and architectures for network-level AI Corporate policy changes to allow new ways of management spread Human and artificial agents working seamlessly together Awareness raised to adapt more traditional management structures Increased capacity for adaptation, anticipation, agility and resilience due to decentralised management Autonomous transaction processes and restructuring Manufacuring as a service and experience Continued digitalisation of supply chain planning, connecting internal production and planning systems Digitise product information, e.g. through administration shell Integration of factories with suppliers and customers \u201dConvergence of technologies for end-to-end transparency, customer benefits, sustainability, accountability, compliance; added value through comprehensive information availability\u201d \u201dKnowledge-based continuous development, network drives innovation; customised products/services, collective design & engineering; capturing the benefits of collaboration, e.g. sharing knowledge and resources\u201d \u201dClosed-loop cycles, greater efficiencies, new ways of sourcing, bio-based products, from performance to resilience; added value through resource efficiency, extended machine operation and securing new resources\u201d \u201dDecentralised, autonomous management of value networks (including human and artificial agents); added value through better anticipation and agility\u201d \u201dOn-the-fly integration, separation, interoperation, federated architectures, manufacturing-as-a-service; added value through overall operational performance, customer satisfaction, enhanced products\u201d Fig. 2 DTI roadmap for advanced networked production292 S. Walter and M. MikkolaSustainability-wise, the emphasis is on minimising the environmental impact of production processes by reducing waste and emissions, using alternative sources for raw materials, such as secondary sources, and considering circular economy principles for material and resource flows. Near-term goals include machinery and equipment to design and engineer products for a circular economy. Mid-term goals include hybrid systems for knowledge-based efficiency gains, and machinery and equipment designed and engineered for long service life. Long-term goals involve decentralised management for reduced risks and increased resilience, minimal manufacturing and maximal servicing paradigm for sustainability, and emphasis on secondary raw materials. Intelligent Control of Value Networks involves decentralised, autonomous man-agement of value networks, comprising various agents including human and artificial agents. This building block generates added value through better antic-ipation and agility. In a learning cognitive production network, assets in the network are interconnected and can self-optimise. Depending on the context, control is carried out automatically or autonomously within the collaboration between humans and artificial intelligence [61]. Predictions can be made based on data sources and amounts that would be hidden from humans alone [4]. Near-term goals include AI solutions applied in various parts of the network, while mid-term goals involve integrated platforms and architectures for network-level AI. Long-term goals involve human and artificial agents working seamlessly together, and increased capacity for adaptation, anticipation, agility, and resilience due to decentralised management. Finally, Integration with (New) Network Partners (or their dissolution of redun-dant relationships) involves on-the-fly integration, separation, and interoperation, federated architectures, and manufacturing-as-a-service [62]. This building block creates added value through overall network performance, operational efficiency, customer satisfaction, and enhanced products. Companies can expand their capa-bilities and access new markets, assets, technologies and resources. This leads to enhanced network performance and will also involve strong collaboration between large companies and smaller, niche manufacturers [14]. Near-term goals include continued digitalisation of supply chain planning, connecting internal production and planning systems, and digitalisation of product information. Mid-term goals involve integration of factories with suppliers and customers, while long-term goals involve autonomous transaction processes and restructuring, and manufacturing-as-a-service and experience. The roadmap for realising advanced networked production with the help of DTI is complex considering, for example, the variety of technologies involved and requires a long-term vision. In addition, it is important to recognise and exploit new business models and opportunities for creating value, while keeping in mind the viability of the proposed solutions from a business perspective.Advancing Networked Production Through Decentralised Technical Intelligence 2935 DTI Deployment from Business and Organisational Perspective The industrial evolution towards networked and self-controlling manufacturing concepts enables and generates groundwork for new business models, as well as sets new requirements for the skills and expertise of the personnel. In addition to the need to maximise profits, new challenges such as acting properly in the face of environmental damage cannot be ignored. It is therefore a matter of recognising and exploiting new opportunities for creating value throughout a product\u2019s life cycle. Due to its cross-company nature, networked manufacturing offers the appropriate conditions for this, for example, partnerships for knowledge-based and sustainable extraction of necessary resources, manufacturing and product development, and innovation development. At the same time, new business models must also recognise new forms of work and the development of skills, learning and education. Digitalization of companies\u2019 and organisations\u2019 processes enables the separation of data and information from their physical/real operational environment. This in turn enables new ways to organise work within and between organisations, which also leads to new business model opportunities. In practice, the so-called cyber-physical systems can be implemented where physical processes are monitored by creating a virtual counterpart of the physical world in which decentralised decisions can be made by communicating and cooperating with each actor in real-time using the Internet and IoT components [63]. From an organisation point of view, the DTI vision brings about changes to the distribution of work between human employees and computer systems. More and more human processing can be automated to be done by smart ICT systems. This provides, on the one hand, an opportunity to increase the efficiency of the organisation, and on the other hand, develop new kinds of data-based services and new ways of connecting customers, partners, and suppliers. Furthermore, the skills and competencies of the personnel must be developed and adapted to meet the new requirements the DTI deployment entails. In general DTI increases the connectivity of the different stakeholders, which means that the actors need to broaden their perspective on their business environment to include partners that are further away from them in the value chain, e.g., they need to consider the operations of their customer\u2019s customer. More systemic thinking is required and skills and competences to realise it. An example of the business opportunities this enables is a condition based maintenance service concept, where a component or sub-system provider is connected to the equipment in use either directly or via OEM\u2019s systems to follow the product performance during its life cycle. All these connections, data availability and security issues need to be understood by all partners in the connected system. This requires enhancement of two kinds of competences: (1) competences to understand the technological system and its operation, and (2) competences to understand the operational environment of the end-product at end-user location.294 S. Walter and M. MikkolaIn the digital world, the DTI envisions new services, such as platforms, that are required to enable the myriad of potential connections of digital data flows between different stakeholders. This digital world forms its market environment where new platform providers as well as traditional business ecosystem actors with different resources, competitive advantages and strategic aims are positioning themselves. The digital marketplace is much more flexible and dynamic than the traditional as digital relationships between actors are easier to establish and terminate. Digital platforms have a specific characteristic of aiming to orchestrate a large number of business actors, i.e., their business is based on connecting other actors. This challenges the traditional strategic planning of organisations rooted in the resource-based view of the firm, which focuses on achieving competitive advantage by owning and controlling resources [64]. These resources should have the so-called VRIN characteristics, i.e., be valuable, be rare, be inimitable, or be non-substitutable. Digital platform business models also challenge the positioning framework of strategic management [3], which focus on competitive advantage by raising structural barriers to entry and increasing bargaining power. The digital marketplace enables more dynamic competition, where, e.g., disruptive innova-tion from start-ups and entry by firms from different industry sectors can bring completely new competitive pressure to existing business models [65]. Instead of competition between firms, the competition is between business ecosystems consisting typically of one or two central (platform) companies and other firms providing complementary goods and services. In this kind of context, the value capture component of a business model should balance the focal firm\u2019s profits and the profitability of the ecosystem partners [65]. While creating new business opportunities the dynamic digital marketplace creates new challenges as well. Many new digital solutions and services are based on combining data from different sources, i.e., from different stakeholders. The knowledge and capabilities of different stakeholders are combined to deliver a specific offering or solution. This can create a challenging business landscape where the perspective on specific assets and complementary assets may be viewed differently by different stakeholders, especially between platform providers and linked service providers [64]. This can bring about risk, especially to the linked parties of the digital ecosystem around the platform. On the one hand, the platform provider may be enticed to integrate successful solutions provided by the linked parties into its offering. On the other hand, the platform operator may stop providing required data sources to the linked parties, thus destroying their digital business model. Naturally, the platform provider has to consider the risk these kinds of actions can cause to its business reputation [64]. Another challenge posed by the digital integration of businesses is the inclusion of the smaller actors in the value chains and business ecosystems, especially consid-ering their digitalization skills and competencies [66]. SMEs are often an important part of a value chain in the manufacturing sector. Thus, to take full advantage of the DTI their integration is essential. Lack of resources and limited competencies are generic barriers for SMEs to implement new technologies. On the one hand, these barriers can be overcome by introducing scalable technology solutions thatAdvancing Networked Production Through Decentralised Technical Intelligence 295are easier to be deployed by SMEs [66]. On the other hand, new services and service providers can be established to support the SMEs in digitalization, from understanding the systemic change it brings to their business to running specific technology services for them [67]. 6 Discussion This article discusses the use of Decentralised Technical Intelligence (DTI) to improve networked production. While the primary focus is on the network, the transition is built on a multilevel perspective that spans from technical processes on the factory floor to networking and business operations at the upper level. This requires the integration of various micro and macro levels in real-time through both company internal and external networks of information and communication technologies, necessitating international standards. Consequently, it is essential to develop and integrate a multilevel architecture for control and management, which includes implementing decentralised intelligence through edge-cloud solutions. This integration allows for the effective combination of physical levels with ICT control structures. This development implies that organisations involved in the networked produc-tion will integrate more and their roles may transform into functional specialisation or strategic competencies within the network. This integration leads to a synergistic effect among collaborating companies, resulting in significant efficiency gains and cost savings across different categories of costs. Achieving advanced networked production through DTI requires following the described roadmap and implement-ing the building blocks of DTI in a way that is transparent, trustworthy, cooperative, sustainable, and intelligent. The figure (Fig. 3) presented in this article illustrates the approach\u2019s goal to surpass the current fragmented approaches that mainly involve incremental Fig. 3 Progress towards advanced networked production based on DTI (adapted from ManuFuture [24] and Sautter [22])296 S. Walter and M. Mikkolaimprovements. Despite witnessing progress within the different levels of the produc-tion system and the interconnections between these levels, disciplinary boundaries often limit us. With DTI, we can surpass these limitations by enabling autonomous activities of DTI agents, which include both humans and machines. This can lead to various benefits such as self-organisation, self-optimisation, and self-maintenance. All of these actions occur within a predefined performance space, with a focus on situational and contextual requirements. Moreover, leveraging DTI technologies enables a shift away from strict hier-archies towards more flexible and adaptive operational management. With DTI, employees are empowered to make decisions based on their expertise and the real-time information provided by AI systems. This empowerment allows for quicker response times, as employees can take immediate action and adapt to unforeseen events without waiting for approval from higher levels of management. Thus, DTI involves converging towards heterarchy, which refers to a non-hierarchical organisational structure where decision-making authority and control are distributed among various nodes or agents rather than being concentrated at the top of a hierarchical chain. Heterarchies emphasize collaboration, decentralised decision-making and empowered employees [68]. As a result, DTI facilitates a systemic and transcending approach that dis-solves the boundaries of organisations and disciplines, allowing for a fundamental transition in production. DTI catalyses leapfrogging performance, as Sautter [22] describes it. DTI also provides a novel understanding of process quality, flexibility, and resilience, enabling the production system to adapt to changing situations. From a business implementation perspective, it is essential to develop incentive systems that support the collaboration of the different stakeholders in the network. Each actor should have a clear business value proposition to engage in the activities DTI entails, i.e., collaboration, commitment to common goals, and sharing of knowledge and information. This may require, e.g., further development of pricing methods and mechanisms for knowledge and data. 7 Conclusion DTI has wide-ranging implications for long-term development in industrial pro-duction. The concept has the potential to alter operative management and enhance flexibility, adaptability, robustness, and resilience in production networks. Understanding the benefits will coincide with a surge in strategic management efforts, research, development and deployment of technologies, which provide an underpinning to the decentralisation of intelligence and agents\u2019 actions and responses. DTI is an overarching visionary concept for the future of manufacturing. Implementing it is a long-term process that requires a mindset change from all the actors in manufacturing ecosystems. Changing all at once is not viable,Advancing Networked Production Through Decentralised Technical Intelligence 297instead, incremental development steps in collaboration with relevant actors in the manufacturing networks should be taken. The roadmap serves as a guiding framework that reflects the need for incremental development in the implementation of DTI and emphasises the importance of taking progressive steps forward while allowing for continuous refinement and adjustment. Stakeholders can align their efforts towards realising the long-term vision of enhanced flexibility, adaptability, robustness and resilience in production networks. This will position them at the forefront of the future of manufacturing. Acknowledgments The research leading to these results has received funding from Horizon 2020, the European Union\u2019s Framework Programme for Research and Innovation (H2020/2014-2020) under grant agreement no. 957331 (www.knowlEdge-project.eu). References 1. Bowersox, D.J., Closs, D.J., Cooper, M.B., Bowersox, J.C.: Supply Chain Logistics Manage-ment, 4th edn. McGraw-Hill, New York, NY, USA (2016) 2. Christopher, M.: Logistics and Supply Chain Management: Strategies for Reducing Cost and Improving Service, 2nd edn. Prentice-Hall, Harlow, UK (1998) 3. Porter, M.E.: Competitive Advantage. Free Press, New York (1985) 4. Werner, H.: Supply Chain Management: Grundlagen, Strategien, Instrumente und Controlling, 7th edn. SpringerGabler, Wiesbaden (2020) 5. Ketchen Jr. D.J., Hult, G.T.M.: Bridging organization theory and supply chain management: The case of best value supply chains. J. Oper. Manag. 25, 573\u2013580 (2007) 6. Lii, P., Kuo, F.I.: Innovation-oriented supply chain integration for combined competitiveness and firm performance. Int. J. Prod. Econ. 60, 142\u2013155 (2016) 7. McDougall, N., Wagner, B., MacBryde, J.: Leveraging competitiveness from sustainable operations: frameworks to understand the dynamic capabilities needed to realise NRBV supply chain strategies. Supply Chain Manag. 27, 12\u201329 (2022) 8. Sakuramoto, C., Di Serio, L.C., de Vicente Bittar, A.: Impact of supply chain on the competitiveness of the automotive industry. RAUSP Manag. J. 54, 205\u2013225 (2019) 9. Maozhu, J., Wang, H., Zhang, Q., Zeng, Y.: Supply chain optimization based on chain management and mass customization. Inf. Syst. e-Bus. Manag. 18, 647\u2013664 (2020) 10. Tukamuhabwa, B.R., Stevenson, M., Busby, J., Zorzini, M.: Supply chain resilience: definition, review and theoretical foundations for further study. Int. J. Prod. Res. 53(18), 5592\u20135623 (2015) 11. Christopher, M., Holweg, M.: Supply chain 2.0: managing supply chains in the era of turbulence. Int. J. Phys. Distrib. 41(1), 63\u201382 (2011) 12. Al-Omoush, K.S., de Lucas, A., del Val, M.T.: The role of e-supply chain collaboration in collaborative innovation and value-co creation. J. Bus. Res. 158, 113647 (2023) 13. K\u00e4hk\u00e4nen, A.-K., Lintukangas, K.: The underlying potential of supply management in value creation. J. Purchas. Supply Manag. 18(2), 68\u201375 (2012). Vision 20/20: Preparing Today for Tomorrow\u2019s Challenges 14. Jovane, F., Westk\u00e4per, E., Williams, D.: The ManuFuture Road. Towards Competitive and Sustainable High-Adding-Value Manufacturing. Springer, Berlin (2009) 15. Bak, O.: Understanding the stimuli, scope, and impact of organizational transformation: The context of eBusiness technologies in supply chains. Strateg. Change 30, 443\u2013452 (2021) 16. Zhang, J., Xu, J., Liu, Y.: Complex adaptive supply chain network: The state of the art. In: 2009 Chinese Control and Decision Conference, pp. 5643\u20135647 (2009)298 S. Walter and M. Mikkola17. Walter, S.: AI impacts on the performance in supply chains. In: The 34th Annual NOFOMA Conference June 8\u201310, 2022 - Reykjav\u00edk, Iceland, pp. 1\u201314. The Nordic Logistics Research Network (NOFOMA) (2022) 18. Sendhil Kumar, R., Pugazhendhi, S.: Information sharing in supply chains: An overview. Procedia Eng. 38, 2147\u20132154 (2012) 19. Ahmad, I., Rodriguez, F., Kumar, T., Suomalainen, J., Kumar, S., Walter, S., Asghar, M.Z., Li, G., Papakonstantinou, N., Ylianttila, M., Huusko, J., Sauter, T., Harjula, E.: Communications security in Industry X: A survey. TechRxiv. Preprint (2023) 20. Baesens, B., Bapna, R., Marsden, J.R., Vanthienen, J., Leon Zhao, J.: Transformational issues of big data and analytics in networked business. MIS Q. 40(4), 807\u2013818 (2016) 21. Surana, A., Kumara, S., Greaves, M., Raghavan, U.N.: Supply-chain networks: a complex adaptive systems perspective. Int. J. Prod. Res. 43(20), 4235\u20134265 (2005) 22. Sautter, B. (ed.): Decentralised Technical Intelligence (DTI) for increased manufacturing performance. Going beyond the limits of today in an interdisciplinary approach. White paper. Version 1.0. ManuFUTURE, Brussels (2022) 23. Jarrahi, M.H.: Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. Bus. Horizons 61(4), 577\u2013586 (2018) 24. ManuFUTURE High-level Group: ManuFUTURE Strategic Research Agenda SRIA 2030. For a competitive, sustainable and resilient European manufacturing. ManuFUTURE, Brussels (2019) 25. Plattform Industrie 4.0: 2030 Vision for Industrie 4.0. Shaping Digital Ecosystems Globally. Federal Ministry for Economic Affairs and Energy (BMWi), Berlin (2019) 26. Lin, Z., Xiangli, P., Li, Z., Liang, F., Li, A.: Towards metaverse manufacturing: A blockchain-based trusted collaborative governance system. In: The 2022 4th International Conference on Blockchain Technology, ICBCT\u201922, pp. 171\u2013177, New York, NY, USA, 2022. Association for Computing Machinery 27. Siahaan, B.P., Simatupang, T.M., Okdinawati, L.: Logistics landscape for metaverse. In: 2022 IEEE International Conference of Computer Science and Information Technology (ICOSNIKOM), pp. 1\u20136 (2022) 28. Thomas, D.J., Griffin, P.M.: Coordinated supply chain management. Eur. J. Oper. Res. 94(1), 1\u201315 (1996) 29. Chandra, C., Kumar, S.: Supply chain management in theory and practice: a passing fad or a fundamental change? Ind. Manag. Data Syst. 100(3), 100\u2013114 (2000) 30. Leit\u00e3o, P.: Agent-based distributed manufacturing control: A state-of-the-art survey. Eng. Appl. Artif. Intell. 22(7), 979\u2013991 (2009). Distributed Control of Production Systems 31. Almeida, R., Toscano, C., Lopes Azevedo, A., Maia Carneiro, L.: A Collaborative Planning Approach for Non-hierarchical Production Networks, chapter 9, pp. 185\u2013204. Wiley (2012) 32. Shen, W., Wang, L., Hao, Q.: Agent-based distributed manufacturing process planning and scheduling: a state-of-the-art survey. IEEE Trans. Syst. Man Cybern. C (Appl. Rev.) 36(4), 563\u2013577 (2006) 33. Straube, F., Beyer, I.: Decentralized planning in supply networks. In: 2006 IEEE International Technology Management Conference (ICE), pp. 1\u20138 (2006) 34. Andr\u00e9s, B., Poler, R., Hern\u00e1ndez, J.E.: An operational planning solution for SMEs in collaborative and non-hierarchical networks. In: Hern\u00e1ndez, J.E., Liu, S., Deliba\u0161ic\u0301, B., Zarat\u00e9, P., Dargam, F., Ribeiro, R. (eds.), Decision Support Systems II - Recent Developments Applied to DSS Network Environments, pp. 46\u201356, Berlin, Heidelberg, 2013. Springer, Berlin, Heidelberg (2013) 35. Bousdekis, A., Mentzas, G.: Enterprise integration and interoperability for big data-driven processes in the frame of industry 4.0. Front. Big Data 4 (2021) 36. Marques, M., Agostinho, C., Zacharewicz, G., Jardim-Gon\u00e7alves, R.: Decentralized decision support for intelligent manufacturing in industry 4.0. J. Ambient Intell. Smart Environ. 9(3), 299\u2013313 (2017)Advancing Networked Production Through Decentralised Technical Intelligence 29937. Fortino, G., Savaglio, C., Palau, C.E. de Puga, J.S., Ganzha, M., Paprzycki, M., Montesinos, M., Liotta, A., Llop, M.: Towards Multi-layer Interoperability of Heterogeneous IoT Platforms: The INTER-IoT Approach, pp. 199\u2013232. Springer International Publishing, Cham (2018) 38. Stadtler, H.: Supply chain management and advanced planning\u2014basics, overview and challenges. Eur. J. Oper. Res. 163(3), 575\u2013588 (2005). Supply Chain Management and Advanced Planning 39. Stavrulaki, E., Davis, M.: Aligning products with supply chain processes and strategy. Int. J. Logist. Manag. 21(1), 127\u2013151 (2010) 40. Amrani, A., Zouggar, S., Zolghadri, M., Girard, P.: Towards a collaborative approach to sustain engineer-to-order manufacturing. In: 2010 IEEE International Technology Management Conference (ICE), pp. 1\u20138 (2010) 41. Ayel, J.: Decision coordination in production management. In: Castelfranchi, C., Werner, E. (eds.), Artificial Social Systems, pp. 295\u2013310, Berlin, Heidelberg, 1994. Springer, Berlin, Heidelberg (1994) 42. Chandra, C., Kumar, S.: Enterprise architectural framework for supply-chain integration. Ind. Manag. Data Syst. 101(6), 290\u2013304 (2001) 43. Zou, X., Pokharel*, S., Piplani, R.: Channel coordination in an assembly system facing uncertain demand with synchronized processing time and delivery quantity. Int. J. Prod. Res. 42(22), 4673\u20134689 (2004) 44. Chankov, S.M., Becker, T., Windt, K.: Towards definition of synchronization in logistics systems. Procedia CIRP 17, 594\u2013599 (2014). Variety Management in Manufacturing 45. Alvarez-Napagao, S., Ashmore, B., Barroso, M., Barru\u00e9, C., Beecks, C., Berns, F., Bosi, I., Chala, S.A., Ciulli, N., Garcia-Gasulla, M., Grass, A., Ioannidis, D., Jakubiak, N., K\u00f6pke, K., L\u00e4ms\u00e4, V., Megias, P., Nizamis, A., Pastrone, C., Rossini, R., S\u00e0nchez-Marr\u00e8, M., Ziliotti, L.: knowledge project\u2013concept, methodology and innovations for artificial intelligence in industry 4.0. In: 2021 IEEE 19th International Conference on Industrial Informatics (INDIN), pp. 1\u20137 (2021) 46. Camarinha-Matos, L.M., Afsarmanesh, H.: Collaborative networks. In: Wang, K., Kovacs, G.L., Wozny, M., Fang, M. (eds.), Knowledge Enterprise: Intelligent Strategies in Product Design, Manufacturing, and Management, pp. 26\u201340, Boston, MA, 2006. Springer US (2006) 47. Camarinha-Matos, L.M., Afsarmanesh, H., Galeano, N., Molina, A.: Collaborative networked organizations \u2013 concepts and practice in manufacturing enterprises. Comput. Ind. Eng. 57(1), 46\u201360 (2009). Collaborative e-Work Networks in Industrial Engineering 48. Romero, D., Molina, A.: Collaborative networked organisations and customer communities: value co-creation and co-innovation in the networking era. Prod. Plann. Control 22(5\u20136), 447\u2013 472 (2011) 49. Brax, S.: A manufacturer becoming service provider \u2013 challenges and a paradox. Manag. Serv. Q. 15(2), 142\u2013155 (2005) 50. Cohen, M.A., Agrawal, N., Agrawal, V.: Winning in the aftermarket. Harv. Bus. Rev. (2006) 51. Isaksson, O., Larsson, T.C., R\u00f6nnb\u00e4ck, A.\u00d6.: Development of product-service systems: challenges and opportunities for the manufacturing firm. J. Eng. Des. 20(4), 329\u2013348 (2009) 52. Gao, J., Yao, Y., Zhu, V.C.Y., Sun, L., Lin, L.: Service-oriented manufacturing: a new product pattern and manufacturing paradigm. J. Intell. Manuf. 22, 435\u2013446 (2011) 53. Fisher, O., Watson, N., Porcu, L., Bacon, D., Rigley, M., Gomes, R.L.: Cloud manufacturing as a sustainable process manufacturing route. J. Manuf. Syst. 47, 53\u201368 (2018) 54. Wahlstr\u00f6m, M., Walter, S., Salonen, T-T., Lammi, H., Heikkil\u00e4, E., Helaakoski, H.: Sustainable Industry X \u2013 a Cognitive Manufacturing Vision. VTT Technical Research Centre of Finland, Espoo (2020) 55. Bray, O.H., Garcia, M.L.: Technology roadmapping: the integration of strategic and technology planning for competitiveness. In: Innovation in Technology Management. The Key to Global Leadership. PICMET \u201997, pp. 25\u201328 (1997) 56. Phaal, R., Farrukh, C.J.P., Probert, D.R.: Technology roadmapping\u2014a planning framework for evolution and revolution. Technol. Forecast. Soc. Change 71(1), 5\u201326 (2004). Roadmapping: From Sustainable to Disruptive Technologies300 S. Walter and M. Mikkola57. Shih, S.C., Hsu, S.H.Y., Zhu, Z., Balasubramanian, S.K.: Knowledge sharing\u2013a key role in the downstream supply chain. Inf. Manag. 49(2), 70\u201380 (2012) 58. Barreto, L., Amaral, A., Pereira, T.: Industry 4.0 implications in logistics: an overview. Procedia Manuf. 13, 1245\u20131252 (2017). Manufacturing Engineering Society International Conference 2017, MESIC 2017, 28\u201330 June 2017, Vigo (Pontevedra), Spain 59. Min, S., Zacharia, Z.G., Smith, C.D.: Defining supply chain management: In the past, present, and future. J. Bus. Logist. 40(1), 44\u201355 (2019) 60. Varela, L., Putnik, G., Romero, F.: The concept of collaborative engineering: a systematic literature review. Prod. Manuf. Res. 10(1), 784\u2013839 (2022) 61. Jones, A.T., Romero, D., Wuest, T.: Modeling agents as joint cognitive systems in smart manufacturing systems. Manuf. Lett. 17, 6\u20138 (2018) 62. Deshmukh, R.A., Jayakody, D., Schneider, A., Damjanovic-Behrendt, V.: Data spine: A federated interoperability enabler for heterogeneous iot platform ecosystems. Sensors 21(12), (2021) 63. Monostori, L., K\u00e1d\u00e1r, B., Bauernhansl, T., Kondoh, S., Kumara, S.R.T., Reinhart, G., Sauer, O., Schuh, G., Sihn, W., Ueda, K.: Cyber-physical systems in manufacturing. Cirp Ann. Manuf. Technol. 65, 621\u2013641 (2016) 64. Paredes-Frigolett, H., Pyka, A.: The global stakeholder capitalism model of digital platforms and its implications for strategy and innovation from a Schumpeterian perspective. J. Evolut. Econ. 32, 463\u2013500 (2022) 65. Teece, D.J., Linden, G.: Business models, value capture, and the digital enterprise. J. Organiz. Des. 6, 1\u201314, 2017 66. Ghobakhloo, M., Iranmanesh, M., Vilkas, M., Grybauskas, A., Amran, A.: Drivers and barriers of industry 4.0 technology adoption among manufacturing SMEs: a systematic review and transformation roadmap. J. Manuf. Technol. Manag. (2022) 67. Mikkola, M., Salonen, J.: Manufacturing SME\u2019s are not worried about novel technology, but people. In: ISPIM Connects Athens Conference: The Role of innovation: Past, Present, Future. Lappeenranta University of Technology (2022) 68. Filip, F.G., Zamfirescu, C.-B., Ciurea, C.: Computer-Supported Collaborative Decision-Making. Springer International Publishing, Cham (2017) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Part III Trusted, Explainable and Human-Centered AI SystemsWearable Sensor-Based Human Activity Recognition for Worker Safety in Manufacturing Line Sungho Suh, Vitor Fortes Rey, and Paul Lukowicz 1 Introduction The advent of Industry 4.0, introduced in 2011, aimed to revolutionize manufac-turing by incorporating advanced technologies to achieve operational efficiency and productivity gains [24]. However, as the focus shifted from technology-driven advancements to a more human-centric approach, the concept of Operator 4.0 emerged. Operator 4.0 envisions a workforce assisted by systems that alleviate physical and mental stress while maintaining production objectives [14]. This shift in perspective laid the foundation for the development of Industry 5.0, a value-driven manufacturing paradigm that places worker well-being at the forefront of the production process [30]. Industry 5.0 encompasses two main visions: one involving human\u2013robot collab-oration and the other centered around a bioeconomy utilizing renewable biological resources. As the researchers explore the potential of Industry 5.0, it becomes crucial to investigate how technology can support the industry while prioritizing worker safety and productivity. This necessitates meeting the human needs outlined in the Industrial Human Needs Pyramid, ranging from workplace safety to the fulfillment of human potential through a trustworthy relationship between humans and machines. In this context, wearable sensor-based human activity recognition (HAR) emerges as a vital component of Industry 5.0. By continuously and unobtrusively monitoring workers\u2019 activities, wearable sensors enable a synergistic collaboration between humans and machines [23, 29]. This collaboration enhances productivity S. Suh (\u0002) \u00b7 V. F. Rey \u00b7 P. Lukowicz  German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany e-mail: sungho.suh@dfki.de; vitor.fortes_rey@dfki.de; paul.lukowicz@dfki.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_17303304 S. Suh et al.while empowering workers to unleash critical thinking, creativity, and domain knowledge. Simultaneously, machines autonomously assist with repetitive tasks, reducing waste and costs. To foster the development of trustworthy coevolutionary relationships between humans and machines, interfaces must consider the unique characteristics of employees and organizational goals. An example of such collaboration is evident in the use of cobots, where machines share physical space, perceive human presence, and perform tasks independently, simultaneously, sequentially, or in a supportive manner [8]. Within this framework, this book chapter focuses on the crucial intersection of wearable sensor-based HAR and Industry 5.0. Especially, we explore the transformative role of sensor-based HAR in promoting worker safety and optimizing productivity in manufacturing environments. We aim to study the intricacies of wearable sensor technologies, sensor data fusion techniques, and advanced machine learning algorithms to effectively capture and interpret workers\u2019 activities in real time. By utilizing wearable sensors, manufacturers can gain real-time insights into the physical movements and behaviors of workers, enabling them to identify poten-tial safety hazards, proactively intervene in hazardous situations, and implement preventive measures. Moreover, the applications of sensor-based HAR extend beyond worker safety. The data collected from wearable sensors can facilitate the optimization of man-ufacturing processes by identifying bottlenecks, streamlining workflows, and min-imizing errors [29]. By analyzing workers\u2019 activities, manufacturers can uncover insights into the ergonomics of workstations, leading to improvements in the job design and a reduction in musculoskeletal disorders. Furthermore, the knowledge derived from sensor-based HAR can inform training programs, enabling targeted interventions and skill development to enhance worker efficiency and job satisfac-tion. Likewise, the integration of HAR using wearable sensors in manufacturing environments aligns with the growing interest in smart manufacturing and Industry 4.0 [23, 29]. In the manufacturing line, HAR can be utilized to quantify and evaluate worker performance [28], understand workers\u2019 operational behavior [1], and support workers\u2019 operations with industrial robots [22]. Activity recognition for worker safety in the manufacturing line is becoming increasingly important, as it provides the ability to quickly identify workers\u2019 needs for assistance or prevent industrial accidents. In this book chapter, we study the intricacies of wearable sensor technologies and their integration into manufacturing environments. We explore various sensor modalities, including inertial sensors, motion sensors, and body capacitance sensors, and discuss their relevance in capturing a comprehensive view of workers\u2019 activities. We also examine sensor data fusion techniques to effectively integrate and interpret data from multiple wearable devices, enabling a holistic understanding of workers\u2019 actions. The outcomes of this research shed light on the transformative capabilities of wearable sensor technologies and open new avenues for future research in this field, aligning with the principles of the Industry 5.0 paradigm.Wearable Sensor-Based Human Activity Recognition 305To demonstrate the practical application of sensor-based worker activity recogni-tion, we present a use case in a smart factory testbed. In this use case, we deploy and test HAR using wearable sensors to predict workers\u2019 movement intentions and plan optimal routes for mobile robots in a collaborative environment. By anticipating workers\u2019 actions, collision risks between workers and robots can be minimized, ensuring both high production levels and worker safety. To further improve the performance of HAR, we explore deep learning tech-niques such as adversarial learning [26, 27] and contrastive learning [9, 12]. These approaches have shown promise in enhancing activity recognition by leveraging additional information and improving the generalization capabilities of the models. In addition to traditional wearable sensor modalities, we introduce the use of body capacitance sensing as an alternative modality for HAR. Body capacitance sensing captures the electric field feature between the body and the environment, providing unique insights into body movement and environmental variations [6]. By combining body capacitance sensing with inertial measurement unit (IMU)-based activity recognition, we aim to extend the sensing capabilities and improve the accuracy of activity recognition systems. Throughout this chapter, we showcase real-world applications of sensor-based worker activity recognition in manufacturing environments. From real-time moni-toring of workers\u2019 movements to detecting unsafe actions and alerting workers and supervisors, the potential benefits are substantial. We also discuss the limitations and potential ethical considerations associated with wearable sensor systems, emphasizing the importance of privacy, data security, and worker consent. In the following sections, we provide a comprehensive review of related works in Sect. 2. Section 3 presents the wearable sensor-based worker activity recognition in a manufacturing line with IMU sensors and body capacitance sensing module, including data fusion approaches and a use case in a smart factory testbed. Section 4 introduces deep learning techniques for improving the performance of human activity recognition, such as adversarial learning and contrastive learning. Finally, Sect. 5 concludes this book chapter. 2 Background The Internet of Things (IoT) has revolutionized various industries, including manufacturing, by enabling the integration of physical devices and digital systems. In the context of smart factories, IoT technologies play a crucial role in creating intelligent and automated production environments. With the advancement of sensing technologies, it has become increasingly feasible to recognize human activities using various sensors such as IMU sensors [26], microphones [5], cameras [20], and magnetic sensors [19]. These sensors capture valuable data about human movements, interactions, and environmental factors, which can be utilized to enhance productivity, safety, and efficiency in smart factory environments.306 S. Suh et al.Supervised machine learning techniques have been widely used for recognizing activities using labeled training data. However, collecting labeled data can be time-consuming and labor-intensive. To overcome this challenge, researchers have explored methods that reduce the effort required for data collection. Among the popular approaches are transfer learning, activity modeling, and clustering techniques. These methods leverage existing knowledge or unsupervised learning to recognize activities with minimal labeled data. The concept of smart manufacturing, often associated with Industry 4.0, has gained significant attention in recent years [21]. Researchers have focused on recognizing and supporting factory work using sensor technologies [2, 3]. In the manufacturing domain, the use of sensors for activity recognition has been extensively explored. For example, Koskimaki et al. [15] utilized a wrist-worn IMU sensor and a K-Nearest Neighbors model to classify activities in industrial assembly lines. Maekawa et al. [17] proposed an unsupervised method for lead time estima-tion of factory work using signals from a smartwatch with an IMU sensor. These studies demonstrate the potential of sensors in recognizing worker activities in manufacturing environments, particularly with the application of machine learning techniques. Sensor-based HAR is a crucial aspect of wearable technology. The IMU has been the dominant sensor in wearable devices, providing motion-sensing capabilities. However, the IMU\u2019s ability is limited to capturing the wearer\u2019s movement patterns and does not account for body\u2013environment and body\u2013machine interactions, which play critical roles in security and safety in manufacturing environments. To extend the motion-sensing ability of wearables, the researchers have explored alternative sensing sources, such as the body capacitance [6]. The body capacitance describes the electric field between the body and the environment, and variations in this field can provide valuable information for pattern recognition. For example, capacitive sensing has been used to detect touch patterns between human fingers and different objects. This alternative sensing approach benefits from low cost and low power consumption and extends the sensing ability beyond IMU-based activity recogni-tion. Machine learning models play a crucial role in wearable activity recognition, enabling the extraction of meaningful patterns and features from sensor data [13]. Classical machine learning methods extract handcrafted features from sensor data, such as time-domain and frequency-domain features [16]. These methods rely on expert knowledge and domain-specific feature engineering. In recent years, deep learning-based methods have gained significant attention in activity recognition [18]. Convolutional neural networks (CNNs), recurrent neural networks (RNNs), and hybrid models have been developed to capture temporal correlations and learn sensor representations for improved activity recognition accuracy. Additionally, multitask learning and generative adversarial learning have been introduced to address different data distribution problems and enhance recognition performance [4, 7]. These advancements in machine learning techniques have paved the way for more accurate and robust activity recognition in wearable devices.Wearable Sensor-Based Human Activity Recognition 307To bridge the gap between wearable sensor-based HAR and the principles of Industry 5.0, this book chapter offers unique contributions and addresses existing research gaps. It presents a comprehensive case study on wearable sensor-based worker activity recognition in a manufacturing line with a mobile robot. The investigation includes the exploration and comparison of sensor data fusion approaches using neural network models to effectively handle the multimodal sensor data obtained from wearable devices. Additionally, several deep learning-based techniques are introduced to enhance the performance of human activity recognition. By harnessing the potential of wearable sensors for human activity recognition, this chapter provides valuable insights into improving worker safety on the manufacturing line, aligning with the principles of the Industry 5.0 paradigm. The outcomes of this research shed light on the transformative capabilities of wearable sensor technologies and open new avenues for future research in this field. 3 Wearable Sensor-Based Worker Activity Recognition in Manufacturing Line 3.1 Use Case at the SmartFactory Testbed The SmartFactory Testbed, developed by the Technology Initiative SmartFactory KL, is a collaborative effort between the Department of Machine Tools and Controls (WSKL) at the TU Kaiserslautern and the Innovative Factory Systems (IFS) research unit at the German Research Center for Artificial Intelligence (DFKI). This non-profit organization focuses on advancing manufacturing technologies with industry specialists known as factory innovators. The SmartFactory Testbed offers unique manufacturer-independent demonstra-tions that enable the development, testing, and deployment of innovative ICT technologies in a realistic industrial production environment. It serves as a vital test environment, particularly for the European GAIA-X subproject SmartMA-X, where flexible production systems can be arranged and integrated in highly customized configurations, enhancing the dynamism of the industrial environment. In this chapter, we utilize the SmartFactory Testbed as a real-world deployment setting to evaluate and validate the Human Action Recognition module within a specific use case referred to as \u201cHuman Action Recognition and Prediction in the Respective Environment.\u201d The use case focuses on a worker\u2019s activity pipeline, including their presence in the pilot area and collaboration with different modules and robots across 20 diverse activities. The accurate prediction of human actions within the production lines is crucial, especially when workers interact with moving robots or when robots generate paths to avoid potential collisions in the layout. By leveraging information about the worker\u2019s location and their next anticipated action, the robot\u2019s movement path can be manipulated to minimize the risk of collisions. This proactive approach ensures the safety and reliability of the industrial environment, particularly when humans are present.308 S. Suh et al.3.2 Data Acquisition In this chapter, we conducted an experiment involving 12 volunteers, from diverse cultural backgrounds and genders, who wore a wearable sensing prototype that we designed, as well as an Apple Watch, currently the top-selling smartwatch [10], while performing various tasks that simulated typical worker scenarios during their daily work. These tasks included opening and closing doors, walking, checking parts inside a module, and interacting with a touch screen. To ensure robust results, the experiment consisted of five sessions, each lasting between 2 and 3 minutes. Some sessions were conducted and recorded in a different direction from the flow chart. Prior to participation, all volunteers signed an agreement in compliance with the university\u2019s committee for the protection of human subjects policies. The experiment was video recorded to enable further confidential analysis, including ground truth activity annotation. Both the observer and the participants adhered to an ethical and hygienic protocol in accordance with public health guidelines. Figure 1 illustrates the wearable sensors attached to the participants. The prototype sensors were placed on both wrists while the Apple Watches were attached to both wrists, and an iPhone mini was attached to the left arm. The Fig. 1 The wearable sensors attached to the participants. (a) The wearable sensing prototype we designed on both wrists and (b) Apple Watches on both wrists and the iPhone mini on the left armWearable Sensor-Based Human Activity Recognition 309Table 1 Comparison of the data distribution of activities in the prototype sensor and Apple Watch datasets Prototype Apple # of Subjects 12 12 # of Session 5 5 # of Channels per device 10 9 # of Devices 2 3 Sampling frequency 25 Hz 100 Hz Activity Null 14 m 9 s (9.9%) 29 m 43 s (17.5%) Pressing button 2 m 24 s (1.7%) 1 m 54 s (1.1%) Sliding doorlock 1 m 58 s (1.4%) 1 m 21 s (0.8%) Opening door 8 m 53 s (6.2%) 10 m 53 s (6.4%) Closing door 12 m 3 s (8.5%) 14 m 52 s (8.7%) Checking machines 47 m 6 s (33.1%) 48 m 53 s (28.7%) Walking 19 m 13 s (13.5%) 32 m 23 s (19.0%) Taking key 4 m 20 s (3.0%) 2 m 21 s (1.4%) Rotating key 10 m 14 s (7.2%) 6 m 47 s (4.0%) Placing key back 6 m 26 s (4.5%) 6 m 16 s (3.7%) Checking door lock 2 m 54 s (2.0%) 0 m 29 s (0.3%) Touching screen 12 m 44 s (8.9%) 14 m 11 s (8.3%) Total 142 m 24 s 170 m 3 s collected data from the wearable sensing prototype consisted of 10 channels per sensor, resulting in a total of 20 channels, including three channels of acceleration, three channels of gyroscope, three channels of magnetometer data, and one channel of body capacitance data. The data collected using the Apple Watch and iPhone mini comprised 9 channels per sensor, totaling 27 channels, including 3 channels of acceleration, 3 channels of gyroscope, and 3 channels of magnetometer data. To synchronize the recorded video data, left wrist sensor data, and right wrist sensor data, we performed five claps at the start and end of each session. Based on the video data, we manually annotated the users\u2019 activities, resulting in 12 different activities, including a Null class. The prototype sensors provided IMU sensor data and body capacitance data with a sampling rate of 25 Hz, while the Apple Watch only provided IMU sensor data with a sampling rate of 100 Hz. This experiment allowed us to assess the performance of the sensor hardware and collect a dataset suitable for developing and testing algorithms for human intention recognition. Table 1 presents the data distribution of activities in the prototype sensor and Apple Watch datasets. The prototype sensor dataset involved data collection for a total duration of 142 minutes and 24 seconds, while the Apple Watch dataset had a total duration of 170 minutes and 3 seconds. To focus on preventing collisions between workers and mobile robots, we decided to collect additional sensor data from the Apple Watches for the walking class after collecting data from the prototype sensor. As a result, the Apple Watch dataset had a higher proportion of walking class data compared to the prototype sensor dataset.310 S. Suh et al.Table 2 Comparison results between Apple Watches and the prototype sensing module combin-ing IMU and body capacitance sensors in terms of the testing accuracy and macro F1 score. The numbers are expressed in percent and represented as . mean \u00b1 stdMethod Accuracy Macro F1 Walking accuracy Apple Watch 67.94 . \u00b1 2.55 43.02 . \u00b1 2.49 69.96 . \u00b1 4.39 The prototype sensing module 69.76 . \u00b1 3.09 52.40 . \u00b1 2.32 75.88 . \u00b1 2.55 To evaluate the prototype sensor hardware and neural network models for worker activity recognition, we annotated the user\u2019s activities based on the workflow of the use case at the SmartFactory Testbed. The workflow classified the sensor data into 12 activities, including Null, opening/closing doors, checking machines, walking, pressing buttons, and placing back keys. In our application, each instance is a sliding window of sensor data. For the Apple Watch data, we used a window of length 100 (1 second) and a step size of 4 (0.04 seconds). For the prototype sensor data, we employed a window of length 25 (1 second) and a step size of 1 (0.04 seconds). That is, in both cases, we use data from 1 second, with a step size of 0.04 seconds, which maximizes the number of windows while keeping the step size suitable in both sensor scenarios. 3.3 Worker Activity Recognition Results To process the collected sensor data, we used neural networks based on convo-lutional neural networks (CNNs) [25]. For training and validation of the neural network models, we employed a leave-one-session-out scheme. In each fold, one session was allocated for testing, another for validation, and the remaining three sessions for training. Table 2 presents the comparison results between Apple Watches and the proto-type sensing module, which combined IMU and body capacitance sensors, for the worker\u2019s activity recognition at the smart factory testbed. The evaluation metrics used include accuracy, macro F1 score [26], and the accuracy of the walking class, which is critical for preventing potential collisions between workers and mobile robots. The results demonstrate that the prototype-sensing module outperformed the Apple Watch in terms of accuracy, macro F1 score, and walking class accuracy. 4 Deep Learning Techniques for Human Activity Recognition Improvement In this section, we focus on exploring advanced deep learning techniques to improve the performance of worker activity recognition in the manufacturing line for worker safety, building upon the findings presented in the previous section. Two specificWearable Sensor-Based Human Activity Recognition 3112/3 1/3 Test users Training users Gap Training Dataset Test Dataset Low recognition accuracy!! Fig. 2 Challenges in activity recognition: accounting for diverse behavior patterns across individ-uals techniques, namely adversarial learning and contrastive learning, are discussed in detail. These techniques offer innovative approaches to improve the accuracy and robustness of the recognition system, addressing the challenges associated with complex and dynamic industrial environments [9, 27]. 4.1 Adversarial Learning Despite the successful digitalization of worker activities through wearable sensors and their recognition by simple CNN models, achieving generalization to unseen workers remains a significant challenge. Numerous studies have demonstrated that individuals perform the same activities in different ways, posing a challenge for activity recognition, despite the feasibility of user recognition [26], as illustrated in Fig. 2. This discrepancy becomes evident when evaluating performance by leaving out subjects rather than leaving out sessions. To deal with this problem, we present an adversarial learning-based method for user-invariant HAR in this subsection, as illustrated in Fig. 3. Inspired by generative adversarial networks (GANs) [11], adversarial learning has been introduced as a technique to enhance the model\u2019s ability to discriminate between different worker activities and improve generalization. This technique, described in [26] and [27], employs four independent networks: a feature extractor, a reconstructor, an activity classifier, and a subject discriminator. The feature extractor maps sensor data to a common embedding feature space, while the reconstructor reconstructs the original signal from the embedding features. The activity classifier predicts activity labels based on the embedding features, and the subject discriminator differentiates between subjects based on the embedding features. The feature extractor and subject discriminator are trained by adversarial learning, with the subject discriminator aiming to distinguish subjects and the feature extractor aiming to deceive the subject discriminator. The method also incorporates a reconstruction loss to minimize the312 S. Suh et al.Input (Person 1) Input (Person N) \u2026 Encoder (Feature Extractor) Decoder Feature (Person 1) Feature (Person N) \u2026 Reconstructed Signal (Person 1) Reconstructed Signal (Person N) \u2026 Activity Classifier Domain Discriminator MMD loss Activity Label Person Label Classification loss Domain loss Reconstruction loss Fig. 3 The overall framework of the user-invariant HAR method using adversarial learning difference between the original and reconstructed signals, along with a classification loss to train the feature extractor and activity classifier using activity labels. Additionally, the proposed method employs maximum mean discrepancy (MMD) regularization to align the distributions among source and target subjects, thereby enhancing the generalization of the embedding feature representation. The user-invariant HAR method has demonstrated improvements of up to 7% in accuracy and 28% in macro F1 score compared to the baseline using the CNN model [26]. By using this adversarial learning technique, we expect to improve worker activity recognition in the manufacturing line for worker safety. For further details on the methods and experiments, please refer to [26] and [27]. 4.2 Contrastive Learning We tackle a common challenge in wearable HAR, where sensor locations that are commonly used for everyday wear provide inadequate information for accurate activity recognition. For instance, in our manufacturing work scenario, we found that sensors placed on the wrist and arm are not optimal for recognizing activities like walking, which would be better detected with an IMU sensor placed on the leg. This is a well-known limitation in HAR, where sensors deployed for long-term everyday use often result in poor or noisy data for the intended application. To address this issue, we propose a method outlined in our work [9] that aims to improve the representation of the deployed sensors during training. The idea is to leverage additional sensors that are available only during the training phase to build a better representation of the target (deployed) sensor. This approach allows us to capture more relevant information about the activities being recognized, even if theWearable Sensor-Based Human Activity Recognition 313Source data Encoder Target data Translator Contrastive loss Contrastive loss i Fig. 4 Step 1: Training representations with paired sensor data by contrastive learning target sensor alone may not provide sufficient information, we can improve it by guiding its representation with through contrastive learning with the source sensor. In our proposed method, we collect temporally paired data from both the source and target sensors. The source sensor refers to a sensor that is available during training but not during deployment, while the target sensor is the sensor that will be deployed for activity recognition in real-world scenarios. Through contrastive learning, we learn a mapping between the representations of the source and target sensors. This process enables us to capture the relationship and similarities between the activities observed by the source and target sensors, enhancing the representation of the target sensor. The training of representations and the mapping between them are depicted in Fig. 4. Each sensor\u2019s data are processed separately through deep neural network encoders to obtain their respective representations. The translation between repre-sentations is facilitated by translation networks, which learn to transform the source sensor representation to align with the target sensor representation. This contrastive learning step can be performed using unlabeled data, where the network learns to align the representations based on the temporal correspondence between the sensors. Once the representations are learned, we proceed to the next step using labeled data from both sensors. In this step, we train our activity classifier using data either from the target sensor in its learned representation or from the source sensor by translating it to the target representation using the translation network. This joint training process allows the classifier to learn to recognize activities based on the enhanced representations from both sensors. The overall training process is illustrated in Fig. 5. For evaluation, we utilize only the target sensor data, as it represents the real-world deployment scenario. By applying the learned representations and the trained classifier to the target sensor data, we can more314 S. Suh et al.Classi er Encoder Source data Activity Label Translator Target data Classification loss Fig. 5 Step 2: Training representations and classifier by minimizing classification loss Target data Encoder Classifier Activity Label Fig. 6 Step 3: Testing with data of the target sensor only in order to evaluate the method accurately recognize and classify activities in practical settings. The evaluation process is illustrated in Fig. 6. We evaluated our method on two benchmark datasets for HAR: PAMAP2 and Opportunity. The results demonstrated significant improvements in activity recog-nition performance. We achieved an average macro F1 score increase ranging from 5 to 13 percentage points across all activities compared to traditional approaches that only rely on the target sensor. Notably, in specific scenarios where the source sensor provides highly informative data compared to the target sensor (e.g., recognizing walking with an ankle sensor as the source and a wrist sensor as the target), we observed even greater improvements, reaching up to 20 to 40 percentage points for certain activity classes. This method using contrastive learning has important implications for real-world applications beyond IMU sensors. By using contrastive learning and knowledge transfer between sensors, our approach enables the development of more robust and accurate HAR systems. This has potential applications in various domains, including human\u2013robot collaboration in manufacturing lines, where HAR plays a crucial role in improving productivity, quality assurance, and worker safety.Wearable Sensor-Based Human Activity Recognition 3155 Conclusion In this book chapter, we explored the role of wearable sensor-based HAR in promot-ing worker safety and optimizing productivity in manufacturing environments. We discussed the importance of worker safety and the potential benefits of using wear-able sensors to monitor and recognize workers\u2019 activities on the manufacturing line. We presented a case study on wearable sensor-based worker activity recognition in a manufacturing line with a mobile robot, using sensor data fusion approaches and neural network models. By combining data from different sensor modalities, such as inertial sensors and body capacitance sensors, we were able to capture a comprehensive view of workers\u2019 activities and improve the accuracy of activity recognition. Furthermore, we introduced several deep learning-based techniques to enhance the performance of HAR, including adversarial learning and contrastive learning. These approaches have shown promise in improving activity recognition accuracy and generalization capabilities. The use case in the SmartFactory Testbed demonstrated the practical appli-cation of sensor-based worker activity recognition in a real-world manufacturing environment. By accurately recognizing workers\u2019 activities and predicting their movement intentions, collision risks between workers and robots can be minimized, ensuring both worker safety and high production levels. Throughout this chapter, we discussed the potential benefits of sensor-based HAR beyond worker safety, including process optimization, ergonomics improvement, and worker training. We also highlighted the challenges and limitations associated with wearable sensor systems, such as privacy concerns and data security. While our studies demonstrate the potential of wearable sensor-based HAR in manufacturing environments, we acknowledge that there are still challenges to overcome. These challenges include ensuring the robustness and reliability of sensor data, addressing issues related to real-time processing and inference, and managing privacy concerns in the collection and storage of personal data. The results obtained from the adopted research can be applied in the practice of manufacturing companies by providing real-time insights into workers\u2019 activities. By accurately recognizing workers\u2019 activities and predicting their movement inten-tions, manufacturers can identify safety hazards, optimize processes, and enhance overall operational efficiency. The implementation of wearable sensor-based HAR systems can lead to improved worker safety, reduced workplace accidents, enhanced productivity, and more efficient resource allocation. In conclusion, wearable sensor-based HAR holds significant potential for improving worker safety and productivity in manufacturing environments. By leveraging the wealth of data collected from wearable sensors and utilizing advanced machine learning techniques, manufacturers can gain real-time insights into workers\u2019 activities, identify safety hazards, optimize processes, and enhance overall operational efficiency. Future research in this field should focus on addressing the challenges and limitations of wearable sensor systems and exploring novel sensing modalities and machine learning approaches to further improve the performance of HAR in manufacturing environments.316 S. Suh et al.Acknowledgments This work was supported by the European Union\u2019s Horizon 2020 program projects STAR under grant agreement number H2020-956573. Carl-Zeiss Stiftung also funded it under the Sustainable Embedded AI project (P2021-02-009). References 1. Aehnelt, M., Gutzeit, E., Urban, B., et al.: Using activity recognition for the tracking of assembly processes: Challenges and requirements. WOAR 2014, 12\u201321 (2014) 2. Al-Amin, M., Tao, W., Doell, D., Lingard, R., Yin, Z., Leu, M.C., Qin, R.: Action recognition in manufacturing assembly using multimodal sensor fusion. Procedia Manuf. 39, 158\u2013167 (2019) 3. Al-Amin, M., Qin, R., Tao, W., Doell, D., Lingard, R., Yin, Z., Leu, M.C.: Fusing and refining convolutional neural network models for assembly action recognition in smart manufacturing. Proc. IME C J. Mech. Eng. Sci. 236(4), 2046\u20132059 (2022) 4. Bai, L., Yao, L., Wang, X., Kanhere, S.S., Guo, B., Yu, Z.: Adversarial multi-view networks for activity recognition. Proc. ACM Interact. Mobile Wearable Ubiquitous Technol. 4(2), 1\u201322 (2020) 5. Bello, H., Zhou, B., Lukowicz, P.: Facial muscle activity recognition with reconfigurable differential stethoscope-microphones. Sensors 20(17), 4904 (2020) 6. Bian, S., Lukowicz, P.: A systematic study of the influence of various user specific and environ-mental factors on wearable human body capacitance sensing. In: Body Area Networks. Smart IoT and Big Data for Intelligent Health Management: 16th EAI International Conference, BODYNETS 2021, Virtual Event, October 25\u201326, 2021, Proceedings, pp. 247\u2013274. Springer, Berlin (2022) 7. Chen, L., Zhang, Y., Peng, L.: Metier: a deep multi-task learning based activity and user recognition model using wearable sensors. Proc. ACM Interact. Mobile Wearable Ubiquitous Technol. 4(1), 1\u201318 (2020) 8. El Zaatari, S., Marei, M., Li, W., Usman, Z.: Cobot programming for collaborative industrial tasks: an overview. Robot. Auton. Syst. 116, 162\u2013180 (2019) 9. Fortes Rey, V., Suh, S., Lukowicz, P.: Learning from the best: contrastive representations learning across sensor locations for wearable activity recognition. In: Proceedings of the 2022 ACM International Symposium on Wearable Computers, pp. 28\u201332 (2022) 10. Global smartwatch shipments grow 9% yoy in 2022; price polarization seen in demand. https:// www.counterpointresearch.com/global-smartwatch-shipments-grow-yoy-2022/, accessed: 2023-06-22 11. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Advances in Neural Information Processing Systems, pp. 2672\u20132680 (2014) 12. Haresamudram, H., Essa, I., Pl\u00f6tz, T.: Contrastive predictive coding for human activity recognition. Proc. ACM Interact. Mobile Wearable Ubiquitous Technol. 5(2), 1\u201326 (2021) 13. Janidarmian, M., Roshan Fekr, A., Radecka, K., Zilic, Z.: A comprehensive analysis on wearable acceleration sensors in human activity recognition. Sensors 17(3), 529 (2017) 14. Kaasinen, E., Schmalfu\u00df, F., \u00d6zturk, C., Aromaa, S., Boubekeur, M., Heilala, J., Heikkil\u00e4, P., Kuula, T., Liinasuo, M., Mach, S., et al.: Empowering and engaging industrial workers with operator 4.0 solutions. Comput. Ind. Eng. 139, 105678 (2020) 15. Koskimaki, H., Huikari, V., Siirtola, P., Laurinen, P., Roning, J.: Activity recognition using a wrist-worn inertial measurement unit: a case study for industrial assembly lines. In: 2009 17th Mediterranean Conference on Control and Automation, pp. 401\u2013405. IEEE, New York (2009) 16. Kwon, H., Abowd, G.D., Pl\u00f6tz, T.: Adding structural characteristics to distribution-based accelerometer representations for activity recognition using wearables. In: Proceedings of the 2018 ACM International Symposium on Wearable Computers, pp. 72\u201375 (2018) 17. Maekawa, T., Nakai, D., Ohara, K., Namioka, Y.: Toward practical factory activity recognition: unsupervised understanding of repetitive assembly work in a factory. In: Proceedings of theWearable Sensor-Based Human Activity Recognition 3172016 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pp. 1088\u2013 1099 (2016) 18. Nakano, K., Chakraborty, B.: Effect of dynamic feature for human activity recognition using smartphone sensors. In: 2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST), pp. 539\u2013543. IEEE, New York (2017) 19. Pirkl, G., Hevesi, P., Cheng, J., Lukowicz, P.: mBeacon: accurate, robust proximity detection with smart phones and smart watches using low frequency modulated magnetic fields. In: Proceedings of the 10th EAI International Conference on Body Area Networks, pp. 186\u2013191 (2015) 20. Pirsiavash, H., Ramanan, D.: Detecting activities of daily living in first-person camera views. In: 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2847\u20132854. IEEE, New York (2012) 21. Radziwon, A., Bilberg, A., Bogers, M., Madsen, E.S.: The smart factory: exploring adaptive and flexible manufacturing solutions. Procedia Eng. 69, 1184\u20131190 (2014) 22. Roitberg, A., Somani, N., Perzylo, A., Rickert, M., Knoll, A.: Multimodal human activity recognition for industrial manufacturing processes in robotic workcells. In: Proceedings of the 2015 ACM on International Conference on Multimodal Interaction, pp. 259\u2013266 (2015) 23. Ro\u017eanec, J.M., Novalija, I., Zajec, P., Kenda, K., Tavakoli Ghinani, H., Suh, S., Veliou, E., Papamartzivanos, D., Giannetsos, T., Menesidou, S.A., et al.: Human-centric artificial intelligence architecture for industry 5.0 applications. Int. J. Protein Res., 61(20), 6847\u20136872 (2022). https://www.tandfonline.com/doi/full/10.1080/00207543.2022.2138611 24. Sanchez, M., Exposito, E., Aguilar, J.: Industry 4.0: survey from a system integration perspective. Int. J. Comput. Integr. Manuf. 33(10\u201311), 1017\u20131041 (2020) 25. Sornam, M., Muthusubash, K., Vanitha, V.: A survey on image classification and activity recognition using deep convolutional neural network architecture. In: 2017 Ninth International Conference on Advanced Computing (ICoAC), pp. 121\u2013126. IEEE, New York (2017) 26. Suh, S., Rey, V.F., Lukowicz, P.: Adversarial deep feature extraction network for user independent human activity recognition. In: 2022 IEEE International Conference on Pervasive Computing and Communications (PerCom), pp. 217\u2013226. IEEE, New York (2022) 27. Suh, S., Rey, V.F., Lukowicz, P.: Tasked: transformer-based adversarial learning for human activity recognition using wearable sensors via self-knowledge distillation. Knowl.-Based Syst. 260, 110143 (2023) 28. Tao, W., Lai, Z.H., Leu, M.C., Yin, Z.: Worker activity recognition in smart manufacturing using imu and semg signals with convolutional neural networks. Procedia Manuf. 26, 1159\u2013 1166 (2018) 29. Wang, S., Wan, J., Li, D., Zhang, C.: Implementing smart factory of industrie 4.0: an outlook. Int. J. Distrib. Sens. Netw. 12(1), 3159805 (2016) 30. Xu, X., Lu, Y., Vogel-Heuser, B., Wang, L.: Industry 4.0 and industry 5.0\u2014inception, conception and perception. J. Manuf. Syst. 61, 530\u2013535 (2021) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Object Detection for Human\u2013Robot Interaction and Worker Assistance Systems Hooman Tavakoli, Sungho Suh, Snehal Walunj, Parsha Pahlevannejad, Christiane Plociennik, and Martin Ruskowski 1 Introduction: Why Object Detection in the Industrial Environment is Helpful? The integration of Object Detection (OD) technology into industrial environments offers significant changes and improvements by addressing critical challenges and optimizing operations. By accurately detecting and recognizing objects in real time, OD systems play an important role in ensuring safety, streamlining workflows, and efficient assistance for humans. In today\u2019s complex industrial landscape, accurate OD is pivotal as it serves as the foundation for various safety mechanisms, such as identifying obstacles and hazardous materials, thereby reducing accidents and downtime. Efficiency, productivity, and worker safety are paramount in industrial settings, making accurate object detection an essential component of worker assistance systems. Leveraging advanced algorithms, sensor fusion techniques, and machine learning methodologies, industries can achieve improved automation, enhanced human\u2013robot interaction, and optimized processes. OD technology enables indus-H. Tavakoli (\u0002) \u00b7 S. Walunj \u00b7 P. Pahlevannejad \u00b7 C. Plociennik \u00b7 M. Ruskowski German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Technologie-Initiative SmartFactory, Kaiserslautern, Germany e-mail: hooman.tavakoli_ghinani@dfki.de; snehal.walunj@dfki.de; parsha.pahlevannejad_chaleshtori@dfki.de; christiane.plociennik@dfki.de; martin.ruskowski@dfki.de S. Suh German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany Department of Computer Science, RPTU Kaiserslautern-Landau, Kaiserslautern, Germany e-mail: sungho.suh@dfki.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_18319320 H. Tavakoli et al.trial modules and agents to perceive and analyze their surroundings, leading to optimized operations and safeguarding the well-being of workers. By integrating OD technology with human assistance and collaboration mech-anisms, safer and more productive interactions are fostered in industrial environ-ments. Collaborative robots, or Cobots, are increasingly deployed to augment the capabilities of human operators and improve overall productivity. Leveraging object detection technology, Cobots accurately perceive and respond to the presence of humans, ensuring safe and seamless cooperation within shared workspaces. This prioritizes safety and productivity in human\u2013robot interactions, driving innovation and efficiency in the industrial domain. Assistance systems play an important role where manual work is prevalent. In industrial processes such as assembly, training, or maintenance processes, these systems support minimizing the workload of humans. There are different types of assistance systems, ranging from manual workstations equipped with cameras and displays to immersive assistance systems over head-mounted devices or smart devices. Computer vision techniques such as object detection help understand the worker\u2019s environment from visual data. This understanding can be used to enrich existing software systems with object information to achieve multiple goals. With applications ranging from healthcare to the automotive industry, object detection models such as Yolo [22] and Faster RCNN [7] have gained popularity on account of their real-time detection performance. For example, in [15], an Advanced Driver Assistance System (ADAS) is equipped with real-time object detection to provide safety and a better driving experience. In use cases such as ADAS systems encountering moving objects, real-time object detection becomes even more important. Object detection also finds applications for solving industrial problems such as quality inspection. An Augmented Reality (AR)-based assistance system uses the context of the existing reality or real environment and intends to augment it with useful informa-tion. In order to capture the real-world context, camera sensors play an integral part in the AR system. They provide real-world data, and the display serves as the counterpart helping the user visualize the system together with augmented information. The input visual data are understood using deep learning methods such as object detection and pose estimation, the output of which can be used for solving a large spectrum of problems in the form of an assistance system. Object detection outputs can be utilized to create effective assistance systems that provide real-time recommendations and guidance. By integrating OD with head-worn devices, workers can receive valuable information and instructions related to their tasks. For instance, an OD system can detect and recognize objects in the assembly place, or potential hazards in the worker\u2019s surroundings. The system can then analyze these data and provide recommendations, such as the next step in the assembly pipeline. It can also alert the worker to the presence of a hazardous object. These recommendations are displayed on the worker\u2019s head-worn device, providing immediate and personalized assistance. By leveraging OD in human assistance systems, workers can benefit from increased safety, improved efficiency,Object Detection for Human\u2013Robot Interaction and Worker Assistance Systems 321and enhanced situational awareness, ultimately leading to a more productive and secure work environment. Supervised learning approaches such as object detection are highly dependent on data. A large amount of image data are required for training. Synthetically generated and labeled dataset offers several advantages in this regard. It simplifies and economizes the generation of large datasets, eliminating manual labeling and reducing human errors. Its flexibility allows for easy manipulation according to specific requirements, enabling researchers to control factors such as lighting, camera angles, and object placements. This enhances the model\u2019s ability to learn from diverse scenarios and improves its generalization capabilities. Furthermore, synthetic data are well-suited for various computer vision tasks, including the detection of small or rare objects that may be challenging to capture in real-world datasets. Its ability to simulate objects of any scale or size makes it invaluable in training models. Synthetic data can be generated in large quantities, providing ample training samples for deep learning models that require extensive labeled data. Moreover, it allows for easy augmentation, increasing dataset diversity and variability. These advantages contribute to the development of more accurate and robust deep learning models in computer vision. In the subsequent sections, we will delve into the following aspects: 1. Background: We will explore the utilization of object detection in industrial environments and its diverse range of applications. 2. Scenarios: We will discuss two pivotal scenarios within the industrial environ-ment setting where object detection is employed for human\u2013robot interaction and worker assistance systems. Moreover, the respective methodology for the worker assistance systems scenario is discussed, and the results are presented. 3. Ongoing and Future Work: We will highlight currently ongoing research that involves the exploration of continual learning techniques and dataset optimiza-tion through the combination of real and synthetic datasets. 4. Conclusion: The chapter will conclude by summarizing the key findings and contributions to the topic. 2 Background The industrial environment is undergoing a profound transformation toward greater intelligence and autonomy, thanks to the emergence of machine learning (ML) approaches. With access to abundant data and powerful hardware resources, deep learning techniques and artificial intelligence methods have become increasingly valuable. In this context, leveraging AI-based methods within industrial settings offers significant potential for reducing human errors and enhancing safety [4], particularly in scenarios involving human\u2013robot collaboration or shared workspaces with close proximity between these two crucial agents. The exploration of human\u2013 robot interaction in complex and unpredictable environments has become a promi-322 H. Tavakoli et al.nent research area, where AI methods can be effectively harnessed [13]. Within this landscape, deep models serve as powerful tools that excel in addressing intricate challenges encountered in the industrial domain. Their ability to learn hierarchical representations directly from raw data positions them as ideal solutions for a wide range of applications, encompassing object detection, anomaly detection, predictive maintenance, quality control, and optimization. Deep models, capable of addressing diverse challenges encountered in industrial settings, have emerged as highly effective tools. These encompass vision-based approaches [25], natural language processing (NLP) techniques [1], as well as human wearable sensor-based approaches for HRI [16], among others. Notably, both conventional and deep-learning-based ML models have recently been harnessed for video streaming analysis with the aim of object detection [6]. Deep models, characterized by their end-to-end nature, aim to address the challenge of laborious and time-consuming feature extraction from data [11]. Vision-based AI approaches have become increasingly valuable in addressing industrial problems due to their ability to interpret and analyze visual data in real time. These approaches leverage deep learning algorithms and computer vision techniques to process images or video streams captured by cameras or sensors installed in industrial settings. By employing vision-based AI, various industrial challenges can be effectively tackled. Hence, vision-based approaches are widely recognized for their significant value across diverse scenarios. One prominent vision-based approach is object detection, which involves the classification and localization of multiple objects in the target frames or images. It has proven to be highly applicable in various scenarios, contributing to tasks such as improving safety, facilitating human\u2013robot interaction [25], aiding in error identification for workers, and optimizing task completion time. Given the wide range of challenges and numerous common use cases encoun-tered by vision-based AI approaches in industrial settings, it is imperative to thoroughly investigate various aspects of AI-based approaches, especially in indus-trial environments. These aspects encompass examining the architecture of deep learning models, conducting comprehensive analysis and assessment of the data sources, and addressing other significant factors to ensure optimal performance and effectiveness. In the following, we dig into some of these challenges and solutions. 2.1 Dataset In the case of industrial scenarios, there is difficulty in terms of real-world data collection. Especially in vision problems, collecting images with diverse conditions and viewpoints, and also labeling them, is an effort-intensive as well as a time-consuming task. In some cases, the frames used as the source of input can originate from various cameras within the environment. These cameras can include ceiling-mounted cameras, robot cameras, as well as head-worn cameras of mixed reality devices like HoloLens that capture workers\u2019 point of view [24]. Also in some cases,Object Detection for Human\u2013Robot Interaction and Worker Assistance Systems 323the data collection cameras are different from the edge devices on which an object detection model needs to be deployed. In such a situation, synthetic data generation becomes inevitable. Also, CAD data play an eminent role in the complete product life cycle of a manufacturing product, and for the product as well as the machine, it is readily available. These CAD models can be exploited to generate synthetic datasets. However, using CAD data directly cannot serve as a reliable solution. The CAD data only resemble the real objects in geometry; however, they lack materials and texture. Thus, there exists a large amount of distinction in the appearance of the real and CAD data. If we use CAD-based synthetic images for training, which is to be tested on real-world objects, there is a problem of domain difference, i.e., the real and synthetic data domain. In an attempt to solve this issue, the technique of domain randomization is demonstrated in [19]. Domain randomization can be achieved by randomizing various aspects of the simulation scene such as the backgrounds, illumination, orientation of the objects, etc. [3]. 2.2 Architectures Numerous prominent object detection architectures, including the R-CNN pipeline [7], Fast-RCNN [8], and Faster-RCNN [9], SSD [12], You Only Look Once (YOLO) approaches [22], and its following versions such as YOLOv7 [28], pro-vide well-defined pipelines for detecting objects across different scenarios. These architectures offer robust methodologies for accurately identifying and localizing objects within the visual data. State-of-the-art techniques, such as YOLO object detection, have particularly excelled in enabling real-time or near-real-time object detection. This capability is of utmost importance in industrial environments, where the ability to detect objects promptly is crucial for effective use cases. By leveraging these advanced object detection methods, industries can enhance their operational efficiency, safety, and decision-making processes. 2.3 Application in Industrial Environment Object detection is highly practical and beneficial in various broad use cases. For instance, in [21], object detection pipelines were employed to automate logistic processes within industrial environments. Saeed et al. [23] addressed the challenge of detecting faults in industrial product images, particularly focusing on small-object detection. Another case study is conducted by Usamentiaga et al. [27] for evaluating the state-of-the-art deep-based object detection models as well as semantic segmentation in the scenario of automated surface inspection in metals. In the field of robotics, [2] researched the integration of an object detection CNN-based model to leverage a robot in a sorting task.324 H. Tavakoli et al.2.4 Challenges It is obvious that object detection in the industrial environment can facilitate many tasks especially in which a robot and a human need to collaborate and work in a shared workplace, and promotes safety by facilitating interaction between humans and robots. However, object detection in the industrial environment does face some challenges. Object detection in a complex and unpredictable industrial environment, in which interference objects similar to the goal objects can be found easily due to the similarity in shape, size, and color, and random positioning and orientation of different objects make this detection much more difficult [2]. Also, detecting small objects poses a significant challenge due to their limited representation of features. An overview of concepts and terminology related to artificial intelligence (AI) is given in ISO/IEC 22989:2022 Information Technology\u2014Artificial intelligence\u2014 Artificial intelligence concepts and terminology\u201d [10]. 3 Scenarios In this section, we explore the scenarios in both projects, STAR and InCoRAP for object detection in the factory environment with specific emphasis on safety in human\u2013robot collaboration and interaction, and human assistance systems. We study the use cases in which object detection can be utilized for safety in the industrial environment. Additionally, we investigate the application of object detection in human assistance systems. Furthermore, we will explain our recent work on context-based object detection methods, particularly for small objects in the assembly use case within the industrial environment. We dive into the details of how context-based approaches can effectively detect and identify small objects in assembly scenarios. 3.1 Object Detection for Human\u2013Robot Interaction in the STAR Project Object detection for human detection can play a crucial role in enhancing safety in industrial environments. Although human detection can be considered as a sub-task of object detection, it is facing some more complexity due to the wide range of possible appearances on account of the articulated pose, and clothing, to name a few [20]. Hence, studying human detection is vital from a safety perspective, especially in a complex, unpredictable, and dangerous industrial environment. Here are a few ways human detection will be utilized: \u2013 Enhancing Worker Safety: Implementing object detection systems that are capa-ble of accurately identifying and tracking human presence can greatly contributeObject Detection for Human\u2013Robot Interaction and Worker Assistance Systems 325to worker safety. These systems enable the implementation of proactive safety measures to prevent accidents or potentially dangerous situations. For instance, if a worker enters a restricted area or approaches a hazardous machine, the object detection system can promptly detect their presence and trigger warnings that can be raised in the HoloLens head-worn device or automatically shut down the equipment to mitigate potential accidents. \u2013 Collision Avoidance: Object detection can be utilized to detect the presence of humans in the vicinity of moving machinery or vehicles. This information can be used to alert operators or autonomous systems to slow down, change direction, or stop to avoid collisions and ensure worker safety. Our pilot study aims to explore the practical application of ceiling cameras or robot cameras in hazardous accident scenarios occurring within an industrial environment. Our focus is specifically directed toward examining the collab-oration between a moving robot and human workers. The moving robot\u2019s primary role is to assist in the transportation of objects from the warehouse to the workstation, as well as facilitating the transfer of objects between various production lines, which often occurs in an unpredictable timescale. To ensure the safety of workers and prevent any potential accidents, we employ localization and classification from object detection techniques for both the robot and human agents. These techniques enable us to effectively localize the position of the robots and humans within the workspace through the ceiling cameras in the environment. By real-time monitoring and analyzing of the robot and human locations, we can promptly identify and mitigate potential collisions or unsafe situations, which leads to a secure and accident-free working environment. Overall, object detection for human detection in industrial environments brings safety by enabling proactive measures and collision avoidance. It helps create a safer working environment, reduces the risk of accidents, and enhances the well-being of workers. 3.2 Object Detection for Manual Assembly Assistance System in InCoRAP In the InCoRAP use case, the AR-based Assistance system observes the egocentric point of view of the worker. The goal is to observe worker activity in the assembly process in order to support them through a mobile robot collaboration. The object detection model is a part of the assistance used to observe the assembly state based on the detected objects. For AR applications, the head-mounted device: HoloLens2 is used. The detected objects are the observations that correspond to the assembly steps, and these observations are later used to support the worker. Research focusing on the evaluation of AR systems has proven AR-based assistance systems advantageous over conventional instruction manuals [5]. Thus,326 H. Tavakoli et al.Fig. 1 The pipeline of the 3 experiments within the training phase with testing on the HoloLens2 frames transferred to the edge server for detecting target objects [25] AR-based assistance places less workload on the worker or user compared to document-based guidance. The field of small-object detection has garnered considerable research interest and has become increasingly popular. In vision-based object detection methods, the texture and arrangement of objects play a pivotal role in enabling the object detection pipeline to extract relevant features. It is worth noting that smaller objects may pose a challenge, as their size can be reduced significantly during the feature extraction process. For example, an object with dimensions of .32 \u00d7 32 pixels, after passing through five pooling layers in the VGG16 model, would be represented as a mere 1-pixel [17]. The concept of small objects, as defined in [26], encompasses objects sized at .32 \u00d7 32 pixels within the context of image analysis. We specifically focus on small-object detection within an assembly scenario, where workers assemble various electrical components (e.g., buttons, resistors, LED, buzzers) on a breadboard to create a final product (Fig. 3b) [25]. In this scenario, a robot assists the worker by delivering parts from the warehouse, and an assistance system detects the current assembly steps and suggests the next probable part to be installed on the breadboard. The frames captured from the worker\u2019s point of view (POV) are seized using the HoloLens2, which the worker wears during the assembly process. The pipeline for this approach is illustrated in Fig. 1. In the testing phase, the frames are transmitted to the server where the object detection model performs inference. The detected objects provide information such as class identification and bounding box coordinates. This information is then communicated from the server to the HoloLens2 device using Unity communica-tion. Subsequently, the HoloLens2 device generates holographic representations, displaying the class identification and bounding box information as augmented data. Workers in the environment can observe these holograms when they focus their gaze on the respective objects.Object Detection for Human\u2013Robot Interaction and Worker Assistance Systems 327Fig. 2 Synthetic dataset generation pipeline [25] 3.3 Methodology: Context-Based Two-Step Object Detection For computer vision problems such as image classification or object detection, the foremost task is the collection of suitable image data and then labeling it. However, this process can be automated using a game engine such as Unity [3]. In a Unity renderer space, there is a game camera that consists of the attributes of a physical camera. There are two types of views obtained in such a game development environment, one being the developer view and the other being the game view. These features allow for creating a simulation scene for synthetic image data generation. As introduced in [3], the Unity Perception allows for customization and user-defined feature development with the goal of synthetic data generation in Unity. We developed a scene similar to that of the Unity Perception Package that allows for multi-object detection dataset generation. The 3D models of the desired object are CAD models converted into Unity-compatible format and imported into the scene. The synthetic dataset generation pipeline shown in Fig. 2 shows the CAD model of the object imported into a Unity scene. On importing into the scene, the CAD models are processed to achieve a photo-realistic appearance using the renderer features. The scene is developed in such a way that it simulates a systematic image-capturing process [3] to deliver the desired dataset. A script has been written for the game camera to capture the object images from various viewpoints and distances to the object during the simulation. From a set of background images, the backgrounds of the objects are randomized in the simulation. By rendering multiple views of the scenes, we generate a diverse set of synthetic images that mimic real-world conditions. Additionally, data augmentation techniques such as object rotation, scene illumination, and object occlusion are applied. Furthermore, the labeling tool within this Unity scene automatically annotates the generated images with bounding boxes, providing ground truth information for training and validation. In Table 1, the benefits of using synthetic data were demonstrated in the context of installing small objects on a breadboard as an assembly process. Additionally, utilizing synthetic data presents advancements in the two-step detection approach. Table 1 illustrates the Mean Average Precision (mAP) for the detection of the small button on the breadboard for our three experiments. The mAP is a widely used evaluation metric in object detection tasks. It measures the accuracy and precision328 H. Tavakoli et al.Table 1 The mAP results for all 3 experiments for different Intersection of Union (IoU) are illustrated and confirmed that the two-step detection improved the mAP for the buttons, the target small object in the frames [25] mAP (full size) mAP (cropped) IoU 0.01 0.10 0.20 0.30 0.40 0.50 0.01 0.10 0.20 0.30 0.40 0.50 Exp. 1 0.3% 0% 0% 0% 0% 0% 2.6% 0% 0% 0% 0% 0% Exp. 2 44% 26% 4% 0.6% 0.03% Exp. 3 44% 26% 4% 0.6% 0.03% 70% 69% 58% 27% 8.5% Fig. 3 (a) Synthetic image for assembly objects, (b) object detection on a video captured from HoloLens2 for the corresponding real objects of object detection algorithms by calculating the average precision for each class and then taking the mean across all classes. The mAP is calculated according to [18]. The first experiment is trained on the 295 conventional images from buttons and tested on the 90 images containing 221 tiny buttons. The same setup is applied in the 2nd experiment, but in the training phase, we utilized the 1300 synthetic images of the breadboard and 2500 images of tiny buttons installed on the breadboard. It is clear that the mAP for the second experiment is considerably higher than the first experiment, which is around 0% for almost all different IoUs. In the third experiment, we utilized the same training and testing data as in the second experiment. However, during the inference phase, we adopted a different approach. Instead of resizing the entire frame, we first detected the breadboard and then cropped it based on the context (specifically, the Breadboard). The resulting cropped frame was then forwarded to the YOLOv4 object detection pipeline to detect the buttons as small objects. Through the third experiment, we demonstrated how employing a context-based cropping approach on the frames leads to a significant improvement in mAP (Table 1). More details can be found in [25] (Fig. 3). 4 Ongoing Research In this section, we present the current research endeavors conducted at our research center in the field of object detection. We will highlight the ongoing projectsObject Detection for Human\u2013Robot Interaction and Worker Assistance Systems 329and studies that are directly aligned with our focus on advancing object detection techniques. 4.1 Hybrid Dataset Considering the advantages that synthetic data offer with respect to reduced human effort and time consumption, it has gained research interest. However, it can encounter challenges related to optimizing various aspects of the scene, including CAD models, lighting conditions, backgrounds, and object textures. In our recent research, we are specifically investigating the utilization of real data in combination with synthetic data to enhance the precision of object detection. By leveraging real data in this manner, we aim to optimize the object detection performance and facilitate the creation of datasets that meet our specific requirements. 4.2 Continual Learning (CL) An additional challenge in this chapter is the need to update previously trained object detection models to accommodate new tasks, rather than retraining the model from scratch with both old and new data. This process of continual learning aims to address the issue of catastrophic forgetting, where the model\u2019s performance on previous tasks significantly declines as it is trained on new tasks [29]. This presents an interesting avenue for further exploration within the field of study. Both domain incremental learning and task incremental learning [14] offer  potential research approaches that can be applied to our specific environmental scenarios. These methods enable the model to adapt to new tasks while retaining knowledge from previous tasks. Investigating and leveraging different continual learning techniques can contribute to the development of a more flexible and efficient object detection approach. Figure 4 depicts the utilization of continual learning to optimize the object detection process using the synthetic data in our scenarios. The procedure begins by importing CAD models of new objects and subsequently generating synthetic image datasets. These datasets are then passed to the next phase, where the previously trained YOLOv7 model is retrained using the replay approach of continual object detection. Finally, in the evaluation phase, frames captured from HoloLens are processed by the new object detection model, and the performance of this model is assessed. Thus it is an iterative process, starting from importing synthetic data to dataset generation, model retraining, and evaluation phase, aiming to expand the range of OD classes by updating the previously trained model.330 H. Tavakoli et al.Fig. 4 The pipeline demonstrates the sequential process of generating synthetic data, conducting training and testing using the HoloLens2 World Camera, with the aim of establishing a continual learning pipeline for model updates 5 Conclusion This chapter provides an exploration of object detection in industrial environments, specifically focusing on various scenarios involving human assistance systems, and safety requirements for human\u2013robot collaboration. Additionally, we examine the application of object detection in conjunction with augmented reality devices, which offer intuitive communication interfaces for workers in these environments. Moreover, we emphasize the substantial advantages gained from the incorpo-ration of synthetic data in expediting the laborious data generation process and enhancing object detection outcomes. Through the utilization of synthetic data, we achieve improved efficiency and precision in object detection results. Additionally, we present our recent research focusing on the detection of small objects within industrial environments, which poses a significant challenge. We demonstrate that our approach significantly enhances the detection of small objects in manual assembly scenarios, resulting in notable improvements in performance. Ultimately, this chapter not only sheds light on some solutions to object detection barriers in industrial settings but also paves the way for further exploration in related fields. This includes the development of sustainable practices within our scenarios and the establishment of a more generalized process that encompasses data generation and the preparation of object detection models. Acknowledgments This work was supported by the European Union\u2019s Horizon 2020 program project STAR, under grant agreement numbers H2020-956573, and by the BMBF (German Federal Ministry of Education and Research) project InCoRAP (0IW19002).Object Detection for Human\u2013Robot Interaction and Worker Assistance Systems 331References 1. Agnello, P., Ansaldi, S.M., Lenzi, E., Mongelluzzo, A., Roveri, M.: RECKONition: a NLP-based system for industrial accidents at work prevention. arXiv preprint arXiv:2104.14150 (2021) 2. BinYan, L., YanBo, W., ZhiHong, C., JiaYu, L., JunQin, L.: Object detection and robotic sorting system in complex industrial environment. In: 2017 Chinese Automation Congress (CAC), pp. 7277\u20137281 (2017). https://doi.org/10.1109/CAC.2017.8244092 3. Borkman, S., Crespi, A., Dhakad, S., Ganguly, S., Hogins, J., Jhang, Y.C., Kamalzadeh, M., Li, B., Leal, S., Parisi, P., et al.: Unity perception: generate synthetic data for computer vision. arXiv preprint arXiv:2107.04259 (2021) 4. Chen, J.H., Song, K.T.: Collision-free motion planning for human-robot collaborative safety under cartesian constraint. In: 2018 IEEE International Conference on Robotics and Automa-tion (ICRA), pp. 4348\u20134354. IEEE, New York (2018) 5. Eversberg, L., Lambrecht, J.: Evaluating digital work instructions with augmented reality versus paper-based documents for manual, object-specific repair tasks in a case study with experienced workers. arXiv preprint arXiv:2301.07570 (2023) 6. Gallo, G., Di Rienzo, F., Ducange, P., Ferrari, V., Tognetti, A., Vallati, C.: A smart system for personal protective equipment detection in industrial environments based on deep learning. In: 2021 IEEE International Conference on Smart Computing (SMARTCOMP), pp. 222\u2013227 (2021). https://doi.org/10.1109/SMARTCOMP52413.2021.00051 7. Girshick, R.: Fast R-CNN. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 1440\u20131448 (2015) 8. Girshick, R.: Fast R-CNN. In: Proceedings of the IEEE International Conference on Computer Vision (ICCV) (2015) 9. Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 580\u2013587 (2014) 10. ISO: Information technology\u2014artificial intelligence\u2014artificial intelligence concepts and terminology. Standard ISO/IEC 22989:2022, International Organization for Standardization (2022) 11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: ImageNet classification with deep convolutional neural networks. Commun. ACM 60(6), 84\u201390 (2017). https://doi.org/10.1145/3065386 12. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C.: SSD: Single shot MultiBox detector. In: Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11\u201314, 2016, Proceedings, Part I 14, pp. 21\u201337. Springer, Berlin (2016) 13. Liu, Z., Liu, Q., Xu, W., Liu, Z., Zhou, Z., Chen, J.: Deep learning-based human motion prediction considering context awareness for human-robot collaboration in manufacturing. Procedia CIRP 83, 272\u2013278 (2019). https://doi.org/https://doi.org/10.1016/j.procir.2019.04. 080. https://www.sciencedirect.com/science/article/pii/S2212827119306948, 11th CIRP Con-ference on Industrial Product-Service Systems 14. Menezes, A.G., de Moura, G., Alves, C., de Carvalho, A.C.: Continual object detection: a review of definitions, strategies, and challenges. Neural Netw. (2023) 15. Murthy, J.S., Siddesh, G.M., Lai, W.C., Parameshachari, B.D., Patil, S.N., Hemalatha, K.L.: ObjectDetect: a real-time object detection framework for advanced driver assistant systems using YOLOv5. Wirel. Commun. Mob. Comput. 2022, 10 (2022). https://doi.org/10.1155/ 2022/9444360 16. Neto, P., Sim\u00e3o, M., Mendes, N., Safeea, M.: Gesture-based human-robot interaction for human assistance in manufacturing. Int. J. Adv. Manuf. Technol. 101, 119\u2013135 (2019) 17. Nguyen, N.D., Do, T., Ngo, T.D., Le, D.D.: An evaluation of deep learning methods for small object detection. J. Electr. Comput. Eng. 2020, 1\u201318 (2020)332 H. Tavakoli et al.18. Padilla, R., Passos, W.L., Dias, T.L., Netto, S.L., Da Silva, E.A.: A comparative analysis of object detection metrics with a companion open-source toolkit. Electronics 10(3), 279 (2021) 19. Pasanisi, D., Rota, E., Ermidoro, M., Fasanotti, L.: On domain randomization for object detec-tion in real industrial scenarios using synthetic images. Procedia Comput. Sci. 217, 816\u2013825 (2023). https://doi.org/https://doi.org/10.1016/j.procs.2022.12.278. https://www.sciencedirect. com/science/article/pii/S1877050922023560, 4th International Conference on Industry 4.0 and Smart Manufacturing 20. Paul, M., Haque, S.M., Chakraborty, S.: Human detection in surveillance videos and its applications-a review. EURASIP J. Adv. Signal Process. 2013(1), 1\u201316 (2013) 21. Poss, C., Ibragimov, O., Indreswaran, A., Gutsche, N., Irrenhauser, T., Prueglmeier, M., Goehring, D.: Application of open source deep neural networks for object detection in industrial environments. In: 2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA), pp. 231\u2013236 (2018). https://doi.org/10.1109/ICMLA.2018.00041 22. Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once: unified, real-time object detection. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 779\u2013788 (2016) 23. Saeed, F., Ahmed, M.J., Gul, M.J., Hong, K.J., Paul, A., Kavitha, M.S.: A robust approach for industrial small-object detection using an improved faster regional convolutional neural network. Sci. Rep. 11(1), 23390 (2021) 24. Su, Y., Rambach, J., Minaskan, N., Lesur, P., Pagani, A., Stricker, D.: Deep multi-state object pose estimation for augmented reality assembly. In: 2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct), pp. 222\u2013227. IEEE, New York (2019) 25. Tavakoli, H., Walunj, S., Pahlevannejad, P., Plociennik, C., Ruskowski, M.: Small object detection for near real-time egocentric perception in a manual assembly scenario. arXiv preprint arXiv:2106.06403 (2021) 26. Torralba, A., Fergus, R., Freeman, W.T.: 80 million tiny images: a large data set for nonparametric object and scene recognition. IEEE Trans. Pattern Anal. Mach. Intell. 30(11), 1958\u20131970 (2008) 27. Usamentiaga, R., Lema, D.G., Pedrayes, O.D., Garcia, D.F.: Automated surface defect detection in metals: a comparative review of object detection and semantic segmentation using deep learning. IEEE Trans. Ind. Appl. 58(3), 4203\u20134213 (2022) 28. Wang, C.Y., Bochkovskiy, A., Liao, H.Y.M.: YOLOv7: trainable bag-of-freebies sets new state-of-the-art for real-time object detectors. arXiv preprint arXiv:2207.02696 (2022) 29. Wang, L., Zhang, X., Su, H., Zhu, J.: A comprehensive survey of continual learning: theory, method and application. arXiv preprint arXiv:2302.00487 (2023) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework Marta Barroso, Daniel Hinjos, Pablo A. Martin, Marta Gonzalez-Mallo, Victor Gimenez-Abalos, and Sergio Alvarez-Napagao 1 Introduction The field of manufacturing is increasingly interested in adopting Artificial Intel-ligence (AI) due to its ability to revolutionize operations, improve efficiency, and drive innovation. AI algorithms can effectively analyze and extract valuable insights from data, enabling manufacturers to optimize processes, detect anomalies, and make data-driven decisions. In addition, they bring automation and predictive capabilities, by enabling the automation of tasks, such as quality control and pre-dictive maintenance, leading to faster inspections, reduced downtime, and improved operational efficiency. However, despite all these benefits, the adoption of AI from manufacturing side is not happening as quickly as expected [1], and it comes with its own set of challenges and difficulties. While it holds great promise, several challenges need to be addressed for successful integration into the manufacturing processes. These challenges include issues related to data availability and quality, integration with existing infrastructure, shortage of skilled personnel, ethical and regulatory considerations, and change management [2]. Manufacturing environments often entail complex data ecosystems, requiring proper data collection and preparation processes to ensure the availability of high-quality and relevant data usable to produce intelligent models. Furthermore, integrating these models with existing infrastructure may require system upgrades and compatibility assurance. The shortage of skilled professionals with simultaneous expertise in both AI and manufacturing processes hinders adoption, while ethical and regulatory concerns M. Barroso (\u0002) \u00b7 D. Hinjos \u00b7 P. A. Martin \u00b7 M. Gonzalez \u00b7 V. Gimenez \u00b7 S. Alvarez-Napagao High Performance and Artificial Intelligence, Barcelona Supercomputing Center, Barcelona, Spain e-mail: marta.barroso@bsc.es; daniel.hinjos@bsc.es; pablo.martin@bsc.es; marta.gonzalez@bsc.es; victor.gimenez@bsc.es; sergio.alvarez@bsc.es \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_19333334 M. Barroso et al.require robust governance policies. Change management is also crucial, requiring cultural shifts and addressing employee concerns to foster a positive AI adoption environment. To overcome these challenges, AI providers should also facilitate adoption through the development of user-centered tools, fostering partnerships between experts and manufacturing professionals, and showcasing the tangible benefits of implementing machine and deep learning algorithms. By making AI accessible, tailored, and demonstrably valuable, the manufacturing industry can overcome barriers and embrace these technologies to unlock their full potential for improving operational efficiency, productivity, and competitiveness. In this matter, there are two research areas that can play significant roles in nur-turing this adoption: Automated Machine Learning (AutoML) [3] and Explainable Artificial Intelligence (XAI) [4].1 AutoML simplifies the process of developing models by automating tasks such as feature engineering, model selection, and hyperparameter tuning. This automation reduces the need for extensive data science expertise, making it easier for manufacturing professionals to leverage AI capa-bilities. By providing user-friendly interfaces, pre-built algorithms, and automated workflows, AutoML tools enable manufacturers to quickly and efficiently build accurate and robust intelligent models tailored to their specific requirements. On the other hand, XAI addresses the critical need for transparency, interpretabil-ity,2 and trust in AI systems. Manufacturing environments require clear explanations of model decisions, especially when it comes down to critical factors such as quality control, predictive maintenance, and process optimization. XAI techniques allow manufacturers to understand the inner workings of models, identify the factors influencing predictions, and detect potential biases or risks. By providing interpretability and explanations, XAI helps build trust in AI systems and facilitates their adoption by manufacturing professionals. Currently, there are some large-scale proprietary solutions that aim to tackle the aforementioned issues by providing users with end-to-end solutions that opera-tionalize the AI cycle with very limited prior technical knowledge. The most popular comes from big tech companies, e.g., Google AutoML-Zero [5], Microsoft Azure AI [6], Amazon SageMaker [7], and the open-source H2O [8]. Although using this type of platforms has been shown to be beneficial [9], they bring about some drawbacks that organizations should seriously consider. One major setback is the potential lack of transparency and control over the underlying algorithms and models. These platforms often abstract away the details of the machine learning process, making it difficult to understand and interpret how the models arrive at their predictions. This lack of transparency can be a concern,1 Explainability (XAI) focuses on providing meaningful and transparent explanations for the decisions or outputs of an AI system. 2 Interpretability is concerned with understanding and making sense of how a model or algorithm operates. It focuses on the internal workings of the model, including the relationships between inputs and outputs, feature importance, or the overall behavior of the model. Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 335especially in regulated industries or situations where interpretability is crucial for decision-making. Another inconvenience is that in many cases using these tools requires con-tracting their providers\u2019 services and infrastructure. The user is then subject to the limitations and potential downtime of third-party software and hardware. Unexpected disruptions or system issues are out of the control of the user and can impact the availability and performance of AutoML platforms. Additionally, organizations may be locked into specific pricing models and contracts with the cloud provider, limiting flexibility and potentially leading to increased costs in the long run. Data privacy and security are also important considerations when using AutoML platforms in Cloud. Organizations need to ensure that sensitive or proprietary data used for training models are protected and handled in compliance with relevant regulations. The transfer of data to the cloud, data storage, and data access controls should all be carefully evaluated to mitigate any risks associated with data privacy and security breaches. Finally, we should consider vendor lock-in issues. Once an organization builds and deploys models on a specific platform, migrating those models to another platform or bringing the infrastructure in-house can be challenging and time-consuming. This can limit flexibility and hinder the ability to switch providers or adapt to changing business needs in the future. To tackle previous obstacles and motivate the use of AI in manufacturing, we introduce our framework called the AI Model Generation. This framework is part of an European project called knowlEdge\u2014Toward AI-powered manufacturing services, processes, and products in an edge-to-cloud-knowlEdge continuum for humans \u00ecn-the-loop and is intended to be used by people with no background in AI, including manufacturing engineers, plant managers, quality control specialists, and supply chain managers. Throughout the chapter, we will refer to it as AMG. AMG is responsible for the automatic creation of supervised AI models and is able to solve tasks based on various scenarios and input variables. Each of these stages constitutes a submodule by itself. After describing the main functionalities of the system (Sect. 2), we then describe the architecture (Sect. 3), the use cases (Sect. 4), and we describe each of the submodules that make it up (Sect. 5). 2 AI Model Generation Framework This component is able to automatically generate AI models capable of solving user-defined tasks based on an initial configuration in which the data source, the type of problem, and the algorithm are specified. In addition, it enables the computation of the algorithms\u2019 training costs using a set of heuristics. Models can be efficiently deployed in different layers of the computer continuum (cloud, fog, and edge) and336 M. Barroso et al.be saved using standards such as ONNX (Open Neural Network Exchange) and PMML (Predictive Model Markup Language).3 The initial configuration is defined in terms of data source, task, task setup, and strategy. Any dataset is made up of a number of variables and can come from three different data sources (local, static database, broker). See Sect. 5.1 for more information on data sources. The problem to be solved is formalized in a task object. A task has a name, a type (classification, regression, or optimization), an associated performance metric, an optional risk function, a set of input and output variables, and one or more associated execution settings. The configuration of a task is formal-ized in a task setup object, which contains information about the type of validation, training, and evaluation datasets, random seeds, and implemented strategies. A task configured with a task setup can train or run inference using one or more algorithms. The algorithm and the hyperparameters to use are encapsulated in an object called strategy. A strategy consists of the method name, the hyperparameters, the initial state, and the loss function of a given algorithm. As a result, models are generated, and a model is associated with a strategy, a set of metrics describing its performance, and the Docker image tag that deployed it. On the top of that, the user can infer existing models or train new models by defining an initial configuration in JSON format. The next code 2 is an example of configuration file that uses a local dataset to perform training and inference. { \"task\": \"classification\", \"task_name\": \"mushrroom_classification\", \"method\": { \"strategy_list\": [\"randomForestClassifier\"], \"arguments\": { \"validation_type\": \"SPLIT\", \"validation_percentage\": 0.2, \"random_seed\": 24, \"risk_function\": \"risk_function\", \"performance_metric\": \"accuracy\" } }, \"processing\": { \"arguments\": { \"dataset_name\": \"\" }, \"orders\": [ { \"order\": 1, \"action\": \"train\",3 PMML and ONNX are standardized file formats that facilitate the interchangeability and interoperability of machine learning models between different software tools and platforms. Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 337\"read\": { \"url\": \"~/home/datasets/mushrooms .csv\", \"type\": \"static\", \"source_type\": \"tabular\", \"connector\": { \"name\": \"local\", \"arguments\": {} }, \"input_attributes\": [], \"target_attributes\": [\"class\"], \"from_i\": 0, \"to_i\": 0 } }, { \"order\": 2, \"action\": \"predict\", \"read\": { \"url\": \"~/home/datasets/mushrooms .csv\", \"type\": \"static\", \"source_type\": \"tabular\", \"connector\": { \"name\": \"local\", \"arguments\": {} }, \"input_attributes\": [], \"target_attributes\": [\"class\"], \"from_i\": 0, \"to_i\": 0 } } ] }, \"modelrepo\": { \"url\": \"~/home/model_descriptors/\" } } To specify what kind of operations we want to perform, we create different orders. An order can perform training or inference. We can also specify the columns to use, or leave the field blank if we want to use all of them. At the end of the process, the model output is provided in a different JSON and converted into a standard for future reuse. This file is stored in the directory specified in modelrepo.338 M. Barroso et al.3 System Architecture At the structural level, the component is divided into the following elements depicted in Fig. 1: \u2022 Python RESTful API: It is implemented through a Flask web service. Allows the user to make requests about existing models, tasks, task configurations, and strategies. \u2022 Core functionalities module: It is responsible for implementing the functional-ities of the component. In turn, each step of the AI cycle is implemented as a submodule. \u2022 PostgreSQLDatabase: Relational database that stores information about datasets, tasks, task configurations, strategies, and models in order to reproduce results and keep a history of the models\u2019 evolution. \u2022 Redis and Celery: Celery is a popular asynchronous task queue library in Python that allows for the distribution and execution of tasks across multiple workers. Redis is used as the result backend in Celery, which means it stores the results of completed tasks. After a task is executed by a Celery worker, the result is stored in Redis for retrieval by the Celery client. Fig. 1 High-level architecture of the AMG componentBoosting AutoML and XAI in Manufacturing: AI Model Generation Framework 339\u2022 RabbitMQ broker: It is a robust and feature-rich message broker that implements the Advanced Message Queuing Protocol (AMQP). After configuring the broker, several consumers subscribed to a queue can receive asynchronous messages. In order to establish connection to a specific queue, the configuration of the broker must be set. \u2022 Edge Embedded AI Kit: This component is responsible for the deployment of models. All the models are containerized to enhance portability and scalability allowing their deployment across different platforms, such as local machines, cloud infrastructure, or edge devices. 4 Use Cases In order to validate the component, several use cases have been defined for three pilot partners participating in the project: \u2022 Dairy products company: A constraint optimization model has been implemented for production scheduling. They are interested in predicting the orders to be produced in a week window taking into account working machines, current orders, and product\u2013machine compatibility. \u2022 Manufacturing plastic fuel company: Several anomaly detection models are currently under testing. The goal is to predict anomalies in the production chain using manufacturing and quality data. \u2022 Power transmission and drives company: Using an image dataset, they want to improve the quality of their assembly procedure automatic quality controls and thus reducing the rate of possible failures. Several defect detection models based on CNNs have been implemented. Before testing these models in customer environments, we have the test machine in the LINKS4 infrastructure in order to test these components and to correctly estimate the host specifications. In addition, several configurations have been defined for the deployment of the component along the continuum depending on the pilot needs. We find two kinds of deployments: \u2022 Training cloud-based/inference fog-based: In this scenario, AI models are trained in the cloud infrastructure of the client. This means that the training process, which often involves computationally intensive tasks such as processing large datasets and training complex models, is handled in their remote cloud envi-ronment. Once the model is trained, it is deployed and executed on fog devices or edge nodes for real-time inference in the manufacturing environment. The4 LINKS Foundation operates at the heart of the Turin research and innovation ecosystem, in a solid international network. Its target is to contribute to technological and socio-economic progress through advanced processes of applied research. 340 M. Barroso et al.fog nodes, being closer to the edge devices, are responsible for performing the inference tasks on local data. This deployment scenario offers several advantages. First, cloud-based training allows for the efficient utilization of computational resources and can handle large-scale datasets and complex model architectures. It provides flexibility in terms of accessing various tools, libraries, and computing power required for model development and training. Additionally, centralized management in the cloud simplifies the process of model training, deployment, and updates. This deployment scenario offers several advantages. First, cloud-based training allows for the efficient utilization of computational resources and can handle large-scale datasets and complex model architectures. It provides flexibility in terms of accessing various tools, libraries, and computing power required for model development and training. Additionally, centralized management in the cloud simplifies the process of model training, deployment, and updates. However, there are some drawbacks to this deployment scenario. The latency introduced by transmitting data from fog devices to the cloud for training and then back to the edge for inference may not be suitable for real-time or time-sensitive applications. It also relies on reliable and high-bandwidth network connectivity between the edge/fog devices and the cloud, which may not always be available or practical. Furthermore, fog devices may have limited offline capabilities, as they may not be able to access the latest models or perform updates if they are disconnected from the cloud. \u2022 Training and inference in fog: Both training and inference occur at the fog or edge devices themselves. Fog nodes have sufficient computational resources to handle training tasks, and the trained models are directly executed on the same devices. This scenario offers low latency as data processing and decision-making happen locally, without the need to communicate with the cloud. It also provides offline capability, making it suitable for environments with intermittent connectivity. Furthermore, fog-based deployment enhances privacy and security as sensitive data remain on the local devices, reducing the need to transmit it to external servers. However, the limited computational resources of fog devices can pose challenges for complex and large-scale training tasks. Managing and updating models across a distributed network of edge devices can also be more complex compared to cloud-based deployment. For this reason, techniques such as split learning along with the application of privacy-preserving encryption methods are advisable. By leveraging split learning, the fog devices can benefit from more efficient utilization of their limited resources. The data remain on the edge device, minimizing the need for data transmission and reducing latency. Only the model updates or gradients are transferred between the edge device and the server, significantly reducing the bandwidth requirements. This approach enables fog devices to participate in the training process without being overwhelmed by the computational demands.Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 3415 Core Components The overall logic of model generation can be broken down into the various steps that make up the AI life cycle: data retrieval model (data acquisition), automatic pre-processing module, cost computation module (estimation of training cost for a specific algorithm), automatic hyperparameter tuning module, automatic training, inference and standardization, explainability module (generation of local and global explanations), pipeline execution module (constitutes the main program that calls the rest of modules), and edge embedded AI kit (builds Docker images for model deployment). The implementation of the individual submodules is described in detail in the following sections. 5.1 Data Retrieval Module Data retrieval stage involves the acquisition and collection of relevant data required for training and testing AI models. It is an essential step as the quality and comprehensiveness of the data directly impact the performance and effectiveness of the AI system. Typically, this process in turn includes: data identification, data collection, and data storage. At this point, we assume that the above processes have been performed and the data are ready to be consumed. Accepted data types include tabular data, images, or time series. Different types of connectors are offered to allow the user to upload their data: \u2022 Local data connector: This allows files to be uploaded from the user\u2019s local file system. Files in csv format or training and evaluation directories for image datasets are taken into account. However, it is not mandatory that image directories be pre-partitioned for training, evaluation, and optional validation. If only one directory is uploaded, the component takes care of the partitioning (note that the data are split 70% training, 10% validation, and 20% evaluation). \u2022 Broker connector: This connector is used to get real-time data from other databases, APIs, or sensors through a RabbitMQ broker. The user must format the data into an appropriate MQTT message format, such as JSON or plain text. Then publish the formatted data to the appropriate topic on the RabbitMQ broker. Later, the MQTT clients subscribed to this topic can receive the published data. Only certain topics are currently considered, but the component is easily scalable to add new ones. \u2022 Connector for Edge/Cloud Apache Database: This connector has support for retrieving data from the Apache IoTDB (Database for Internet of Things), an IoT native database with high performance for data management and analysis, deployable on the edge and the cloud. Because of its lightweight architecture, high performance, and rich feature set, as well as deep integration with Apache Hadoop, Spark, and Flink, Apache IoTDB can meet the needs of massive data storage, high-speed data ingestion, and complex data analysis in IoT industrial342 M. Barroso et al.fields. Using the connection details, i.e., IP address, port and login information, data can be easily queried in the form of SQL statements. Once the data are collected, it often requires pre-processing to ensure its quality and usability. This process involves tasks such as removing noise, normalizing, or standardizing variables. Other tasks such as formatting issues, fixing inconsistencies and outliers, and missing value analysis are not performed in this component because the management of missing data and outliers is highly user-dependent and has been handled by other components. 5.2 Automatic Pre-processing Module Overall, the pre-processing stage aims to transform raw data into a clean, structured, and optimized form that is suitable for analysis by AI algorithms. As mentioned above, while data cleaning is out of our scope, our focus is put on data transforma-tion, feature selection, feature engineering, and class imbalance handling. It should be noted that pre-processing is highly dependent on the type of data you are working with. For tabular data, you can choose between normalization and standardization. In addition, label encoding is also applied. For feature selec-tion and engineering, we use the AutoGluon [10] framework, specifically the AutoMLPipelineFeatureGenerator. This pipeline is able to handle most tabular data including text and dates adequately. Pre-processing for image datasets includes, but is not limited to, data augmenta-tion, label encoding, normalization, and rescaling. Since these processes depend on the neural network model to be used, they are only executed after the model has been defined, i.e., before training. This process was implemented using Keras framework. Specifically, it is worth noting that all Keras models with predefined architectures have an in-built method called preprocess_input, which is responsible for pre-processing a tensor or NumPy array representing a stack of images into the right format for the corresponding model. On top of that, data augmentation parameters are defined by the HyperImageAugment class implemented by the KerasTuner.5 Regarding time series data, we have generalized the steps to scaling and data transformation for stationarity conversion. This last step is really important since working with stationary data in time series analysis simplifies the modeling process, enhances interpretability, and ensures reliable and accurate analysis. Time stationarity is tested by applying the adfuller test for each feature. If data are non-stationary, the following transformations are considered: differencing, detrending, moving average, and power transformation. In order to ensure that the previous transformations can be applied, autocorrelation, non-zero mean checking, season-ality, and heteroscedasticity (Breusch\u2013Pagan Lagrange Multiplier test) are tested5 KerasTuner is an open-source Python library that provides a user-friendly and efficient API for hyperparameter tuning of machine learning models built with Keras and TensorFlow. Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 343for each feature. Statistical tests are imported from the stattools module from statsmodels.6 To overcome class imbalance issues when dealing with tabular datasets, we use a combination of over- and under-sampling methods implemented by the library imbalanced-learn [11]: SMOTETomek and SMOTEENN [12]. 5.3 Cost Computation Module This module is responsible for computing the cost of training a model and ensures that executed AI models are running with the desired behavior and performance, providing enough data to expose inefficiencies or poorly managed resources. The cost is computed using the performance and runtime history of previous models trained on the same algorithm. For this purpose, the execution of a number of representative models of the different algorithms was analyzed manually using tools such as Extrae, Paraver, and Dimemas, commonly used in the field of parallel computing and performance analysis. The scalability of each model has been analyzed on four machines with different architectures (MN4,7 CTE-ARM,8 CTE-AMD,9 CTE-Power10 ), and Barcelona Supercomputing Center infrastructure.11 The overall process is depicted in Fig. 2. 5.4 Automatic Hyperparameter Tuning Module The Automatic Hyperparameter Tuning module provides automated methods for finding the best combination of hyperparameters that optimize the performance of machine learning and deep learning models. Hyperparameters are configuration settings that cannot be learned directly from the training data, such as the learning rate, regularization strength, or the number of hidden layers in a neural network, that are involved in the training process. They are not learned from the data but are set6 Stattools is a Python package that provides a collection of statistical tools and functions specifically designed for time series analysis and econometric modeling. 7 MN4 is composed by 2 sockets Intel Xeon Platinum 8160 CPU with 24 cores each @ 2.10 GHz for a total of 48 cores per node 96GB of main memory, 2GB/core, 12x 8GB 2667MHz DIMM. 8 CTE-ARM is composed by A64FX CPU @ 2.20GHz, 32GB of main memory HBM2, 0.7GB/-core. 9 CTE-AMD is composed by AMD EPYC 7742 @ 2.25GHz, 1024GB of main memory distributed in 16 dimms x 64GB @ 3200MHz, 8GB/core. 10 CTE-Power is composed by 2x IBM Power 8335-GTH @ 2.4GHz (3.0GHz on turbo), 512GB of main memory distributed in 16 dimms x 32GB @ 2666MHz, 3.2GB/core. 11 The Barcelona Supercomputing Center (BSC) is a research center located in Barcelona, Spain, dedicated to high-performance computing (HPC) and advanced scientific research. 344 M. Barroso et al.Fig. 2 Overview of the cost computation process by the practitioner or determined through a process called hyperparameter tuning or optimization. However, determining their optimal values can be a time-consuming and computationally expensive process and requires extensive experimentation and testing. AutoML algorithms for hyperparameter tuning automate this process by automatically searching through a predefined range of hyperparameters and selecting the best combination based on performance metrics, such as accuracy or loss. In case of machine learning algorithms, hyperparameter tuning is performed by RayTune library [13]. It allows to tune several machine learning frameworks (PyTorch, XGBoost, Scikit-Learn, TensorFlow, and Keras, etc.) by running state-of-the-art search algorithms such as population-based training (PBT) [14] and HyperBand [15]/ASHA [16]. In addition, RayTune further integrates with a wide range of additional hyperparameter optimization tools. However, it is worth noting that not all optimizers are available for all frameworks and image datasets must be treated as a numpy array without allowing the use of TF.data.Dataset12 or other dynamic objects.12 TF.data.Dataset is a high-level interface for efficient and flexible data loading, pre-processing, and manipulation, making it easier to handle large datasets and build scalable machine learning pipelines with TensorFlow. Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 345The machine learning models included in the component are implemented using the scikit-learn [17] library or similar libraries such as lightgbm [18] and XGBoost [19], reason for which we chose the Tune.Sklearn. According to the type of search, it implements: TuneGridSearchCV (grid search) and TuneSearchCV (random search). The latter with Bayesian search method was preferable to grid search because of its advantages [20]. Bayesian optimization is a method for hyperparameter optimization that uses Bayesian inference to efficiently search for the optimal set of hyperparameters. It is particularly useful when the evaluation of the objective function (e.g., model performance) is time-consuming or computationally expen-sive. After the search algorithm has been defined, the model and the parameter grid with the value range of the hyperparameters to be examined must be passed to the tuner along with other optional parameters, i.e., n_trials (the number of parameter settings tried by the tuner). All machine learning models are encapsulated in a class called SklearnModelBuilder. See Sect. 5.5 for more details. The best set of hyperparameters can be retrieved after fitting the tuner with the call tuner.best_params_. In the case of deep learning models, the difficulty of passing complex data to the Ray tuner led us to use tuners specifically designed for hyperparameter tuning of neural networks, that is, the KerasTuner mentioned above. The tuner manages the hyperparameter search process, including model creation, training, and evaluation. Keras Tuner provides different kind of tunners based on the optimization strategy that is used to select hyperparameters. In addition, some tuners can be combined or aggregated to leverage the strengths of each. In our specific case, we define an instance of BayesianOptimization tuner with the metric to be optimized during (called objective) and the seed. At this point, we will also define the hyperparameters and their parameter space to carry out the search, by means of KerasTunerHyperparameters class. Additionally, we modify the tuner training flow so that we can also fine-tune training-associated hyperparameters such as batch size or epochs. In this flow, the hyperparameters for data augmentation, as implemented by the KerasTuner HyperImageAugment class mentioned before, can also be tuned. After calling the search method, the best selection of hyperparam-eters is retrieved with the call get_best_hyperparameters. Furthermore, it is also possible to obtain the trained model that maximizes the objective using get_best_models call. In the end, both tuners are encapsulated in two different methods of the HyperparameterTuner class: tune_ml and tune_dl. 5.5 Automatic Training, Inference, and Standardization This module builds a model that can make accurate predictions or classifications based on pre-processed data and the optimal choice of hyperparameters. Once a model has been trained, it can be deployed to a production environment where it can process new data and generate predictions or classifications. Models are346 M. Barroso et al.interoperable, and all of them have been wrapped in the convention of Sklearn objects to enable interoperability. Once a model has been trained, it can be directly converted into ONNX or PMML. PMML and ONNX are both model interchange formats that enable the portability and interoperability of machine learning models across different platforms and frameworks. They serve as standard representations for sharing, deploying, and executing machine learning models. PMML is a more general-purpose model interchange format that supports a broader range of predictive models beyond deep learning. It is used for various machine learning algorithms and techniques. ONNX, on the other hand, focuses specifically on deep learning models and their interchange between frameworks. All machine learning models are instantiated within the method _build_model inside the SklearnModelBuilder class. This method passes the best selection of hyperparameters to the model. In order to perform any operation to a machine learning model, an instance of SklearnModelBuilder is created. A SklearnModelBuilder object can execute the following public methods: \u2022 fit: Trains the algorithm using the training dataset. The builder already has defined the best selection of hyperparameters and the name of the algorithm to be trained. \u2022 predict: Executes inferences process on evaluation dataset. \u2022 export: Saves the model into the corresponding standard. \u2022 load: Loads the model from the filename passed as argument. The filename must be a PMML or ONNX file. \u2022 explain_model: Provides insights and explanations behind the model predic-tions or actions, enabling users to trust, validate, and effectively use the model properly. \u2022 explain_instance: Focuses on explaining individual predictions or deci-sions made by the model, providing insights into which features or factors contributed most to a particular output. More information can be found in this matter in Sect. 5.6. Deep learning models are implemented following two approaches. In case the user wants to perform hyperparameter tuning, the training is done according to the process described above. On the contrary, when the set of hyperparameters is initially clear, the system creates an object of the KerasModelBuilder class. All objects of this class have the same format as the objects of the SklearnModelBuilder class. Both classes inherit from the abstract ModelBuilder class. This allows us to keep a more homogeneous format while making the code more intuitive for the user.Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 3475.6 Explainability Generation Module Toward the end of the pipeline, we find the application of Explainable Artificial Intelligence (XAI). Its application is of utmost importance as it addresses key challenges in AI adoption. XAI enhances transparency, fostering trust between users and AI systems by providing insights into the decision-making process. It promotes ethical practices and accountability, ensuring that AI models operate with fairness and avoid biases or discriminatory outcomes. Furthermore, XAI supports compliance with regulatory standards that demand interpretability and explainability. Despite its significance, XAI is often skipped in the AI pipeline due to several factors. These include the complexity of implementing XAI techniques, the focus on achieving high performance without considering interpretability, and the trade-off between model complexity and explainability. Additionally, limited awareness and understanding of XAI among practitioners, along with the perception that explainability compromises predictive accuracy, may contribute to its omission. To overcome these obstacles and motivate its application, explainability is embedded in the model. So it can be run once the model has been trained by calling the methods previously introduced: explain_model and explain_instance. The XAI methods are implemented by the library Dalex [21].13 All the explanations are model-agnostic that allow us to provide information of these models without relying on their internal structure. As an example, the Dalex explainer generates, in a JSON or png format, feature importance analysis and visualizations such as partial dependence plots [22] and accumulated local effects (ALE) [22]. These visualizations offer intuitive representations of the model\u2019s behavior and enable users to explore the relationships between input features and the model\u2019s predictions. In order to explain concrete predictions, the explainer generates visualizations of the SHAP values [23], the ceteris paribus profile, and interactive breakdown plots. Although the number of XAI methods applied may seem sufficient because of the possibilities that Dalex offers, we are considering expanding the explainer further. 5.7 Pipeline Execution Module The above steps are part of the so-called AI life cycle or AI pipeline. To deploy the model later, all these steps are encapsulated in the execute_pipeline method. This method is responsible for receiving the input configuration and creating the appropriate objects to perform data loading, pre-processing, hyperparameter optimization (optional), training and/or evaluation, and explainability (optional).13 Dalex is a Python library designed for model-agnostic explainability in machine learning. It provides a comprehensive set of tools and visualizations to understand and interpret the behavior of machine learning models. 348 M. Barroso et al.As a result of executing the pipeline, a Docker image responsible for deploying the model is generated if it did not previously exist. Afterward, using the image, the container can be created to execute the pipeline by passing it the input configuration. In turn, the pipeline returns a JSON file with the execution result. 5.8 Edge Embedded AI Kit This module is in charge of the model deployment. In this stage, it is assumed that the AI model is available and operational for use in a production environment. After developing and training a model, model deployment involves implementing the model into a system where it can generate predictions or perform specific tasks in real time. The complete AI pipeline can be integrated seamlessly with the existing software or system architecture of the client using Docker images for the deployment. Docker helps to simplify the deployment process, improves flexibility, and ensures consistent and reliable execution of AI models. More precisely, it provides porta-bility, allowing the model to run consistently across different environments without compatibility issues. Overall, there are two types of images, those that are in charge of deploying machine learning models and those for deep learning, both use the Python image as a base but use different dependencies. As endpoint, we use the execute_pipeline method described above. Once the image has been created, it is stored in a private Docker registry. The creation and configuration of the Docker registry must be done by the user. The username, password, and ip address along with the port are part of the configuration of this component. In order to upload and download images, the Edge Embedded AI Kit has an API with push and pull methods, respectively. Those methods have been implemented using the Docker SDK for Python.14 6 Conclusions and Future Work In this chapter, we presented the AI Model Generation (AMG) framework, which enables the creation of AI models for non-experienced users. AMG component has been designed in order to solve general-purpose problems supporting different types of data and allowing the deployment of machine learning and deep learning models. Ensuring the reproducibility of any type of analysis, model results and configuration are saved in a PostgresSQL Database. In addition, model descriptors are generated that allow easy loading and exporting of models by means of standardization (ONNX and PMML). All the models are interoperable, which will allow to add14 Docker SDK is a Python library for the Docker Engine API. It lets you do anything the Docker command does, but from within Python apps\u2014run containers, manage containers, manage Swarms, etc. Boosting AutoML and XAI in Manufacturing: AI Model Generation Framework 349new models or integrate other AutoML systems in the future. Furthermore, it enhances the scalability, promotes the interpretability, and simplifies long-term maintainability of the code. On the other hand, it should be noted that the models are also containerized to ensure that they can be run in any environment. This gives the customer the freedom to transfer the model and use it wherever they want. Explainability is easy to apply, and all models have a set of explanatory techniques that can provide insight into the model\u2019s decision-making process. In that direction, as future work we believe that the platform is easily scalable and a possible research direction would be to analyze the performance of new models and applying new methods of explainability. It would also be worth comparing different search algorithms outside of Bayesian optimization. Additionally, it would make sense to consider new approaches such as Federated Learning (FE)15 and Split Learning (SL)16 in cases where privacy, data distribution, or network restrictions play an important role. However, building a general federated system that can effectively support most of machine learning and deep learning models is challenging due to the inherent heterogeneity of models, varying data distributions, and the need to address communication and privacy concerns. Models used in different domains or tasks have distinct architectures, training algorithms, and requirements, making it difficult to create a single framework that caters to all models. Furthermore, ensuring efficient communication and privacy preservation across participants adds complexity to the design and implementation of a general federated system. Acknowledgments This work has been supported by the H2020 Framework Programme of the European Commission under Grant Agreement no. 957331. References 1. Kinkel, S., Baumgartner, M., Cherubini, E.: Prerequisites for the adoption of AI technologies in manufacturing \u2013 Evidence from a worldwide sample of manufacturing companies. Techno-vation 110, 102375 (2022) 2. Peres, R.S., Jia, X., Lee, J., Sun, K., Colombo, A.W., Barata, J.: Industrial artificial intelligence in industry 4.0 - systematic review, challenges and outlook. IEEE Access 8, 220121\u2013220139 (2020) 3. He, X., Zhao, K., Chu, X.: AutoML: a survey of the state-of-the-art. Knowl. Based Syst. 212, 106622 (2021). ArXiv:1908.00709 [cs, stat] 4. Gohel, P., Singh, P., Mohanty, M.: Explainable AI: current status and future directions (2021). ArXiv:2107.07045 [cs]15 Federated learning is a machine learning approach that enables training models on decentralized data sources while preserving data privacy by keeping the data local and performing model updates collaboratively. 16 Split learning is a distributed machine learning technique where the model is divided into segments, with the initial layers residing on the client device, and the remaining layers processed on a central server, allowing for privacy-preserving and resource-efficient training. 350 M. Barroso et al.5. Real, E., Liang, C., So, D.R., Le, Q.V.: AutoML-Zero: evolving machine learning algorithms from scratch (2020). ArXiv:2003.03384 [cs, stat] 6. Salvaris, M., Dean, D., Tok, W.H., Salvaris, M., Dean, D., Tok, W.H.: Microsoft AI platform. Deep Learning with Azure: Building and Deploying Artificial Intelligence Solutions on the Microsoft AI Platform, pp. 79\u201398 (2018) 7. Das, P., Perrone, V., Ivkin, N., Bansal, T., Karnin, Z., Shen, H., et al.: Amazon SageMaker Autopilot: a white box AutoML solution at scale (2020). ArXiv:2012.08483 [cs] 8. LeDell, E.: H2O AutoML: Scalable Automatic Machine Learning (2020) 9. Singh, V.K., Joshi, K.: Automated machine learning (AutoML): an overview of opportunities for application and research. J. Inf. Technol. Case Appl. Res. 24(2), 75\u201385 (2022) 10. Erickson, N., Mueller, J., Shirkov, A., Zhang, H., Larroy, P., Li, M., et al.: AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data (2020). ArXiv:2003.06505 [cs, stat] 11. Lemaitre, G., Nogueira, F., Aridas, C.K.: Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning (2016). ArXiv:1609.06570 [cs] 12. Batista, G.E.A.P.A., Prati, R.C., Monard, M.C.: A study of the behavior of several methods for balancing machine learning training data. ACM SIGKDD Explorat. Newsl. 6(1), 20\u201329 (2004) 13. Liaw, R., Liang, E., Nishihara, R., Moritz, P., Gonzalez, J.E., Stoica, I.: Tune: A Research Platform for Distributed Model Selection and Training (2018). ArXiv:1807.05118 [cs, stat] 14. Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.M., Donahue, J., Razavi, A., et al.: Population Based Training of Neural Networks (2017). ArXiv:1711.09846 [cs] 15. Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization (2018). ArXiv:1603.06560 [cs, stat] 16. Li, L., Jamieson, K., Rostamizadeh, A., Gonina, E., Hardt, M., Recht, B., et al.: A System for Massively Parallel Hyperparameter Tuning (2020). ArXiv:1810.05934 [cs, stat] 17. Buitinck, L., Louppe, G., Blondel, M., Pedregosa, F., Mueller, A., Grisel, O., et al.: API design for machine learning software: experiences from the scikit-learn project. In: ECML PKDD Workshop: Languages for Data Mining and Machine Learning, pp. 108\u2013122 (2013) 18. Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., et al.: LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In: NIPS (2017) 19. Chen, T., Guestrin, C.: XGBoost: A Scalable Tree Boosting System, pp. 785\u2013794 (2016) 20. Turner, R., Eriksson, D., McCourt, M.J., Kiili, J., Laaksonen, E., Xu, Z., et al.: Bayesian Optimization is Superior to Random Search for Machine Learning Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020 (2021). ArXiv:abs/2104.10201 21. Baniecki, H., Kretowicz, W., Piatyszek, P., Wisniewski, J., Biecek, P.: dalex: Respon-sible Machine Learning with Interactive Explainability and Fairness in Python (2021). ArXiv:2012.14406 [cs, stat] 22. Apley, D., Zhu, J.: Visualizing the effects of predictor variables in black box supervised learning models. J. Roy. Stat. Soc. B (Stat. Methodol.) 06, 82 (2020) 23. Lundberg, S., Lee, S.I.: A Unified Approach to Interpreting Model Predictions (2017) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Anomaly Detection in Manufacturing Jona Scholz, Maike Holtkemper, Alexander Gra\u00df, and Christian Beecks 1 Introduction Consider a machine that performs a simple operation in the production cycle of a product. On a typical day, this machine can perform the same motions over and over, with very little deviation. Then one day, one of its motors develops a problem and does not function properly anymore. As a result, the machine performs its operations incorrectly and damages the product. The longer it continues, the more damages accrue, potentially causing significant losses in damages and production delays. Detecting anomalous behaviors like this is important for quality control and safety. Fortunately with the rise of digitization and advanced analytics, industry has developed automated methods to accomplish just that. We begin this chapter by introducing the concept of anomaly detection in more detail. For this purpose, we summarize different perspectives on that topic. We then discuss statistical methods to detect anomalies. The widely used techniques discussed in this section will offer a solid foundation for detecting anomalies and serve as a starting point for further research. Next, we explore deep learning, a more advanced approach that employs artificial intelligence to detect anomalies. Deep learning has found success in many areas of machine learning including anomaly detection. Here we present a case study from the EU project knowlEdge [3], where an autoencoder was used to detect anomalies J. Scholz (\u0002) \u00b7 M. Holtkemper \u00b7 C. Beecks FernUniversity of Hagen, Hagen, Germany e-mail: jona.scholz@fernuni-hagen.de; maike.holtkemper@fernuni-hagen.de; christian.beecks@fernuni-hagen.de A. Gra\u00df Fraunhofer-Institut f\u00fcr Angewandte Informationstechnik FIT, Schloss Birlinghoven, Sankt, Augustin e-mail: alexander.grass@fit.fraunhofer.de \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_20351352 J. Scholz et al.in a manufacturing process of fuel tanks. The autoencoder architecture is explained in depth and further illustrated by the case study. Finally, we stress the importance of human involvement in the anomaly detection process. While AI has many capabilities, humans are essential in interpreting the results, refining the models and making informed decisions. 2 Anomaly Detection in Industry As digitization progresses, the desire of manufacturing companies for more trans-parency about their machine and plant landscape is increasing. Once the data are available, suitable processes are needed to gain a deeper insight into the production processes. With the help of data and process analysis, irregularities and occurring disturbances in the production process flow can be viewed and analyzed in detail. These irregularities are referred to as anomalies, although there is no standard definition of the term in the literature [8]. For example, Zheng et al. [24] define an anomaly as \u201ca mismatch between a node and its surrounding contexts,\u201d Lu et al. [13] as a \u201cdata object that deviates significantly from the majority of data objects\u201d, and Su et al. [18] as an \u201cunexpected incidence significantly deviating from the normal patterns formed by the majority of the dataset.\u201d Anomalies can be further specified depending on the context, such as described in Hasan et al. [10], where anomalies that occur in IoT datasets are divided into eight classes: Denial of Service (DoS), Data Type Probing (D.P), Malicious Control (M.C), Malicious Operation (M.O), Scan (SC), Spying (SP), Wrong Setup (W.S), and Normal(NL). Wu et al. [23], on the other hand, classify the anomalies that occur into three types that are more descriptive in nature, namely punctual, contextual, and collective anomalies. Here, a punctual anomaly represents a specific reference point with anomalous information, a collective anomaly characterizes a set of data records that have an anomalous character compared to the other data collected, and a continuous anomaly, which is a collective anomaly whose considered time period extends from a specific starting point to infinity [8]. The occurrence of anomalies can have many reasons. One common reason represents a change in the environment, such as a sudden increase in temperature, which is considered an abnormal condition by the sensor [8]; another reason may simply be due to a sensor error [8]; or it may be a malicious attack intended to weaken the computing power of an IoT network and thus intentionally cause the sensor to malfunction [15]. With the help of machine learning (ML) tools for anomaly detection, a variety of algorithms and methods are available to enterprises to identify anomalies [14]. Agrawal and Agrawal [2] divided the process of anomaly detection into three major phases, as shown in Fig. 1. Here, parameterization describes the preprocessing of data into a previously defined acceptable format, which in turn serves for the further training phase. In this, a model is created based on the normal or abnormal behavior of the system. Depending on the type of anomaly detection considered,Anomaly Detection in Manufacturing 353Fig. 1 Methodology of anomaly detection different methods can be chosen, which can be either manual or automatic. The last phase is the detection phase, where finally the model is compared with the parameterized datasets. For example, if a predefined threshold is exceeded, an alarm can be triggered to draw attention to the anomalies. Toshniwal et al.  [21] further elaborate on the basic idea of ML algorithms. According to them, ML algorithms require input data for training, and in turn output labels are generated for test instances, where each feature represents a dimension. The input data represent the batch or real-time data of the data instances, where each data instance can be considered as a data point. Depending on the type of data, the input data are tagged or untagged. The output of the algorithm in turn has classes with which the instances are associated. Clustering is used as one method for anomaly detection. For this, data are divided into groups of similar objects, where each group (cluster) consists of objects that are similar to each other and can be distinguished from objects in other groups [4]. Various clustering methods [1] can be used for anomaly detection, including partitional methods such as k-means or probabilistic methods such as EM. In addition, outlier detection algorithms find patterns in data that do not follow a specific behavior. There are a variety of outlier detection schemes, such as the distance-based approach [4]. This is based on the nearest-neighbor algorithm and uses a distance-based metric to identify outliers [19]. Another possibility for the identification of anomalies is based on classification, which describes the problem of identifying the category of new instances based on a classification model learned on a training dataset that contains observations354 J. Scholz et al.of known memberships of categories. The category represents the class label, and different observations may belong to multiple class labels. In machine learning, clas-sification is considered an instance of supervised learning. An algorithm that resorts to the method of classification is called a classifier. It can predict class labels and distinguishes between normal and abnormal data in the case of anomaly detection [2]. Well-known classification methods form the Classification Tree, Fuzzy Logic, Na\u00efve Bayes network, Genetic Algorithm, and Support Vector Machines. The Classification Tree is also called decision tree because it resembles the structure of a flow chart. Here, the internal nodes form a test property, each branch represents the test result, and the leaves represent the classes to which an object belongs [22]. Fuzzy Logic, derived from fuzzy set theory, deals with approximate inference. In this method, data are classified using various statistical metrics and classified as normal or abnormal data according to the Fuzzy Logic rules [12]. The Na\u00efve Bayes network is based on a probabilistic graph model where each node represents a system variable and each edge represents the influence of one node on another [2]. The Genetic Algorithm belongs to the class of Evolutionary Algorithms and generates solutions to optimization problems based on techniques inspired by natural evolution such as selection and mutation. The Genetic Algorithm is particularly robust to noise and is characterized by a high anomaly detection rate [12]. A Support Vector Machine (SVM) is a supervised learning method used for classification and regression. It is more widely used especially in the field of pattern recognition. A one-class SVM is based on examples that belong to a specific class and do not include negative examples [20]. 3 Feature Selection and Engineering As with all machine learning methods, feature selection plays an important role in anomaly detection. One important category of features in the context of manu-facturing is sensory data from monitoring systems. For example, the operation of a robotic arm might create measurable vibrations during motor operations [16]. These vibration data could be used in the process of detecting anomalous behavior, which might act as a trigger to perform maintenance on the arm. The importance of feature selection comes from the fact that irrelevant features can lead to decreased performance of the model. In addition, the computational complexity and data storage costs increase with the number of features. When developing models for feature detection, a large chunk of development time will typically be allocated to the selection and transformation of features. Not all data can readily be used by a model. Continuing the example of our robotic arm, there may be noise in the data from other vibrations or inaccurate measurements. In these cases, we may have to preprocess or engineer features. This could involve running a noise filter on our vibration data to produce a clearer signal. However, it may also be the case that there is hidden information unavailable to theAnomaly Detection in Manufacturing 355model due to a lack of complexity in its architecture. In the example of our robotic arm, performing frequency analysis leads to engineered features that may be more informative for a given model. 4 Autoencoder Case Study In this case study, we will take a look at a real manufacturing process from an industry partner in the knowlEdge project. KnowlEdge is an EU project funded by the Horizon2020 initiative that advances AI powered manufacturing processes and services [3]. The scenario described here represents the production of fuel tanks for combustion engines in cars. More precisely, it defines the blow molding procedure during tank manufacturing, which is subject to a variety of individual steps controlled and observed by high-precision sensors for different metrics such as temperature, position, and energy consumption. In Fig. 2, we see an overview of the blow molding process as exemplified by a water bottle. Essentially, it involves melting plastic and forming it into a preform, which resembles a test tube with a threaded neck. This preform is then placed into a mold cavity and air is blown into it, forcing the plastic to expand and take the shape of the mold. Once the plastic has cooled and solidified, the mold is opened and the finished bottle is ejected. This process can be highly efficient, allowing for the mass production of objects with consistent shapes and properties. Unfortunately, as blow molding of complex shapes is a very sensitive process, not every production cycle is successful, and produced tanks can show defects indicated Fig. 2 An illustration of the blow molding process. The plastic is melted and shaped into a tube-like preform. The preform is then placed in a mold, inflated with air to take the mold\u2019s shape, and cooled. Once solidified, the finished bottle is ejected from the mold356 J. Scholz et al.by quality measures out of tolerance. To reduce these erroneous cycles already in early stages and thus to decrease additionally emerging costs, we will present a solution for anomaly detection that was implemented during the project. Although in this context different kinds of detection methods were considered including supervised approaches for already identified anomalous behaviors, in the following, we will focus on autoencoders [9] as a representative method for unsupervised anomaly detection that is applicable to a large quantity of potential use cases. 4.1 Autoencoders An autoencoder is a neural network architecture that encodes and decodes data to learn a compact and efficient representation. For simplicity, imagine a neural network with several layers that simply tries to output whatever was put in (identity function). This is of course a non-challenging task for small datasets, if the layers in-between are big enough to maintain all the information. But what if you need a representation of many individual data instances? Since learning every instance is too complex for large datasets, the idea of autoencoders is to find a reduced description that generalizes well for big data, while still maintaining the essential information to reproduce given inputs. Considering the aforementioned architecture of a multi-layered neural network (as illustrated in Fig. 3), autoencoders split up the propagation of information into an encoder and decoder part. In the encoder, information generally flows through to a chain of shrinking layers with a final layer that equals a bottleneck to encode and therefore to learn a compressed version of the data. Subsequent layers, representing the decoder, are responsible to restore information from the generated encoding. The accuracy of the model is given by the reconstruction error, which is defined as a measure on how much the original data differ from its compressed approximation constructed via a propagation through the learned encoding. Fig. 3 A simplified example of an autoencoder with 1 hidden layer. There are fewer neurons in the middle than at the start and the end. This forces the model to learn a compressed representation of the dataAnomaly Detection in Manufacturing 3574.2 Anomaly Detection for Blow Molding The original task of fuel tank manufacturing comprises many steps including continuous and cyclic sub-processes such as extrusion or blow molding. Focusing on the cyclical blow molding process, more than 100 associated data attributes were analyzed. Attributes mainly corresponded to predefined and observed values for machine positions, temperatures, energy consumption, and pressures. As this information is recorded over time, the problem becomes a multivariate anomaly detection task for timeseries data. To better capture the inherent structure of timeseries data, a specific variant of autoencoders was utilized, called Long-Short-Term-Memory Autoencoders (or LSTM-Autoencoders) [11]. In the first step, all relevant process information was assigned to its associated machine cycle\u2014 indicated by a combination of two binary machine events\u2014to produce input data for model training and evaluation. The resulting dataset is then used to learn a compressed representation of individual machine cycles. Since autoencoders are used to find a suitable representation of the provided information, the model tries to find an encoding, which reflects essential cycle information. With anomalies being defined as rarely occurring events, it makes use of the fact that a deviation from common behaviors is not regarded as characteristic information. As explained in the previous section, this deviation leads to higher reconstruction errors for cycles not following the usual patterns. A problem with unsupervised models is the lack of a ground truth. While theoretically one can try to make the model more and more complex to capture different behaviors of a system, the goal is not to consider anomalies as rare, but valid data entries. However, the question remains: how do we draw a line to distinguish which reconstruction errors indicate an anomaly and which do not? One potential solution, which was also used in the presented approach, is to make use of probability distributions\u2014usually the normal distribution\u2014to estimate the distribution of the reconstruction error for each data attribute. As a result, the reconstruction error can be compared against a predefined threshold derived from the overall dispersion, e.g., errors that are higher than three times the standard deviation. This simple method also regularizes the accuracy, as a poorly fitted model automatically leads to an increase in the overall reconstruction error and the associated spread. A representative illustration is given in Fig. 4. It  shows individual machine cycles during a blow molding process, including modeled approximations and identified anomalies based on exceeded thresholds with respect to the reconstruction error. 4.3 Human-Enhanced Interaction The lack of a ground truth, as is the case for unsupervised anomaly detection, leaves room for further enhancements to improve the accuracy of the system. One solution is to integrate expert feedback, also known as \u201chumans-in-the-loop.\u201d A domain-358 J. Scholz et al.Fig. 4 A snippet from the original process data showing 5 attributes including identified anoma-lies. Each row presents a different attribute over time, with the original signal shown in black. Differently colored lines indicate distinct cycle approximations generated from the autoencoder (reproduced signals). Highlighted by the red-shaded rectangles, two cycles are regarded as anomalies, since for one or more dimensions, the reconstruction error is too high specific verification of generated results enables us to label former predictions and to subsequently reuse this information as input for supervised approaches. In addition, human feedback can help to fine-tune predefined thresholds for the reconstruction error. If a domain expert notices that the approach detects too many false-positives (i.e., the number of identified anomalies, which are not anomalies according to the expert), thresholds for associated attributes can be reduced. The same holds for the opposite case, where the sensitivity of the system might be increased if no anomalies can be identified, although a manual inspection would reveal existing anomalies. Further information on how human feedback enhances approaches for unsupervised anomaly detection can be found in the literature [5\u20137, 17]. 5 Conclusions In the fifth industrial revolution, human-centered AI (HCAI) is becoming a key part of manufacturing processes. Anomaly detection can be used to improve quality con-trol and elevate the human operator. There are several machine learning approaches to detect anomalies. Some of the methods we discussed are clustering, which groups similar data objects, and classification, which categorizes new instances based on known categories. In the scope of the EU project KnowlEdge, we have used autoencoders to detect manufacturing flaws in the production of fuel tanks. We have seen in detail how autoencoders work and how they efficiently solve the problem of anomaly detection for large datasets. The involvement of human expertise, or \u201chumans-in-the-loop,\u201d is crucial for improving model performance and managing false-positive detections. Acknowledgments This work has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under grant agreement No. 957331\u2014KNOWLEDGE.Anomaly Detection in Manufacturing 359References 1. Aggarwal, C.C., Reddy, C.K. (eds.): Data Clustering: Algorithms and Applications. CRC Press (2014) 2. Agrawal, S., Agrawal, J.: Survey on anomaly detection using data mining techniques. Procedia Comput. Sci. 60, 708\u2013713 (2015). Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings 3. Alvarez-Napagao, S., Ashmore, B., Barroso, M., Barru\u00e9, C., Beecks, C., Berns, F., Bosi, I., Chala, S.A., Ciulli, N., Garcia-Gasulla, M., et al.: Knowledge project\u2013concept, methodology and innovations for artificial intelligence in Industry 4.0. In: 2021 IEEE 19th International Conference on Industrial Informatics (INDIN), pp. 1\u20137. IEEE (2021) 4. Berkhin, P.: A survey of clustering data mining techniques. Grouping Multidimensional Data: Recent Advances in Clustering, pp. 25\u201371 (2006) 5. Chai, C., Cao, L., Li, G., Li, J., Luo, Y., Madden, S.: Human-in-the-loop outlier detection. In: Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data, pp. 19\u201333 (2020) 6. Chawla, A., Jacob, P., Farrell, P., Aumayr, E., Fallon, S.: Towards interpretable anomaly detection: Unsupervised deep neural network approach using feedback loop. In: NOMS 2022\u2013 2022 IEEE/IFIP Network Operations and Management Symposium, pp. 1\u20139. IEEE (2022) 7. Das, S., Wong, W.-K., Dietterich, T., Fern, A., Emmott, A.: Incorporating expert feedback into active anomaly discovery. In: 2016 IEEE 16th International Conference on Data Mining (ICDM), pp. 853\u2013858. IEEE (2016) 8. DeMedeiros, K., Hendawi, A., Alvarez, M.: A survey of AI-based anomaly detection in IoT and sensor networks. Sensors 23(3), 1352 (2023) 9. Goodfellow, I., Bengio, Y., Courville, A.: Deep Learning. MIT Press (2016) 10. Hasan, M., Islam, M.M., Zarif, M.I.I., Hashem, M.: Attack and anomaly detection in IoT sensors in IoT sites using machine learning approaches. Internet Things 7, 100059 (2019) 11. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural Comput. 9(8), 1735\u20131780 (1997) 12. Kaur, H., Gill, N.: Host based anomaly detection using fuzzy genetic approach (FGA). Int. J. Comput. Appl. 74(20), 5\u20139 (2013) 13. Lu, J., Wang, J., Wei, X., Wu, K., Liu, G.: Deep anomaly detection based on variational deviation network. Fut. Internet 14(3), 80 (2022) 14. Ma, X., Wu, J., Xue, S., Yang, J., Zhou, C., Sheng, Q.Z., Xiong, H., Akoglu, L.: A comprehensive survey on graph anomaly detection with deep learning. IEEE Trans. Knowl. Data Eng. (2021) 15. Ngo, Q.-D., Nguyen, H.-T., Tran, H.-A., Pham, N.-A., Dang, X.-H.: Toward an approach using graph-theoretic for IoT botnet detection. In: 2021 2nd International Conference on Computing, Networks and Internet of Things, pp. 1\u20136 (2021) 16. Sharp, M.: Observations on developing anomaly detection programs with case study: Robotic arm manipulators 2019-02-13 2019 17. Smits, G., Lesot, M.-J., Yepmo Tchaghe, V., Pivert, O.: PANDA: Human-in-the-loop anomaly detection and explanation. In: Information Processing and Management of Uncertainty in Knowledge-Based Systems: 19th International Conference, IPMU 2022, Milan, Italy, July 11\u2013 15, 2022, Proceedings, Part II, pp. 720\u2013732. Springer (2022) 18. Su, Y., Zhao, Y., Niu, C., Liu, R., Sun, W., Pei, D.: Robust anomaly detection for multivariate time series through stochastic recurrent neural network. In: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD \u201919, pp. 2828\u20132837, New York, NY, USA, 2019. Association for Computing Machinery 19. Syarif, I., Prugel-Bennett, A., Wills, G.: Unsupervised clustering approach for network anomaly detection. In: Networked Digital Technologies: 4th International Conference, NDT 2012, Dubai, UAE, April 24\u201326, 2012. Proceedings, Part I 4, pp. 135\u2013145. Springer (2012)360 J. Scholz et al.20. Tang, H., Cao, Z.: Machine learning-based intrusion detection algorithms. J. Comput. Inf. Syst. 5(6), 1825\u20131831 (2009) 21. Toshniwal, A., Mahesh, K., Jayashree, R.: Overview of anomaly detection techniques in machine learning. In: 2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), pp. 808\u2013815 (2020) 22. Wu, S.-Y., Yen, E.: Data mining-based intrusion detectors. Expert Syst. Appl. 36(3), 5605\u2013 5612 (2009) 23. Wu, Y., Dai, H.-N., Tang, H.: Graph neural networks for anomaly detection in industrial Internet of Things. IEEE Internet Things J. 9(12), 9214\u20139231 (2021) 24. Zheng, Y., Jin, M., Liu, Y., Chi, L., Phan, K.T., Chen, Y.-P.P.: Generative and contrastive self-supervised learning for graph anomaly detection. IEEE Trans. Knowl. Data Eng. (2021) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches Eduardo Vyhmeister and Gabriel Gonzalez Castane 1 Introduction The industrial sector has evolved from mechanization and steam power to mass pro-duction and automation, known as Industry 4.0. This digital revolution incorporates technologies such as Additive Manufacturing, Internet of Things (IoT), Edge and Cloud computing, Simulation, Cyber-Security, Horizontal and Vertical Integration, and Big Data analysis for efficient task execution [1]. To prioritize resilience, societal well-being, and economic growth, the European Commission (EC) introduced Industry 5.0, aiming to transform traditional factories into resilient providers of prosperity [2]. Artificial Intelligence (AI) plays a crucial role in this transition, helping in automating and getting insight in large-scale production and customization. Building user confidence in AI products is essential, achieved through risk mitigation and facilitating AI technology adoption. Trustworthy AI (TAI) and human-centric AI integration are key challenges that need to be addressed [3]. Human-centric AI focuses on optimizing performance while prioritizing human needs, improving working conditions, and fostering a sustainable and socially responsible industrial ecosystem. We provide an overview of the transition from Industry 4.0 to Industry 5.0, highlighting the use of AI and advanced technologies to create sustainable, human-centric, and resilient industries. It explores the challenges and opportunities of adopting TAI, offering strategies to mitigate risks and promote effective adoption. The presented strategies for risk mitigation in TAI assets align with established approaches in the industry, particularly the Process of Risk Management (PRM) E. Vyhmeister (\u0002) \u00b7 G. G. Castane The Insight SFI Research Centre of Data Analytics, University College Cork, Cork, Ireland e-mail: eduardo.vyhmeister@insight-centre.org \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_21361362 E. Vyhmeister and G. G. Castanebased on the ISO 31000 standard. Combining these approaches, we propose the TAI-PRM framework. The framework is designed to meet current and future regulatory requirements for AI, with specific goals that include: \u2022 To support management units and developers in incorporating trustworthy requirements within the AI life cycle process. \u2022 To secure the use of AI artefacts independently of legal and technical changes. The legislation heterogeneity applied in different countries on the use of AI can be varied; therefore, flexibility is key. \u2022 To ease the combination of the frameworks that handle ethical-driven risks with other approaches commonly used for PRM. It needs to be designed as a complementary asset to these used by the industry and not a replacement to facilitate its adoption. \u2022 To facilitate an iterative process to handle risks on AI artefacts within the frame-work. Many processes in software do not follow sequential development but spiral/iterative development processes. Therefore, the framework must flexibly adapt to any development cycle applied by developers for its incorporation. \u2022 To ensure that Key Performance Indicators (KPIs) can be tracked through well-defined metrics that register the progress on the identified risks handling. Tracking KPIs is essential for their daily operations and business units. In addition, managerial levels can use these indicators to understand the impact of incorporating ethical aspects. \u2022 To construct an architecture that addresses personal responsibilities and channels of communication. With this aim, the framework must foster communication between technical and non-technical stakeholders. \u2022 To foster the reuse of outcomes in other research areas and market segments to avoid duplication of effort. This is translated as savings in revenue and research time on future developments. In addition, well-structured risk identification can avoid the repetition of failing conditions on AI components with similar target objectives. \u2022 To enable a seamless path for the transition to Industry 5.0. By linking ethical considerations and risks, companies can handle TAI requirements as a PRM. \u2022 To provide users with a tool for performing the TAI-PRM and evaluate approaches already developed for TAI. 1.1 Understanding the Transition to Industry 5.0 Industry 4.0 incorporates cyber-physical systems and digital platforms into factories to improve production processes and decision-making [4]. Different technologies have helped shape this industrial revolution. The impact of these technologies extends beyond industry, including home products, business models, clean energy, and sustainability, surpassing those of previous industrial revolutions. Industry isTowards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 363recognized as a driving force for sustainable transformation, necessitating consider-ation of societal and environmental aspects [5]. Previously, technologies focused on economic optimization, neglecting sustain-able development. To address this, there is a growing demand for a shift to circular economies, prioritizing well-being, social governance, environmental efficiency, and clean energy. In 2020, the EC organized a workshop that gave rise to the concept of Industry 5.0. This vision, incorporated in industry\u2019s future roadmap, combines AI and the societal dimension as enablers [6]. Industry 5.0 entails integrating technologies to optimize workplaces, processes, and worker performance, emphasizing collaboration between humans and machines instead of replacing one another. This human-centric approach promotes the devel-opment of technologies that enhance human capabilities. To promote the adoption of Industry 5.0, the EC has established initiatives like the Skills Agenda and the Digital Education Action Plan, aiming to enhance the digital skills of European workers [7, 8]. The Commission also seeks to boost industry competitiveness by accelerating investments in research and innovation, as outlined in the Industrial Strategy [9]. Environmental sustainability is a key consideration for the EC, which promotes the use of resources efficiently and the transition to a circular economy through supporting initiatives such as the Green Deal [10]. Additionally, to promote a human-centric approach, initiatives and regulations have been developed that include the Artificial Intelligence Act, the White Paper on Artificial Intelligence, and the Trustworthy requirements [11\u201313]. Industry 5.0 introduces new challenges and technological enablers. These include real-time decision-making, human-centric solutions, edge computing, and trans-parency. Managing approaches and AI techniques can support and drive these advancements. Meanwhile, challenges from Industry 4.0, such as security, financ-ing, talent, data analytics, integration, and procurement limitations, remain relevant [14, 15]. In terms of technological enablers, different approaches have been recognized, which includes Individualized Human\u2013Machine Interaction, Bio-Inspired Technolo-gies and Smart Materials, Digital Twins and simulation, Data Transmission, storage, and analysis technologies, AI, and Technologies for Energy Efficiency, Renewable, Storage, and Trustworthy Autonomy [16, 17]. 1.2 AI, Trustworthy AI, and its Link to Industry 5.0 Industry 5.0 builds upon Industry 4.0, integrating ethical considerations for AI assets while prioritizing humans. It aims to promote societal well-being through the collaboration of humans and machines in smart working practices. Ethical concerns in AI vary across domains and application types, with unique considerations. Trust development emerges as a common challenge, crucial for instilling confi-dence among users. The EC emphasizes TAI as a foundational ambition, acknowl-364 E. Vyhmeister and G. G. Castaneedging the significance of trust in advancing AI and establishing a robust framework [18]. Ensuring trustworthiness becomes imperative in AI technology, as reliable interactions between AI agents and humans are essential [19]. AI technology providers must address risks related to performance and user impact, emphasizing collaboration between AI-driven systems and humans, considering transparency, reliability, safety, and human needs, to foster user acceptance [20]. The interaction between humans and AI in manufacturing can be categorized into three types (human-in-the-loop HITL, human-on-the-loop HOTL, and human-in-command HIC), depending on the level of human involvement. Importantly, the decisions made by these systems can be influenced by humans and data, thus impacted by societal, legal, and physical considerations. According to the High-Level Expert Group set up by the EC [21], TAI has three main pillars, which should be met throughout the system\u2019s entire life cycle: it should be lawful, ethical, and robust. To deem an AI Trustworthy, different requirements must be addressed, depending on the intrinsic risk of the AI assets. These require-ments are related to Human Agency and Oversight, Technical Robustness and Safety, Privacy and Data Governance, Transparency, Diversity, Non-discrimination, and Fairness (DnDF), as well as Environmental and Societal Well-being, and Accountability. The Trustworthy requirements [13] aim to minimize risks associated with AI and its potential adverse outcomes throughout the AI life cycle. These requirements align with five key principles derived from 84 ethics guidelines: transparency, justice and fairness, non-maleficence, responsibility, and privacy. They ensure that AI systems respect fundamental rights, are secure and reliable, protect privacy and data, are transparent and explainable, avoid bias, promote stakeholder participation, and are subject to accountability mechanisms. 1.3 PRM and Considerations for AI Implementation In a 2020 study, Hagendorff [22] provides guidelines and strategies for addressing critical AI issues, focusing on areas of greatest attention. However, the study lacks specific definitions for handling AI assets throughout their life cycle [23]. Moreover, the implementation of these approaches in different domains and environments can present specific challenges that need to be understood [20]. Different organizations have developed diverse methods based on multiple ethical principles to facilitate practitioners in developing AI components. These organizations include academia, trade union, business, government, and NGOs. To ensure a trustworthy component, the actions of any agent over humans must be reliable [19]. This definition depicts the linkage between trust and risk management, in agreement with the definitions in the EC AI Act [11]. By defining a proper methodology that tracks and manages risk components derived from trustworthy requirements, the probability of producing adverse outcomes is minimized. Developing a framework that ensures the ethical use of AI while minimizing potential harms and maximizing benefits requires a comprehensive approach. HowTowards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 365can such a framework be implemented in the manufacturing sector, considering existing approaches? PRM involves identifying, assessing, and controlling risks that can impact systems and organizations. Integrating ethical considerations into PRM processes requires defining the concept of ethical risks (E-risks). We propose the following definition: \u201cE-risks are conditions and processes that can disrupt the expected behaviour of an AI asset due to the lack of consideration of TAI requirements, including values, social, legal, environmental, and other constraints.\u201d The PRM involves intervention, communication, and involvement of various areas within the managing companies. A risk management framework consists of three key components: Risk Architecture (RA), Strategy (S), and Protocols (P), forming the RASP strategy. RA provides a formal structure for communication and reporting, S defines implementation strategies, and P includes guidelines and procedures for managing risks [24]. The risk management policy statement plays a crucial role in the framework. It outlines the organization\u2019s strategy and approach to PRM, aligned with its objectives and tailored to the specific environment. However, when establishing enterprise policies for AI management, minimal considerations may exist due to regulatory requirements, such as the Artificial Intelligence Act [11], which may influence the policy\u2019s content. ISO 31000 is widely used as a standard for PRM in industry. It provides procedures for assessing, treating, monitoring, reviewing, recording, and reporting risks. ISO 31000 is often combined with other specific standards, such as ISO 9001 for supply chain and product quality improvement [25] and ISO/AWI23247 for the digital twin manufacturing framework [26]. However, these standards need to be reviewed and updated to align with the requirements of smart manufacturing and Industry 5.0 [27]. Although ISO 31000 does not explicitly address application security risks or pro-vide guidance on implementing RASP controls, organizations adopting the RASP framework can benefit from considering ISO 31000 principles and guidelines. ISO 31000 promotes a systematic and proactive approach to PRM, which complements the objectives of the RASP framework. The TAI-PRM adheres to ISO 31000 and adopts a RASP approach [28, 29]. TAI-PRM provides a supporting structure for communication and reporting of failures, implementation strategies, and guidelines for managing risks. In this chapter, we focus on developing and testing the protocols for the PRM, based on ISO 31000 with some considerations. The communication and consultation activities are part of the RASP architecture, not the PRM itself, and the Ethical PRM includes the Monitoring and Review process as a primary component after Risk Evaluation and Risk Treatment. The mentioned works [28, 29] provide a scope contextualization for understand-ing the PRM and evaluation, as well as a groundwork for AI development and management, establishing connections between requirements and risk components.366 E. Vyhmeister and G. G. Castane2 Failure Mode and Effects Analysis The Failure Mode and Effects Analysis (FMEA) method is commonly used for risk assessment in various industries, including the technology sector. When it comes to assessing risks derived from TAI considerations, the FMEA method can be an effective tool for several reasons: \u2022 Holistic approach: The method can be applied on the entire system, rather than just focusing on individual components. This aligns with the principles of TAI, which emphasizes a comprehensive approach to ethical and technical considerations. \u2022 Identifying potential hazards: TAI requires identifying potential hazards, assess-ing their likelihood and impact, and taking steps to mitigate them. The FMEA method provides a structured framework for this, helping also to uncover hidden hazards. \u2022 Systematic approach: The method involves a systematic approach to risk assess-ment, helping to ensure that risks are addressed in a consistent and comprehen-sive manner, which is critical for TAI. \u2022 Continuous improvement: The FMEA method is designed to be an iterative process. This aligns with the principles of TAI, which emphasize the need for ongoing monitoring and continuous improvement to ensure that AI systems remain ethical, transparent, and accountable over time. The key steps of the FMEA are outlined next. These steps should be performed consecutively with the exception of the Identify Failure, Detection Methods, and Existing Risk Control; Analyse Effects; and Identify Corrective Actions: Define the Analysis Developing TAI systems involves defining constraints, fail-ures, and objectives while considering the system\u2019s context. Trustworthy require-ments, including explainability, are outlined in the AI Act [11]. Adapting these requirements to the industrial context and AI asset goals is crucial. Methods for achieving TAI depend on functionalities, data usage, user understanding, and objectives [11]. Development of System Functional Block Diagrams Various supporting docu-ments, including block diagrams, analyse failure modes, and their impact. Detail level should correspond to the AI asset\u2019s risk level, with worksheets and matrices as valuable tools. Additional information such as system and AI boundary descriptions, design specifications, safety measures, safeguards, and control system details are necessary for risk analysis. Identify Failure Modes Identifying failure modes is crucial in understanding system failures. Certain failure modes align with the needs of TAI-PRM have already been identified. For instance, [30] define failure modes in IT safety. FMEA has been applied to TAI with limited success, focusing mainly on fairness [31]. To expand the scope of failure modes, we propose incorporating eleven ethical-based failure families derived from system norms and TAI requirements. TheseTowards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 367encompass failures related to robustness, safety, transparency, accountability, soci-etal well-being, environmental well-being, human agency and oversight, privacy, data governance, bias (DnDF), and users\u2019 values. This approach facilitates detection and metric definition. Identifying failure modes involves measuring observable conditions using sup-porting protocols. We propose to group the conditions based on drivers such as physical, social, data, user/system interface, and algorithms. Physical drivers include power supply, communication/data link cables, robot parts, wearables, lenses, and sensors. Internal social drivers relate to stakeholders\u2019 values and biases, including social responsibilities and ethics-in-design. Data drivers encompass sources affect-ing AI trustworthiness, such as biases, quality, quantity, and security. User and system interface drivers are linked to inadequate usage, absence of information display, tutorials, guidelines, and user\u2019s ill-intentioned usage. Algorithm drivers include problem-solving processes and expected functionality during AI code execution. Identify Failure, Detection Methods, and Existing Risk Control Detecting and managing failure modes using metrics and methods to reduce risk conditions. Adequate intervention procedures are needed for high-risk AI components. Linking further actions, such as control devices and circuit breakers, is crucial to enhance system understanding and reduce risk. A lack of detection methods could affect system robustness, security, and transparency. The importance of these actions should be linked to the intrinsic risk level of the AI assets involved. Analyse Effects This step analyses the consequences of failure modes, including the end effect and its impact on social-driven components and each HSE (Health, Safety, and Environment) element. Identify Corrective Actions Involves identifying actions that can prevent or reduce the likelihood of failure, comply with legal requirements, ensure safe operation of the system, recover from failures, and incorporate norms based on user values and AI trustworthiness requirements. Ranking Assigns values to each failure mode\u2019s likelihood, severity, and detectabil-ity, which can be used as KPIs for estimating the TAI state.1 The Risk Priority Number index (RPN) with respect to a concrete failure mode enables the normal-ization of the AI artefacts risks. The RPN mathematical expression is . RPNitem =S \u00b7 O \u00b7 D. Here  S is the severity (scale of 1\u201310, with 10 being the most severe), O the occurrence or likelihood (scale of 1\u201310, with 10 being the most likely), and D corresponds to the detection ranking (scale of 1\u201310, with 10 being the least capable). The RPN indicates the risk level of the failure mode, with a higher RPN indicating, indirectly, a higher risk for the AI component.1 More information and tables for the ranking process are available on a GitHub page https://github. com/lebriag/TAI-PRM/tree/main/Support/RPN%20ranking%20tables. 368 E. Vyhmeister and G. G. CastaneTo evaluate the overall risk of an AI component on different failure modes, the Global Risk Priority Number index (.GRPNitem) can be calculated by summing the RPN of each item i to its corresponding failure mode ratio; . GRPNitem =\u2211ni=1 RPNi\u03b1i . In this equation, i represents the different Failure Modes linked to the same source; n is the number of failure modes of a specific component; and . \u03b1iis the failure mode ratio and represents the part attributed to a concrete failure mode if the failure materializes. This means the percentage of the AI asset to fail with the specific Failure Mode. The Failure Mode Ratio can be estimated as .\u03b1i = eietot . . ei is the amount of failing conditions of a specific failure mode, and .etot is the total amount of all failing conditions in the system. The failure mode ratio can be used to group risks with the same trustworthy requirement, by a proper weighting, thus identifying the most significant TAI risk consideration for the AI asset. Tabulate and Report The report includes documentation and a repository for users to understand failure modes, risks, control measures, safeguards, and recommenda-tions. 3 TAI\u2013PRM Protocol An overview of the TAI-RPM is shown in Fig. 1\u2014more details at [29]. The figure shows an abstraction of the PRM with activities related to AI artefacts and TAI considerations. The diagrams show the starting point (black circle), activities (boxes), decision points (diamonds), and endpoints (crossed circle). Some activities contain sub-flow charts, denoted by a [+] symbol, that follow the same approach explained here. As seen in Fig. 1, the first activity is the AI confirmation, which involves identifying AI elements by defining and categorizing them.2 Next, the e-Risk identification and classification activity focuses on identifying the AI elements\u2019 intrinsic level of risk under regulatory conditions (i.e., given the current regulatory approach in the EU, we focused on the risk levels defined by the AI Act [11]). This activity has previously been thoroughly discussed [28, 29], so it will not be covered here. If AI classification is deemed not acceptable in the mentioned stage, the user will proceed to either the AI Scope Definition activity or the <can be modified to acceptable?> node\u2014Fig. 1. This node assesses whether the AI\u2019s approach, data characteristics, and functionalities can be modified to meet TAI considerations for high-risk assets. If modification is feasible, the AI modification activity is executed to redefine the AI, followed by another round of <e-risk identification and2 The recommended categorization approach is based on the AI Watch definitions for European countries\u2014https://publications.jrc.ec.europa.eu/repository/handle/JRC126426. Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 369AI confirmation E-risk identification and classification AI modification AI Scope definition Analysis of Values e-Risk management process is the e-risk u acceptablen  is AI in any component can be modified to acceptable yes yes yes no no no Fig. 1 Benchmark e-risk management process classification>. If it is not possible to secure an AI asset\u2019s acceptable risk level, the design, deployment, or use process should be halted or decommissioned. In Analysis of Values (see [28, 29] for more information), the potential for biases and use of personal information that could impact the requirements of DnDF are evaluated. It also considers the level of automation that is left to the AI asset and how this affects the agency of humans in decision-making processes. This activity also allows integrating users\u2019 values into the system. If there are conflicts, well-documented approaches for decision-making (e.g., ANP or AHP) can be used to resolve it. Finally, e-Risk Management Process encapsulates the risk assessment, treatment, monitoring, and review\u2014described in Sect. 3.1. 3.1 e-Risk Management Process Figure 2 shows a high-level diagram of the ethical-driven PRM.3 Each of the activities in the figure is discussed next. Establishing Context In this activity, a gathering and run of information is performed. This is done by: (1) Define how the AI asset interacts with other components and subsystems (i.e., software architecture documentation), (2) Define hierarchical extension of the components. Users must track cascade effects on risk analysis, for example, using root cause analysis. (3) Analyse the interactions between AI elements actions, UIs, and humans, defined in the activity AI scope (Fig. 1 in Sect. 3). (4) Analyse constraints set up as requirements to control functionalities, input behaviours, system outcomes, and component values. If relevant, these constraints were established with the physical context, enhancing the system security, especially in AI\u2013user interaction. (5) Analyse diagrams that include Connectivity with other components and subsystems, Dependencies, and3 Full detailed diagram at: https://github.com/lebriag/TAI-PRM/tree/main/Flowcharts/e-risk %20management. 370 E. Vyhmeister and G. G. CastaneEstablishing Context Merging with other Risk Management Processes Risk analysis and evaluation Risk Treatment Tr ansfer, Tole rate and Terminate Estimate KPIs, Risk register and Monitor Update Interactions & Update Requirements Review, Update and Implement Fig. 2 High-level overview of the e-Risk Management Pipeline Human\u2013AI and Human\u2013UI interactions. (6) Analyse collected information from Requirements and values. Merging with Other Risk Management Process When several PRM instances are identified and similar approaches are used (i.e., FMEA), the analyses can be merged (e.g., merging with DFMEA and PFMEA processes; the DFMEA involves a comprehensive analysis of systems, while the PFMEA identifies and evaluates failures in processes). Risk Analysis and Evaluation The FMEA (or Criticality Analysis (CA) if information exists\u2014FMECA) is used as core component for risk analysis. Given the depth of the content, this activity is described in detail in Sect. 4 as it contains a detailed sub-flow\u2014core in the management of e-risks. Risk Treatment, Transfer, Termination, or Tolerate Depending on the risk appetite and the risk levels, this activity evaluates if an AI asset should be: Treated: Failing conditions can be modified, upgraded, or safeguarded. Transferred: Exter-nal safeguards will allocate the responsibility of the failure events if materialized\u2014 Conditions can limit the option to transfer e-risks for TAI requirements. Tolerated: No need of AI asset modification. Periodic updates on the status must be continued according to the frequency established in the risk management policy. Terminated: The AI asset should not be used or developed. These activities are known as the 4T\u2019s of risk management. This process and its activities are further extended in Sect. 5. Estimate KPIs, Risk Register, and Monitor The KPIs should be linked to each trustworthy requirement or value defined for AI and their risk level measured. The monitoring part of the activity involves analysing and evaluating stakeholder outcomes to trace contingency actions, and the implementation of PRMs. The risk register involves the process of Tabulate and Report of the FMEA. Update Interactions and Update Requirements The outcomes of the previous process involve modifications related to AI assets and their interactions with other components, data structures managed by other AI assets, and the incorporation of additional AI assets or new functionalities that can impact the system\u2019s trustworthi-Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 371ness. Therefore, it is necessary to analyse these new interactions to identify potential risks. The iterative process of running the PRM must be tracked for accountability.4 Review, Update, and Implementation Once there are no outstanding updates, the user must implement the risk treatment strategy, which depends on the interactions between the different personas involved in the PRM as described in the Risk Architecture [29]. In addition, the status of the failure modes has to be revised, along with the mechanisms and processes to implement the 4T\u2019s\u2014secure protocols, strategies, and control mechanisms for implementing the AI asset. Internal or external auditing processes can be used to evaluate the system status and the PRM. Finally, the risk register must be updated for accountability. 4 Risk Analysis and Evaluation Activity Figure 3 extends the component described in the previous section. The figure depicts a flowchart that defines the instruments between the approaches FMEA, FMECA, and RCA (Root Cause Analyses) used for the risk assessment. The first decision node, <Protocol defined?>, analyses if the user has defined an FMEA or alternatives (i.e., RCA\u2014The RCA is a well-documented approach beyond the scope of this chapter, and therefore, it is not further explained.) for risk assessment. If no, the set of decision nodes drives the user to the most convenient approach to follow. The set of questions are: \u2022 <All failures identified?>: Whether it is aimed to identify all possible failing conditions. This means that the user is interested in detecting every situation that might trigger risk outcomes. \u2022 <Top events limitations?>: This question focuses on the circumstance that the number of failure events is large or could be unexpected. \u2022 <AI updates needed?>: When an AI asset requires human intervention or software updates, FMEA has extensive applicability and efficiency. \u2022 <AI system early stage:?> When the system is in the design or definition phase\u2014 An FMEA approach can better help to detect conditions that could lead to system failures. \u2022 <System modified?>: This decision node analyses when the system will be modified considerably in future stages. \u2022 <Robust examination?>: If AI assets are used in critical systems, or AI failures can have severe impacts on users and the environment, this decision node will allow the user to decide if a robust examination is required.4 Extended diagrams available at: https://github.com/lebriag/TAI-PRM/tree/main/Flowcharts/e-risk%20management/Risk%20Analysis%20and%20evaluation. 372 E. Vyhmeister and G. G. CastaneUse FMEA Use RCA Heat map construction protocol defined? yes yesyes yes yesyes yes yes yesyes yes yes yes no yes no concern with events? fil fpro e o  pde endencies? human  error ?failure  tif i kquan y r s  evaluation? failure probabilities? expert judgement? no no no no no no all failures identified? top events limitations? AI updates needed? AI tsys em early gsta e? system modified? bro ustness examination? no no no no no no Qualitative critical analysis Quantitative critical analysis Perform analysis protocol FMEA? Fig. 3 Risk analysis and evaluation flowchart overview \u2022 <Quantity risk evaluation?>: Since FMEA allows classification and grouping into failure modes in terms of their occurrence, severity, and detection, this decision node facilitates the definition. \u2022 <Human error failure?>: This decision node addresses the systems that require considerable human intervention. \u2022 <Profile of dependencies?>: If failures can trigger cascade events when they materialize, FMEA can foster a proper identification of system interdependence. \u2022 <Concern with events?>: If explanation of the relations between failures that can lead to severe consequences and impacts is required. In case the user is led to Use FMEA activity\u2014detailed in Sect. 4.1\u2014information regarding qualitative and quantitative evaluation must be gathered. Two decision nodes are used to define these: <Failure probabilities?> and <Expert judgement?>. These led to the two activities in Figure Qualitative criticality analysis? and Quantitative criticality analysis?. Within them, a CA could be performed. In order to be performed, additional information, such as: (1) the Failure Mode Ratio (. \u03b1), (2) the conditional probability . \u03b2, which represents the probability that the failure effect will result in the identified severity classification, and (3) the . \u03bb, which represents the overall system failure rate due to different causes over the operating time in units of time or cycles per time, are needed. Then, the Criticality Number (. CM ) provides a metric to classify a specific failure mode of an AI asset as follows .Cm = \u03b2\u03b1\u03bb. The Overall Criticality Number (. Cr ) estimates how critical an AI asset is with respect to a complete system; .Cr = \u2211ni=1(Cm)i .Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 373Furthermore, a heat map and a risk matrix must be constructed to keep the quantitative information tracked and to incorporate the numerical analysis based on the probabilistic information collected about the failure modes (as described in Sect. 4.2). 4.1 Use FMEA Activity Figure 4 shows the FMEA pipeline. The process starts with a decision node, <design risk analysis defined?>, where the user can check if PFMEA or DFMEA protocols are run in parallel with TAI-PRM. When this occurs, the next decision node, <scope enable ethics?>, checks if the scope of the framework and the ongoing approaches can be merged or extended. This means to define components, items, dependencies, and to establish similitude between policies. An activity named Define and Merge DFMEA/PFMEA defines the strategy to extend the functional blocks\u2014if the process is running. The decision node <AI lifecycle considered?> checks whether the user has considered analysing the complete AI asset life cycle. If that is the case, an FMEA approach must be considered for each stage of the AI life cycle and analysing the risks involved during each phase: design, development, use, and decommissioning. Identify Ethical failure modes Model/root cause ocurrence analysis (O) Severity Analysis (S) Failing Detection (D) Causes of potential failure Analysis of each stage Define/Merge DFMEA/PFMEA Identify and/or design failure modes Design risk analysis ?defined  yes yes yes yes yes yesno no no all failures identified? AI lifecycle considered? failure  modes ?defined  scope enable ethics? PFMEA in parallel? no no no Fill FMEA forms Recommendations and estimate Risk Priotity Number Fig. 4 FMEA pipeline374 E. Vyhmeister and G. G. CastaneThe following decision node, <All failures identified?>, is an internal check that evaluates that all relevant failing conditions, and their drivers, have been considered for the AI asset. After this, it is required to check if the AI asset is used within maintenance or operational processes. If it is, a PFMEA process must be set for the combination of both processes. This must be executed by the user within <PFMEA in parallel?>. Independently of the path that the user takes for the FMEA flow, TAI-PRM provides two activities key to identifying failures. The first, named Identify Ethical failure modes, defines the scope of the analyses of ethical, trustworthy, and values to be considered by the user. The second activity is Identifying and/or design failure modes, where, based on the design of the AI asset, the user must analyse possible system\u2019s general failure modes and based on the analysis as overall system including DFMEA and PFMEA considerations (i.e., not ethical base only). A list of over 130 Failure Modes related to trustworthy considerations have been already identified.5 Users can access this list in the repository mentioned or through the tool described at the end of this chapter. Importantly, the possible Failure Modes are not limited to those presented, so users can expand the knowledge base for Failure Modes based on e-risks. This list is based on a literature and industrial feedback from case studies. Furthermore, the tool constructed to perform TAI-PRM (described in Sect. 6 of the document) further facilitates the identification of failure modes and adds the capability to incorporate and share Failure Modes between tool users. After identifying the failure modes, a ranking activity of these must be executed.6 As observed in the figure, for each failure condition\u2014Model/Root\u2014on each component, the likelihood/occurrence rank (O), Severity (S), and Detection (D) must be considered. It should be considered that if the detection (D) is performed by an entity external to the system, for example, throughout IoT devices, constraints of the communication channels should be implemented. This could drive the risk appetite to be set in a more stringent condition. The final three steps of the FMEA process focus on documentation for improving the detection and accountability of future failure modes. The first, Causes of potential failure, focuses on the keeping control on the failure mode causes for future corrections. In the case of Recommendations and estimate the Risk Priority Number\u2014RPN activity, failure compensating previsions, functionality extensions or restrictions, or AI asset modifications should be documented to prevent/reduce the likelihood and severity, or improving the detection of the failure modes. Finally, in Fill FMEA forms, the user must fill the Risk Register.5 The list of failure modes is available at: https://github.com/lebriag/TAI-PRM/tree/main/Support/ Failure%20modes. 6 The ranking information is available at: https://github.com/lebriag/TAI-PRM/tree/main/Support/ RPN%20ranking%20tables. Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 375Table 1 RPN ranges in function of the intrinsic risk level Tolerate risk score range Treat risk score range Terminate risk score rangeRisk level Unacceptable risk \u2013 \u2013 1\u20131000 High risk 1\u2013200 201\u2013800 801\u20131000 Limited risk 1\u2013400 401\u20131000 \u2013 Minimal risk 1\u2013800 801\u20131000 \u2013 4.2 Heat Map Construction The heat map\u2014also referred to as risk matrix\u2014provides a mechanism to identify and compare AI artefacts and failure modes associated to the risks. This component is directly linked to a process of Fig. 3 with the same name. Authors in [32] detail how to construct a risk matrix. Nevertheless, an extension can be made depending on the intrinsic risk level of the AI asset, as defined in the AI Act. The basis for the risk matrix is the risk definition, which is the combination of the severity of a risk when it materializes and its likelihood. To describe the risk, a classification can be used for severity and likelihood following qualitative descriptions and scales.7 As a result, the failure modes can be allocated on a matrix constructed based on the likelihood scale, the severity scale, and the risk score, by using a direct translation of the risk appetite.8 4.3 Perform Analysis To link the heat map with the AI Act, different risk appetites should be considered, depending on the intrinsic risk of the AI asset\u2014i.e., the higher the risk of the AI asset, more stringent must be the risk appetite. Table 1 imposes the contingency actions for the risks associated to the 4T\u2019s, described in detail in Sect. 3.1. Further refinement is required as further knowledge is obtained from implement-ing the PRM in AI assets and our use cases. Importantly, users can modify the proposed ranges based on the risk policies established in their own enterprises, always considering the constraints of the AI Act.7 Tables available at: https://github.com/lebriag/TAI-PRM/tree/main/Support/RPN%20ranking %20tables. 8 Example result available in Heat Map Construction.pdf at: https://github.com/lebriag/TAI-PRM/ tree/main/Support/. 376 E. Vyhmeister and G. G. Castane5 Risk Treatment Transfer Terminate or Tolerate Activity The process associated with the 4T\u2019s of risk management is part of the larger process depicted in Fig. 2. The process should consider if the PRM process is repeated or new. If it is repeated, the user should determine if new failure modes have been identified for the AI asset. If new failure modes are identified, a new evaluation of the failure modes is necessary using the 4T\u2019s analysis. If there are no new failure modes, a confirmation over the possible modifications of the risk appetite should be performed. The process should be run accordance to the specific needs (requirements and intrinsic risk condition) of the AI asset and thus specifying the actions of Treat, Transfer, Terminate, or Tolerate over their explainability, transparency, accountabil-ity, human agency and oversight, privacy, and robustness, among other conditions. Each of these analysis leads to specific activities that provide recommendations and options to address the corresponding risks. A flowchart is provided in a repository9 that also includes a decision node for other requirements and an activity called \u201cFramework Construction\u201d to handle new approaches and requirements. Finally, the \u201cRisk Processing\u201d activity summarizes the previous analyses and guides the user to determine whether to terminate, tolerate, or treat the AI assets based on the risk appetite and recommendations. Overall, the flowchart provides a structured approach to assess and manage risks associated with AI assets, considering various factors such as failure modes, risk appetite, explainability, transparency, accountability, privacy, and robustness. 6 Validation and Real Case Scenario The TAI-PRM validation process was executed on multiple AI assets as a coopera-tion between different manufacturing companies and research institutions involved in the ASSISTANT project [28, 29, 33]. The project involves five academic and seven industrial partners. The real case scenario has been used to develop and refine the framework with their inputs over multiple iterations. It is currently in use for its improvement, given the iterative process defined in its implementation. Furthermore, a tool was developed to facilitate the implementation of the framework and evaluate the ALTAI tool and its applicability in the manufacturing sector. The rest of this section describes the ASSISTANT scenario as a case study. The case study description starts from Sect. 3 of the TAI-PRM.9 https://github.com/lebriag/TAI-PRM/tree/main/Flowcharts/e-risk%20management. Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 3777 TAI-PRM Tool A tool based on TAI-PRM has been developed for the ASSISTANT use case. The tool is accessible via the https://assistant.insight-centre.org/ page and offers comprehensive information on the PRM. It includes two main sections with user feedback. Users can access information on how to use the ALTAI tool or the TAI-PRM process. The tool is not an alternative to the ALTAI tool but rather helps to record the linkage and usefulness of Trustworthy requirements, component assessment, and AI implementation functionality. The records will be compared to provide users with trends based on their domain. Users only interested in the TAI-PRM process need not complete the ALTAI component. To use the tool, select the My TAI-PRM tab and create as many PRMs as needed. Complete the pipeline before generating a downloadable report. The tool also allows users to create and share failure modes to extend knowledge based on the presented strategies. Users can provide feedback at the end of each TAI-PRM to improve the tool. A total of eight steps are needed to perform the TAI-PRM including: (1) Initiation of PRM, (2) E-risk identification and classification, (3) AI Scope Definition and Analysis of Values, (4) Establishing Context, Merging with other PRM, and defining criticality analysis or FMEA, (5) FMEA or CA, (6) Ranking, (7) Risk Register, and (8) Treat, Terminate, Tolerate, and Transfer. The tools follow a distribution similar to the ALTAI tool to familiarize users with both elements. Facilitating the acceptance of user\u2019s that have already driven ALTAI assessments. Finally, information from the analogue of the ALTAI tool can be linked to a specific TAI-PRM, so information generated from it is also used in the final report of the TAI-PRM. 8 Conclusions In this chapter, we explored the current paradigm in which Industry 4.0 is evolving towards Industry 5.0, where AI and other advanced technologies are being used to build services from a sustainable, human-centric, and resilient perspective. Furthermore, we present a framework for developing and designing responsible AI artefacts in the manufacturing sector. The TAI-PRM approach combines PRM and TAI, utilizing the failure modes and effects analysis (FMEA) method. The methodology includes defining risk appetites and strategies in the industrial sector based on the AI Act. It also incorporates the 4T\u2019s of risk management. TAI-PRM can be used to implement trustworthy considerations and manage risks in compliance with current regulations. It can also serve as a guide for developing standards in AI risk management. Feedback from various domains emphasizes the importance of considering the human factor in risk management processes. However, the lack of regulatory conditions, certification, and standards for managing AI poses obstacles to the adoption and implementation of transparent378 E. Vyhmeister and G. G. Castaneand accountable AI systems. Addressing this challenge requires substantial training and effort to transform business and development team operations. Acknowledgments We acknowledge the support of the European Commission by funding the ASSISTANT project (no. 101000165) and, at the same time, we thank the contribution of the Science Foundation Ireland under Grant No. 12/RC/2289 for funding the Insight Centre of Data Analytics (which is co-funded under the European Regional Development Fund). References 1. Samoili, S., Cobo, M. L., Delipetrev, B., Martinez-Plumed, F., Gomez, E., De Prato, G., et al.: AI watch. Defining Artificial Intelligence 2.0. towards an operational definition and taxonomy of AI for the AI landscape, JRC Research Reports (JRC126426) (2021) 2. Brunetti, D., Gena, C., Vernero, F.: Smart interactive technologies in the human-centric factory 5.0: a survey. Appl. Sci. 12(16), 7965 (2022) 3. Devitt, S.K., Horne, R., Assaad, Z., Broad, E., Kurniawati, H., Cardier, B., Scott, A., Lazar, S., Gould, M., Adamson, C., Karl, C., Schrever, F., Keay, S., Tranter, K., Shellshear, E., Hunter, D., Brady, M., Putland, T.: Trust and safety Publisher: arXiv Version Number: 1. https://doi. org/10.48550/ARXIV.2104.06512 4. Zheng, T., Ardolino, M., Bacchetti, A., Perona, M.: The applications of Industry 4.0 tech-nologies in manufacturing context: a systematic literature review. Int. J. Prod. Res. 59(6), 1922\u20131954 (2021) 5. Renda, A., Schwaag Serger, S., Tataj, D., Morlet, A., Isaksson, D., Martins, F., Giovannini, E.: Industry 5.0, A transformative vision for Europe: governing systemic transformations towards a sustainable industry (2022) 6. D.-G. for Research, Innovation, Industry 5.0, a transformative vision for Europe, European Commission (2022) 7. E. C. (EC), European skills Agenda (2020) 8. Yanli, X., Danni, L., Prospect of vocational education under the background of digital age: Analysis of European Union\u2019s \u201cDigital Education Action Plan (2021\u20132027)\u201d. In: 2021 International Conference on Internet, Education and Information Technology (IEIT), pp. 164\u2013 167. IEEE, Piscataway (2021) 9. Cappellin, R., Ciciotti, E., Marelli, E., Garofoli, G.: A new European industrial strategy and the European recovery program after the Covid-19 crisis. Rivista Internazionale di Scienze Sociali 128, 265\u2013284 (2020) 10. Fetting, C.: The European Green Deal, ESDN Report, December (2020) 11. Commission, E.: Regulation of the European parliament and of the council; laying down harmonised rurles on artificial intelligence (artificial intelligence act) and amending certain union legislative acts (2021). https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri= CELEX:52021PC0206&from=EN. Accessed 10 Jun 2022 12. European Parliament. Directorate General for Internal Policies of the Union. The white paper on artificial intelligence. Publications Office. https://data.europa.eu/doi/10.2861/614816 13. H.-L. E. G. on Artificial Intelligence, Ethics Guidelines for Trustworthy AI, European Commission 14. Accenture, Big success with big data - executive summary (2012). https://www.accenture. com/us-en/_acnmedia/accenture/conversion-assets/dotcom/documents/global/pdf/industries_ 14/accenture-big-data-pov.pdf. Accessed 18 Aug 2022 15. Finance, A.: Industry 4.0 challenges and solutions for the digital transformation and use of exponential technologies. Finance Audit Tax Consult. Corporate: Zurich, Swiss, 1\u201312 (2015). https://www2.deloitte.com/content/dam/Deloitte/ch/Documents/manufacturing/ch-en-manufacturing-industry-4-0-24102014.pdf 16. Xu, X., Lu, Y., Vogel-Heuser, B., Wang, L.: Industry 4.0 and Industry 5.0\u2014inception, conception and perception. J. Manuf. Syst. 61, 530\u2013535 (2021). https://doi.org/10.1016/j.jmsy. 2021.10.006. https://linkinghub.elsevier.com/retrieve/pii/S0278612521002119Towards Industry 5.0 by Incorporation of Trustworthy and Human-Centric Approaches 37917. P. O. o. t. E. Union: Enabling technologies for Industry 5.0: results of a work-shop with Europe\u2019s technology leaders. http://op.europa.eu/en/publication-detail/-/publication/ 8e5de100-2a1c-11eb-9d7e-01aa75ed71a1/language-en 18. Bedu\u00e9, P., Fritzsche, A.: Can we trust AI? an empirical investigation of trust requirements and guide to successful AI adoption. J. Enterprise Informat. Manag. 35, 530\u2013549 (2021). 19. Bartneck, C., L\u00fctge, C., Wagner, A., Welsh, S.: An Introduction to Ethics in Robotics and AI. Springer Nature, Berlin (2021) 20. Dignum, V.: Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way. Springer Nature, Berlin (2019) 21. European Commission. Directorate General for Communications Networks, Content and Tech-nology., High Level Expert Group on Artificial Intelligence. Ethics guidelines for trustworthy AI. Publications Office. https://data.europa.eu/doi/10.2759/346720 22. Hagendorff, T.: The ethics of AI ethics: an evaluation of guidelines. Minds Mach. 30(1), 99\u2013 120 (2020) 23. Eitel-Porter, R.: Beyond the promise: implementing ethical AI. AI Ethics 1(1), 73\u201380 (2021) 24. Hopkin, P., Thompson, C.: Fundamentals of Risk Management: Understanding, Evaluating and Implementing Effective Enterprise Risk Management, 6th edn. Kogan Page, London (2022) 25. Palacios Guillem, M.: New methodology developed for the integration of lean manufacturing; kaizen and ISO 31000: 2009 based on ISO 9001:2015 (2019). https://www.3ciencias. com/articulos/articulo/nueva-metodologia-desarrollada-para-la-integracion-de-lean-manufacturing-kaizen-e-iso-310002009-basados-en-la-iso-90012015/. Accessed 18 July  2022. https://doi.org/10.17993/3cemp.2019.080238.12-43 26. ISO, ISO 23247-1:2021. (2021) https://www.iso.org/cms/render/live/en/sites/isoorg/contents/ data/standard/07/50/75066.html. Accessed 21 July 2022 27. Lu, Y., Huang, H., Liu, C., Xu, X.: Standards for smart manufacturing: A review. In: 2019 IEEE 15th International Conference on Automation Science and Engineering (CASE), pp. 73\u2013 78, IEEE, Piscataway (2019) 28. Vyhmeister, E., Castane, G., \u00d6stberg, P.-O., Thevenin, S.: A responsible AI framework: pipeline contextualisation. AI Ethics 3, 1\u201323 (2022) 29. Vyhmeister, E., Gonzalez-Castane, G., \u00d6stbergy, P.-O.: Risk as a driver for AI framework development on manufacturing. AI Ethics 3, 1\u201320 (2022) 30. Kumar, R.S.S., Brien, D.O., Albert, K., Vilj\u00f6en, S., Snover, J.: Failure modes in machine learning systems (2019). Preprint arXiv:1911.11034 31. Li, J., Chignell, M.: FMEA-AI: AI fairness impact assessment using failure mode and effects analysis. AI Ethics 2, 1\u201314 (2022) 32. Ni, H., Chen, A., Chen, N.: Some extensions on risk matrix approach. Safety Sci. 48(10), 1269\u20131278 (2010) 33. ASSISTANT: Assistant project \u2013 learning and robust decision support sytem for agile manufacturing environments. https://assistant-project.eu/. Accessed 04Jun 2022 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Human in the AI Loop via xAI and Active Learning for Visual Inspection Jo\u017ee M. Ro\u017eanec, Elias Montini, Vincenzo Cutrona, Dimitrios Papamartzivanos, Timotej Klemenc\u030cic\u030c, Bla\u017e Fortuna, Dunja Mladenic\u0301, Entso Veliou, Thanassis Giannetsos, and Christos Emmanouilidis 1 Introduction Industrial revolutions have historically disrupted manufacturing by introducing automation into the production process. Increasing automation changed worker responsibilities and roles. While past manufacturing revolutions were driven from the optimization point of view, the Industry 5.0 concepts capitalize on the techno-logical foundations of Industry 4.0 to steer manufacturing toward human-centricity [32, 67], adding resilience and sustainability among its key targets [29]. This change is part of a holistic understanding of the industry\u2019s societal role. In particular, the J. M. Ro\u017eanec (\u0002) Jo\u017eef Stefan Institute, Ljubljana, Slovenia Qlector d.o.o., Ljubljana, Slovenia e-mail: joze.rozanec@ijs.si E. Montini \u00b7 V. Cutrona University of Applied Science of Southern Switzerland, Manno, Switzerland D. Papamartzivanos \u00b7 T. Giannetsos Ubitech Ltd., Athens, Greece T. Klemenc\u030cic\u030c University of Ljubljana, Ljubljana, Slovenia B. Fortuna Qlector d.o.o., Slovenia D. Mladenic\u0301 Jo\u017eef Stefan Institute, Ljubljana, Slovenia E. Veliou University of West Attica, Aigaleo, Greece C. Emmanouilidis University of Groningen, Groningen, The Netherlands \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_22381382 J. M. Ro\u017eanec et al.European Commission expects the industry to collaborate on achieving societal goals that transcend jobs and company growth. Human-centric manufacturing within the Industry 5.0 aims to ensure that human well-being, needs, and values are placed at the center of the manufacturing process. Furthermore, it seeks to enable collaborative intelligence between humans and machines to enable co-innovation, co-design, and co-creation of products and services [62], thus allowing leveraging on their strengths to maximize individual and joint outcomes and their joint added value [34]. It is expected that synergies enabled within Industry 5.0 will still allow for high-speed and mass-personalized manufacturing but will shift repetitive and monotonous tasks to be more assigned to machines to capitalize more on the human propensity for critical thinking and give them to more cognitively demanding tasks [71]. The emerging shift in human roles goes beyond allowing them to move away from repetitive tasks to undertake other physical activities. As non-human actors, including artificial intelligence (AI) - enabled ones, undertake tasks that can be automated, humans are not necessarily excluded but may well play a higher added value and steering role, bringing their cognitive capabilities into the AI loop [33]. This includes active synergies between AI-enabled non-human entities and humans, resulting in novel work configurations [41]. Such configurations empower human actors in new roles rather than diminishing them [8]. As a consequence, it is increasingly recognized that involving instead of replacing the human from the AI loop not only elevates the role of humans in such work environments but also significantly enhances the machine learning process, and, therefore, the emergent capabilities of the AI-enabled actors [77]. As a result, such synergies involve humans and non-human entities who jointly contribute to shaping an emergent meta-human learning system, which in turn is more capable and powerful than human and non-human entities acting alone [70]. A possible realization of such human-machine collaboration emerges from two sub-fields of artificial intelligence: active learning and explainable artificial intelligence (XAI). Active learning is concerned with finding pieces of data that allow machine learning algorithms to learn better toward a specific goal. Human intervention is frequently required, e.g., to label selected pieces of data and enable such learning. On the other hand, XAI aims to make the machine learning models intelligible to the human person so that humans can understand the rationale behind machine learning model predictions. While active learning requires human expertise to teach machines to learn better, XAI aims to help humans learn better about how machines learn and think. This way, both paradigms play on the strengths of humans and machines to realize synergistic relationships between them. Among the contributions of the present work are (i) a brief introduction to the state-of-the-art research on human-machine collaboration, key aspects of trustwor-thiness and accountability in the context of Industry 5.0, and research related to automated visual inspection; (ii) the development of a vision on how an AI-first human-centric visual inspection solution could be realized; and (iii) a description of experiments and results obtained in the field of automated visual inspection at the EU H2020 STAR project.Human in the AI Loop via xAI and Active Learning for Visual Inspection 383The rest of the work is structured as follows: Sect. 2 describes related work, providing an overview of human-machine collaboration, the industry 5.0 paradigm and human-centric manufacturing, state-of-the-art on automated quality inspection, and a vision of how human-machine collaboration can be realized in the visual inspection domain. In Sect. 3, relevant research contributions from the EU H2020 STAR project are outlined, offering concrete examples of humans and AI working in synergy. Finally, Sect. 4 provides conclusions and insights into future work. 2 Background 2.1 Overview on Human-Machine Collaboration The advent of increasingly intelligent machines has enabled a new kind of rela-tionship: the relationship between humans and machines. Cooperative relationships between humans and machines were envisioned back in 1960 [39, 65]. This work defines machines in a broad sense, considering intelligent systems that can make decisions autonomously and independently (e.g., automated, autonomous, or AI agents, robots, vehicles, and instruments) [39, 83, 114]. Relationships between humans and machines have been characterized through different theories, such as the Socio-Technical Systems theory (considers humans and technology shape each other while pursuing a common goal within an organization), Actor-Network theory (considers machines should be equally pondered by humans when analyzing a social system, considering the later as an association of heterogeneous elements), Cyber-Physical Social Systems theory (extends the Socio-Technical Systems theory emphasizing social dimensions where computational algorithms are used to monitor devices), the theory on social machines (considers systems that combine social participation with machine-based computation), and the Human-Machine Networks theory (considers humans and machines form interdependent networks character-ized by synergistic interactions). The first three theories conceptualize humans and machines as a single unit, while the last two consider social structures mediated in human-machine networks. In particular, the Socio-Technical Systems theory consid-ers humans and technology shape each other while pursuing a common goal within an organization. The Cyber-Physical Social Systems theory extends this vision, emphasizing social dimensions where computational algorithms are used to monitor and control devices. Moreover, the Actor-Network theory conceptualizes the social system as an association of heterogeneous elements and advocates that machines should be equally pondered to humans. The theory of social machines is interested in systems that combine social participation with machine-based computation. In contrast, the Human-Machine Networks theory considers humans and machines to form interdependent networks characterized by synergistic interactions. A thorough analysis of the abovementioned concepts can be found in [105].384 J. M. Ro\u017eanec et al.Regardless of the particular theory, the goal remains the same: foster and understand mutualistic and synergistic relationships between humans and machines, where the strengths of both are optimized toward a common goal to achieve what was previously unattainable to each of them. To that end, individual roles must either be clearly defined or allow for a clear sliding of roles when a role can be shared among different types of actors. This will ensure a dynamic division of tasks, optimal use of resources, and reduced processing time. Machines are aimed at supporting, improving, and extending human capabilities. The joint outcomes of human-machine collaboration can result in systems capable of creativity and intuitive action to transcend mere automation. Communication is a critical aspect of every social system. Therefore, emphasis must be placed on the interaction interfaces between such actors. To make such interfaces effective, the concept of shared context or situation awareness between collaborating agents becomes essential and can be seen as a form of mutual understanding [33]. This shared context is enabled through interaction communication of different modalities, including direct verbal (speech, text) and non-verbal (gestures, action and intention recognition, emotions recognition). On the other hand, means must be designed so that humans can understand the machine\u2019s goals and rationale for acting to reach such goals in a human-like form. In this regard, human-machine interfaces to support multi-modal interaction play a crucial role. These aspects were also identified by Jwo et al. [53], who described the 3I (Intellect, Interaction, and Interface) aspects that must be considered for achieving human-in-the-loop smart manufacturing. Beyond shared context, human-machine cooperation requires adequate commu-nication and shared or sliding control [101]. To realize an effective bidirectional information exchange, theory and methods must address how data and machine rea-soning can be presented intuitively to humans. Frameworks and models abstracting human cognitive capabilities [60] are key to achieving this. Aligning the design of interactive interfaces and support tools for human-machine interactions with such concepts can be critically important for making effective human\u2013machine interfaces. Enhancements in the interactivity, multisensitivity, and autonomy of feedback functions implemented on such interfaces allow for deeper integration between humans and machines. Shared control can be articulated at operational, tactical, and strategic levels, affecting information-gathering, information-analysis, decision-making, and action implementation. Human-machine interactions can be viewed from multiple perspectives, neces-sitating a thorough consideration of several factors influencing such collaborations. These factors encompass emotional and social responses, task design and assign-ment, trust, acceptance, decision-making, and accountability [23]. Notably, research indicates that machines in collaborative settings impact human behavior, resulting in a diminished emotional response toward them. Consequently, this reduced emotional response can foster more rational interactions. Moreover, studies reveal that humans perceive a team more favorably when machines acknowledge and admit their errors. Additionally, the absence of social pressure from humans can detrimen-Human in the AI Loop via xAI and Active Learning for Visual Inspection 385tally affect overall human productivity. Furthermore, concerning accountability for decision-making, humans tend to shift responsibility onto machines. Trust, a critical aspect to consider, has been explored extensively. Studies demonstrate that trust in machines is closely linked to perceived aptness [23]. Instances of machine errors often lead to a loss of trust, particularly when machines act autonomously. However, if machines operate in an advisory capacity, trust can be amended over time. Additionally, research reveals that while humans value machine advice, they hesitate to relinquish decision-making authority entirely. Nevertheless, relying excessively on machines can result in sub-optimal outcomes, as humans may fail to identify specific scenarios that necessitate their attention and judgment. For further details about the abovementioned experiments and additional insights the reader may be interested on the works by Chugunova et al. [23]. 2.2 Industry 5.0 and Human-Centric Manufacturing 2.2.1 New Technological Opportunities to Reshape the Human Workforce Digital transformation in production environments demands new digital skills and radically reshapes the roles of plant and machine operators [22, 104]. While Industry 4.0 emphasizes the use of technologies to interconnect different stages of the value chain and the use of data analytics to increase productivity, Industry 5.0 emphasizes the role of humans in the manufacturing context [16, 54]. Further-more, it aims to develop means that enable humans to work alongside advanced technologies to enhance industry-related processes [68]. An extensive review of this paradigm and its components was written by Leng et al. [62]. Nevertheless, two components are relevant to this work: collaborative intelligence and multi-objective interweaving. Collaborative Intelligence is the fusion of human and AI [110]. In the context of Industry 5.0, the fusion of both types of intelligence entails the cognitive coordination between humans and AI in machines, enabling them to collaborate in the innovation, design, and creation of tailored products and services. Complementarity between humans and AI (see Table 1) leads to the more effective execution of such tasks than would be possible if relegated to humans or machines only [18, 51, 75, 86]. When analyzing complementarities, humans have the knowledge and skills to develop and train machines by framing the problems to be solved and providing feedback regarding their actions or outputs [50, 62, 82, 112]. Furthermore, humans can enrich machine outcomes by interpreting results and insights and deciding how to act upon them [113]. Machines amplify workers\u2019 cognitive abilities: they can track many data sources and decide what information is potentially relevant to humans. Furthermore, machines can excel at repetitive tasks and free humans from such a burden. Such complementary is considered within the multi-objective interweaving nature of Industry 5.0, which enables optimizing multiple goals beyond process performance and social and environmental sustainability [13].386 J. M. Ro\u017eanec et al.Table 1 Overview on humans and AI complementarity (adapted from [50, 62, 82], and comple-mented with our observations). x: capability completely fulfilled; o: capability partially fulfilled Capability Humans Machines Strengths and capabilities Leadership x Teamwork x Creativity x o Problem-solving x x Risk assessment x o Intuition x Interpretation x Empathy x Adapt behavior x o Learn from experience x o Speed x Scalability x Endurance x Quantitative accuracy x Process large amounts of data x Process different kinds of data in parallel x Perform continuous operations x Consistent decision-making x Physical and cognitive abilities x o Weaknesses Prone to biases and errors x Affected by emotions x Affected by distractions x Prone to frauds and adversarial attacks o x Affected by fatigue x Limited to certain scope and goals x Lack of emotional intelligence x Lack of social skills x Moreover, research suggests that leading companies are beginning to recognize the benefit of using machines and automation systems to supplement human labor rather than replacing the human workforce entirely [5, 28]. While AI was already able to tackle certain tasks with super-human capability [24], it has recently shown progress in areas such as creativity (e.g., through generative models such as DALL.\u00b7E 2 [84]) or problem-solving [20], opening new frontiers of human-machine collaboration, such as co-creativity [9, 64]. In addition to the direct human involvement described above, digital twins [74] are another way to incorporate human insights into the AI processes. By creating virtual models of human behavior and mental processes, more profound insights into how humans interact with the world and use this information to improve AI systems. Digital twins can also support explainability and transparency in AIHuman in the AI Loop via xAI and Active Learning for Visual Inspection 387systems, making explaining how they arrive at their decisions easier [12]. Moreover, digital representations can be used to consider users\u2019 preferences in the AI system behaviors, e.g., type of support [48, 106]. 2.2.2 Trustworthiness and Implications for AI-Driven Industrial Systems Trustworthiness for systems and their associated services and characteristics is defined according to the International Organization for Standardization (ISO) as \u201cthe ability to meet stakeholders\u2019 expectations in a verifiable way\u201d [3]. It follows that trustworthiness can refer to products, services, technology, and data and, ultimately, to organizations. Therefore, the concept of trustworthiness is directly applicable to AI-driven systems, particularly to human-centric AI-enabled solutions. However, it should be understood that trustworthiness is a multifaceted concept, incorporating distinct characteristics such as accountability, accuracy, authenticity, availability, controllability, integrity, privacy, quality, reliability, resilience, robust-ness, safety, security, transparency, and usability [3]. Some of these characteristics should be seen as emerging characteristics of AI-enabled systems, which are not solely determined by the AI\u2019s contribution to an overall solution. Focusing specifically on the AI components of such solutions, ethics guidelines published by the European Commission (EC) identifies seven key requirements for trustworthiness characteristics that must be addressed [35]. These include (i) human agency and oversight; (ii) technical robustness and safety; (iii) privacy and data governance; (iv) transparency; (v) diversity, non-discrimination, and fairness; (vi) societal and environmental well-being; and (vii) accountability. Regarding some of these characteristics, there is a direct correspondence between broader trustworthiness as documented according to ISO and the EC guidelines. Technical robustness, safety, privacy, transparency, and accountability are identified in both sources. Human agency and oversight are directly linked to controllability, and so is governance, which is also the prime focus of ISO recommendations [2]. Given the societal impacts that AI-induced outcomes can have, the EC has also highlighted diversity, non-discrimination, fairness, and societal and environmental well-being as key characteristics of trusted AI solutions. However, these aspects are also partly addressed as part of the broader concept of \u201cfreedom from risk\", which can be defined as the extent to which a system avoids or mitigates risks to economic status, human life, health, and well-being and or the environment [1]. The trustworthiness of an AI system can be affected by multiple factors. Some of them relate to cybersecurity. In particular, machine learning algorithms are vulnerable to poison and evasion attacks. During poisoning attacks, the adversary aims to tamper with the training data used to create the machine learning models and distort the AI model on its foundation [42, 96]. Evasion attacks are performed during inference, where the attacker crafts adversarial inputs that may seem normal to humans but drive the models to classify the inputs wrongly [49, 72]. Such an adversarial landscape poses significant challenges and requires a collaborative approach between humans and machines to build defenses that can lead to more388 J. M. Ro\u017eanec et al.robust and trustworthy AI solutions. While human intelligence can be used for the human-in-the-loop adversarial generation, where humans are guided to break models [108], AI solutions can be trained to detect adversarial inputs and uncover potentially malicious instances that try to evade the AI models [10]. Furthermore, human-machine collaboration can be fostered to detect such attacks promptly. Accountability refers to the state of being accountable and relates to allocated responsibility [3]. At the system level, accountability is a property that ensures that the actions of an entity can be traced uniquely to the entity [4]. However, when considering governance, accountability is the obligation of an individual or organization to account for its activities, accept responsibility for them, and disclose the results in a transparent manner [2]. Therefore, accountability is closely linked to transparency for AI-enabled systems, which is served via XAI and interpretable AI. XAI and interpretable AI ensure that AI systems can be trusted when analyzing model outcomes that impact costs and investments or whenever their outputs provide information to guide human decision-making. Accuracy generally refers to the closeness of results and estimates to true values but, in the context of AI, further attains the meaning appropriate for specific machine learning tasks. Any entity that is what it claims to be is said to be characterized by authenticity, with relevant connotations for what AI-enabled systems claim to deliver. Such systems may furthermore be characterized by enhanced availability to the extent that they are usable on demand. Other characteristics such as integrity, privacy, and security attain additional meaning and importance in AI-driven systems and are further discussed in the next section. They can contribute to and affect the overall quality, reliability, resilience, robustness, and safety, whether the unit of interest is a component, a product, a production asset, or a service, with implications for individual workers all the way to the organization as a whole. When considering accountability for AI systems from the legal perspective, the EU AI Act [36] in its current form considers developers and manufacturers responsible for AI failures or unexpected outcomes. Nevertheless, the concept of accountability will evolve based on the issues found in practice and the corresponding jurisprudence that will shape the learning on how different risks, contexts, and outcomes must be considered in the industry context [46]. 2.3 Automated Quality Inspection 2.3.1 The Role of Robotics The increasing prevalence of human-robot collaboration in diverse industries show-cases the efforts to enhance workplace productivity, efficiency, and safety through the symbiotic interaction of robots and humans [44]. In manufacturing, robots are employed for repetitive and physically demanding tasks, enabling human workers to allocate their skills toward more intricate and creative endeavors. This collaborativeHuman in the AI Loop via xAI and Active Learning for Visual Inspection 389partnership allows for the fusion of human and robot capabilities, maximizing the overall outcomes. The successful implementation of human-robot interaction owes credit to col-laborative robots, commonly called cobots [56]. These advanced robots have sophisticated sensors and programming that facilitate safe and intuitive human inter-action. This collaboration improves productivity and fosters a work environment where humans and robots can coexist harmoniously. This approach harmoniously merges robots\u2019 precision and accuracy with human workers\u2019 adaptability and dexterity. Robotic integration in product quality control has become widespread across diverse industries and production sectors. Robots offer exceptional advantages within quality inspection processes, including precise repeatability and accurate movements [17]. They possess the capability to analyze various product aspects such as dimensions, surface defects, color, texture, and alignment, ensuring adher-ence to predefined standards. Robots\u2019 superior accuracy and efficiency make them an ideal choice for quality control applications. To facilitate quality testing, robots are equipped with a range of sensors. These sensors enable precise measurement, detection, and sorting operations. Robots with cameras utilize advanced machine vision techniques to analyze image and video streams and identify anomalies like cracks, scratches, and other imperfections [107]. Subsequently, defective items are segregated from conforming ones, elevating overall production quality. The industry is witnessing an increasing adoption of 3D vision systems, particularly in applications requiring object grasping and precise information about object position and orientation. Specially designed robots, such as coordinate measuring machines, are employed for dimensional and precision measurements. These robots feature high-precision axis encoders and accurate touch probes, enabling them to detect part measurements and consistently evaluate adherence to quality standards [61]. The active learning paradigm can be applied to enable efficient and flexible learning in robots. This can be particularly useful in resource-constrained industrial environments, where data scarcity and limited human knowledge prevail, acquiring essential data through unsupervised discovery becomes imperative [26]. Active learning demonstrates extensive applicability in robotics, encompassing prioritized decision-making, inspection, object recognition, and classification. Within quality control, active learning algorithms optimize machine learning models\u2019 defect detection and quality assessment training process. By actively selecting informative samples for labeling, active learning minimizes labeling efforts, augments model training efficiency, and ultimately enhances the accuracy and performance of quality control systems. An intriguing domain of investigation pertains to the advancement of intuitive and natural interfaces that foster seamless communication and interaction between humans and robots. This entails the exploration of innovative interaction modalities, encompassing speech, gestures, and facial expressions, or even using augmented reality to customize the robots\u2019 appearance and foster better interaction with humans [59]. Other key research areas involve developing adaptive and flexible robotic390 J. M. Ro\u017eanec et al.systems that dynamically adapt their behavior and actions to the prevailing context and the human collaborator\u2019s preferences, achieving low processing times [78]. These could be critical to enable real-time human intent recognition, situational awareness, and decision-making, all aimed at augmenting the adaptability and responsiveness of robots during collaborative tasks. 2.3.2 Artificial Intelligence\u2014Enabled Visual Inspection Visual inspection is frequently used to assess whether the manufactured product complies with quality standards and allows for the detection of functional and cosmetic defects [21]. It has historically involved human inspectors in determining whether the manufactured pieces are defective. Nevertheless, the human visual system excels in a world of variety and change, while the visual inspection process requires repeatedly observing the same product type. Furthermore, human visual inspection suffers from poor scalability and the fact that it is subjective, creating an inherent inspector-to-inspector inconsistency. The quality of visual inspection can be affected by many factors. See [94] classified them into five categories, whether they are related to the (i) task, (ii) individual, (iii) environment, (iv) organization, or (v) social aspects. To solve the issues described above, much effort has been invested in automated visual inspection by creating software capable of inspecting manufactured products and determining whether they are defective. Cameras are used to provide visual input. Different approaches have been developed to determine whether a defect exists or not. Automated optical quality control may target visual features as simple as colors, but more complex ones are involved in crack detection, the orientation of threads, defects in bolts [52] and metallic nuts [14]. Through automated optical inspection, it is also possible to detect defects on product surfaces of wide-ranging sizes [19, 103, 117]. Furthermore, it is also possible to target the actual manufacturing process, for example, welding [102], injection molding [66], or assembly of manufactured components [37]. Additionally, automated visual inspection applies to remanufacturing products at the end of their useful life [91]. State-of-the-art (SOTA) automated visual inspection techniques are dominated by deep learning approaches, achieving high-performance levels [6]. Among the many types of learning from data for visual inspection, unsupervised, weakly supervised, and supervised methods can be named. Unsupervised methods aim to discriminate defective manufactured pieces without labeled data. The weakly supervised approach assumes that data has an inherent cluster structure (instances of the same class are close to each other) and that the data lies in a manifold (nearby data instances have similar predictions). Therefore, it leverages a small amount of annotated data and unlabeled data to learn and issue predictions. Finally, supervised methods require annotated data and usually perform best among the three approaches. Often, labeled data are unavailable in sufficient range and numbers to enable fully supervised learning and additional exemplar images can beHuman in the AI Loop via xAI and Active Learning for Visual Inspection 391produced through data augmentation [55]. In addition, multiple strategies have been developed to reduce the labeled data required to train and enhance a given classifier. Among them are active learning, generative AI, and few-shot learning. In the context of visual inspection, active learning studies how to select data instances that can be presented to a human annotator to maximize the models\u2019 learning. Generative AI aims to learn how to create data instances that resemble a particular class. Finally, few-shot learning aims to develop means by which the learner can acquire experience to solve a specific task with only a few labeled examples. To compensate for the lack of labeled data, it can either augment the dataset with samples from other datasets or use unlabeled data, acquire knowledge on another dataset, or algorithm (e.g., by adapting hyperparameters based on prior meta-learned knowledge) [109]. Regardless of the progress made in automated visual inspection, many challenges remain. First, there is no universal solution for automated visual inspection: solu-tions and approaches have been developed to target a specific product. Flexibility to address the inspection of multiple manufactured products with a single visual inspection system is a complex challenge and remains an open issue [21, 25, 80]. Second, unsupervised machine learning models do not require annotating data and may provide a certain level of defect detection when associating data clusters to categories (e.g., types of defects or no defects). Furthermore, given that no prior annotation of expected defects is required, they are suitable when various defects exist. Nevertheless, their detection rates are lower than those obtained by supervised machine learning models. Therefore, it should be examined use case by use case whether the unsupervised machine learning models are a suitable solution. Third, data collection and annotation are expensive. While data collection affects unsupervised machine learning models, data collection and annotations directly impact supervised machine learning approaches. While multiple strategies have been envisioned to overcome this issue (e.g., generative models, active learning, and few-shot learning), data collection and annotation remain an open challenge. Finally, better explainability techniques and intuitive ways to convey information to humans must be developed to understand whether the models learn and predict properly. 2.4 Realizing Human-Machine Collaboration in Visual Inspection While much progress has been made in automated visual inspection, the authors rec-ognize that most solutions are custom and developed for a particular product type. Developing systems that could adapt to a broad set of products and requirements remain a challenge. In human-centered manufacturing, it is critical to rethink and redesign the role of humans in the visual inspection process. The role of humans in automated visual inspection is shifting away from repetitive and manual tasks to roles with more cognitive involvement, which can still not be replicated by machines392 J. M. Ro\u017eanec et al.and AI. In the simplest case, this involves humans labeling acquired image samples to guide the machine learning process [98]. However, the role of humans extends beyond data labeling and may involve interaction loops between humans and AI as part of the machine learning process [79]. In this regard, two machine learning paradigms are particularly important: active learning and XAI. On the one side, active learning is an AI paradigm that seeks the intervention of an oracle (usually a human person) to help the machine learning model learn better toward an objective. XAI, on the other side, aims to explain the rationale behind a machine learning model action or prediction. Doing so enables a fruitful dialogue between humans and machines by providing insights into the machines\u2019 rationale and decision-making process. Active learning for classification is based on the premises that unlabeled data (either collected or generated) is abundant, the data labeling is expensive, and the models\u2019 generalization error can be minimized by carefully selecting new input instances with which the model is trained [95, 99]. Active learning for classification has traditionally focused on the data (selecting or generating the data without further consideration for the model at hand) and the model\u2019s learning (e.g., considering the uncertainty at the predicted scores). Nevertheless, approaches have been developed to consider both dimensions and provide a holistic solution. One of them is the Robust Zero-Sum Game (RZSG) framework [119], which attempts to optimize both objectives at once, framing the data selection as a robust optimization problem to find the best weights for unlabeled data to minimize the actual risk, reduce the average loss (to achieve greater robustness to outliers) and minimize the maximal loss (increasing the robustness to imbalanced data distributions). Another perspective has been considered by Zajec et al. [118] and Kri\u017enar et al. [57], who aim to select data based on insights provided by XAI methods and, therefore, benefit from direct insights into the model\u2019s learning dynamics. Regardless of the approach, Wu et al. [111] propose that three aspects must be considered when searching for the most valuable samples: informativeness (contains rich information that would benefit the objective function), representativeness (how many other samples are similar to it), and diversity (the samples do not concentrate in a particular region but rather are scattered across the whole space). Strategies will be conditioned by particular requirements (e.g., whether the data instances are drawn from a pool of samples or a data stream). For a detailed review of active learning, the reader may be interested in some high-quality surveys of this domain. In particular, the works by Settles [95] and Ro\u017eanec et al. [87] can serve as an introduction to this topic. Furthermore, the surveys by Fu et al. [38] and Kumar et al. [58] provide an overview of querying strategies in a batch setting; the survey by Lughofer [69] give  an overview of active learning in online settings, and the study by Ren et al. [85] describes active learning approaches related to deep learning models. While AI models have the potential to automate many tasks and achieve super-human performance levels, in most cases, such models are opaque to humans: their predictions are mostly accurate, but no intuition regarding their reasoning process is conveyed to humans. Understanding the rationale behind a model\u2019s prediction is of utmost importance, given it provides a means to assess whetherHuman in the AI Loop via xAI and Active Learning for Visual Inspection 393the predictions are based on accurate facts and intuitions. Furthermore, it is crucial to develop means to understand the model\u2019s reasoning process given the impact such techniques have on the real world, either in fully automated settings or when decision-making is delegated to humans. Such insights enable responsible decision-making and accountability. The subfield of AI research developing techniques and mechanisms to elucidate the models\u2019 rationale and how to present them to humans is known as XAI. While the field can be traced back to the 1970s [93], it has recently flourished with the advent of modern deep learning [115]. When dealing with XAI, it is important to understand what makes a good explanation. A good explanation must consider at least three elements [11]: (a) reasons for a given model output (e.g., features and their values, how strongly do features influence a forecast, whether the features at which the model looks at make sense w.r.t. the forecast, how did training data influence the model\u2019s learning), (b) context (e.g., the data on which the machine learning model was trained, the context on which inference is performed), and (c) how is the abovementioned information conveyed to the users (e.g., target audience, the terminology used by such an audience, what information can be disclosed to it). XAI can be valuable in enhancing human understanding with new (machine-based) perspectives. It can also help to understand whether the model is optimizing for one or few of all required goals and, therefore, identify an appropriate compromise between the different goals that must be satisfied for the problem at hand [30]. To assess the goodness of an explanation, aspects such as user satisfaction, the explanation persuasiveness, the improvement of human judgment, the improvement of human-AI system performance, the automation capability, and the novelty of explanation must be considered [92]. For a detailed review of XAI, the reader may consider the works of Arrieta et al. [11], Doshi-Velez et al. [30], and Schwalbe et al. [92]. The work of Bodria et al. [15] provides a comprehensive introduction to XAI black box methods, and the works of Doshi-Velez et al. [30], Hoffman et al. [45], and Das et al. [27] focus on insights about how to measure the quality of explanations. Active learning and XAI can complement each other. Understanding the rationale behind a model prediction provides valuable insight to humans and can also be leveraged in an active learning setting. In the particular case of defect inspection, insights obtained by XAI techniques are usually presented in anomaly maps. Such anomaly maps highlight regions of the image the machine learning models consider to issue a prediction. The more perfect the learning of a machine learning model, the better those anomaly maps should annotate a given image indicating defective regions. Therefore, the insights obtained from those anomaly maps can be used in at least two ways. First, the anomaly maps can be handed to the oracle (human inspector), who, aided by the anomaly map and the image of the product, may realize better where the manufacturing errors are, if any. Second, anomaly maps can be used to develop novel models and active learning policies that allow for data selection, considering what was learned by the model and how the model perceives unlabeled data. This approach is detailed in Fig. 1, which depicts how an initial dataset is used to train machine learning models for defect classification or data generation. In the model training process, XAI can be used to debug and iterate the394 J. M. Ro\u017eanec et al.Fig. 1 Envisioned setup for an AI-first human-centric visual inspection solution model until getting satisfactory results. The classification model is then deployed to perform inference on incoming product images from the manufacturing line. If the classification scores for certain classes are high enough, the product can be classified as good or defective. When the uncertainty around the predicted scores is not low enough, the case can be sent for manual revision. Insights obtained through XAI and unsupervised classification models can be used to hint to the human inspector where the defects may be located. Alternative data sources for the manual revision or data labeling process can be generative models (e.g., generative adversarial networks), which can be used to generate labeled synthetic data and validate the level of attention of a human inspector. When collecting data, active learning techniques can be used to select the most promising data instances from either generative models or incoming images from the manufacturing line, reducing the labeling effort. Finally, a separate model can monitor human inspectors to predict fatigue and performance. Such models can be a valuable tool to ensure workplace well-being and enhance work quality. Some of the results obtained within the STAR project are presented in Sect. 3.1. In recent years, researchers have made significant progress in understanding and quantifying fatigue and recognizing its impact on human performance and overall well-being. Through AI techniques, new approaches have emerged to accurately estimate the fatigue levels of individuals during different tasks and in different contexts [7, 47]. One notable area of inquiry concerns the assessment of fatigue in the workplace. Understanding and managing worker fatigue has become essential given the increasing demands and pressures of modern work environments. AI models can consider various factors and features to assess employee fatigue levels accurately. These models can provide valuable insights for organizations looking to implement strategies and interventions to optimize productivity and ensureHuman in the AI Loop via xAI and Active Learning for Visual Inspection 395employee well-being or to support workflows, including quality controls, such as identifying when operators need a break. Although laboratory experiments have been conducted in this area [63], industrial applications remain relatively restricted compared to other fields, such as driving [97]. 3 Industrial Applications This section briefly describes how some ideas presented in the previous sections have been realized within the EU H2020 STAR project. Three domains are consid-ered: artificial intelligence for visual inspection, digital twins, and cybersecurity. 3.1 Machine Learning and Visual Inspection In the domain of visual inspection, multiple use cases were considered. The datasets were provided by two industrial partners: Philips Consumer Lifestyle BV (Drachten, The Netherlands) and Iber-Oleff - Componentes Tecnicos Em Pl\u00e1stico, S.A. (Portu-gal). The Philips Consumer Lifestyle BV manufacturing plant is considered one of Europe\u2019s most important Philips development centers and is devoted to producing household appliances. They provided us with three datasets corresponding to different products. The first one corresponded to logo prints on shavers. The visual inspection task required understanding whether the logo was correctly printed or had some printing defect (e.g., double printing or interrupted printing). The second one corresponded to decorative caps covering the shaving head\u2019s center, and it required identifying whether the caps were correctly manufactured or if some flow lines or marks existed. Finally, the third dataset was about toothbrush shafts transferring motion from the handle to the brush. It required identifying whether the handles were manufactured without defects or if big dents, small dents, or some stripes could be appreciated. Iber-Oleff - Componentes Tecnicos Em Pl\u00e1stico, S.A. provided us with another dataset about automobile air vents they manufacture. The air vents have three components of interest: housing, lamellas (used to direct the air), and plastic links (which keep the lamellas tied together). The visual inspection task required us to determine whether (a) the fork is leaning against the support and correctly positioned, (b) the plastic link is present, (c) the lamella 1 is present, and the link is correctly assembled, and (d) the lamella 3 is present, and the link is correctly assembled. Through the research, the researchers aimed to develop a comprehensive AI-first and human-centric approach to automated visual inspection. In particular, they (i) developed machine learning models to detect defects, (ii) used active learning to enhance the models\u2019 learning process while alleviating the need to label data, (iii) used XAI to enhance the labeling process, (iv) analyzed how data augmentation techniques at embeddings and image level, along with anomaly maps can enhance396 J. M. Ro\u017eanec et al.the machine learning discriminative capabilities, (v) how human fatigue can be detected and predicted in humans, and (vi) how to calibrate and measure models\u2019 calibration quality to provide probabilistic predictive scores. Research at the EU H2020 STAR project confirmed that active learning could alleviate the need for data labeling and help machine learning models learn better based on fewer data instances [90]. Nevertheless, the effort saved depends on the pool of unlabeled images, the use case, and the active learning strategy. Data augmentation techniques at an image or embedding level have increased the models\u2019 discriminative performance [89]. Furthermore, complementing images with anomaly maps as input to supervised classification models has substantially improved discriminative capabilities [88]. The data labeling experiments showed decreased labeling accuracy by humans over time [86], which was attributed to human fatigue. While the future labeling quality can be predicted, it requires ground truth data. This can be acquired by showing synthetically generated images. Nevertheless, more research is required to devise new models that would consider other cues and predict human fatigue in data labeling without the requirement of annotated data. Finally, predictive scores alone provide little information to the decision-maker: predictive score distributions differ across different models. Therefore, performing probability calibration is paramount to ensure probability scores have the same semantics across the models. The research compared some of the existing probability calibration techniques and developed metrics to measure and assess calibration quality regardless of ground truth availability [90]. 3.2 Human-Digital Twins in Quality Control In the context of STAR, significant advancements have been made in developing human-digital twins (HDTs). In particular, the project has developed an infras-tructure (Clawdite Platform [74]) that allows the effortless creation of replicas of human workers through instantiating their digital counterparts. These HDTs have diverse features, encompassing static characteristics, dynamic data, and behavioral and functional models [73]. To ensure a comprehensive representation of the human worker, STAR\u2019s HDT incorporates two crucial data types. Firstly, it assimilates physiological data col-lected from wearable devices. Secondly, it utilizes quasi-static data, which encapsu-lates characteristic attributes of the human, offering a holistic perspective on their traits. Central to STAR\u2019s HDT is an AI model designed to detect mental stress and physical fatigue. By leveraging physiological and quasi-static data, this AI model effectively gauges the stress and fatigue levels experienced by the human worker. This breakthrough in automated quality control holds remarkable significance, manifesting in two distinct ways:\u2022 During user manual inspection, the HDT continuously monitors the quality control process, actively identifying instances where the worker may be underHuman in the AI Loop via xAI and Active Learning for Visual Inspection 397significant mental or physical stress. In such cases, the system promptly suggests the worker take a break, ensuring their well-being and preventing any potential decline in performance.\u2022 During the training of automatic quality assessment models, as the worker evaluates and labels pictures during the dataset creation, the system periodically assigns a confidence score to each label provided by the user. This confidence score is computed based on evaluating the worker\u2019s mental and physical stress levels estimated through the HDT\u2019s AI model. By considering these stress levels as an integral part of the quality evaluation process, the HDT provides valuable insights into the worker\u2019s state of mind and physical condition, allowing one to consider these features during the training of AI models for quality assessment and control. The integration of the HDTs, supported by the Clawdite Platform, in STAR\u2019s operations signifies a significant step forward in human-AI collaboration. This inno-vative approach prioritizes human workers\u2019 well-being and empowers automated quality control systems, ensuring optimal productivity and efficiency in various industrial settings. 3.3 Making AI Visual Inspection Robust Against Adversarial Attacks In the context of the STAR project, an AI architecture was created for evaluating adversarial tactics and defense algorithms intended to safeguard, secure, and make the environments of manufacturing AI systems more reliable. More specifically, it was focused on AI-based visual inspection and tackled multiple use cases provided by two industrial partners: Philips Consumer Lifestyle BV (Drachten, The Nether-lands) and Iber-Oleff - Componentes Tecnicos Em Pl\u00e1stico, S.A. (Portugal). Current production lines are often tailored for the mass production of one product or product series in the most efficient way. Given its many advantages, AI is being increasingly adopted for quality inspection. Such models are usually trained considering some convolutional neural network (CNN), which then classifies whether a product is defective through inference upon receiving images captured by the inspection cameras. Nevertheless, such models can be attacked through adversarial data, leading AI models to wrongly classify the products (e.g., not detecting defects). For instance, the adversary may exploit a vulnerability in the visual inspection camera and compromise the integrity of the captured data by manipulating the operational behavior of this business resource. Among the various experimental testbeds built in the context of the STAR project, the ones created with soother cherries provided by Philips Consumer Lifestyle BV were the most challenging. The cherry is the upper part of the soother. The high quality of the cherry must be guaranteed to avoid any harm to the babies. Therefore, detecting any adversarial attack is of primary importance, given the398 J. M. Ro\u017eanec et al.Fig. 2 Evaluation results of pairwise comparison of adversarial attacks and defenses consequences of the attack can directly impact children\u2019s health. The goal of the testbed was to quantify the impact of adversarial attacks on classification models performing a visual inspection and evaluate how effective the defenses against such attacks were. To build the testbed, the Adversarial Robustness Toolbox [81] was used. In the experiments, the following adversarial methods were used: Fast Gradient Sign Attack (FGSM) [40], DeepFool [76], NewtonFool [49], and Projected Gradient Descent (PGD) [72]. The aim was to utilize these well-documented adversarial methods to derive crafted instances that can be used to attack the baseline classification model. Experiments were performed with defense strategies, namely feature squeezing [116], JPEG compression [31], spatial smoothing [116], TotalVarMin [43], and adversarial training [100]. To gather insights regarding adversarial tactics and defenses, they were evaluated pairwise. This enabled us to identify adversarial training as the best defense strategy to enhance the robustness of the CNN models. The basic idea behind adversarial training is to create examples that will be used later in the training process, creating a model aware of adversarial vectors launched against the quality control system. The results of the pairwise evaluation of the attacks and defenses are summarized in Fig. 2. The results are grouped into four sets based on the attack strategy. A baseline classifier was initially trained for each of the four experiments (see tag \u201cTraining\") to get the perception of the accuracy level that the quality inspection algorithm can achieve. The baseline model achieved an accuracy between 93% and 98%. The \u201cAttack\u201d bar indicates the accuracy of the classifier when posed against the adversarial attack. The DeepFool, FGSM, and PGD attacks strongly affected the classifier, causing the model\u2019s accuracy to drop below 30%. This was not the case for the NewtonFool attack, where the classifier\u2019s accuracy dropped to 84%. When considering defense strategies, feature squeezing, JPEG compression, and spatial smoothing can defend against the DeepFool attack: for the given dataset, theyHuman in the AI Loop via xAI and Active Learning for Visual Inspection 399led to an accuracy of 98%. However, TotalVarMin failed to defend the model. All the defenses failed against the FGSM and the PGD attacks. Based on the acquired results of the pairwise evaluations, it became clear that no clear mapping exists between types of attacks and defenses. Therefore, it can be challenging for defenders to plan a strategy to cope against any attack successfully. This outcome advocates the criticality and the challenge of defending against adversarial AI attacks. While the off-the-shelf and state-of-the-art defenses cannot perform in a stable manner under different adversarial methods, the adversarial training approach seems robust. The results agree with the literature, advocating that Adversarial Training can be a robust solution that can cope with adversaries despite its simplicity. A more detailed description of the abovementioned work can be found in [10]. 4 Conclusion This work has briefly introduced state-of-the-art research on human-machine collaboration, perspectives on human-centric manufacturing, and the key aspects of trustworthiness and accountability in the context of Industry 5.0. It described research on automated quality inspection, considering the role of robotics, AI approaches, and solutions to visual inspection and how a fruitful human-machine collaboration can be developed in the visual inspection domain. Finally, it described the experience and results obtained through research performed in the EU H2020 STAR project. The converging view from the literature analysis is that human-machine coop-eration requires adequate communication and control realized through effective bidirectional information exchange. Studies have been performed to understand peoples\u2019 emotional and social responses in human-machine interactions, understand task design, and how humans\u2019 trust, acceptance, decision-making, and account-ability are developed or impacted in the presence of machines. In the field of visual inspection, much research was invested in automating the task of visual inspection by developing machine learning models to detect product defects. Furthermore, many research efforts targeted the development of techniques for XAI related to machine vision. Visual aids and hints derived by XAI are conveyed to humans through heat maps. Similarly, insights obtained from unsupervised machine learning models are conveyed to humans as anomaly maps. While such approaches solve particular problems, little research describes how a human-in-the-loop approach could be developed for visual inspection in manufacturing settings. This research aims to bridge the gap by implementing existing and researching novel active learning techniques for data selection to enhance the learning of machine learning algorithms. It also explores how labeling requirements could be reduced by employing few-shot learning and active learning techniques. Furthermore, research was conducted to understand how XAI and unsupervised classification methods can be used to generate heat maps and anomaly maps to facilitate data labeling in the context of manual revision or data annotation tasks. Moreover, predictive400 J. M. Ro\u017eanec et al.models were developed to predict how heat maps and anomaly maps should be adapted over time to bridge the gap between the information conveyed by machine learning algorithms and explainability techniques and human perception. In addition, experiments were performed to gain insights related to human fatigue monitoring in the context of visual inspection. The present work described a complete and modular infrastructure developed to instantiate HDT, and different AI models for perceived fatigue exertion and mental stress have been trained to derive relevant features for human-centered production systems. Finally, it describes some research on adversarial attacks and defenses to enhance the understanding of protecting visual inspection setups in manufacturing environments. While the research presented above advances the understanding of developing a human-in-the-loop approach for visual inspection in manufacturing, many open issues remain to be solved. Further research is required to understand how adaptive humans perceive hinting and how the many solutions described above contribute to building trust between humans and machines. Furthermore, effort must be invested to quantify the benefits such solutions bring to a manufacturing plant when implemented. Future research will encompass the integration of these solutions, aiming to achieve a comprehensive and synergistic implementation. The research will aim to develop new approaches that interleave active learning and XAI. Furthermore, novel few-shot learning solutions will be considered to allow for greater flexibility of the visual inspection while reducing data labeling requirements to a minimum. Finally, integrating AI visual inspection models and the HDT is expected to significantly augment the efficacy of quality inspection processes during user manual assessment and AI model training. Acknowledgments This work was supported by the Slovenian Research Agency and the Euro-pean Union\u2019s Horizon 2020 program project STAR under grant agreement number H2020-956573. References 1. 25022:2015 I: System and software quality requirements and evaluation (square) - measure-ment of quality in use (2015) 2. 38500:2015 I: Information technology \u2014 governance of it for the organization (2015) 3. 5723 IT: Trustworthiness - vocabulary (2022) 4. 7498-2:1989 I: Information processing systems - security architecture (1989) 5. Accenture: Reworking the revolution (2018). https://www.accenture.com/_acnmedia/pdf-69/ accenture-reworking-the-revolution-jan-2018-pov.pdf 6. Aggour, K.S., Gupta, V.K., Ruscitto, D., et al.: Artificial intelligence/machine learning in manufacturing and inspection: A GE perspective. MRS Bull. 44(7), 545\u2013558 (2019) 7. Aguirre, A., Pinto, M.J., Cifuentes, C.A., et al.: Machine learning approach for fatigue estimation in sit-to-stand exercise. Sensors 21(15), 5006 (2021) 8. Amershi, S., Cakmak, M., Bradley Knox, W., Kulesza, T.: Power to the people: the role of humans in interactive machine learning. AI Mag. 35, 105\u2013120 (2014). https://doi.org/10.1609/ aimag.v35i4.2513Human in the AI Loop via xAI and Active Learning for Visual Inspection 4019. Anantrasirichai, N., Bull, D.: Artificial intelligence in the creative industries: a review. Artif. Intell. Rev., 1\u201368 (2022) 10. Anastasiou, T., Karagiorgou, S., Petrou, P., et al.: Towards robustifying image classifiers against the perils of adversarial attacks on artificial intelligence systems. Sensors 22(18), (2022). https://doi.org/10.3390/s22186905, https://www.mdpi.com/1424-8220/22/18/6905 11. Arrieta, A.B., D\u00edaz-Rodr\u00edguez, N., Del Ser, J., et al.: Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Inf. Fusion 58, 82\u2013115 (2020) 12. Bansal, G., Nushi, B., Kamar, E., et al.: Beyond accuracy: The role of mental models in human-AI team performance. In: Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, pp. 2\u201311 (2019) 13. Bettoni, A., Montini, E., Righi, M., et al.: Mutualistic and adaptive human-machine collabo-ration based on machine learning in an injection moulding manufacturing line. Procedia CIRP 93, 395\u2013400 (2020) 14. Bharti, S., McGibney, A., O\u2019Gorman, T.: Edge-enabled federated learning for vision based product quality inspection. In: 2022 33rd Irish Signals and Systems Conference (ISSC), pp. 1\u20136 (2022). https://doi.org/10.1109/ISSC55427.2022.9826185 15. Bodria, F., Giannotti, F., Guidotti, R., et al.: Benchmarking and survey of explanation methods for black box models. Data Mining Knowl. Discovery, 1\u201360 (2023) 16. Breque, M., De Nul, L., Petridis, A.: Industry 5.0: Towards a sustainable, human-centric and resilient European industry (2021) 17. Brito, T., Queiroz, J., Piardi, L., et al.: A machine learning approach for collaborative robot smart manufacturing inspection for quality control systems. Procedia Manuf. 51, 11\u201318 (2020) 18. Cai, C.J., Reif, E., Hegde, N., et al.: Human-centered tools for coping with imperfect algorithms during medical decision-making. In: Proceedings of the 2019 Chi Conference on Human Factors in Computing Systems, pp. 1\u201314 (2019) 19. Cao, G., Ruan, S., Peng, Y., et al.: Large-complex-surface defect detection by hybrid gradient threshold segmentation and image registration. IEEE Access 6, 36235\u201336246 (2018). https:// doi.org/10.1109/ACCESS.2018.2842028 20. Cao, L.: A new age of AI: Features and futures. IEEE Intell. Syst. 37(1), 25\u201337 (2022) 21. Chin, R.T., Harlow, C.A.: Automated visual inspection: A survey. IEEE Trans. Pattern Anal. Mach. Intell. 4(6), 557\u2013573 (1982) 22. Chuang, S.: Indispensable skills for human employees in the age of robots and AI. Eur. J. Train. Dev. (ahead-of-print) (2022) 23. Chugunova, M., Sele, D.: We and it: An interdisciplinary review of the experimental evidence on human-machine interaction. Center for law & economics working paper series 12 (2020) 24. Ciregan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp 3642\u20133649. IEEE (2012) 25. Czimmermann, T., Ciuti, G., Milazzo, M., et al.: Visual-based defect detection and classifica-tion approaches for industrial applications\u2014a survey. Sensors 20(5), 1459 (2020) 26. Daniel, C., Viering, M., Metz, J., et al.: Active reward learning. In: Robotics: Science and Systems (2014) 27. Das, A., Rad, P.: Opportunities and challenges in explainable artificial intelligence (XAI): A survey. Preprint (2020). arXiv:200611371 28. Deloitte: The rise of the social enterprise. 2018 Deloitte global human capital trends (2018). https://www2.deloitte.com/content/dam/insights/us/articles/HCTrends2018/ 2018-HCtrends_Rise-of-the-social-enterprise.pdf 29. Directorate-General for Research and Innovation, European Commission, Breque, M., De Nul, L., Petridis, A.: Industry 5.0: towards a sustainable, human centric and resilient European industry. Publications Office of the European Union (2021). https://op.europa.eu/ en/publication-detail/-/publication/468a892a-5097-11eb-b59f-01aa75ed71a1/language-en402 J. M. Ro\u017eanec et al.30. Doshi-Velez, F., Kim, B.: Towards a rigorous science of interpretable machine learning. Preprint (2017). arXiv:170208608 31. Dziugaite, G.K., Ghahramani, Z., Roy, D.M.: A study of the effect of jpg compression on adversarial images. Preprint (2016). arXiv:160800853 32. EESC: Industry 5.0 (2018). https://www.eesc.europa.eu/en/agenda/our-events/events/ industry-50, Accessed: 24 May 2023 33. Emmanouilidis, C., Pistofidis, P., Bertoncelj, L., et al.: Enabling the human in the loop: Linked data and knowledge in industrial cyber-physical systems. Annu. Rev. Control 47, 249\u2013265 (2019). https://doi.org/10.1016/j.arcontrol.2019.03.004 34. Emmanouilidis, C., Waschull, S., Bokhorst, J.A., et al.: Human in the AI Loop in Production Environments, vol. 633 IFIP. Springer Science and Business Media Deutschland GmbH, pp. 331\u2013342 (2021). https://doi.org/10.1007/978-3-030-85910-7_35 35. European Commission: Ethics guidelines for trustworthy AI (2019) 36. European Commision: Laying down harmonised rules on artificial intelligence (artificial intelligence act) and amending certain union legislative acts (2021) 37. Frustaci, F., Spagnolo, F., Perri, S., et al.: Robust and high-performance machine vision system for automatic quality inspection in assembly processes. Sensors 22, 2839 (2022). https://doi.org/10.3390/s22082839, https://www.mdpi.com/1424-8220/22/8/2839 38. Fu, Y., Zhu, X., Li, B.: A survey on instance selection for active learning. Knowl. Inf. Syst. 35(2), 249\u2013283 (2013) 39. Gerber, A., Derckx, P., D\u00f6ppner, D.A., et al.: Conceptualization of the human-machine symbiosis\u2014a literature review. In: Proceedings of the 53rd Hawaii International Conference on System Sciences (2020) 40. Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. In: Bengio Y, LeCun Y (eds) 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7\u20139, 2015, Conference Track Proceedings (2015) 41. Gr\u00f8nsund, T., Aanestad, M.: Augmenting the algorithm: Emerging human-in-the-loop work configurations. J. Strat. Inf. Syst. 29, 101614 (2020). https://doi.org/10.1016/j.jsis.2020. 101614 42. Gu, T., Dolan-Gavitt, B., Garg, S.: Badnets: Identifying vulnerabilities in the machine learning model supply chain. Preprint (2017). arXiv:170806733 43. Guo, C., Rana, M., Cisse, M., et al.: Countering adversarial images using input transforma-tions. In: International Conference on Learning Representations (2018). https://openreview. net/forum?id=SyJ7ClWCb 44. Heyer, C.: Human-robot interaction and future industrial robotics applications. In: 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp 4749\u20134754. IEEE (2010) 45. Hoffman, R.R., Mueller, S.T., Klein, G., et al.: Metrics for explainable ai: Challenges and prospects. Tech. rep., DARPA Explainable AI Program (2018) 46. Hohma, E., Boch, A., Trauth, R., et al.: Investigating accountability for artificial intelligence through risk governance: A workshop-based exploratory study. Front. Psychol. 14, 86 (2023) 47. Hooda, R., Joshi, V., Shah, M.: A comprehensive review of approaches to detect fatigue using machine learning techniques. Chronic Dis. Transl. Med. 8(1), 26\u201335 (2022) 48. Hu, Z., Lou, S., Xing, Y., et al.: Review and perspectives on driver digital twin and its enabling technologies for intelligent vehicles. IEEE Trans. Intell. Veh. (2022) 49. Jang, U., Wu, X., Jha, S.: Objective metrics and gradient descent algorithms for adversarial examples in machine learning. In: Proceedings of the 33rd Annual Computer Security Applications Conference. Association for Computing Machinery, New York, NY, USA, ACSAC \u201917, pp. 262\u2013277 (2017). https://doi.org/10.1145/3134600.3134635 50. Jarrahi, M.H.: Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. Bus. Horizons 61(4), 577\u2013586 (2018) 51. Jarrahi, M.H., Davoudi, V., Haeri, M.: The key to an effective AI-powered digital pathology: Establishing a symbiotic workflow between pathologists and machine. J. Pathol. Inf. 13, 100156 (2022)Human in the AI Loop via xAI and Active Learning for Visual Inspection 40352. John Rajan, A., Jayakrishna, K., Vignesh, T., et al.: Development of computer vision for inspection of bolt using convolutional neural network. Mater. Today Proc. 45, 6931\u20136935 (2021). https://doi.org/10.1016/j.matpr.2021.01.372, https://www.sciencedirect.com/science/ article/pii/S2214785321004636. International Conference on Mechanical, Electronics and Computer Engineering 2020: Materials Science 53. Jwo, J.S., Lin, C.S., Lee, C.H.: Smart technology\u2013driven aspects for human-in-the-loop smart manufacturing. Int. J. Adv. Manuf. Technol. 114, 1741\u20131752 (2021) 54. Kaasinen, E., Anttila, A.H., Heikkil\u00e4, P., et al.: Smooth and resilient human\u2013machine teamwork as an industry 5.0 design challenge. Sustainability 14(5), 2773 (2022) 55. Kim, T.H., Kim, H.R., Cho, Y.J.: Product inspection methodology via deep learning: An overview. Sensors 21(15), 5039 (2021). https://doi.org/10.3390/s21155039 56. Kosuge, K., Hirata, Y.: Human-robot interaction. In: 2004 IEEE International Conference on Robotics and Biomimetics, pp. 8\u201311. IEEE (2004) 57. Kri\u017enar, K., Ro\u017eanec, J.M., Fortuna, B., et al.: Explainable artificial intelligence meets active learning: A novel gradcam-based active learning strategy, submitted (2023) 58. Kumar, P., Gupta, A.: Active learning query strategies for classification, regression, and clustering: A survey. J. Comput. Sci. Technol. 35(4), 913\u2013945 (2020) 59. Lambert, A., Norouzi, N., Bruder, G., et al.: A systematic review of ten years of research on human interaction with social robots. Int. J. Human Comput. Interact. 36(19), 1804\u20131817 (2020) 60. Langley, P.: Interactive cognitive systems and social intelligence. IEEE Intell. Syst. 32, 22\u201330 (2017). https://doi.org/10.1109/MIS.2017.3121556 61. Leach, R., Bourell, D., Carmignato, S., et al.: Geometrical metrology for metal additive manufacturing. CIRP Ann. 68(2), 677\u2013700 (2019) 62. Leng, J., Sha, W., Wang, B., et al.: Industry 5.0: Prospect and retrospect. J. Manuf. Syst. 65, 279\u2013295 (2022) 63. Leone, A., Rescio, G., Siciliano, P., et al.: Multi sensors platform for stress monitoring of workers in smart manufacturing context. In: 2020 IEEE International Instrumentation and Measurement Technology Conference (I2MTC), pp 1\u20135. IEEE (2020) 64. Liapis, A., Yannakakis, G.N., Alexopoulos, C., et al.: Can computers foster human users\u2019 creativity? theory and praxis of mixed-initiative co-creativity. Digit. Cult. Educ. 8, (2016) 65. Licklider, J.C.R.: Man-computer symbiosis. IRE Trans. Human Fact. Electron. HFE-1(1), 4\u201311 (1960). https://doi.org/10.1109/THFE2.1960.4503259 66. Liu, J., Guo, F., Gao, H., et al.: Defect detection of injection molding products on small datasets using transfer learning. J. Manuf. Process. 70, 400\u2013413 (2021). https://doi.org/10. 1016/j.jmapro.2021.08.034 67. Longo, F., Padovano, A., Umbrello, S.: Value-oriented and ethical technology engineering in industry 5.0: A human-centric perspective for the design of the factory of the future. Appl. Sci. 10(12), 4182 (2020) 68. Lu, Y.: The current status and developing trends of industry 4.0: A review. Inf. Syst. Front., 1\u201320 (2021) 69. Lughofer, E.: On-line active learning: A new paradigm to improve practical useability of data stream modeling methods. Inf. Sci. 415, 356\u2013376 (2017) 70. Lyytinen, K., Nickerson, J.V., King, J.L.: Metahuman systems = humans + machines that learn. J. Inf. Technol. (2020). https://doi.org/10.1177/0268396220915917 71. Maddikunta, P.K.R., Pham, Q.V., Prabadevi, B., et al.: Industry 5.0: A survey on enabling technologies and potential applications. J. Ind. Inf. Integr. 26, 100257 (2022) 72. Madry, A., Makelov, A., Schmidt, L., et al.: Towards deep learning models resistant to adversarial attacks. In: 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30\u2013May 3, 2018, Conference Track Proceedings (2018). OpenReview.net. https://openreview.net/forum?id=rJzIBfZAb 73. Montini, E., Bettoni, A., Ciavotta, M., et al.: A meta-model for modular composition of tailored human digital twins in production. Procedia CIRP 104, 689\u2013695 (2021)404 J. M. Ro\u017eanec et al.74. Montini, E., Cutrona, V., Bonomi, N., et al.: An iiot platform for human-aware factory digital twins. Procedia CIRP 107, 661\u2013667 (2022) 75. Montini, E., Cutrona, V., Dell\u2019Oca, S., et al.: A framework for human-aware collaborative robotics systems development. Procedia CIRP (2023) 76. Moosavi-Dezfooli, S.M., Fawzi, A., Frossard, P.: DeepFool: a simple and accurate method to fool deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2574\u20132582 (2016) 77. Mosqueira-Rey, E., Hern\u00e1ndez-Pereira, E., Alonso-R\u00edos, D., et al.: Human-in-the-loop machine learning: a state of the art. Artif. Intell. Rev. (2022). https://doi.org/10.1007/s10462-022-10246-w 78. Mukherjee, D., Gupta, K., Chang, L.H., et al.: A survey of robot learning strategies for human-robot collaboration in industrial settings. Robot. Comput. Integr. Manuf. 73, 102231 (2022) 79. M\u00fcller, D., M\u00e4rz, M., Scheele, S., et al.: An interactive explanatory AI system for industrial quality control. In: Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference on Innovative Applications of Artificial Intelligence, IAAI 2022, The Twelfth Symposium on Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event, February 22\u2013March 1, 2022, pp. 12580\u201312586. AAAI Press (2022) 80. Newman, T.S., Jain, A.K.: A survey of automated visual inspection. Comput. Vis. Image Understand. 61(2), 231\u2013262 (1995) 81. Nicolae, M.I., Sinn, M., Tran, M.N., et al.: Adversarial robustness toolbox v1.0.0. Preprint (2018). arXiv:180701069 82. Paul, S., Yuan, L., Jain, H.K., et al.: Intelligence augmentation: Human factors in ai and future of work. AIS Trans. Human Comput. Interact. 14(3), 426\u2013445 (2022) 83. Rahwan, I., Cebrian, M., Obradovich, N., et al.: Machine behaviour. Machine Learning and the City: Applications in Architecture and Urban Design, pp. 143\u2013166 (2022) 84. Ramesh, A., Dhariwal, P., Nichol, A., et al.: Hierarchical text-conditional image generation with CLIP latents. Preprint (2022). arXiv:220406125 85. Ren, P., Xiao, Y\u201e Chang, X., et al.: A survey of deep active learning. ACM Comput. Surv. (CSUR) 54(9), 1\u201340 (2021) 86. Ro\u017eanec, J.M., Karel, K., Montini, E., et al.: Predicting operators\u2019 fatigue in a human in the artificial intelligence loop for defect detection in manufacturing. In: Proceedings of the 2023 IFAC World Congress (2023) 87. Ro\u017eanec, J.M., Fortuna, B., Mladenic\u0301, D.: The future of data mining. chapter 6: Active learning (2022). https://doi.org/10.52305/KCIN5931 88. Ro\u017eanec, J.M., Zajec, P., Theodoropoulos, S., et al.: Robust anomaly map assisted multiple defect detection with supervised classification techniques. Preprint (2022). arXiv:221209352 89. Ro\u017eanec, J.M., Zajec, P., Theodoropoulos, S., et al.: Synthetic data augmentation using GAN for improved automated visual inspection. Preprint (2022). arXiv:221209317 90. Ro\u017eanec, J.M., Bizjak, L., Trajkova, E., et al.: Active learning and novel model calibration measurements for automated visual inspection in manufacturing. J. Intell. Manuf., 1\u201322 (2023) 91. Saiz, F.A., Alfaro, G., Barandiaran, I.: An inspection and classification system for automotive component remanufacturing industry based on ensemble learning. Information 12(12), (2021) 92. Schwalbe, G., Finzel, B.: A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts. Data Mining Knowl. Disc., 1\u201359 (2023) 93. Scott, A.C., Clancey, W.J., Davis, R., et al.: Explanation capabilities of production-based consultation systems. Tech. rep., Stanford Univ CA Dept Of Computer Science (1977) 94. See, J.E.: Visual inspection: a review of the literature. Sandia Report SAND2012-8590, Sandia National Laboratories, Albuquerque, New Mexico (2012) 95. Settles, B.: Active learning literature survey. Tech. rep., University of Wisconsin-Madison Department of Computer Sciences (2009) 96. Shokri, R., et al.: Bypassing backdoor detection algorithms in deep learning. In: 2020 IEEE European Symposium on Security and Privacy (EuroS&P), pp 175\u2013183. IEEE (2020)Human in the AI Loop via xAI and Active Learning for Visual Inspection 40597. Sikander, G., Anwar, S.: Driver fatigue detection systems: A review. IEEE Trans. Intell. Transp. Syst. 20(6), 2339\u20132352 (2018) 98. Silva, B., Marques, R., Faustino, D., et al.: Enhance the injection molding quality prediction with artificial intelligence to reach zero-defect manufacturing. Processes 11, (2023). https:// doi.org/10.3390/pr11010062 99. Sugiyama, M., Kawanabe, M.: Active Learning, pp 183\u2013214. MIT Press (2012) 100. Szegedy, C., Zaremba, W., Sutskever, I., et al.: Intriguing properties of neural networks. In: Bengio, Y., LeCun, Y. (eds.) 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14\u201316, 2014, Conference Track Proceedings (2014) 101. Tang, F., Mohammed, M., Longazo, J.: Experiments of human-robot teaming under sliding autonomy. In: 2016 IEEE International Conference on Advanced Intelligent Mechatronics (AIM), pp 113\u2013118 (2016). https://doi.org/10.1109/AIM.2016.7576752 102. Tripicchio, P., Camacho-Gonzalez, G., D\u2019Avella, S.: Welding defect detection: coping with artifacts in the production line. Int. J. Adv. Manuf. Technol. 111, 1659\u20131669 (2020). https:// doi.org/10.1007/s00170-020-06146-4 103. Tsai, D.M., Jen, P.H.: Autoencoder-based anomaly detection for surface defect inspection. Adv. Eng. Inf. 48, (2021). https://doi.org/10.1016/j.aei.2021.101272 104. Tschang, F.T., Almirall, E.: Artificial intelligence as augmenting automation: Implications for employment. Acad. Manag. Perspect. 35(4), 642\u2013659 (2021) 105. Tsvetkova, M., Yasseri, T., Meyer, E.T., et al.: Understanding human-machine networks: a cross-disciplinary survey. ACM Comput. Surv. (CSUR) 50(1), 1\u201335 (2017) 106. van Berkel, N., Skov, M.B., Kjeldskov, J.: Human-AI interaction: intermittent, continuous, and proactive. Interactions 28(6), 67\u201371 (2021) 107. Villalba-Diez, J., Schmidt, D., Gevers, R., et al.: Deep learning for industrial computer vision quality control in the printing industry 4.0. Sensors 19(18), 3987 (2019) 108. Wallace, E., Rodriguez, P., Feng, S., et al.: Trick me if you can: Human-in-the-loop generation of adversarial examples for question answering. Trans. Assoc. Comput. Linguist. 7, 387\u2013401 (2019) 109. Wang, Y., Yao, Q., Kwok, J.T., et al.: Generalizing from a few examples: A survey on few-shot learning. ACM Comput. Surv. (CSUR) 53(3), 1\u201334 (2020) 110. Wilson, H.J., Daugherty, P.R.: Collaborative intelligence: Humans and AI are joining forces. Harv. Bus. Rev. 96(4), 114\u2013123 (2018) 111. Wu, D.: Pool-based sequential active learning for regression. IEEE Trans. Neural Networks Learn. Syst. 30(5), 1348\u20131359 (2018) 112. Wu, J., Huang, Z., Hu, Z., et al.: Toward human-in-the-loop AI: Enhancing deep rein-forcement learning via real-time human guidance for autonomous driving. Engineering 21, 75\u201391 (2023). https://doi.org/10.1016/j.eng.2022.05.017, https://www.sciencedirect.com/ science/article/pii/S2095809922004878 113. Wu, X., Xiao, L., Sun, Y., et al.: A survey of human-in-the-loop for machine learning. Fut. Gener. Comput. Syst. 135, 364\u2013381 (2022). https://doi.org/10.1016/j.future.2022.05.014, https://www.sciencedirect.com/science/article/pii/S0167739X22001790 114. Xiong, W., Fan, H., Ma, L., et al.: Challenges of human\u2014machine collaboration in risky decision-making. Front. Eng. Manag. 9(1), 89\u2013103 (2022) 115. Xu, F., Uszkoreit, H., Du, Y., et al.: Explainable AI: A brief survey on history, research areas, approaches and challenges. In: CCF International Conference on Natural Language Processing and Chinese Computing, pp 563\u2013574. Springer (2019) 116. Xu, W., Evans, D., Qi, Y.: Feature squeezing: Detecting adversarial examples in deep neural networks. Preprint (2017). arXiv:170401155 117. Yun, J.P., Shin, W.C., Koo, G., et al.: Automated defect inspection system for metal surfaces based on deep learning and data augmentation. J. Manuf. Syst. 55, 317\u2013324 (2020) 118. Zajec, P., Ro\u017eanec, J.M., Theodoropoulos, S., et al.: Few-shot learning for defect detection in manufacturing, submitted (2023) 119. Zhu, D., Li, Z., Wang, X., et al.: A robust zero-sum game framework for pool-based active learning. In: The 22nd International Conference on Artificial Intelligence and Statistics, pp 517\u2013526. PMLR (2019)406 J. M. Ro\u017eanec et al.Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 Thomas Hoch, Jorge Martinez-Gil, Mario Pichler, Agastya Silvina, Bernhard Heinzl, Bernhard Moser, Dimitris Eleftheriou, Hector Diego Estrada-Lugo, and Maria Chiara Leva 1 Introduction The potential applications of AI in smart manufacturing are numerous, ranging from improving the efficiency of machinery maintenance to detecting defects in the machine or the product to preventing worker injury. AI-based systems can identify bottlenecks, optimize production schedules, and adjust settings to maximize efficiency by analyzing large amounts of data from sensors and other sources in real time. Furthermore, AI-based software systems can provide context-specific support to machine operators. By monitoring machine performance in real time, these systems can detect potential issues, give the operators recommended actions to solve the problem, and even automate the resolution, if necessary. This support can reduce operator errors, improve machine up-time, and increase productivity. In general, collaborative processes in smart manufacturing are characterized by alternating phases of reactive and proactive elements, with each actor supporting the other alternately [1]. AI-enabled smart manufacturing systems can be self-sensing, self-adapting, self-organizing, and self-decision [2, 3], enabling them to respond to physical changes in the production environment in a variety of ways. T. Hoch \u00b7 J. Martinez-Gil (\u0002) \u00b7 M. Pichler \u00b7 A. Silvina \u00b7 B. Heinzl \u00b7 B. Moser Software Competence Center Hagenberg GmbH, Hagenberg, Austria e-mail: thomas.hoch@scch.at; Jorge.Martinez-Gil@scch.at; Mario.Pichler@scch.at; Agastya.Silvina@scch.at; Bernhard.Heinzl@scch.at; Bernhard.Moser@scch.at D. Eleftheriou CORE Innovation, Athens, Greece e-mail: d.eleftheriou@protonmail.com H. D. Estrada-Lugo \u00b7 M. C. Leva Technological University Dublin, School of Environmental Health, Dublin, Ireland e-mail: hectordiego.estradalugo@tudublin.ie; mariachiara.leva@TUDublin.ie \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_23407408 T. Hoch et al.Fig. 1 Teaming.AI project overview AI-guided interactions in the manufacturing process include stopping machines, adapting production tasks, or suggesting a change in production parameters. However, achieving effective teaming between machine operators and AI-enabled manufacturing systems requires mutual trust based primarily on the self-sensing and self-adaptation of each actor [4]. The increased situational awareness through an improved Human-AI collabo-ration enables operators to make informed decisions about optimizing machine settings and adjusting production schedules. This collaboration can improve product quality, reduce waste, and increase efficiency [5]. As AI continues to evolve, we can expect to see even more significant advances in smart manufacturing in the years to come. In the frame of the international research project Teaming.AI,1 we develop a software platform to facilitate human-AI teaming in smart manufacturing as shown if Fig. 1. We already presented reference architecture in [6]. However, in this work, we elaborate on different stakeholders\u2019 requirements regarding the quality characteristics of AI software platforms. For this purpose, we conducted 14 structured interviews with various stakeholders of the prospective platform. They rated a set of 11 different quality characteristics and provided vital success factors that can evaluate the fulfillment of these quality characteristics during the development and operation of the platform. The results of our study provide valuable insights into the different stakeholders\u2019 expectations and remark on the importance of addressing their specific needs in the platform\u2019s design and development. Considering these quality characteristics and critical success factors, we can ensure effective collaboration between human operators and AI systems.1 https://www.teamingai-project.eu/. Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 409The remainder of this work is structured as follows: Sect. 2 presents the related work regarding stakeholder interaction in AI-related projects. Section 3 addresses the three use cases we have faced in the context of the Teaming.AI project. Section 4 details stakeholders\u2019 different roles in projects of this type. Section 5 discusses the pains identified when implementing such a solution. Section 6 discusses the expectations toward the technical realization. Section 7 discusses the characteristics of the high-level teaming concept. Finally, we point out the lessons we have learned in this work and some lines of future work. 2 Related Work The field of human-AI collaboration has gained significant attention in recent years, driven by the emphasis on integrating AI technologies into collaborative work settings in Industry 5.0 [7\u201312]. This growing interest revolves around the explo-ration of how AI systems can complement human abilities rather than replace them. Numerous studies have delved into different aspects of human-AI collaboration, including the design of intelligent systems [13], the development of new interaction paradigms [14], and the evaluation of the usefulness of these approaches in real-world scenarios [15]. One area of study in human-AI collaboration strives to design AI systems that can work effectively with human counterparts. Researchers have examined various strategies for designing intelligent systems to communicate and collaborate with human users, including natural language processing, machine learning, and cognitive modeling [14]. Additionally, some studies have focused on designing new interaction paradigms that enable seamless collaboration between humans and AI systems. For example, researchers have investigated using augmented and virtual reality to create immersive environments that improve human-AI interaction. Another focus is evaluating their usage in real-world scenarios. Several studies analyze the impact of AI systems on the performance of human workers, as well as their acceptance and adoption of these systems. These studies have explored dif-ferent elements that influence the success of human-AI collaboration, such as trust, transparency, and the nature of the tasks being performed [16]. Additionally, some researchers have investigated the ethical implications of human-AI collaboration, such as the potential for bias in decision-making processes. Within this context, Knowledge graphs (KGs) have also become a powerful tool for making production lines more efficient and flexible in manufacturing and production [17]. They provide a means of organizing and processing vast amounts of data about devices, equipment, machine models, location, usage, and other related data [18]. KGs can also help make manufacturing smarter by providing insights into the complex and competitive landscape [19]. This can enable manufacturers to identify patterns, trends, and correlations that were previously hidden, leading to more informed decision-making and improved operational efficiency. The potential410 T. Hoch et al.benefits of KGs in manufacturing and production make them an essential technology for the future of industrial operations and highlight the importance of continued research and development in this field [20]. Especially interesting and relevant in this context are recent AI developments like ChatGPT by OpenAI2 and Luminous by Aleph Alpha.3 Both of them are providing natural language interfaces for their human users, so that they are able to express their problems, information needs etc. through their most natural communication means. This seems beneficial especially in situations of mental pressure or other forms of stress that workers might have to cope with in their daily routines. The TEAMING.AI sister project COALA4 performs research on such kinds of voice-enabled digital intelligent assistants. With Luminous-Explore, Aleph Alpha points out the importance of semantic representations,5 so that humans are no more forced to represent their thoughts and intentions in machine representations but are enabled to expressing them in a more natural way. With those kind of developments, Aleph Alpha is also focusing on industrial use cases of their technology.6 3 Manufacturing Context The following use cases (UC) describe concrete applications where an AI-based smart manufacturing solution could support a Human and AI collaboration in a manufacturing context. UC1 and UC2 derive from automotive suppliers and cover the process of plastic injection molding. In UC3, we investigate the ergonomic risk assessment during large-part manufacturing. Optimization focuses on the interplay between AI-controlled machine tasks and manual human labor. 3.1 UC1: Quality Inspection The main objective of UC1 is to support the machine operator during the visual quality inspection of plastic parts produced by injection molding. The software platform shall classify products as OK or not-OK (including the type of defect), with the machine operator double-checking the latter. The software system interacts with the machine operator during the quality inspection and provides context-specific information for fault analysis and adjusting parameters to mitigate product defects.2 https://openai.com/blog/chatgpt. 3 https://www.aleph-alpha.com/. 4 https://www.coala-h2020.eu/. 5 https://www.aleph-alpha.com/luminous-explore-a-model-\\for-world-class-semantic-representation. 6 https://de.nachrichten.yahoo.com/aleph-alpha-weg-halben-einhorn-125545116.html. Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 411The main focus is on integrating human feedback: The machine operator should have the chance to overrule and correct the suggestions of the AI system, e.g., by manually marking defective regions if they were classified wrong. This collaborative interaction between the machine operator and the software platform reinforces the notion of human-AI partnership, with each contributing their unique strengths to achieve the best possible outcomes. It empowers the machine operator with the authority to validate and correct AI decisions while ensuring continuous learning and improvement of the AI system by incorporating the operator\u2019s feedback [21]. 3.2 UC2: Parameter Optimization UC2 is also concerned with injection molding. However, the produced plastic parts are bigger, and cycle times are longer. Therefore, the software platform should provide a more proactive way to reduce and prevent non-OK parts effectively (zero waste production). The software platform should predict possible process deviations and identify the likely root failure causes before they materialize in faulty parts. It should be able to explain its findings (e.g., likelihoods), present recommendations (e.g., on parameter changes), and give the machine operator the ability to provide feedback to the software platform. To achieve this proactive approach, the software platform leverages its analytical capabilities to predict possible process deviations. It analyzes real-time data from various sensors and monitors the production parameters to identify patterns or anomalies that might indicate an impending issue. The software platform can provide the machine operator with early warnings and proactive recommendations by continuously monitoring and analyzing the production process. 3.3 UC3: Ergonomic Risk Assessment UC3 focuses on high-precision manufacturing of significant components (e.g., gear cases for wind turbines). This manufacturing process is typically time-consuming, physically strenuous, and involves a combination of automated and manual labor. The objective is to analyze the ergonomic risks of human workers in terms of static loads and repetitive strains, especially during workpiece setup (involving manual part positioning, clamping, unloading, etc.). Using a camera-based tracking system, the software platform can determine the location of the machine operators on the shop floor, analyze their pose for ergonomic suitability and give feedback to the operator, e.g., via alerts. In addition, the software platform should also identify manual tasks associated with milling operations (e.g., taking measurements) and collect information about the tooling used during these tasks. This way, the software412 T. Hoch et al.platform mediates between the milling machine and the operator by combining this information with context information, such as machine data. Overall, the software system should 1. Improve communication between the operator and the machine 2. Perform a continuous ergonomic risk assessment 3. Allow rescheduling of similar assembly tasks to reduce repetitive strains By incorporating these functionalities, the software platform empowers both the machine operator and the milling machine to work in harmony, prioritizing the well-being and safety of the operator. It is an intelligent assistant providing real-time insights, guidance, and risk assessments to optimize ergonomics and prevent work-related injuries. This holistic approach promotes a healthier and more productive working environment, ensuring the efficient manufacturing of large parts while prioritizing the workers\u2019 welfare. 4 Stakeholder Roles In the following, we describe the different stakeholder roles with their exemplary activities identified during requirements engineering. \u2022 Data Protection Officer (DPO) enforces the laws protecting the company and individuals\u2019 data (e.g., the GDPR) by controlling the processing of data and properly auditing the system. \u2022 Software Scientist (SS) queries runtime data of the software components of the software platform, such as logging information, for evaluating and optimizing the system\u2019s base code and behavior. \u2022 Data Scientist (DS) applies statistical methods to the data processed by a software platform. \u2022 Machine Operator (MO) performs a visual inspection of the produced parts, clamping, adjusting the workpieces, and performing manual tasks on the machine, such as obtaining measurements and making parameter adjustments. \u2022 Production Line Manager (PLM) monitors and optimizes the processes for producing and assembling the product or its parts on the shop floor. The involvement of these stakeholders, each with their unique roles and activities, highlights the multi-dimensional nature of the software platform and its impact on various aspects of the manufacturing process. By incorporating these stakeholders\u2019 expertise and responsibilities, the software platform\u2019s development and operation can benefit from a well-rounded perspective, ensuring compliance, optimization, data analysis, production efficiency, and quality assurance.Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 4135 Identified Pains According to [22], pains are \u201cbad outcomes, risks, and obstacles related to customer jobs.\u201d In a collaborative project like Teaming.AI, the end users\u2019 participation enables the technical side to address real market needs. To this end, two questionnaires were circulated among all use case partners to identify the existing issues and pains related to their processes and understand the potential benefits they would expect from the technologies developed. Each questionnaire is directed toward two categories of employees: (1) Managers, who can present more managerial challenges of the organization, and (2) Operators, who can more effectively depict their day-to-day challenges and are the active users of the machines that will be retrofitted. Specifically, the questionnaire was circulated among 18 individuals who partic-ipated in the study and distributed evenly for each use case through the EUSurvey platform.7 The personas analyzed included: \u2022 Injection Technician \u2022 Production Shift Coordinator \u2022 Operator \u2022 Engineering Director \u2022 Process Managers \u2022 R&D Manager \u2022 Innovation Manager \u2022 Production Manager \u2022 Head of Automotive Digital Transformation \u2022 Data Scientist The first section of the questionnaire aimed to analyze the profile of each end user. Overall, all end users are more results-driven organizations. When asked about the top 2 priorities in selecting third-party collaboration for Industry 4.0 initiatives, 78% preferred parties with proven pilot cases. The next most selected priority involved the ability to ensure an easier integration of solutions by 45% of the respondents. The third and fourth most selected priorities were results-oriented and involved the capacity to promise short-term value and the market participant\u2019s brand acknowledgment with 34% and 23%, respectively. Less prominent options also included the proximity of the technology provider and the sustainability improvement. 5.1 UC1: Quality Inspection This particular use case involved the participation of the following roles:7 https://ec.europa.eu/eusurvey/auth/login. 414 T. Hoch et al.\u2022 Data scientist \u2022 Head of Mobile and Digital Transformation \u2022 R&D Manager \u2022 Operator Overall, the results indicate that the end user faces pains primarily within the production department, which also affects coordinating activities. Specifically: 1. Setup parametrization: The most significant bottleneck in the particular pro-duction system, according to the respondents. As the manufacturing context section demonstrates, adjusting the parameters is necessary to mitigate product defects. 2. Scrap Generation: Causes for scrap generation can emerge from lack of quality raw materials, setup mistakes, machine issues, etc. Although scrap generation is considered financially sustainable, it impacts planning and financing. 3. Unexpected downtime/equipment failures: Mechanical and electrical failures accompanied by non-optimal maintenance are primary factors leading to failures. 4. Loss of time: Issues related to time loss refer to production delays, waste generation, lack of raw materials, non-productive processes, etc. 5. Not optimal production quality: The capacity to be prone to errors is affected by the level of control in the existing production system. 6. Increased inventory: Supply chain disruptions and unexpected failures lead to material unavailability, which leads planners to over-order to ensure that production does not remain stagnant. 7. Lack of Flexibility in tasks and product design: Flexibility is not limited to how operators are liberated to move between activities but also to the ability to switch between orders and in the adaptability to produce different types of products. 5.2 UC2: Parameter Optimization The second use case of the project involved the following six roles: \u2022 Engineering Director \u2022 Injection Technician \u2022 Operator \u2022 Process Manager \u2022 Production shift technician \u2022 R&D Manager As mentioned above, the first two use cases encounter similarities between each other contextually and, by extension, similar pains. Specifically: 1. Setup parameterization: The level of operator expertise influences the possibil-ity for a defect to occur.Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 4152. Unexpected downtimes/equipment failures: The main consequence of unex-pected downtimes leads to production pauses and redirection of employees to other places. 3. Lack of human-machine interaction: Similarly with the first pain, the level of expertise has a dominant impact on production and handling impending issues. 4. Loss of time: The primary concern is from a managerial perspective. Identified loss of time lies in sales, dispatch, unexpected failures, and scrap generation for the organization. 5. Scrap generation: At a similar level with UC1. However, areas such as cost management and logistics would be the first areas to be improved by reducing scrap in production. 6. Increased inventory: Even though scrap generation is considered sustainable, it directly influences the purchasing and warehouse departments, which need to add to their risk management and planning activities. 7. Increasing Costs: Although all UCs experience increased costs due to other pains, UC2 respondents have highlighted the challenges in their cost manage-ment activities. 5.3 UC3: Ergonomic Risk Assessment The third and final use case focused on the following roles: \u2022 Injection Technician \u2022 Innovation Manager \u2022 Machine Operator \u2022 Operator \u2022 Production Manager \u2022 R&D Manager Following the questionnaire results, the ergonomic risk assessment use case is characterized by the following pains: 1. Setup parameters: In UC3, operators indicate that setup difficulties make them feel there is a lack of time. 2. Unexpected downtimes/equipment failures: Similarly to other use cases, it leads to high rework costs. 3. Waste generation: Classified as below average, there is an excess of production material waste in the current form of processes. 4. The system does not help meet scheduling demands: Bureaucracy leads to a lack of control over increasing equipment productivity. 5. Delivery delays: Inability to meet scheduling demands on time lead to delivery delays and profit reductions. 6. Increased inventory: Like all the use cases mentioned above, over-ordering leads to an increased inventory and profit reduction.416 T. Hoch et al.7. Not optimal planning: The current production system impedes stakeholders from conducting optimal planning activities. 8. Loss of time: A consequence of those mentioned above and other relevant factors reduces the production system\u2019s time and productivity. 5.4 Total Results: Pains To summarize, although the project involves three different use cases, which may signify different needs from different stakeholders, some common themes offer a common ground to build upon. Particularly, 1. Setup parameters 2. Unexpected downtimes/equipment failures 3. Loss of time 4. Waste/scrap generation 5. Increased inventory The five pains are the primary market needs that are the groundwork to construct compelling value propositions, which is one of the building blocks of a business model. 6 Expectations Toward the Technical Realization In previous work [23], we conducted 14 interviews with stakeholders from three industry partners and three specialized SMEs for software development of AI-based systems. We defined candidate scenarios [24] that describe the context and the anticipated functionality from the stakeholders\u2019 perspectives when interacting with the prospec-tive software platform. In an interview-based case study, we assessed each of the 11 quality characteristics in terms of their importance to the overall platform from the stakeholders\u2019 perspective. We elicited the critical success criteria related to the software platform. The quality characteristics comprised the 11 characteristics of the ISO 25010:2011 standard for software quality (SQuaRE) [25] and 3 AI-specific quality characteristics, such as trustworthiness and explicability. At the beginning of the interviews, we explained the research context of our study (i.e., human-AI teaming in smart manufacturing) to the interviewees. Each interviewee thoroughly understood the research context since they had participated in the project for over 1 year. For the relevance assessment, we adapted the Quality Attribute Workshop format [26] and asked the interviewees to assign, in total, 100 points to the different quality characteristics according to their subjective relevance for human-AI teaming in smart manufacturing.Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 417The interviewees rated trustworthiness, functional suitability, reliability, and security as the most important quality characteristics. In contrast, portability, compatibility, and maintainability are rated as the least important. Furthermore, the results indicate consensus regarding the relevance of the quality characteristics among interviewees with the same role. However, we also recognized that the relevance of the quality characteristics varies according to the concrete use case for the prospective software platform. In addition, we asked interviewees to discuss critical success factors related to the prospective software platform. According to the interviewees, critical success criteria for human-AI teaming in smart manufacturing are improved production cycle efficiency, fewer faulty parts and scrap, and a shorter period for detecting deviations (product or process quality). This response was unsurprising since similar pains had already been expressed earlier (see Sect. 5). 7 Team Effectiveness As described in [27], well-designed coordination mechanisms can improve team effectiveness to ensure that relevant information is distributed throughout the team. These coordination mechanisms, which have first been described by Salas, Sims, and Burke [4] as part of their big five framework for team effectiveness, are: \u2022 Shared Mental Models: Shared mental models facilitate a common under-standing of the environment by creating knowledge structures that promote the information exchange about state changes and team member needs. The knowledge structures need to be designed to be comprehensible by humans and AI. \u2022 Mutual Trust: Trust in the team setting has been defined by Webber [28] as  \u201cthe shared perception ... that individuals in the team will perform particular actions important to its members and ... will recognize and protect the rights and interests of all the team members engaged in their joint endeavor.\u201d A culture of mutual trust is essential in supporting the core components of teamwork, especially since, as [29] shows, trust critically influences how individuals within a team will interpret others\u2019 behaviors. \u2022 Closed-Loop Communication: Communication between humans and AI may suffer from similar issues as communication between humans. Communication may be hindered because of misinterpretation of messages due to their perspec-tives and biases or because team members have become focused on their tasks rather than on how those tasks affect other team members\u2019 tasks. Although the original big five framework focused purely on teaming between humans, it nonetheless builds a solid foundation for human-AI teaming digitaliza-tion. By prioritizing team effectiveness as a goal rather than just performance output, the emphasis remains on human team members instead of AI, acknowledging that the interactions among team members are equally vital.418 T. Hoch et al.Effective communication is, therefore, essential for teams to function correctly. In the context of human-AI teams, communication can help to ensure that AI systems are correctly interpreting human input and that humans are correctly interpreting the output of AI systems. This can be particularly important in high-stakes environments where errors can have serious consequences. 8 Conclusions and Future Work In this work, we have seen how the development of AI-based software platforms that facilitate collaboration between human operators and AI services needs the integration of the different stakeholder perspectives into a common framework. In this regard, it is vital to identify the individual relevance of different quality characteristics per stakeholder and propose key success factors related to human-AI teaming to measure fulfillment. This can help ensure that the software platform is user-friendly and practical, meeting the expectations and needs of all stakeholders involved in the collaboration. Furthermore, it can mitigate conflicts arising from differing stakeholder perspectives during the projects. Our research has thoroughly analyzed the critical issues, challenges, and oppor-tunities of integrating AI technologies into collaborative work environments. To do that, we have adopted a multi-stakeholder perspective, considering the perspectives of different actors involved in the human-AI collaboration process. We aim to pro-vide insights and recommendations for designing effective human-AI collaboration systems that enhance productivity, innovation, and social welfare. We have observed that human-AI collaboration in Industry 5.0 requires careful consideration of various factors, such as the design of intelligent systems, the development of new interaction paradigms, the evaluation of the effectiveness of these systems in real-world scenarios, and the ethical implications of human-AI collaboration [24, 30]. Moreover, we have highlighted the importance of adopting a human-centric approach to AI system design, prioritizing human users\u2019 needs, pref-erences, and capabilities. Other elements (e.g., establishing trust and transparency in human-AI collaboration systems and ensuring fairness, accountability, and transparency in decision-making processes) are also essential in this manufacturing context. In conclusion, integrating AI technologies into collaborative work environments offers immense potential for enhancing productivity, innovation, and social welfare. However, it also presents numerous challenges that require careful consideration and proactive measures. By adopting a multi-stakeholder perspective, prioritizing human-centric design, fostering interdisciplinary collaborations, and implementing responsible governance, we can pave the way for practical and ethical human-AI collaboration systems that maximize the benefits while minimizing the risks associated with this transformative technology. As future lines of research, it is necessary to remark that as AI technologies continue to advance, it becomes increasingly essential to handle the issue of AIMulti-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 419bias in collaborative work environments. Bias in AI systems can perpetuate existing social imbalances, support discriminatory practices, and limit opportunities for specific groups. Therefore, it is crucial to develop mechanisms that detect and mitigate bias in AI algorithms and data sets used in human-AI collaboration. In addition, integrating AI technologies into collaborative work environments necessitates ongoing training and upskilling programs for people. These programs aim to introduce individuals to AI capabilities, promote digital literacy, and provide them with the necessary skills to collaborate with intelligent systems effectively. Acknowledgments We would like to thank the anonymous reviewers for their constructive comments to improve this work. SCCH co-authors has been partially funded by the Federal Ministry for Climate Action, Environment, Energy, Mobility, Innovation, and Technology (BMK), the Federal Ministry for Digital and Economic Affairs (BMDW), and the State of Upper Austria in the frame of SCCH, a center in the COMET\u2014Competence Centers for Excellent Technologies Programme managed by Austrian Research Promotion Agency FFG. All co-authors involved in this study have also received funding from Teaming.AI, a project supported by the European Union\u2019s Horizon 2020 research and innovation program, under grant agreement No. 957402. References 1. Johnson, M., Vera, A.: No AI is an island: the case for teaming intelligence. AI Mag. 40(1), 16\u201328 (2019) 2. Qu, Y.J., Ming, X.G., Liu, Z.W., Zhang, X.Y., Hou, Z.T.: Smart manufacturing systems: state of the art and future trends. Int. J. Adv. Manuf. Technol. 103, 3751\u20133768 (2019) 3. Phuyal, S., Bista, D., Bista, R.: Challenges, opportunities and future directions of smart manufacturing: a state of art review. Sustainable Futures 2, 100023 (2020) 4. Salas, E., Sims, D.E., Burke, C.S.: Is there a \u201cbig five\u201d in teamwork? Small Group Res. 36(5), 555\u2013599 (2005) 5. Daugherty, P.R., Wilson, H.J.: Human +Machine: ReimaginingWork in the Age of AI. Harvard Business Press, Cambridge (2018) 6. Haindl, P., Buchgeher, G., Khan, M., Moser, B.: Towards a reference software architecture for human-ai teaming in smart manufacturing. In: Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results (2022), pp. 96\u2013100 7. Bauer, A., Wollherr, D., Buss, M.: Human\u2013robot collaboration: a survey. Int. J. Humanoid Rob. 05(01), 47\u201366 (2008) 8. Mingyue Ma, L., Fong, T., Micire, M., Kim, Y., Feigh, K.M.: Human-robot teaming: Concepts and components for design. In: Field and Service Robotics: Results of the 11th International Conference (FSR) (2017) 9. Chella, A., Lanza, F., Pipitone, A., Seidita, V.: Human-robot teaming: Perspective on analysis and implementation issues. In: AIRO@AI*IA (2018) 10. Kr\u00e4mer, N.C., Rosenthal von der P\u00fctten, A.M., Eimler, S.C.: Human-agent and human-robot interaction theory: similarities to and differences from human-human interaction. In: Human-Computer Interaction: The Agency Perspective (2012) 11. Nikolaidis, S., Shah, J.A.: Human-robot cross-training: Computational formulation, modeling and evaluation of a human team training strategy. In: 2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI) (2013), pp. 33\u201340 12. Chen, J.Y.C., Barnes, M.J.: Human\u2013agent teaming for multirobot control: a review of human factors issues. IEEE Trans. Hum.-Mach. Syst. 44(1), 13\u201329 (2014)420 T. Hoch et al.13. Freudenthaler, B., Martinez-Gil, J., Fensel, A., H\u00f6fig, K., Huber, S., Jacob, D.: Ki-net: Ai-based optimization in industrial manufacturing\u2014A project overview. In: Computer Aided Systems Theory\u2014EUROCAST 2022\u201418th International Conference, Las Palmas de Gran Canaria, Spain, February 20\u201325, 2022, Revised Selected Papers. Lecture Notes in Computer Science, vol. 13789, pp. 554\u2013561. Springer, Berlin (2022) 14. S\u0327ahinel, D., Akpolat, C., G\u00f6r\u00fcr, O.C., Sivrikaya, F., Albayrak, S.: Human modeling and interaction in cyber-physical systems: a reference framework. J. Manuf. Syst. 59, 367\u2013385 (2021) 15. Johnson, M., Vignatti, M., Duran, D.: Understanding human-machine teaming through inter-dependence analysis. In: Contemporary Research, pp. 209\u2013233. CRC Press, New York (2020) 16. Chen, M., Nikolaidis, S., Soh, H., Hsu, D., Srinivasa, S.: Planning with trust for human-robot collaboration. In: Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction, HRI \u201918, pp. 307\u2013315. Association for Computing Machinery, New York (2018) 17. Buchgeher, G., Gabauer, D., Martinez-Gil, J., Ehrlinger, L.: Knowledge graphs in manufactur-ing and production: a systematic literature review. IEEE Access 9, 55537\u201355554 (2021) 18. Martinez-Gil, J., Buchgeher, G., Gabauer, D., Freudenthaler, B., Filipiak, D., Fensel, A.: Root cause analysis in the industrial domain using knowledge graphs: a case study on power transformers. In: Longo, F., Affenzeller, M., Padovano, A. (eds.) Proceedings of the 3rd International Conference on Industry 4.0 and Smart Manufacturing (ISM 2022), Virtual Event/Upper Austria University of Applied Sciences\u2014Hagenberg Campus\u2014Linz, Austria, 17\u201319 November 2021. Procedia Computer Science, vol. 200, pp. 944\u2013953. Elsevier, Amsterdam (2021) 19. Noy, N.F., Gao, Y., Jain, A., Narayanan, A., Patterson, A., Taylor, J.: Industry-scale knowledge graphs: lessons and challenges. Commun. ACM 62(8), 36\u201343 (2019) 20. Hogan, A., Blomqvist, E., Cochez, M., d\u2019Amato, C., de Melo, G., Gutierrez, C., Kirrane, S., Gayo, J.E.L., Navigli, R., Neumaier, S., et al.: Knowledge graphs. Synthesis Lectures on Data, Semantics, and Knowledge 12(2), 1\u2013257 (2021) 21. Hoi, S.C.H., Sahoo, D., Lu, J., Zhao, P.: Online learning: a comprehensive survey. Neurocom-puting 459, 249\u2013289 (2021) 22. Osterwalder, A., Pigneur, Y., Bernarda, G., Smith, A.: Value Proposition Design. Wiley, New York (2014) 23. Haindl, P., Hoch, T., Dominguez, J., Aperribai, J., Ure, N.K., Tun\u00e7el, M.: Quality charac-teristics of a software platform for human-ai teaming in smart manufacturing. In: Quality of Information and Communications Technology: 15th International Conference, QUATIC 2022, Talavera de la Reina, Spain, September 12\u201314, 2022, Proceedings, pp. 3\u201317. Springer, Berlin (2022) 24. Sutcliffe, A.: Scenario-based requirements engineering. In: Proceedings. 11th IEEE Interna-tional Requirements Engineering Conference, 2003, pp. 320\u2013329 (2003). ISSN: 1090-705X 25. ISO/IEC 25010. ISO/IEC 25010:2011, Systems and Software Engineering\u2014Systems and Software Quality Requirements and Evaluation (SQuaRE)\u2014System and Software Quality Models (2011) 26. Barbacci, M.R., Ellison, R., Lattanze, A.J., Stafford, J.A., Weinstock, C.B.: Quality attribute workshops (QAWS). Technical report, Carnegie Mellon University, Pittsburgh PA (2003) 27. Hoch, T., Heinzl, B., Czech, G., Khan, M., Waibel, P., Bachhofner, S., Kiesling, E., Moser, B.: Teaming.AI: enabling human-AI teaming intelligence in manufacturing. In: Proceedings http:// ceur-ws.org ISSN, 1613:0073 (2022) 28. Webber, S.S.: Leadership and trust facilitating cross-functional team success. J. Manag. Dev. 21(3), 201\u2013214 (2002) 29. Simons, T.L., Peterson, R.S.: Task conflict and relationship conflict in top management teams: the pivotal role of intragroup trust. J. Appl. Psychol. 85(1), 102 (2000) 30. Weyns, D.: Software engineering of self-adaptive systems: an organised tour and future challenges. In: Chapter in Handbook of Software Engineering (2017)Multi-Stakeholder Perspective on Human-AI Collaboration in Industry 5.0 421Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Holistic Production Overview: Using XAI for Production Optimization Sergi Perez-Castanos, Ausias Prieto-Roig, David Monzo, and Javier Colomer-Barbera 1 Use Case Context The eXplainable MANufacturing Artificial Intelligence (XMANAI) Ford use case focuses on managing the complexity of manufacturing in large production lines. These lines are composed of multiple work stations that mostly work sequentially, creating a direct dependence among them. Moreover, each of the stations is also made up of diverse machines and assets, with interconnected processes that range from fully automated to manual labor. All this considered, in a manufacturing line there are numerous complexities and challenges that can arise, making it difficult to anticipate and address potential production problems effectively. For example, a minor problem undetected, and thus not solved, at an asset at the beginning of the line may propagate affecting with great impact to the subsequent stations at the end of the line, and creating bottlenecks that hamper to reach the production goals. These kind of difficulties emphasize the crucial need for developing intelligent systems to ensure that the objective quality and quantity of produced items reach each industry goal, while keeping the production times within a profitable margin; such systems should not only anticipate unwanted situations during production, but in order to help the line operators to make proper decisions to manage them, it is also of great relevance for them to know the root causes that may cause production deviations. The Ford use case has been designed in order to tackle these inherent complexi-ties applying AI-based optimization systems, complemented with an explainability layer, applied on a real engine production line to monitor the overall standards that S. Perez-Castanos (\u0002) \u00b7 A. Prieto-Roig \u00b7 D. Monzo Tyris AI, Valencia, Spain e-mail: sergi.perez@tyris.ai; ausias.prieto@tyris.ai; david.monzo@tyris.ai J. Colomer-Barbera Ford, Valencia, Spain e-mail: jcolome5@ford.com \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_24423424 S. Perez-Castanos et al.are needed, and therefore minimizing deviations on the expected production. One of the main challenges addressed in this case is the high variability in engine types and their corresponding components. In an engine manufacturing facility, different engine derivatives are produced to meet the requirements of various vehicle models. Each engine type may require specific components, such as the engine crankcase, fuel pump, oil pump, clutch, and more. Managing the diverse range of components and ensuring their availability and correct installation on the assembly line can be a daunting task. The sheer number of engine types and components increases the likelihood of errors, delays, and production bottlenecks. Another complexity lies in the planning and scheduling of production batches. Currently, manual processes driven by the expertise of the MP&L (Material Plan-ning & Logistics) team and production staff are employed to manage weekly pro-duction batches. However, accurately determining the optimal batch size, sequenc-ing, and allocation of resources is a complex task. The planning engineer relies on customer demand and their own experience to make decisions, which can result in suboptimal production plans and resource allocation. This can lead to inefficiencies, increased downtime, and compromised production capacity. Moreover, unforeseen issues and disruptions during the manufacturing process can significantly impact production efficiency. Shift foremen must make decisions on the fly to minimize planned stoppages and address unexpected failures on the assembly line. Without a comprehensive understanding of the root causes and potential solutions for such issues, decision-making becomes challenging, and it becomes difficult to maintain consistent line availability and performance. By developing AI models specifically designed for optimizing production on the engines line, these challenges can be effectively addressed. AI systems can analyze real-time and batch data simultaneously acquired from various systems to identify patterns, detect anomalies, and provide recommendations for line optimization. With advanced Machine Learning techniques, AI models can simulate different scenarios, predict the impact of changes, and suggest the best course of action to maximize line performance. These AI models can assist operators and engineers in making data-driven decisions, reducing errors, improving resource allocation, and minimizing downtime. Overall, the complexities and uncertainties inherent in engine manufacturing highlight the critical need for AI models to optimize production. By leveraging AI technologies, manufacturers can enhance their ability to anticipate and tackle potential problems, leading to increased efficiency, reduced costs, and improved overall performance on the assembly line. The current situation at Ford Engine Plant does not allow the power of quasi-real-time data to be harnessed for decision-making. There are records on the status of the different operations on the production line, the quantity of engines produced and their parts, quality reports, and production plans. Despite having this information, there is not a centralized database and all the information is disaggregated in different corporate databases. This lack of centralized information is the first problem that needs to be solved in order to optimize the different processes that occur on the production line. This problem implies another one, which is the lack ofHolistic Production Overview: Using XAI for Production Optimization 425artificial intelligence applied to the different decision-making processes due to the impossibility of taking advantage of all the available data. The proposed application aims to mitigate these problems by means of a set of functionalities that will be explained in the following sections. This use case consists of a set of actions related to the current status of the line within a shift. By means of the information provided by the different disaggregated data sources, it is possible to analyze this information jointly to establish trends and to make predictions about anomalous situations in the line or the total amount of produced engines at the end of the shift. Thus, this use case is focused on the estimation of the production at the end of the shift, detection of unwanted scenarios, and simulations of new hypothetical situations, while giving insights on the assets that may cause potential deviations regarding the expected production goals. Ford internal databases have different information about the status of operations (whether an operation is cycling a new component, waiting for a new part, blocked or in another possible state), operation failures, cycle times (both actual and design time), number of parts produced in a shift and data related to the quality of the parts produced. In this use case, different data sources related to production data will be joined to represent the historical status of the production line and to make predictions about the number of engines produced at the end of the shift following the current trend of the line. Both information will help the business experts to understand the significant deviations that may occur between the predicted (planned) production and the actual engines produced at the end of the shift. 2 XAI Approach The application of explainability techniques is not a merely technical process, since explainability is precisely the bridge that connects intelligent systems with the users who are using them. Therefore, it is important that the end-users of XAI solutions are involved in the design process of explainable systems, looking for a human-in-the-loop approach to be followed. Therefore, in order to provide a solid explainability layer to the AI system developed in relation to the Ford use case, two key activities were carried out prior to the development of the XAI models. The initial activity involved identifying the specific XAI needs of the end-users, i.e. the operators of the engine production line. This step is crucial in understanding the requirements and preferences of the stakeholders who will be interacting with the AI system. By closely collaborating with the end-users, their expectations and concerns regarding the interpretability of the AI models are effectively captured. This process ensures that the subsequent selection of Machine Learning models and explainability tools is aligned with the identified needs of the end-users. Consequently, the second activity focused on selecting the appropriate methods that fulfills the identified XAI needs. Drawing from a range of available techniques, the selection process took into consideration the specific requirements and con-straints of the manufacturing problem. The chosen methods were evaluated based426 S. Perez-Castanos et al.on their capability to provide interpretable insights into the decision-making process of the AI models. Through this meticulous selection process, the chosen methods effectively address the XAI needs identified during the initial activity. By conducting these two activities, the system can ensure that the AI and explainability aspects of the demonstrator are tailored to the requirements of the end-users at the plant. This approach fosters a collaborative and user-centric approach, guaranteeing that the selected methods provide meaningful and actionable explanations. Ultimately, the identification of explainability needs and the subse-quent selection of appropriate methods enable the development of explainable AI models that empowers plant personnel to understand and trust the decisions made by the AI models, facilitating effective decision-making and driving the optimization of manufacturing processes. 2.1 Identification of XAI Needs Prior to the development of XAI models, several tasks need to be addressed to effectively solve the intended problem. The general workflow follows the next steps. The initial step is identifying the relevant data sources and determining the technical requirements necessary for data collection, storage, and processing. This involves understanding the data ecosystem within the manufacturing environment, including sources such as corporate systems, maintenance records, tooling systems, and real-time data acquisition. Concretely, for this problem, the data employed are related to the status of the production of the line and quality data. Next, it is essential to assess the AI needs specific to the manufacturing problem at hand. This includes identifying the key challenges and objectives, such as optimizing production, minimizing downtime, and improving resource allocation. Understanding the desired outcomes helps in defining the scope and purpose of the AI models to be developed. The objective for this problem consists on finding deviations from the expected productions and preventing line bottlenecks. Simultaneously, it is important to recognize the explainability needs of the stakeholders involved. This entails considering the requirements for transparency, interpretability, and trust in the decision-making process. Different stakeholders may have varying levels of expertise and understanding of AI systems, so it is crucial to determine the appropriate level of explanation needed to ensure effective collaboration and decision-making. For this problem, it is essential to understand which elements of the line and to what degree they have influenced predicted deviations and analyze the best action to fit it. By applying XAI models, several advantages can be achieved in the manufactur-ing context. The foremost advantage is that the end-user involved in the production lines will be able to make better decisions based on results of the analysis of the available data and understand why these results are originated, in terms of knowing the specific assets that have the most influence on them.Holistic Production Overview: Using XAI for Production Optimization 427Fig. 1 Identification of AI and explainability needs for the use case The combination of XAI models and their advantages opens up significant business opportunities in this use case. Specifically, the application of XAI models will affect positively the line in two aspects: firstly, the line will increase its availability, preventing line bottlenecks by quick fixing issues that can affect the whole production, and secondly, the efficiency of the production will also be increased, by reducing unnecessary maintenance stops. Overall, the tasks preceding the development of XAI models involve identifying data sources, technical requirements, AI needs, explainability needs, recognizing the advantages of using XAI models, and uncovering the resulting business oppor-tunities. In Fig. 1, a diagram of the whole identification process is presented. By addressing these aspects, it is possible to identify which Machine Learning Models and explainability tools meet the XAI needs of the demonstrator as it is explained in the next section. 2.2 Hybrid Models In the context of the XMANAI project, a hybrid model [2] refers to the combination of two components: a Machine Learning model and an explainability tool used to interpret the results produced by the Machine Learning model. The component with the Machine Learning model is responsible for learning patterns and making predictions based on input data. It leverages algorithms and techniques to extract information, generalize from training examples, and generate predictions for new data instances. The Machine Learning model may include various approaches such as decision trees [3] or random forests [4]. On the other hand, the component with the explainability tool is employed to provide insights into the decision-making process of the Machine Learning model. It helps to uncover the underlying factors, features, or patterns that influ-ence the model\u2019s predictions. The explainability tool enhances transparency and interpretability by providing explanations, visualizations, or metrics that shed light on how the Machine Learning model arrives at its results.428 S. Perez-Castanos et al.Fig. 2 Ford experiment diagram By combining these two components, the hybrid model aims to address the \u201cblack box\u201d nature of some Machine Learning algorithms, providing added trans-parency. The explainability tool provides insights into the most relevant features on a specific prediction, the relative contributions of those features, and how they have impacted on the final model decision. Since the goal of this approach is the development and training of a model for the estimation of the production at the end of a shift, a regression model has been determined to be a good fit to solve the problem, and thus it has been selected for that purpose. As this estimation is a regression task, this model can be employed to that end and the output prediction of the system will be the number of engines produced at the end of one production shift. Based on the comparison of this prediction with regard to the expected production, the plant manager and the operators will be able to make decisions to correct potential deviations. In order to solve this use case, an experiment based on the architecture shown in Fig. 2 has been built in order to configure the use case assets and train the AI model. From left to right, the use case data asset will be generated retrieving operation data directly from the different production line stations of the engine assembly line. Those assets will feed the Machine Learning pipeline performing a regression prediction on the number of engines that will be produced at the end of the shift. Different ML predictive models have been evaluated to analyze which of them provide more accurate results. Finally, Random Forest was selected as the most suitable AI base-model for this goal. Therefore, the explainability requirement of this problem is to understand what elements and how much have influenced the deviation so as to infer the root causes of the deviation as mentioned above. Considering the explainability requirement, LIME [8] has been selected as the optimal XAI Tool due to its feature contribution explanation, which gives much value to the model explanation in this use case scenario. Local Interpretable Model-Agnostic Explanations (LIME) is anHolistic Production Overview: Using XAI for Production Optimization 429explainability tool that provides interpretable explanations for individual predictions made by Machine Learning models. It creates local surrogate models to approximate the behavior of the original model, generating feature importance weights that indicate the relative influence of each input feature. LIME is model-agnostic, making it applicable to various models without requiring access to their internal workings. Its explanations enhance transparency and understanding, fostering trust in complex Machine Learning systems. Taking into account the selected Machine Learning model and the explainability tool, the expected output of the ML pipeline is a prediction which indicates the expected performance of the production at the end of the shift, which ultimately will be compared with the actual production goals to prevent potential deviations. Thus, the explanations given should help to understand what the key elements are and how much they have influenced on production deviations, and supporting the end-users to infer root causes that could be tackled to minimize the impact. 2.2.1 Interpretation of XAI Outputs Using a Random Forest as a model and LIME as an explainability tool, an example of explainability is shown in Fig. 3 where an entire shift of production is analyzed to estimate the production of the current shift through the regression of the input data. On the left side, it can be seen that the model predicts a value of 19.16. This value has to be interpreted as the average value of engines produced by the line in time intervals of 10 minutes. For this use case, values in the range between 15 and 20 are Fig. 3 Lime explainability result example. On the left side, it is shown the ML prediction information. On the right side, it can be see, the contributions (both positive and negative) of the different input features430 S. Perez-Castanos et al.considered as proper values, representing a nominal behavior of the line. When the value is lower than 15, a deviation from the expected value has to be considered. On the right side, the information provided by the LIME explainability tool is presented. As this technique consists on a feature relevance representation, the different rows in the diagram represents the input features, coming from the input data used for this concrete prediction, that are contributing the most to this concrete output and in what degree they are contributing. The negative or positive side represents how much they are affecting to an upper o lower value from the average output value of the training data employed to train the model. 2.3 Graph Machine Learning Models Graph Machine Learning (Graph ML) [7] models are a class of Machine Learning algorithms designed to operate on structured data represented as graphs. In contrast to traditional Machine Learning approaches that work with tabular data or sequential data, graph ML models leverage the inherent relational information present in graph structures to make predictions or gain insights. Graph ML models are particularly suited for tasks that involve complex rela-tionships and dependencies among data points. They find applications in various domains, including social network analysis, recommendation systems, bioinformat-ics, fraud detection, knowledge graph completion, and many more [10]. This topology of models can be correlated with the complex structure of interconnected processes present at production plants of manufacturing industries. Thus, a research line within XMANAI has been dedicated to determine the fit of this type of approach to provide IA-based predictive models adapted to the specifics of manufacturing considering the addition of an explainability layer. Specifically, among our experiments with the data, Heterogeneous Graph ML models were selected as they are focused on Explainability. After a research among different beyond-state-of-the-art options, we were inclined to use in this case Tensorflow GNN (TFGNN) [5]. This library is capable of handling Heterogeneous Graphs to fit a dynamic number of nodes and edges, with different node classes and edge classes, and their own set of data. This also leverages Tensorflow\u2019s [1] graph execution, which speeds up the training and inference process, allowing for faster iteration and less waiting time. 2.3.1 Graph Models Graph models offer distinct advantages over regular models in the context of predicting the output of a manufacturing line. By leveraging the inherent relational structure present in the data, graph models can incorporate contextual information and capture the interdependencies between different components. ManufacturingHolistic Production Overview: Using XAI for Production Optimization 431lines often exhibit complex relationships, such as cascading effects or feedback loops, which graph models excel at representing and exploiting. Additionally, graph models can effectively utilize both the graph topology and the node-level features associated with each component, enabling them to learn embeddings that encode intrinsic properties and interactions. The transferability capabilities of graph models allow them to generalize knowl-edge across different manufacturing line states with shared characteristics. Further-more, graph models provide interpretability and explainability by analyzing learned embeddings and the influence of components on the output. GNNs have gained significant attention in recent years due to their ability to capture both the local and global structural information of the graph. They leverage a combination of node-level features, graph topology, and message passing mechanisms to update the representations of nodes throughout the network layers. GNNs can learn expressive node embeddings that encode both the inherent features of the nodes and their relationships with neighboring nodes. During the training stage of the graph ML models, they are often optimized using gradient-based methods, where the gradients are computed through backpropaga-tion. Graph ML models can be trained in a supervised manner, where labeled data is available, or in an unsupervised or semi-supervised manner, where only a subset of the data is labeled or no labels are available. Graph ML models can provide various types of outputs that capture different aspects of the graph data. For example, in node classification tasks, the model may assign a label or class to each node in the graph, indicating the predicted category or behavior of the corresponding entity. Graph ML models can also generate outputs related to link prediction, where they estimate the likelihood or presence of connections between nodes in the graph. Additionally, graph ML models may produce node embeddings or representations that capture the learned features and relationships of each node, enabling downstream tasks or further analysis. In the scenario analyzed, we work on temporal slices of the manufacturing line and we will be predicting the output at the final slice of the manufacturing line, encoded in the graph training as an attribute of the nodes. This has been proven to be possible, per example by Google in their paper [6], where they improved the state of the art by reducing the loss by 6% (using RMSLE). 2.3.2 Explainability Techniques For the explainability, we used Graph ATtention (GAT) [9] layers to collect the weight that each input is given by the model. Graph Machine Learning not only allows us to adapt both the inference and explainability to the layout of the manufacturing process when operators are added or removed, but it also allows the model to have more contextual information about what operators are connected or what kinds of data there is, which in the end, this improves the accuracy of the model and explanations432 S. Perez-Castanos et al.Fig. 4 Graph ML GAT contribution weights full graph. Brighter colors and wider edges means greater contribution Upon completion of training and explanation, we obtain a graph that depicts the manufacturing line, including all the relationships between its components and their respective importance. In Fig. 4, we present a visualization that represents the connections between operators (green dots) and teams (red dots) in our project. The relevance of each node is indicated by the darkness of its color, with darker colors indicating less relevance and brighter colors indicating more relevance. The size of the edges connecting the nodes also represents the strength of the connection, with larger edges denoting more relevant connections. Specifically, the green dots represent operators, and a connection between two green dots implies that those operators are connected in line, with the next operator receiving the output of the previous one. Similarly, the red dots represent teams, and connections between red dots indicate that one team receives the output of the previous team\u2019s work. Additionally, there are connections between the red and green dots, indicating which operators belong to which team. Figure 5 is a modified version of the first graph, where we have removed some of the less relevant connections. This filtering process results in retaining only groups of highly influential operators, represented by the remaining connections. The utility of presenting this information to a user is that it provides a clear understanding of the relationships and dependencies between operators and teams in the project. By visualizing the graph, the user can identify the most relevant operators and teams based on their brightness and the size of their connections. This information helps in understanding the flow of work, identifying key contributors, and potentially optimizing the project by focusing on the most influential aspects.Holistic Production Overview: Using XAI for Production Optimization 433Fig. 5 Graph ML GAT contribution weights trimmed graph to only highest contributors. Brighter colors and wider edges means greater contribution By removing less relevant connections in the second graph, the user can quickly grasp the core components and key dependencies, simplifying the visualization and highlighting the most critical elements. This focused view is simpler and straighter. Finally, if this were to be too hard to understand for users, this has the potential to be added in a map of the line to better represent the positions of each team and operator. 3 XMANAI Platform Usage All training of Hybrid models and the exploration of the available data is performed under the XMANAI platform. For this, Ford uploads their datasets to the platform, ensuring the data\u2019s security and privacy by sharing it under a contractual agreement while retaining ownership. The platform provides tools for visualizing the data, allowing us to gain insights and understand its characteristics. After visualizing the data, we can further explore the problem and develop solutions using notebooks available on the platform, leveraging its computational capabilities and pre-built libraries. To create a hybrid model and explainable artificial intelligence (XAI) tool, we can upload their model and associated artifacts to the platform. We can configure the model with its hyperparameters with a viable explainability tool, and fine-tuning them to achieve optimal performance. The output is a session which will be used for training, and that will ensure that the model can always be used with the selected explainability tool.434 S. Perez-Castanos et al.After creating the session, we can use the platform\u2019s pipeline functionality to establish a streamlined process for training both the model and the explainer component. Once the pipeline is set up, Ford can run it whenever they wish to make inferences or predictions based on the trained model. The pipeline ensures consistent and automated execution, saving time and effort. Finally, we can visualize the explanations provided by the XAI tool through the platform\u2019s visualization capabilities. This allows them to gain interpretability and insights into how the model arrived at its predictions, aiding in decision-making and model validation. 4 Achievements, Conclusions, and Open work lines In the following paragraphs, we will delve into the accomplishments we have made in the areas of data veracity, data ingestion automation, data processing and analyt-ics, hybrid and graph model development, explainability methods, manufacturing app creation, and infrastructure enhancement. In terms of data veracity, we have allocated a team of programmers to thoroughly review and ensure that all machines adhere to the standardized manufacturing data reporting. This serves as the starting point for all other aspects, as the availability of accurate data is paramount. Without reliable data, we cannot construct models that accurately represent the reality of our manufacturing processes. We have also made significant progress in automating the data ingestion process. Previously done manually, the data ingestion is now automated, creating dumps of data periodically and producing new batches of data that can be used to retrain existing models. Our focus on data processing and data analytics has involved extracting features from different datasets and determining the best approach for ingesting the input data to achieve relevant results. Furthermore, we have been actively working on developing hybrid models that combine machine learning algorithms with explainability tools. Specifically, we have utilized Local Interpretable Model-Agnostic Explanations to create explana-tions that help identify the parts of the production line that are affecting specific predictions. Alongside this, we have also been working on graph models that provide explanations in a similar manner to our hybrid models. Additionally, we have utilized the eXplainable MANufacturing Artificial Intel-ligence platform to develop a manufacturing app, as described in Sect. 3. This app has been designed for use by demonstrators in their respective use cases. To accommodate the on-premise segment of the platform and effectively host the entire backend infrastructure for our final applications, we have recently acquired a dedicated physical server. This acquisition ensures efficient and reliable hosting for our platform.Holistic Production Overview: Using XAI for Production Optimization 435In conclusion, our achievements in data veracity have ensured a solid foundation for our manufacturing processes by guaranteeing accurate and reliable data. This has enabled us to construct models that accurately represent the reality of our operations. The automation of data ingestion has not only saved valuable time and resources but also provided us with fresh batches of data for continuous model improvement. Our focus on data processing and analytics has allowed us to extract meaningful insights and achieve relevant results. The development of hybrid and graph models, coupled with explainability tools, has enhanced our understanding of predictions and identified the specific factors influencing them. The implementation of explainability methods has increased transparency and trust in our models\u2019 outputs, empowering us to make informed decisions. Furthermore, the creation of the manufacturing app has facilitated streamlined processes and improved collaboration among demonstrators in their respective use cases. Lastly, our investment in infrastructure, including the acquisition of a dedicated physical server, ensures a robust and efficient hosting environment for our final applications. As we look toward the future, one of our key objectives is to bridge the gap between scientific explanations and end-user accessibility. While our current focus on developing explanations has been rooted in scientific rigor, we recognize the need to make these explanations more comprehensible and user-friendly for a non-technical audience. Our next step involves refining and adapting the explanations derived from our models, transforming them into a format that is easily under-standable and meaningful to end-users. By translating complex technical concepts into accessible language and visualizations, we aim to empower the end-users to make informed decisions and derive maximum value from our manufacturing processes. This user-centric approach will enable us to deliver explanations that not only provide scientific insights but also serve as practical tools for enhancing productivity, efficiency, and overall business profitability. References 1. Abadi, M., et al.: TensorFlow, Large-scale Machine Learning on Heterogeneous Systems (2015). https://doi.org/10.5281/zenodo.4724125 2. Amini, M., et al.: Discovering injury severity risk factors in automobile crashes: a hybrid explainable AI framework for decision support. Reliab. Eng. Syst. Saf. 226, 108720 (2022). https://doi.org/10.1016/j.ress.2022.108720. https://www.sciencedirect.com/science/article/pii/ S0951832022003441 3. Breiman, L.: Classification and regression trees. In: The Wadsworth & Brooks/Cole (1984) 4. Brieman, L.: Random Forests Machine Learning (2001) 5. Ferludin, O., et al.: TF-GNN: graph neural networks in TensorFlow. CoRR abs/2207.03522 (2022). http://arxiv.org/abs/2207.03522 6. Kapoor, A., et al.: Examining covid-19 forecasting using spatio-temporal graph neural networks. In: MLG workshop @ KDD\u20192020, epiDAMIK workshop @ KDD\u20192020 (2020). https://arxiv.org/abs/2007.03113 7. Liu, Z., et al.: Heterogeneous graph neural networks for malicious account detection. In: Proceedings of the 27th ACM International Conference on Information and Knowledge436 S. Perez-Castanos et al.Management (CIKM \u201918). Association for Computing Machinery, New York (2018), pp. 2077\u2013 2085. https://doi.org/10.1145/3269206.3272010 8. Ribeiro, M.T., et al.: Model-agnostic interpretability of machine learning (2016). arXiv preprint arXiv:160605386 9. Wang, X., et al.: Heterogeneous graph attention network. In: The World Wide Web Conference (WWW \u201919). Association for ComputingMachinery, NewYork (2019), pp. 2022\u20132032. https:// doi.org/10.1145/3308558.3313562 10. Xia, F., et al.: Graph learning: a survey. IEEE Trans. Artif. Intell. 2(2), 109\u2013127 (2021). https:// doi.org/10.1109/TAI.2021.3076021 Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt Fenareti Lampathaki, Enrica Bosani, Evmorfia Biliri, Erifili Ichtiaroglou, Andreas Louca, Dimitris Syrrafos, Mattia Calabresi, Michele Sesana, Veronica Antonello, and Andrea Capaccioli 1 Introduction The H2020 XMANAI project represents a unique experience in Whirlpool\u2019s Operations Excellence, within the I4.0 technology research work stream, as it really faces one of the most commonly experienced obstacles to the successful introduction of Artificial Intelligence (AI) technologies. Human engagement in the AI Loop is commonly addressed through a structured change management which acts on communication and training to achieve the readiness level that enables adoption by real users. XMANAI has developed dedicated tools that serve the customized need of the user to understand and trust the AI system. Besides, the project\u2019s strength lies not only on the implemented solution but also in the journey to arrive there. The latter unveils the complexity of the explainability requirements for a user, even when one is aware of what to look for. The conversion of desired information into a format which is really usable by the business experts, F. Lampathaki (\u0002) \u00b7 E. Biliri \u00b7 E. Ichtiaroglou \u00b7 A. Louca \u00b7 D. Syrrafos Suite5 Data Intelligence Solutions, Limassol, Cyprus e-mail: fenareti@suite5.eu; evmorfia@suite5.eu; erifili@suite5.eu; andreas@suite5.eu; dimitris.syrrafos@suite5.eu E. Bosani Whirlpool Management EMEA, Milan, Italy e-mail: enrica_bosani@whirlpool.com M. Calabresi \u00b7 M. Sesana \u00b7 V. Antonello TXT e-solutions SpA, Milan, Italy e-mail: mattia.calabresi@txtgroup.com; michele.sesana@txtgroup.com; veronica.antonello@txtgroup.com A. Capaccioli Deep Blue, Rome, Italy e-mail: andrea.capaccioli@dblue.it \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_25437438 F. Lampathaki et al.and sometimes also by the technical experts, has been demonstrated to be a long path. The successful navigation of this path requires the adoption of structured mapping techniques and methods, along with an agile approach to the development of the solution that ensures a smooth, step-by-step, progress. The continuous and strict collaboration between technical experts and business experts has also been a key success factor for achieving the final goal in the manufacturing environment. This is a success factor not only for AI adoption but also for the successful deployment of most of the innovative technologies offered by I4.0. This chapter explores and documents the experience gained by Whirlpool in the XMANAI project [1], where the explainability of AI technology is applied in a sales demand forecasting scenario. In this scenario, the level of adoption of the AI tool is highly dependent on the trust that can be generated in the users. In the Whirlpool\u2019s case, the possibility to explain AI results to users has been identified as one of the key enablers to gain users\u2019 trust and to fully engage human stakeholders within the AI loop. XAI is the door to open toward full awareness on why a specific result has been generated. The possibility to achieve a deeper understanding of the processes simulated by the AI rises the awareness and the belief in XAI: It is the spark to achieve better decisions and results in daily business management. In this context, this chapter starts with a detailed description of the Whirlpool\u2019s use case in the H2020 XMANAI project in Sect. 2. It presents the motivation driving the project and the business context of the use cases. Then, the chapter describes the current state and the identified business requirements driving the XMANAI solution design, providing an outline of the \u201cto-be\u201d scenario and the key objectives to be achieved in Sect. 3. Accordingly, Sect. 4 presents the technical implementation journey, followed by the explainability value presentation. The process used to detail the explainability requirements with the users is outlined and the meaningfulness of the explanation mode, deployed into the system, is justified in Sect. 5. Moreover, Sect. 6 includes the description of the XMANAI platform, showing details of the users\u2019 journey in the XAI platform and in the XAI Manufacturing application of Whirlpool\u2019s use case. Finally, Sect. 7 presents the evaluation results of the demonstration sessions held with the users, along with a summary of the lessons learnt so far in Sect. 8. 2 Whirlpool as XMANAI Demonstrator Whirlpool is the biggest player in white goods business at global level and one of the most important players in Europe, where it counts 9 industrial sites in 5 countries and more than 50 OEM (Original Equipment Manufacturers) producing and delivering in the 35 European markets and more than 100 other destinations in the world.XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 439Overall, the white goods business is characterized by high levels of competition in the European market. Several very aggressive global competitors play a big role in the traditional B2B (Business to Business) market, where currently the key success factors are price and brand reputation. In this context, all the players started, some years ago, to enrich their product offers with services to final customers. Most of these services were partially driven by product IoT (Internet of Things) functionalities and partially leveraged on post-sales organization. Nevertheless, most of these offerings had no real and disruptive effect on business setup and market share footprint. Today, Whirlpool\u2019s products are mainly considered a commodity. Hence, due to the maturity of the market, the overall business setup had been quite stable until 2020. However, the pandemic event of COVID19 has significantly modified such a market setup through the competitive advantage of companies, like Whirlpool, which early addressed the safety constraints for contagion avoidance and quickly restarted the production flow after the lockdowns. In addition, the pandemic lockdown has provided a unique opportunity, for white goods producers, to finally exploit the direct sales to final customers (D2C), leveraging the functionalities of the web and by-passing the B2B selling constraints. This element is opening up new opportunities for market share acquisition, and the successful competition on this new channel is expected to be crucial in the future. This new business channel is characterized by a set of specific and challenging requirements, which are mainly related to the speed of the buying experience and the hard competition on the web based on product offers and brand reputation. Specifically, key success factors include the range of the available offerings, the speed of order-to-delivery, the pricing policy with focused and personalized promotions, as well as additional services that can be offered (e.g., free installation, guarantee extension, home delivery, old product scrapping, and waste disposal). In this context, the complexity of the overall process and the speed required in decision making can be barely addressed by humans, even if experts, with traditional analytic methods. Thus, AI becomes the key enabler for a significant improvement in decision-making process, ensuring a reliable forecasting service which may support people in \u201cacting.\u201d It needs to be noted that Whirlpool\u2019s experience in applying AI technology in the manufacturing environment started more than 10 years ago, mostly with appli-cations to quality control (like vision systems or product testing) and in predictive maintenance. After every successful project implementation, the company is faced with the challenge of sustaining the implemented solutions in the mid/long term and of exploiting the successful pilot application in other areas of the factories. Some key factors have been identified as root cause of this effect: firstly, the users\u2019 difficulty to understand AI technology fully and deeply. The awareness of AI\u2019s potential and limitations prevents a dangerous misalignment between expectations and results. This weak awareness was mainly due to the poor control and understanding of the data fed to the AI, implying a progressive and unexpected derail in the quality of AI results, which often end in systems shutdowns. In these cases, the original trust of the users in AI system was progressively con-440 F. Lampathaki et al.sumed, sometimes even resulting in rejection or boycott. Moreover, in the case of predictive analytics applications, the user\u2019s trust was negatively affected by a weak understanding of the AI results, mainly when they were far from their usual experience or expertise. In these cases, the users\u2019 approach was to tentatively reject the recommendation, i.e., to bypass the AI system. In both cases, the capability to create and sustain the trust in AI technology has been demonstrated as a key factor to really make the most out of this approach. In this context, eXplainable AI (XAI) may represent the key to unlock the achievement of all the AI solution objectives, as it may enable the users to deep dive into AI results with a language that makes them understandable (i.e., in terms of how and why such results are generated) and, therefore, actionable and sustainable in the long term. Thus, Whirlpool has joined the XMANAI project experience with a use case that is quite far from the traditional manufacturing domain, yet which can be used to demonstrate, in terms of business impact, the full potential of this technology. 3 White Appliances Use Case Description Whirlpool, as other competitors in these years, has launched the D2C (Direct To Consumer) channels in the biggest European markets ensuring a wide product offer among its several important European brands (e.g., Whirlpool, KitchenAid, Hotpoint, Ariston, Ignis, Indesit) with a promised order-to-delivery time of 3 working days. With a highly complex manufacturing footprint, composed by mono-product factories which produce one single product platform distributed in all the destination markets, the supply network imposes a transportation time, and consequent order-to-delivery time, that cannot fulfill the request of the D2C business. The traditional approach is based on inventory strategy, focused on ensuring a certain safety level of stock to be able to serve any customer, at any place, for any product, and at any moment. Due to the need to extend as much as possible the product range offer to the customer, the risk of obsolescence and the high blocked working capital must be balanced with the customer. A reliable demand forecasting may minimize the protected inventory, maximiz-ing the possibility for customers to find exactly what they are looking for. Thus, a reliable forecasting functionality represents the first business requirement posted to XMANAI. As explained earlier, this is not enough to ensure the full and conscious adoption of an AI solution. Here is where the explainability functionality has to enable the \u201cactionability\u201d of the AI results by answering users\u2019 questions about how and why an outcome is generated. The second, perhaps more important, business requirement which XMANAI project needs to address is a deep understanding of the business process. This is based on the development of a tool capable of supporting users with a clear and user-friendly visualization of how the forecast is generated and why. This enablesXAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 441them to understand what they can do to change (when possible) the forecasting results toward achieving their business goals. In summary, the Whirlpool use case in the H2020 XMANAI project is focused on the creation of a reliable, explainable, and actionable demand forecasting tool capable of providing the following: 1. Demand forecast reliability, including:\u2022 Getting a reliable demand forecasting\u2022 Minimizing inventory for D2C\u2022 Maximizing product availability on request\u2022 Maximizing customer satisfaction 2. Business dynamics understanding, including:\u2022 Understanding of demand evolution\u2022 Understanding of customers\u2019 behavior\u2022 Understanding of buying patterns\u2022 Supporting of promotional initiatives\u2022 Supporting simulations (i.e., execution of \u201cwhat-if\u201d scenarios) Currently, the demand forecasting of D2C market is embedded into the full ODP process (Operational Demand Plan), which funnels all the expected sales demand of all the markets in a unique master production plan for all the factories and OEM sources. This process is coordinated by a central Demand Planning team, which enriches the unconstrained forecast generated by statistical analytics on historical data, with adjustments driven by factory capacity planning, supply base constraints, inventory and transportation strategy guidelines. They work starting from each single market demand profile to generate a total demand, which is then split to supply each single market. At this moment, the marketing and sales team of each market analyzes the forecast to take decisions about pricing strategy, promotional actions, and product range offer. The result of this second enrichment is the input for the manufacturing production plan. In the \u201cto-be\u201d situation, as depicted in Fig. 1, the XMANAI platform will be used to support the decisions made by these two groups of users to achieve better results, using the reliability of AI functionality and the business dynamic understanding of XAI. It needs to be noted that the sustainable usage of AI and XAI pipelines generates the need to include an IT role with the specific responsibility of managing the XMANAI platform daily. Data scientists and data engineers become key organi-zational roles to ensure that the XMANAI platform will perform according to high standard levels, granting the optimal forecast accuracy and ensuring the models\u2019 and pipelines\u2019 maintenance during the whole system lifecycle. This element is new in the organizational structure of a traditional industrial company, which, in most cases, does not have internally the competence to effectively support the business users. In this case, the answer provided by XMANAI platform highlights this organizational gap and the strategy that must be adopted to fill it.442 F. Lampathaki et al.Fig. 1 XMANAI and Whirlpool ODP management process Fig. 2 Users\u2019 scenarios in Whirlpool\u2019s use case The so-defined scenarios presented in Fig. 2 have facilitated the identification of the user\u2019s stories, which generated the specifications for the explainability requirements, as described in the following chapters, and set the foundation for demonstrator validation. Last but not least, taking into consideration the fact that the XMANAI platform has the credentials to eventually become a very strategic business tool that can set Whirlpool apart from its competitors, it must guarantee the security and protection of the strictly confidential and sensitive data that are used. Thus, a security-by-design approach and a full GDPR (General Data Protection Regulation) compliance must be embedded into the solution development since the beginning. 4 Explainable AI Approach The technical activities performed and the achievements reached during the preparation and execution of Whirlpool demonstrator span across different work areas, including data exploration, predictive model development and performance improvement, development of explainability methods, adaptation of the results for the needs of business users, as well as development and validation of theXAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 443initial release of the corresponding XMANAI manufacturing app (i.e., Demand Forecasting Manufacturing App). The main achievements across these axes are as follows: (a) use case detailed analysis and elaboration presented in Sect. 4.1; (b) data acquisition and exploration as explained in Sect. 4.2; (c) development and validation of hybrid XAI models out-lined in Sect. 4.3; and (d) design and development of the XMANAI manufacturing app (i.e., the Demand Forecasting Manufacturing App) as elaborated in Sect. 4.4. 4.1 In-Depth Analysis A close collaboration and discussions between the technical partners and the business users needed to occur in order to ensure that the business problem, the \u201cas-is\u201d situation, and the business requirements were explained in depth and that all partners acquired a common understanding in order to properly address the challenges. Various user stories were formulated based on the business needs, including the generation of an accurate demand forecast per each single product in specified time horizons and steps, in an explainable way for different target audiences. The AI needs and the data requirements were identified and discussed, along with the different technical and business aspects that needed to be aligned. The main identified AI and explainability needs were the following:\u2022 AI requirements, including the extraction of D2C profiles and the improvement of forecasting reliability.\u2022 General explainability requirements, including the extraction of insights about demand trends to optimize supply flow, as well as the identification of influential factors for demand and of critical situations that need to be handled to avoid stock breakage. 4.2 Data Acquisition and Exploration The data employed for the forecasting task were acquired mainly by Google Analytics datasets, which track information from the Whirlpool\u2019s website. The data include information regarding product sales and customer-related data and are accessed through frequently updated database tables that are extracted as CSV (Comma Separated Values) files. Google Analytics generates data related to various fields that are not necessarily of use for the task at hand. Hence, there was a need to identify and isolate only a valuable subset of information that could aid the sales forecasting task and provide useful insights for the business users. Based on the Google Analytics documentation, some initial data investigation of the provided fields and various statistics, it was possible to select a subset of approximately 30 fields that were considered the most relevant. Accordingly, data from other database444 F. Lampathaki et al.tables, containing Whirlpools internal product information, were also considered and added as needed to the previous extracted subset. The next phase of data manipulation included data cleaning, identification of irregularities, and exploratory data analysis to detect interesting properties and correlations among the different data fields. The extracted results were discussed among the XMANAI partners, in order to get feedback from the business users regarding some of the findings, the assumptions, and the insights made by the technical users. Based on the findings of this procedure, the business partners agreed to provide additional data, such as product hierarchies/categories, product price, and campaigns. Next, more features were extracted based on the fields of the selected subset including sales, visits, price, calendar information. Sales\u2019 lag features, average number of unique visits, future product price, day of the week, and month are some of the features that were created. An exploratory data analysis focused on the extracted features was performed to conclude on which of them might be the most promising for the forecasting model. Finally, the datasets that were to be used for the next steps of the analysis were anonymized and uploaded (as CSV files) to the XMANAI platform. Note that certain extensions to the data model were required to ensure that the data uploaded are accompanied by proper semantics (i.e., explanations at the data level). 4.3 Development and Validation of Hybrid XAI Models Once data exploration concluded and the Whirlpool data were available in the XMANAI platform, the implementation activities for an appropriate predictive model for the sales forecasting use case, along with a suitable explainability model, started. During the initial experimentation, the focus was on the development of various forecasting models for the most sold individual products and product categories. Whirlpool\u2019s D2C channel is new and, therefore, during the first experimentation, Google Analytics contained sufficient information only for a subset of the com-pany\u2019s products that permitted the implementation of high-performing predictive models. The examined time horizons were (a) 1 week, (b) 1 month, and (c) 3 months ahead, and the models were implemented both for weekly and daily predictions, whenever this was possible, since daily predictions for 3 months ahead were not feasible. The models were evaluated using appropriate evaluation metrics and the most promising results were obtained by boosting models and more specifically XGBoost. As the implementation phase progressed over time, the focus moved toward improving the performance of the forecasting models. The selected horizons were fixed to 1 week and 1 month ahead with weekly steps. More data were available through Google Analytics, and the walk forward approach for training the XGBoost models was examined and found to improve the results. Additionally, differentXAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 445product hierarchies and categories were considered based on the input from the business users, and the hierarchical approach was employed to provide more coherent forecasts for the individual levels of the products\u2019 hierarchies. Regarding the explainability aspect of the task, descriptive visualizations depict-ing correlations among the features and their influence on the target value were employed to provide initial explainability insights. After developing the predictive models, a range of explainability tools [2, 3] has been used, including SHAP, per-mutation importance, counterfactuals, and what-if scenarios, to generate additional explanation results. This allowed the provision of clear and meaningful insights to business users, while also offering them the flexibility to explore hypothetical scenarios as needed. The work performed included \u201coffline\u201d experimentation, as well as experimentation and configuration of the hybrid XAI models within XAI pipelines in the XMANAI platform. 4.4 Delivery of the XMANAI Demand Forecasting Manufacturing App Through dedicated brainstorming sessions among the business users and the technical partners of the XMANAI project, the detailed design of mockups for the user interface of the manufacturing app has been defined. The identification of the right visualization tools has been supported by the QFD (Quality Function Deployment) methodology and led to the definition of the type of diagrams and the exact information to be displayed. The subsequent development activities of the manufacturing app fulfilled the specified visualization requirements, through front-end and back-end development. In addition, they involved integration activities with the XMANAI Platform to retrieve necessary data, results, and explanations from pre-configured XAI pipelines (as described in Sect. 4.3) and display them in the dedicated dashboard presented in Fig. 3. Finally, they insured that only authorized partners could utilize the app through single sign-on functionalities with the XMANAI Platform. 5 Explainable AI Implications and Added Value For the Whirlpool\u2019s use case, the purpose of the explainability activities is to address the needs of the business users who want to comprehend how product sales are influenced by multiple parameters. The concerned business users are the central demand planner, the D2C marketing and sales specialist, and the data scientist/engineer. Different explainability needs have been identified for each of the users. For example, the central demand planner is interested in understanding the causes of critical situations in forecasting process and the root causes that affect446 F. Lampathaki et al.Fig. 3 XMANAI Demand Forecasting Manufacturing App the forecast accuracy the most, visualizing forecasting plots and getting the trends and the directions based on the past, understanding customer behaviors and the impact of marketing strategies (campaigns, promotions), and finally being able to examine how the output would change based on different company\u2019s decisions. The D2C marketing and sales specialist is interested in understanding demand evolution, customers\u2019 buying patterns, and the effect of the marketing strategies. The user\u2019s stories developed in the aforementioned activities and indicatively presented in Fig. 4 have been the key drivers to guide the finalization of the visualization tools for XAI deployment. The design methodology was extracted based on user\u2019s questionnaires, personas identification, and user\u2019s stories definition. All these were integrated into the user\u2019s journey description, which embeds the full user\u2019s experience within XMANAI platform and Manufacturing App. The main explainability functionalities that have been identified for business users are the following:\u2022 Demand forecasting visibility\u2022 Demand root cause analysis\u2022 Feature relations visualization\u2022 Feature impact visualization\u2022 Target scenario simulation\u2022 Demand trends identificationXAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 447Fig. 4 User\u2019s stories example\u2022 Demand trends root cause analysis\u2022 Demand anomalies visualization\u2022 Demand anomalies root cause analysis\u2022 Forecast accuracy visualization\u2022 Buying patterns identification\u2022 Buying patterns root cause analysis\u2022 Customer\u2019s behaviors visualization\u2022 Customer\u2019s behavior root cause In order to meet the above-mentioned business needs, the implementations of the explainability approaches were divided into two categories: (a) Explanation at data level (b) Explanations at instance and model levels The primary focus was on the generation of appropriate explanations, followed by the selection and development of suitable visualizations that are more user-friendly and easily interpreted by the business users. 5.1 Explanations at Data Level In the case of explanations at the data level, the aim has been to extract descriptive visualizations that provide insights in a comprehensive way for the business needs. At this stage, line plots and histograms were employed to explain demand evolution, historical and forecasting patterns, trend lines, and seasonality. Pie charts were448 F. Lampathaki et al.employed to explain fluctuations in the forecasts\u2019 accuracy based on the inclu-sion/exclusion of individual features. Partial dependency plots were also examined to illustrate the influence of the features on the output. Finally, heat maps were used to depict the relationships among the features, the sales, and the buying patterns of the customers, as well as the sales with respect to different calendar information. Upon discussion with the business users, the technical partners included only the visualizations that were most appropriate for their needs. 5.2 Explanations at Instance and Model Levels In the case of explanations at instance and model levels, the aim has been to carry out a post-hoc processing of the already trained models using SHAP and permutation importance explainability techniques. In addition, a tool for the creation of what-if scenarios has been provided to inspect the effect of features on hypothetical test cases. The instance-level explanations provide insights into the direction and the contribution of individual features to the model\u2019s output. The explanations at this level are significant to the business users as they are capable of understanding individual extreme situations and the factors that were the most influential. The model-level explanations provide a more holistic view of how the features affect the outputs, showing their relevance. Instance-level explanations are typically provided by SHAP force plots. The forecasted value of the model is explained by showing in a graph the feature contributions and the impact direction. Shapley values (average marginal contribution of a feature value over all possible coalitions) are calculated locally for specific instances and shown in a graph provided by the SHAP library (Fig. 5). After discussing with the business users, a more self-explanatory graph than the default SHAP force plots was requested and designed, with a less data scientist\u2013 oriented approach: alluvial plots, as depicted in Fig. 6. The possibility to generate and explore what-if scenarios is also provided to the business users, who can examine how the predicted value of an instance would change in response to a modification of the input features. Such scenarios (as indicatively presented in Fig. 7) allow the business users to understand how strong the correlation of the input features to the models output is, potentially even suggesting changes that could increase the company\u2019s sales. The model-level explanations are indicatively provided by SHAP and permu-tation importance. The SHAP library provides and visualizes global explanations by creating a bees-warm plot and aggregating all local feature contributions, while permutation importance generates global feature contributions by computing the change in the forecasting error, as it randomly shuffles each input feature. The results are presented in a table with the most influential features and their weights. In the context of the first phase of the manufacturing app, global explanation results were decided to be depicted through bar plots, upon discussions with the business users (as indicatively shown in Fig. 8).XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 449Fig. 5 Instance-level explanations through a SHAP force plots \u2013 data scientist\u2013oriented Fig. 6 Alluvial plot example presenting the feature contributions on the output at instance level \u2013 business user\u2013oriented450 F. Lampathaki et al.Fig. 7 What-if scenario example. Impact of the product price to the products\u2019 sales 0 nber of Sales Avg Price Unique Visits Items on Cart Example1 Example2 Example3 Example4 How do different features influence all sales forecasts? 2 4  6  8  10  Fig. 8 Bar plot example presenting the feature contributions on the output at model level 6 Application of the XMANAI Platform and Manufacturing App In order to deliver explainable AI results to the target end-users, Whirlpool has leveraged (a) the XMANAI Platform that provides a wide range of functionalities to address explainability from a data, model, and result perspective [4] (as presented in Sect. 6.1) and (b) a dedicated Manufacturing App that offers the user interface with appropriate visualizations specifically selected for demand analysis, what-if simulation, and customer behavior visualization (as outlined in Sect. 6.2). 6.1 XMANAI Platform In brief, the main aim of the XMANAI XAI platform is to enable the efficient XAI pipelines lifecycle management and to ensure the capability of the user to maintain the best performance level. It\u2019s mainly dedicated to IT roles (data scientists and dataXAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 451Fig. 9 XMANAI Platform \u2013 data exploration over a selected Whirlpool dataset engineers) and business roles (demonstrator\u2019s business/technical users) and follows the specific users\u2019 journey identified during the previous design phases [5]. In particular, for the Whirlpool demonstrator, the relevant CSV files that have been extracted from the Whirlpool databases and systems (as explained in Sect. 4.2) have been uploaded in the XAI Platform and then mapped to their equivalent fields in XMANAI Data Model. Once the dataset has been ingested, the metadata have been provided by Whirlpool data scientists. As a last step, an appropriate access policy has been defined for the uploaded datasets by Whirlpool users, in order to ensure full data protection: a dedicated sharing contract signature management function has been created to ensure a secure access to allowed partners. Once the available datasets are available and access rights have been granted, the data exploration phase may start in the Interactive Exploration & Experimentation menu depicted in Fig. 9. Based on the data exploration outcomes, different models have been trained in the XMANAI Platform and different XAI pipelines have been configured, utilizing both the data preparation functionalities and the ML/XAI functionalities. Once the pipelines were configured, the different execution logs were leveraged by the data scientists of the technical partner to check the progresses made (Fig. 10). 6.2 XMANAI Manufacturing App The main aim of the XMANAI manufacturing app of Whirlpool is to offer business users the possibility to get access to the explainability dashboard, which is targeted to the \u201cdemand forecasting\u201c problem and consists in 3 different web pages offering the functionalities of Demand profile, What-If Scenario and Customer\u2019s behavior that map to corresponding menu items.452 F. Lampathaki et al.Fig. 10 XMANAI Platform \u2013 XAI Pipeline utilizing the Whirlpool data The \u201cDemand Profile\u201d is dedicated to the demand forecast analysis results visu-alization for both central planning users and market users. It includes information regarding the sales predictions and the features\u2019 influence on the predictions. The information may be presented with a weekly scale in different relevant time horizons in the future (1 week, 1 month) and in the past. Here, the user may get important information not only on predicted sales value for specific products or product families but may also see which features have higher impact on the prediction value and prediction accuracy. This is relevant, as it allows them to understand which levers to use to drive the values. Also, they may get visibility of the correlations among features and awareness about the final result of a potential action. An extract of the \u201cDemand Profile\u201d page is presented in Fig. 11. The \u201cWhat-If Scenario\u201d page provides insights into how the sales predictions change depending on the values of the input features, as well as on which features are to be changed (and how) in order to reach a predefined sales prediction. The user can also create new scenarios using a wizard, edit the configuration of the existing ones, view an existing scenario of their interest (as depicted in Fig. 12), or delete those which are no longer useful. All the created scenarios provide the possibility to see the \u201cDemand Profile\u201d diagrams. This function, dedicated to central planning users and market users, allows to see the effect on the output by modifying one or more features. Conversely, it also provides information about the specific values of the modifiable features required to achieve the desired forecast.XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 453Fig. 11 XMANAI Manufacturing App view 7 Evaluation of the XMANAI Solution The validity of the XMANAI solution and the status of achievement of the project objectives have been captured, after the completion of the demonstrator sessions held by the users, through questionnaires that identified key results from a user\u2019s perspective on different dimensions (in a scale 1\u20135, where 1 = not at all and 5 = completely). As the main strategic objective of the XMANAI platform is to gain the users\u2019 trust through the explainability associated with artificial intelligence, the users\u2019454 F. Lampathaki et al.Fig. 12 View of a configured what-if scenario Fig. 13 Users\u2019 XAI Manufacturing App evaluation questionnaire for Whirlpool\u2019s use case 0 Actionable Insights Explanation Clarity Explanation Consistency Explanation Validity Feature Importance Missing Features Model Improvements Predicting Output Changes Real-world Applicability Transparency Trustworthiness Unexpected Findings Whirlpool Understanding of Input Features 1 2 3  4  5  feedback has been particularly meaningful, even in a first release of the XMANAI results. As depicted in detail in Fig. 13, the questionnaire results highlighted a strong improvement on the business impact driven by XAI solution, even if the alpha release that was assessed still needs to be significantly improved to achieve the expected excellence. The effort spent on explainability and the refinement path (which started from visualization diagrams fit for data scientists to a dashboard fit for business users) has been appreciated even if, at the moment, the expectations are not fully satisfied. The questionnaire focused on what is still missing and what can be done to fully reach the goals. The business objectives that have been identified during the preliminary project phases and are mainly related to the reliability of the forecast and the explainability of the results have been summarized as follows:XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 455Fig. 14 Whirlpool\u2019s use case KPIs 5STARS Sales trend ATP DFE Weekly target (Lag 2,3,4) DFE Monthly target (Lag1, Lag2) Demand Forecast Error at SKU level 1/2 months before Demand Forecast Error at SKU/week/market level 2/3/4 weeks before Availability To Promise Revenue\u2019s monthly variation Customer appreciation MeaningDemonstrator KPI \u2013 Optimization of the order-to-delivery process, maximizing the customer sat-isfaction (revenues, margins) with minimal required resources (inventory minimization, supply management just-in-time) \u2013 Business dynamics knowledge acquisition for people empowerment in driving process As a consequence, the corresponding business KPIs (Key Performance Indica-tors) set has been identified in Fig. 14 in order to capture the business impact of XMANAI usage. In this initial demonstration phase, a detailed and solid measurement of the KPIs set has not been feasible, but the data gathering related to weekly DFE (Demand Forecast Error) generated by XMANAI platform vs the demand generated in the actual management process showed a significant improvement as shown in Fig. 15, notwithstanding an overall fluctuation effect. To conclude, the users\u2019 feedback has been very positive, demonstrating a high confidence on the possibility of further improvement in reliability of prediction, completeness, and effectiveness of the visualization tools. Finally, an evaluation tool based on 6P methodology [6] has been applied to the demonstrator session after the sessions with the end users. The gathered results have been compared with the same questionnaire submitted at the beginning of the project, in order to capture the \u201cas-is\u201d situation. The assessment has been focused on various aspects of AI and XAI adoption to measure the progress in the development journey during the project lifecycle. The specificity of Whirlpool\u2019s use case excluded the possibility to measure some of the dimensions, specific for manufacturing environment. However, the final result has provided clear evidence of the main gap in the dimensions of people readiness for AI and explainability technologies (as depicted in Fig. 16). The strategy to address this gap coverage456 F. Lampathaki et al.Fig. 15 Whirlpool\u2019s use case \u2013 preliminary KPIs results for example product range Fig. 16 Whirlpool\u2019s use case \u2013 6P assessment result for the PEOPLE dimension after the initial demonstrator phase represents one of the most interesting indirect results expected out of the XMANAI project experience. 8 Conclusions and Lessons Learnt Following the completion of the first demonstration phase with the end users of the XMANAI solution, some key lessons learnt have been captured and are to be used for a more effective continuation both of the next project phases and of any XAI initiative:\u2022 As with any AI initiative, the availability of appropriate data is instrumental. In the case of Whirlpool, the need to enrich the underlying data pipelines has been further highlighted (after the initial results) to improve accuracy and explainability of the demand forecasts.XAI for Product Demand Planning: Models, Experiences, and Lessons Learnt 457\u2022 The end users have significant difficulty in vocalizing and describing their explainability requirements: a preliminary preparation of the target users is recommended in terms of change management to enable awareness of XAI earlier and then competence to get the most out of it.\u2022 Predictions at multiple product hierarchy levels are not trivial and need to be reconciliated with appropriate techniques to ensure homogeneous results. Such an activity requires additional work on the XAI pipelines to ensure that all predictions across all product hierarchy levels (e.g., category, item, product function) are consistent, while always in consultation with the business experts to understand the business dynamics.\u2022 The product demand forecasting problem has significant complexity since each product has its own peculiarities and one-size-fits-all XAI models do not work. Therefore, the selection of a single product hierarchy that brings maximum impact and development of targeted XAI models to improve accuracy is a most recommended approach (instead of trying to solve the full product demand forecasting problem at once). Overall, from the business perspective, the support of a structured change management, which includes communication and focused training actions, seems to be the key success factor for the introduction of XMANAI platform into a business organization. Besides, from a technical point of view, the communication between data scientists and business experts represents some of the real challenges to be addressed and to which XMANAI has tried to contribute. Acknowledgments The research leading to this work has received funding from the European Union\u2019s Horizon 2020 research and innovation programme under Grant Agreement No: 957362. References 1. Lampathaki, F., Agostinho, C., Glikman, Y., Sesana, M.: Moving from \u2018black box\u2019 to \u2018glass box\u2019 artificial intelligence in manufacturing with XMANAI. In: 2021 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC), Cardiff, United Kingdom, vol. 2021, pp. 1\u20136 (2021). https://doi.org/10.1109/ICE/ITMC52061.2021.9570236 2. Lundberg, S.M., Lee, S.-I.: A unified approach to interpreting model predictions. In: Proceed-ings of the 31st International Conference on Neural Information Processing Systems (NIPS\u201917), pp. 4768\u20134777. Curran Associates Inc., Red Hook (2017) 3. Arrieta, A.B., D\u00edaz-Rodr\u00edguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., Garc\u00eda, S., Gil-L\u00f3pez, S., Molina, D., Benjamins, R., Chatila, R.: Explainable Artificial Intelligence (XAI): concepts, taxonomies, opportunities and challenges toward responsible AI. Inf. Fusion. 58, 82\u2013 115 (2020) 4. Miltiadou, D., Perakis, K., Sesana, M., Calabresi, M., Lampathaki, F., Biliri, E.: A novel explainable artificial intelligence and secure artificial intelligence asset sharing platform for the manufacturing industry. In: Proceedings of 2023 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC) (2023)458 F. Lampathaki et al.5. Branco, R., Agostinho, C., Gusmeroli, S., Lavasa, E., Dikopoulou, Z., Monzo, D., Lampathaki, F.: Explainable AI in manufacturing: an analysis of transparency and interpretability methods for the XMANAI platform. In: Proceedings of 2023 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC) (2023) 6. Spaltini, M., Acerbi, F., Pinzone, M., Gusmeroli, S., Taisch, M.: Defining the roadmap towards industry 4.0: the 6Ps maturity model for manufacturing SMEs. Procedia CIRP. 105, 631\u2013636 (2022) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Process and Product Quality Optimization with Explainable Artificial Intelligence Michele Sesana, Sara Cavallaro, Mattia Calabresi, Andrea Capaccioli, Linda Napoletano, Veronica Antonello, and Fabio Grandi 1 Introduction XAI holds great potential for enhancing operators in modern factories, revolution-izing the way they interact with AI systems and improving their decision-making capabilities. By providing understandable and transparent explanations for the outputs of AI models, XAI empowers operators to gain deeper insights into the underlying processes and logic behind AI-driven recommendations or predictions. This enables operators to make informed judgments, validate AI-generated sugges-tions, and identify potential errors or biases in the system\u2019s output. With XAI, operators can trust AI systems as reliable assistants, leveraging their expertise while retaining control and accountability. The ability to understand and interpret AI\u2019s reasoning fosters collaboration between operators and AI systems, leading to more effective problem-solving, optimized processes, and improved overall factory performance. XAI serves as a valuable tool in bridging the gap between human M. Sesana (\u0002) \u00b7 M. Calabresi \u00b7 V. Antonello TXT e-tech, Milan, Italy e-mail: michele.sesana@txtgroup.com; mattia.calabresi@txtgroup.com; veronica.antonello@txtgroup.com S. Cavallaro CNH Industrial, Modena, Italy e-mail: sara.cavallaro@cnhind.com A. Capaccioli \u00b7 L. Napoletano Deep Blue, Rome, Italy e-mail: andrea.capaccioli@dblue.it; linda.napoletano@dblue.it F. Grandi Universit\u00e0 di Modena e Reggio Emilia, Modena, Italy e-mail: fabio.grandi@unimore.it \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_26459460 M. Sesana et al.operators and intelligent machines, driving a symbiotic relationship that maximizes efficiency and productivity in modern factory settings. Potential applications of XAI in product optimization are as follows [1]: 1. Feature Importance Analysis: XAI techniques can identify the most influential features or factors affecting product performance, allowing businesses to priori-tize and optimize those aspects for enhanced product quality. 2. Failure Analysis and Predictive Maintenance: XAI techniques aid in identifying potential failure modes, understanding failure causes, and predicting mainte-nance needs. This enables operators to proactively address maintenance issues, reducing downtime and optimizing product performance. 3. Continuous Improvement and Iterative Optimization: XAI enables operators to continuously monitor and evaluate product performance, identifying areas for improvement and iterative optimization. By understanding the factors contribut-ing to product success or failure, operators can drive ongoing enhancements and innovation. Potential applications of XAI in process optimization are as follows [2]: 1. Anomaly Detection and Root Cause Analysis: XAI techniques can identify anomalies in process data and provide interpretable explanations for their occurrence. This helps operators understand the underlying causes of process deviations and take corrective actions to optimize process performance. 2. Process Monitoring and Control: XAI enables operators to monitor and control complex processes by providing transparent explanations for system outputs and recommendations. This enhances operators\u2019 understanding of the process dynamics, facilitating real-time decision-making and adjustments to optimize process efficiency. 3. Process Bottleneck Identification: XAI helps identify bottlenecks in complex process workflows by providing interpretable insights into the factors limiting throughput or efficiency. Operators can then focus on optimizing these bottle-necks to improve overall process performance and productivity. 4. Quality Control and Defect Prevention: XAI techniques can explain the rela-tionship between process parameters and product quality. By understanding the key factors affecting quality, operators can adjust process settings and reduce the likelihood of defects, ensuring consistent and high-quality output. These applications highlight the valuable role of XAI in process and product optimization, enabling operators to gain insights, make informed decisions, and drive continuous improvement in complex manufacturing processes. By enhancing transparency, trust, and collaboration between operators and AI systems, XAI paves the way for more efficient, cost-effective, and high-quality process operations. This chapter begins describing CNH Industrial, which is a partner of H2020 XMANAI European research project [3]. CNH explores the use of XAI in a practical manufacturing context. This chapter provides a comprehensive overview of the use case and its application in today\u2019s competitive business environment. It delves intoProcess and Product Quality Optimization with Explainable Artificial Intelligence 461the challenges faced in developing XAI within the current manufacturing scenario considering the maintenance operator\u2019s needs during the XAI implementation. Subsequently, the focus shifts to the XAI platform, briefly describing the scope of each component useful to avoid conventional \u201cblack boxes\u201d AI approaches, due to their lack of transparency, introducing XAI techniques that brought a new level of interpretability to the field traducing it into \u201cglass box.\u201d Furthermore, this chapter explores the explainability value and the methods to design XAI web-app considering user needs applied to a real-world case study where organizations have successfully employed XAI in their quality optimization processes. This case study highlights the tangible benefits derived from the utiliza-tion of explainable AI, such as improved anomaly detection and enhanced process efficiency. Finally, the chapter concludes by discussing the XAI evaluation within the application on a real manufacturing environment for quality optimization and the Key Performance Indicator selected to measure the global benefits of the explainability. By the end of this chapter, readers will have gained some take aways of the role of explainable artificial intelligence in process and product quality optimization. 2 The CNH Industrial XMANAI Demonstrator CNH Industrial is a world leader in the design and manufacture of machinery and services for agriculture and construction. It employs more than 40,000 people in 43 manufacturing plants and 40 research and development centers all over the world. The CNH Industrial use case for XMANAI European project focused on San Matteo plant, located in Modena, in Italy, where there is one of the most important research centers in the tractor field in Europe, using the most advanced technologies for design and engineering purposes. In addition to the San Matteo research site, Modena is also home to one of Italy\u2019s manufacturing plants where the medium tractor transmissions are produced. They are used to assemble tractors in CNHi factories around the world. It is within this plant that the application cases of the European-funded XMANAI project originate. The use cases focus on Modena Plant which is currently manufacturing 60,000 APL (all purpose low) and APH (all purpose high) tractors drivelines used to equip all tractors assembled in CNHi plants worldwide. The case study stems from a real problem that the Modena production plant frequently encounters nowadays. In fact, today\u2019s production lines are mainly affected by unexpected failures of the production machine that stops the line for undefined periods of time. Within CNHi\u2019s production plant, the needs of the operators who face downtime issues every day lie in restoring the machinery, the beating heart of the plant, in such a quick timeframe that it does not cause major production losses. Downtimes are usually due to replacement of defective parts or for maintenance. XAI could act462 M. Sesana et al.as a bridge between the machines and the operators, enabling them to understand in a quicker way the status of the machines and improving their productivity through a fast-responsive intervention. The primary objectives CNHi aims to address through XAI within the XMANAI project, are ingest, manage and analyze the real-time and batch data acquired by CNHi systems, and the faults history data related to the maintenance and tooling systems to give user simplified suggestion thanks to explainability to restore the machine. The goal is to implement XAI models that should help the operator with recommendations, to optimize the production line avoiding waste of time and cost for the company. In the next sections are described the use case and the current challenges the operators face during the use of machineries and how the proposed platform could enhance their work through the use of XAI. 2.1 Use Case Description In the current state, within the Modena CNHi production plant, when a machine stops, maintenance operators must exclude different parts of the machine step by step to get to the faulty component and understand where the fault occurred and which anomaly caused the stoppages. As a result, operators waste significant amounts of time troubleshooting the faulty component and for replacing the component. Moreover, if the operator is not able to restore the machine, it is necessary to call for external maintenance operators, which slows down the process even more. By implementing the XAI platform in the production process, the maintenance operators receive assistance in diagnosing machine errors. This support involves utilizing XAI suggestions derived from the sensor values installed on the machine. Thus, a twofold benefit is targeted: 1. Detect where the fault occurs so that maintenance operators will know which component is responsible and why, which allows to replace immediately the faulty part (for faster recovery). 2. Identifying the specific anomaly responsible for the failure assists operators in tracking the occurrence, minimizing troubleshooting duration, and enabling them to concentrate on pinpointing the root cause, thereby reducing recovery time. To implement XAI within CNHi plant, the developed platform takes data from the current systems, carrying information about the status of the Heller 400, the CNC machine that is selected for the use cases (Fig. 1). A data pipeline will be created to ingest data and to train the XAI models and give suggestions from AI to the operator in an explainable form. In such a way, the user will test how to create a more organized data management and sharing and how to generate knowledge graphs with clear relationships between data and defined actions. Finally, the trainedProcess and Product Quality Optimization with Explainable Artificial Intelligence 463Fig. 1 The CNC machine selected for the use case algorithm provides scheduling suggestions to the production manager to improve the scheduling in the Plant Management System (PMS) and visualization tools employed to aid operators by displaying and elucidating the AI results. For the CNHi case study, explainability is indispensable to provide the worker with the necessary explanations and clarity to understand which part of the machine equipped with appropriate sensors may have caused the blockage. The worker must therefore be put in a position to decide and understand whether the artificial intelligence algorithm has correctly processed and considered the various possibilities of machine error and why it has arrived at that suggestion, according to which correlation between the various data extrapolated from the sensors. Several sensors were considered to equip the machine to be monitored by AI, but it could also occur that some machine malfunction could not be correlated with the currently installed sensors. Hence, it is crucial that the algorithm through explainability provides all the logical connections used by machine learning to make the operator aware of the machine\u2019s operating/malfunctioning state. 2.2 XAI Technical Implementation The data sources, collected by the sensors installed in the selected plant machine, a CNC work center machine named Heller 400, will interface with the advanced XAI platform developed specifically for the manufacturing industries, called XMANAI platform. The CNC work center is managed by machine conductor and shopfloor people in CNH. The machine is equipped with different sensors that collect data on the operating status of the machine and they are conned to the network. In detail, a dedicated management system is set up to collect sensor data (SmartObserver).464 M. Sesana et al.This use case focuses on anomaly detection on sensor data and explanation of machinery faults. The activities carried out for the development of the case study are discussed below, grouped in these different steps:\u2022 Data processing and data analytics: In this task, the complete history of sensor measurements was collected from the Heller 400 CNC machine. Data have been cleaned, sorted, and completed with the missing information, in order to obtain a usable dataset to feed to the selected ML models. Finally, the features selected have been identified as the complete set of 76 sensors data and a collection of recorded anomalies throughout the years.\u2022 Development of intelligent analytical model: In this task, a suitable set of ML models (Isolation Forest) was selected among others, taking into account the type and amount of data at disposal and the end goal of the detection task to be performed. For a more detailed explanation of the selected model, please refer to the upcoming section.\u2022 Training of the selected ML models: In this task, the selected Isolation Forest models were trained on a portion of the available dataset. The goal of the training was to correctly categorize a set of sensor configurations as anomalies or regular data. The set of models was then tested on the remaining portion of the dataset to generate insights about the model accuracy and quality of the predictions.\u2022 Definition of the explainability requirements and visualization tools: As part of this task, the explainability requirements were collected and analyzed to find the best output format in which the model explanation could be displayed, considering the target audience, their knowledge in term of explainability charts, and their explainability needs.\u2022 Production of visual explanations: The trained ML models are exploited to generate the needed explanation using a combination of custom tools and standard graphs, taken from the SHAP [4] library, and taking into account the requirements stated above. In this phase, the models produced explainability charts targeting individual sensor configurations (the one classified as anomalies) with local explanations, grouped sets of sensors (for multivariate explanations), as well as global explanations concerning the overall correlation between anomalies and the sensors having the higher contribution impact on these. A high-level overview on the motivations behind the selection of an Isolation Forest approach as the basis for the models is provided in following paragraphs, along with the general idea behind the implementation of such technique in both univariate and multivariate cases. To this end, a crucial aspect that has been carefully considered for the current use case was the selection of the model to be used to accomplish the described tasks with the support of the XMANAI platform. The model needed to perform well with various irregular time series of varying lengths. It also needed to keep into account the possibility to add new sensors in the future without compromising accuracy or forcing to homogenize data every time. For all these reasons, an Isolation Forest approach was identified as the most suitable to use. This algorithm selects a feature and then randomly selects a split between minimum and maximum values of the selected parameter. The core idea is that many splitsProcess and Product Quality Optimization with Explainable Artificial Intelligence 465are required to isolate a normal point while a small number of splits are required to isolate an anomaly. The sequence of splits that brings to an individual data point is called path. Depending on the path length, an anomaly score is computed and interpreted as follows:\u2022 A score close to 0.5 indicates a normal point.\u2022 A score close to \u22120.5 indicates an anomaly. With this basic concept in mind, two approaches were explored: 1. Initially, the method involved fitting an Isolation Forest for each accessible sensor, followed by evaluating the models\u2019 outcomes on the day when the failure occurred. Finally build plots to visualize and interpret the results. This method allows each individual model to be fitted on the specific sensor, increasing classification accuracy and making each prediction independent to the number of samples available for other sensors. This approach, however, prevents the user to catch correlation between sensors (since each model only refers to an individual sensor). This aspect is crucial in identifying possible points of failures in the machine, as multiple sensors can contribute to the same anomaly together. For this reason, a second approach was proposed to account for this scenario. 2. The second approach relies in fitting an Isolation Forest for each group of sensors and checking the results of the models in the day of occurrence of the failure. Groups were identified by domain experts considering the placement of each machine component with respect to the others and their reciprocal influence. Finally, some summary plots have been built exploiting the visualization capa-bilities of the SHAP library to interpret the results. The crucial aspect of this method is the selection of the groups; these should be large enough to allow the model to correlate together as many sensors as possible, while avoid grouping sensors with too different time series shape, so that only a few samples need to be discarded/extended to harmonize all sensors in the group. The combination of the two approaches described allows the overall process to be precise enough, thanks to the individual models tailored for each sensor, while providing good correlation information, thanks to the categorization of the sensors. The visualizations produced by each of the two approaches are presented in the section below. 2.3 Explainability Value Methods like questionnaires, user stories, user journey, and personas play a crucial role in exploiting XAI for product and process optimization. These methods facilitate a deeper understanding of user needs, preferences, and experiences, which are essential for designing and implementing effective XAI systems. The importance of these methods is expressed in more detail below:466 M. Sesana et al.Fig. 2 Personas developed for the CNHi use case 1. Questionnaires: valuable tools for gathering quantitative and qualitative data from users. They help in capturing user perspectives, expectations, and feedback related to product or process optimization, collecting valuable insights that inform the development of XAI models. 2. Personas: represent fictional archetypes of target users, based on real user research. They provide a human-centered perspective, helping businesses empathize with and understand the needs and motivations of different user groups. Personas facilitate the creation of XAI systems that meet various user requirements, ensuring, in the case of CNHi, the optimization of the XAI web app interface for different maintenance profiles (Fig. 2). 3. User Stories: they provide a narrative description of users\u2019 interactions with a product or process. They capture users\u2019 goals, motivations, and pain points, highlighting key aspects that need to be considered for optimization. User stories also help in identifying specific areas where explainability is crucial to enhance user trust and decision-making. User story descriptions typically follow a simple template as a Card: As a < role>, I want <goal> so that <Benefit>. Finally, the key output from user story is a series of <Acceptance Criteria> preparatory to the interface design of the XAI web app (Fig. 3). User Journey: maps to visualize the end-to-end experience of users throughout their interaction with a product or process. These maps illustrate touchpoints, pain points, and opportunities for optimization. Understanding the user journey helps in designing XAI systems that provide relevant explanations at the right moments, ensuring a seamless and trusted user experience. Incorporating user perspectives through the use of these methods enhances the user-centric design of XAI, ensuring that explanations provided by AI systems align with user expectations, facilitate informed decision-making, and build trust. Ultimately, these methods contribute to the successful adoption and exploitation of XAI in optimizing products and processes to meet user needs and improve overall performance.Process and Product Quality Optimization with Explainable Artificial Intelligence 467Fig. 3 User stories developed for the CNHi use case 2.4 XMANAI Manufacturing App Experience This section introduces the XMANAI platform key features and capabilities and discusses their usage in the CNH pilot. Subsequently, the chapter describes the manufacturing Web App developed to connect the generic platform functionalities to the specific final user to solve real manufacturing problems like troubleshooting. 2.4.1 XMANAI Platform and Components Usage The XMANAI platform was developed to enable XAI takeup specifically for the manufacturing industry. It bridges the gap between the complex nature of AI algorithms and the demand for transparency, interpretability, and trust in decision-making processes within manufacturing operations. Fig. 4 shows an overview of the components constituting the XMANAI cloud platform. In particular, the components surrounded in a red box are being employed in the context of the CNH demonstrator. Starting with the XAI Insight Services and Data Manipulation Services, those are used at an early stage to perform tests on the models and the training data, in order to understand the challenges related to the use case realization (Fig. 5). The XAI Secure Sharing Services allows secure sharing of the input data between the CNH demonstrator and the technical supporting partners, granting CNH full ownership of their data in the platform and the ability to setup sharing policies according to company internal policies. The XAI Execution Services allow to execute the XAI algorithms experimented earlier in a robust production-ready environment, once the models have been finalized.468 M. Sesana et al.Fig. 4 XMANAI platform components usage Fig. 5 Visualization of the explanations through the XAI Pipeline Designer Moving on to the XAI Pipeline Lifecycle Management Services, those are being used in all aspects of the process, in order to securely create, schedule, and monitor the execution of XAI pipelines (Figs. 6, 7 and 8). The Scalable Storage Services are used both as the source of input data to be processed and to store the refined data undergoing the process of data ingestion. Those are further utilized to store the trained models and the associated prediction. Moving to the Data Collection & Governance Services and, in particular, to the Data Handler category, the File Data Harvester component finds particular use to ingest the raw machinery data in the proper format, following the CNH data model and ensuring type consistency (Fig. 9).Process and Product Quality Optimization with Explainable Artificial Intelligence 469Fig. 6 Configuration of the model through the XAI Model Engineering Engine Fig. 7 Design of the Isolation Forest Univariate pipeline through the XAI Pipeline Designer Finally, the Platform Management Services are used to guarantee security and authorization of the users in the platform, allowing access to data and pipelines only to CNH and the supportive partners of choice. It is important to highlight that, although some of the components haven\u2019t been marked as used, they are exploited indirectly through other components of the XMANAI platform. The above description only refers to the components directly used in the realization of the use case.470 M. Sesana et al.Fig. 8 Execution and monitoring of the Isolation Forest Univariate pipeline through the XMANAI Platform Fig. 9 Dataset is imported into the platform through the File Data Harvester 2.4.2 XAI Powered Manufacturing Web App The overall explainability design process resulted in the development of an interface for the manufacturing Web App that encompasses the explainability requirements and the acceptance criteria defined in the user stories. The manufacturing Web App, as an explainability tool, refers to a web-based application specifically designed to provide transparent and interpretable explanations for the outputs and decision-making processes of AI systems. It serves as a user interface that enables users toProcess and Product Quality Optimization with Explainable Artificial Intelligence 471Fig. 10 (a) Home screen; (b) sensor values screen; (c, d) sensor details interact with AI models and gain insights into the reasoning behind AI-generated outcomes, coming from the XMANAI platform. The purpose of the Web App is to bridge the gap between the complexity of AI algorithms and the need for human understanding and trust. It provides users, such as domain experts, decision-makers, or end-users, with a user-friendly interface to access and interpret the explanations generated by AI models. Through the Web App prototype, showed in Fig. 10, end-users can monitor information about the operating condition of the monitored machine. Looking closely at the different interfaces designed, in the Home screen there are information regarding the number of active sensors, the number of alarms and anomalies detected, together with the historical data of failures and a specific feature to compare trends of various sensors. The Sensor Values page displays the hierarchy of the most crucial sensors, utilizing a chromatic scale of red to indicate their level of criticality based on the algorithm confidence value. In the specific Sensor page, there is possibility to view its trend over time and compare different suggested and ranked anomalies. Finally, there is also a tab where the user can provide feedback on whether the platform\u2019s suggestion was helpful in solving the fault or not. The proposed manufacturing Web App prototype design was changed during the development phase due to technical issues related to the availability of data. The final developed manufacturing Web App has a simplified Home screen with just two widgets: Sensors values and Anomalies (Fig. 11a). The Sensor values menu allows the user to check the value of all sensors connected to the faults on different days, while the Anomalies menu includes the entire fault history of the machine. By clicking on Sensor values page (Fig. 11b), the application will show all the sensors in the selected time range, ranked according to the algorithm confidence value for the specific fault, highlighted by an increasingly bright red color showing the increasing criticality of the fault.472 M. Sesana et al.Fig. 11 Web App pages. (a) Home screen; (b) Sensor values screen Fig. 12 Web App pages for specific sensor. (a) Sensor\u2019s trend; (b) XAI Visualization button By clicking on the specific sensor (Fig. 12a), the Web App opens a page with the sensor\u2019s trend where the user can check the value for each day and the potential anomalies (i.e., the top ten potential anomalies ranked by the algorithm) associated with that specific sensor. Displayed above the graph are the sensor threshold (if applicable) and the most recent measured value. In Fig. 12b, the graph shows suggested anomalies that can be associated with that specific sensor according to the value. The anomalies are ranked from the most probable according to the algorithm.Process and Product Quality Optimization with Explainable Artificial Intelligence 473On the contrary, by clicking on the XAI Visualization button (see Fig. 12b), the Web App will open a page with all the XAI standard SHAP plots mainly designed for advanced users. Moreover, it is possible to select the type of explanation according to user expertise and role. In addition to the Web App, an Augmented Reality (AR) application will be available to aid workers in executing maintenance procedures. It will provide step-by-step guidance for machine recovery through a suggested wizard interface. The AR app will assist the operator in solving maintenance problems and help the explainability to take place with the XAI algorithms. 2.4.3 AR App Design Augmented reality (AR) combined with an XAI approach holds immense potential in supporting maintenance operators in manufacturing context. By overlaying digital information onto the real-world environment, AR provides operators with contextualized and visual guidance, enabling them to perform complex maintenance tasks more effectively. When coupled with XAI, AR becomes even more powerful by offering transparent explanations for AI-generated recommendations or insights, empowering operators to understand and trust the AI\u2019s assistance. In the considered use case, the integration of AR and XAI benefits maintenance operators from different points of view:\u2022 Real-Time Visualization and Guidance: AR overlays digital information, such as step-by-step instructions, diagrams, or annotations, onto the physical equipment or machinery being maintained. This visual guidance helps operators locate components, identify potential issues, and follow the correct procedures. By combining XAI, operators can understand the reasoning behind AI-generated instructions, enhancing their confidence and ensuring accurate execution of maintenance tasks.\u2022 Predictive Maintenance and Anomaly Detection: XAI techniques can analyze real-time sensor data from the equipment to detect anomalies or potential failures. AR can then visualize this information, highlighting critical areas that require attention. By providing transparent explanations for the AI\u2019s predictions or alerts, operators can understand the factors contributing to potential equipment failures, enabling them to take preventive actions or plan maintenance activities effectively.\u2022 Historical Data Analysis and Process Optimization: XAI techniques can analyze historical maintenance data, identifying patterns and correlations that are not eas-ily noticeable by humans alone. AR can present this analysis visually, enabling operators to understand how past maintenance actions have affected equipment performance and reliability. By comprehending the insights provided by XAI, operators can make data-driven decisions, optimize maintenance processes, and improve overall equipment effectiveness.474 M. Sesana et al.Understanding of Input Features Trustworthiness Transparency Real-world Applicability Predicting Output Changes Model Improvements Missing Features Feature Importance Explanation Validity Explanation Consistency Explanation Clarity Actionable Insights 0 1  Preference values CNHi (1:Not at all, 5:Completely) Questions for XAI Validation 2 3  43,83  5  Fig. 13 Questionnaire for XAI evaluation The integration of AR and XAI in maintenance operations not only improves efficiency, accuracy, and safety but also empowers operators with explainable AI support. By visualizing information and providing transparent explanations, this approach enhances operators\u2019 understanding, trust, and collaboration with AI systems, ultimately leading to optimized maintenance processes and increased equipment reliability. From a practical point of view, the operator launches the AR application from the list of anomalies highlighted in the Web App. The AR application is running on a hand-held device like a smartphone or tablet, so the operator is able to intervene on the machine to restore the production through some digital instruction. Once the procedure is finished, the operator can give a feedback on the proposed workflow, in order to understand if it helped in restoring the machine. 2.4.4 Evaluation of XAI Platform Definitely, the added value of XAI platform is the explainability associated with artificial intelligence. The evaluation of the platform through the questionnaire shows a positive impact of the XAI implemented in industrial environment. In fact, the ratings recorded during the questionnaire for the validation of the XAI Web App show that the explainability plays a key role (Fig. 13). Each parameter was rated by experts using a scale ranging from 1 to 5 (in which 1 is not at all and 5 is completely), obtaining a mean value of 3.83 (std dev = 0.83). For instance, when considering feature importance, a high value signifies that users can comprehend the significance of each feature in the final algorithm suggestion through the confidence score, expressed as a percentage in the output. And another example is the explanation clarity obtained by adding standard explainability graphs.Process and Product Quality Optimization with Explainable Artificial Intelligence 475Table 1 KPIs selected to measure the benefits of the implementation of XAI Demonstrator Key Performance Indicators (KPI) Measured value Expected value Means of verification Trust in XAI predictions for production managers Medium (60%) High (at least 70%) Number of decisions following XAI suggestions vs number of suggestions to solve downtime Accuracy of XAI assistance in providing predictions relieving the production manager from onerous tasks with low \u201chuman value\u201d is low, while maintaining situational awareness and control of the task Medium (45%) Medium\u2013high (65%) Number of preventive maintenance executed/number of unplanned stoppages Relevant information sharing between the XAI and blue-collar worker in collaborative troubleshooting High (75%) High (85%) Heuristic evaluation/user observation The chosen Key Performance Indicators (KPIs) used to evaluate the advantages of integrating XAI into the production line primarily center around accuracy, reliability, and human-machine collaboration. These are outlined in detail in Table 1. Despite the current medium-high values displayed by the Key Performance Indicators (KPIs), there remains a necessity for additional optimization. This requirement arises from the fault grouping process, which was conducted solely by data scientists without input or support from maintenance experts. This optimization requires additional support from the maintenance staff to ensure greater accuracy and achieve the expected values. Furthermore, samples of sensors\u2019 data currently available are only based on few months of data coming from the new sensors (recently installed), but it is planned to expand the sample to optimize the predictions of the algorithm and achieve the expected levels of KPIs. 3 Conclusion and Lessons Learnt During the development and integration of XAI modules for manufacturing tasks in the scope of the XMANAI, several issues have been addressed and overcome, which is summarized in Table 2.476 M. Sesana et al.Table 2 Lesson learnt table Category Problem/success Impact Recommendation Technology Difficulties in extracting data from the internal server No real-time updated data in the final web app Store data in an  internal environment that can communicate easily with the XAI web app Coordination Difficulty in coordinating some people from plant (maintenance technicians) available and dedicated for a long time for innovation project More time to develop certain part of the project that directly involves the maintenance people Be more flexible when considering the availability of a maintenance worker who is constantly busy within a production plant Implementation planning Considering short time for implementing web app in production More time to develop certain part of the project that directly involves the maintenance people Planning by paying attention to the availability of operators within the production facilities considering the frequent unplanned stoppage At the technological level, an initial challenge was encountered in retrieving sensor data stored within the internal server to ensure real-time updates on the XAI web app. There should be an on-premises solution with a dedicated internal server with which the XAI Web App can easily communicate to update data in real time. At pilot coordination level, there was a difficulty in collaborating constantly and effectively with the plant maintenance staff, who were often busy with emergencies to be solved on the production lines. Greater flexibility should be observed when assessing the availability of maintenance personnel, especially during the planning phase of implementation. It is essential to meticulously plan activities, considering the schedules and availability of maintenance workers. The expected benefits of using the XMANAI platform will be the beginning of a human-machine collaboration in which the XAI will actively assist the maintenance technician during fault diagnosis. This collaboration will be achieved with a certain level of accuracy and trustworthiness of the XAI that will significantly increase the operators\u2019 trust in XAI suggestions. Acknowledgments The research leading to this work has been carried out within the context of the XMANAI project. The XMANAI project is being funded by the European Commission under the Horizon 2020 Programme (Grant Agreement No 957362).Process and Product Quality Optimization with Explainable Artificial Intelligence 477References 1. Chen, T.C.T., et al.: Explainable artificial intelligence (XAI) in manufacturing. In: Explainable Artificial Intelligence (XAI) in Manufacturing: Methodology, Tools, and Applications, pp. 1\u201311. Springer International Publishing, Cham (2023) 2. Sidahmed Alamin, K.S., et al.: SMART-IC: smart monitoring and production optimiza-tion for zero-waste semiconductor manufacturing. In: 2022 IEEE 23rd Latin American Test Symposium (LATS), Montevideo, Uruguay, pp. 1\u20136 (2022). https://doi.org/10.1109/ LATS57337.2022.9937011 3. XMANAI. https://cordis.europa.eu/project/id/957362, https://ai4manufacturing.eu/ 4. Lundberg, S.M., Lee, S.-I.: A unified approach to interpreting model predictions. In: Proceed-ings of the 31st International Conference on Neural Information Processing Systems (NIPS\u201917), pp. 4768\u20134777. Curran Associates Inc., Red Hook (2017) Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict the Pointwise Accuracy of Laser Scanning Devices in Industrial Manufacturing Eleni Lavasa, Christos Chadoulos, Athanasios Siouras, Ainhoa Etxabarri Llana, Silvia Rodr\u00edguez Del Rey, Theodore Dalamagas, and Serafeim Moustakidis 1 Introduction Quality control for manufactured parts in the automotive, aeronautics, and energy sectors is performed by certified metrological laboratories, often by using 3D laser scanners. The part under study is captured in a set of points constituting a point cloud that is the virtual representation of the actual object. The point cloud is filtered to reduce noise and then processed to achieve the final goal of the study, which is dimensional and/or positional measurement and tolerancing. Based on the geometry of the features of the object, the metrologist initially constructs a measurement plan. However, this preliminary study may need to be repeated for less-experienced operators who are less likely to define an appropriate measurement plan from the beginning. This obstacle may lead to both time-consuming processes and inconsistent results between operators. E. Lavasa \u00b7 T. Dalamagas Athena Research Center, Marousi, Greece e-mail: elavasa@athenarc.gr; dalamag@athenarc.gr C. Chadoulos \u00b7 A. Siouras \u00b7 S. Moustakidis (\u0002) AIDEAS OU, Tallinn, Estonia e-mail: s.moustakidis@aideas.eu A. Etxabarri Llana UNIMETRIK S.A., Legutiano, \u00c1lava, Spain e-mail: aetxabarri@unimetrik.es S. Rodr\u00edguez Del Rey Asociaci\u00f3n de Empresas Tecnol\u00f3gicas Innovalia, Calle Rodr\u00edgez Arias, Bilbao, Spain e-mail: srodriguez@innovalia.org \u00a9 The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2_27479480 E. Lavasa et al.The goal of this study is to model the differential accuracy of the laser scanning device in response to different geometries and under various scanning configurations. Capture errors are driven by several sources, such as the incident angle, measurement distance, and surface texture. Measurement error is introduced by the instrument itself, which has an anisotropic response by design: accuracy is maximum in the axial direction (axis of movement of the rotary head) and diminishes laterally. Another important source of errors can be the surface ori-entations that the object\u2019s geometry encompasses with respect to the laser source orientation and the viewing direction of the CMOS sensor. In essence, very small incidence angles of the laser light on the surface (i.e., when surface and laser source orientations are quasi-parallel) result in severe backscattering of the light toward the CMOS camera, so large capture errors are introduced. On the other hand, very large incidence angles (close to 90\u25e6) also introduce large errors, but for a different reason: most of the laser light is scattered away from the CMOS sensor rather than being collected to capture an accurate representation of the surface. To address these issues, we propose a novel approach that leverages the power of artificial intelligence (AI) and a specific subfield known as Explainable AI (XAI). XAI is an emerging area of AI that aims at making the decision-making process of AI models transparent and understandable. Unlike traditional AI, where decision-making processes can be black boxes, XAI allows users to understand, trust, and manage AI outcomes. By breaking down complex AI decisions into digestible, human-interpretable components, XAI tools help enhance trust and improve adoption of AI systems. In this context, we propose a novel approach to assist metrologists in defining the optimal scanning setup for the measurement. This approach focuses on the geometrical properties of the objects and enables manufacturers to save time and costs while providing consistent results. We develop an AI-based decision support system to predict the point-wise accuracy of the laser scanner across the surface of the part under analysis. We further apply an explainability tool to provide a comprehensive view of the most important parameters affecting the model\u2019s predictions. These user-centered explanations are the key ingredients in building trust and allowing inexperienced operators to have better understanding about the different responses of the scanning device and make informed decisions. The rest of this chapter is organized as follows: the necessary background on optical industrial metrology as well as XAI applications in industry 4.0 is provided in Sect. 2; the formulation of the problem and the available data sources are outlined in Sect. 3; The proposed methodology and experimental setting are explained in detail in Sect. 4; experimental results and associated explanations are presented in Sect. 5; and conclusions and practical implications are presented in Sect. 6.Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 4812 Background and Related Work 2.1 Optical Metrology Optical measurement in digital manufacturing has been extensively researched, with a growing emphasis on integrating metrology into the production flow to optimize processes and enable fully automated manufacturing cells [1]. Laser-based instruments have emerged as the most common technology for industrial applications, although on-machine inspection still faces challenges due to high processing temperatures and random process variations. Key trends in this field include the shift toward zero-defect manufacturing strategies, facilitated by in-line measurement and in-process monitoring. However, several challenges must be addressed to ensure effective and efficient integrated metrology, including limitations in measurement and data processing speed, part complexity (size, shape, and surface texture), user-dependent constraints, and measurements in challenging environments [2]. Measurement speed is crucial, as faster measurements without sacrificing accu-racy and precision lead to increased throughput and reduced production costs [3]. Addressing part complexity necessitates adaptable and versatile measurement solutions to accommodate various manufacturing scenarios [4]. Challenging envi-ronments present additional difficulties, requiring alternative design strategies and robust sensors capable of reliable in situ operation [5]. Furthermore, multi-sensor integration and data fusion are essential to enhance overall measurement quality and provide comprehensive information about parts and processes [6]. This demands robust and efficient methods for sensor compatibility, data synchronization, and data fusion techniques. Addressing these challenges is vital for advancing integrated metrology and improving its effectiveness in modern manufacturing. Optical inspection methods, particularly laser triangulation measurements, have developed significantly in recent years, providing fast data acquisition, contactless measurements, and high sampling rates. However, challenges remain with the accu-racy and reliability of these measurements. The random measurement error is an important aspect to consider, as it quantifies the variation of the actual measurement from its expected value [7]. Factors that affect the measurement error of scanners include the angle of inclination [8], sensor distance from the surface, color [9], texture, and surface reflectiveness [10]. Various studies have investigated the impact of different factors on measurement performance and proposed methods to improve the quality of this process. These include the use of least-squares methods [11], color-error compensation methods [12], and mathematical frameworks for statistical modeling of uncertainties [13]. Some machine learning (ML) methods have also been applied to determine the measurement capacity of scanning devices and improve processes related to non-contact 3D scanning [14\u201316]. These ML applications include simplifying information about geometry obtained from point clouds and identifying distinct482 E. Lavasa et al.geometrical features of objects. With the ongoing advancement of optical inspection methods, researchers are investigating various techniques to improve the accuracy and reliability of measurements across various contexts [17]. Despite the numerous advantages and improvements offered by ML methods, there remains a notable gap in the current literature. A major concern is that most ML models are considered \u201cblack boxes,\u201d meaning their inner workings and decision-making processes are not easily interpretable or transparent. Transparency is of crucial importance in various industries, including metrology, since it ensures that stakeholders can trust the results generated by these models. When implementing ML techniques, it is vital to have a clear understanding of how the models arrive at their conclusions, particularly when making critical decisions that directly impact product quality, safety, or compliance with industry regulations. The lack of transparency in current ML models raises questions about their reliability and suitability for widespread adoption in the field of metrology. To address this gap, our work focuses on developing more transparent and inter-pretable ML models that can be easily understood by practitioners and stakeholders in the metrology industry. By providing transparency for ML models, researchers can foster greater confidence in their adoption, leading to more accurate and reliable measurements and, ultimately, enhancing the overall quality of optical inspection methods. 2.2 Explainable Artificial Intelligence The research and application field of XAI has been very active, following the widespread use of AI systems in many sectors related to everyday life and the rising need for interpreting the predictions of these complex systems. Interpretable by design models such as Decision Trees and linear models are outperformed by more complex methods such as Neural Networks, Support Vector Machines (SVMs), or ensemble models. The term XAI mostly refers to post-hoc explainability being applied to interpret-trained ML/DL models with complex internal mechanics that are otherwise opaque. Many different approaches have been proposed to this end (see for example [18] for a comprehensive review), and although taxonomies in the literature are not identical, a first-level distinction of XAI methods mainly pertains to the following: The applicability of the method: Model-agnostic methods are methods applicable to any kind of model, whereas model-specific methods are designed to explain a certain type of model, considering their particular properties and internal design. The scale of explanations: global methods explain the overall behavior of the model (at the global level), whereas local explanations refer to individual predictions (at the instance level). XAI methods are further classified by their scope, with those related to our study being feature attribution methods that aim to quantify the effect of individual inputToward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 483features on the model\u2019s output. Global techniques estimate feature importance by the overall change in model\u2019s performance in the absence of an input feature or under shuffling of its values, such as permutation importance [19]. Local feature attributions, on the other hand, explain how individual predictions change with each input feature. Shapley Additive eXplanations, or SHAP [20], apply methods from cooperative game theory to machine learning. Like Shapley values measure a player\u2019s impact in a game, SHAP values measure each input feature\u2019s impact on a model\u2019s prediction, compared to the average prediction. Local explanations are then aggregated to provide the ranking of global feature importances. SHAP is a well-established, model-agnostic method with robust theoretical background that has been widely employed to interpret the predictions of ML models across various application domains, including the industrial sector. In the field of machine prognosis and health monitoring, the authors of [21] designed a deep-stacked convolutional bidirectional Long Short-Term Memory (Bi-LSTM) network. This network predicts a turbofan engine\u2019s Remaining Useful Life (RUL) using time-series data measured from 21 sensors. They apply SHAP values to identify the sensors that are mostly affecting the prediction and produce rich visualizations to meticulously study the explanations. In a similar line of work, [22] used SVM and k-Nearest Neighbor models on vibration signals to achieve fault diagnosis of industrial bearings. They depict the most important features influencing fault prediction with SHAP. An XAI approach for process quality optimization is proposed by [23]. They train a gradient-boosting tree-based ensemble on transistor chip production data of Hitachi ABB and identify the most significant production parameters affecting the industry\u2019s yield using SHAP. A detailed study on how these parameters affect the production allowed for the prioritization of processes and the selection of improvement actions. Experimental validation of the method on a new production batch showed a remarkable improvement in yield losses, leading the company to adopt the method for further use. These indicative studies show the added value brought about by the SHAP method explaining complex models\u2019 predictions, allowing thus otherwise \u201cblack-box\u201d models to be transparent to stakeholders. Despite the active research and applications of XAI in various sectors, its appli-cation within the realm of metrology remains relatively unexplored. Specifically, there is a notable gap in the literature regarding work focusing on developing an explainable pipeline for predicting point-wise accuracy of laser scanning devices in the metrology domain. This chapter aims to bridge this gap. Our work contributes to the nascent field of \u201cExplainable Metrology 4.0\u201d by designing a robust, interpretable model that not only predicts the accuracy of laser scanning devices but also provides valuable insights into the features that drive these predictions. By incorporating XAI techniques, particularly the model-agnostic SHAP, into metrology, we aim to transform \u201cblack-box\u201d models into transparent tools that empower stakeholders to understand and trust the AI-driven measurement process. This novel approach is envisioned to bring about a significant positive shift in the field of industrial metrology.484 E. Lavasa et al.3 Methodology The proposed methodology is described step by step in this section, from data preparation and feature extraction to the established pipelines for model training, optimization, evaluation, and explanation. 3.1 Setting Up a Supervised Learning Task Our study aims to model the behavior of the scanning instrument, taking into account both the scanning configuration and surface orientation. Specifically, our objective is to predict point-wise measurement errors at individual points along the three axes (X, Y, and Z). This prediction is a function of the scanning conditions, surface orientation, laser orientation, and the viewing direction of the CMOS sensor. Therefore, we can formulate the problem as: . measurment error = f(scanning conditions, surface orientation,laser orientation, CMOS viewing direction)Having defined the problem to be solved, we seek to establish a supervised learning setting to address its solution. Supervised learning requires access to a certain ground truth that the models are trained to predict. This is achieved with the use of calibrated object measurements. Calibrated artifacts have properties known to be a very high level of precision (of the order of 1 \u03bcm = 10\u22126 m). Characteristic properties include dimension/position of features, while shape perfection is also certified. For these objects, we can safely consider that the actual properties, such as dimension, are identical to the nominal ones (provided by the manufacturer). Assuming that the center of the calibrated object is perfectly positioned at the center of the scanning instrument\u2019s reference frame, the problem can be formulated as a supervised regression task, where the ground truth is found in the location of points (in X, Y, Z coordinates) on the nominal surface of the calibrated object. 3.2 Data Sources Our database so far comprises measurements of three calibrated spheres (three diameters), under different scanning configurations. Scanning configurations are obtained by variation between three levels (low\u2013 medium\u2013high) of the following scanning conditions: \u2022 Lateral density: Point density in the lateral direction with respect to the move-ment axis of the rotary head.Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 485\u2022 Direction density: the velocity of the rotary head, inversely proportional to point density along the axial direction (axis of movement). \u2022 Exposure time: the duration of each laser pulse. As a result, we have an initial database comprising 108 raw point cloud files (3 objects \u00d7 33 scanning configurations). The number of points in each point cloud varies (min: 16 k, max:180 k) depending on the size of the object and scanning conditions. The total number of points adds up to ~6.5 M. 3.3 Data Pre-processing Preliminary processing of raw Point Clouds is performed with the Open3D open-source library [24]. Open3D offers a rich collection of data structures and geometry processing algorithms to support the analysis of 3D data. With the use of Open3D functions, two key processing steps are performed: \u2022 Statistical outlier removal: Points that are, on average, further away from their neighbors are described as outliers. Configurable parameters are the number of nearest neighbors and the standard deviation ratio to be considered in the calculations. \u2022 Estimation of surface normal: The normal vectors are estimated for points in the point cloud based on the number of nearest neighbors within a given radius (these are configurable parameters). Once normal vectors are calculated, a second function is applied to ensure that they are consistently aligned. The alignment of surface normals is verified via visual inspection. 3.4 Feature Extraction Based on the estimated normal vectors that stand for the surface orientation at each point, a set of informative features is extracted to describe the geometric setup between (a) surface orientation . \u2212\u2192N , (b) the laser source orientation . \u2212\u2192L , and (c) the CMOS sensor viewing direction . \u2212\u2192V . Geometric features include cosine similarities between vectors and vector differences. In addition, the vertical distance between each point and the laser source is calculated, as well as the four-quadrant angle between the laser and the surface orientation (Fig. 1). Overall, the input features to the ML algorithms are listed below: \u2022 Scanning conditions: lateral density, direction density, and exposure time \u2022 Components of surface normal:486 E. Lavasa et al.Fig. 1 The vectors contributing to the measurement geometric setup are surface orientation (N), laser orientation (L), and CMOS viewing direction (V). Each measured point P is projected along surface orientation to retrieve the closest point P\u2032 on the nominal surface .\u2212\u2192N = [Nx,Ny,Nz](1) \u2022 Components of the difference vector . \u2212\u2192ori: .\u2212\u2192ori = \u2212\u2192N \u2212 \u2212\u2192L = [oriX, oriY , oriZ] (2) \u2022 Components of the difference vector .\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192oriCMOS (we use only the Y-component, because X & Z components are equal to those of .\u2212\u2192ori above by design): .\u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192oriCMOS = \u2212\u2192N \u2212 \u2212\u2192V = [oriCMOSX, oriCMOSY, oriCMOSZ] (3) \u2022 Cosine similarity Inc between .(\u2212\u2192N ,\u2212\u2192L), that is, the cosine of the incidence angle of light on the surface: .Inc = cos\u239b\u239d\u2212\u2192N \u2022 \u2212\u2192L\u2225\u2225\u2225\u2212\u2192N\u2225\u2225\u2225\u2225\u2225\u2225\u2212\u2192L\u2225\u2225\u2225\u239e\u23a0 (4) \u2022 Cosine similarity ViewAng between .(\u2212\u2192N ,\u2212\u2192V), that is, the cosine of the viewing angle of the surface from the CMOS camera:Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 487.V iewAng = cos\u239b\u239d\u2212\u2192N \u2022 \u2212\u2192V\u2225\u2225\u2225\u2212\u2192N\u2225\u2225\u2225\u2225\u2225\u2225\u2212\u2192V\u2225\u2225\u2225\u239e\u23a0 (5) \u2022 The vertical distance Rs from each point to the laser source, which is always at Zlaser \u2248 90 mm: .Rs = 90 \u2212 Z (6) \u2022 The four-quadrant angle ang between laser orientation and surface orientation: .ang = arctan2d(\u2225\u2225\u2225\u2212\u2192N \u00d7 \u2212\u2192L\u2225\u2225\u2225 ,\u2212\u2192N \u2022 \u2212\u2192L)(7) The target variables, i.e., point capture errors in the x, y, z axes, are defined by projecting captured points on the nominal surface of the calibrated object. The projection is radial in the case of the sphere and axial for the cylinder (the cylinder\u2019s axis lies along the Y-axis of the instrument\u2019s reference frame). In practice, by projecting each measured point P(X, Y, Z), we find the closest point P\u2032(Xnom, Ynom, Znom) on the nominal surface of the calibrated object. For this \u201creference\u201d point we can assume that: \u2022 If it belongs to a sphere, its actual radial distance to the center of the sphere C(0, 0, 0) is equal to the nominal radius of the sphere Rnom. This can be compared to the radial distance R of the measured point P, where: .R =\u221aX2 + Y 2 + Z2 (8) \u2022 If it belongs to the cylinder, its axial distance (distance to the Y-axis) is equal to the nominal radius of the cylinder, Rnom. This can be compared to the axial distance R of the measured point P, where: .R =\u221aX2 + Z2 (9) This analysis is based on the underlying assumption that the center of the sphere is perfectly positioned at the center of the scanning instrument\u2019s reference frame and that the cylinder\u2019s axis is perfectly aligned to the Y-axis of the reference frame.488 E. Lavasa et al.The coordinates of the reference/projected point P\u2032 for the sphere are calculated as follows: .Xnom = XRnomR(10) .Ynom = Y RnomR(11) .Znom = ZRnomR(12) The same formulas as above also apply to Xnom and Znom for the cylinder, whereas Ynom = Y, since the projection is axial in this case. It follows that the target variables for our models, that is, point-wise measurement errors in three axes, can be computed as the difference between projected (nominal) and measured point coordinates: .Xerr = Xnom \u2212 X (13) .Yerr = Ynom \u2212 Y (14) .Zerr = Znom \u2212 Z (15) Obviously, Ydev is applicable to spherical geometry, while for the cylinder Ydev = 0. Equations 13, 14 and 15 imply that, in the positive X, Y, Z coordinate range, negative errors correspond to points captured outward to the surface, while points with positive errors are captured inward to the surface. The situation is reversed in the negative coordinate range. Models will be trained and optimized to predict capture errors in each axis, with the same input features, while the target variable will be the measurement error in the respective axis. 3.5 Model Training, Optimization, and Validation The original PointNet architecture [25] was proposed to deal with tasks pertaining to the segmentation and classification of point clouds. Taking n points as input (each point represented by its spatial coordinates), it initially feeds the input points in a Spatial Transformer Network (STN), with the aim of endowing the overall model with invariability with respect to affine transformations, specifically rotations andToward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 489translations. The learned features are then passed through a Max Pooling layer, producing a global feature vector. In classification-oriented tasks, this global feature vector is fed to a standard Multi-layer Perceptron (MLP) which outputs scores for each one of the classes under consideration; in segmentation-oriented tasks, an additional step takes place, whereby the global features produced by the Max Pooling layer are concatenated with the output of the last layer of the model, resulting in a feature vector comprising both local and global features. A final pass through a second MLP takes place, and the model outputs a label for each point, indicating the object it belongs to. In order to utilize PointNet for the prediction of deviations for each point, certain modifications must first take place: 1. Since the problem we are dealing with is neither classification nor segmentation, but regression, the output layer of PointNet must be modified accordingly to reflect the difference in objective. Therefore, the final layer of the model is replaced by a Linear Layer, and the evaluation metric which drives the updates of the model\u2019s parameters is changed to the MAE function. The model outputs the deviation of each point in a specific axis; therefore, three distinct models must be trained in order to obtain the overall deviation in 3D space. 2. The employment of the Spatial Transformer Network is redundant in our case, since spherical objects are by default invariant to rotations, and the objects in consideration are not subject to potential translations. Having to learn additional parameters for the STN submodule would only lead to overfitting of the overall model. Therefore, the first step of passing the inputs through an STN submodule is skipped (Fig. 2). Fig. 2 Modified PointNet Architecture. The network takes n points as input, passes the data through two series of MLPs, and extracts a global feature vector through a MaxPooling layer. The global feature vector is concatenated with the output of the first MLP sub-module and a final MLP is used to perform regression on point deviations490 E. Lavasa et al.In training the model, grid search and cross validation were performed for the final MLP submodule. Specifically, a range of different numbers of layers and the respective units comprising each layer were tested to identify the optimal combination. The Rectified Linear Unit (ReLU) activation function is used for all MLP layers, and the learning rate is set to adaptive in order to avoid training stagnation. 3.6 Comparative Analysis An extended search over competing solutions was carried out, with the employment of diverse ML algorithms to address the formulated regression tasks. These include Decision Tree (DT), Support Vector Machine (SVM), and Multi-layer Perceptron (MLP) regressors implemented by using the Scikit-Learn Python library [26], as well as the CatBoost regressor from the Catboost Python library [27]. MLP is a feed-forward Neural Network, while CatBoost is an ensemble model that combines multiple DT base learners. Next, we define the strategy that is applied to train, optimize, and validate the performance of the proposed and the competing ML algorithms, which comprised the steps listed below. 1. Train \u2013 test data partitions Our training and testing data partitions were built using a random selection of points from each of the available Point Clouds. Specifically, we selected 100 points per Point Cloud randomly and without replacement for the training dataset. To comprehensively test the model\u2019s performance, we generated five separate testing datasets, each containing 50 points per Point Cloud, also selected randomly and without replacement. The rationale behind this approach was to obtain a more unbiased assessment of model performance and gain an understanding of the variance in performance scores across different testing datasets. 2. Performance assessment In assessing the performance of our models for the given regression tasks, we used Mean Absolute Error (MAE) and R-Squared (R2) as our chosen metrics. Importantly, the model optimization process was primarily driven by the MAE score. Performance was separately assessed for each axis, thereby allowing us to individually tune and optimize performance per axis. 3. Model training & fine-tuning Each regression algorithm was provided with a broad hyper-parameter grid for model training and fine-tuning. This was followed by a Randomized Grid Search combined with fivefold cross-validation on the training data partitions. This process allowed us to identify the optimal model of each type based on the mean validation scores, primarily using the MAE score. This randomized grid search helped usToward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 491explore a wide range of possible parameters and their combinations to find the most effective ones. 4. Model deployment All models were then deployed on the testing datasets. Importantly, these datasets were unseen by the models during the training and optimization phases, safeguarding against overfitting and information leakage. The final performance scores were calculated as the mean scores plus or minus the standard deviation (mean \u00b1 std) derived from the 5 testing data partitions. This strategy gave us a robust and reliable measurement of the model\u2019s ability to generalize to new, unseen data. 3.7 Generation of Explanations Post-hoc explainability techniques refer to methods used to interpret the predictions or decisions of machine learning models after they have been trained. These techniques aim to provide insights and explanations for the decisions made by the model to users. Specifically, we used SHAP (SHapley Additive exPlanations) [20], a method specifically designed to measure the impact of input features on the predictions of a machine learning model. The SHAP method is rooted in cooperative game theory, providing a unified measure of feature importance that allocates the \u201ccontribution\u201d of each feature to the prediction for each instance in a principled, theoretically sound manner. SHAP values quantify the change in the expected model prediction when conditioning on that feature, reflecting the feature\u2019s contribution to the prediction. They can handle interactions between features and provide fairness attributes because they sum up to the difference between the prediction for the instance and the average prediction. For individual predictions or instances (local interpretability), SHAP values indicate how much each feature in the data set contributes, either positively or negatively, to the target variable. In essence, the SHAP method provides a more detailed view of how specific values of features, whether low or high, impact a prediction by nudging it above or below the average prediction value. This localized insight is aggregated to provide a global understanding of the model, i.e., which features are most important across all instances. Regarding the integration of XAI into our work, we primarily used the SHAP method to interpret our model\u2019s predictions and decisions. After the model was trained and optimized, we computed SHAP values for all features over the entire dataset. This gave us an overall picture of how each feature contributes to the model\u2019s decision-making process. In addition, we generated SHAP plots to visually illustrate the impact of individual features on the model\u2019s predictions, making it easy to understand the relationships between feature values and their effects on the model\u2019s output. This way, the SHAP method provided us with an interpretability tool that helped in understanding the model\u2019s complex decision-making process,492 E. Lavasa et al.promoting transparency and trust in the model\u2019s outcomes. This utilization of XAI ensured that our model was not just a black box producing predictions, but a comprehensible system where both its decisions and processes are understandable and explainable. 4 Results 4.1 Model Performance \u2013 Quantitative Analysis Tables 1, 2 and 3 showcase the performance of the proposed PointNet-based approach compared to the other machine learning models. PointNet outperformed all other models, achieving the best MAE across all three axes (X, Y, Z) and the highest R2 score on the Y axis. The second-best performance was demonstrated by the MLP model, which achieved the highest R2 scores on the X and Z axes. However, the remaining models performed poorly in comparison. These results can likely be attributed to PointNet\u2019s inherent design to manage point clouds, which renders it superior to other models that do not consider the adjacency of data points. Table 1 Model performance for X-axis errors Model MAE (mm) R2 Decision tree 0.0179 \u00b1 0.0002 0.54 \u00b1 0.02 SVM 0.0203 \u00b1 0.0002 0.52 \u00b1 0.02 MLP 0.0153 \u00b1 0.0004 0.64 \u00b1 0.02 CatBoost 0.0181 \u00b1 0.0001 0.56 \u00b1 0.02 PointNet+ 0.0084 (0.0003) 0.61 (0.013) Table 2 Model performance for Y-axis errors Model MAE (mm) R2 Decision tree 0.0191 \u00b1 0.0003 0.69 \u00b1 0.01 SVM 0.0263 \u00b1 0.0003 0.49 \u00b1 0.02 MLP 0.0216 \u00b1 0.0004 0.61 \u00b1 0.03 CatBoost 0.0178 \u00b1 0.0002 0.73 \u00b1 0.02 PointNet+ 0.0018 (0.0003) 0.76 (0.018) Table 3 Model performance for Z-axis errors Model MAE (mm) R2 Decision tree 0.0256 \u00b1 0.0005 0.37 \u00b1 0.02 SVM 0.0288 \u00b1 0.0004 0.26 \u00b1 0.01 MLP 0.0268 \u00b1 0.0005 0.57 \u00b1 0.03 CatBoost 0.0249 \u00b1 0.0004 0.40 \u00b1 0.01 PointNet+ 0.011 (0.0002) 0.41 (0.009)Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 493Fig. 3 Predicted versus actual deviation maps for the X-axis 4.2 Qualitative Analysis \u2013 Error Maps Figures 3, 4 and 5 illustrate the predicted deviations of the data points, presenting a distinct 3D deviation map for each axis. Both predicted and actual deviations are represented in each figure for all three axes. These figures effectively highlight the proficiency of the proposed model in predicting the measurement accuracy (deviation) of the scanning device, with the predicted deviations closely mirroring the actual ones. However, a noticeable discrepancy between the predicted and actual deviations is only discernible in the case of the Z axis, corroborating the findings from Tables 1, 2 and 3. Overall, the consistency between the predicted and actual deviations underscores the efficacy of the proposed model, demonstrating its potential to be a reliable tool for estimating the accuracy of scanning devices. Even in the case of the Z axis, where slight deviations occur, the model provides insightful data that could lead to further improvements and enhanced predictability in the next iterations. 4.3 Explanations Figures 6, 7 and 8 feature the SHAP summary plots of the trained PointNet model, presented individually for each of the three axes. Features appear on the y-axis, ordered by their global importance in the model\u2019s output. SHAP values are measured on the x-axis, so that each point in the summary plot corresponds to a SHAP value for a given sample and feature. The magnitude of feature values is color-coded from blue to magenta, corresponding to low and high values,494 E. Lavasa et al.Fig. 4 Predicted versus actual deviation maps for the Y-axis Fig. 5 Predicted versus actual deviation maps for the Z-axis respectively, so that the effect of different feature values on the model\u2019s output can be deduced by the summary plot. More specifically, the summary plot is indicative of how feature values (high/low) push individual predictions upward or downward with respect to the average prediction, which is specified by the vertical line at SHAP value zero. The most important features affecting the measurement errors of the predicted point on the X-axis are found to be the x-component of surface orientation (Nx) and the x-component of the vector difference between laser and surface orientationsToward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 495Fig. 6 SHAP summary plots of the trained PointNet model for the X-axis Fig. 7 SHAP summary plots of the trained PointNet model for the Y-axis (oriX). For both of these features, low values correspond to outputs lower than the average prediction (i.e., toward negative measurement errors), while outputs larger than average (i.e., toward positive errors) are induced by high feature values. Points with low Nx values are those facing the negative side of the X-axis, while large Nx corresponds to points facing the positive side. Taking into account the calculation formula (Eq. 13), it follows that points on both sides are captured inward to the surface, with the larger measurement errors corresponding to parts of the object496 E. Lavasa et al.Fig. 8 SHAP summary plots of the trained PointNet model for the Z-axis where the surface is oriented toward the x-axis (lateral direction), scattering light away from the CMOS sensor. Regarding predicted point measurement errors in the Y-axis, these are mostly affected by the Y-components of vector differences between surface and CMOS orientation (oriYcmos) and surface and laser orientation (oriY). Large values for these features correspond to points mostly facing the positive side of the Y-axis, while low values indicate points mostly facing the negative side of the axis. Considering the calculation formula for measurement errors (Eq. 14), these correspond to points being misplaced inward to the surface. The effect is most visible in areas of the surface facing toward (positive or negative) the Y-axis (scan direction), where most of the incident light is scattered away from the CMOS sensor due to large reflecting angles. Predicted measurement errors in the Z-axis are highly affected by the measure-ment distance (Rs) between each point and the rotary head of the scanner, where the laser source and CMOS camera are located. Considering the calculation formula (Eq. 15) and the fact that the objects under study lie in the positive Z-coordinate range, we find that points at large measurement distances are misplaced outward to the surface (negative errors), while points closer to the laser and CMOS (low measurement distance) tend to be captured inward to the surface (positive errors). Overall, we observe that the model\u2019s response in the prediction of errors along each axis is affected by relevant properties of the geometric setup that match optics intuition.Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 4975 Discussion 5.1 Discussion on Experimental Results This study presents an innovative approach using a PointNet-based model to handle point cloud data with a focus on predicting measurement accuracy in scanning devices. Unlike traditional machine learning models, the design of the proposed approach is inherently equipped to manage point clouds, accounting for the adjacency of data points, making it ideal for this specific task. Leveraging the unique capabilities of the PointNet-based model, our research aimed to develop a more precise and reliable tool for estimating the accuracy of point cloud scanning devices, an area of increasing importance in numerous fields such as robotics, geospatial sciences, and architecture. The results of our study demonstrate the superior performance of the PointNet-based approach compared to traditional machine learning models. Our quantitative analysis revealed that the PointNet-based model achieved the lowest MAE on all three axes (X, Y, Z) and attained the highest R2 score on the Y axis, reflecting its enhanced predictive accuracy. The qualitative analysis, in the form of 3D deviation maps, visually underscored the proficiency of the model in predicting deviations. These maps revealed a significant consistency between the predicted and actual deviations, validating the model\u2019s effectiveness. However, a slight discrepancy observed on the Z axis highlights an area for potential improvement. Despite this, even the deviation on the Z-axis offers valuable insights that can be used to refine future iterations of the model, ultimately improving its predictability and reliability. The SHAP summary plots, represented in Figs. 6, 7 and 8, play a crucial role in explaining how the PointNet-based model operates, highlighting that the model\u2019s predictions are largely guided by key geometric properties consistent with principles of optics. Specifically, measurement errors on the X-axis are influenced by the surface\u2019s orientation and its vector difference with the laser, while Y-axis errors are significantly impacted by the surface\u2019s vector differences with the CMOS and laser orientation. For the Z-axis, the model recognizes that errors are largely dependent on the measurement distance between the point and the scanner\u2019s rotary head. This ability of the proposed model to incorporate and leverage these geometric and optical principles when making predictions not only underscores its robustness but also provides a high degree of explainability that enhances its practical utility in the field of metrology. 5.2 Limitations of the Analysis This study presents some limitations, mainly regarding the data utilized. We opted to demonstrate the models\u2019 efficiency using spherical geometrical objects, which embody diverse conditions in terms of angles between the laser orientation, surface498 E. Lavasa et al.orientation, and CMOS viewing orientation. However, to assess the generalizability of the proposed approach, the analysis should be extended to include non-spherical geometrical objects. The key point here is that this experimentation requires calibrated objects, rendering the data collection process both costly and time-consuming. Looking ahead, we plan to expand our research to incorporate additional geometries, including both convex and concave structures, to further challenge and refine our model\u2019s capability. By considering diverse geometrical shapes, we aim to enhance the model\u2019s robustness and ensure its applicability across a wider array of scenarios. This extension, though demanding in terms of resources, would enable a more comprehensive understanding of the model\u2019s performance, contributing significantly to the development of more accurate and versatile scanning devices in the future. 5.3 Practical Implications and Future Perspectives The application of AI in metrology, particularly with the advent of XAI, holds the potential to dramatically enhance both the accuracy and efficiency of measurements, a revolution with profound implications for sectors such as aeronautics and automo-tive. The integration of ML algorithms can improve precision by identifying patterns and correcting errors within large datasets, consequently fostering automation and promoting real-time data analysis. This approach can result in advanced decision-making, where metrologists are empowered with data-driven insights and correlations, potentially reducing manual interventions significantly. XAI is poised to bring a new layer of transparency and interpretability to these intricate AI systems, providing users with a clearer understanding of the decision-making processes of these models, thus encouraging trust and validation in AI-driven measurements. The use of XAI can also allow for the identification of biases or errors within AI models, promoting a deeper understanding of the measurement process as a whole. This transparency will enhance the credibility, accountability, and reliability of AI in metrology, reinforcing confidence in its application. Looking forward, we envisage that AI will facilitate adaptive calibration and compensation by dynamically adjusting measurement systems to cater to environ-mental changes and complex geometries. XAI, in particular, is expected to provide significant advancements in the metrology sector by enabling professionals to gain deeper insights into the inner workings of AI models. This understanding will facilitate data-driven decision-making and allow for potential error sources to be identified and mitigated, promoting continuous improvement in the metrological process. Furthermore, XAI\u2019s role in knowledge transfer, specifically in assisting junior metrologists to understand and validate results, will be instrumental in achieving higher accuracy, repeatability, and reliability in measurements, ultimately leading to zero-defect manufacturing. Companies focused on metrology products and services, like Unimetrik and Trimek, could significantly benefit from XAI\u2019s ability to support decision-making during measurement plan definition, enablingToward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 499time-saving and error reduction, particularly for less experienced professionals. The adoption of XAI in metrology is thus poised not only to improve process efficiency but also to enhance understanding of the metrological process by providing profes-sionals insights into AI models and the impact of key configuration parameters on measurement accuracy. 6 Conclusions This chapter effectively demonstrated the superiority of a PointNet-based model in predicting 3D scanning device accuracy, significantly outperforming traditional machine learning models. The unique 3D deviation maps contributed greatly to the model\u2019s explainability, offering clear insight into its decision-making process and resultant errors. Despite a minor discrepancy noted on the Z axis, this study represents a promising advancement in metrology, demonstrating the potential of machine learning models to improve the accuracy, reliability, and explainability of measurements in industries that rely on 3D scanning technology. The consequent benefits have broad implications, spanning from precision manufacturing to pre-serving archaeological artifacts, bringing about a new era of improved accuracy and accountability in metrology. Acknowledgments This research was supported by the European Union\u2019s Horizon 2020 research and innovation program under grant agreement No 957362, project XMANAI (eXplainable MANufacturing Artificial Intelligence). References 1. Gao, W., Haitjema, H., Fang, F.Z., Leach, R.K., Cheung, C.F., Savio, E., Linares, J.M.: On-machine and in-process surface metrology for precision manufacturing. Ann. CIRP. 68, 843\u2013 866 (2019) 2. Catalucci, S., et al.: Optical metrology for digital manufacturing: a review. Int. J. Adv. Manuf. Technol. 120, 4271\u20134290 (2022). https://doi.org/10.1007/s00170-022-09084-5 3. Caggiano, A.: Cloud-based manufacturing process monitoring for smart diagnosis services. Int. J. Comput. Integr. Manuf. 31, 612\u2013623 (2018) 4. Leach, R.K., Bourell, D., Carmignato, S., Donmez, A., Senin, N., Dewulf, W.: Geometrical metrology for metal additive manufacturing. Ann. CIRP. 68, 677\u2013700 (2019) 5. French, P., Krijnen, G., Roozeboom, F.: Precision in harsh environments. Microsyst. Nanoeng. 2, 1\u201312 (2016) 6. Remani, A., Williams, R., Thompson, A., Dardis, J., Jones, N., Hooper, P., Leach, R.: Design of a multi-sensor measurement system for in-situ defect identification in metal additive man-ufacturing. In: Proceedings ASPE/Euspen Advancing Precision in Additive. Manufacturing (2021) 7. Joint Committee for Guides in Metrology: Evaluation of measurement data\u2014the role of measurement uncertainty in conformity assessment. JCGM. 106, 2012 (2012)500 E. Lavasa et al.8. Pathak, V.K., Singh, A.K.: Optimization of morphological process parameters in contactless laser scanning system using modified particle swarm algorithm. Measurement. 109, 27\u201335 (2017) 9. Vuka\u0161inovic\u0301, N., Bracun, D., Mozina, J., Duhovnik, J.: The influence of incident angle, object colour and distance on CNC laser scanning. Int. J. Adv. Manuf. Technol. 50, 265\u2013274 (2010). https://doi.org/10.1007/s00170-009-2493-x 10. Mueller, T., Poesch, A., Reithmeier, E.: Measurement uncertainty of microscopic laser triangulation on technical surfaces. Microsc. Microanal. 21, 1443\u20131454 (2015) 11. Isa, M.A., Lazoglu, I.: Design and analysis of a 3D laser scanner. Measurement. 111, 122\u2013133 (2017) 12. Li, S., Jia, X., Chen, M., Yang, Y.: Error analysis and correction for color in laser triangulation measurement. Optik. 168, 165\u2013173 (2018) 13. Mohammadikaji, M., Bergmann, S., Irgenfried, S., Beyerer, J., Dachsbacher, C., W\u00f6rn, H.: A framework for uncertainty propagation in 3D shape measurement using laser triangulation. In: Proceedings, IEEE International Instrumentation and Measurement Technology Conference, pp. 1\u20136 (2016) 14. Wissel, T., Wagner, B., St\u00fcber, P., Schweikard, A., Ernst, F.: Data-driven learning for calibrating galvanometric laser scanners. IEEE Sens. J. 15, 5709\u20135717 (2015) 15. Bos, A., Bos, M., van der Linden, W.E.: Artificial neural networks as a multivariate calibration tool: modeling the Fe\u2013Cr\u2013Ni system in x-ray fluorescence spectroscopy. Theor. Chim. Acta. 277, 289\u2013295 (1993) 16. Urbas, U., Vlah, D., Vuka\u0161inovic\u0301, N.: Machine learning method for predicting the influence of scanning parameters on random measurement error. Meas. Sci. Technol. 32(6), 065201 (2021). https://doi.org/10.1088/1361-6501/abd57a 17. Vallejo, M., de la Espriella, C., G\u00f3mez-Santamar\u00eda, J., Ram\u00edrez-Barrera, A.F., Delgado-Trejos, E.: Soft metrology based on machine learning: a review. Meas. Sci.Technol. 31, 032001 (2019) 18. Barredo Arrieta, A., D\u00edaz-Rodr\u00edguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado Gonz\u00e1lez, A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, V.R., Chatila, R., Herrera, F.: Explainable Artificial Intelligence (XAI): concepts, taxonomies, opportunities and challenges toward responsible AI. Inf. Fusion. 58 (2019). https://doi.org/10.1016/j.inffus.2019.12.012 19. Breiman, L.: Random forests. Mach. Learn. 45(1), 5\u201332 (2001) 20. Lundberg, S., Lee, S.-I.: A unified approach to interpreting model predictions. In: Advances in Neural Information Processing Systems, vol. 30. Curran Associates, Inc. (2017) 21. Hong, C.W., Lee, C., Lee, K., Ko, M.-S., Kim, D.E., Hur, K.: Remaining useful life prognosis for turbofan engine using explainable deep neural networks with dimensionality reduction. Sensors. 20(22), 6626 (2020) 22. Brusa, E., Cibrario, L., Delprete, C., Di Maggio, L.G.: Explainable AI for machine fault diagnosis: understanding features\u2019 contribution in machine learning models for industrial condition monitoring. Appl. Sci. 13(4), 2038 (2023) 23. Senoner, J., Netland, T., Feuerriegel, S.: Using explainable artificial intelligence to improve process quality: evidence from semiconductor manufacturing. Manag. Sci. 68(8), 5704\u20135723 (2021) 24. Zhou, Q.-Y., Park, J., Koltun, V.: Open3D: a modern library for 3D data processing. arXiv preprint arXiv, 1801.09847 (2018) 25. Qi, C.R., Hao, S., Mo, K., Guibas, L.J.: Pointnet: Deep learning on point sets for 3d classification and segmentation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 652\u2013660 (2017) 26. Pedregosa, F., et al.: Scikit-learn: machine learning in python. JMLR. 12, 2825\u20132830 (2011) 27. Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A.V., Gulin, A.: CatBoost: unbiased boosting with categorical features. In: Advances in Neural Information Processing Systems (2018)Toward Explainable Metrology 4.0: Utilizing Explainable AI to Predict. . . 501Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made. The images or other third party material in this chapter are included in the chapter\u2019s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter\u2019s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.Index A Active learning (AL), 5, 9\u201311, 18, 19, 381\u2013400 Agent, 28, 56, 98, 126, 148, 196, 218, 232, 252, 267, 282, 320, 364, 383 Agile manufacturing, 43, 44 AI Act, vii, 5, 23, 25, 363\u2013366, 368, 375, 377, 382, 388 AI Agents, 147\u2013175, 206, 277, 288, 364 AI-based software platforms, 418 AI in manufacturing, v\u2013viii, 87\u2013102, 288, 325, 364 AI kits, 99, 102, 108, 339, 341, 348 AI-marketplace, 28, 29, 39, 91 AI Model Repository, 30, 31, 35, 45 AI platform, vii, 89, 91, 102, 108\u2013117 Anomaly detection, 50, 95, 99, 244, 322, 339, 351\u2013358, 460, 461, 464, 473 Artificial intelligence (AI), 3, 27, 43, 55, 72, 87, 108, 125, 147, 187, 196, 235, 252, 266, 282, 321, 333, 351, 361, 382, 407, 423, 437, 459, 480 Asset Administration Shell (AAS), 148, 150, 152\u2013156, 171\u2013174, 217\u2013228, 232, 234, 236\u2013243, 245\u2013248, 251\u2013253, 256, 258\u2013261 Augmented Reality (AR), 91, 320, 325, 326, 330, 473\u2013474 Autoencoder, 351, 352, 355\u2013358 Automated machine learning (AutoML), 129, 132, 134\u2013137, 139, 333\u2013349 Autonomy, 235, 247, 286, 321, 363, 384 B Blockchain, 16, 21\u201324, 29, 30, 34, 36, 39 Business dynamic, 441, 455, 457 Business model (BM), 105\u2013118, 292\u2013294, 362 C Case study, 108\u2013117, 121\u2013140, 148, 170\u2013174, 183, 192, 288, 307, 315, 323, 351, 352, 355\u2013358, 374, 376, 416, 461, 463, 464 Conversational agents, 265\u2013278 Cyber-physical production systems (CPPS), v, 3, 13\u201316, 21, 232, 234\u2013236 Cyber-physical systems (CPS), 10, 56, 91, 97, 99, 115, 195, 196, 284, 362 D Data integration, 17, 79, 125 Decentralised Technical Intelligence (DTI), 281\u2013297 Decision-making, vi, 45, 55, 56, 64, 67, 79, 80, 94, 96, 99\u2013101, 126, 147, 148, 150, 152\u2013154, 158, 169, 174, 181, 184, 192, 197\u2013199, 201, 209, 232, 233, 235, 262, 268, 282, 283, 286\u2013288, 296, 323, 335, 340, 347, 349, 362, 363, 369, 384\u2013386, 388\u2013390, 392, 393, 399, 409, 418, 424\u2013427, 434, 439, 459, 460, 466, 480, 482, 491, 498, 499 Deep learning (DL), v, 8, 15, 17, 75, 77\u201379, 90, 128\u2013131, 149, 151, 168, 174, 182, 201, 270, 305, 307, 310\u2013315, 320\u2013322, 334, 343, 345, 346, 348, 349, 351, 390, 392, 393, 482 Demand forecasting, 288, 438, 440, 441, 443, 445, 446, 451, 457 \u00a9 The Editor(s) (if applicable) and The Author(s) 2024 J. Soldatos (ed.), Artificial Intelligence in Manufacturing, https://doi.org/10.1007/978-3-031-46452-2503504 Index Digital business models, 106, 294 Digital twin (DT), vii, viii, 3\u20135, 12, 19, 60, 100, 125, 147\u2013175, 181\u2013192, 196, 203, 204, 213, 220, 232, 237, 285, 288, 363, 365, 386, 395\u2013397 Distributed control, 296 Domain knowledge fusion, 43, 44 Dynamic knowledge graph embedding, 81\u201382 E Ergonomics, 304, 315, 410\u2013412, 415 Explainability, 7, 8, 22, 24, 334, 341, 347, 349, 366, 376, 386, 391, 400, 423, 425\u2013435, 437, 438, 440, 442\u2013448, 450, 451, 453\u2013457, 461\u2013466, 470, 473, 474, 480, 491, 497, 499 eXplainable AI (XAI), vii, viii, 4, 10, 16\u201318, 21, 23, 24, 45, 333\u2013349, 382, 388, 392\u2013395, 399, 400, 423\u2013435, 437\u2013457, 459\u2013476, 479\u2013499 F Flexible manufacturing system (FMS), 123, 124 Forecasting, 80, 288, 438\u2013441, 448, 451, 457 Framework, 6, 7, 30, 31, 34\u201337, 43, 51, 58, 97, 98, 110, 126, 147\u2013175, 181\u2013192, 196, 201\u2013204, 208, 209, 220, 221, 224, 237, 252, 262, 269, 273, 284, 289, 294, 297, 304, 312, 333\u2013349, 362, 364\u2013366, 373, 376, 377, 384, 392, 417, 418, 481 Fuzzy, 125, 126, 129, 137\u2013140, 354 G Graph models, 354, 430\u2013431, 434, 435 H Holon, 232, 235\u2013248, 260, 261 Holonic manufacturing systems (HMS), 235, 236, 239 Human activity, 303\u2013315 Human-AI collaboration, 43\u201352, 397, 407\u2013419 Human-AI interaction, 11, 43\u201353, 291, 409 Human-AI teaming, 408, 416\u2013418 Human-centered AI (HCAI), viii, 358 Human-centric Artificial Intelligence, 9, 361\u2013378 Human in the loop (HITL), vi, viii, 4, 23, 26, 45, 80, 99, 364, 384, 388, 400, 425 Human-machine collaboration, 382\u2013386, 388, 391\u2013395, 475, 476 Hybrid models, 306, 427\u2013430, 433, 434 Hyperparameter tuning, 334, 341\u2013346 I Industrial data reliability, 10, 14, 21 Industrial Internet of Things (IIoT) platform, vi, 101 Industrial quality control, 389, 479 Industry 4.0, v\u2013viii, 3\u20135, 25, 29, 35, 79, 91, 125, 127, 148, 149, 153, 174, 195, 219, 220, 223, 246, 303, 306, 361\u2013363, 377, 381, 413, 480 Industry 5.0, vi\u2013viii, 3\u201325, 27\u201339, 55, 56, 80, 303, 304, 307, 361\u2013378, 381\u2013383, 385, 399, 407\u2013419 Internet-of-Thing (IoT), 3, 6, 7, 15, 20, 56, 89\u201391, 95\u2013100, 147, 181, 185, 188, 192, 195, 289, 293, 305, 341, 352, 361, 374, 439 Interoperability, vi, 6, 34, 61, 64, 94, 95, 100\u2013102, 150, 153, 183, 185, 218\u2013220, 223, 224, 226, 228, 232, 237, 241, 246, 247, 286, 336, 346 K Knowledge graph (KG), vi, viii, 11, 55\u201367, 71\u201383, 268, 409, 430 Knowledge graph embedding, 71\u201383 L Labor market, 265, 266, 268, 272\u2013274, 278 Logic, 6, 28\u201330, 99, 156, 197, 220, 227, 232, 238, 245, 252, 257, 289, 341, 459 M Machine learning (ML), 5, 27, 43, 65, 72, 90, 125, 147, 181, 203, 257, 285, 306, 321, 334, 351, 382, 409, 424, 463, 481 Manufacturing, 3, 28, 43, 55, 71, 87, 109, 147, 181, 195, 218, 231, 251, 266, 281, 303, 323, 333, 351, 361, 381, 407, 423, 438, 460, 479, 481 Manufacturing Industry, 5, 55\u201367, 181, 188, 190, 192, 214, 251, 252, 334, 430, 463, 467Index 505 Manufacturing Plant Control, 395, 400, 461 Methodology, 44, 48, 57, 72, 76, 100, 106\u2013108, 118, 133\u2013137, 157, 165, 169, 183, 218, 219, 222\u2013224, 226\u2013228, 290, 291, 319, 327, 353, 377, 445, 446, 455, 480, 484\u2013492 Model, 3, 27, 43, 57, 71, 88, 105, 126, 147, 181, 197, 217, 231, 251, 269, 287, 305, 320, 333, 352, 362, 382, 409, 424, 437, 459, 480 Model deployment, 348, 491 Multi-Agent System (MAS), vi, vii, viii, 148, 150, 152\u2013173, 232\u2013239, 242, 246\u2013248 Multisided platforms, 105\u2013119 N Natural Language Processing (NLP), 12, 19, 45, 198, 322, 409 Networked production, 281\u2013297 Non-Fungible Token (NFTs), 30, 34\u201337 O Object detection (OD), 319\u2013330 Occupational Database, 274 Optical metrology, 481\u2013482 P Platform as a service (PaaS), 89 Plat-form design toolkit (PDT), 106\u2013118 Predictive analytics, 440 Pre-processing, 341\u2013344, 347 Production Process optimisation, 65, 125, 132 R Real-time monitoring, 147, 150, 290, 325 Recognition, xv, 29, 198, 201, 272, 283, 303\u2013316 Reconfigurable manufacturing system (RMS), 123\u2013124 Reference architecture (RA), v, vii, 3\u201325, 66, 97, 98, 235, 408 Reinforcement learning (RL), v, 10, 12, 14, 17, 18, 125\u2013127, 149, 151, 152, 182, 187, 195\u2013214, 245, 269 Repository, 28, 30\u201335, 37, 43, 45, 46, 48\u201350, 102, 188, 192, 209, 224\u2013228, 241, 252, 255, 260, 368, 374, 376 Representation learning, 72\u201379, 201 Resource, 10, 27, 56, 88, 108, 123, 147, 181, 196, 219, 231, 251, 267, 281, 321, 340, 363, 384, 424, 455, 498 Roadmap, 283, 289\u2013292, 297, 363 S Security, 4, 29, 94, 150, 182, 196, 266, 282, 305, 335, 361, 387, 417, 433, 442, 469 Self-reconfigurable manufacturing system, 123, 125\u2013127, 138 Semantic modeling, 11 SHapley Additive exPlanations (SHAP), 347, 445, 464, 465, 473, 483, 488, 491, 493\u2013497 Shared production, 123, 231\u2013248 Smart factory, 125, 305, 310 Smart manufacturing, 29, 38, 304, 306, 407, 408, 410, 416, 417 Standardization, xv, 150, 153, 184\u2013186, 217\u2013220, 227, 228, 232, 237, 341, 342, 345, 348, 387 Synthetic data, 192, 209, 321, 323, 327, 329, 330, 394 T Trustworthy Artificial Intelligence (TAI), 24, 361\u2013371, 373, 374, 376, 377, 388 U User-centric Services, 30 W Wearable sensors, 97, 303\u2013316, 322 Worker Safety, 9, 12, 303\u2013316, 319, 324, 325",
      "id": 170171113,
      "identifiers": [
        {
          "identifier": "637933269",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:library.oapen.org:20.500.12657/87623",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.1007/978-3-031-46452-2",
          "type": "DOI"
        }
      ],
      "title": "Artificial Intelligence in Manufacturing",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:library.oapen.org:20.500.12657/87623"
      ],
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://library.oapen.org/bitstream/20.500.12657/87623/1/978-3-031-46452-2.pdf"
      ],
      "updatedDate": "2025-02-04T22:30:43",
      "yearPublished": null,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/637933269.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/637933269"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/637933269/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/637933269/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/170171113"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": null,
      "authors": [
        {
          "name": "Menghi, Claudio"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Cardoso, Rafael C.",
        "Menghi, Claudio",
        "Ahlbrecht, Tobias",
        "Ferrando, Angelo",
        "Briola, Daniela"
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/630963064"
      ],
      "createdDate": "2024-12-28T18:45:56",
      "dataProviders": [
        {
          "id": 510,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/510",
          "logo": "https://api.core.ac.uk/data-providers/510/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "Multi-agent systems, robotics and software engineering are large and active research areas with many applications in academia and industry. The First Workshop on Agents and Robots for reliable Engineered Autonomy (AREA), organised the first time in 2020, aims at encouraging cross-disciplinary collaborations and exchange of ideas among researchers working in these research areas. This paper presents a perspective of the organisers that aims at highlighting the latest research trends, future directions, challenges, and open problems. It also includes feedback from the discussions held during the AREA workshop. The goal of this perspective is to provide a high-level view of current research trends for researchers that aim at working in the intersection of these research areas",
      "documentType": "research article",
      "doi": "10.3390/jsan10020033",
      "downloadUrl": "https://core.ac.uk/download/630963064.pdf",
      "fieldOfStudy": null,
      "fullText": "Journal of Actuator NetworksSensor andPerspectiveAgents and Robots for Reliable Engineered Autonomy:A Perspective from the Organisers of AREA 2020Rafael C. Cardoso 1,* , Angelo Ferrando 2,* , Daniela Briola 3,* , Claudio Menghi 4,* and Tobias Ahlbrecht 5,*\u0001\u0002\u0003\u0001\u0004\u0005\u0006\u0007\b\u0001\u0001\u0002\u0003\u0004\u0005\u0006\u0007Citation: Cardoso, R.C.; Ferrando,A.; Briola, D.; Menghi, C.; Ahlbrecht,T. Agents and Robots for ReliableEngineered Autonomy: A Perspectivefrom the Organisers of AREA 2020. J.Sens. Actuator Netw. 2021, 10, 33.https://doi.org/10.3390/jsan10020033Academic Editor: Thomas NeweReceived: 15 March 2021Accepted: 13 May 2021Published: 14 May 2021Publisher\u2019s Note: MDPI stays neutralwith regard to jurisdictional claims inpublished maps and institutional affil-iations.Copyright: \u00a9 2021 by the authors.Licensee MDPI, Basel, Switzerland.This article is an open access articledistributed under the terms andconditions of the Creative CommonsAttribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/).1 Department of Computer Science, The University of Manchester, Manchester M13 9PL, UK2 Department of Computer Science, Bioengineering, Robotics and Systems Engineering (DIBRIS),University of Genova, 16145 Genova, Italy3 Department of Informatics, Systems and Communication (DISCO), University of Milano Bicocca,20126 Milan, Italy4 Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg,L-4365 Luxembourg, Luxembourg5 Department of Informatics, Clausthal University of Technology, 38678 Clausthal-Zellerfeld, Germany* Correspondence: rafael.cardoso@manchester.ac.uk (R.C.C.); angelo.ferrando@dibris.unige.it (A.F.);daniela.briola@unimib.it (D.B.); claudio.menghi@uni.lu (C.M.); tobias.ahlbrecht@tu-clausthal.de (T.A.)Abstract: Multi-agent systems, robotics and software engineering are large and active research areaswith many applications in academia and industry. The First Workshop on Agents and Robots forreliable Engineered Autonomy (AREA), organised the first time in 2020, aims at encouraging cross-disciplinary collaborations and exchange of ideas among researchers working in these research areas.This paper presents a perspective of the organisers that aims at highlighting the latest research trends,future directions, challenges, and open problems. It also includes feedback from the discussions heldduring the AREA workshop. The goal of this perspective is to provide a high-level view of currentresearch trends for researchers that aim at working in the intersection of these research areas.Keywords: multi-agent systems; robotics; software engineering; verification and validation; human\u2013agent interaction1. IntroductionThe robotics market is dramatically changing. Robots are more and more used toreplace humans in their activities. For example, robots can be used in emergency searchand rescue scenarios to reduce risks for humans rescuers. To operate in unpredictableenvironments, robots often need to be autonomous. Autonomous robots can performtheir tasks with a high degree of autonomy without any human supervision. In addition,robots need to operate in a reliable manner to avoid failures that can have catastrophicconsequences and lead to the loss of human life. The design of such robotic applications iscomplex since it requires engineers to consider different requirements related to differentresearch domains.The design of robotic applications requires multi-agent solutions. Robots are no longeronly used in industrial applications, where robots operate in highly controllable andpredictable environments. They are also used in an increasing number of domains, wherethe environment is often unpredictable and agents can have unexpected behaviours. Forexample, in an emergency search and rescue scenario the environment in which the robotsoperate is unpredictable: the structure of the buildings where robots are deployed maynot be known in advance, and humans can have unpredictable reactions in emergencies.Robots in these applications often benefit from (or require) some level (semi or full) ofautonomy. In addition, the missions the robots need to achieve are more and more complexand require multiple robots, with different capabilities, to collaborate. Thus, multi-agentsolutions are required.J. Sens. Actuator Netw. 2021, 10, 33. https://doi.org/10.3390/jsan10020033 https://www.mdpi.com/journal/jsanJ. Sens. Actuator Netw. 2021, 10, 33 2 of 24Verification and Validation (V&V) aims at checking whether software behaves as ex-pected. The distributed and autonomous nature of multi-agent systems poses a novel set ofchallenges for V&V. For example, the autonomous behaviour responsible for decision-making should (ideally) be extensively verified since these systems are expensive toproduce and are often deployed in safety-critical situations. However, the autonomousbehaviour of these systems is often unpredictable: it depends on the environmental con-ditions in which the system operates, and often changes at runtime. Thus, autonomousrobotic systems are introducing a novel set of challenges that need to be addressed bynovel V&V techniques.Software Engineering (SE) refers to a branch of computer since that aims at supportingrigorous software development. Engineering multi-agent systems requires systematic andrigorous techniques that allow developing systems that meet their requirements. Multi-agent systems are instances of complex distributed systems. They require engineers todefine the software architecture, to design the agent behaviours (e.g., through models),the protocols (if any) that agents should use to communicate, and how and when agentsneed to collaborate. Selecting and defining all of these components is often a difficult andcomplex activity, since it requires cross-disciplinary skills, and knowledge of multi-agentsolutions, and the verification and validation to be used to support software design.Finally, since multi-agent systems usually need to interact with people, engineersneed to consider human\u2013agent interactions as a key feature during the software design.Human\u2013robot interactions are complex to be designed. Humans can (negatively) affect thebehaviour of the robots, especially when humans and robots are collaborating for achievingcertain goals. Human behaviour can trigger unexpected software reactions. Softwarecomponents must be designed to adapt and modify their behaviours and to effectivelysupport unexpected human actions.Therefore, the design of complex robotic applications requires combining solutionscoming from different research areas: multi-agent systems, verification and validation,software engineering, and human\u2013agent interaction. This paper presents a perspectivefrom the organisers of the first workshop on Agents and Robots for reliable EngineeredAutonomy (https://area2020.github.io/ accessed: 14 May 2021) (AREA 2020). The goal ofthis workshop was to attract researchers from these areas, to support the exchange of ideas,and the cross-fertilisation and collaboration among the different research communities.This perspective presents some of the latest research trends and promising solutions ineach of these areas. It is based on the research experience of the authors, and some of thediscussions held during the AREA workshop. As such, it does not aim to be a complete anddetailed review of the work done in these research areas, but it aims to be an initial readfor researchers that aim at working in the intersection of these areas based on a speculativeview of the organisers of AREA 2020.This perspective paper is organised as follows. Section 2 concerns multi-agent program-ming. It discusses the use of programming languages designed for multi-agent systemsfor developing decision-making in robots, listing some of the tools for agents and robotsindividually and how these have been combined by the community. Section 3 concernsverification and validation. It presents works performed in the verification and validationwith a special interest on multi-agent systems and robotic applications. Section 4 concernssoftware engineering. It describes research work in SE with a special interest in multi-agentsystems. Section 5 concerns human\u2013agent interactions. It describes research works thatconcern the development of robotic applications that consider human\u2013agent interactionsin the software design. Finally, Section 6 concludes our perspective. It summarises anddiscusses the challenges identified for each of the research areas we considered, and linksthe findings of the different sections.J. Sens. Actuator Netw. 2021, 10, 33 3 of 242. Multi-Agent ProgrammingIn this section, we will present some techniques that support the use of agent program-ming for the development of robotic applications. We will then present some challengesthat prevent the effective use of agent programming for developing robotic systems.One of the most popular models for agent programming languages is the Belief\u2013Desire\u2013Intention (BDI) model [1,2]. In the BDI model, there are three major concerns to modelthe agent behaviours: beliefs\u2014knowledge that the agent has about the world, itself, andother agents; desires\u2014goals that the agent wants to achieve; and intentions\u2014recipes on howto achieve goals. Some examples of BDI agent programming languages include Jason [3](used in many of the applications we cite in our perspective paper), JaCaMo [4,5] (Jasoncombined with two other technologies to provide first-class support for programmingagents, environments, and organisations), and GWENDOLEN [6] (a more bare-bones agentlanguage made specifically to support formal verification of agent programs).The Robot Operating System (ROS) [7] is the de facto standard for the development ofsoftware for robotic applications. ROS supports the development of robotic applicationsthrough ROS nodes. An ROS node is a process that performs some computation. AnROS application is made by several nodes (representing components and subsystems ofthe robot) that communicate with one another following the publisher/subscriber model.The main advantage of ROS is its interoperability with different robot manufacturers andmodels. Since robot manufacturers provide support for executing the ROS, developers donot have to learn the firmware of each robot model.An approach combining JaCaMo (in particular, the agent and environment layers)with ROS is presented in [8]. Their approach uses environment artifacts to implementROS nodes and to provide actions for agents to publish and subscribe to nodes. Sinceenvironment artifacts in JaCaMo are implemented in Java, the approach makes use of therosjava package (http://wiki.ros.org/rosjava accessed: 14 May 2021) (an implementation ofsome of ROS core features in Java) to make the artifacts able to interact with ROS. However,rosjava is not directly maintained by the ROS community. Therefore, it requires additionaltime to be supported after each new ROS release.A Jason based integration with ROS is introduced in [9]. Their approach modifiesJason\u2019s reasoning cycle to support agents with the ability to subscribe and publish in topicsfrom ROS nodes. Extra code for ROS (written in C++) is required for the integration as well.In [10,11], Jason is linked with ROS through their SAVI ROS BDI architecture. Thisarchitecture is implemented in Java (using the rosjava package, and as such has the samedisadvantage present in [8]) and mainly introduces a state synchronisation module that actsas a mediator between ROS and Jason by managing perceptions, incoming and outgoingmessages, and actions being sent by the agent.Differently from all of the above approaches, the authors in [12] propose an interfacefor programming autonomous agents in ROS that works without any changes to ROSor to any of the supported agent languages (Jason and GWENDOLEN). This is achievedthrough the rosbridge library [13], which allows code written in other languages (ROS hasnative support for C++ and Python only) to communicate with ROS topics through theWebSocket protocol.Perspective of the AuthorsAs noted in recent agent programming reviews and surveys [14\u201316], there are stillmany open challenges that prevent agent programming languages to be used in the roboticdomain. Some of these challenges include:\u2022 the limited set of features provided by existing agent-based languages;\u2022 immature methodologies and tools;\u2022 no significant advantages for developers to change to agent programming since mostapplications can be implemented in more contemporary programming languages;J. Sens. Actuator Netw. 2021, 10, 33 4 of 24\u2022 the lack of quantitative and qualitative comparisons with other agent languages andother programming paradigms that guide developer in the selection of the mostsuitable language for their needs;\u2022 the limited integration of agent-based technologies with other techniques, e.g., tech-niques coming from Artificial Intelligence (AI).Additionally, there are other challenges that are more specifically related to the use ofagent programming languages in robotic systems development.One of these challenges is the limited support for high frequency data that comingfrom sensors, which are commonly used to represent \u201cbeliefs.\u201d When high-frequency datarepresenting beliefs come from sensors, then the agent has to spend a large amount oftime reasoning on these new perceptions. This reduces the performance of the robots incomputing the new actions to be executed. A common solution to this problem is to usefilters that limit the amount of data that is perceived, either by decreasing the frequency orlimiting data based on its content and what would be interesting to the agent. However,these filters are often domain-specific and have to be tweaked based on the application.Another challenge is the compatibility of agent languages with popular robotic frame-works such as ROS. An increasing number of languages are being extended by the commu-nity to work with ROS; however, these often modify either ROS or the agent language (orsometimes both) which can discourage new developers from using them.An earlier survey [17] on agent languages for programming autonomous robots hasidentified four major challenges:1. support for agent languages in robotic frameworks;2. effectively managing sensor data into beliefs;3. support for real-time reactivity;4. synchronising robots while executing their plans.As previously discussed, a significant amount of research has been conducted foraddressing challenges 1 and 2. However, more work is needed to support additional agent-based languages, and more sophisticated and effective filtering techniques to managesensor data. Less research has been conducted to address challenges 3 and 4, since thesechallenges do not always appear in robotic applications. For example, in a scenarioin which a robot has to inspect a nuclear facility, the robot should be able to handleand adapt to failures. We believe that research on real-time reactivity of robots and theeffective synchronisation of robots for executing their plans, on the one hand, will benefitfrom the additional support provided for existing agent-based languages and the moresophisticated and effective management, on the other hand, may highlight limitations ofthese frameworks and pave the way for further additional research.3. Verification and ValidationAs discussed in our introduction, reliability is very important in the design of roboticapplications. However, multi-agent applications are posing a new set of challenges for theverification and validation (V&V) activities. In this section, we are considering both staticverification techniques for MAS and dynamic verification techniques. Static formal verifi-cation techniques, such as Model Checking and Theorem Proving, usually check whetherthe system meets its requirements. Requirements are usually represented using formalspecifications, a.k.a. properties, the system is usually represented using models. Dynamicformal verification techniques, such as Runtime Verification techniques, usually monitor thesystem execution and check whether observed behaviours meet the system requirements.In this section, we describe the latest developments in the context of formal verificationand validation of MAS (Section 3.1) and robotic systems (Section 3.2). Some of the works wepresent in this section were also discussed by a recent survey on formal verification appliedto autonomous systems and robotic applications [18]. Then, we will argue (Section 3.3)that, as also argued by [19], robotic applications and autonomous systems pose a new setof challenges for formal verification and validation techniques.J. Sens. Actuator Netw. 2021, 10, 33 5 of 243.1. Multi-Agent SystemsFor MAS, V&V techniques usually check the behaviour of a set of agents collaboratingor competing amongst themselves to achieve certain goals.3.1.1. Model CheckingModel-checking exhaustively verifies a system against a formal property. It returnsa Boolean verdict: true if the property is satisfied, and false and a counterexample, if it isnot. Model-checking techniques are usually compute-intensive since the implementedprocedures have a high temporal complexity because all the behaviours of the system needto be analysed for proving that the property is satisfied.In [20], a model checker for verifying MAS, called MCMAS, is proposed. MCMASsupports temporal, epistemic and strategic properties. In its standard version, MCMASrequires to know the number of agents at design time. In [21], a parametric extension(MCMAS-P) to handle scenarios where the number of components cannot be determinedat design time is presented, while, in [22], a more expressive extension (MCMAS-SL) isproposed to support strategy logic. MCMAS has been used in many different works forverifying MAS. In particular, in [23], where an analysis is carried out on the verificationproblem of synchronous perfect recall multi-agent systems with imperfect information.While the general problem is known to be undecidable, [23] shows that, if the agents\u2019actions are public, then verification is decidable.In [24], the authors propose a method for, and implement a working prototype of, anethical extension to a rational agent governing an unmanned aircraft. Differently from [20],this work is focused on verifying BDI agents, defined using the agent language Ethan, anextension of GWENDOLEN. The resulting ethical agent is verified in AJPF [25], a modelchecker for agent programs. Differently from MCMAS, which verifies an abstract modelof the MAS (i.e., a Concurrent Game Structure\u2014CGS), AJPF verifies the source code ofthe MAS application. Furthermore, MCMAS assumes that properties are expressed usingAlternating-Time Temporal Logic (ATL), which allows for reasoning on agents\u2019 strategies,while AJPF assumes that properties are expressed in Linear Temporal Logic (LTL) (enrichedwith epistemic logic operators).In [26], the authors proposed the VERMILLION framework. VERMILLION targetsa broad class of avionics systems that is amenable to analysis using formal methods. Itextends the BDI model to incorporate learning, safety, determinism, and real-time response,and represents the abstract formal model using the Z language [27]. Compared to MCMAS,VERMILLION performs formal verification on an abstract model of the system, and notto the source code of the MAS. This requires engineers to build the abstract model of theMAS before running the verification framework.Autonomous platoons are a typical example of MAS which are subject to extensiveresearch. Formal verification of autonomous platoons has been considered for examplein [28]. In this work, the authors proposed a reconfigurable multi-agent architecture to en-sure the safety of the platoon, and specifically to guarantee a certain inter-vehicle distanceamong the different vehicles of the platoon. The authors proposed a model for the platoonthat enables vehicles to join and leave the platoon, and verified whether this model ensuresthe satisfaction of a set of safety properties. Safety properties are formally verified using theUppaal model checker [29]. Additionally, this work proposes to use the Webots simulator(https://github.com/cyberbotics/webots accessed: 14 May 2021) to simulate certain be-haviors of the model.Similarly, in [30], the authors applied formal verification to the model of the systemand the actual implementation to ensure that autonomous decision-making agents invehicle platoons never violate some safety requirements. In addition, in this work, themodel checking procedure relies on the Uppaal model checker: the models of the agentsare translated into timed automata, which are verified in Uppaal.In [31], the authors present a new technique for model checking the logic of knowledgeand commitments (CTLKC+). The proposed technique is fully-automatic and reduction-J. Sens. Actuator Netw. 2021, 10, 33 6 of 24based. It reduces the problem of model checking CTLKC+ specifications to the problem ofmodel checking an ARCTL [32] specifications. ARCTL is an existing logic that is supportedby an existing model checker that relies on the NuSMV symbolic model checker [33].3.1.2. Runtime VerificationThere are various runtime verification techniques available in literature for MAS.In [34], the authors present a framework to verify agent interaction protocols at runtime.The formalism used in this work allows using variables to represent complex MAS be-haviours. In [35], the authors extended their approach by supporting the usage of multiplemonitors. Specifically, the global specification, which is used to represent the global proto-col, is translated into partial decentralised specifications\u2014one for each agent of the MAS.In [36,37], other works on runtime verification of agent interactions are proposed for theJADE platform. Specifically, in [36], the authors propose a framework called Multi-agentRuntime Verification (MARV). In this framework, requirements of MAS interaction duringruntime are defined, such as availability and trustability. Differently from the other works,the requirements are expressed using natural language. The translation to a more formalrepresentation is seen as a future work and not supported yet. Considering interactions inJADE, in [37], we may find a different approach which is partially obtained at runtime. Infact, the proposed method is performed in a semi-runtime way, where logs of messagingevents are kept, and an algorithm for converting these logs to Time Petri Net as runtimeprogram models is used.When agents are dynamically adaptable, we may find application of runtime verifica-tion as presented in [38], where a runtime verification framework for dynamic adaptiveMAS (DAMS-RV) based on an adaptive feedback loop is presented.In [39], the authors propose a framework that combines model checking and runtimeverification for analysing MAS. In this framework, the agents are first verified statically(using the AJPF [25] model checking), and, then, they are validated at runtime, throughruntime verification using an extension of the work proposed in [34].3.2. Robotic ApplicationsThis section analyses works related to the formal V&V of robotic systems.3.2.1. Model CheckingIn [40], the authors propose an approach to formally verify an autonomous decision-making planner/scheduler system for an assisted living environment with the Care-O-botrobotic assistant. This is done by converting the robot house planner/scheduler rules intoa multi-agent modelling language, i.e., Brahms model [41], and then, by translating thismodel into the PROMELA [42] language, which is then verified using the SPIN modelchecker [43]. Differently from the works we presented in the previous section, in this work,the model to be verified concerns scheduling rules used by an actual robot, rather than thereasoning process of an abstract agent.In [44], the authors verified a formal model that describes mobile robot protocolsoperating in a discrete space is proposed. This formal model is then verified using theDiVinE model checker [45]. In [46], the authors propose an approach to verify real-timeproperties of ROS systems related to the communication between ROS nodes. Specifically,the authors analysed the source code of the Kobuki robot. Verification is performed byusing the Uppaal model checker.In [47], the authors analysed a collision avoidance protocol for multi-robot systemsbased on control barrier functions. The authors formally verified the properties of thecollision avoidance framework. They showed that their controller formally guaranteescollision free behaviour in heterogeneous multi-agent systems by applying slight changesto the desired controller via safety barrier constraints.Finally, formal methods are also used to check whether the tasks of a robotic applica-tion can be scheduled with respect to a given hardware platform (e.g., [48,49]). For example,some of these works considered components specified in GenoM [50] (a middleware forJ. Sens. Actuator Netw. 2021, 10, 33 7 of 24robotic development similar to ROS) and automatically translate them into FIACRE [51], aformal language for timed systems.3.2.2. Human\u2013Robot InteractionBuilding reliable software systems involving human\u2013robot interactions poses sig-nificant challenges for formal verification. In [52], the authors propose a risk analysismethodology for collaborative robotic applications, which relies on well-known standards,and use formal verification techniques to automate the traditional risk analysis methods.In [53], the authors propose an innovative methodology, called SAFER-HRC, is presented.This methodology is centred around the logic language TRIO and the companion boundedsatisfiability checker Zot [54], to assess the safety risks in a Human\u2013Robot Collaboration(HRC) application.3.2.3. Runtime VerificationRuntime Verification approaches for robotic applications are also discussed in thescientific literature. RobotRV [55] is a data-centred real-time verification approach forrobotic systems. Within this approach, a domain-specific language named RoboticSpec isdesigned to specify the complex application scenario of the robot system.Another runtime verification framework, called ROSMonitoring [56,57], allows theverification of ROS-based systems. In ROSMonitoring, runtime monitors are automaticallysynthesised from high-level specifications and used to verify formal properties againstmessage passing amongst ROS nodes. The advantage of this framework is its beingformalism-agnostic and portable. Indeed, the formal part of the monitors is decoupled andcan be easily replaced.3.2.4. Machine LearningMachine learning is widely relevant for designing robotic applications. In [58], theauthors consider the problem of formally verifying the safety of an autonomous robotequipped with a neural network controller that processes LiDAR images to produce controlactions. The contributions are: (i) the definition of a framework for formally provingsafety properties of autonomous robots equipped with LiDAR scanners; (ii) the notionof imaging-adapted partitions along with a polynomial-time algorithm for processingthe workspace into such partitions; and (iii) a Satisfiability Modulo Convex (SMC)-basedalgorithm combined with an SMC-based pre-processing for computing finite abstractionsof neural network controlled autonomous systems.3.3. Perspective of the AuthorsA lot of research was done on formal verification of MAS and Robotic applications.However, many challenges still need to be addressed. In the following, we will discusstwo of these challenges.\u2022 scalability. Many approaches suffer from scalability issues [59]. Researchers shouldfind more efficient ways to verify the system under analysis especially when thenumber of agents and robots increases. Indeed, MAS and robotic applications areintrinsically distributed, and we expect the number of robots and agents of futurerobotic applications to increase over time. As previously mentioned, scalability issuesare less relevant for dynamic verification approaches, such as runtime verificationthat only verify subsets of system executions. We believe that combining static anddynamic verification may be a valuable direction to address this challenge;\u2022 verification of ML components. ML components are mode and more used in safety-critical scenarios (e.g., Robotic applications). However, the behaviours of machinelearning components are usually not understandable by humans. Indeed, the be-haviour of ML components is not defined a priori by humans, but ML componentslearn their behaviours from a set of training data. This poses the challenge of under-standing if a ML component ensures the satisfaction of safety properties. While inJ. Sens. Actuator Netw. 2021, 10, 33 8 of 24the past years many works have been proposed to enhance learning algorithms withformal methods, a lot of work needs to be done to make these approaches applicablein practice. For example, for MAS applications, some works have been proposedfor single Reinforcement Learning agents, but few of them considered Multi-AgentReinforcement Learning.4. Software EngineeringThis section provides a brief overview on some of the software engineering (SE) tech-niques that aim to support the development of reliable multi-agent and robotic applications.Researchers are extending, adapting, and creating new SE techniques to meet the needs ofrobotic applications. However, there are still many challenges that prevent the effectiveand efficient development of multi-agent systems and the community requires novel SEsolutions. We introduce the overall main problems by giving an overview of them, citingsome of the existing and known approaches and solutions, and discussing promisingresearch trends and open problems.Specifically, in this section, we discuss rigorous and systematic techniques that allowthe specification of MAS requirements (Section 4.1), effective and efficient techniques thatsupport testing MAS (Section 4.2), and simulation tools that enable reproducing the MASand robotic behaviour with reasonable accuracy (Section 4.3). Finally, we will discuss ourperspectives (Section 4.4).4.1. Requirement SpecificationThe specification of the requirements of a multi-agent application is critical duringsoftware development. In MAS, requirements specification often concerns the definitionof the task, also known as mission [60], what the application should achieve, and how tomake the requirement executable by the MAS. Compared with conventional software, thepresence of multiple agents makes the requirement specification phase more complex anderror-prone since engineers need to precisely identify the different agents and identify thetasks they need to execute [61]. To support engineers in the specification of the requirementsof the MAS application, several tools were proposed in the literature, such as naturallanguages, logic-based languages, pattern-based languages, domain-specific languages,and goal-modelling techniques.In the following, we summarise some of the solutions proposed in these areas andevaluate how these solutions were used within the papers presented in the AREA 2020workshop (https://area2020.github.io/ accessed: 14 May 2021), since they provide goodexamples of research covering different aspects of MASs. Specifically, Table 1 summarisesthe requirement specification technique used for each of the papers presented in the AREA2020 workshop. Each row contains a requirement specification technique, i.e., naturallanguages, logic-based languages, pattern-based languages, domain-specific languages,and goal-modelling. Each column contains the reference to one of the papers presented inthe AREA 2020 workshop. The cell at the intersection between a row of one requirementspecification technique, and a column, of one paper presented in the AREA 2020 work-shop, indicates the requirement specification technique used in that paper. For example,the marker at the intersection between the row labelled as \u201clogic-based languages\u201d andthe column labelled with the reference [62] indicates that a logic-based language is therequirement specification technique used in [62].J. Sens. Actuator Netw. 2021, 10, 33 9 of 24Table 1. Requirements specification technique used by the papers published in AREA 2020 ([63] is not reported in the tablesince it does not consider MAS requirements).[62] [64] [65] [66] [67] [68] [69] [70] [10]Natural Language !Logic-based ! !Pattern-basedDomain-specific ! ! ! ! !Goal-modellingDemonstrations !4.1.1. Natural LanguagesIn many contexts, requirements are initially expressed in natural language. This isa common case in many industrial applications (e.g., [71,72]). Natural languages offersignificant benefits, they are easy to understand, and they support effective communicationamong different stakeholders. Several works considered the role of natural languages inthe requirement specifications of multi-agent and robotic systems. For example, in [73], theauthors proposed an approach to teach agents to communicate with humans in naturallanguage. In [74], the authors analyse how to utilise and extend the Software RequirementsSpecifications model (IEEE Std 830-2009) to support the specification of requirements ofmulti-agent systems. In [75], the authors apply techniques of natural language processingfor identifying the requirements and goals of multi-agent systems.One paper presented at the AREA workshop assumed that the requirements of theMAS are specified using natural language. Specifically, in [68], the authors propose dif-ferent types of interactions between an MAS and the final users who might benefit fromcommunication-intensive, voice-based interactions.4.1.2. Logic-Based LanguagesMany researchers specify the requirements of the MAS in a logic-based language(e.g., [18,19,76\u201378]). Logic-based languages, such as LTL or CTL, assume that requirementsare expressed using a set of atomic propositions that express relevant statements on themulti-agent system, combined with logical operators. One of the main advantages of usinglogic-based language is the availability of automated tools that support verification (e.g.,model checking) and synthesis.Two papers presented at the AREA workshop assumed that the requirements of theMAS are specified using logic-based languages. In [62], the authors use the TRIO [79]logical-language to specify the requirements of the MAS. TRIO is a first-order logicallanguage. It provides temporal operators to constrain the values of some propositions atdifferent time instants. In [64], the authors use the logical-based language provided byUppaal [80] to specify the requirements of the MAS. Uppaal allows specifying missionsthrough an extension of the CTL logic, which is a subset of TCTL. Specifically, it allows thespecification of properties constraining a proposition to hold globally (resp. eventually)for every execution or querying whether there exists an execution such that a propositionholds globally (resp. eventually).4.1.3. Pattern-Based LanguagesPattern-based languages are a common solution to solve recurrent problems ofmany domains, including robotics [60,81], cyber-physical systems [82], self-adaptivesystems [83,84], machine learning [85], IoT [86], and multi-agent systems [84,87\u201389]. Exist-ing design patterns in the field of multi-agent systems were classified in a recent survey [88].By analysing the papers presented at the AREA workshop, we noticed that none ofthe published papers used pattern-based languages to specify the requirements of themulti-agent system.J. Sens. Actuator Netw. 2021, 10, 33 10 of 244.1.4. Domain-Specific LanguagesSeveral Domain-Specific Languages (DSL) for MAS were proposed in the literature(e.g., [90\u201392]). For MAS, DSLs usually provide constructs that enable engineers to modelagents, the task they need to execute, and their interactions. Some of the recent DSLs formulti-agent systems are reported in the following.In [93], the authors present a DSL for multi-robot application, based on the roboticmission specification patters [60]. In [94], the authors apply the DESIRE specificationframework [95] on a case study on multi-agent systems. In [91], the authors propose a DSLfor MAS. They also use the language and their graphical tool support for developing anMAS using a model-driven development approach.Four papers presented at the AREA workshop proposed a DSL for the specificationof a robot\u2019s core behaviours. In [65], the authors propose the use of Capability AnalysisTables (CATs). CATs provide a tabular representation that connects the inputs, outputs,and the behaviours of an MAS. Differently from other tools, e.g., logic-based languages,CATs are more understandable by non-expert users. We also considered the languageused for specifying requirements by [66] as a domain-specific language. In this work,the authors assume that the requirement concerns reaching some specific states of thecompetence-aware systems used to model the MAS.In [67], the authors use Jadescript [96] to specify the MAS and its requirements.Jadescript is a novel agent-oriented programming language compiled to Java. In [70], theauthors consider the Planning Domain Definition Language (PDDL) [97] to specify the taskto be performed by the MAS. PDDL is a DSL that is proposed to standardise automatedplanning languages. It enables the definition of the domain and the problem. The domaindefinition allows users to define predicates and operators (a.k.a. actions). The problemdefinition defines the objects of the problem instance, its initial state, and the goal. In [10],the authors use the Jason language to express the requirements of the MAS application.Jason is an agent-oriented programming language based on the BDI software model.4.1.5. Goal-Modelling TechniquesSeveral goal-modelling techniques (e.g., Tropos [98], Gaia [99], Mobmas [100], INGE-NIAS [61]) support the development of multi-agent applications. These techniques enableusers to identify the goals and the agents of the application. They also usually support thedecomposition of goals into subgoals, and subgoals into tasks, and the assignment of tasksto agents.By analysing the papers presented at the AREA workshop, we noticed that none ofthe published papers used goal-modelling techniques to specify the requirements of themulti-agent system.4.1.6. DemonstrationsMany approaches use demonstrations to train the agents of a multi-agent applicationto perform their tasks [101\u2013104]. Demonstration approaches usually require a human todemonstrate to the agent the task to be performed. Then, the agent learns and repeatsthe task.One paper presented at the AREA workshop used demonstrations to specify the sys-tem goals. Specifically, in [69], the authors proposed a semi-supervised learning approachfrom demonstrations through program synthesis. Within this approach, a human operatorspecifies the goals by demonstrating to the agents how to perform the task. The MAS auto-matically infers high-level goals from the demonstration, synthesises a computer programbased on the demonstrations, and learns behavioural models for predictive control.The analysis of the papers presented at the AREA workshop (see Table 1) showsthat, despite the many approaches proposed in the literature, it seems that there is still noconsensus on the strategy to be used to specify MAS requirements. Most of the papers(5) used domain-specific languages for specifying the MAS requirements, followed bylogic-based languages (2), natural languages (1), and demonstrations (1). Many researchpapers often do not explicitly discuss the reason that motivates the usage of a givenJ. Sens. Actuator Netw. 2021, 10, 33 11 of 24specific language for the requirement specification. For example, many papers assume thatrequirements are expressed using logic-based languages (a formalism that easily supportsthe development of research prototypes). We believe that this is often dictated by the factthat these languages have formal semantics and are supported by verification and synthesistools that can be reused for verifying and synthesising plans of the MAS. Others use DSLs.We believe that this choice is dictated by the need of providing solutions closer to the needsof the final users.4.2. MAS TestingTesting robotic and multi-agent systems is a complex activity. It starts from theunit testing level, where the units can be the single agent functionalities, to the systemintegration level. At the system integration level, many aspects, such as the concurrentexecution of the agents, the environment integration, the control over the coordinationprotocol and communication management and modalities, are considered. Testing allthese aspects is inherently complex, and becomes even harder when tools do not provideappropriate support.Agent development frameworks, such as JADE [105] or Jason, support developingand testing of MAS and robotic applications. However, each of these frameworks comeswith some limitations. These limitations are particularly relevant for the design and devel-opment of MAS that need to be executed in a physical distributed environment, deployedover many machines and used by humans. A concrete testing and maintenance supportthat covers all of these requirements is still missing. In addition, the performances of V&Vtechniques are not sufficient to support the requirement of distributed environments, andcannot be easily integrated in the running environment.In this section, we summarise a set of works that considered the problem of testingMAS and robotic applications. These works have been selected based on the authors\u2019knowledge and experience. Specifically, in this section, we considered works that are:(1) exploring current support for testing MASs, (2) analysing applications of standardtesting techniques from the software engineering community, and (3) reporting how V&Vapproaches have been exploited in the field.4.2.1. Support for Testing MASsA starting point for testing an MAS is provided by the development framework itself,allowing and supporting the agent internal state inspection and the messages exchangesupervision. Both JADE and Jason offer such kind of tools (the Mind Inspector in Jason,the Introspector agent, and the Sniffer in JADE), which are usually necessary to perform amanual first check of the behaviours of agents and of the overall MAS, or that can be theused to perform more automated tests and verification.Some studies related to JADE are, for example, [106,107]. In [106], the authors pro-posed a solution, based on mock agents, that is presented to perform testing of a single roleof an agent under successful and exceptional scenarios; in [107], the authors proposed aframework developed on JADE [105] for building and running MAS test scenarios. Thisframework relies on the use of aspect-oriented techniques to monitor the autonomousagents during tests and control the test input of asynchronous test cases.In [108], the authors proposed an approach for enabling DevOps activities (that is,collaborative programming features to achieve fast and continuous deployment of complexsystems) in a new framework based on JaCaMo-web IDE [109] (which is a tool relatedto JaCaMo (http://jacamo.sourceforge.net/ accessed: 14 May 2021), and consequently toJason). This extension to the IDE enables for interactive facilities, such as the automaticaccess to the updates made to the components (agents), and the possibility to executetests on temporary running instances (allowing the framework to check the compatibilityof new changes using the real scenario, since tests are performed while the programmertypes, without affecting running instances). In addition, this extension provides facilitiesfor preventing conflicts when developers attempt to edit a resource simultaneously, andJ. Sens. Actuator Netw. 2021, 10, 33 12 of 24for managing versions. Thus, this is a concrete step toward offering real testing facilitiesto AOP.There are some other works related to MAS testing that do not consider JADE or Jason.The SUnit framework [110] provides a model based approach based on an extension ofJunit. The eCAT testing framework [111,112] supports continuous testing and automatedtest case generation. In [113], the authors proposed a tracing method supported by a toolimplementation to capture and analyse dynamic runtime data collected by logging thebehaviours of a set of agents. These solutions are ad-hoc solutions with limited practicaladoption, compared to JADE or Jason. They usually rely on specific formal languages thatmake their use difficult, in particular in industrial applications.4.2.2. Applications of Standard Testing Techniques from Software EngineeringStandard model-driven testing techniques coming from the SE domain (e.g., [114])are usually difficult to be used in multi-agent applications. One of the main limitationsof these techniques is that they require a model of the multi-agent application. Whilethere are standard approaches for modelling object-oriented or service-oriented systems,standard models for MAS are less mature. Therefore, MAS design is still often performedby relying on ad-hoc solutions, which need to be standardised. Therefore, we believe thatthere is room for exploiting SE techniques in the Agent-Oriented Software Engineering(AOSE) area [115].Some examples where standard SE testing approaches or techniques have beenadopted for MASs platforms are reported in the following.The BEAST methodology [116] is an example of agile testing methodology for multi-agent systems based on Behaviour Driven Development (BDD). It automatically generatestest cases skeletons from BDD scenarios specifications. The BEAST framework enablestesting MASs based on JADE or JADEX [117] platforms.In [118], mutation testing is used to test Jason specifications. The authors proposea set of mutation operators for Jason, and present a mutation testing framework forindividual Jason agents based on these mutation operators. In [119], the authors proposeda property-based testing (a particular form of model based testing) framework for MASsspecified in Jason. Specifically, the authors proposed to replace a subset of the agents bya QuickCheck [120] state machine. This state machine interacts with the other agents bysending messages and modifying the environment, and judging whether the remainingreal agents are correctly implemented by examining the messages sent to any replacedagent, and the belief perceptions that they receive.4.2.3. Exploitation and Integration of V&V ApproachesThere are many studies to check that the interaction between agents conforms to aformal specification (which is as a part of the testing activity). This is a very complextask since it involves the need to formally model and verify the protocol (as described inSection 3), and a concrete way to oversee the runtime execution, mixing together both atheoretical and an applied aspect.A concrete example of the integration of a V&V technique directly into a developmentplatform is proposed in [121,122], where an extension of the JADE Sniffer is used to createa monitor able to verify at runtime the MAS execution with respect to a global protocolspecified using the Attribute Global Types formalism [123\u2013125]. Since this is a JADEagent, it can be directly used in any JADE MAS, provided that the global protocol (if any) istranslated into the requested language. Similarly, in [121], an extension of Jason is proposedto achieve the same monitoring.In [39], we can find a work presenting the combination of formal verification andvalidation in the context of MAS verification, integrated into the MCAPL [126] framework.The verification part is obtained through the verification of the BDI agent, implemented inGwendolen [6], against a formal model of the environment, while the corresponding valida-tion is achieved through runtime verification, where monitors are used to verify at runtimethat the real environment does not violate the assumptions made by the model checker.J. Sens. Actuator Netw. 2021, 10, 33 13 of 244.3. Simulation ToolsPhysically distributed systems are often needed in industrial and academic solutions,such as unmanned vehicles, logistic, ambient intelligent systems.4.3.1. Simulation Tools for MASsJADE is largely adopted in industry, due to its simplicity in modelling agents\u2019 tasks,its support for agent communication, and its extensive community support. JADE suffersfrom scalability issues [127,128]. In addition, it provides limited support for dynamicallydiscovering new platforms that join the MAS at run-time. This limitation forces the usageof p2p communication, which is quite common in real world applications ([129]). However,differently from Jason, JADE was integrated within existing simulation platforms.Before deploying the MAS, developers need to test their solutions. To be representativeof a real situation, the physical environment must contain agents representing physicalentities, such as vehicles, computers, and production systems. Testing these systems isusually done by first relying on simulations. We can simulate the behaviour of an MASby relying on some stub entities, instead of using the actual MAS components. Stubsimplement a logic which is similar but usually simpler than the one that will be executedby the actual agents. For example, stubs may abstract and simplify the interaction protocolsused by the different agents to communicate.Some simulators for MASs exist, and we will present them in this section, but theydeal with the simulation in different ways.In [130], the authors propose DMASF, a Python distributed simulator for large scaleMASs (made of billions of agents). In this simulator, agents are implemented as specificentities using the simulator language. This means that a large number of agents can besimulated (we speak of numbers that are usually not manageable with JADE nor Jason,even using a simulation setup with many machines). However, the agents have to bere-implemented using the language of the simulator. This prevents user from testing actualcode executed by agents of the MAS. Netlogo (http://ccl.northwestern.edu/netlogo/index.shtml accessed: 14 May 2021) is another simulator that can handle MAS applications witha high number of agents. However, similarly to DMASF, the logic of the MAS agents hasto be re-implemented using the input language of the simulator. We do not provide adeeper analysis of these types of simulators since, in the rest of this paper, we will focus onsimulators that can support JADE specifications.The JREP platform [131] integrates JADE and Repast Simphony [132]. It solves somelimitations of a similar approach presented in [133] that supports an older version of Repastand was limited by the focus on supply chain performance analysis and by an inefficientpolling strategy affecting performances. The JREP platform offers an MAS developmentplatform exploiting the JADE support for modelling the internal agent behaviour and theRepast support for simulating an environment where entities can interact in a simulation.JREP is a new development platform, where JADE agents need to be modified to implementnew interfaces to be able to interact with the Repast environment. In this way, a bidirectionalinterface between the JADE agents and the Repast running environment is achieved, but theresulting JADE MAS is no longer able to run independently outside of the JREP platform.In [134,135], the authors proposed the SAJaS API. This API has to be used with RepastSimphony to create, or improve, MAS based simulations enhanced with JADE-basedfeatures. Then, the \u201cMAS Simulation to Development (MASSim2Dev)\u201d code conversiontool transforms an MAS, developed using the SAJaS API, to a \u201cstandalone\u201d standard JADEMAS. This tool is useful in scenarios where JADE developers need to perform tests ina simulator before distributing their JADE MAS. The architectural design of the JADEframework is based on Repast. However, since it is \u201cJADE-like\u201d environment, it is simplerto generate the JADE standard implementation. Unfortunately, MASSim2Dev can notmanage the JADE blocking functions, and does not allow Ticker and Waker behavioursdue to problems with time management.J. Sens. Actuator Netw. 2021, 10, 33 14 of 244.3.2. Simulation Tools for RobotsRobotics systems also need to be extensively tested before deployment. Testing thesesystems is even more complex since robots interact with their physical environmentsthrough sensors and actuators. Therefore, to test these systems, simulators must providereliable and accurate simulators between the robots and their environment. The variety ofthe environments in which the robots operate (e.g., very deep sea, disaster areas, no gravityscenarios and so on), makes the creation of accurate simulators even more complex.In the following, we report a few examples of simulators present in the literature.USARSim (Urban Search and Rescue Simulation) [136] is a general-purpose multi-robot simulator environment used as the simulation engine for the Virtual Robots Com-petition within the Robocup initiative, and has been often adopted in research activities.It presents an interface with Player [137] (a popular middleware used to control manydifferent robots), and, thanks to this interface, the code developed within USARSim can betransparently moved to real platforms without any change (and vice versa). This simulatorprovides is relatively accurate: there is a close correspondence between results obtainedwithin the simulation and the one obtained by the corresponding physical system.MORSE (Modular Open Robots Simulation Engine) [138] is an open-source applicationthat can be used in different contexts for the testing and verification of robotics systems. Itis completely modular and can interact with any middleware used in robotics. In addition,it does not impose a format to which programmers must adapt. MORSE is designed tohandle the simulation of several robots simultaneously, as a distributed application wherethe robotics software being evaluated can run on the same or a different computer as thesimulation one. The evaluated components are executed on the target hardware and interactwith the simulator with the very same protocols as the ones of the actual robots, sensors,and actuators, to make the shift from simulations to actual experiments transparent.Gazebo [139] is a 3D dynamic multi-robot environment simulator. It is developedstarting from the well known Player/Stage project [137], with the goal of enabling simu-lating dynamic outdoor environments and providing realistic sensor feedback, while stillmodelling robots as dynamic structures composed of rigid bodies connected via joints.The hardware simulated in Gazebo is designed to accurately reflect the behaviour of itsphysical counterpart: consequently, a client program shows an interface that is identicalto the one that will be executed on the final robot. This makes Gazebo to be seamlesslyinserted into the development process of a robotic system. Nowadays, it is largely adoptedby the robotic community, and has a large and active supporting community.4.4. Perspective of the AuthorsMany SE approaches for MAS and robotic applications were proposed in the literature.However, many challenges still need to be addressed. In the following, we will discussthree of these challenges.\u2022 lack of clear guidance for the selection of the specification language to be used for the re-quirement specification. The analysis of the paper presented in Section 4.1 showed theabsence of a consensus on the strategy to be used to specify MAS requirements. Giventhe limited number of papers analysed (10), we cannot make any general claim onour observations, which should be confirmed by more extensive and in-depth studies.However, we believe that all the formalisms proposed in the literature for requirementspecifications offer pro and cons, and that the research community should spend someeffort in understanding when and how to use them and providing guidelines thatcan be used in research and practical works. We believe that our observations canpave the way for discussions and further studies on the requirement specification ofmulti-agent systems.\u2022 lack of mature testing tools for MAS and robotic applications. The works summarised inSection 4.2 are some examples of SE techniques that support testing MAS and roboticapplications. However, these techniques are supported by research prototypes thatare still not mature enough to be used in industrial settings. Therefore, we believeJ. Sens. Actuator Netw. 2021, 10, 33 15 of 24that more effort is needed to implement and develop mature tools that can be used inindustrial applications.\u2022 lack of use of industrial simulators. As discussed in Section 4.3, there are many simulatorsfor JADE MASs. However, these simulators are still not ready for industrial usages.In addition, while there are many platforms for simulating robotics systems, thecontinuous innovation of available solutions from the robotic community (e.g., newsensors and actuators) is asking for more accurate simulators. It is also necessary toprecisely document the usage scenarios and assumptions of each simulator, to enabledevelopers to quickly find the best simulation platform for their needs. For this reason,we believe that research should work with integrating research solutions with realindustrial products.5. Human\u2013Agent InteractionBuilding reliable applications is of primary importance when agents and robots needto interact with humans. Robots or humans could be directly (negatively) affected by anagent\u2019s behaviour, e.g., when humans and agents are working together to achieve a goal.To ensure reliable interactions, humans and agents need to anticipate each other\u2019sactions and reactions to some degree. They need to communicate and understand eachother, as well as develop a shared understanding of their environment. In addition, humansneed to trust the autonomous system.We discuss three main approaches for realising reliable applications based on human\u2013agent interaction, namely (i) building it right from the ground up, (ii) analysing existinginteractions, and (iii) adjusting the users\u2019 expectations when necessary. In addition, theverification of human\u2013robot interaction was discussed in Section 3.5.1. Interaction DesignAgent interaction is usually based on interaction protocols. If humans are part of thesystem, the means of interaction between a user and an autonomous component have to bedesigned before the deployment of the application. Some approaches have been proposedto design human\u2013robot interaction protocols.Interaction Design Patterns (IDPs) [140] have been proposed to capture workablesolutions for human\u2013agent interaction. As design patterns are rather descriptive in nature,they allow for more flexibility in how they are actually implemented. In [141], five designpatterns for eliciting self-disclosure are presented, as self-disclosure is an important part ofgetting acquainted, which leads to more trust and helps with long-term interactions. Intheir paper, children were the target audience. IDPs are also used in the framework of [142]to specify how to communicate explanations in order to improve the performance of mixedhuman\u2013agent teams.In [143], 18 guidelines for interactions between humans and AI are proposed fromthe perspective of the human\u2013computer interaction field and evaluated through a userstudy. The guidelines include making clear what the system can do, how well it can doit, considering social norms, supporting efficient interaction, giving explanations, andadapting to the current user.In [144], planning agents are used to coordinate in disaster response scenarios so thathumans can choose to be guided by an agent. The authors also propose some guidelinesfor interaction design: agents should always be able to respond to the needs of the users,interactions should be rather simple with limited options, and interaction should enabletransfer of control between the autonomous agent and its user. In [145], the authors pro-posed adjustable autonomy, which enables a (human) controller to switch unmanned aerialvehicles operation between manual control and autonomy, enabling them to supervisemultiple entities at once and only assume control when necessary.5.2. Modelling Mixed Human\u2013Agent SystemsIf a system can be modelled, it can be simulated (or even verified), it is easier to reasonabout it and reach a deeper understanding of the system behaviour. Modelling human\u2013J. Sens. Actuator Netw. 2021, 10, 33 16 of 24agent interaction is a challenging endeavour. On the one hand, we have the autonomousnature of the agent, while, on the other hand, human behaviour tends to be unpredictable.In [146], the authors proposed an approach to synthesise control protocols. An un-manned aerial vehicle and the operator are modelled as Markov Decision Processes (MDP),interacting via synchronised actions. MDPs allow modelling uncertainties regarding thebehaviour of the human operator. The model is then augmented to a stochastic two-playergame to account for non-determinism.Another modelling approach for autonomous systems (e.g., autonomous driving) isproposed in [147]. They combine discrete event simulation with system dynamics modelsto simulate the effects of different system designs.In [148], an entire robot swarm interacting with humans is considered. Challengesinclude which control type to use in which situation (assigning and controlling a leader,using the environment, controlling only parameters, or assigning behaviours), and alsovisualisation techniques to help the user understand a swarm\u2019s behaviour.The modelling approaches for interaction design presented in this section are allcreated for a specific use case. More work is required to find general-purpose models thatcan be used in different domains.5.3. Trust and TransparencyAs systems get more and more autonomous, anticipating their behaviour becomesmore challenging. Transparency can help users understand what their system is doing.In [149], the authors use a tiered transparency model based on situation awareness toshow that more agent transparency leads to better trust calibration of the human operatorwithout necessarily increasing their workload. This is further developed in [150], wherethe authors argue that bidirectional transparency is important. Thus, agents have to bedesigned to understand the plans, reasoning and future projections of their users.In [151], the author argues that trust (in an autonomous system) at least requires aframework for recourse, the system\u2019s ability to give explanations, and verification andvalidation of the system.In [150], the authors discuss further challenges regarding trust, namely how to quantifytrust, how to model its evolution, how to create a logic that allows for specificationsincluding trust, and also how to verify whether a system satisfies such a specification.5.4. Behaviour ExplanationsThere are still many cases where full autonomy is not yet achievable. In these cases,humans have to take on a supervisory role. In these cases, humans may want to implicitlyperform some kind of (mostly informal) verification of the agents\u2019 autonomous behaviour.One way of achieving this is giving autonomous systems the ability to explain their actions,their decisions and reasoning. While the previous paragraph handled how to enable usersto get expectations which are more justified, some expectations might still be unreasonable.Behaviour explanations are one way of realigning these expectations, or even finding flawsin the autonomous logic of the system.In [152], the author draws on the large body of work on explanations in the social sci-ences to infer properties of good explanations that humans will accept. They are contrastive(explaining why something happened instead of something else), selected (giving onlyrelevant and important information) and social (considering the needs and background ofthe recipient).In [153], a mechanism for answering \u201cWhy?\u201d-questions about an agent\u2019s behaviour isimplemented for the GWENDOLEN language. The questions are answered by identifyingcausal factors in the trace of the program, i.e., choice points, where another decisionwouldn\u2019t have led to the result that needs to be explained.A general perspective on explanations in AI is taken in [154] with a focus on systemsincorporating machine learning. They give a formal definition of explainability, distin-guishing it from interpretability and transparency of learning algorithms. Among others,they give possible reasons for making a system explainable (since each system does notJ. Sens. Actuator Netw. 2021, 10, 33 17 of 24need to be, e.g., if users have no way of reacting to an explanation), possible groups oftarget recipients, ways to create interpretations and the relations between these questions.In [155], the authors take another stance on explanation. They consider explanation asa model reconciliation problem. Explaining means making the mental models of the agentand the user converge, leading to a shared understanding of their world, so that the planof the agent appears optimal.5.5. Perspective of the AuthorsMany researchers had considered human\u2013agent interaction problems and designedsolutions for these problems. However, many challenges still need to be addressed. In thefollowing, we will discuss three of these challenges:\u2022 Making human\u2013agent interaction more reliable. There is an increasing need for makinghuman\u2013agent interaction more reliable. This problem can and has to be tackled frommany different research angles. Interaction design, employing foremost guidelines anddesign patterns have laid the foundation for reliable interaction. However, reliabilityis mostly targeted implicitly, which leaves a need for the incorporation of an explicitnotion of reliable interaction.\u2022 Providing modelling formalisms that effectively enable modelling human\u2013agent systems.Modelling human\u2013agent systems requires new ways of specifying formerly informalconcepts, such as trust, transparency, and maybe even more exotic concepts (for amachine) such as honesty and loyalty. Of course, the ability to model such systems isclosely linked to being able to verify them.\u2022 Making systems more understandable. Finally, making systems more understandable,e.g., by explaining them, requires many different parts coming together. In theconcrete case of improving reliability, challenges include making sure users correctlyunderstand what they are told, systems explaining their actions truthfully and usersbeing able to verify that, or agents being able to understand why users perceive themas unreliable and act upon that.6. ConclusionsIn this perspective paper, we have discussed the applicability of agent-based program-ming in robotics, presented an overview of the landscape in the verification and validationof MAS and robot systems, analysed the use of software engineering in MAS, and describedthe latest research in human\u2013agent interaction. Combining knowledge coming from theseresearch areas may lead to innovative approaches that solve complex problems related tothe development of autonomous robotic systems, and there is growing interest in solutionsthat are at the intersection of these research areas. The AREA workshop was a successfulevent attended by researchers working in these areas. It was an exciting event that enabledsharing ideas, open problems, and solutions and fostering cross-disciplinary collaborationsamong researchers. In this work, we used the papers and discussions from this workshopto analyse some of the aspects covered in this perspective.Our perspective provided a high-level view of current research trends. We also identi-fied a set of challenges for each of the areas we considered. For multi-agent programming,the challenges we identified include among others, the limited set of features provided byexisting agent-based languages, immature methodologies and tools, and the limited inte-gration of agent-based technologies with other techniques. For verification and validations,the challenges include the scalability of the proposed techniques and the verification of MLcomponents. For software engineering, the challenges include the lack of clear guidancefor the selection of the specification language to be used for expressing requirements,the lack of mature testing tools for MAS and robotic applications and the lack of use ofindustrial simulators within research works. Finally, for human\u2013agent interactions, thechallenges include the still inadequate reliability of human\u2013agent interaction systems, thestill immature modelling support for these systems, and the lack of techniques able toJ. Sens. Actuator Netw. 2021, 10, 33 18 of 24make these systems more understandable. We believe that this perspective can be usefulfor researchers that aim at working at the intersection of these research areas.We hope that the different research communities improve their collaboration efforts,so that the best proposals from different areas can be combined to create new and existingsolutions and tools to be exploited both in academia and in industry.Author Contributions: All authors (R.C.C., A.F., D.B., C.M. and T.A.) contributed equally to thiswork. All authors have read and agreed to the published version of the manuscript.Funding: Rafael C. Cardoso and Angelo Ferrando\u2019s work in this research was supported by UKResearch and Innovation, and EPSRC Hubs for \u201cRobotics and AI in Hazardous Environments\u201d:EP/R026092 (FAIR-SPACE), EP/R026173 (ORCA), and EP/R026084 (RAIN). Claudio Menghi issupported by the European Research Council under the European Union\u2019s Horizon 2020 researchand innovation programme (grant No 694277).Conflicts of Interest: The authors declare no conflict of interest. The funders had no role in the designof the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, orin the decision to publish the results.AbbreviationsThe following abbreviations are used in this manuscript:AI Artificial IntelligenceAOSE Agent-Oriented Software EngineeringBDD Behaviour Driven DevelopmentBDI Belief-Desire-IntentionCAT Capability Analysis TableDSL Domain-Specific LanguageIDP Interaction Design PatternMAS Multi-Agent SystemMDP Markov Decision ProcessPDDL Planning Domain Definition LanguageROS Robot Operating SystemSE Software EngineeringReferences1. Bratman, M.E. Intentions, Plans, and Practical Reason; Harvard University Press: Cambridge, MA, USA, 1987.2. Rao, A.S.; Georgeff, M. BDI Agents: From Theory to Practice. In Proceedings of the 1st International Conference Multi-AgentSystems (ICMAS), San Francisco, CA, USA, 12\u201314 June 1995; pp. 312\u2013319.3. Bordini, R.H.; H\u00fcbner, J.F.; Wooldridge, M. Programming Multi-Agent Systems in AgentSpeak Using Jason (Wiley Series in AgentTechnology); John Wiley & Sons, Inc.: Hoboken, NJ, USA, 2007.4. Boissier, O.; Bordini, R.H.; H\u00fcbner, J.F.; Ricci, A.; Santi, A. Multi-agent Oriented Programming with JaCaMo. Sci. Comput.Program. 2013, 78, 747\u2013761. [CrossRef]5. Boissier, O.; Bordini, R.; Hubner, J.; Ricci, A. Multi-Agent Oriented Programming: Programming Multi-Agent Systems Using JaCaMo;Intelligent Robotics and Autonomous Agents Series; MIT Press: Cambridge, MA, USA, 2020.6. Dennis, L.A.; Farwer, B. Gwendolen: A BDI Language for Verifiable Agents. In Workshop on Logic and the Simulation of Interactionand Reasoning; AISB: London, UK, 2008.7. Quigley, M.; Conley, K.; Gerkey, B.; Faust, J.; Foote, T.; Leibs, J.; Wheeler, R.; Ng, A. ROS: An open-source Robot OperatingSystem. In Proceedings of the Workshop on Open Source Software at the International Conference on Robotics and Automation,Kobe, Japan, 12\u201317 May 2009.8. Wesz, R. Integrating Robot Control into the Agentspeak(L) Programming Language. Master\u2019s Thesis, Pontificia UniversidadeCatolica do Rio Grande do Sul, Porto Alegre, Brazil, 2015.9. Morais, M.G.; Meneguzzi, F.R.; Bordini, R.H.; Amory, A.M. Distributed fault diagnosis for multiple mobile robots using an agentprogramming language. In Proceedings of the 2015 International Conference on Advanced Robotics (ICAR), Istanbul, Turkey,27\u201331 July 2015; pp. 395\u2013400. [CrossRef]10. Onyedinma, C.; Gavigan, P.; Esfandiari, B. Toward Campus Mail Delivery Using BDI. In Agents and Robots for Reliable EngineeredAutonomy; Electronic Proceedings in Theoretical Computer Science; Open Publishing Association: The Hague, The Netherlands,2020; Volume 319, pp. 127\u2013143. [CrossRef]J. Sens. Actuator Netw. 2021, 10, 33 19 of 2411. Onyedinma, C.; Gavigan, P.; Esfandiari, B. Toward Campus Mail Delivery Using BDI. J. Sens. Actuator Netw. 2020, 9, 56.[CrossRef]12. Cardoso, R.C.; Ferrando, A.; Dennis, L.A.; Fisher, M. An Interface for Programming Verifiable Autonomous Agents in ROS. InMulti-Agent Systems and Agreement Technologies; Springer: Berlin/Heidelberg, Germany, 2020; pp. 191\u2013205.13. Crick, C.; Jay, G.; Osentoski, S.; Pitzer, B.; Jenkins, O.C. Rosbridge: ROS for Non-ROS Users. In Robotics Research: InternationalSymposium ISRR; Springer: Berlin/Heidelberg, Germany, 2017; pp. 493\u2013504.14. Logan, B. An agent programming manifesto. Int. J. Agent-Oriented Softw. Eng. 2018, 6, 187\u2013210. [CrossRef]15. Bordini, R.H.; Seghrouchni, A.E.F.; Hindriks, K.V.; Logan, B.; Ricci, A. Agent programming in the cognitive era. Auton. AgentsMulti Agent Syst. 2020, 34, 37. [CrossRef]16. Cardoso, R.C.; Ferrando, A. A Review of Agent-Based Programming for Multi-Agent Systems. Computers 2021, 10, 16. [CrossRef]17. Ziafati, P.; Dastani, M.; Meyer, J.J.; van der Torre, L. Agent Programming Languages Requirements for Programming AutonomousRobots. In Programming Multi-Agent Systems; Springer: Berlin/Heidelberg, Germany, 2013; pp. 35\u201353.18. Luckcuck, M.; Farrell, M.; Dennis, L.A.; Dixon, C.; Fisher, M. Formal specification and verification of autonomous robotic systems:A survey. ACM Comput. Surv. CSUR 2019, 52, 1\u201341. [CrossRef]19. Farrell, M.; Luckcuck, M.; Fisher, M. Robotics and integrated formal methods: Necessity meets opportunity. In InternationalConference on Integrated Formal Methods; Springer: Berlin/Heidelberg, Germany, 2018; pp. 161\u2013171.20. Lomuscio, A.; Qu, H.; Raimondi, F. MCMAS: An open-source model checker for the verification of multi-agent systems. Int. J.Softw. Tools Technol. Transf. 2017, 19, 9\u201330. [CrossRef]21. Kouvaros, P.; Lomuscio, A. Parameterised verification for multi-agent systems. Artif. Intell. 2016, 234, 152\u2013189. [CrossRef]22. C\u030cerm\u00e1k, P.; Lomuscio, A.; Murano, A. Verifying and synthesising multi-agent systems against one-goal strategy logic specifica-tions. In Proceedings of the AAAI Conference on Artificial Intelligence, Austin, TX, USA, 25\u201330 January 2015; Volume 29.23. Belardinelli, F.; Lomuscio, A.; Murano, A.; Rubin, S. Verification of Multi-agent Systems with Imperfect Information and PublicActions. In Proceedings of the AAMAS, S\u00e3o Paulo, Brazil, 5\u20138 May 2017; Volume 17, pp. 1268\u20131276.24. Dennis, L.; Fisher, M.; Slavkovik, M.; Webster, M. Formal verification of ethical choices in autonomous systems. Robot. Auton.Syst. 2016, 77, 1\u201314. [CrossRef]25. Dennis, L.A.; Fisher, M.; Webster, M.P.; Bordini, R.H. Model checking agent programming languages. Autom. Softw. Eng. 2012,19, 5\u201363. [CrossRef]26. Kashi, R.N.; D\u2019Souza, M. Vermillion: A Verifiable Multiagent Framework for Dependable and Adaptable Avionics; Technical Report;IIIT-Bangalore: Bengaluru, India, 2018.27. Meyer, B.; Baudoin, C. M\u00e9thodes de Programmation, 1st ed.; Eyrolles: Paris, France, 1978.28. Karoui, O.; Khalgui, M.; Koub\u00e2a, A.; Guerfala, E.; Li, Z.; Tovar, E. Dual mode for vehicular platoon safety: Simulation and formalverification. Inf. Sci. 2017, 402, 216\u2013232. [CrossRef]29. Bengtsson, J.; Larsen, K.G.; Larsson, F.; Pettersson, P.; Yi, W. UPPAAL\u2014A Tool Suite for Automatic Verification of Real-TimeSystems. In Workshop on Verification and Control of Hybrid Systems; Springer: Berlin/Heidelberg, Germany, 1995; Volume 1066,pp. 232\u2013243. [CrossRef]30. Kamali, M.; Dennis, L.A.; McAree, O.; Fisher, M.; Veres, S.M. Formal verification of autonomous vehicle platooning. Sci. Comput.Program. 2017, 148, 88\u2013106. [CrossRef]31. Al-Saqqar, F.; Bentahar, J.; Sultan, K.; Wan, W.; Asl, E.K. Model checking temporal knowledge and commitments in multi-agentsystems using reduction. Simul. Model. Pract. Theory 2015, 51, 45\u201368. [CrossRef]32. Pecheur, C.; Raimondi, F. Symbolic Model Checking of Logics with Actions. In Model Checking and Artificial Intelligence; Springer:Berlin/Heidelberg, Germany, 2006; Volume 4428, pp. 113\u2013128. [CrossRef]33. Cimatti, A.; Clarke, E.M.; Giunchiglia, F.; Roveri, M. NUSMV: A New Symbolic Model Checker. Int. J. Softw. Tools Technol. Transf.2000, 2, 410\u2013425. [CrossRef]34. Ancona, D.; Ferrando, A.; Mascardi, V. Parametric Runtime Verification of Multiagent Systems. In Proceedings of the AAMAS,S\u00e3o Paulo, Brazil, 8\u201312 May 2017; Volume 17, pp. 1457\u20131459.35. Ferrando, A.; Ancona, D.; Mascardi, V. Decentralizing MAS Monitoring with DecAMon. In Proceedings of the Conference onAutonomous Agents and MultiAgent Systems, S\u00e3o Paulo, Brazil, 8\u201312 May 2017; ACM: New York, NY, USA, 2017; pp. 239\u2013248.36. Bakar, N.A.; Selamat, A. Runtime verification of multi-agent systems interaction quality. In Asian Conference on IntelligentInformation and Database Systems; Springer: Berlin/Heidelberg, Germany, 2013; pp. 435\u2013444.37. Roungroongsom, C.; Pradubsuwun, D. Formal Verification of Multi-agent System Based on JADE: A Semi-runtime Approach. InRecent Advances in Information and Communication Technology 2015; Springer: Berlin/Heidelberg, Germany, 2015; pp. 297\u2013306.38. Lim, Y.J.; Hong, G.; Shin, D.; Jee, E.; Bae, D.H. A runtime verification framework for dynamically adaptive multi-agent systems.In Proceedings of the International Conference on Big Data and Smart Computing (BigComp), Hong Kong, China, 18\u201320 January2016; pp. 509\u2013512.39. Ferrando, A.; Dennis, L.A.; Ancona, D.; Fisher, M.; Mascardi, V. Verifying and Validating Autonomous Systems: Towards anIntegrated Approach. In Runtime Verification RV; Lecture Notes in Computer Science; Springer: Berlin/Heidelberg, Germany,2018; Volume 11237, pp. 263\u2013281.40. Webster, M.; Dixon, C.; Fisher, M.; Salem, M.; Saunders, J.; Koay, K.L.; Dautenhahn, K.; Saez-Pons, J. Toward reliable autonomousrobotic assistants through formal verification: A case study. IEEE Trans. Hum.-Mach. Syst. 2015, 46, 186\u2013196. [CrossRef]J. Sens. Actuator Netw. 2021, 10, 33 20 of 2441. Sierhuis, M.; Clancey, W.J. Modeling and Simulating Work Practice: A Method for Work Systems Design. IEEE Intell. Syst. 2002,17, 32\u201341. [CrossRef]42. Holzmann, G. Spin Model Checker, the: Primer and Reference Manual, 1st ed.; Addison-Wesley Professional: Boston, MA, USA, 2003.43. Holzmann, G.J. The Model Checker SPIN. IEEE Trans. Softw. Eng. 1997, 23, 279\u2013295. [CrossRef]44. B\u00e9rard, B.; Lafourcade, P.; Millet, L.; Potop-Butucaru, M.; Thierry-Mieg, Y.; Tixeuil, S. Formal verification of mobile robotprotocols. Distrib. Comput. 2016, 29, 459\u2013487. [CrossRef]45. Barnat, J.; Brim, L.; Cern\u00e1, I.; Moravec, P.; Rockai, P.; Simecek, P. DiVinE\u2014A Tool for Distributed Verification. In Computer AidedVerification, CAV; Springer: Berlin/Heidelberg, Germany, 2006; Volume 4144, pp. 278\u2013281.46. Halder, R.; Proen\u00e7a, J.; Macedo, N.; Santos, A. Formal verification of ROS-based robotic applications using timed-automata.In Proceedings of the IEEE/ACM FME Workshop on Formal Methods in Software Engineering (FormaliSE), Buenos Aires,Argentina, 27\u201327 May 2017; pp. 44\u201350.47. Wang, L.; Ames, A.; Egerstedt, M. Safety barrier certificates for heterogeneous multi-robot systems. In Proceedings of the 2016American Control Conference (ACC), Boston, MA, USA, 6\u20138 July 2016; pp. 5213\u20135218.48. Foughali, M.; Berthomieu, B.; Dal Zilio, S.; Ingrand, F.; Mallet, A. Model checking real-time properties on the functional layer ofautonomous robots. In International Conference on Formal Engineering Methods; Springer: Cham, Switzerland, 2016; pp. 383\u2013399.49. Foughali, M.; Berthomieu, B.; Dal Zilio, S.; Hladik, P.E.; Ingrand, F.; Mallet, A. Formal verification of complex robotic systems onresource-constrained platforms. In Proceedings of the IEEE/ACM International FME Workshop on Formal Methods in SoftwareEngineering (FormaliSE), Gothenburg, Sweden, 27 May\u20133 June 2018; pp. 2\u20139.50. Fleury, S.; Herrb, M.; Chatila, R. GenoM: A tool for the specification and the implementation of operating modules in a distributedrobot architecture. In Proceedings of the IEEE/RSJ International Conference on Intelligent Robot and Systems, InnovativeRobotics for Real-World Applications, Grenoble, France, 11 September 1997; pp. 842\u2013849. [CrossRef]51. Berthomieu, B.; Bodeveix, J.; Filali, M.; Garavel, H.; Lang, F.; Peres, F.; Saad, R.; St\u00f6cker, J.; Vernadat, F. The Syntax and Semantics ofFIACRE; Technical Report, Deliverable number F.3.2.11 of project TOPCASED; LAAS-CNRS: Toulouse, France, 2009.52. Vicentini, F.; Askarpour, M.; Rossi, M.G.; Mandrioli, D. Safety assessment of collaborative robotics through automated formalverification. IEEE Trans. Robot. 2019, 36, 42\u201361. [CrossRef]53. Askarpour, M.; Mandrioli, D.; Rossi, M.; Vicentini, F. SAFER-HRC: Safety analysis through formal verification in human\u2013robotcollaboration. In International Conference on Computer Safety, Reliability, and Security; Springer: Berlin/Heidelberg, Germany, 2016;pp. 283\u2013295.54. Pradella, M. A User\u2019s Guide to Zot. arXiv 2009, arXiv:0912.5014.55. Wang, R.; Wei, Y.; Song, H.; Jiang, Y.; Guan, Y.; Song, X.; Li, X. From offline towards real-time verification for robot systems. IEEETrans. Ind. Inform. 2018, 14, 1712\u20131721. [CrossRef]56. Ferrando, A.; Cardoso, R.C.; Fisher, M.; Ancona, D.; Franceschini, L.; Mascardi, V. ROSMonitoring: A Runtime VerificationFramework for ROS. In Towards Autonomous Robotic Systems; Springer: Berlin/Heidelberg, Germany, 2020; pp. 387\u2013399.57. Ferrando, A.; Kootbally, Z.; Piliptchak, P.; Cardoso, R.C.; Schlenoff, C.; Fisher, M. Runtime Verification of the ARIAC Competition:Can a Robot be Agile and Safe at the Same Time? In Proceedings of the Italian Workshop on Artificial Intelligence and Robotics,Online, 25\u201327 November 2020; Volume 2806, pp. 7\u201311.58. Sun, X.; Khedr, H.; Shoukry, Y. Formal verification of neural network controlled autonomous systems. In ACM InternationalConference on Hybrid Systems: Computation and Control; Association for Computing Machinery: Montreal, QC, Canada, 2019; pp.147\u2013156.59. Askarpour, M.; Menghi, C.; Belli, G.; Bersani, M.M.; Pelliccione, P. Mind the gap: Robotic Mission Planning Meets SoftwareEngineering. In FormaliSE@ICSE 2020: International Conference on Formal Methods in Software Engineering; ACM: New York, NY,USA, 2020; pp. 55\u201365.60. Menghi, C.; Tsigkanos, C.; Pelliccione, P.; Ghezzi, C.; Berger, T. Specification Patterns for Robotic Missions. IEEE Trans. Softw.Eng. 2019, 1. [CrossRef]61. Pav\u00f3n, J.; G\u00f3mez-Sanz, J.J.; Fuentes, R. The INGENIAS methodology and tools. In Agent-Oriented Methodologies; IGI Global:Hershey, PA, USA, 2005; pp. 236\u2013276.62. Askarpour, M.; Rossi, M.; Tiryakiler, O. Co-Simulation of Human-Robot Collaboration: From Temporal Logic to 3D Simulation.In Agents and Robots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; Open PublishingAssociation: The Hague, The Netherlands, 2020; Volume 319, pp. 1\u20138. [CrossRef]63. Halvari, T.; Nurminen, J.K.; Mikkonen, T. Testing the Robustness of AutoML Systems. In Agents and Robots for Reliable EngineeredAutonomy; Electronic Proceedings in Theoretical Computer Science; Open Publishing Association: The Hague, The Netherlands,2020; Volume 319, pp. 103\u2013116. [CrossRef]64. Lestingi, L.; Askarpour, M.; Bersani, M.; Rossi, M. Statistical Model Checking of Human-Robot Interaction Scenarios. In Agentsand Robots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; Open Publishing Association:The Hague, The Netherlands, 2020; Volume 319, pp. 9\u201317. [CrossRef]65. Edwards, V.; McGuire, L.; Redfield, S. Establishing Reliable Robot Behavior using Capability Analysis Tables. In Agents andRobots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; Open Publishing Association:The Hague, The Netherlands, 2020; Volume 319, pp. 19\u201335. [CrossRef]J. Sens. Actuator Netw. 2021, 10, 33 21 of 2466. Basich, C.; Svegliato, J.; Wray, K.H.; Witwicki, S.J.; Zilberstein, S. Improving Competence for Reliable Autonomy. In Agents andRobots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; Open Publishing Association:The Hague, The Netherlands, 2020; Volume 319, pp. 37\u201353. [CrossRef]67. Iotti, E.; Petrosino, G.; Monica, S.; Bergenti, F. Exploratory Experiments on Programming Autonomous Robots in Jadescript. InAgents and Robots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; Open PublishingAssociation: The Hague, The Netherlands, 2020; Volume 319, pp. 55\u201367. [CrossRef]68. Ancona, D.; Bassano, C.; Chessa, M.; Mascardi, V.; Solari, F. Engineering Reliable Interactions in the Reality-ArtificialityContinuum. In Agents and Robots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; OpenPublishing Association: The Hague, The Netherlands, 2020; Volume 319, pp. 69\u201380. [CrossRef]69. Smith, S.C.; Ramamoorthy, S. Semi-supervised Learning From Demonstration Through Program Synthesis: An Inspection RobotCase Study. In Agents and Robots for Reliable Engineered Autonomy; Electronic Proceedings in Theoretical Computer Science; OpenPublishing Association: The Hague, The Netherlands, 2020; Volume 319, pp. 81\u2013101. [CrossRef]70. Stringer, P.; Cardoso, R.C.; Huang, X.; Dennis, L.A. Adaptable and Verifiable BDI Reasoning. In Agents and Robots for ReliableEngineered Autonomy; Electronic Proceedings in Theoretical Computer Science; Open Publishing Association: The Hague, TheNetherlands, 2020; Volume 319, pp. 117\u2013125. [CrossRef]71. Lami, G.; Gnesi, S.; Fabbrini, F.; Fusani, M.; Trentanni, G. An Automatic Tool for the Analysis of Natural Language Requirements;Technical Report; CNR Information Science and Technology Institute: Pisa, Italy, 2004.72. Ambriola, V.; Gervasi, V. Processing natural language requirements. In Proceedings of the International Conference AutomatedSoftware Engineering, Incline Village, NV, USA, 1\u20135 November 1997; pp. 36\u201345.73. Lazaridou, A.; Potapenko, A.; Tieleman, O. Multi-agent communication meets natural language: Synergies between functionaland structural language learning. arXiv 2020, arXiv:2005.07064.74. Slhoub, K.; Carvalho, M.; Bond, W. Recommended practices for the specification of multi-agent systems requirements. InProceedings of the IEEE Annual Ubiquitous Computing, Electronics and Mobile Communication Conference (UEMCON), NewYork, NY, USA, 19\u201321 October 2017; pp. 179\u2013185.75. Moreno, J.C.G.; L\u00f3pez, L.V. Using Techniques Based on Natural Language in the Development Process of Multiagent Systems.In International Symposium on Distributed Computing and Artificial Intelligence 2008 (DCAI 2008); Springer: Berlin/Heidelberg,Germany, 2009; pp. 269\u2013273.76. Elkholy, W.; El-Menshawy, M.; Bentahar, J.; Elqortobi, M.; Laarej, A.; Dssouli, R. Model checking intelligent avionics systems fortest cases generation using multi-agent systems. Expert Syst. Appl. 2020, 156, 113458. [CrossRef]77. Menghi, C.; Garcia, S.; Pelliccione, P.; Tumova, J. Multi-robot LTL Planning Under Uncertainty. In Formal Methods; Springer:Berlin/Heidelberg, Germany, 2018; pp. 399\u2013417.78. Lacerda, B.; Lima, P.U. Designing petri net supervisors for multi-agent systems from LTL specifications. In International Conferenceon Autonomous Agents and Multiagent Systems-Volume 3; International Foundation for Autonomous Agents and MultiagentSystems: Taipei, Taiwan, 2011; pp. 1253\u20131254.79. Ghezzi, C.; Mandrioli, D.; Morzenti, A. TRIO: A logic language for executable specifications of real-time systems. J. Syst. Softw.1990, 12, 107\u2013123. [CrossRef]80. Behrmann, G.; David, A.; Larsen, K.G. A tutorial on uppaal. In Formal Methods for the Design of Real-Time Systems; Springer:Berlin/Heidelberg, Germany; Bertinoro, Italy, 2004; pp. 200\u2013236.81. Menghi, C.; Tsigkanos, C.; Berger, T.; Pelliccione, P. PsALM: Specification of Dependable Robotic Missions. In Proceedings of the2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion), Montreal,QC, Canada, 25\u201331 May 2019; pp. 99\u2013102. [CrossRef]82. Boufaied, C.; Menghi, C.; Bianculli, D.; Briand, L.; Parache, Y.I. Trace-Checking Signal-based Temporal Properties: A Model-Driven Approach. In Proceedings of the IEEE/ACM International Conference on Automated Software Engineering (ASE),Melbourne, Australia, 21\u201325 September 2020; pp. 1004\u20131015.83. Arcaini, P.; Mirandola, R.; Riccobene, E.; Scandurra, P. MSL: A pattern language for engineering self-adaptive systems. J. Syst.Softw. 2020, 164, 110558. [CrossRef]84. Musil, A.; Musil, J.; Weyns, D.; Bures, T.; Muccini, H.; Sharaf, M. Patterns for self-adaptation in cyber-physical systems. InMulti-Disciplinary Engineering for Cyber-Physical Production Systems; Springer: Berlin/Heidelberg, Germany, 2017; pp. 331\u2013368.85. Washizaki, H.; Uchida, H.; Khomh, F.; Gu\u00e9h\u00e9neuc, Y.G. Studying software engineering patterns for designing machine learningsystems. In Proceedings of the International Workshop on Empirical Software Engineering in Practice (IWESEP), Tokyo, Japan,13\u201314 December 2019; pp. 49\u2013495.86. Washizaki, H.; Ogata, S.; Hazeyama, A.; Okubo, T.; Fernandez, E.B.; Yoshioka, N. Landscape of architecture and design patternsfor iot systems. Internet Things J. 2020, 7, 10091\u201310101. [CrossRef]87. Garcia, A.; Silva, V.; Chavez, C.; Lucena, C. Engineering multi-agent systems with aspects and patterns. J. Braz. Comput. Soc.2002, 8, 57\u201372. [CrossRef]88. Juziuk, J.; Weyns, D.; Holvoet, T. Design patterns for multi-agent systems: A systematic literature review. In Agent-OrientedSoftware Engineering; Springer: Berlin/Heidelberg, Germany, 2014; pp. 79\u201399.89. Dastani, M.; Testerink, B. Design patterns for multi-agent programming. Int. J. Agent-Oriented Softw. Eng. 2016, 5, 167\u2013202.[CrossRef]J. Sens. Actuator Netw. 2021, 10, 33 22 of 2490. Challenger, M.; Kardas, G.; Tekinerdogan, B. A systematic approach to evaluating domain-specific modeling language environ-ments for multi-agent systems. Softw. Qual. J. 2016, 24, 755\u2013795. [CrossRef]91. Challenger, M.; Demirkol, S.; Getir, S.; Mernik, M.; Kardas, G.; Kosar, T. On the use of a domain-specific modeling language in thedevelopment of multiagent systems. Eng. Appl. Artif. Intell. 2014, 28, 111\u2013141. [CrossRef]92. Bauer, B.; M\u00fcller, J.P.; Odell, J. Agent UML: A formalism for specifying multiagent software systems. Int. J. Softw. Eng. Knowl.Eng. 2001, 11, 207\u2013230. [CrossRef]93. Garc\u00eda, S.; Pelliccione, P.; Menghi, C.; Berger, T.; Bures, T. High-level mission specification for multiple robots. In Proceedingsof the ACM SIGPLAN International Conference on Software Language Engineering, Athens, Greece, 20\u201322 October 2019;pp. 127\u2013140.94. Brazier, F.M.T.; Dunin-Keplicz, B.; Jennings, N.R.; Treur, J. Formal Specification of Multi-Agent Systems: A Real-World Case.In Proceedings of the First International Conference on Multiagent Systems, San Francisco, CA, USA, 12\u201314 June 1995; The MITPress: Cambridge, MA, USA, 1995; pp. 25\u201332.95. Van Langevelde, I.; Philipsen, A.; Treur, J. Formal Specification of Compositional Architectures. In ECAI\u201992: European Conferenceon Artificial Intelligence; John Wiley & Sons, Inc.: Hoboken, NJ, USA, 1992; pp. 272\u2013276.96. Bergenti, F.; Monica, S.; Petrosino, G. A scripting language for practical agent-oriented programming. In ACM SIGPLANInternational Workshop on Programming Based on Actors, Agents, and Decentralized Control; Association for Computing Machinery:New York, NY, USA, 2018; pp. 62\u201371.97. Aeronautiques, C.; Howe, A.; Knoblock, C.; McDermott, I.D.; Ram, A.; Veloso, M.; Weld, D.; SRI, D.W.; Barrett, A.; Christianson, D.;et al. PDDL|The Planning Domain Definition Language; Technical Report; Yale Center for Computational Vision and Control: NewHaven, CT, USA, 1998.98. Giunchiglia, F.; Mylopoulos, J.; Perini, A. The tropos software development methodology: Processes, models and diagrams. InInternational Workshop on Agent-Oriented Software Engineering; Springer: Berlin/Heidelberg, Germany, 2002; pp. 162\u2013173.99. Wooldridge, M.; Jennings, N.R.; Kinny, D. The Gaia methodology for agent-oriented analysis and design. Auton. AgentsMulti-Agent Syst. 2000, 3, 285\u2013312. [CrossRef]100. Tran, N.; Beydoun, G.; Low, G. Design of a peer-to-peer information sharing MAS using MOBMAS (ontology-centric agentoriented methodology). In Advances in Information Systems Development; Springer: Berlin/Heidelberg, Germany, 2007; pp. 63\u201376.101. Nicolescu, M.N.; Mataric, M.J. Natural methods for robot task learning: Instructive demonstrations, generalization and practice.In Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, Melbourne, Australia,14\u201318 July 2003; pp. 241\u2013248.102. Verstaevel, N.; Boes, J.; Nigon, J.; d\u2019Amico, D.; Gleizes, M.P. Lifelong machine learning with adaptive multi-agent systems.In Proceedings of the International Conference on Agents and Artificial Intelligence (ICAART 2017), Porto, Portugal, 24\u201326February 2017; Volume 2, p. 275.103. Wang, X.; Klabjan, D. Competitive multi-agent inverse reinforcement learning with sub-optimal demonstrations. In Proceedingsof the 35th International Conference on Machine Learning, Stockholm, Sweden, 10\u201315 July 2018; pp. 5143\u20135151.104. Le, H.M.; Yue, Y.; Carr, P.; Lucey, P. Coordinated multi-agent imitation learning. In Proceedings of the 34th InternationalConference on Machine Learning, Sydney, Australia, 6\u201311 August 2017; pp. 1995\u20132003.105. Bellifemine, F.L.; Caire, G.; Greenwood, D. Developing Multi-Agent Systems with JADE; Wiley: Hoboken, NJ, USA, 2007.106. Coelho, R.; Kulesza, U.; von Staa, A.; Lucena, C. Unit Testing in Multi-Agent Systems Using Mock Agents and Aspects. InSELMAS\u201906: International Workshop on Software Engineering for Large-Scale Multi-Agent Systems; ACM: New York, NY, USA, 2006;pp. 83\u201390. [CrossRef]107. Coelho, R.; Cirilo, E.; Kulesza, U.; von Staa, A.; Rashid, A.; Lucena, C. JAT: A Test Automation Framework for Multi-AgentSystems. In Proceedings of the IEEE International Conference on Software Maintenance, Paris, France, 2\u20135 October 2007;pp. 425\u2013434.108. Amaral, C.J.; Kampik, T.; Cranefield, S. A Framework for Collaborative and Interactive Agent-Oriented Developer Operations.In AAMAS\u201920: Proceedings of the International Conference on Autonomous Agents and MultiAgent Systems; International Foundationfor Autonomous Agents and Multiagent Systems: Richland, SC, USA, 2020; pp. 2092\u20132094.109. Amaral, C.J.; H\u00fcbner, J.F. Jacamo-Web is on the Fly: An Interactive Multi-Agent System IDE. In Engineering Multi-Agent Systems;Springer: Berlin/Heidelberg, Germany, 2020; pp. 246\u2013255.110. Tiryaki, A.M.; \u00d6ztuna, S.; Dikenelli, O.; Erdur, R.C. SUNIT: A Unit Testing Framework for Test Driven Development ofMulti-Agent Systems. In Agent-Oriented Software Engineering VII; Springer: Berlin/Heidelberg, Germany, 2007; pp. 156\u2013173.111. Nguyen, C.D.; Perini, A.; Tonella, P. Automated Continuous Testing of MultiAgent Systems. In Proceedings of the EuropeanWorkshop on Multi-Agent Systems (EUMAS), Hammamet, Tunisia, 13\u201314 December 2007.112. Nguyen, C.D.; Perini, A.; Tonella, P.; Miles, S.; Harman, M.; Luck, M. Evolutionary Testing of Autonomous Software Agents.In AAMAS\u201909: Proceedings of the International Conference on Autonomous Agents and Multiagent Systems\u2014Volume 1; InternationalFoundation for Autonomous Agents and Multiagent Systems: Richland, SC, USA, 2009; pp. 521\u2013528.113. Lam, D.N.; Barber, K.S. Debugging Agent Behavior in an Implemented Agent System. In Programming Multi-Agent Systems;Springer: Berlin/Heidelberg, Germany, 2005; pp. 104\u2013125.J. Sens. Actuator Netw. 2021, 10, 33 23 of 24114. Zhang, Z.; Thangarajah, J.; Padgham, L. Model Based Testing for Agent Systems. In AAMAS\u201909: Proceedings of the InternationalConference on Autonomous Agents and Multiagent Systems\u2014Volume 2; International Foundation for Autonomous Agents andMultiagent Systems: Richland, SC, USA, 2009; pp. 1333\u20131334.115. Padmanaban, R.; Thirumaran, M.; Suganya, K.; Priya, R.V. AOSE Methodologies and Comparison of Object Oriented and AgentOriented Software Testing. In ICIA-16: Proceedings of the International Conference on Informatics and Analytics; ACM: New York, NY,USA, 2016. [CrossRef]116. Carrera, \u00c1.; Iglesias, C.; Garijo, M. Beast methodology: An agile testing methodology for multi-agent systems based on behaviourdriven development. Inf. Syst. Front. 2014, 16, 169\u2013182. [CrossRef]117. Braubach, L.; Pokahr, A.; Lamersdorf, W. Jadex: A BDI-Agent System Combining Middleware and Reasoning. In SoftwareAgent-Based Applications, Platforms and Development Kits; Birkh\u00e4user Basel: Basel, Switzerland, 2005; pp. 143\u2013168.118. Huang, Z.; Alexander, R.; Clark, J. Mutation Testing for Jason Agents. In Engineering Multi-Agent Systems; Springer:Berlin/Heidelberg, Germany, 2014; pp. 309\u2013327.119. Benac Earle, C.; Fredlund, L.\u00c5. A Property-Based Testing Framework for Multi-Agent Systems. In AAMAS\u201919: Proceedings of theInternational Conference on Autonomous Agents and MultiAgent Systems; International Foundation for Autonomous Agents andMultiagent Systems: Richland, SC, USA, 2019; pp. 1823\u20131825.120. Claessen, K.; Hughes, J. QuickCheck: A Lightweight Tool for Random Testing of Haskell Programs. SIGPLAN Not. 2000,35, 268\u2013279. [CrossRef]121. Briola, D.; Mascardi, V.; Ancona, D. Distributed Runtime Verification of JADE and Jason Multiagent Systems with Prolog. InProceedings of the Conference on Computational Logic, Torino, Italy, 16\u201318 June 2014; Volume 1195, pp. 319\u2013323.122. Ancona, D.; Briola, D.; Ferrando, A.; Mascardi, V. MAS-DRiVe: A Practical Approach to Decentralized Runtime Verification ofAgent Interaction Protocols. In Proceedings of the Workshop \u201cFrom Objects to Agents\u201d Co-Located with 18th European AgentSystems Summer School (EASSS 2016), Catania, Italy, 29\u201330 June 2016; Volume 1664, pp. 35\u201343.123. Mascardi, V.; Ancona, D. Attribute Global Types for Dynamic Checking of Protocols in Logic-based Multiagent Systems. TheoryPract. Log. Program. 2013, 13, 4\u20135.124. Mascardi, V.; Briola, D.; Ancona, D. On the Expressiveness of Attribute Global Types: The Formalization of a Real MultiagentSystem Protocol. In AI*IA 2013: Advances in Artificial Intelligence\u2014XIIIth International Conference of the Italian Association for ArtificialIntelligence; Springer: Berlin/Heidelberg, Germany, 2013; Volume 8249, pp. 300\u2013311.125. Ancona, D.; Briola, D.; Ferrando, A.; Mascardi, V. Runtime verification of fail-uncontrolled and ambient intelligence systems: Auniform approach. Intell. Artif. 2015, 9, 131\u2013148. [CrossRef]126. Dennis, L.A. The MCAPL Framework including the Agent Infrastructure Layer and Agent Java Pathfinder. J. Open Source Softw.2018, 3. [CrossRef]127. Mengistu, D.; Tr\u00f6ger, P.; Lundberg, L.; Davidsson, P. Scalability in Distributed Multi-Agent Based Simulations: The JADE Case.In Proceedings of the Second International Conference on Future Generation Communication and Networking Symposia, Hinan,China, 13\u201315 December 2008; Volume 5, pp. 93\u201399. [CrossRef]128. Lo Piccolo, F.; Bianchi, G.; Salsano, S. Measurement Study of the Mobile Agent JADE Platform. In Proceedings of the InternationalSymposium on on World of Wireless, Mobile and Multimedia Networks, Buffalo-Niagara Falls, NY, USA, 26\u201329 June 2006; pp.638\u2013646.129. Briola, D.; Micucci, D.; Mariani, L. A platform for P2P agent-based collaborative applications. Softw. Pract. Exp. 2019, 49, 549\u2013558.[CrossRef]130. Aprameya Rao, I.V.; Jain, M.; Karlapalem, K. Towards Simulating Billions of Agents in Thousands of Seconds. In AAMAS\u201907:Proceedings of the 6th International Joint Conference on Autonomous Agents and Multiagent Systems; ACM: New York, NY, USA, 2007.131. Gormer, J.; Homoceanu, G.; Mumme, C.; Huhn, M.; Muller, J.P. JREP: Extending Repast Simphony for JADE Agent BehaviorComponents. In Proceedings of the IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent AgentTechnology, Lyon, France, 22\u201327 August 2011; Volume 2, pp. 149\u2013154. [CrossRef]132. North, M.; Howe, T.; Collier, N.; Vos, J. Repast Simphony runtime system. In Proceedings of the Agent 2005 Conference onGenerative Social Processes, Models, and Mechanisms, Chicago, IL, USA, 13\u201315 October 2005.133. Yoo, M.J.; Glardon, R. Combining JADE and Repast for the Complex Simulation of Enterprise Value-Adding Networks. InAgent-Oriented Software Engineering IX; Springer: Berlin/Heidelberg, Germany, 2009; pp. 243\u2013256.134. Cardoso, H.L. SAJaS: Enabling JADE-Based Simulations. In Transactions on Computational Collective Intelligence XX; Springer:Berlin/Heidelberg, Germany, 2015; pp. 158\u2013178. [CrossRef]135. Lopes, J.; Cardoso, H. From simulation to development in MAS a JADE-based approach. In Proceedings of the ICAART\u2014International Conference on Agents and Artificial Intelligence, Lisbon, Portugal, 10\u201312 January 2015; Volume 1, pp. 75\u201386.136. Carpin, S.; Lewis, M.; Wang, J.; Balakirsky, S.; Scrapper, C. USARSim: A robot simulator for research and education. InProceedings of the IEEE International Conference on Robotics and Automation, Rome, Italy, 10\u201314 April 2007; pp. 1400\u20131405.137. Brian P. Gerkey, R.T.V.; Howard, A. The Player/Stage Project: Tools for Multi-Robot and Distributed Sensor Systems. InProceedings of the International Conference on Advanced Robotics, Coimbra, Portuga, 30 June\u20133 July 2003; pp. 317\u2013323.138. Echeverria, G.; Lassabe, N.; Degroote, A.; Lemaignan, S. Modular open robots simulation engine: MORSE. In Proceedings of theIEEE International Conference on Robotics and Automation, Shanghai, China, 9\u201313 May 2011; pp. 46\u201351.J. Sens. Actuator Netw. 2021, 10, 33 24 of 24139. Koenig, N.; Howard, A. Design and Use Paradigms for Gazebo, An Open-Source Multi-Robot Simulator. In Proceedings ofthe IEEE/RSJ International Conference on Intelligent Robots and Systems, Sendai, Japan, 28 September\u20132 October 2004; pp.2149\u20132154.140. Kahn, P.H.; Freier, N.G.; Kanda, T.; Ishiguro, H.; Ruckert, J.H.; Severson, R.L.; Kane, S.K. Design patterns for sociality inhuman\u2013robot interaction. In Proceedings of the ACM/IEEE International Conference on Human Robot Interaction, Amsterdam,The Netherlands, 12\u201315 March 2008; pp. 97\u2013104.141. Ligthart, M.; Fernhout, T.; Neerincx, M.A.; van Bindsbergen, K.L.; Grootenhuis, M.A.; Hindriks, K.V. A child and a robot gettingacquainted-interaction design for eliciting self-disclosure. In Proceedings of the International Conference on Autonomous Agentsand Multiagent Systems, Montreal, QC, Canada, 13\u201317 May 2019; pp. 61\u201370.142. Neerincx, M.A.; van der Waa, J.; Kaptein, F.; van Diggelen, J. Using perceptual and cognitive explanations for en-hanced human\u2013agent team performance. In International Conference on Engineering Psychology and Cognitive Ergonomics;Springer:Berlin/Heidelberg, Germany, 2018; pp. 204\u2013214.143. Amershi, S.; Weld, D.; Vorvoreanu, M.; Fourney, A.; Nushi, B.; Collisson, P.; Suh, J.; Iqbal, S.; Bennett, P.N.; Inkpen, K.; et al.Guidelines for human-AI interaction. In Proceedings of the Chi Conference on Human Factors in Computing Systems, Glasgow,UK, 4\u20139 May 2019; pp. 1\u201313.144. Ramchurn, S.D.; Wu, F.; Jiang, W.; Fischer, J.E.; Reece, S.; Roberts, S.; Rodden, T.; Greenhalgh, C.; Jennings, N.R. Human\u2013agentcollaboration for disaster response. Auton. Agents Multi-Agent Syst. 2016, 30, 82\u2013111. [CrossRef]145. Orsag, M.; Haus, T.; Tolic\u0301, D.; Ivanovic, A.; Car, M.; Palunko, I.; Bogdan, S. Human-in-the-loop control of multi-agent aerialsystems. In Proceedings of the 2016 European Control Conference (ECC), Aalborg, Denmark, 29 June\u20131 July 2016; pp. 2139\u20132145.146. Feng, L.; Wiltsche, C.; Humphrey, L.; Topcu, U. Synthesis of human-in-the-loop control protocols for autonomous systems. IEEETrans. Autom. Sci. Eng. 2016, 13, 450\u2013462. [CrossRef]147. Cummings, M.; Clare, A. Holistic modelling for human-autonomous system interaction. Theor. Issues Ergon. Sci. 2015, 16, 214\u2013231.[CrossRef]148. Kolling, A.; Walker, P.; Chakraborty, N.; Sycara, K.; Lewis, M. Human interaction with robot swarms: A survey. IEEE Trans.Hum.-Mach. Syst. 2015, 46, 9\u201326. [CrossRef]149. Selkowitz, A.; Lakhmani, S.; Chen, J.Y.; Boyce, M. The effects of agent transparency on human interaction with an autonomousrobotic agent. In Human Factors and Ergonomics Society Annual Meeting; SAGE Publications Sage CA: Los Angeles, CA, USA, 2015;Volume 59, pp. 806\u2013810.150. Schaefer, K.E.; Straub, E.R.; Chen, J.Y.; Putney, J.; Evans, A.W., III. Communicating intent to develop shared situation awarenessand engender trust in human\u2013agent teams. Cogn. Syst. Res. 2017, 46, 26\u201339. [CrossRef]151. Winikoff, M. Towards trusting autonomous systems. In International Workshop on Engineering Multi-Agent Systems; Springer:Berlin/Heidelberg, Germany, 2017; pp. 3\u201320.152. Miller, T. Explanation in artificial intelligence: Insights from the social sciences. Artif. Intell. 2019, 267, 1\u201338. [CrossRef]153. Koeman, V.J.; Dennis, L.A.; Webster, M.; Fisher, M.; Hindriks, K. The \u201cWhy did you do that?\u201d Button: Answering Why-questionsfor end users of Robotic Systems. In International Workshop on Engineering Multi-Agent Systems; Springer: Berlin/Heidelberg,Germany, 2019; pp. 152\u2013172.154. Rosenfeld, A.; Richardson, A. Explainability in human\u2013agent systems. Auton. Agents Multi-Agent Syst. 2019, 33, 673\u2013705.[CrossRef]155. Chakraborti, T.; Sreedharan, S.; Zhang, Y.; Kambhampati, S. Plan explanations as model reconciliation: Moving beyondexplanation as soliloquy. In Proceedings of the International Joint Conference on Artificial Intelligence, Melbourne, Australia,19\u201325 August 2017; pp. 156\u2013163.",
      "id": 275336674,
      "identifiers": [
        {
          "identifier": "630963064",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:aisberg.unibg.it:10446/237253",
          "type": "OAI_ID"
        },
        {
          "identifier": "10.3390/jsan10020033",
          "type": "DOI"
        }
      ],
      "title": "Agents and robots for reliable engineered autonomy: A perspective from the organisers of area 2020",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:aisberg.unibg.it:10446/237253"
      ],
      "publishedDate": "2021-01-01T00:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "https://aisberg.unibg.it/bitstream/10446/237253/1/jsan-10-00033-v2.pdf"
      ],
      "updatedDate": "2025-05-09T14:52:07",
      "yearPublished": 2021,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/630963064.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/630963064"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/630963064/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/630963064/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/275336674"
        }
      ]
    },
    {
      "acceptedDate": "2007-07-23T00:00:00",
      "arxivId": null,
      "authors": [
        {
          "name": "Anton Nijholt"
        },
        {
          "name": "E Bowring"
        },
        {
          "name": "H Nakanishi"
        },
        {
          "name": "J Sellen"
        },
        {
          "name": "JF Nunamaker Jr"
        },
        {
          "name": "LK Tracy"
        },
        {
          "name": "M Deutsch"
        },
        {
          "name": "P Barthelmess"
        },
        {
          "name": "P Cook"
        },
        {
          "name": "Paulo Barthelmess"
        },
        {
          "name": "PM Berry"
        },
        {
          "name": "R Oehlmann"
        },
        {
          "name": "R Rienks"
        },
        {
          "name": "R Rienks"
        },
        {
          "name": "Rutger Rienks"
        },
        {
          "name": "S Shum"
        },
        {
          "name": "TL Ruble"
        }
      ],
      "citationCount": 0,
      "contributors": [
        "Miura, A.",
        "Matsumura, N."
      ],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/572162469",
        "https://api.core.ac.uk/v3/outputs/191409979"
      ],
      "createdDate": "2013-07-10T17:28:11",
      "dataProviders": [
        {
          "id": 4786,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/4786",
          "logo": "https://api.core.ac.uk/data-providers/4786/logo"
        },
        {
          "id": 363,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/363",
          "logo": "https://api.core.ac.uk/data-providers/363/logo"
        }
      ],
      "depositedDate": "2007-07-24T00:00:00",
      "abstract": "This paper gives an overview of pro-active meeting assistants, what they are and when they can be useful. We explain how to develop such assistants with respect to requirement definitions and elaborate on a set of Wizard of Oz experiments, aiming to find out in which form a meeting assistant should operate to be accepted by participants and whether the meeting effectiveness and efficiency can be improved by an assistant at all. This paper gives an overview of pro-active meeting assistants, what they are and when they can be useful. We explain how to develop such assistants with respect to requirement definitions and elaborate on a set of Wizard of Oz experiments, aiming to find out in which form a meeting assistant should operate to be accepted by participants and whether the meeting effectiveness and efficiency can be improved by an assistant at all",
      "documentType": "research",
      "doi": "10.1007/s00146-007-0135-0",
      "downloadUrl": "https://core.ac.uk/download/pdf/11467800.pdf",
      "fieldOfStudy": null,
      "fullText": "ORI GIN AL ARTICLE\nPro-active meeting assistants: attention please!\nRutger Rienks \u00c6 Anton Nijholt \u00c6 Paulo Barthelmess\nReceived: 25 July 2006 / Accepted: 10 April 2007 / Published online: 24 July 2007\n\u0001 Springer-Verlag London Limited 2007\nAbstract This paper gives an overview of pro-active meeting assistants, what they\nare and when they can be useful. We explain how to develop such assistants with\nrespect to requirement definitions and elaborate on a set of Wizard of Oz experi-\nments, aiming to find out in which form a meeting assistant should operate to be\naccepted by participants, and whether the meeting effectiveness and efficiency can\nbe improved by an assistant at all. This paper gives an overview of pro-active\nmeeting assistants, what they are and when they can be useful. We explain how to\ndevelop such assistants with respect to requirement definitions and elaborate on a set\nof Wizard of Oz experiments, aiming to find out in which form a meeting assistant\nshould operate to be accepted by participants, and whether the meeting effectiveness\nand efficiency can be improved by an assistant at all.\nIntroduction\nMeetings are often inefficient (Romano Jr and Nunamaker Jr 2001). Starting with\nprobably the first meeting ever held by humans, people have looked at techniques\nR. Rienks (&) \u0001 A. Nijholt\nHuman Media Interaction Group (HMI), University of Twente, PO Box 217,\n7500 AE Enschede, The Netherlands\ne-mail: rienks@ewi.utwente.nl\nURL: http://hmi.ewi.utwente.nl/\nA. Nijholt\ne-mail: anijholt@ewi.utwente.nl\nP. Barthelmess\nNatural Interaction Systems, Portland, OR, USA\ne-mail: Paulo.Barthelmess@naturalinteraction.com\nURL: http://www.naturalinteraction.com/\n123\nAI & Soc (2009) 23:213\u2013231\nDOI 10.1007/s00146-007-0135-0\nand protocols to enhance them. The development of technology to support meetings\nhas therefore long been a subject of research (Turoff and Hiltz 1977).\nMeetings can nowadays be assisted by a wide variety of tools and technologies,\nfacilitating interaction, saving money and time and creating opportunities that\nwould not be possible without technology. The foremost benefit of technology so far\nis its support for meetings in which participants are distributed.\nBeing able to attend meetings remotely results in substantial savings of time and\nmoney that might have been otherwise spent on travel. Tele-conferencing systems\naugmented by additionally advanced services such as instant messaging, file transfer\nand application sharing are becoming more and more prevalent. In the near future\nmeetings will be possible in virtual worlds where participants will be represented by\nvirtual humans (Nijholt et al. 2005).\nThere is also evidence that technology-enabled processes can positively impact\nmeeting performance. Studies reported by De Vreede et al. (2003) and Nunamaker\nJr et al. (1995) show a significant reduction in labor cost and overall project duration\nwhen Group Support Systems (GSS), or Electronic Meeting Systems are used.\nThese systems support alternative, technology-enabled meeting processes that can\nhelp participants with the formulation of and search for solutions to \u2018problems\u2019\nlisted on the agenda. A participant generally has a computer terminal connected to a\ncentral server at his or her disposal through which several problem resolution tools\nare available. Typical tools are an electronic brainstorming tool, an idea organizer, a\ntopic commenter and a voting support tool.\nDespite the huge savings and proven increased efficiency brought about by GSS\nand similar technology, its adoption has proven to be sometimes problematic. There\nare instances in which the use of these systems has been discontinued due to the\nobjections of the stakeholders to the (radical) changes in the work practice that are\nintroduced (Nunamaker Jr et al. 1995). This leads us to investigate alternative means\nfor positively influencing meeting outcomes in ways that would encounter less\nresistance. In particular, we want to investigate how pro-active meeting assistants\ncan be exploited to reap the benefits of technology-enabled meetings instead of\nbeing exposed to its drawbacks. Successful automated meeting assistants can\npotentially integrate themselves into their surrounding social environment, offering\nsupport that blends more seamlessly into users\u2019 work practices.\nTechnology in the field of meeting support ranges from completely passive\nobjects like microphones to pro-active autonomous actors such as virtual meeting\nparticipants. In earlier work we defined several dimensions that can be distinguished\nin this spectrum, with the major ones being the reasoning ability, the acting ability\nand the sensing ability (Rienks et al. 2005b). In this paper we will focus on pro-\nactive meeting assistants that are able to act autonomously. Pro-active meeting\nassistants are those that (preferably in real-time) support the participants and act\nautonomously in the process either before, during or after a meeting. For these type\nof assistants, their operating dimensions are highly dependent on their functionality.\nThis functionality or sophistication directly depends on the state of the art of\nautomatic collection of appropriate meeting information (the sensing) as well as the\nrequired intelligence to use it (its reasoning ability) and the means through which\nthe assistant can influence a meeting (its acting ability). To aid in this process,\n214 AI & Soc (2009) 23:213\u2013231\n123\nso-called \u2018smart\u2019 meeting rooms appeared. These smart rooms embed all sorts of\nsensors, providing data about the meeting and hence create the opportunity to\ncollect and learn from this data in order to build models. These models may in turn\nprovide insights into interactions and their contents. The first project presenting\nideas to augment meetings with various \u2018smart\u2019 technologies was probably Project\nNick (Cook et al. 1978). This project discussed the incorporation of screens\ndisplaying both the agenda and live meeting statistics to aid the meeting process.\nFrom that point onward smart meeting rooms appeared at several institutions where\nlarge meeting corpora were recorded.\nIn the last 4\u20135 years there has been a surge in interest in meeting support. Many\nlarge projects were established, including consortia with partners from all over the\nglobe, working on meeting collection and research on meeting models and support\ntechnology (Nijholt et al. 2004; Waibel et al. 2004; IM2 Website; CALO Website;\nNectar Website).\nThe remainder of this paper will elaborate on the concept of pro-active meeting\nassistants, in particular software agents that aim to assist the meeting process and\nthereby facilitate more effective and efficient meetings. As there are a lot of ideas\nbut hardly any implemented systems yet, we will, apart from looking at the existing\nideas, show how to get from ideas to a full requirements specification. We also\npresent a Wizard of Oz experiment where we simulate several forms of pro-active\nmeeting assistants designed to streamline the meeting process.\nMeeting assistants\nMeeting assistants have been the topic of research in various projects, e.g., the\nNeem Project (Ellis and Barthelmess 2003; Barthelmess and Ellis 2005). In Neem, a\nbasic premise is that assistance has to be provided along multiple dimensions,\nincluding the organizational, but also the social and informational. A good meeting\nis one in which organizational goals are achieved, but not at the expense of the\nsocial well-being of a group. Support in Neem revolves around tools and virtual\nparticipants, both of which are designed to explore aspects along the organizational,\nsocial and informational dimensions. Tools are artifacts that crystallize certain\naspects of an interaction, allowing for participants to become aware of and be able\nto influence these aspects (e.g., by being able to manipulate items of discussion\nwithin an agenda tool). Virtual participants are anthropomorphic assistants. They\nare designed to have consistent personalities and well-determined roles. Kwaku is a\nvirtual participant that takes care of the organizational aspects of a meeting. Kwaku\nfor instance reacts to discussions that extend over the pre-allocated period of time\nby reminding participants that they might want to move on to the next agenda item.\nKwaku \u2018listens\u2019 to the reaction of the group (by examining transcribed speech and\ntext message channels) and will either update the agenda tool, moving it to the next\nagenda item in case of agreement, or leaving it in the current item if its perception is\nthat the suggestion was overruled by the group. Kwabena on the other hand is a\nsocial facilitator. Kwabena looks after the participants\u2019 social well-being, monitor-\ning the actions a group would want to undertake at each point in time, such as take a\nAI & Soc (2009) 23:213\u2013231 215\n123\nbreak, switch topics, change the level of detail or pace of the interaction. These\nwishes are expressed via a \u2018Moodbar\u2019 tool that displays a set of possible actions that\nparticipants can select by clicking on corresponding buttons.\nA mechanism is provided to poll the input from the different participants.\nKwabena takes the initiative to suggest the course of action (e.g., taking a break)\nexpressed by the group. (e.g., by voicing the suggestion via all participants\u2019 audio\nsystems.) Conversely, if a particular participant is expressing wishes that disagree\nwith the rest of the group, Kwabena communicates in private with this participant,\nletting him or her know that the rest of the group seems to think differently. Finally,\nKweisi is responsible for providing the group with additional information. This can\nhappen upon request of one or more participants, but also autonomously, as Kweisi\nperceives (again by analyzing the content of the speech and typed messages) that a\ncertain topic is under discussion for which additional documents are available.\nAll these assistants can be realized as embodied pervasive software systems that\noperate alone or in groups, interact with the users and with other participants and\nlearn user preferences. Neem illustrates an approach to assistance during the\nmeeting. We will now frame ongoing research in the domain of meeting assistants\nby dividing assistants that support activities that take place before, during as well as\nafter the meeting.\nAssistance for meeting preparation\nA first opportunity for assistance takes place at the meeting preparation phase.\nOpportunities during this phase can be related to the identification of the group of\npeople for whom a meeting\u2019s particular topics of discussion are of interest. Once it\nis assured a meeting will take place, a meeting planner can be used to assist with the\ncreation of the actual agenda and with the negotiation of schedule, time and place\nfor the meeting. There has been some research on agents that schedule meetings, for\nexample Garrido and Sycara (1995) and more recently Oh and Smith (2005).\nBowring et al. (2005) proposes the use of agents to optimize schedules given a set\nof personalized criteria. This is more or less similar to the personalized time\nmanagement system described in Berry et al. (2005) where a personal assistant is\ndescribed to have, amongst others, the ability to negotiate with other personal\nassistants for a suitable time and location given people\u2019s constraints or preferences.\nSuch preference-driven negotiations can lead to flexible scheduling of meetings. An\nassistant that has enough perception and reasoning capabilities could for instance\ntake advantage of its knowledge of people\u2019s whereabouts to schedule a meeting at a\ntime during which it knows the people involved will be in the same building, rather\nthan requiring them to waste time commuting on another less convenient day.\nBesides dealing with the instantiation of the meeting\u2019s agenda, its time and its\nlocation, another type of assistant could for example help with the choice of\nchairman based on the personalities of the participants (see the SYMLOG agent as\ndescribed in Wainer and Braga 2001). As Oehlmann (2006) mentions that\nexternalization of the social context of the group to its members, such as conflict\nresolution styles, does increase the harmony and trust amongst the group members,\nit would definitely be wise to have systems able to externalize and hypothesize the\n216 AI & Soc (2009) 23:213\u2013231\n123\nexpected group functioning. These sorts of assistants could then also advise on the\ndesired format of a meeting depending on the expected or possible attendees, or\npropose a group size for a meeting based on the topics of the agenda as mentioned in\nPadilha and Carletta (2003). Once the date and location are settled, assistants might\ninform participants about possible changes in the schedule and gather the documents\nto be discussed. Others could prepare the data projector, the light settings and\ntemperature settings of the room and schedule the presentations such as mentioned\nin Chen et al. (2004).\nAssistance during the meeting\nAntunes and Carrio (2003) describe three main aspects that pertain to meetings: the\nmeeting process, the meeting resources and the meeting roles. To optimize the\nmeeting process one could have assistants like Kwabena, Kwaku and Kweisi take\ncare of the participants\u2019 well-being, the organizational and the informational\naspects, respectively. Assistants could greet the participants and make them feel at\nease (Chen and Perich 2004). Other assistants could look after the content of the\nmeeting, by analyzing the semantics of the group discourse; it would then be\npossible to gauge the progress of a discussion (convergence/divergence), signal\npossible repetitions or determine the level of agreement or disagreement (Galley\net al. 2004). With respect to the meeting resources, once a meeting starts, the\ncontext of the meeting such as the room and equipment can be regulated (e.g., by\nclosing curtains, starting projectors, etc.)\u2014see Oh et al. (2001) for more examples.\nAn assistant could also alert participants when someone is calling them Danninger\net al. (2005), or provide background information about other participants. A final\ncategory of meeting assistants can aid specific meeting roles. In the best case the\ncomplete role of the secretary could be performed by an automated meeting\nassistant, as we could have an assistant that creates meeting minutes and takes over\nall care of other tasks pertaining to a secretary. The role of the chairman could be\nsimilarly assisted and eventually completely replaced by an automated assistant.\nThese are complex roles, and much work remains to be done before enough is\nachieved in terms of understanding the meeting dynamics and the issues related to\nthe integration of such assistants into meetings.\nAn assistant taking over the role of a meeting chairman should at the minimum\ntake care of the activities carried out by the human chairman. In a meeting, the\nchairman has to manage the meeting process in order to maximize the output of the\nmeeting, stick to the agenda and to maintain a positive meeting atmosphere.\nGuarding agenda and time constraints is an obvious task: taking care of the\ndecision-making process and trying to exploit the expertise of the meeting\nparticipants is much less obvious. All sorts of assistants could gather information\nthat could be useful in this respect. A chairman could, for example, be provided with\npoints of view expected from the participants, based on the known background of a\nparticipant or on the companies\u2019 viewpoints about a topic. All sorts of participants\u2019\nbehavior that could potentially influence the process might be of relevance for a\nchairman. Niekrasz and Purver (2005) describe the usage of a shared discourse\nontology that could serve as common ground for these sorts of assistants. We\nAI & Soc (2009) 23:213\u2013231 217\n123\nelaborate on the aspect of (semi-) automatic meeting understanding in Sect. 2.4,\nwhere we describe related research we have carried out. Other relevant abilities for\nan assistant in the role of a meeting chairman are, for example, described by Jebara\net al. (2000), where a system is able to provide feedback and ask relevant questions\nto stimulate further conversation.\nNakanishi et al. (2004) describe a system in the role of a party host, which tries\nto find a safe common topic of conversation for participants having trouble\ncommunicating. This system is able to generate a topic closely related to the\nongoing conversation based on a set of detected keywords and a topic tree prepared\nbeforehand. For more elaborate information about leadership issues and required\nabilities for a meeting chairman the reader is referred to (Sudweeks and Simoff\n2005; Misiolek and Heckman 2005).\nAssistance after the meeting\nThe preservation of meeting information, also referred to as group memory is a\nproblem due to the volatile nature of meetings. Apart from the fact that people\nmight be interested in things not captured in the notes, it might take hours to find\nanswers by digging through piles of hard-copy notes. After the meeting, assistants\ncould remind people of commitments and action items they are responsible for.\nOther assistants might analyze the interaction and produce documents and artifacts\nthat reflect the content of the discussions. An example of such a system is CALO\u2019s\nCharter (Kaiser et al. 2004); this suite of agents analyzes multimodal interaction\nduring project planning meetings and automatically produces MS-Project renditions\nof Gantt Charts sketched by participants on interactive boards, thus avoiding the\nmanual labor to reenter the information that would otherwise be necessary. More\nrecently, this system was extended to support collaborative sketching by multiple,\npotentially distributed participants Barthelmess et al. (2005).\nAssistants could also provide selective information about the meeting. Three\ncategories of people can be distinguished that might show interest in (parts of) the\ncontent or outcome of a meeting: (1) the actual participants, (2) people who did not\nattend the meeting interested in aspects such as the contributions of a person, or the\narguments in favor or against a specific decision and (3) analysts who are just\nwilling to gather information about meeting processes in general. The key issue is to\nprovide access to representations of conveyed information from the meeting as\nmentioned in Palotta et al. (2004). Once this information is available for access, it is\nshown that people will adapt their way of working based on what they have\navailable in order to increase efficiency (Moran et al. 1997). As it might be hard for\npeople to express their informational needs to an assistant, the interface is of utmost\nimportance. Jaimes et al. (2004) describes an implementation of a system that helps\nusers to easily express cues people might recall about a particular meeting. A related\narea of research is the automatic generation of (multimodal) summaries of a meeting\n(see e.g., Erol et al. 2003). In fact, a summary can be seen as an answer to a\nquestion, where the best summary is perhaps the one that answers the most\nfrequently asked questions. Ultimately, we would want assistants that would be able\n218 AI & Soc (2009) 23:213\u2013231\n123\nto answer all questions in a clear and comprehensible manner. For an overview of\napproaches providing access to meeting records see (Tucker and Whittaker 2005).\nA very important question here is what information should be captured (Shum\n1997), which is tightly related to what people would want to remember from\nmeetings. Lisowska (2003) gives an overview of typical queries posed to meeting\nretrieval systems, obtained through questionnaires, that in the future will be\nevaluated using a Wizard of Oz experiment. Similar research was conducted by\nBanerjee et al. (2005). It appears that people are interested in two kinds of\ninformation: (1) descriptions of the interactions among participants and (2) things\nthat involve elements from the meeting domain itself. In order to provide information\nabout the interaction amongst participants several techniques have to be developed,\nable to frame the understanding of what is going on in a meeting. Apart from\npreserving this data for people interested in it after the fact, this type of information\nwould also be highly relevant to almost any assistant operating during the meeting.\nThe next section will therefore elaborate on, and give pointers to ongoing research\nabout the automatic interpretation of human behavior in a meeting setting.\nInterpreting human behavior\nOnce a chairman is appointed and given the authority to manage the meeting process\nhe or she is authorized to perform a set of interventions such as selective turn-giving\nand interrupting. These typical actions are triggered on the basis of the behavior\ndisplayed by the participants. The occurrence of unwanted situations such as a rare\nevent with a large disturbing impact, or the repetitive occurrence of events with a\nsmaller disturbing impact, are typical examples of situations that could trigger an\nintervention. Human behavior reveals itself through several modalities over time.\nThe behavior of meeting participants is generally evaluated relative to social\nnorms and regulated by various means of social control. These norms generally are\nunstated and unwritten. The typical forms of social norms one might encounter in\nmeetings are that one should not yell or scream, that one should let people finish\ntalking, that one should not start private conversations, that one should not whisper\nand that one should not engage in \u2018ad hominem\u2019 arguments. These social norms or\nconventions define the shared belief of what is normal and acceptable and hence\nconstrain people\u2019s actions. Other restrictions are described by Tracy and Coupland\n(1990), stating that during a conversation a balance should be maintained between\nvarious levels of communication. An example of such a balance for a participant is\nthe one between the urge to immediately achieve one\u2019s agenda or objective (task\ngoal) on the one hand and to act in line with social norms and roles (face goal) on\nthe other hand. The intentions of the exhibited behavior are, amongst other things, a\ncombination of the social constraints, the individual agenda of the participants and\nthe amount of effort they are willing to put into realizing a set of predefined goals.\nTo explore some of these behavioral characteristics, one could, for example, analyze\nits frequency. Simple (possibly automatic) counting of occurrences could suffice in\norder to get some first impressions. The problem lies in the automatic detection of\nan observation. How does one know that a specific observation occurred and which\nsensors are required?\nAI & Soc (2009) 23:213\u2013231 219\n123\nThe Human Media Interaction (HMI) Group at Twente University has a long\ntradition of work in automatic observations of behavioral aspects. Currently HMI is\ntaking part in a European 6th Framework program called Augmented Multiparty\nInteraction (AMI), which is concerned with research on multimodal interaction, and,\nas the name suggests, multimodal interaction in a multiparty context. The AMI\nproject concentrates on multiparty interaction during meetings. The main aims of\nthe AMI project are to develop technologies for the disclosure of meeting content\nand to provide online support for (possibly remote) meetings. Our work consists,\namongst other things, of: automatic body pose estimation (Poppe et al. 2005),\nautomatic dominance detection (Rienks and Heylen 2005), addressee detection\n(Jovanovic et al. 2005), emotion analysis (Heylen et al. 2006) and analysis of\nargumentation patterns of meeting discussions (Rienks et al. 2005a). All of these\nareas represent open problems that are far from being solved and completely\nunderstood. On the other hand the results that are and will be achieved are without\ndoubt beneficial for all meeting assistants that will come to be developed in the\nfuture. The next section describes part of the process of how to develop an actual\nmeeting assistant. More specifically, it describes an effort to develop formal\nrequirements for a conflict managing meeting assistant (CMMA), which could work\nin conjunction with a meeting chairman.\nRequirements for a conflict managing meeting assistant\nThis section describes an excerpt of the work from Kernkamp (2006), explaining\nhow a CMMA can be specified in terms of functional requirements. How should\nsuch an assistant work? What information does it need from the meeting, what does\nit derive from this information and what specific actions should it undertake in order\nto avoid conflicts?\nIt is well known that conflicts between participants may disrupt meetings. In\norder to have an efficient meeting it is therefore usually better to avoid them. We\nforesee a CMMA as a system able to observe a meeting, for instance through\ncameras and microphones as in the AMI project, and able to detect emerging\nconflicts (i.e., escalating debates). The CMMA should in the end be able to act in\norder to prevent conflicts from escalating, e.g., through interruption or intervention\nby means of actuators such as a voice-over. An important step in the development\nphase of any system is the process of requirements engineering, which results in a\n(formal) specification explaining what the system should do. With this document,\nprogrammers and developers can start to build the software. The specification of\nrequirements is recognized as one of the important and difficult areas of systems\ndevelopment (Lauesen 2002). There has already been some research on user-\nrequirements for a meeting assistant. Tucker et al. (2005), for example, proposes to\nspecify user requirements by means of user cases in the context of a remote-meeting\nassistant. The process of requirements engineering has, however, never been tackled\nin the context of a CMMA. Our goal here is therefore threefold: We needed to\ndevise an appropriate specification technique, to identify obstructing conflict types\nand to develop a set of corresponding resolution strategies.\n220 AI & Soc (2009) 23:213\u2013231\n123\nWhat are meeting conflicts?\nA conflict is an open clash between two or more opposing groups (or individuals)\naiming for different objectives, or adhering to different norms. This incompatibility\nis the root cause of the conflict. These clashes generally escalate beyond the\ntraditional \u2018debate\u2019 and may eventually result in deleterious open antagonism. Note\nthat not all conflicts are bad and some conflicts should not be avoided (Deutsch\n2003). If a conflict takes a constructive course, the conflict can potentially be of\nconsiderable personal and social value as it is sometimes necessary to strengthen the\nrelations between team members and to improve productivity when it takes the form\nof a lively argument. It could prevent stagnation, and might stimulate interest and\ncuriosity. Although conflicts are known to be associated with disruption, violence\nand civil disorder, the negative connotation is not always appropriate. Hence, not all\nconflicts within organizational meetings should be suppressed. If, on the other hand,\nconflict seems to harm cooperation and productivity among the members of a team\nand the conflict takes a destructive course as in a bitter disagreement or when\nexpected to develop over a long period of time, there is room for our CMMA to\nintervene.\nDuncan (1996) has made an overview of various categories in which conflicts\nemerge. These categories are depicted in Fig. 1. This diagram shows the sources of\nconflict, their types and how they relate to the physical/psychological and \u2018in fact\u2019/\n\u2018in principle\u2019 aspects. A source of conflict could be for example a bad relationship\nbetween some of the meeting participants. This is a psychological and subjective\nconflict. An example of a subjective and \u2018in principle\u2019 conflict is for instance when\nsomeone\u2019s values or beliefs clash with the other participants\u2019 values or beliefs.\nTechniques to avoid conflicts\nIn order to avoid or to limit conflict, it is convenient to have a set of conflict\navoidance rules prepared, ready to be applied whenever a conflict emerges or seems\nabout to emerge. These rules legitimize some kinds of behavior and ascertain as a\nconsequence what is, and what is not allowed during the meeting.\nFig. 1 Sources of conflict\nAI & Soc (2009) 23:213\u2013231 221\n123\nIf an assistant that can apply the proper rules at the appropriate time can be\ncreated, meetings are likely to become more efficient. A simple example of such a\nrule is to establish that if off-topic discussions (e.g., because of conflict over\nresources) are detected, it could be useful to make a remark that will encourage the\nparticipants to get back on track. More sophisticated rules could be based on the\nfacilitation techniques described in Paulsen (2004), which elaborate on how a\nfacilitator creates a safe group environment where people are free to disagree with\neach other.\nHere we concern ourselves with a set of rules that can be applied to the types\nelaborated by Sellen et al. (2004), hereby excluding rules that physically interfere in\nthe meeting environment. Sellen\u2019s model distinguishes the following types of rules:\n\u2013 Boundary rules; define who is and who is not in the group and can detail the\npermeability of the group, i.e., whether members can easily enter or exit. It\ndetermines the extent to which norms developed within the group can be\nmaintained and shared and the extent to which groups can impose sanctions.\n\u2013 Aggregation rules; define how a group reaches a collective decision. This can be\nby majority, unanimity or \u2018anyone\u2019 rule. The unanimity rule is dangerous\nbecause if one person objects it can take a lot of time before an acceptable\nchoice is negotiated. The \u2018anyone\u2019 rule means any actor can impose a group\nchoice.\n\u2013 Position rules; define who can act at any point, so define to a great extent\nauthority. Some positions have higher authority than other (lower) positions.\n\u2013 Information rules; describe how information is shared and what each actor can\nknow, for instance, whether a member can know what other members have done\n(or what they are planning to do).\nOne could reduce conflicts by applying the position rule. This could take the form of\nthe appointment of a chairman with power to take measures against conflicts.\nChairmanship is associated with different rights, privileges and responsibilities that\ncharacterize leadership positions within an organizational structure. If these\nleadership positions or particular rules about positions are in place, a conflict is\nless likely to arise.\nApart from defining a list of possible rules that can be applied, there are several\nmodes or ways in which the rules can be enforced. Ruble and Thomas (1976), for\ninstance list the following: competing, collaborating, compromising, avoiding and\naccommodating.\nExamining real meeting conflicts\nTo get an idea about the most frequently occurring destructive conflicts ten student\ncommittee meetings were observed. Table 1 gives an overview of the most\ndestructive conflicts. For all of these, possible conflict resolution strategies have\nbeen created using the four types of rules from Sellen presented above. The possible\noptions are listed, together with their type in Table 1. It should be noted that this\nconflict list is solely based on the ten attended meetings and that there might be\nother conflicts having a much greater impact in other meetings. A second point to be\n222 AI & Soc (2009) 23:213\u2013231\n123\naware of is the fact that many other possible resolution rules could be thought of.\nThe exact rule as well as its desired mode of execution relates to the eventual\n\u2018personality\u2019 of the CMMA.\nCreating complete task descriptions\nAs a method to further specify the resolution strategies into functional requirements,\ntask descriptions were created. Task descriptions are domain level requirements,\nlisting what the user and the system should achieve together (Lauesen 2002;\nRobertson and Robertson 1999). They consist of structured texts that are easy to\nunderstand for the users as well as for the developers. Domain level requirements\nare useful for defining what is required, without describing how the product is going\nTable 1 Meeting conflicts and possible corresponding resolution rules\nNumber Conflict Rule\n9 Not all participants agree on the costs of an\nitem\nIt should be clear how this choice is to be\nmade and how a decision can be enforced.\nThis could either be done by using the\nmajority, unanimity or anyone rule. In many\ncases the majority rule should be applied so\nthe decision does not take too much time.\nWhen the costs are very high, the choice\nshould be made using the unanimity rule.\n(AR)\n7 Too many off-topic personal matters are\ndiscussed, annoying some of the\nparticipants\nDuring the meeting it should be clear which\ninformation is to be discussed. If everybody\nwants to chitchat, the meeting is to be\nadjourned for 10 min before being resumed\nor the discussion should be stopped through\nintervention. (IR and PR)\n6 Insufficient information is available causing a\nlot of superfluous discussions\nThe information should be available in the\nnext meeting, and the decision is to be\npostponed. (IR)\n6 Not everybody is equally talkative, or some\npersons are neglected.\nIf this person is expected to make valuable\ncontributions, he should be invited to give\nhis/her opinion. (BR)\n5 People with a relatively high authority and\nmuch experience neglect the chairman and\nkeep on arguing with each other\nIf this quarrel takes up too much time without\nbeing useful, an intervention should assure\nthat all participants stick to the current\nagenda. The persons should be requested to\ncatch up and told to talk about this outside\nthe meeting, the current status should be\nsummarized and then it is to be explained\nwhat is to be discussed. (PR)\n4 Personal habits and preferences differ between\nparticipants and they argue because of this\nQuarrels between participants about personal\npreferences and habits should be excluded\nfrom the meeting. Sanctions can be\nconsidered if the arguers do not comply.\n(BR)\nAR aggregation rule, BR boundary rule, PR position rule, IR information rule\nAI & Soc (2009) 23:213\u2013231 223\n123\nto look. In this case they focus on the tasks that are to be supported to avoid\ndestructive conflicts. Table 2 lists the task descriptions for the conflicts emerging\nwhen the participants do not agree on the costs of an item and when superfluous\ndiscussions emerge due to lack of information.\nThe first task Enforcing a Decision has a subtask that chooses the best conflict-\nhandling mode (see e.g., Ruble and Thomas 1976). The collaborative mode is the\nbest for a majority or unanimity decision, because when the decision is made, the\nchairman and the other participants must be heard in order to satisfy both their own\nTable 2 Task descriptions for the conflicts arising when not all participant agree on the costs of an item\nand when superfluous discussions emerge due to lack of information\nTask Enforcing a decision Controlling a discussion that started while\nlacking information\nPurpose To make a choice using the\nunanimity, anyone or majority\nrule\nTo shorten the meeting time, people\ncontinue trying to find the required\ninformation otherwise\nTrigger or\nprecondition\nA decision is to be made about\nsomething\nA discussion is started because of\nlittle or no information available\nFrequency Average: one decision\nevery 15 min\nAverage: one discussion due to insufficient\ninformation per meeting\nCritical More than ten participants in a\nmeeting\nMore than three discussions due to insufficient\ninformation\nSubtask Define the decision\nFor variant 1a and 1b: switch to\ncollaborative handling mode\nFor variant 1a: switch to competing handling\nmode, make a list of what information\nshould be available the next meeting,\nassign this task to the specific person(s),\ngo to next subject\nFor variant 1b: switch to compromising\nhandling mode, talk to the person\nresponsible for collection the specific\ninformation or the person with specific\nknowledge about this topic and ask the\nquickest way to get the information,\nassign the person who has to get the\ninformation, continue with the meeting if\npossible until the information is available\nFor variant 1c: switch to\naccommodation handling\nmode\nFill in which choice is made\nVariants\n1a The decision has to be made\nusing the unanimity rule\nThe subject can be discussed during the next\nmeeting\n1b The decision has to be made\nusing the majority rule\nThe subject is to be handled during this\nmeeting\n1c The decision has to be made using the\nanyone rule\nThe topic is important\n1d The decision can be postponed The topic is not really important\n224 AI & Soc (2009) 23:213\u2013231\n123\nand other concerns. With the \u2018anyone\u2019 rule, the accommodation mode should be\napplied in order to satisfy only the concerns of the experts. The second task deals\nwith an emerging discussion for which insufficient information is available. Here,\nthe compromise-handling mode should be applied if the discussion about the subject\nis to be concluded during the meeting. If the subject can be talked about during the\nnext meeting the competing mode should be applied, as one aims for a structured\nand efficient meeting.\nPutting the CMMA together\nIf properly constructed, the use of a CMMA sounds promising and has much\npotential. Although it obviously takes much more to develop a meeting assistant than\nwhat has been so far discussed, we have shown a first important step in its production\nprocess. Successful implementation will depend upon reliable detection of the\nrequired input parameters, as well as efficient implementation of the resolution\ninterventions. With respect to the CMMA, some specific remarks can be made. First\nand foremost, all meetings and people are different, resulting in more than just one\nsolution to avoid negative conflicts. The only thing the CMMA is designed for is to\nsuggest its best-known solution to a detected conflict. A second point is that in order\nto make a clearer distinction between what the system and the user should do, the task\ndescription defined above can be split up into user case descriptions. By doing so a\nclearer view of the role of the user and the role of the system is created, potentially\nproviding more insights in the design phase. A final point we address here is about\nquality requirements with respect to the usability of the system. Any meeting\nassistant, including the CMMA should in the end be easy and straightforward to use.\nBesides, interacting with such an assistant should not take too much time.\nPutting live meeting assistance to the test: does it work?\nIn work from DiMicco (2004) a system called Second Messenger is described that\nshows real-time text summaries of participants contributions. After increasing the\nvisibility of the less frequently speaking group members, it appeared that these\nstarted to speak more frequently than before, whereas the more dominant people\nstarted to speak 15% less. This shows that it is possible to build systems that are able\nto influence the meeting process. This section describes a summary of experiments\ninvestigating whether and in what form meeting assistants aiming at improving\nmeeting effectiveness can work in practice. See Kuperus (2006) and Broenink\n(2006) for the complete versions. The experiments try to find out how the\nappearance and associated actions of a meeting assistant can influence the\ninteraction with participants. How should the assistant intervene and act in order to\nbe obeyed and listened to?\nAnother goal of the experiments is to investigate if it is really true that meetings\ncan become more efficient when assistants are applied. The assistant used in all\nexperiments is simulated using a Wizard of Oz technique. This means that the\nmeeting participants are led to believe that they are interacting with an autonomous\nAI & Soc (2009) 23:213\u2013231 225\n123\nsystem, when in fact a human being controls the behavior of the system remotely.\nThis approach is highly suitable, as the implementation of a complete assistant is not\neasily feasible and it is expected that a good Wizard of Oz experiment will have\nnearly identical results.\nThe research setting\nThe research setting consisted of a meeting \u2018control center\u2019 with a computer outside\nthe room where meetings took place. Two monitors were connected to this\ncomputer. One of them was inside the room, one outside. The monitor outside the\nroom is used to control the interaction with the meeting and displays the live video\nfootage of the meeting coming from a DV camera located on the ceiling. A\nmicrophone is used to capture the audio inside the meeting room. Interaction with\nthe meeting takes place through the monitor and a speaker set inside the meeting\nroom. The \u2018control center\u2019 is placed on a moveable cart as meetings take place at\nvarious locations. The monitor and a speaker set are able to transmit information to\nthe participants. The consistency of the experiment was guaranteed by the creation\nof a script, which the agent followed.\nThe experiments\nAs a preliminary investigation to find out which aspects of the meeting were\nconsidered useful to influence, questionnaires were issued to 15 different chairmen;\n9 were fully completed and returned. Especially off-topic, balance and time\nindications were pointed out as useful. The chairmen also expected that information\npresented on a display would be more beneficial than voiced information. The\nscreen was expected to be less intrusive than the voice-over. (See Fig. 2a.)\nUsing this information, a set of four different systems with varying intrusiveness\nlevels was devised for the experiment. Table 3 shows descriptions of the systems\nranked from least to most intrusive according to the perceptions expressed in the\nquestionnaires. Two student committees (of eight and seven members respectively)\nwere subsequently exposed to all four versions of the system over a period of\n4 weeks. Before each meeting we asked the participants to provide the agenda\nincluding an expected time-line; the names of participants and the chairs they would\noccupy during the meeting. After each meeting questionnaires were issued in order\nto discover how the assistant and its actions were received by the meeting\nparticipants. Participants were asked, amongst other things, to rate on a 7 point scale\ntheir perception of the meeting\u2019s efficiency, the meeting being off-topic, the\nmeeting being balanced and the system\u2019s enjoyableness and intrusiveness. A control\ngroup of three more committees was used to correct for \u2018learning effects\u2019 that could\noccur as people get used to the system.\nSome findings and results\nTo verify whether meeting assisting agents can benefit the meeting process we\ncompared the predefined given agendas with the actual agendas of the meetings of\n226 AI & Soc (2009) 23:213\u2013231\n123\nthe various systems. The results averaged for the two groups are shown in Fig. 2b. It\nappears that when no system is used at all, the meetings lasted on an average 57%\nlonger than what had actually been planned. With System 3 we reached an\noptimum, shortening the meeting by 27%. Although the chairmen might have\nimproved their planning capabilities in the meantime, they were not informed about\nany of the results.\nFig. 2 Some results of the Wizard of Oz experiment\nTable 3 Description of the systems simulated for the experiment\nSystem Description\n1 Displays messages on a screen when an item is due to be finished in 5, 2 or 0 min. Also displays\nmessages when something is off-topic, a subject takes too long or when a discussion is\nunbalanced\n2 Similar to System 1, but instead of displaying messages, continuously displaying a clock\n3 Similar to System 1, but instead of displaying messages, voice samples were played\n4 A combination of Systems 1, 2 and 3. The clock is displayed and messages can be sent either\nto the screen or played as a voice sample\nAI & Soc (2009) 23:213\u2013231 227\n123\nWhen we look at the participants\u2019 ratings of degree of intrusiveness versus\nefficiency, Fig. 2d shows that the added intrusiveness of System 3 pays off in terms\nof meeting efficiency. Notable is the fact that the perceived efficiency appears to be\nin line with the actual efficiency. System 3 also resulted in a slight disturbance\nincrease, whereas its enjoyment is rated much lower than Systems 1 and 2 (see\nFig. 2c).\nAfter every session the chairmen were asked again to give their opinion about the\ndisturbance and efficiency for both the voice as well as the screen feedback\nstrategies. It appeared that in contrast to the pre-meeting questionnaire results, they\nnow rated them equally for efficiency. The voice messages were still found more\nintrusive than the text messages, though. An interesting side result was that when\nthe system uses voiced feedback, the participants of the meeting appeared to be\nmuch more aware of their own behavior. When they tended to go off-topic for\nexample they corrected themselves very quickly, sometimes saying: \u2018off-topic\u2019\nbefore continuing with the current item on the agenda. This is probably due to the\nfact that the system can speak directly to the specific participants; the participants\nwould therefore try to prevent being corrected by the system. After getting used to a\nsystem with voice output, the participants did notice and use the information, but\ndid not interrupt their talking. It should be noted that although the above findings\nspeak in favor of a system that assists the meeting process; a lot of additional\nresearch is required, for instance by examining a larger number of groups over a\nlonger period of time.\nConclusions\nWe have shown that there is potential for ambient intelligent systems that aid the\nmeeting process. We have discussed a wide variety of possible applications and\napplication areas. A concrete example of how requirements for a conflict\nmanagement meeting assistant can be developed has been given. We have shown\nthat the results of an experiment utilizing multiple system paradigms of varying\ndegree of intrusiveness; the experiments employed a Wizard of Oz technique. The\nresults show that meeting efficiency can be improved with respect to a baseline in\nwhich no meeting assistants are employed.\nAcknowledgments This work was partly supported by the European Union 6th FWP IST Integrated\nProject AMI (Augmented Multi-party Interaction, FP6-506811, publication AMI-154). Some material is\nbased upon work supported by the Defense Advanced Research Projects Agency (DARPA) under\nContract No. NBCHD030010. Any opinions, findings and conclusions or recommendations expressed in\nthis material are those of the author(s) and do not necessarily reflect the views of the DARPA or the\nDepartment of Interior-National Business Center (DOINBC). We thank Gerben Broenink, Johan Kuperus\nand Reinier Kernkamp for their efforts.\nReferences\nAntunes P, Carrio L (2003) Modeling the information structures of meetingware. In Proceedings of\nworkshop de Sistemas de Informao Multimedia e Cooperativos (COOP-MEDIA\u201903)\n228 AI & Soc (2009) 23:213\u2013231\n123\nBanerjee S, Rose C, Rudnicky AI (2005) The necessity of a meeting recording and playback system, and\nthe benefit of topic-level annotations to meeting browsing. In: Proceedings of the tenth international\nconference on Human\u2013Computer Interaction, Rome, Italy\nBarthelmess P, Ellis CA (2005) The neem platform: an evolvable framework for perceptual collaborative\napplications. J Intell Inf Syst 25(2):207\u2013240\nBarthelmess P, Kaiser E, Huang X, Demirdjian D (2005) Distributed pointing for multimodal\ncollaboration over sketched diagrams. In: International Conference on Multimodal Interfaces\u2014\nICMI, Trento, Italy\nBerry PM, Gervasio MT, Uribe TE, Pollack ME, Moffitt ME (2005) A personalized time management\nassistant: research directions. In: Saphiro D (ed) Persistant assistants: living and working with AI,\nworkshop at the AAAI spring symposium 2005. AAAI Press, Menlo Park\nBowring E, Tambe M, Yokoo M (2005) Optimize my schedule but keep it flexible: distributed multi-\ncriteria coordination for personal assistants. In: Saphiro D (ed) Persistant assistants: living and\nworking with AI, workshop at the AAAI spring symposium 2005. AAAI Press, Menlo Park\nBroenink EG (2006) How a computer actor influences the time-efficiency of a meeting. In: Proceedings of\nthe 4th Twente student conference on IT. Twente University Press, Enschede\nCALO Website. http : //www.ai.sri.com/project/calo/\nChen H, Perich F (2004) Intelligent agents meet semantic web in a smart meeting room. In: Proceedings\nof the third international joint conference on Autonomous Agents and Multi Agent Systems\n(AAMAS 2004), New York, USA\nChen H, Finin T, Joshi A (2004) A context broker for building smart meeting rooms. In: Proceedings of\nthe Knowledge Representation and Ontology for autonomous systems symposium, (AAAI spring\nsymposium). AAAI, Menlo Park\nCook P, Ellis CS, Graf M, Rein G, Smith T (1978) Project nick: meetings augmentation and analysis.\nACM Trans Inf Syst 5(2):132\u2013146\nDanninger M, Flaherty G, Bernardin K, Ekenel HK, Khler T, Malkin R, Stiefelhagen R, Waibel A (2005)\nThe connector\u2014facilitating context-aware communication. In: Proceedings of the international\nconference on Multimodal Interfaces, Trento, Italy\nDe Vreede GJ, Vogel D, Kolfschoten G, Wien J (2003) Fifteen years of GSS in the field: a comparison\nacross time and national boundaries. In: Proceedings of the 36th Hawaii international conference on\nSystem Sciences. IEEE Press, Big Island, HI\nDeutsch M (2003) International handbook of organizational teamwork and cooperative working, chapter\ncooperation and conflict: a personal perspective on the history of the social psychological study of\nconflict resolution. Wiley, New York, pp 9\u201344\nDiMicco JM (2004) Designing interfaces that influence group processes. In: doctoral consortium\nproceedings of the conference on Human Factors in Computer Systems (CHI 2004), CHI, Vienna\nDuncan M (ed) (1996) Effective meeting facilitation: sample forms, tools, and checklists. http://www.nea.\ngov/resources/Lessons/\nEllis CS, Barthelmess P (2003) The neem dream. In: Proceedings of the 2003 conference on Diversity in\ncomputing. ACM Press, New York, pp 23\u201329. ISBN 1-58113-790-7\nErol B, Lee D, Hull J (2003) Multimodal summarization of meeting recordings. In: Proceedings of the\nIEEE international conference on Multimedia and Expo (ICME 2003). IEEE, Baltimore, MD\nGalley M, McKeown K, Hirshberg J, Shriberg E (2004) Identifying agreement and disagreement in\nconversational speech: use of bayesian networks to model pragmatic dependencies. In: Proceedings\nof the 42nd annual meeting of the Association for Computational Linguistics (ACL), ACL, East\nStroudsburg, pp 669\u2013676\nGarrido L, Sycara K (1995) Multi-agent meeting scheduling: preliminary experimental results. In: Victor\nLesser (ed) Proceedings of the first international conference on Multi-Agent Systems (ICMAS\u201995).\nThe MIT Press, Cambridge\nHeylen D, Nijholt A, Reidsma D (2006) Determining what people feel and think when interacting with\nhumans and machines: notes on corpus collection and annotation. In: Proceedings 1st California\nconference on Recent Advances in Engineering Mechanics (to appear), California State University,\nFullerton\nIM2 Website. http: //www.im2.ch/\nJaimes A, Omura K, Nagamine T, Hirata K (2004) Memory cues for meeting video retrieval. In:\nCARPE\u201904: Proceedings of the the 1st ACM workshop on Continuous archival and retrieval of\npersonal experiences. ACM Press, New York, pp 74\u201385\nAI & Soc (2009) 23:213\u2013231 229\n123\nJebara T, Ivanov Y, Rahimi A, Pentland A (2000) Tracking conversational context for machine mediation\nof human discourse. In: AAAI fall 2000 symposium\u2014Socially Intelligent Agents\u2014The Human in\nthe Loop, North Falmouth, MA\nJovanovic N, Op den Akker H, Nijholt A (2005) A corpus for studying addressing behavior in multi-party\ndialogues. In: Proceedings of the sixth SigDial conference on Discourse and Dialogue\nKaiser E, Demirdjian D, Gruenstein A, Li X, Niekrasz J, Wesson M, Kumar S (2004) Demo: a\nmultimodal learning interface for sketch, speak and point creation of a schedule chart. In:\nProceedings of the international conference on Multimodal Interfaces\u2014ICMI\u201904. ICMI, State\nCollege, pp 329\u2013330\nKernkamp RRJ (2006) Functional requirements for a conflict managing meeting assistant. In: Proceedings\nof the 4th Twente student conference on IT. Twente University Press, Enschede\nKuperus J (2006) The effect of agents on meetings. In: Proceedings of the 4th Twente student conference\non IT. Twente University Press, Enschede\nLauesen S (ed) (2002) Software requirements\u2014styles and techniques. Addison Wesley, Boston. ISBN 0-\n201-74570-4\nLisowska A (2003) Multimodal interface design for the multimodal meeting domain: preliminary\nindications from a query analysis study. Technical report, ISSCO/TIM/ETI, Universit de Genve,\nGeneva, IM2.MDM Report 11\nMisiolek N, Heckman R (2005) Patterns of emergent leadership in virtual teams. In: Proceedings of the\nthirty-eighth annual Hawaii international conference on System Sciences\nMoran T, Palen L, Harrison S, Chiu P, Kimber D, Minneman S, Van Melle W, Zellweger P (1997) I\u2019ll\nget that off the audio: a case study of salvaging multimedia meeting records. In: Proceedings of\nthe SIGCHI conference on Human factors in computing systems, ACM Press, New York, pp 202\u2013\n209\nNakanishi H, Ishida T, Ibister K, Nass C (2004) Agent culture: human\u2013agent interaction in a multicultural\nworld, chapter 11, designing a social agent for virtual meeting space. Lawrence Erlbaum Associates,\nMahwah, pp 245\u2013266\nNectar Website. http: //www.nectar\u2014research.net\nNiekrasz J, Purver M (2005) A multimodal discourse ontology for meeting understanding. In: Bourlard H,\nBengio S (eds) Proceedings of MLMI\u201905. Springer, New York\nNijholt A, Op den Akker H, Heylen D (2004) Meetings and meeting modeling in smart surroundings. In:\nNijholt A, Nishida T (eds) Social intelligence design. Proceedings third international workshop, vol\n02. CTIT, Enschede, pp 145\u2013158. ISBN 90-75296-12-6\nNijholt A, Zwiers J, Peciva J (2005) The distributed virtual meetingroom exersize. In: Vinciarelli A,\nOdobez JM (eds) Multimodal multiparty meeting processing, Workshop at the 7th International\nConference on Multimodal Interfaces (ICMI), ICMI, Trento, pp 93\u201399\nNunamaker JF Jr, Briggs RO, Mittleman D (1995) Electronic meeting systems: ten years of lessons\nlearned. In: Coleman D, Khanna R (eds) Groupware: technology and applications. Prentice Hall,\nEnglewood Cliffs\nOehlmann R (2006) The function of harmony and trust in collaborative chance discovery. New Math Nat\nComput 1(4):69\u201383\nOh A, Tuchinda R, Wu L (2001) Meetingmanager: a collaborative tool in the intelligent room. In:\nProceedings of the MIT Student Oxygen workshop, MIT, Cambridge\nOh J, Smith F (2005) Calendar assistants that learn preferences. In: Saphiro D (ed) Persistent assistants:\nliving and working with AI, workshop at the AAAI spring symposium 2005. AAAI Press, Menlo\nPark\nPadilha EG, Carletta J (2003) Nonverbal behaviours improving a simulation of small group discussion. In\nProceedings of 1st Nordic symposium on Multimodal Communication, pp 93\u2013105\nPalotta V, Ghorbel H, Ballim A, Lisowska A, Marchand-MailletS (2004) Towards meeting information\nsystems. In: Seruca E, Filipe J, Hammoudi S, Cordeiro J (eds) Proceedings of the ICEIS 2004: 6th\ninternational conference on enterprise information systems, vol 4. ICEIS, Porto\nPaulsen D (2004) Leadership essentials: facilitation skills for improving group effectiveness. In:\nSIGUCCS \u201804: Proceedings of the 32nd annual ACM SIGUCCS conference on User services. ACM\nPress, New York, pp 153\u2013160\nPoppe RW, Heylen D, Nijholt A, Poel M (2005) Towards real-time body pose estimation for presenters in\nmeeting environments. In: Proceedings of the international conference in Central Europe on\nComputer Graphics, Visualization and Computer Vision\u20192005 (WSCG\u20192005). Science Press, Plzen\n230 AI & Soc (2009) 23:213\u2013231\n123\nRienks R, Heylen D (2005) Automatic dominance detection in meetings using easily detectable features\nIn: Renals S, Bourlard H (eds) 2nd Joint workshop on Multimodal Interaction and Related Machine\nLearning Algorithms. Springer, Edinburgh\nRienks R, Heylen D, Van der Weijden E (2005a) Argument diagramming of meeting conversations. In:\nVinciarelli A, Odobez JM (eds) Multimodal multiparty meeting processing, workshop at the 7th\nInternational Conference on Multimodal Interfaces. ICMI, Trento, pp 85\u201392\nRienks R, Nijholt A, Reidsma D (2005b) Meetings and meeting support in ambient intelligence, chapter\n18, in ambient intelligence, wireless networking, ubiquitous computing. Artech House, Norwood\nRobertson S, Robertson J (eds) (1999) Mastering the requirements process. Addison Wesley, Boston.\nISBN 0-201-36046-2\nRomano N Jr, Nunamaker JF Jr (2001) Meeting analysis: findings from research and practice. In:\nProceedings of the 34th Hawaii international conference on System Sciences. IEEE Press, pp 1072\u2013\n1085\nRuble TL, Thomas KW (1976) Support for a two-dimensional model of conflict behavior. Organ Behav\nHum Perform 16:143\u2013155\nSellen J, Lovaglia MJ, Mannix EA, Samuelson CD, Wilson RK (2004) Investigating conflict, power and\nstatus within and among groups. Small Group Res 35(1):44\u201372\nShum S (1997) Negotiating the construction and reconstruction of organizational memories. J Universal\nComput Sci 3(8):899\u2013928\nSudweeks F, Simoff S (2005) Leading conversations: communication behaviours of emergent leaders in\nvirtual teams. In: Proceedings of the thirty-eighth annual Hawaii international conference on System\nSciences. IEEE Press, Los Alamitos\nTracy LK, Coupland N (1990) Multiple goals in discourse: an overview of issues. J Lang Soc Psychol\n9:1\u201313\nTucker S, Whittaker S (2005) Reviewing multimedia meeting recordings: current approaches. In:\nMultimodal multiparty meeting processing, Workshop at the 7th International Conference on\nMultimodal Interfaces, ICMI, Trento\nTucker S, Whittaker S, Laban R (2005) Identifying user requirements for novel interaction capture. In:\nSymposium \u2018annotating and measuring meeting behaviour\u2019 at measuring behaviour, The Nether-\nlands\nTuroff M, Hiltz SR (1977) Meeting through your computer. IEEE Spectr :58\u201364\nWaibel A, Steusloff H, Stiefelhagen R (2004) Chil\u2014computers in the human interaction loop. In: NIST\nICASSP meeting recognition workshop, NIST ICASSP, Montreal\nWainer J, Braga D (2001) Symgroup: applying social agents in a group interaction system. In:\nProceedings of the 2001 international ACM SIGGROUP conference on Supporting Group Work.\nACM Press, New York, pp 224\u2013231\nAI & Soc (2009) 23:213\u2013231 231\n123\n",
      "id": 4862168,
      "identifiers": [
        {
          "identifier": "11467800",
          "type": "CORE_ID"
        },
        {
          "identifier": "2143646642",
          "type": "MAG_ID"
        },
        {
          "identifier": "10.1007/s00146-007-0135-0",
          "type": "DOI"
        },
        {
          "identifier": "oai:ris.utwente.nl:publications/6f3889aa-b49f-4238-b6ea-6004c18e3a24",
          "type": "OAI_ID"
        },
        {
          "identifier": "oai:doc.utwente.nl:64130",
          "type": "OAI_ID"
        },
        {
          "identifier": "571983593",
          "type": "CORE_ID"
        },
        {
          "identifier": "572162469",
          "type": "CORE_ID"
        },
        {
          "identifier": "oai:ris.utwente.nl:openaire_cris_publications/6f3889aa-b49f-4238-b6ea-6004c18e3a24",
          "type": "OAI_ID"
        },
        {
          "identifier": "191409979",
          "type": "CORE_ID"
        }
      ],
      "title": "Pro-active Meeting Assistants: Attention Please!",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:doc.utwente.nl:64130",
        "oai:ris.utwente.nl:openaire_cris_publications/6f3889aa-b49f-4238-b6ea-6004c18e3a24",
        "oai:ris.utwente.nl:publications/6f3889aa-b49f-4238-b6ea-6004c18e3a24"
      ],
      "publishedDate": "2009-01-01T00:00:00",
      "publisher": "Springer-Verlag",
      "pubmedId": null,
      "references": [
        {
          "id": 10306365,
          "title": "Determining what people feel and think when interacting with humans and machines: notes on corpus collection and annotation. In:",
          "authors": [],
          "date": "2006",
          "doi": null,
          "raw": "The MIT Press, Cambridge Heylen D, Nijholt A, Reidsma D (2006) Determining what people feel and think when interacting with humans and machines: notes on corpus collection and annotation. In: Proceedings 1st California conference on Recent Advances in Engineering Mechanics (to appear), California State University, Fullerton IM2 Website. http: //www.im2.ch/ Jaimes A, Omura K, Nagamine T, Hirata K (2004) Memory cues for meeting video retrieval. In: CARPE\u201904: Proceedings of the the 1st ACM workshop on Continuous archival and retrieval of personal experiences. ACM Press, New York, pp 74\u201385 AI & Soc (2009) 23:213\u2013231 229 123Jebara T, Ivanov Y, Rahimi A, Pentland A (2000) Tracking conversational context for machine mediation of human discourse. In: AAAI fall 2000 symposium\u2014Socially Intelligent Agents\u2014The Human in the Loop, North Falmouth, MA Jovanovic N, Op den Akker H, Nijholt A (2005) A corpus for studying addressing behavior in multi-party dialogues. In: Proceedings of the sixth SigDial conference on Discourse and Dialogue Kaiser E, Demirdjian D, Gruenstein A, Li X, Niekrasz J, Wesson M, Kumar S (2004) Demo: a multimodal learning interface for sketch, speak and point creation of a schedule chart. In: Proceedings of the international conference on Multimodal Interfaces\u2014ICMI\u201904. ICMI, State College, pp 329\u2013330 Kernkamp RRJ (2006) Functional requirements for a con\ufb02ict managing meeting assistant. In: Proceedings of the 4th Twente student conference on IT. Twente University Press, Enschede Kuperus J (2006) The effect of agents on meetings. In: Proceedings of the 4th Twente student conference on IT. Twente University Press, Enschede Lauesen S (ed) (2002) Software requirements\u2014styles and techniques. Addison Wesley, Boston. ISBN 0-201-74570-4 Lisowska A (2003) Multimodal interface design for the multimodal meeting domain: preliminary indications from a query analysis study. Technical report, ISSCO/TIM/ETI, Universit de Genve, Geneva, IM2.MDM Report 11 Misiolek N, Heckman R (2005) Patterns of emergent leadership in virtual teams. In: Proceedings of the thirty-eighth annual Hawaii international conference on System Sciences Moran T, Palen L, Harrison S, Chiu P, Kimber D, Minneman S, Van Melle W, Zellweger P (1997) I\u2019ll get that off the audio: a case study of salvaging multimedia meeting records. In: Proceedings of the SIGCHI conference on Human factors in computing systems, ACM Press, New York, pp 202\u2013 Nakanishi H, Ishida T, Ibister K, Nass C (2004) Agent culture: human\u2013agent interaction in a multicultural world, chapter 11, designing a social agent for virtual meeting space. Lawrence Erlbaum Associates, Mahwah, pp 245\u2013266 Nectar Website. http: //www.nectar\u2014research.net Niekrasz J, Purver M (2005) A multimodal discourse ontology for meeting understanding. In: Bourlard H, Bengio S (eds) Proceedings of MLMI\u201905. Springer, New York Nijholt A, Op den Akker H, Heylen D (2004) Meetings and meeting modeling in smart surroundings. In: Nijholt A, Nishida T (eds) Social intelligence design. Proceedings third international workshop, vol 02. CTIT, Enschede, pp 145\u2013158. ISBN 90-75296-12-6 Nijholt A, Zwiers J, Peciva J (2005) The distributed virtual meetingroom exersize. In: Vinciarelli A, Odobez JM (eds) Multimodal multiparty meeting processing, Workshop at the 7th International Conference on Multimodal Interfaces (ICMI), ICMI, Trento, pp 93\u201399 Nunamaker JF Jr, Briggs RO, Mittleman D (1995) Electronic meeting systems: ten years of lessons learned. In: Coleman D, Khanna R (eds) Groupware: technology and applications. Prentice Hall, Englewood Cliffs Oehlmann R (2006) The function of harmony and trust in collaborative chance discovery. New Math Nat Comput 1(4):69\u201383 Oh A, Tuchinda R, Wu L (2001) Meetingmanager: a collaborative tool in the intelligent room. In: Proceedings of the MIT Student Oxygen workshop, MIT, Cambridge Oh J, Smith F (2005) Calendar assistants that learn preferences. In: Saphiro D (ed) Persistent assistants: living and working with AI, workshop at the AAAI spring symposium 2005. AAAI Press, Menlo Park Padilha EG, Carletta J (2003) Nonverbal behaviours improving a simulation of small group discussion. In Proceedings of 1st Nordic symposium on Multimodal Communication, pp 93\u2013105 Palotta V, Ghorbel H, Ballim A, Lisowska A, Marchand-MailletS (2004) Towards meeting information systems. In: Seruca E, Filipe J, Hammoudi S, Cordeiro J (eds) Proceedings of the ICEIS 2004: 6th international conference on enterprise information systems, vol 4. ICEIS, Porto Paulsen D (2004) Leadership essentials: facilitation skills for improving group effectiveness. In: SIGUCCS \u201804: Proceedings of the 32nd annual ACM SIGUCCS conference on User services. ACM Press, New York, pp 153\u2013160 Poppe RW, Heylen D, Nijholt A, Poel M (2005) Towards real-time body pose estimation for presenters in meeting environments. In: Proceedings of the international conference in Central Europe on Computer Graphics, Visualization and Computer Vision\u20192005 (WSCG\u20192005). Science Press, Plzen 230 AI & Soc (2009) 23:213\u2013231 123Rienks R, Heylen D (2005) Automatic dominance detection in meetings using easily detectable features In: Renals S, Bourlard H (eds) 2nd Joint workshop on Multimodal Interaction and Related Machine Learning Algorithms. Springer, Edinburgh Rienks R, Heylen D, Van der Weijden E (2005a) Argument diagramming of meeting conversations. In: Vinciarelli A, Odobez JM (eds) Multimodal multiparty meeting processing, workshop at the 7th International Conference on Multimodal Interfaces. ICMI, Trento, pp 85\u201392 Rienks R, Nijholt A, Reidsma D (2005b) Meetings and meeting support in ambient intelligence, chapter 18, in ambient intelligence, wireless networking, ubiquitous computing. Artech House, Norwood Robertson S, Robertson J (eds) (1999) Mastering the requirements process. Addison Wesley, Boston. ISBN 0-201-36046-2 Romano N Jr, Nunamaker JF Jr (2001) Meeting analysis: \ufb01ndings from research and practice. In: Proceedings of the 34th Hawaii international conference on System Sciences. IEEE Press, pp 1072\u2013 Ruble TL, Thomas KW (1976) Support for a two-dimensional model of con\ufb02ict behavior. Organ Behav Hum Perform 16:143\u2013155 Sellen J, Lovaglia MJ, Mannix EA, Samuelson CD, Wilson RK (2004) Investigating con\ufb02ict, power and status within and among groups. Small Group Res 35(1):44\u201372 Shum S (1997) Negotiating the construction and reconstruction of organizational memories. J Universal Comput Sci 3(8):899\u2013928 Sudweeks F, Simoff S (2005) Leading conversations: communication behaviours of emergent leaders in virtual teams. In: Proceedings of the thirty-eighth annual Hawaii international conference on System Sciences. IEEE Press, Los Alamitos Tracy LK, Coupland N (1990) Multiple goals in discourse: an overview of issues. J Lang Soc Psychol 9:1\u201313 Tucker S, Whittaker S (2005) Reviewing multimedia meeting recordings: current approaches. In: Multimodal multiparty meeting processing, Workshop at the 7th International Conference on Multimodal Interfaces, ICMI, Trento Tucker S, Whittaker S, Laban R (2005) Identifying user requirements for novel interaction capture. In: Symposium \u2018annotating and measuring meeting behaviour\u2019 at measuring behaviour, The Netherlands Turoff M, Hiltz SR (1977) Meeting through your computer. IEEE Spectr :58\u201364 Waibel A, Steusloff H, Stiefelhagen R (2004) Chil\u2014computers in the human interaction loop. In: NIST ICASSP meeting recognition workshop, NIST ICASSP, Montreal Wainer J, Braga D (2001) Symgroup: applying social agents in a group interaction system. In: Proceedings of the 2001 international ACM SIGGROUP conference on Supporting Group Work.",
          "cites": null
        },
        {
          "id": 10306363,
          "title": "Modeling the information structures of meetingware.",
          "authors": [],
          "date": "2003",
          "doi": null,
          "raw": "Antunes P, Carrio L (2003) Modeling the information structures of meetingware. In Proceedings of workshop de Sistemas de Informao Multimedia e Cooperativos (COOP-MEDIA\u201903) 228 AI & Soc (2009) 23:213\u2013231 123Banerjee S, Rose C, Rudnicky AI (2005) The necessity of a meeting recording and playback system, and the bene\ufb01t of topic-level annotations to meeting browsing. In: Proceedings of the tenth international conference on Human\u2013Computer Interaction, Rome, Italy Barthelmess P, Ellis CA (2005) The neem platform: an evolvable framework for perceptual collaborative applications. J Intell Inf Syst 25(2):207\u2013240 Barthelmess P, Kaiser E, Huang X, Demirdjian D (2005) Distributed pointing for multimodal collaboration over sketched diagrams. In: International Conference on Multimodal Interfaces\u2014 ICMI, Trento, Italy Berry PM, Gervasio MT, Uribe TE, Pollack ME, Mof\ufb01tt ME (2005) A personalized time management assistant: research directions. In: Saphiro D (ed) Persistant assistants: living and working with AI, workshop at the AAAI spring symposium 2005. AAAI Press, Menlo Park Bowring E, Tambe M, Yokoo M (2005) Optimize my schedule but keep it \ufb02exible: distributed multicriteria coordination for personal assistants. In: Saphiro D (ed) Persistant assistants: living and working with AI, workshop at the AAAI spring symposium 2005. AAAI Press, Menlo Park Broenink EG (2006) How a computer actor in\ufb02uences the time-ef\ufb01ciency of a meeting. In: Proceedings of the 4th Twente student conference on IT. Twente University Press, Enschede CALO Website. http : //www.ai.sri.com/project/calo/ Chen H, Perich F (2004) Intelligent agents meet semantic web in a smart meeting room. In: Proceedings of the third international joint conference on Autonomous Agents and Multi Agent Systems (AAMAS 2004), New York, USA Chen H, Finin T, Joshi A (2004) A context broker for building smart meeting rooms. In: Proceedings of the Knowledge Representation and Ontology for autonomous systems symposium, (AAAI spring symposium). AAAI, Menlo Park Cook P, Ellis CS, Graf M, Rein G, Smith T (1978) Project nick: meetings augmentation and analysis.",
          "cites": null
        },
        {
          "id": 10306364,
          "title": "The connector\u2014facilitating context-aware communication. In:",
          "authors": [],
          "date": "2005",
          "doi": "10.1145/1088463.1088478",
          "raw": "ACM Trans Inf Syst 5(2):132\u2013146 Danninger M, Flaherty G, Bernardin K, Ekenel HK, Khler T, Malkin R, Stiefelhagen R, Waibel A (2005) The connector\u2014facilitating context-aware communication. In: Proceedings of the international conference on Multimodal Interfaces, Trento, Italy De Vreede GJ, Vogel D, Kolfschoten G, Wien J (2003) Fifteen years of GSS in the \ufb01eld: a comparison across time and national boundaries. In: Proceedings of the 36th Hawaii international conference on System Sciences. IEEE Press, Big Island, HI Deutsch M (2003) International handbook of organizational teamwork and cooperative working, chapter cooperation and con\ufb02ict: a personal perspective on the history of the social psychological study of con\ufb02ict resolution. Wiley, New York, pp 9\u201344 DiMicco JM (2004) Designing interfaces that in\ufb02uence group processes. In: doctoral consortium proceedings of the conference on Human Factors in Computer Systems (CHI 2004), CHI, Vienna Duncan M (ed) (1996) Effective meeting facilitation: sample forms, tools, and checklists. http://www.nea. gov/resources/Lessons/ Ellis CS, Barthelmess P (2003) The neem dream. In: Proceedings of the 2003 conference on Diversity in computing. ACM Press, New York, pp 23\u201329. ISBN 1-58113-790-7 Erol B, Lee D, Hull J (2003) Multimodal summarization of meeting recordings. In: Proceedings of the IEEE international conference on Multimedia and Expo (ICME 2003). IEEE, Baltimore, MD Galley M, McKeown K, Hirshberg J, Shriberg E (2004) Identifying agreement and disagreement in conversational speech: use of bayesian networks to model pragmatic dependencies. In: Proceedings of the 42nd annual meeting of the Association for Computational Linguistics (ACL), ACL, East Stroudsburg, pp 669\u2013676 Garrido L, Sycara K (1995) Multi-agent meeting scheduling: preliminary experimental results. In: Victor Lesser (ed) Proceedings of the \ufb01rst international conference on Multi-Agent Systems (ICMAS\u201995).",
          "cites": null
        }
      ],
      "sourceFulltextUrls": [
        "http://www.clubofamsterdam.com/contentarticles/32 business meetings/pro-active meeting assistants.pdf",
        "https://ris.utwente.nl/ws/files/6548292/ai-soc2008.pdf",
        "http://purl.utwente.nl/publications/64130"
      ],
      "updatedDate": "2023-09-10T18:50:29",
      "yearPublished": 2009,
      "journals": [
        {
          "title": null,
          "identifiers": [
            "0951-5666"
          ]
        }
      ],
      "links": [
        {
          "type": "download",
          "url": "https://core.ac.uk/download/pdf/11467800.pdf"
        },
        {
          "type": "reader",
          "url": "https://core.ac.uk/reader/11467800"
        },
        {
          "type": "thumbnail_m",
          "url": "https://core.ac.uk/image/11467800/large"
        },
        {
          "type": "thumbnail_l",
          "url": "https://core.ac.uk/image/11467800/large"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/4862168"
        }
      ]
    },
    {
      "acceptedDate": "",
      "arxivId": "2403.04931",
      "authors": [
        {
          "name": "Aggarwal, Riya"
        },
        {
          "name": "Davis, James"
        },
        {
          "name": "Ding, Lei"
        },
        {
          "name": "Gandamani, Devanathan Nallur"
        },
        {
          "name": "Ghosalkar, Rohan"
        },
        {
          "name": "Grinnell, Nathan"
        },
        {
          "name": "Ho, Richard"
        },
        {
          "name": "Hussain, Nafisa"
        },
        {
          "name": "Liu, Li"
        },
        {
          "name": "Liu, Minghao"
        },
        {
          "name": "Malreddy, Sai Venkat"
        },
        {
          "name": "Mehta, Jay"
        },
        {
          "name": "Nizam, Marzia Binta"
        },
        {
          "name": "Prasad, Mohnish Sai"
        },
        {
          "name": "Ravichandran, Kesav"
        },
        {
          "name": "Shen, Celeste"
        },
        {
          "name": "Shen, Rachel"
        },
        {
          "name": "Tang, Xinyi"
        },
        {
          "name": "Titterton, Vincent"
        },
        {
          "name": "Vats, Vanshika"
        },
        {
          "name": "Wang, Ziyuan"
        },
        {
          "name": "Xu, Yanwen"
        },
        {
          "name": "Zhong, Sijia"
        }
      ],
      "citationCount": 0,
      "contributors": [],
      "outputs": [
        "https://api.core.ac.uk/v3/outputs/634231744"
      ],
      "createdDate": "2025-01-04T02:35:55",
      "dataProviders": [
        {
          "id": 144,
          "name": "",
          "url": "https://api.core.ac.uk/v3/data-providers/144",
          "logo": "https://api.core.ac.uk/data-providers/144/logo"
        }
      ],
      "depositedDate": "",
      "abstract": "In the rapidly evolving landscape of artificial intelligence (AI), the\ncollaboration between human intelligence and AI systems, known as Human-AI\n(HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and\ndecision-making processes. The advent of Large Pre-trained Models (LPtM) has\nsignificantly transformed this landscape, offering unprecedented capabilities\nby leveraging vast amounts of data to understand and predict complex patterns.\nThis paper surveys the pivotal integration of LPtMs with HAI, emphasizing how\nthese models enhance collaborative intelligence beyond traditional approaches.\nIt examines the potential of LPtMs in augmenting human capabilities, discussing\nthis collaboration for AI model improvements, effective teaming, ethical\nconsiderations, and their broad applied implications in various sectors.\nThrough this exploration, the study sheds light on the transformative impact of\nLPtM-enhanced HAI Teaming, providing insights for future research, policy\ndevelopment, and strategic implementations aimed at harnessing the full\npotential of this collaboration for research and societal benefit",
      "doi": null,
      "downloadUrl": "http://arxiv.org/abs/2403.04931",
      "fieldOfStudy": null,
      "fullText": "A Survey on Human-AI Teaming with Large Pre-Trained ModelsVANSHIKA VATS\u2217, MARZIA BINTA NIZAM\u2217, MINGHAO LIU, ZIYUAN WANG\u2020, RICHARDHO\u2020, MOHNISH SAI PRASAD\u2020, VINCENT TITTERTON\u2020, SAI VENKAT MALREDDY\u2020, RIYAAGGARWAL\u2020, YANWEN XU\u2020, LEI DING\u2020, JAY MEHTA\u2020, NATHAN GRINNELL\u2020, LI LIU\u2020, SIJIAZHONG\u2020, DEVANATHAN NALLUR GANDAMANI\u2020, XINYI TANG\u2020, ROHAN GHOSALKAR\u2020,CELESTE SHEN\u2020, RACHEL SHEN\u2020, NAFISA HUSSAIN\u2020, KESAV RAVICHANDRAN\u2020, and JAMESDAVIS, University of California, Santa Cruz, USAIn the rapidly evolving landscape of artificial intelligence (AI), the collaboration between human intelligence and AI systems, known asHuman-AI (HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and decision-making processes. The adventof Large Pre-trained Models (LPtM) has significantly transformed this landscape, offering unprecedented capabilities by leveragingvast amounts of data to understand and predict complex patterns. This paper surveys the pivotal integration of LPtMs with HAI,emphasizing how these models enhance collaborative intelligence beyond traditional approaches. It examines the potential of LPtMsin augmenting human capabilities, discussing this collaboration for AI model improvements, effective teaming, ethical considerations,and their broad applied implications in various sectors. Through this exploration, the study sheds light on the transformative impactof LPtM-enhanced HAI Teaming, providing insights for future research, policy development, and strategic implementations aimed atharnessing the full potential of this collaboration for research and societal benefit.CCS Concepts: \u2022 Computing methodologies \u2192 Artificial intelligence; \u2022 Human-centered computing \u2192 Human computerinteraction (HCI).Additional Key Words and Phrases: Human-AI Teaming, Artificial Intelligence, Large Pre-Trained Models, Large Language ModelsACM Reference Format:Vanshika Vats, Marzia Binta Nizam, Minghao Liu, Ziyuan Wang, Richard Ho, Mohnish Sai Prasad, Vincent Titterton, Sai VenkatMalreddy, Riya Aggarwal, Yanwen Xu, Lei Ding, Jay Mehta, Nathan Grinnell, Li Liu, Sijia Zhong, Devanathan Nallur Gandamani,Xinyi Tang, Rohan Ghosalkar, Celeste Shen, Rachel Shen, Nafisa Hussain, Kesav Ravichandran, and James Davis. 2024. A Survey onHuman-AI Teaming with Large Pre-Trained Models. 1, 1 (June 2024), 32 pages. https://doi.org/XXXXXXX.XXXXXXX1 INTRODUCTIONThe journey towards blending human intelligence with advanced technology spans several centuries, beginning withinventive attempts to simulate human intellect in machines. One notable example from the 1770s is the \"Mechanical\u2217Shared First Authorship\u2020Equal ContributionAuthors\u2019 address: Vanshika Vats, vvats@ucsc.edu; Marzia Binta Nizam, manizam@ucsc.edu; Minghao Liu; Ziyuan Wang; Richard Ho; Mohnish SaiPrasad; Vincent Titterton; Sai Venkat Malreddy; Riya Aggarwal; Yanwen Xu; Lei Ding; Jay Mehta; Nathan Grinnell; Li Liu; Sijia Zhong; DevanathanNallur Gandamani; Xinyi Tang; Rohan Ghosalkar; Celeste Shen; Rachel Shen; Nafisa Hussain; Kesav Ravichandran; James Davis, University of California,Santa Cruz, 1156 High St, Santa Cruz, California, USA, 95064.Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are notmade or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for componentsof this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post onservers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\u00a9 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.Manuscript submitted to ACM 1arXiv:2403.04931v2  [cs.AI]  26 Jun 20242 Vats and Nizam, et al.(a) (b)Fig. 1. A graphical depiction of the number of relevant articles submitted from 2013-2023. (a) illustrates the increasing engagement ofresearch communities in collaborations between humans and AI over the years. (b) observes a notably sharp increase in submissionsrelated to human-AI and large-scale models attributed to the recent emergence of large models.Turk,\" a machine that appeared to play chess autonomously but was, in fact, operated by a person concealed inside it[32]. This early endeavor, while not \"Artificial Intelligence\" (AI) in the modern sense, reflects the enduring fascinationwith creating technology that can mimic or complement human cognitive abilities. The formal realization of integratinghuman-like intelligence into machines culminated in 1956 at Dartmouth College, marking the official birth of ArtificialIntelligence as a research field [134]. As AI technology has advanced and become more prevalent over the last decade,researchers have identified limitations within purely automated systems [53, 110, 133] leading to renewed focus onaugmenting AI with human expertise, aiming to harness the best of both worlds (Fig. 1a). This approach seeks toenhance AI applications and foster a symbiotic relationship between human and artificial intelligence.Navigating the rapidly advancing AI landscape, the integration of human cognition with Large Pre-trained Models(LPtM), including Large Language Models (LLM) [14, 151] and Large Vision Models (LVM) [70, 81, 129], has initiated atransformative shift. These models are \"pre-trained\" on vast datasets before being fine-tuned for specific tasks. Thisparadigm has opened new avenues for collaborative problem-solving and decision-making. LPtMs are shaped andrefined by human expertise in terms of ethical guidance, creativity, and contextual understanding. In turn, AI amplifieshuman capabilities by processing data at large scales, offering insights and augmenting decision-making. This paperundertakes an extensive survey of Human-AI teaming, analyzing the complex interactions between human agentsand sophisticated pre-trained models across various fields. Our study aims to uncover the progress made, confront thechallenges, and understand the implications of this evolving partnership.The primary contribution of this survey is to provide an in-depth perspective on the complex and diverse landscapeof Human-AI teaming with large pre-trained models. We explore this synergy by studying Human-AI collaborationthat refines AI model behavior, effective HAI systems, safety concerns, and sector-specific applications. Our goal is toinform future research, influence policy-making, and guide development strategies, ultimately driving an effective andethical integration of Human-AI collaboration across various facets of society.A Survey on Human-AI Teaming with Large Pre-Trained Models 3(a) (b)Fig. 2. A representation of the scope of this survey. (a) We cover four broad categories - Model improvements, Effective HAI systems,Safe and Trustworthy AI, and their Applications - in the human-AI domain, along with the recent developments in them with thehelp of LPtM. The overlap between the four petals illustrates the fact that the four categories are not mutually exclusive; the articlesmay belong to two or more categories at the same time. (b) The heatmap shows a general trend of the number of articles co-existingwithin subcategories, including the articles discussing large models within each subject area. The overlap between the applications isnot analyzed, given their specific and varied nature. AI: Artificial Intelligence, HAI: Human-AI, UI/UX : User Interface/User Experience.1.1 Scope of the SurveyOur survey focuses on the articles describing the developments of human-AI teaming through the years and howthe introduction of large pre-trained models is reforming the field. The search for articles was conducted on GoogleScholar using keywords such as \"Human-AI\", \"Human-AI teaming\", and other similar terms. For research focusingon the collaboration between humans and AI involving large models, additional keywords, including \"large models\",\"large language models\", and \"large vision models\" were utilized. Since human-AI teaming and large models have onlyrecently gained a lot of interest from the research community given the recent popularity of large pre-trained models(Fig. 1b), some portion of studies cited in this survey could also be from arXiv preprints. We then sample the articlesaccording to the structure desired for this survey, i.e., primarily covering Human-AI teaming and its large pre-trainedmodel counterparts in better model training, effective human-AI joint systems, safe and secure HAI teaming, and theirapplications (Fig. 2a).In order to show support for the theme of our survey article, we try to implement human-AI teaming with the helpof large language models to prepare this review. For the human part, the authors survey the existing literature abouthuman-AI teaming, collect a subset of articles according to the desired structure, organize the survey into relevantsections, study submission statistics and put together tables and visualizations, and finally, prepare the first completedraft of the manuscript. Using the AI part in human-AI teaming, we ask ChatGPT-4 [120] for its feedback regarding thelanguage flow of each subsection, placement of the citations, and revising the language wherever necessary. This helps4 Vats and Nizam, et al.in the ease in identifying the missing elements and making necessary revisions. The final manuscript is, therefore, aproduct of human and AI collaboration.1.2 Outline of the SurveyIn each segment of our study, we commence by delineating traditional methodologies employed in human-AI collabo-ration, subsequently delving into the contributions of extensive pre-trained models in the fulfillment of these tasks.Section 2 explores the involvement of incorporating human expertise into the AI model training cycle, fostering acooperative relationship between humans and AI in active learning scenarios, enhancing learning through humanfeedback, and involving human experts in the thorough evaluation of machine learning models [66, 138, 182]. Section 3delves into understanding the scope of effective Human-AI joint systems, optimizing user interfaces (UI) and systemarchitectures emerges as a crucial area. It covers a range of topics under innovative UI designs and system structuresaimed at boosting efficiency and user engagement in collaborative settings [44, 89].A paramount concern in the realm of Human-AI collaboration is the safety, security, and trustworthiness of AIsystems. Section 4 of our comprehensive analysis encompasses multiple dimensions: mitigating algorithmic biases touphold fairness, assessing the impact of Human-AI collaboration on workers\u2019 autonomy, well-being, and job satisfaction,examining economic repercussions on employment and wages, addressing data privacy and security concerns, buildingtrust in AI systems, and navigating the legal and regulatory frameworks governing Human-AI interactions [13, 63, 83].These factors are integral to creating an ethical and responsible environment for AI\u2019s integration into human-centricworkflows. Furthermore, section 5 survey explores the broad spectrum of Human-AI teaming applications across varioussectors. We investigate the unique challenges and opportunities in fields such as healthcare [11], autonomous vehicles,surveillance systems [61], gaming [46], education, and accessibility. Understanding the specific characteristics andbenefits of Human-AI collaboration in these areas is key to influencing its future direction and maximizing its societalimpact.2 AI MODEL IMPROVEMENTS WITH HUMAN-AI TEAMINGIn this section, we delve into the process of training AI models, a critical stage that underpins their effectiveness andefficiency. Drawing upon the framework presented in Maadi et al. [100], we explore the integral role of human-AIinteractions in model training. This framework delineates three interdependent phases: 1) Data control, where data ispre-processed and produced under stringent quality standards; 2) Machine Learning (ML) modeling and execution,guided by human expertise; and 3) ML evaluation and refinement. Our discussion primarily centers on the secondphase, highlighting its pivotal role in shaping models that fulfill human-centric goals of effectiveness and efficiency.This section covers four key approaches: Human in the Loop, where human judgment directly influences AI training;Active Learning, focusing on AI systems that efficiently incorporate human input; Reinforcement Learning from HumanFeedback, where AI behavior is shaped by human feedback; and Human Evaluated Machine Learning, emphasizingthe role of human evaluation in refining AI models. Together, these subsections provide insights into how human-AIcollaboration can enhance the training process, leading to more effective and reliable AI models.2.1 Human in the LoopIn the \u2018Human in the Loop\u2019 (HITL) approach, we explore the synergistic collaboration between human intellect and AIcapabilities. This collaboration is especially critical in addressing AI\u2019s limitations in self-learning and humans\u2019 challengesin processing vast data within time constraints. The interplay of human and AI strengths leads to more robust andA Survey on Human-AI Teaming with Large Pre-Trained Models 5Human-AI Topics Subtopics Articles CitedSection 2: AI modelimprovements withhuman-AI teamingHuman in the loop [171], [66], [105], [47], [138], [127], [95], [8], [91], [176], [29], [68],[88], [74], [144], [121], [182], [113], [130], [180], [73], [109], [178],[103]Human evaluation in AI [6], [181], [5], [25], [66], [146], [34], [30], [121], [96], [24], [26],[152]Section 3: Effectivehuman-AI jointsystemsImproving user interfaces for ef-fective teaming [180], [61], [15], [128], [108], [173], [85], [135], [179], [25], [31],[160], [154], [45], [44], [166], [89]Effective human-AI collaboration [166], [173], [126], [39], [93], [115], [179], [112], [54], [139], [131],[113], [121], [182], [181], [64], [103], [97], [163], [157], [123], [105],[66], [1], [48], [7], [21], [154], [94], [114], [116], [107], [76], [132],[140], [20]Compatibility of human-AI sys-tems [167], [25], [9], [163], [41], [59], [117], [103], [98], [65], [7], [173],[157], [64], [94], [112], [105], [22]Section 4: Safe, secureand trustworthy AIAlgorithmic bias and fairness [55], [143], [33], [25], [111], [82], [67], [106], [84], [92], [50], [119],[10]Worker autonomy and well being [25], [83], [123], [37], [163], [172]Effect on wages and jobs [63], [28], [25], [123], [3], [37], [163], [158]Data privacy and security [43], [177], [75], [136], [90], [58], [153], [57], [36], [149], [137]Trustworthy AI and accountabil-ity [65], [126], [18], [163], [80], [6]Law and public policy [71], [19], [143], [12], [148], [159], [101]Section 5: ApplicationsHealthcare [64], [11], [104], [102], [16], [27], [17], [99], [87], [72]Autonomous vehicles [4], [97], [181], [48], [175], [124], [35], [169], [164], [162]Surveillance and security [125], [79], [61], [56], [23], [69]Games [46], [174], [142], [2], [150], [156], [46], [66]Education [118], [155], [170], [77], [40], [60], [38], [141], [42], [161], [62], [22]Accessibility [86], [122], [78], [168], [52], [49], [147]Table 1. A tabular representation of the four broader focus topics covered in this survey, with their relevant subtopics. Each categorycontains its cited articles for the ease of reader reference.ethically sound AI systems. For instance, during the model design phase, human insights on ethical considerations,as highlighted by Whittlestone et al. [171], enrich AI perspectives beyond mere technical aspects. Conversely, in themodel training and execution phase, the directional flow of information between humans and AI plays a pivotal role.Strategies such as InstructRL, as proposed by Hu and Sadigh [66], demonstrate the effectiveness of NLP instructionsfrom humans in guiding AI, enhancing the model\u2019s explainability and alignment with our expectations. Similarly, aresearch on AI-assisted brainstorming illustrates how AI\u2019s engagement with human ideas can foster greater creativityand innovation [105].6 Vats and Nizam, et al.Fig. 3. A visual representation of an active learning workflow. If the model predictions do not pass the required confidence valuethresholds required for a task, the data is sent to humans for manual annotations, further improving the model by retraining it withthe now-labeled data.The diverse roles of humans, ranging from providing ethical oversight in the design phase to contributing to qualitycontrol and data labeling during model training and execution, are crucial for optimizing AI performance. These rolesnot only bridge gaps in AI knowledge but also ensure that AI systems are aligned with human values and needs.As we proceed, we will delve deeper into two specific HITL machine learning approaches: Active Learning, whereAI models dynamically integrate human input to refine learning, and Reinforcement Learning from Human Feedback(RLHF), which leverages human feedback to shape AI behavior. These sections will illuminate the intricate ways inwhich human involvement is woven into the fabric of AI development, showcasing the multifaceted nature of Human-AIcollaboration.2.1.1 Human-AI Collaboration with Active Learning. Unlike traditional machine learning paradigms, activelearning involves an iterative process where a model selectively identifies data requiring labeling, optimizing systemperformance with minimal training data [47]. Particularly, this approach is crucial for fine-tuning large pre-trainedmodels, especially transformer-based ones, which require substantial labeled data for specific user scenarios. Activelearning efficiently harnesses human expertise to pinpoint areas of uncertainty, enabling more targeted training withless annotation effort [138]. The active learning workflow begins with an unlabeled dataset and a pre-trained model.The model predicts labels for each sample, outputting confidence levels (Fig. 3). When predictions fall below a qualitythreshold, human annotators step in for manual annotation. This iterative process of re-training the model with newlabeled data continues until satisfactory confidence levels are achieved. Human AI teaming plays a vital role in efficientdata labeling and continuous model improvement.Recent research in this area has introduced novel methods to leverage human expertise effectively. For instance,Pries et al. [127] propose a method for efficient data labeling using precise distance measurements to filter data samples,streamlining the presentation of data to experts. Lu et al. [95] discuss human-guided interventions for continuous modelimprovement, focusing on dissociating biases. Bao et al. [8] explore the transformation of human-annotated rationalesinto continuous attention mechanisms, enhancing the learning of domain-invariant representations. Additionally,Lertvittayakumjorn et al. [91] present a generalizable approach for debugging deep text classification models withA Survey on Human-AI Teaming with Large Pre-Trained Models 7human input, applicable to larger models. Finally, Yao et al. [176] propose an explainable-generation active learningframework for simpler tasks, potentially improving the sampling process in data augmentation.2.1.2 Reinforcement Learning from Human Feedback. Reinforcement Learning from Human Feedback (RLHF) isa paradigm that integrates human insights into the training process [29, 68]. This approach enhances the collaborationbetween humans and AI systems, especially during the data control phase \u2014 a critical stage for the success of largepre-trained models. In RLHF, the human role extends beyond mere data provision to actively shaping the AI\u2019s learningtrajectory. This human-AI symbiosis is particularly effective in mitigating biases in training data, leading to fairer AIoutcomes. Additionally, the human touch in RLHF makes AI decisions more transparent and comprehensible, therebyfostering greater trust among users. The adaptability of RLHF models to user preferences highlights the significance ofhuman understanding in complex, contextual situations, enabling AI systems to be more aligned with ethical standardsand personalization needs.However, the implementation of RLHF is not without its challenges. Ensuring the consistency and accuracy ofhuman feedback, effectively scaling this approach for large datasets, and harmonizing human insights with algorithmicprocesses are areas that require careful consideration [88]. Overcoming these challenges is essential to maximize thebenefits of RLHF, paving the way for AI models that are not only technically proficient but also deeply attuned tohuman values and needs.Reinforcement Learning Enhanced by Human Feedback. As an active research area of machine learning, Re-inforcement Learning (RL) focuses on enhancing agent behaviors to make decisions by performing actions in anenvironment and receiving feedback as rewards or penalties. Due to the success of RLHF in large models (LMs) andthe similar interaction in HAI teaming, researchers are now striving to figure out how to leverage RLHF for furtherimprovement on HAI frameworks and even put forward more flexible ones.Despite various theories and empirical models behind RL, as mentioned in [74], RL frameworks can be abstracted asa continuous interaction between agents and their surrounding environment, in which they take actions individually orcooperatively given their states and state transitions to maximize long-term rewards. Traditionally, given a designatedreward model, if the accumulated long-term reward is exactly or approximately converged under limited horizons, theagent\u2019s behaviors and the corresponding dynamics [144], like policy \ud835\udf0b (\ud835\udc4e |\ud835\udc60), Q function \ud835\udc44 (\ud835\udc60, \ud835\udc4e), etc. are more likelyto converge. Only after OpenAI \u2019s introduction of instructGPT [121] to illustrate how a reward model trained byhigh-quality data from labelers can optimize the LM\u2019s ranking of generative content did research communities realizeRL\u2019s critical role in improving LM performance. Since labelers are asked to label this data in multiple turns to yield themost suitable outputs, this interaction pattern under RL formalization is considered RLHF. Furthermore, this workingpattern can be widely applied in similar scenarios within feedback-acquiring processes. In the HAI teaming model,once human instructions are quantitatively converted to a reward model by ranking or scoring, the interaction betweenhuman and AI system agents can be formalized and optimized by RLHF.Design of RLHF. In exploring the design of RLHF, a key challenge emerges: aligning human instructions with RLagent behaviors to ensure that these instructions effectively guide and evaluate agent actions. This alignment, complexin nature, has been a pivotal focus in recent large language model (LLM) research, contributing significantly to theadvancement of LLMs and their applications. This section reviews the development of RLHF from its early stages in2019 to its current evolution.8 Vats and Nizam, et al.A notable early work in RLHF is by Ziegler et al. [182], where language models were trained to improve textgeneration and summarization based on human preferences. However, this approach, limited by its reliance on asingle-run process and restricted data, faced challenges in generalization. In contrast, OpenAI\u2019s instructGPT [121]introduced a three-phase training paradigm: initial training with supervised policy via demonstration data, traininga reward model with labeler feedback, and optimizing the ranking policy using RL against the reward model. Thismethodology provides a robust baseline and ensures that GPT models evolve with continuous human feedback, leadingto the creation of more sophisticated and responsive models, such as the web browser-assisted question-answeringagent by Nakano et al. [113].Despite these advancements, RLHF remains a complex and often unstable process. To address this, Stanford\u2019s recentresearch has introduced the Direct Preference Optimization (DPO) training model [130]. DPO simplifies policy trainingby directly mapping reward functions to optimal policies, circumventing the need for intricate reward maximizationconstraints. This approach not only surpasses traditional RLHF in controlling sentiment in generations but also enhancesresponse quality in tasks like summarization and single-turn dialogue. Its simplicity in implementation and trainingoffers a promising direction for further simplifying RLHF processes.New Human-AI Teaming Paradigms in RLHF. The integration of Reinforcement Learning from Human Feedback(RLHF) into Human-AI (HAI) processes presents unique challenges due to the intricate steps and components involved,as evidenced by the work of Zhang et al. [180], and Johnson and Vera [73]. Recognizing these complexities, recentresearch has shifted focus towards enhancing collaboration within the closely-coupled phases of HAI, with the aspirationof exploring further extensions in the future. A notable gap in current RLHF models is the communication barrierbetween AI and humans, highlighting the need for more advanced frameworks to bridge this divide.A significant contribution to human-agent coordination is the instructRL model by Hu and Sadigh [66], whichemploys natural language instructions to align RL agents with human-preferred policies. This model leverages theembedded knowledge of pre-trained models, enabling AI agents to collaborate more effectively with humans acrossvarious tasks, including gaming, robotics, and control decision-making. InstructRL\u2019s adaptability to different domainsthrough knowledge transfer and meta-learning positions it as a versatile model for diverse HAI scenarios.Research by Mirchandani et al. [109] suggests that Large Language Models (LLMs), even without additional training,can function as proficient general sequence modelers due to their in-context learning abilities. This research explores theuse of LLMs in robotics, particularly for extrapolating state sequences and prompting reward-conditioned trajectories,despite challenges like latency and compute costs. Chain-of-thought prompting further enhances LLM performance incomplex reasoning tasks, as shown by Wei et al. [165]. The Distillation and Retrieval of Online Corrections (DROC)system by Zha et al. [178] exemplifies the capability of LLMs to assimilate language feedback and distill knowledgefrom corrections, demonstrating effectiveness in novel settings.However, McNeese et al.\u2019s research [103] provides a counterpoint to the notion of RLHF as a universal solution.Despite the success of NeoCITIES [103] RL agents in simulated environments, the disparity between these environmentsand real-world complexities remains a significant hurdle. Furthermore, RL agents lack proficiency in non-verbalcommunication and still struggle with detailed verbal interactions, indicating a need for more sophisticated models thatcan fully comprehend both verbal and non-verbal human communication. These observations underscore the necessityfor developing new HAI frameworks that go beyond existing RLHF models, calling for enhanced human integration toaddress the multifaceted nature of real-world environments.A Survey on Human-AI Teaming with Large Pre-Trained Models 9Fig. 4. Evaluation training strategies based on Clark et al. [30]. They employ training methods by giving example and comparisontests, along with their correct answers. This is followed by an explanation of why the answer is correct. This way, the evaluatorsgradually learn about how to distinguish between human and machine-generated texts.2.2 Human Evaluation in AIHuman Evaluation in Artificial Intelligence (Human-Eval-AI) is an essential process that integrates human expertisewith AI-driven insights. This collaborative approach leverages the unique strengths of human judgment to refine andguide AI decision-making. The objective is to develop models that are accurate and also resonate with the diverse andmultifaceted nature of our world. Such collaboration is key to training robust models, enhancing decision-makingprocesses, and fostering a symbiotic relationship to improve model training.2.2.1 Evaluation of Trust and Transparency. Establishing trust and transparency is crucial in Human-Eval-AIsystems. Trust, inherently linked with transparency and understandability, aligns closely with how users perceive anAI system\u2019s abilities and limitations. As highlighted by Bansal et al. [6], it is essential for users to recognize the AIsystem\u2019s potential for errors. This understanding enables users to develop a realistic mental model of the AI, crucial foranticipating possible failures or underperformance.Zhou and Chen\u2019s work [181] further discusses this by recommending the integration of uncertainty measuresand machine learning model performance into AI-informed human decision-making processes. They advocate for atrial-to-trial approach in decision-making, where users adjust their judgment boundaries based on their experience ofuncertainty and AI interactions. Their proposed Uncertainty-Performance Interface (UPI) allows users to concurrentlyevaluate the quality and performance of machine learning models, fostering deeper trust in AI systems. Similarly, Av etal. [5] emphasize the importance of incorporating intrinsic uncertainty into the collaborative process. They suggest amechanism for human experts to offer feedback, either as corrections to current AI recommendations or insights onpreferable aspects within the search space. This feedback is integrated into a Bayesian optimization model, aiming toalign the model\u2019s inferences with the expert\u2019s domain-specific knowledge.10 Vats and Nizam, et al.2.2.2 Approaches to Improve Human Evaluation. In Human-Eval-AI, human input remains essential, especiallyin instructing AI agents and refining AI decision-making processes. The study by Chhibber et al. [25] showcasesthe benefits of integrating human teachings into AI, not only enhancing AI performance but also building trust andinfluencing job delegation practices. In a similar vein, Hu and Sadigh\u2019s instructRL [66] introduces a novel form ofhuman-AI interaction through high-level natural language instructions, thereby improving AI interpretability andalignment with human intentions. Aaquib et al.\u2019s research [146] on mental modeling in human-robot teaming revealsthat mutual understanding between humans and AI significantly boosts team performance, advocating for AI systemscapable of adapting to human mental models. Complementing this, Correia et al. [34] emphasize context in AI systemdesign, proposing personalized user interactions for more relevant human-machine team actions and information.Further exploring human evaluation, Clark et al. [30] examine how human evaluators can differentiate between textsproduced by humans and models like GPT-2 and GPT-3. They suggest methods to enhance evaluation accuracy, includingdetailed instructions, annotated examples, and text comparisons (Fig. 4). Ouyang et al. [121] present a different approach,fine-tuning GPT-3 into \u2018InstructGPT\u2019 using human feedback for improved user instruction alignment. Additionally, Luet al.\u2019s Error Analysis Prompting (EAPrompt) [96] focuses on evaluating machine translations by LLMs, leveragingChain-of-Thought reasoning to refine LLM evaluative capabilities. Chen et al\u2019s work [24] shows domain specificevaluation of LLM in problem-solving. Chiang and Lee [26] investigate LLMs for human-like text quality assessmentsin specific NLP tasks, highlighting similarities with human evaluations. Finally, Uchendu et al. [152] highlight theeffectiveness of collaborative efforts in enhancing detection capabilities, offering a unique perspective on humancollaboration in evaluations.3 EFFECTIVE HUMAN-AI JOINT SYSTEMSThis section concentrates on achieving efficiency in the joint human-AI (HAI) systems. The focus is on merging thestrengths of different HAI systems to ensure optimal performance while maintaining compatibility between the two(Fig. 5).3.1 Improving User Interfaces for Effective TeamingThe following module discusses enhancing human-AI collaboration through improved user interfaces and data process-ing. It highlights AI\u2019s role in team adaptation, personalization, conversational dynamics, and User Interface/Experience(UI/UX) design. The discussion will be focused around AI\u2019s influence on team collaboration and trust, its facilitationof learning and feedback via dialogue, and the significance of ethical, effective UI/UX design in supporting humancollaboration.3.1.1 Adaptation and Personalization. The integration of AI agents into human teams has historically been limitedby their narrow adaptability and personalization capabilities. Traditional AI systems struggled to understand humansubtleties and adapt to team dynamics, being confined to specific tasks without the ability to learn or adjust, therebyreducing their effectiveness in collaborative settings [180].The introduction of large pre-trained models has significantly revolutionized AI\u2019s adaptability and personalizationin teamwork. These models, trained on extensive datasets and utilizing sophisticated algorithms, have a markedlyimproved capacity to comprehend and adapt to team changes. Research demonstrates that LLM-equipped AI agents canfine-tune their autonomy, aligning with human team dynamics and operational needs more seamlessly [61]. LLMs haveadvanced conversational capabilities, enabling more natural, context-aware interactions and supporting more complex,A Survey on Human-AI Teaming with Large Pre-Trained Models 11Fig. 5. The chart shows the topics discussed to understand effective human-AI joint systems in this survey. The topics broadly discussbetter interfacing, collaboration, and compatibility of human-AI systems.multi-party engagements [15, 128]. Their application in mobile UI and UX evaluation also showcases their role inpersonalizing interactions and enhancing team collaboration [108]. The practice of chaining LLM prompts underscorestheir potential to customize Human-AI collaboration, ensuring greater control and transparency in the process [173].3.1.2 Conversational Interaction. In Human-AI Teams (HATs), effective communication is as crucial as in humanteams, with the conversational capabilities of AI playing a pivotal role in maintaining trust, facilitating knowledgesharing, and ensuring smooth coordination. These capabilities are essential for both the cognitive processing of tasksand the emotional dynamics within the team, impacting decision-making and situational awareness [85, 135]. Quickand appropriate responses from AI can enhance human members\u2019 confidence in their AI partners, leading to betterteamwork [179].The proactive sharing of information by AI, crucial for building trust and promoting collaboration, has seen significantstrides with the development of Teachable Conversational Agents. These agents improve text classification tasks bylearning from dialogue-based teaching and feedback, adjusting their focus based on interaction, which can range fromacquiring new knowledge to refining existing information based on the conversation\u2019s context [25]. The perception ofthese agents\u2019 likability and human-likeness is key to their effectiveness in communication [31]. Voice-based interactions,supported by Natural Language Processing (NLP), offer substantial benefits for both verbal and written exchanges inHATs [160].Research efforts have also been made to create a \"Shared Vocabulary\" (Taxonomy Model) for HATs, aiming for aunified set of terms and concepts accessible to both humans and AI. Furthermore, the \"Communication and Expla-nation\" framework (Communication Model) suggests equipping AI with the skills and training necessary for clearcommunication and explanations of their actions and reasoning, improving team understanding and efficiency [154].This approach not only fosters mutual comprehension but significantly boosts team performance.3.1.3 UI/UX. The evolution of User Interface (UI) and User Experience (UX) design in Human-AI Joint Systems iscrucial in defining the quality of collaborative experiences. Historically, UI design principles have focused on ensuringuser-friendly and ethical interactions between humans and AI systems. These ethical concerns, particularly abouttheir impact on individuals and society, have become more pressing as AI\u2019s role in human interactions expands[45]. The complexity of such interactions demands rigorous usability testing, requiring a keen eye for detail and a12 Vats and Nizam, et al.profound understanding of human-computer interaction principles [44]. Traditional methodologies have highlightedthe importance of clear communication and the synchronization of AI in UX evaluations, allowing AI to articulate itsfindings in usability testing and to determine effective modes of collaboration, whether they occur in real-time or aredelayed.The recent introduction of large models has significantly transformed UI/UX design practices within Human-AI JointSystems. Innovations such as the two-stage frameworks, with ChatIE being a prime example, have redefined zero-shotInformation Extraction (IE) tasks into multi-turn question-answering sequences, marking a significant advance in thefield. These models, including ChatIE, have outperformed numerous established models across various datasets [166].Further, studies involving human subjects in varied social settings have shown that these advanced approaches notonly improve the quality of interactions but also lead to more engaging and emotionally gratifying user experiences.This reflects the burgeoning capability of artificial intelligence to adopt more human-like behaviors and seamlesslyintegrate into social contexts [89]. This progression highlights a significant shift in the landscape of UI/UX design inHuman-AI systems, where the deployment of large-scale models plays an increasingly central role in enhancing userexperience and interaction fidelity.3.2 Effective Human-AI CollaborationIn this section, we categorize and discusses different interaction methods for human-AI collaboration. We divide thesemethods into 3 subsections: Human Helps AI, AI Helps Human, and their combination. Human Helps AI focuses onsystems where the AI has the final say, and humans provide it with support and guidance along the way. Humanoversight and intervention are also discussed in this subsection. AI Helps Human is the inverse; where a humanproduces the final output, using AI assistance along the way. The final part looks into systems where humans and AIshave more equal roles. Specifically, how the outputs of both humans and AI can be \u2018combined\u2019 to produce a higherquality output than either can produce alone.3.2.1 Human Helps AI. The indispensable role of human input in the development and refinement of AI systemsis well-documented, underscoring the symbiotic relationship between human expertise and AI capabilities. Humaninvolvement is pivotal at various stages of AI system development, from initial data preparation to the fine-tuning ofalgorithms for enhanced precision and reliability.Data annotation and preparation, as highlighted by Wei et al. [166], serve as the bedrock for training AI systems,ensuring they are equipped with accurate and contextually relevant data. The customization and refinement ofAI algorithms, driven by human feedback and insights, further illustrate the central role of human expertise inAI development, enhancing the system\u2019s accuracy and applicability [173]. Ethical considerations and contextualunderstanding are also paramount, with Pflanzer et al. [126] emphasizing the need for AI to operate within societalnorms and comprehend complex human contexts\u2014an aspect that purely algorithmic approaches may miss. Theadaptation of AI systems to specific industry requirements showcases the importance of tailoring AI technologies tomeet diverse application needs, thus enhancing their personalization and relevance [39, 93, 115].Interface design and communication strategies, as discussed by Zhang et al. [179], play a crucial role in making AItools both accessible and user-friendly, bridging the gap between sophisticated AI outputs and practical user interaction.The continuous evolution of AI systems necessitates ongoing human intervention and guidance to stay abreast ofadvancements in the field [112]. In specialized domains like adaptive AI systems for driving, human behavioral dataand feedback are utilized to simulate and incorporate diverse driving behaviors, demonstrating the integration ofA Survey on Human-AI Teaming with Large Pre-Trained Models 13human subtleties into AI training for real-world applications [54]. Hybrid human-AI teaming scenarios, where controlis dynamically allocated between humans and AI based on situational awareness, further highlight the collaborationbetween human judgment and AI efficiency [139].Recent advancements in large language models (LLMs) have also showcased the significant impact of human feedbackon improving AI performance. Direct Preference Optimization (DPO), as introduced by Rafailov et al. [131], representsa significant leap forward in the customization of language models. DPO focuses on aligning model outputs withhuman preferences through a direct optimization process, bypassing the complexities and limitations associated withtraditional reinforcement learning approaches. Similarly, the work of Nakano et al. [113] demonstrates how LLMs likeGPT-3 can be fine-tuned using human feedback for tasks such as web-assisted question-answering. Furthermore, theinstructRL framework introduces a method where AI agents, trained through reinforcement learning, are fine-tunedwith human-provided natural language instructions, demonstrating the efficacy of intuitive human-AI collaboration[66]. On the similar lines, Ouyang et al. [121] explore the benefits of fine-tuning LLMs with human feedback throughthe development of instructGPT models. The research of Ziegler et al. [182] complements these findings by applyingreward learning, informed by human judgments, to tailor language models for specific tasks such as stylized textgeneration and summarization. This approach highlights the versatility of human feedback in enhancing AI models,enabling them to adapt to a wide range of stylistic preferences and content requirements.3.2.2 AI Helps Human. This discussion delves into how AI systems, from traditional approaches to cutting-edgeLarge Language Models (LLMs), provide pivotal assistance across various domains, enhancing human capabilities andstreamlining complex tasks. It traverses the evolution from conventional AI applications, such as medical diagnosticaids and vehicular control improvements, to the transformative potential of LLMs in data analysis, creative contentgeneration, and decision-making, illustrating the dynamic progression of AI as an indispensable partner in humanendeavors.Initial discussions focus on traditional AI\u2019s role in simplifying complex tasks, like transforming zero-shot informationextraction into manageable question-answering formats, aiding humans in navigating large datasets effectively [166].Additionally, AI\u2019s contribution to enhancing human decision-making, particularly under uncertainty, is explored throughits applications in autonomous vehicles, emphasizing the need for transparency and trust in AI-human collaborations[181]. The use of ML-based systems in healthcare, such as TREWS for sepsis detection, exemplifies AI\u2019s capacity to act asa \"second pair of eyes,\" assisting clinicians with the voluminous clinical data for timely interventions [64]. Experimentalstudies on team dynamics, incorporating both humans and AI agents, reveal the efficiency gains from AI integration,where AI handles tasks suited to its capabilities, thus optimizing team performance [103]. Furthermore, innovations inhuman-machine collaboration, such as intelligent haptic interfaces for vehicular control, showcase improvements insafety and efficiency during the transition from automated to manual driving [97].More recently, impressive capabilities of LLMs in assisting humans, like chaining multiple LLM prompts offer a novelapproach to complex task management, enhancing the human-AI collaborative experience through a transparent andcontrollable interface [173]. LLMs\u2019 role in augmenting, rather than replacing, human tasks is further detailed in Wang\u2019swork [163], highlighting their utility in providing insights and suggestions for tasks that would otherwise be daunting forhumans. Further, Veselovsky et al. [157] touch on the balance required in leveraging LLMs to maintain the authenticityof human responses, underscoring the potential for high-quality but homogeneous outputs versus lower-quality butgenuine human responses. Interdisciplinary collaboration is advocated as a means to shape the future of LLMs andAI-human interaction, promoting a proactive and global perspective [123]. The impact of AI on human brainstorming14 Vats and Nizam, et al.processes, where systems like GPT-3 stimulate broader idea generation, is also examined, indicating AI\u2019s potential toenhance cognitive processes and creativity in individual and collaborative settings [105]. The application of ChatGPTin software architecture, aiding in the translation of architectural narratives into technical specifications, exemplifiesAI\u2019s role in enhancing productivity and fostering creative design processes [1]. Furthermore, the examination of AI\u2019srole in driving safety and autonomous systems, via a delegation manager that intelligently assigns control based on thesituation and capabilities, illustrates the potential for AI to significantly improve operational safety and efficiency inhybrid human-AI systems [48].3.2.3 Combining Human and AI Strengths. The essence of merging the strengths of humans and AI lies inleveraging the unique capabilities of each. It involves a careful balance where each compensates for the other\u2019slimitations, aiming for a collaboration where the overlap in errors is minimized, thus maximizing the opportunity formutual correction and improvement. Research indicates that while explanations of AI predictions can foster blind trust,they may not always promote the appropriate reliance needed in critical domains where human oversight is crucial [7].Optimal collaboration requires an intricate understanding of each other\u2019s capabilities, where humans excel in cognitiveskills like context recognition, anticipation of team behaviors, and corresponding action support [21].However, recognizing and integrating these diverse forms of intelligence within Human-AI Teams (HATs) posesnew challenges, necessitating an in-depth understanding of AI\u2019s capabilities and limitations by human teammates[94, 154]. Initially, mismatches in mental models of AI\u2019s abilities can lead to errors, but over time, as humans develop amore accurate understanding, they learn to effectively complement the AI\u2019s functions. Advanced hybrid AI approaches,including neuro-symbolic frameworks, have been introduced to model human psychological states, aiding in theprediction and adaptation to human behaviors for enhanced cooperation [114, 116, 154].Adaptation in AI behavior, aimed at enhancing collaboration, involves learning from relevant human features andmodifying behavior to align with human goals, thereby fostering a more intuitive and effective partnership [107].Incorporating computational models of emotion into mental models allows AI agents to consider affective states indecision-making, enriching the collaboration with sophisticated, goal-oriented actions [76]. Establishing a commonvocabulary and shared understanding of goals, capabilities, and emotional states further solidifies the foundation ofeffective Human-AI collaboration [154].Recent research initiatives showcase practical applications of this synergy. AdaTest++, an augmented tool forauditing large language models (LLMs), exemplifies the collaborative effort between humans and AI in enhancingmodel reliability and understanding, facilitating the identification of model failures through a combined effort [132].In the realm of mental health support, the HAILEY system demonstrates how AI can augment human empathy withanalytical insights, providing feedback-driven support for more empathetic and effective peer-to-peer conversations[140]. Additionally, the innovative integration of LLMs and diffusion models for creating visual metaphors highlightsthe creative potential unleashed by human-AI collaboration, where human-proposed linguistic metaphors are visuallyrealized through AI-generated imagery, bridging the gap between conceptual ideas and visual representation [20].3.3 Compatibility of Human-AI SystemsIn human-AI joint systems, compatibility is crucial for ensuring that AI systems can seamlessly work alongside existinghuman technologies, thereby enhancing the overall efficacy of the system. As systems grow in complexity, systemdesigners and engineers face the intricate challenge of ensuring harmonious interaction between humans and AI. Thisintegration encompasses aspects such as communication protocols, security measures, scalability considerations, andA Survey on Human-AI Teaming with Large Pre-Trained Models 15workflow integration. When AI systems are tailored to fit within the existing workflows of human users, they facilitatesmooth integration, avoiding disruptions or compromises to the system\u2019s current functioning. In the context of human-AI systems, compatibility transcends technical alignment. It encompasses the adaptability of AI systems to existinghuman processes, the user-friendliness and learning curve associated with new AI tools, and the effectiveness of thesecompatible joint systems in achieving their intended results. This section delves into these key aspects, highlighting theimportance of compatibility in the effectiveness and safety of human-AI systems.3.3.1 Backwards Compatibility. In the realm of AI technologies, backward compatibility plays a pivotal role inensuring the smooth integration of new or updated systems with pre-existing frameworks. This concept is crucialwhen embedding AI into legacy systems, as it involves careful consideration of existing tools, processes, and practices.Weisz et al. [167] delve into how generative models contribute to the modernization of applications, emphasizing thenecessity for AI systems to function cohesively within older infrastructures. In the context of traditional crowd work,Chhibber et al. [25] illustrate the significance of aligning AI tools with established workflows, showcasing the potentialof generative models, like Generative Adversarial Networks (GANs) and autoencoders, to augment and refine datasetsin legacy systems. Additionally, Bau et al. [9] present a novel approach using GANs to adapt image priors to specificimage statistics in individual photographs, thereby tackling challenges in reproducing and manipulating high-levelimage attributes, as evidenced in various semantic editing tasks.Discussing the broader compatibility challenges outside just the technological perspective, Wang [163] talks aboutthe transformative effects of Large Language Models (LLMs) on the job market, underscoring the necessity of integratingthese advanced technologies into existing economic structures without causing major disruptions. Eloundou et al. [41]examine the impact of LLMs on the US labor market, revealing that approximately 80% of workers could experience asignificant change in their tasks, with 19% potentially seeing over half of their tasks affected. This \u2018exposure\u2019 refers to a50% increase in task efficiency without compromising quality. Furthermore, Harrer et al. [59] highlight the potentialof LLMs in generative AI applications, emphasizing the need for responsible design, human oversight, and ethicalconsiderations to prevent the spread of misinformation. They offer insights into how these models, when developedresponsibly, can serve as efficient and trustworthy tools in sectors like healthcare, addressing technology, risks, andethical issues.3.3.2 Learning Curve and Effective Usability. In Human-AI Teaming (HAT), a critical factor is the ease andefficiency of interaction between humans and AI which significantly influences the learning curve and overall usability.McNeese et al.\u2019s [103] study talks about the team composition in HAT, revealing that AI\u2019s ability to take a leading rolein teams can enhance performance, though it often presents an initial learning curve for human participants. Lyons etal. [98] discuss the importance of intuitive interfaces in fostering a partnership, rather than a tool-based relationship,between machines and humans. A pivotal aspect in this regard is the AI\u2019s ability to explain its decisions, especiallywhen those decisions may seem counter-intuitive to human collaborators. Hou et al.\u2019s [65] research highlights that trustin AI is bolstered when humans understand the rationale behind AI decisions, fostering a sense of vulnerability andreliance on AI actions. This concept is further supported by Bansal et al. [7], who find that AI explanations significantlyincrease human trust in the algorithm.Exploring the potential of Large Models, Wu et al. [173] also explore that breaking down the complex humantasks into multiple LLM prompts and chaining them together helps with increased human-AI interaction towardsimprovement. The users improvised over the new ways of interacting with the LLMs by leveraging the sub-tasks toset calibrate model expectations and making new-unit tests for each submodule of the LLM chain. Veselovsky et al.\u2019s16 Vats and Nizam, et al.[157] study, however, suggests that even though prevalent usage of LLMs generating high-quality but homogeneousresponses might not truly capture the real essence of human behavior, they can prove to be useful too. They analyzethat human workers not using LLMs in their tasks produced lower quality (less essential) information than whenallowed the use of LLMs. They, hence, given the rapidly evolving large model landscape, emphasize a need to constantlymonitor the co-evolution of LLM and human teaming to get to some constructive contributions.3.3.3 Evaluating the Effectiveness of Joint Human-AI Systems. Evaluating the efficacy of human-AI systemsextends beyond technical performance, encompassing a holistic approach that includes technical, social, and psy-chological dimensions of human-AI collaboration. The study by Henry et al. [64] emphasizes the importance of usertrust and system usability, suggesting that evaluation frameworks should assess how systems support user autonomyand are endorsed by domain experts to facilitate adoption. Similarly, Liu et al. [94] highlight the need to understandperceptual differences between humans and AI, advocating for evaluations that measure how these systems leveragethe complementary strengths of human and machine intelligence to improve joint decision-making processes. Munyakaet al. [112] delve into the impact of decision-making styles and AI identity disclosure on team dynamics and efficacy,underlining the significance of evaluating social dynamics and collaboration patterns within human-AI teams. Further-more, Memmert et al. [105] explore the integration of AI in creative processes, pointing to the necessity of assessingboth the cognitive contributions of AI and its effects on group dynamics, such as the potential for free-riding.In terms of large models, Chang et al. [22] present a comprehensive theoretical framework for evaluating LLMs. Thisframework spans a wide array of metrics and scenarios, such as natural language processing, reasoning capabilities,and robustness. This study highlights the necessity of multifaceted evaluation frameworks that extend beyond taskperformance to include considerations like ethical implications and bias, which are crucial in human-AI systems. On theother hand, Veselovsky et al.[157] adopt a more empirical approach by examining the practical use of LLMs in crowdwork. Their evaluation method involves observing and adapting the behavior of crowd workers as they interact withLLMs, offering a practical perspective on Human-AI interaction. These studies collectively suggest that a comprehensiveevaluation of human-AI systems should not only focus on accuracy or efficiency but also consider factors like trust,usability, collaboration dynamics, and the psychological impact on users, to ensure the development of systems that areeffectively integrated into human workflows and decision-making processes.4 SAFE, SECURE AND TRUSTWORTHY AIThe integration of AI in professional domains has been both revolutionary and disruptive, significantly affectingemployment and wage dynamics. In this section, we embark on a detailed examination of the multifaceted implicationsof these developments. First, we address the critical issue of algorithmic bias and fairness. By drawing on existingliterature, we explore the complexities surrounding this challenge and investigate potential solutions. Next, we assesshow AI impacts worker autonomy and job satisfaction, shedding light on both positive and negative effects. The conceptof trustworthy AI is then analyzed, with a focus on the crucial aspect of accountability in human-AI interactions.Subsequently, we explore the intricate relationship between AI, law, and public policy, underscoring the challenges indeveloping regulatory frameworks that effectively balance ethical considerations with rapid technological advances.Our objective throughout this section is to provide an informed perspective on human-AI collaboration and its socio-economic implications, contrasting these new models with traditional paradigms.A Survey on Human-AI Teaming with Large Pre-Trained Models 17Fig. 6. Large Language Models often exhibit gender bias due to primarily being trained on large datasets of human language thatreflect existing societal biases. Kotek et al. [84] test this by probing LLMs to answer permutations of complex questions, as shownabove. The answers and their explanation help the authors to quantify the bias.4.1 Algorithmic Bias and FairnessAlgorithmic fairness is a cornerstone of contemporary AI, demanding the development and deployment of unbiased andnon-discriminatory algorithms. This pursuit, though challenging due to the complexities in defining fairness, mitigatingdata biases, and ensuring algorithm transparency, has become a focal point for researchers and organizations [55].Fairness in algorithms is inherently complex. For instance, biases in the training data can lead to skewed outputs, andinherent biases in algorithmic design can persist even with unbiased data. These issues are further complicated bythe often opaque nature of algorithms and the lack of established accountability measures [143]. Several strategieshave been proposed to address these challenges. Key among them are ensuring data representativeness and employingalgorithms known for their fairness. Pre-deployment testing for biases, enhancing transparency, and establishingrobust accountability mechanisms are equally crucial [33]. Chhibber et al\u2019s [25] research sheds light on the role ofuser interaction in shaping algorithmic outcomes. It demonstrates how data quality, user engagement, and systemlocalization impact fairness in machine learning systems. Additionally, Morrison et al.\u2019s [111] study discusses thevalue of causal explanations in AI, arguing that they foster trust, facilitate error correction, and support informeddecision-making, thereby contributing to the enhancement of algorithmic fairness.The incorporation of Large Language Models (LLMs) into various applications has intensified the need to addressalgorithmic bias and fairness. Kirk et al. [82] have shown that biases in large language models, particularly thoseavailable \u2018out-of-the-box\u2019 like GPT-2, can lead to stereotypical and less diverse occupational associations for women,especially when intersecting with other categories like religion or ethnicity. Meanwhile, Huang et al. [67] reveal that asignificant portion of code functions generated by LLMs can contain biases related to sensitive attributes such as ageand gender, raising concerns about the fairness and integrity of software applications reliant on these models. Kotek etal. [84] further investigate gender stereotypes within LLMs (Fig. 6), demonstrating that these models are significantlymore likely to align occupations with stereotypical gender roles, sometimes amplifying biases beyond societal norms orofficial statistics. They find out that, on average, these LLMs are 6.8 times more likely to choose a stereotypical femaleanswer when a female pronoun is present and 3.4 times for male answers and pronouns. Further, Meyer et al. [106]explore the paradigm shift brought by conversational LLMs, discussing their potential to enhance academic work whilecautioning against their inherent biases and accuracy issues.18 Vats and Nizam, et al.Recent studies are also working on diverse strategies for mitigating bias in LLMs, emphasizing the importanceof fairness across their applications. Li et al. [92] review fairness strategies for both medium and large-sized LLMs,highlighting the need for tailored debiasing methods based on model size and training paradigms. Gallegos et al. [50]offer a detailed survey on bias evaluation and mitigation, categorizing techniques across model development stages andintroducing taxonomies for bias metrics and mitigation methods. Ohi et al. [119] propose a novel approach to counteractlikelihood bias in LLM evaluations using few-shot examples for in-context learning, showing marked improvements infairness. Bi et al. [10] focus on group fairness in social media, presenting a hierarchical schema for bias evaluation anda chain-of-thought mitigation method, GF-Think, to reduce bias. These contributions underline possible approaches tobias mitigation, aiming for ethical and equitable use of LLMs.4.2 Worker Autonomy and Well BeingIn the realm of AI-enhanced platforms, worker autonomy, well-being, and job satisfaction are pivotal, directly influencingengagement and productivity. Current AI practices sometimes neglect these factors, leading to dissatisfaction andturnover. Addressing this, several studies propose frameworks to improve these aspects in AI-centric work environments.Chhibber et al. [25] demonstrate how teachable conversational agents in crowd-based applications can empowerworkers, enhancing control, personalized learning, and ownership, thereby boosting job satisfaction. Konstantis etal. [83] emphasize transparency and fairness in crowdsourcing platforms, advocating for clear decision-making andrespectful treatment to improve worker experience. Furthermore, Pal [123] highlights the design of LLMs focused onworker well-being and autonomy, avoiding stress-inducing features and promoting engagement and learning.Despotovic and Bogodistov [37] highlight a trend in job seekers preferring roles that incorporate advanced AI, likeChatGPT, aligning with their identities and technological interests. This shift towards AI-interactive jobs indicatesa broader preference for technologically engaging roles, impacting job satisfaction and autonomy. Complementarily,Wang [163] explores the paradox of LLMs in the job market, noting their role in both creating new opportunities andobsoleting certain jobs. This dual effect is key in assessing worker autonomy and well-being, as LLM-driven automationfosters more creative roles and autonomy but also raises concerns about job security and satisfaction. Integratinginsights from recent research, it\u2019s evident that while generative AI has the potential to automate menial tasks and fostermore creative roles, it also poses challenges to worker autonomy, necessitating a balanced approach to AI deploymentin the workplace [172].4.3 Effect on Wages and JobsThe influence of AI on labor, particularly wages and job security, is a subject of global debate. The discourse ranges fromAI augmenting human capabilities and creating new jobs to concerns about task automation and worker displacement.Hemmer et al. [63] suggest AI could enhance productivity by up to 40%, potentially leading to higher wages. Incontrast, Chowdhury et al. [28] point to AI\u2019s role in both creating and displacing jobs, with an estimated 1.7 millionnew jobs and significant displacements in the U.S. by 2029. This highlights the necessity for proactive support for thoseaffected by AI-driven changes. Chhibber et al. [25] discuss AI\u2019s impact on the gig economy, noting potential job lossesin areas like customer service, balanced by new opportunities in AI-related fields. Pal [123] foresees a growing LLMindustry, suggesting increased job creation in AI R&D. Conversely, Wang [163] anticipates the displacement of up to800 million jobs globally by 2030, advocating for protective legislation and equitable AI benefit distribution. Ashktorabet al. [3] examine Human-AI collaboration in the gaming industry, where AI\u2019s role in automating tasks like game testingcould lead to job enrichment in creative roles.A Survey on Human-AI Teaming with Large Pre-Trained Models 19The integration of Large Language Models has diverse implications for the job market. Despotovic and Bogodistov\u2019s[37] research reveals that job seekers show a preference for roles that resonate with their personal identity and involvefrequent interaction with technologies like ChatGPT. This sees a shift in job market dynamics and the necessity forbusinesses to adapt their recruitment strategies. Wang [163] discusses the paradoxical effect of LLMs, highlighting bothjob creation and displacement across various sectors. This includes an examination of LLMs\u2019 influence on routine tasks,specialized professions, and broader economic and societal aspects. Walkowiak et al. [158] focus on the Australianworkforce, quantifying the exposure to GenAI risks and potential job transformations, addressing privacy, cybersecurity,and ethical issues.4.4 Data Privacy and SecurityIn the realm of human-AI collaboration, trust, particularly in data privacy and security, is foundational. Ezer et al. [43]emphasize the critical role of trust engineering, advocating for algorithmic transparency and dynamic management toestablish mutual trust in complex, information-imperfect environments. Yin et al. [177] further this by proposing aprivacy-focused, human-centric approach, leveraging logistic regression and differential privacy to strike a balancebetween privacy and utility, achieving notable classification accuracy. In medical imaging, Kaissis et al. [75] highlight theimperative for secure, privacy-preserving AI through federated learning, addressing the privacy-utilization dichotomyto advance patient care. The synergy of AI and cybersecurity, as explored by Admin et al. [136], showcases AI\u2019s potentialto fortify cyber defenses, underscoring the role of machine and deep learning in countering complex cyber threats andsafeguarding data integrity. Lepri et al. [90] advocate for a human-centric AI ethos, stressing the importance of privacy,accountability, and ethical decision-making in building secure, trustworthy AI systems.Regulatory and privacy challenges for Large Generative AI Models (LGAIMs), including ChatGPT and GPT-4, demandtargeted legal and technical solutions for safe use. Hacker et al. [58] recommend a regulatory framework for LGAIMsfocusing on transparency, risk management, and equitable treatment, particularly for high-risk uses. Ullah et al. [153]propose PrivChatGPT, a model incorporating differential privacy for LLMs, highlighting the balance between privacyand utility. Gupta et al. [57] discuss cybersecurity risks with GenAI, emphasizing the need for ethical practices andsecure defenses against potential misuse. De Angelis et al. [36] identify LLMs as vectors for misinformation, advocatingfor policies to combat the \"AI-driven infodemic\" in public health. Thapa and Adhikari [149] balance LLMs\u2019 benefitsagainst misinformation risks in biomedical research, calling for strict validation. Sebastian [137] focuses on privacy inAI chatbots, suggesting federated learning and data minimization to protect user information, reflecting increasingprivacy concerns among LLM users.4.5 Trustworthy AI and AccountabilityInitially, conventional methods in trustworthy AI emphasized the importance of ethical principles, human oversight,and transparency. Hou et al. [65] discuss these principles, stressing the need for secure systems that identify risks whileremaining under human control. Pflanzer et al. [126] introduce the Agent-Deed-Consequence model as a traditionalethical algorithm framework, emphasizing human oversight in AI ethics. Caldwell et al. [18] highlight factors influencingtrust in AI in cooperative environments, such as multiplayer gaming, underscoring the importance of environmentalfactors and peer influence in conventional trust-building.The advent of LLMs introduces new dimensions to these conventional methods. In healthcare, a case study using LLMs[163] showcases the balance between patient engagement and AI over-reliance risks, underscoring the advancements indata sensitivity and patient communication. Kim et al. [80] demonstrate how LLMs contribute to managing uncertainty20 Vats and Nizam, et al.in human-AI collaboration, proposing a trial-to-trial approach to effectively communicate and estimate uncertainty.Furthermore, LLMs influence the formation of mental models, as discussed by Bansal et al. [6]. They highlight LLMs\u2019role in enhancing predictability and understanding of AI\u2019s error boundaries, crucial for developing accurate mentalmodels for better human-AI collaboration.4.6 Law and Public PolicyTraditionally, AI legal and policy frameworks have focused on ensuring transparency, accountability, fairness, andbias mitigation. Pioneering work by Jobin et al. [71], which analyzed AI guidelines globally, highlights the universalemphasis on ethical standards, transparency, and accountability. Similarly, research by Cath et al. [19] highlights thecritical need for transparent and accountable AI, especially in decision-making processes. Stahl et al.[143] propose sixguidelines for AI regulation: Transparency, Accountability, Bias Mitigation, Human Oversight, Data Protection, andPublic Education.The integration of Large Language Models (LLMs) into the AI landscape underscores the need for updated legalframeworks to address new challenges in data use and AI-generated content regulation. Bender et al. [12] examinethe ethical implications of LLMs, focusing on data usage and biases. An accredited law partner [159] specializingin technology and intellectual property discusses U.S. court cases like GitHub Copilot\u2019s use of open-source code,highlighting the legal intricacies of data attribution and compliance. This situation prompts a reevaluation of thedatasets used for AI training and the adaptation of laws, particularly concerning copyrights and patents. Ekenobi etal. [148] explore the legal impacts of deploying LLMs, with a focus on data protection and privacy. They commendChatGPT\u2019s privacy measures as a step towards mitigating potential risks. Additionally, Marcos and Pullin\u2019s article[101] talks about the EU\u2019s GDPR challenges, emphasizing the balance between technological growth and privacy rights.This necessitates robust regulatory frameworks that ensure LLM compliance with strict data protection standards,highlighting the importance of new laws in safeguarding privacy while fostering innovation.5 APPLICATIONSThis section highlights the role of Human-AI (HAI) Teaming and Large Pre-trained Models (LPtM) in revolutionizingfields such as healthcare, autonomous vehicle domain, surveillance, gaming, education, and accessibility. It highlights thesymbiosis between human expertise and AI\u2019s analytical power, emphasizing the importance of ethical AI developmentand user-centric design in maximizing benefits and inclusivity within society.5.1 HealthcareIn the healthcare sector, recent researchers highlight the studies performed in enhancing patient diagnosis accuracyand fostering trust, emphasizing AI\u2019s transformative influence in human-AI collaboration [11, 64, 104]. Advancessuch as the application of AI in breast cancer detection have markedly boosted diagnostic efficacy, sometimes evenoutperforming human experts, showcasing the remarkable potential of AI in healthcare [102]. These developmentsnecessitate reevaluating AI\u2019s role in patient care, addressing ethical considerations and practical challenges [16]. Researchfocusing on healthcare practitioners\u2019 views within the US highlights the critical factors of training, trustworthiness,and perceived AI risks, which are pivotal in its acceptance and application in clinical environments [27]. Additionally,improvements in AI-powered medical image retrieval systems have been shown to augment both diagnostic capabilitiesand user trust, advocating for integrated systems that blend human insight with algorithmic accuracy [17]. ThisA Survey on Human-AI Teaming with Large Pre-Trained Models 21Fig. 7. An example of how multimodal foundation models and large language models can be used for enhancing generalization androbustness in autonomous driving, as studied by Wang et al. [162]. They develop pixel/patch-aligned feature descriptors and latentspace simulation, enriched with language modality, suggesting potential for optimizing the training and debugging processes forend-to-end learning-based control. The RGB images in this figure are taken from the KITTI dataset [51] for representation purposes.partnership between AI technologies and healthcare professionals is vital for enhancing patient care outcomes andalleviating professional strain, albeit confronted by hurdles related to training and the accountability of AI systems.Integrating Large Pre-trained Models such as ChatGPT into healthcare has shown promise in enhancing medicaleducation, patient communication, and clinical decision-making. Lyu et al. [99] demonstrated ChatGPT\u2019s ability tosimplify radiology reports for patients and healthcare providers, highlighting the potential for improved clinicaleducation despite noting areas for accuracy and specificity enhancements. Kung et al. [87] found that ChatGPT scoredat or near the passing threshold on the USMLE, suggesting its capability to support medical education and hinting atfuture roles in clinical settings. Johnson et al. [72] further validated ChatGPT\u2019s usefulness by showing its generallyaccurate responses to a range of medical questions, though recognizing the need for further refinement.5.2 Autonomous VehiclesAdvancements in autonomous driving promise safer, AI-enhanced transportation, with significant milestones achievedin vehicle sensing and decision-making [4]. Key to these advancements is understanding Human-AI collaboration,particularly during critical transitions between automated and manual driving modes, as explored by Lv et al. [97]. Thisresearch highlights the importance of seamless transitions for safety, showing improvements in control and stabilitywith a new hybrid driving model. Additionally, establishing trust in AI through transparent decision-making processesunder uncertainty is crucial, as Jianlong and Chen [181] discuss with a novel framework aimed at enhancing Human-AIcollaboration. Fuchs et al. [48] further examine the managerial aspects of task delegation between humans and AI,proposing reinforcement learning to optimize collaboration and improve autonomous system performance, includingdriving.Building on foundational studies, recent explorations into large language models (LLMs) signal a transformative era inautonomous driving technologies. Yang et al.[175] underscore the importance of LLMs for interpreting user commandsin complex scenarios, emphasizing the necessity of model quality and prompt design. Park et al. [124] introduce VLAAD,a multi-modal LLM that demonstrates proficient interpretive capabilities across varied driving situations, showcasingthe potential of natural language models in enhancing decision-making processes. Cui et al. [35] propose a framework22 Vats and Nizam, et al.that integrates LLMs for improved decision-making in autonomous vehicles, aiming for personalized assistance andefficient operation. Wang et al. [164] discuss using LLMs as behavior planners to ensure safety in decision-makingby interpreting driving scenes and adjusting trajectory plans based on safety constraints. More generally, Wen et al.[169] highlight the role of Visual Language Models (VLMs) like GPT-4V in scene understanding and decision-making,noting superior performance but also pointing out existing challenges. Additionally, Wang et al. [162] describe anend-to-end autonomous driving system using multimodal foundation models to enhance adaptability and robustnessin diverse environments, leveraging pixel-aligned features and language-based latent space simulation for improveddata augmentation and policy debugging (Fig. 7). Together, these studies highlight the transformative potential oflarge foundation models in advancing autonomous vehicle technologies, from improving interpretive capabilities toenhancing decision-making processes and data generation.5.3 Surveillance and SecurityThe advancements in vision-based AI and IoT-connected cameras have heightened the potential for AI in cybersecurity[125], including in Cyber Security Incident Response Teams (CSIRTs) [79]. Determining the optimal level of AI autonomyin these settings is critical. A study by Hauptman et al. [61] explored this through a mixed-method approach, assessingAI\u2019s role across the CSIRT cycle\u2014preparation, identification, containment, eradication, and recovery. Surveying 103cybersecurity professionals and conducting interviews with 22, the study found that higher AI autonomy is preferredduring the identification phase, while lower autonomy suits high-risk phases better. This suggests that adaptive AI, withproper team training, can integrate effectively into CSIRTs, enhancing teamwork and response efficiency. Furthermore,the real-time update preference and successful integration of human and machine intelligence in crowd-poweredcamera sensing, as noted by Guo et al. [56], highlights the potential for enhancing cybersecurity measures throughimproved situational awareness and resource management.Moreover, the utilization of LLMs for video surveillance analysis, as proposed by Chen et al. [23], with the VideoLLMframework, demonstrates the potential for transferring LLMs\u2019 understanding and reasoning capabilities to videounderstanding tasks, offering a unified approach for various video-based security challenges. Additionally, Jain\u2019s [69]insights into integrating ChatGPT with video security underscore the gradually increasing impact of foundation modelson physical security systems, enhancing operational efficiency and surfacing new insights for businesses.5.4 GamesGames serve as a dynamic platform for interaction, typically involving multiple human players engaging throughvarious forms of competition or collaboration, each game offering unique goals and gameplay mechanics. The essenceof these interactions often relies on the expressiveness unique to human participants, critical for optimal play. However,the advent of advanced Large Language Models (LLMs), such as ChatGPT, has expanded the potential for AI to mimicthis human expressiveness, opening new avenues for AI to compete alongside or against humans in a broader array ofgaming contexts. This segment delves into the integration of LLM-driven AIs as alternatives to human players withingames, alongside their application in generating content for video games, marking a significant evolution in gamedesign and interaction.5.4.1 LLM-Based AI as Players. Artificial intelligence has long been utilized in video games, from serving as basicadversaries in titles like Mario Kart [145] to mastering complex games such as chess, demonstrating AI\u2019s algorithmicprowess. Yet, these AIs often fell short as complete substitutes for human players due to their lack of flexibility andA Survey on Human-AI Teaming with Large Pre-Trained Models 23limited language processing capabilities. The advent of LLMs has shifted this landscape, offering AIs that can engagewith humans in more expressive ways, suitable across a broader spectrum of games.Research into LLMs as game players, while in its nascent stages, has yielded intriguing insights. For instance, Frans[46] showcases \"AI Charades\" using GPT-2 to illustrate LLMs\u2019 potential in games requiring deep language interaction,highlighting their structured uncertainty\u2014an attribute highly valued in games traditionally reliant on human partners.Xu et al.\u2019s [174] exploration into LLMs within the social deduction game Werewolf demonstrates these AIs\u2019 capabilityfor strategic play, underscoring the necessity for advanced language understanding and social intuition. However,challenges such as limited input lengths and the impracticality of fine-tuning LLMs for specific games highlight currentlimitations.Further critical examination by Sobieszek and Price [142] raise concerns over LLMs\u2019 reliability in information delivery,emphasizing the risk of information pollution due to GPT-3\u2019s occasionally untruthful responses. Research evaluatingGPT models in social and moral contexts reveals mixed results, with models showing promise in single-player strategiesbut struggling in cooperative, ethical scenarios [2]. This suggests a need for further development in LLMs\u2019 ability tonavigate complex social interactions and ethical decision-making. Despite these challenges, the expressive capabilitiesof LLMs compared to earlier AI models mark a significant advancement in human-computer interaction within games.5.4.2 LLMs for Content Generation in Games. Large Language Models have significantly impacted game devel-opment, from generating complex game levels as demonstrated by Todd et al.[150], to enriching RPGs with dynamicquest narratives through advancements shown by Vartinen et al. [156]. These models enhance game narratives andenvironment design, also facilitating interactive tutorials and support systems, a concept explored by Frans [46] withLanguage Model Games. Despite their potential, challenges persist, including ensuring content quality and coherence,addressing ethical concerns, and maintaining player immersion. The instructRL framework by Hu and Sadigh [66] offerinsights into fine-tuning LLM integration for effective human-AI interaction in games. Advancing LLM applications ingaming requires addressing these hurdles through hybrid approaches and ethical guidelines.5.5 EducationThe integration of AI in education is revolutionizing teaching and learning by enabling personalized learning experiencesthrough the analysis of student performance and real-time feedback. This advancement fosters increased studentengagement and improved learning outcomes, yet raises concerns about data privacy and the transparency of AIdecisions.Intelligent Tutoring Systems (ITSs), such as Carnegie Learning\u2019s Mika platform, demonstrate AI\u2019s ability to tailoreducation to individual needs, showing promising results like higher exam scores and reduced dropout rates [118,155]. However, the opacity of AI\u2019s decision-making has sparked debates over potential biases [170]. Despite thesechallenges, companies like Century Tech and Fishtree have successfully incorporated AI to enhance personalizedlearning experiences [77]. Virtual learning agents, including Georgia Tech\u2019s chatbot Jill Watson, have been developed tosupplement teaching by handling administrative queries or facilitating peer collaboration, albeit with risks of fosteringparasocial relationships with digital avatars [40, 60]. Moreover, automated essay scoring systems offered by EdX andPearson exemplify AI\u2019s efficiency in grading, aligning closely with human grader assessments while saving time andcosts [38]. Nonetheless, there remains skepticism about AI\u2019s ability to fully grasp the subtleties of written expressions,highlighting the ongoing need for advancements in natural language processing.24 Vats and Nizam, et al.The use of LLMs in education is poised to personalize learning experiences further. Extance [42] explores the practicaldeployment of AI chatbots as interactive learning tools, demonstrating their potential to enhance the teaching andlearning dynamic significantly. However, Milano et al. [141] raise critical points regarding the operational, ethical, andenvironmental considerations of LLMs in educational settings, emphasizing the need for sustainable and transparentpractices. These insights offer a deeper look at AI\u2019s role in education, balancing technological innovation with mindfulconsideration of its broader impacts [22, 62, 161].5.6 AccessibilityAssistive technologies powered by artificial intelligence (AI) are revolutionizing support for individuals with sensory andphysical disabilities, offering innovative solutions for improved mobility and communication. A notable advancement isa deep learning-based navigation assistant for the visually impaired, which employs computer vision to facilitate obstacledetection and navigation with remarkable accuracy, as demonstrated in the work by [86]. Similarly, the development ofcommunication aids for the deaf, utilizing audio-visual recognition algorithms, provides an automated solution thatenhances daily interactions, a concept explored by [122]. These technologies exemplify the transformative potentialof AI in creating more inclusive environments, with significant improvements in user independence and quality oflife. Further contributions include a compact, low-cost visual aid system for blind individuals that integrates advancedimage processing for obstacle avoidance and object detection [78], and an AI-enabled sign language recognition systemthat supports sentence-level communication for the hearing/speech impaired [168]. Additionally, the deployment ofservice robots to assist the elderly in shopping tasks demonstrates the practical applications of AI in facilitating dailyactivities [52].In addition to these technological innovations, recent studies highlight the opportunities and challenges presentedby large language models in promoting accessibility. Taheri et al.[147] explore the potential of text-to-image generationmodels to revolutionize accessible art creation, demonstrating how generative text models can reduce typing effortand make visual art creation more accessible to people with diverse abilities. In contrast, Gadiraju et al.[49] shed lighton the subtle yet harmful biases LLMs can perpetuate towards disabled communities, emphasizing the importanceof incorporating disability-positive resources in training data to foster a more inclusive digital environment. Theseinsights underline the evolving landscape of AI-driven accessibility tools, while also stressing the need for continuousrefinement and inclusivity in their development.6 CONCLUSIONThis survey on Human-AI (HAI) Teaming, with a focus on Large Pre-trained Models (LPtM), underscores a notableevolution in collaborative problem-solving and decision-making. Integrating human expertise into AI model traininghas enhanced performance and fostered intuitive and effective human-AI interactions. Safety, security, and trust emergeas critical components, requiring a balanced approach between technological progress and ensuring privacy and fairness.The survey\u2019s exploration across various sectors, including healthcare, autonomous vehicles, and education, showcasesHAI\u2019s versatility in addressing unique challenges and enhancing societal benefits. As we advance, the integration ofhuman intelligence with LPtMs looks like a promising domain in unlocking innovative solutions and improving overalldecision-making. The future of HAI Teaming will hinge on navigating its challenges responsibly, ensuring ethicalalignment, and maximizing its societal impact. This research contributes to the academic dialogue, offering insightsfor future exploration, policy-making, and strategic development towards a collaborative, effective, and equitable HAIecosystem.A Survey on Human-AI Teaming with Large Pre-Trained Models 25REFERENCES[1] Aakash Ahmad, Muhammad Waseem, Peng Liang, Mahdi Fahmideh, Mst Shamima Aktar, and Tommi Mikkonen. 2023. Towards human-botcollaborative software architecting with ChatGPT. In Proceedings of the 27th International Conference on Evaluation and Assessment in SoftwareEngineering. 279\u2013285.[2] Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. 2023. Playing repeated games with Large LanguageModels. arXiv preprint arXiv:2305.16867 (2023).[3] Zahra Ashktorab, Vera Liao, Casey Dugan, James Johnson, Qian Pan, Wei Zhang, Sadhana Kumaravel, and Murray Campbell. 2020. Human-AICollaboration in a Cooperative Game Setting: Measuring Social Perception and Outcomes. Proceedings of the ACM on Human-Computer Interaction4 (10 2020), 1\u201320. https://doi.org/10.1145/3415167[4] Shahin Atakishiyev, Mohammad Salameh, Hengshuai Yao, and Randy Goebel. 2021. Explainable Artificial Intelligence for Autonomous Driving: AComprehensive Overview and Field Guide for Future Research Directions. arXiv preprint arXiv:2112.11561 (12 2021).[5] Arun Kumar AV, Santu Rana, Alistair Shilton, and Svetha Venkatesh. 2022. Human-AI Collaborative Bayesian Optimisation. Advances in NeuralInformation Processing Systems 35 (2022), 16233\u201316245.[6] Gagan Bansal, Besmira Nushi, Ece Kamar, Walter S Lasecki, Daniel S Weld, and Eric Horvitz. 2019. Beyond accuracy: The role of mental models inhuman-AI team performance. In Proceedings of the AAAI conference on human computation and crowdsourcing. 2\u201311.[7] Gagan Bansal, Tongshuang Wu, Joyce Zhou, Raymond Fok, Besmira Nushi, Ece Kamar, Marco Tulio Ribeiro, and Daniel Weld. 2021. Does thewhole exceed its parts? the effect of AI explanations on complementary team performance. In Proceedings of the 2021 CHI Conference on HumanFactors in Computing Systems. 1\u201316.[8] Yujia Bao, Shiyu Chang, Mo Yu, and Regina Barzilay. 2018. Deriving Machine Attention fromHuman Rationales. In Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing, Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun\u2019ichi Tsujii (Eds.). Association forComputational Linguistics, Brussels, Belgium, 1903\u20131913. https://doi.org/10.18653/v1/D18-1216[9] David Bau, Hendrik Strobelt, William Peebles, Jonas Wulff, Bolei Zhou, Jun-Yan Zhu, and Antonio Torralba. 2019. Semantic Photo Manipulationwith a Generative Image Prior. ACM Trans. Graph. 38, 4, Article 59 (jul 2019), 11 pages. https://doi.org/10.1145/3306346.3323023[10] Guanqun Bi, Lei Shen, Yuqiang Xie, Yanan Cao, Tiangang Zhu, and Xiaodong He. 2023. A Group Fairness Lens for Large Language Models. arXivpreprint arXiv:2312.15478 (2023).[11] Nadine Bienefeld, Michaela Kolbe, Giovanni Camen, Dominic Huser, and Philipp Karl Buehler. 2023. Human-AI teaming: leveraging transactivememory and speaking up for enhanced team effectiveness. Frontiers in Psychology 14 (2023).[12] Marcel Binz, Stephan Alaniz, Adina Roskies, Balazs Aczel, Carl T Bergstrom, Colin Allen, Daniel Schad, Dirk Wulff, Jevin D West, Qiong Zhang,et al. 2023. How should the advent of large language models affect the practice of science? arXiv preprint arXiv:2312.03759 (2023).[13] Matthias Braun, Hannah Bleher, and Patrik Hummel. 2021. A Leap of Faith: Is There a Formula for \u201cTrustworthy\u201d AI? The Hastings Center Report51 (2021), 17\u201322.[14] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, JeffreyWu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner,Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models Are Few-Shot Learners. In Proceedings of the 34thInternational Conference on Neural Information Processing Systems (Vancouver, BC, Canada) (NIPS\u201920). Curran Associates Inc., Red Hook, NY, USA,Article 159, 25 pages.[15] Yang Li Bryan Wang, Gang Li. 2023. Enabling Conversational Interaction with Mobile UI using Large Language Models. In Proceedings of the 2023CHI Conference on Human Factors in Computing Systems. ACM, New York, NY, USA, Hamburg, Germany. Accessed: 2023-11-28.[16] Samuel Budd, Emma C. Robinson, and Bernhard Kainz. 2021. A survey on active learning and human-in-the-loop deep learning for medical imageanalysis. Medical Image Analysis 71 (jul 2021), 102062. https://doi.org/10.1016/j.media.2021.102062[17] Carrie J Cai, Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel Smilkov, Martin Wattenberg, Fernanda Viegas, Greg S Corrado, Martin CStumpe, et al. 2019. Human-centered tools for coping with imperfect algorithms during medical decision-making. In Proceedings of the 2019 chiconference on human factors in computing systems. 1\u201314.[18] Sabrina Caldwell, Penny Sweetser, Nicholas O\u2019Donnell, Matthew J Knight, Matthew Aitchison, Tom Gedeon, Daniel Johnson, Margot Brereton,Marcus Gallagher, and David Conroy. 2022. An agile new research framework for hybrid human-AI teaming: Trust, transparency, and transferability.ACM Transactions on Interactive Intelligent Systems (TiiS) 12, 3 (2022), 1\u201336.[19] Corinne Cath, Sandra Wachter, Brent Mittelstadt, Mariarosaria Taddeo, and Luciano Floridi. 2018. Artificial intelligence and the \u2018good society\u2019: theUS, EU, and UK approach. Science and engineering ethics 24 (2018), 505\u2013528.[20] Tuhin Chakrabarty, Arkadiy Saakyan, Olivia Winn, Artemis Panagopoulou, Yue Yang, Marianna Apidianaki, and Smaranda Muresan. 2023. I spy ametaphor: Large language models and diffusion models co-create visual metaphors. arXiv preprint arXiv:2305.14724 (2023).[21] Tathagata Chakraborti, Subbarao Kambhampati, Matthias Scheutz, and Yu Zhang. 2017. AI challenges in human-robot cognitive teaming. arXivpreprint arXiv:1707.04775 (2017).[22] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, YueZhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. 2023. A Survey on Evaluation of Large Language Models. arXiv preprint arXiv:2307.0310926 Vats and Nizam, et al.(2023). arXiv:2307.03109 [cs.CL][23] Guo Chen, Yin-Dong Zheng, Jiahao Wang, Jilan Xu, Yifei Huang, Junting Pan, Yi Wang, Yali Wang, Yu Qiao, Tong Lu, and Limin Wang. 2023.VideoLLM: Modeling Video Sequence with Large Language Models. arXiv preprint arXiv:2305.13292 (2023).[24] Yuhao Chen, Chloe Wong, Hanwen Yang, Juan Aguenza, Sai Bhujangari, Benthan Vu, Xun Lei, Amisha Prasad, Manny Fluss, Eric Phuong, MinghaoLiu, Raja Kumar, Vanshika Vats, and James Davis. 2024. Assessing the Impact of Prompting Methods on ChatGPT\u2019s Mathematical Capabilities.arXiv preprint arXiv:2312.15006 (2024).[25] Nalin Chhibber, Joslin Goh, and Edith Law. 2022. Teachable Conversational Agents for Crowdwork: Effects on Performance and Trust. Proceedingsof the ACM on Human-Computer Interaction 6 (2022), 1\u201321. https://doi.org/10.1145/3555223[26] Cheng-Han Chiang and Hung-yi Lee. 2023. Can Large Language Models Be an Alternative to Human Evaluations? arXiv preprint arXiv:2305.01937(2023).[27] Avishek Choudhury and Onur Asan. 2022. Impact of accountability, training, and human factors on the use of artificial intelligence in healthcare:Exploring the perceptions of healthcare practitioners in the US. Human Factors in Healthcare 2 (2022), 100021. https://doi.org/10.1016/j.hfh.2022.100021[28] Soumyadeb Chowdhury, Pawan Budhwar, Prasanta Kumar Dey, Sian Joel-Edgar, and Amelie Abadie. 2022. AI-employee collaboration and businessperformance: Integrating knowledge-based view, socio-technical systems and organisational socialisation framework. Journal of Business Research144 (2022), 31\u201349. https://doi.org/10.1016/j.jbusres.2022.01.069[29] Paul F. Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and Dario Amodei. 2017. Deep Reinforcement Learning from HumanPreferences. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December4-9, 2017, Long Beach, CA, USA, Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, andRoman Garnett (Eds.). 4299\u20134307. https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html[30] Elizabeth Clark, Tal August, Sofia Serrano, Nikita Haduong, Suchin Gururangan, and Noah A Smith. 2021. All that\u2019s\u2019 human\u2019is not gold: Evaluatinghuman evaluation of generated text. arXiv preprint arXiv:2107.00061 (2021).[31] Lei Clark, Abdulmalik Ofemile, Svenja Adolphs, and Tom Rodden. 2016. A multimodal approach to assessing user experiences with agent helpers.ACM Transactions on Interactive Intelligent Systems (2016).[32] William Clark, Jan Golinski, and Simon Schaffer. 1999. The Sciences in Enlightened Europe. University of Chicago Press.[33] Nicholas Conlon, Nisar Ahmed, and Daniel Szafir. 2023. A Survey of Algorithmic Methods for Competency Self-Assessments in Human-AutonomyTeaming. Comput. Surveys (08 2023). https://doi.org/10.1145/3616010[34] Ant\u00f3nio Correia, Andrea Grover, Daniel Schneider, Ana Paula Pimentel, Ramon Chaves, Marcos Antonio de Almeida, and Benjamim Fonseca. 2023.Designing for Hybrid Intelligence: A Taxonomy and Survey of Crowd-Machine Interaction. Applied Sciences 13 (2023). https://www.mdpi.com/2076-3417/13/4/2198[35] Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, and Ziran Wang. 2024. Drive As You Speak: Enabling Human-Like Interaction With Large LanguageModels in Autonomous Vehicles. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops. 902\u2013909.[36] Luigi De Angelis, Francesco Baglivo, Guglielmo Arzilli, Gaetano Pierpaolo Privitera, Paolo Ferragina, Alberto Eugenio Tozzi, and Caterina Rizzo.2023. ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health. Frontiers in Public Health 11 (2023),1166120.[37] Petar Despotovic and Yevgen Bogodistov. 2024. Does ChatGPT Alter Job Seekers\u2019 Identity? An Experimental Study. Proceedings of the 57th HawaiiInternational Conference on System Sciences (2024).[38] Semire Dikli. 2006. Automated essay scoring. Turkish Online Journal of Distance Education 7, 1 (2006), 49\u201362.[39] Alpana Dubey, Kumar Abhinav, Sakshi Jain, Veenu Arora, and Asha Puttaveerana. 2020. HACO: A Framework for Developing Human-AI Teaming.In Proceedings of the 13th Innovations in Software Engineering Conference on Formerly Known as India Software Engineering Conference (Jabalpur,India) (ISEC 2020). Association for Computing Machinery, New York, NY, USA, Article 10, 9 pages. https://doi.org/10.1145/3385032.3385044[40] Bobbie Eicher, Lalith Polepeddi, and Ashok Goel. 2018. Jill Watson doesn\u2019t care if you\u2019re pregnant: Grounding AI ethics in empirical studies. InProceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society. 88\u201394.[41] Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. 2023. GPTs are GPTs: An Early Look at the Labor Market Impact Potential ofLarge Language Models. arXiv preprint arXiv:2303.10130 (2023).[42] Andy Extance. 2023. ChatGPT has entered the classroom: how LLMs could transform education. Nature (2023). https://doi.org/10.1038/d41586-023-03507-3[43] Neta Ezer, S. Bruni, Yang Cai, S. Hepenstal, C. Miller, and D. Schmorrow. 2019. Trust Engineering for Human-AI Teams. Proceedings of the HumanFactors and Ergonomics Society Annual Meeting 63 (2019), 322 \u2013 326. https://doi.org/10.1177/1071181319631264[44] Mingming Fan, Xianyou Yang, TszTung Yu, Q Vera Liao, and Jian Zhao. 2022. Human-AI collaboration for UX evaluation: Effects of explanationand synchronization. Proceedings of the ACM on Human-Computer Interaction 6, CSCW1 (2022), 1\u201332.[45] Christopher Flathmann, Beau Schelble, and Nathan McNeese Rui Zhang. 2021. Modeling and Guiding the Creation of Ethical Human-AI Team. InProceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society (2021). https://doi.org/doi/pdf/10.1145/3461702.3462573[46] Kevin Frans. 2021. AI Charades: Language Models as Interactive Game Environments. In 2021 IEEE Conference on Games (CoG). IEEE, 1\u20132.[47] Scott Freeman, Sarah L. Eddy, Miles McDonough, Michelle K. Smith, Nnadozie Okoroafor, Hannah Jordt, and Mary Pat Wenderoth. 2014. Activelearning increases student performance in science, engineering, and mathematics. Proceedings of the National Academy of Sciences 111 (2014), 8410A Survey on Human-AI Teaming with Large Pre-Trained Models 27\u2013 8415. https://api.semanticscholar.org/CorpusID:219206935[48] Andrew Fuchs, Andrea Passarella, and Marco Conti. 2023. Compensating for Sensing Failures via Delegation in Human-AI Hybrid Systems. Sensors23, 7 (2023), 3409.[49] Vinitha Gadiraju, Shaun Kane, Sunipa Dev, Alex Taylor, Ding Wang, Emily Denton, and Robin Brewer. 2023. \"I wouldn\u2019t say offensive but...\":Disability-Centered Perspectives on Large Language Models. In FAccT \u201923: Proceedings of the 2023 ACM Conference on Fairness, Accountability, andTransparency (Chicago, IL, USA). Association for Computing Machinery, New York, NY, USA, 205\u2013216. https://doi.org/10.1145/3593013.3593989[50] Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, Tong Yu, Ruiyi Zhang, and Nesreen KAhmed. 2023. Bias and fairness in large language models: A survey. arXiv preprint arXiv:2309.00770 (2023).[51] Andreas Geiger, Philip Lenz, and Raquel Urtasun. 2012. Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite. In Conferenceon Computer Vision and Pattern Recognition (CVPR).[52] Mohammed Ghazal, Maha Yaghi, Abdalla Gad, Gasm El Bary, Marah Alhalabi, Mohammad Alkhedher, and Ayman S. El-Baz. 2021. AI-PoweredService Robotics for Independent Shopping Experiences by Elderly and Disabled People. Applied Sciences 11, 19 (Sept. 2021), 9007. https://doi.org/10.3390/app11199007[53] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In International Conference onLearning Representations.[54] D. Gopinath, J. DeCastro, G. Rosman, E. Sumner, A. Morgan, S. Hakimi, and S. Stent. 2022. HMIway-env: A Framework for Simulating Behaviorsand Preferences to Support Human-AI Teaming in Driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition(2022). https://doi.org/content/CVPR2022W/HCIS/papers/Gopinath_HMIway-Env_A_Framework_for_Simulating_Behaviors_and_Preferences_To_Support_CVPRW_2022_paper.pdf[55] Ben Green and Yiling Chen. 2019. The Principles and Limits of Algorithm-in-the-Loop Decision Making. Proc. ACM Hum.-Comput. Interact. 3,CSCW, Article 50 (nov 2019), 24 pages. https://doi.org/10.1145/3359152[56] Anhong Guo, Anuraag Jain, Shomiron Ghose, Gierad Laput, Chris Harrison, and Jeffrey P. Bigham. 2018. Crowd-AI Camera Sensing in the RealWorld. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 3, Article 111 (sep 2018), 20 pages. https://doi.org/10.1145/3264921[57] Maanak Gupta, CharanKumar Akiri, Kshitiz Aryal, Eli Parker, and Lopamudra Praharaj. 2023. From chatGPT to threatGPT: Impact of generativeAI in cybersecurity and privacy. IEEE Access (2023).[58] Philipp Hacker, Andreas Engel, and Marco Mauer. 2023. Regulating ChatGPT and other large generative AI models. In Proceedings of the 2023 ACMConference on Fairness, Accountability, and Transparency. 1112\u20131123.[59] Stefan Harrer. 2023. Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine.EBioMedicine 90 (2023).[60] Luminita Hartle and Tara Kaczorowski. 2019. The positive aspects of Mursion when teaching higher education students. Quarterly Review ofDistance Education 20, 4 (2019), 71\u2013100.[61] Allyson I Hauptman, Beau G Schelble, Nathan J McNeese, and Kapil Chalil Madathil. 2023. Adapt and overcome: Perceptions of adaptive autonomousagents for human-AI teaming. Computers in Human Behavior 138 (2023), 107451.[62] Arto Hellas, Juho Leinonen, Sami Sarsa, Charles Koutcheme, Lilja Kujanp\u00e4\u00e4, and Juha Sorva. 2023. Exploring the Responses of Large LanguageModels to Beginner Programmers\u2019 Help Requests. In Proceedings of the 2023 ACM Conference on International Computing Education Research -Volume 1 (<conf-loc>, <city>Chicago</city>, <state>IL</state>, <country>USA</country>, </conf-loc>) (ICER \u201923). Association for ComputingMachinery, New York, NY, USA, 93\u2013105. https://doi.org/10.1145/3568813.3600139[63] Patrick Hemmer, Monika Westphal, Max Schemmer, Sebastian Vetter, Michael V\u00f6ssing, and Gerhard Satzger. 2023. Human-AI Collaboration: TheEffect of AI Delegation on Human Task Performance and Task Satisfaction. In Proceedings of the 28th International Conference on Intelligent UserInterfaces (Sydney, NSW, Australia) (IUI \u201923). Association for Computing Machinery, New York, NY, USA, 453\u2013463. https://doi.org/10.1145/3581641.3584052[64] Katharine E Henry, Rachel Kornfield, Anirudh Sridharan, Robert C Linton, Catherine Groh, Tony Wang, Albert Wu, Bilge Mutlu, and Suchi Saria.2022. Human\u2013machine teaming is key to AI adoption: clinicians\u2019 experiences with a deployed machine learning system. NPJ digital medicine 5, 1(2022), 97.[65] Keke Hou, Tingting Hou, and Cai Lili. 2023. Exploring Trust in Human-AI Collaboration in the Context of Multiplayer Online Games. Systems.Human\u2013AI Teaming: Synergy, Decision-Making and Interdependency (2023). https://doi.org/10.3390/systems11050217[66] Hengyuan Hu and Dorsa Sadigh. 2023. Language Instructed Reinforcement Learning for Human-AI Coordination. arXiv preprint arXiv:2304.07297(2023).[67] Dong Huang, Qingwen Bu, Jie Zhang, Xiaofei Xie, Junjie Chen, and Heming Cui. 2023. Bias assessment and mitigation in LLM-based codegeneration. arXiv preprint arXiv:2309.14345 (2023).[68] Borja Ibarz, Jan Leike, Tobias Pohlen, Geoffrey Irving, Shane Legg, and Dario Amodei. 2018. Reward learning from human preferences anddemonstrations in Atari. In Proceedings of the 32nd International Conference on Neural Information Processing Systems (Montr\u00e9al, Canada) (NIPS\u201918).Curran Associates Inc., Red Hook, NY, USA, 8022\u20138034.[69] Ashesh Jain. 2023. ChatGPT Meets Video Security: A New Era of Intelligent Surveillance. https://www.coram.ai/post/chatgpt-meets-video-security[70] Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath Hariharan, and Ser-Nam Lim. 2022. Visual Prompt Tuning. InEuropean Conference on Computer Vision (ECCV).28 Vats and Nizam, et al.[71] Anna Jobin, Marcello Ienca, and Effy Vayena. 2019. The global landscape of AI ethics guidelines. Nature machine intelligence 1, 9 (2019), 389\u2013399.[72] Douglas B Johnson, Rachel S Goodman, J Randall Patrinely, Cosby A Stone, Eli Zimmerman, Rebecca Rigel Donald, Sam S Chang, Sean T Berkowitz,Avni P Finn, Eiman Jahangir, Elizabeth A Scoville, Tyler Reese, Debra E. Friedman, Julie A. Bastarache, Yuri F van der Heijden, Jordan Wright,Nicholas Carter, Matthew R Alexander, Jennifer H Choe, Cody A Chastain, John Zic, Sara Horst, Isik Turker, Rajiv Agarwal, Evan C. Osmundson,Kamran Idrees, Colleen M. Kiernan, Chandrasekhar Padmanabhan, Christina Edwards Bailey, Cameron Schlegel, Lola B. Chambless, Mike Gibson,Travis J. Osterman, and Lee Wheless. 2023. Assessing the Accuracy and Reliability of AI-Generated Medical Responses: An Evaluation of theChat-GPT Model. Research Square (2023). https://api.semanticscholar.org/CorpusID:257437276[73] Matthew Johnson and Alonso Vera. 2019. No AI is an island: the case for teaming intelligence. AI magazine 40, 1 (2019), 16\u201328.[74] Leslie Pack Kaelbling, Michael L Littman, and Andrew W Moore. 1996. Reinforcement learning: A survey. Journal of artificial intelligence research 4(1996), 237\u2013285.[75] Georgios A Kaissis, Marcus R Makowski, Daniel R\u00fcckert, and Rickmer F Braren. 2020. Secure, privacy-preserving and federated machine learningin medical imaging. Nature Machine Intelligence 2, 6 (2020), 305\u2013311.[76] Frank Kaptein, Joost Broekens, Koen V Hindriks, and Mark Neerincx. 2016. CAAF: A cognitive affective agent programming framework. EngineeringPsychology and Cognitive Ergonomics 10906 (2016), 317\u2013330.[77] Vinothini Kasinathan, Aida Mustapha, and Imran Medi. 2017. Adaptive learning system for higher learning. In 2017 8th international conference oninformation technology (ICIT). IEEE, 960\u2013970.[78] Muiz Ahmed Khan, Pias Paul, Mahmudur Rashid, Mainul Hossain, and Md Atiqur Rahman Ahad. 2020. An AI-Based Visual Aid With IntegratedReading Assistant for the Completely Blind. IEEE Transactions on Human-Machine Systems 50, 6 (2020), 507\u2013517. https://doi.org/10.1109/THMS.2020.3027534[79] Georgia Killcrece, Klaus-Peter Kossakowski, Robin Ruefle, and Mark Zajicek. 2003. State of the Practice of Computer Security Incident ResponseTeams (CSIRTs). Technical Report CMU/SEI-2003-TR-001. Carnegie Mellon University, Software Engineering Institute\u2019s Digital Library. https://doi.org/10.1184/R1/6584396.v1 Accessed: 2024-Feb-13.[80] Sunnie SY Kim, Elizabeth AnneWatkins, Olga Russakovsky, Ruth Fong, and Andr\u00e9s Monroy-Hern\u00e1ndez. 2023. \"HelpMeHelp the AI\": UnderstandingHow Explainability Can Support Human-AI Interaction. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. 1\u201317.[81] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg,Wan-Yen Lo, Piotr Doll\u00e1r, and Ross Girshick. 2023. Segment Anything. arXiv preprint arXiv:2304.02643 (2023).[82] Hannah Rose Kirk, Yennie Jun, Filippo Volpin, Haider Iqbal, Elias Benussi, Frederic Dreyer, Aleksandar Shtedritski, and Yuki Asano. 2021. Biasout-of-the-box: An empirical analysis of intersectional occupational biases in popular generative language models. Advances in neural informationprocessing systems 34 (2021), 2611\u20132624.[83] Konstantinos Konstantis, Antonios Georgas, Antonis Faras, Konstantinos Georgas, and Aristotle Tympas. 2023. Ethical considerations in workingwith ChatGPT on a questionnaire about the future of work with ChatGPT. AI and Ethics (Online) (2023). https://doi.org/10.1007/s43681-023-00312-6[84] Hadas Kotek, Rikker Dockum, and David Sun. 2023. Gender bias and stereotypes in Large Language Models. In Proceedings of The ACM CollectiveIntelligence Conference (Delft, Netherlands) (CI \u201923). Association for Computing Machinery, New York, NY, USA, 12\u201324. https://doi.org/10.1145/3582269.3615599[85] Steve WJ Kozlowski and Daniel R Ilgen. 2006. Enhancing the effectiveness of work groups and teams. Psychological science in the public interest.Psychological Science in the Public Interest (2006).[86] Nitin Kumar and Anuj Jain. 2022. A Deep Learning Based Model to Assist Blind People in Their Navigation. Journal of Information TechnologyEducation: Innovations in Practice 21 (2022), 095\u2013114.[87] Tiffany H Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De Leon, Camille Elepa\u00f1o, Maria Madriaga, Rimel Aggabao, GiezelDiaz-Candido, James Maningo, et al. 2023. Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large languagemodels. PLoS digital health 2, 2 (2023), e0000198.[88] Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, AbhinavRastogi, and Sushant Prakash. 2023. RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback.[89] S\u00e9verin Lemaignan, MathieuWarnier, E. Akin Sisbot, Aur\u00e9lie Clodic, and Rachid Alami. 2017. Artificial cognition for social human\u2013robot interaction:An implementation. Artificial Intelligence 247 (2017), 45\u201369.[90] Bruno Lepri, Nuria Oliver, and Alex Pentland. 2021. Ethical machines: The human-centric use of artificial intelligence. IScience 24, 3 (2021).[91] Piyawat Lertvittayakumjorn, Lucia Specia, and Francesca Toni. 2020. Human-in-the-loop Debugging Deep Text Classifiers. arXiv preprintarXiv:2010.04987 abs/2010.04987 (2020). https://api.semanticscholar.org/CorpusID:222290812[92] Yingji Li, Mengnan Du, Rui Song, Xin Wang, and Ying Wang. 2023. A survey on fairness in large language models. arXiv preprint arXiv:2308.10149(2023).[93] Minghao Liu, Zeyu Cheng, Shen Sang, Jing Liu, and James Davis. 2023. Tag-based annotation creates better avatars. arXiv preprint arXiv:2302.07354(2023).[94] Minghao Liu, Jiaheng Wei, Yang Liu, and James Davis. 2023. Do humans and machines have the same eyes? Human-machine perceptual differenceson image classification. arXiv preprint arXiv:2304.08733 (2023).[95] Jinghui Lu, Linyi Yang, Brian Mac Namee, and Yue Zhang. 2022. A Rationale-Centric Framework for Human-in-the-loop Machine Learning. InAnnual Meeting of the Association for Computational Linguistics. https://api.semanticscholar.org/CorpusID:247627717A Survey on Human-AI Teaming with Large Pre-Trained Models 29[96] Xinyi Lu, Simin Fan, Jessica Houghton, Lu Wang, and Xu Wang. 2023. ReadingQuizMaker: A Human-NLP Collaborative System that SupportsInstructors to Design High-Quality Reading Quiz Questions. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems.1\u201318.[97] Chen Lv, Yutong Li, Yang Xing, Chao Huang, Dongpu Cao, Yifan Zhao, and Yahui Liu. 2021. Human-Machine Collaboration for Automated DrivingUsing an Intelligent Two-Phase Haptic Interface. Advanced Intelligent Systems (02 2021), 2000229. https://doi.org/10.1002/aisy.202000229[98] Joseph B Lyons, Kevin T Wynne, Sean Mahoney, and Mark A Roebke. 2019. Trust and human-machine teaming: A qualitative study. In Artificialintelligence for the internet of everything. Elsevier, 101\u2013116.[99] Qing Lyu, Josh Tan, Mike E Zapadka, Janardhana Ponnatapuram, Chuang Niu, Ge Wang, and Christopher T Whitlow. 2023. Translating radiologyreports into plain language using chatGPT and GPT-4 with prompt learning: Promising results, limitations, and potential. arXiv preprintarXiv:2303.09038 (2023).[100] Mansoureh Maadi, Hadi Akbarzadeh Khorshidi, and Uwe Aickelin. 2021. A Review on Human\u2013AI Interaction in Machine Learning and Insights forMedical Applications. International Journal of Environmental Research and Public Health 18 (2021). https://doi.org/10.3390/ijerph18042121[101] Henrique Marcos and Melina Pullin. 2023. LARGE LANGUAGE MODELS AND EU DATA PROTECTION: MAPPING (SOME) OF THE PROBLEMS.https://digi-con.org/large-language-models-and-eu-data-protection-mapping-some-of-the-problems/. Accessed: 2024-02-28.[102] Scott Mayer McKinney, Marcin Sieniek, Varun Godbole, Jonathan Godwin, Natasha Antropova, Hutan Ashrafian, Trevor Back, Mary Chesus,Greg S Corrado, Ara Darzi, et al. 2020. International evaluation of an AI system for breast cancer screening. Nature 577, 7788 (2020), 89\u201394.[103] Nathan J. McNeese, Beau G. Schelble, Lorenzo Barberis Canonico, and Mustafa Demir. 2021. Who/What Is My Teammate? Team CompositionConsiderations in Human\u2013AI Teaming. IEEE Transactions on Human-Machine Systems 51, 4 (2021), 288\u2013299. https://doi.org/10.1109/THMS.2021.3086018[104] Lucas Memmert and Eva Bittner. 2022. Complex Problem Solving through Human-AI Collaboration: Literature Review on Research Contexts. InProceedings of the Annual Hawaii International Conference on System Sciences.[105] Lucas Memmert and Navid Tavanapour. 2023. TOWARDS HUMAN-AI-COLLABORATION IN BRAINSTORMING: EMPIRICAL INSIGHTS INTOTHE PERCEPTION OF WORKING WITH A GENERATIVE AI. In 31st European Conference on Information Systems (ECIS).[106] Jesse G Meyer, Ryan J Urbanowicz, Patrick CNMartin, Karen O\u2019Connor, Ruowang Li, Pei-Chen Peng, Tiffani J Bright, Nicholas Tatonetti, Kyoung JaeWon, Graciela Gonzalez-Hernandez, et al. 2023. ChatGPT and large language models in academia: opportunities and challenges. BioData Mining16, 1 (2023), 20.[107] Henny Admoni Michelle Zhao, Reid Simmons. 2022. The Role of Adaptation in Collective Human\u2013AI Teaming. Topics in Cognitive Science (2022).https://doi.org/doi/pdf/10.1111/tops.12633[108] Fan Mingming, Yang Xianyou, Yu Tsz Tung, Q. Liao Vera, and Zhao Jian. 2023. Human-AI Collaboration for UX Evaluation: Effects of Explanationand Synchronization. arXiv.org (2023). Accessed: 2023-11-28.[109] Suvir Mirchandani, F. Xia, Peter R. Florence, Brian Ichter, Danny Driess, Montse Gonzalez Arenas, Kanishka Rao, Dorsa Sadigh, and Andy Zeng. 2023.Large Language Models as General Pattern Machines. arXiv preprint arXiv:2307.04721 (2023). https://api.semanticscholar.org/CorpusID:259501163[110] Brent Mittelstadt, Patrick Allo, Mariarosaria Taddeo, Sandra Wachter, , and Luciano Floridi. 2016. The ethics of algorithms: Mapping the debate.Big Data and Society (2016).[111] Katelyn Morrison, Donghoon Shin, Kenneth Holstein, and Adam Perer. 2023. Evaluating the Impact of Human Explanation Strategies on Human-AIVisual Decision-Making. Proc. ACM Hum.-Comput. Interact. 7, CSCW1, Article 48 (apr 2023), 37 pages. https://doi.org/10.1145/3579481[112] I. Munyaka, Z. Ashktorab, C. Dugan, J. Johnson, and Q. Pan. 2023. Decision Making Strategies and Team Efficacy in Human-AI Teams. Proceedingsof the ACM on Human-Computer Interaction, (2023). https://doi.org/doi/pdf/10.1145/3579476[113] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, WilliamSaunders, et al. 2021. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332 (2021).[114] Mark A Neerincx, Jasper van der Waa, Frank Kaptein, and Jurrian van Diggelen. 2018. Using Perceptual and Cognitive Explanations for EnhancedHuman-Agent Team Performance. Lecture Notes in Computer Science 10011 (2018), 204\u2013214.[115] An Ngo, Daniel Phelps, Derrick Lai, Thanyared Wong, Lucas Mathias, Anish Shivamurthy, Mustafa Ajmal, Minghao Liu, and James Davis. 2023.Tag-Based Annotation for Avatar Face Creation. arXiv preprint arXiv:2308.12642 (2023).[116] Stefanos Nikolaidis, David Hsu, and Siddhartha Srinivasa. 2017. Human-robot mutual adaptation in collaborative tasks: Models and experiments.The International Journal of Robotics Research 36 (2017), 618\u2013634.[117] Wei Niu, Zhenglun Kong, Geng Yuan, Weiwen Jiang, Jiexiong Guan, Caiwen Ding, Pu Zhao, Sijia Liu, Bin Ren, and Yanzhi Wang. 2020. Real-TimeExecution of Large-scale Language Models on Mobile. arXiv:2009.06823 [cs.CL][118] Hyacinth S Nwana. 1990. Intelligent tutoring systems: an overview. Artificial Intelligence Review 4, 4 (1990), 251\u2013277.[119] Masanari Ohi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, and Naoaki Okazaki. 2024. Likelihood-based Mitigation of Evaluation Bias in LargeLanguage Models. arXiv preprint arXiv:2402.15987 (2024).[120] OpenAI. 2023. ChatGPT-4. https://openai.com/chatgpt.[121] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, AlexRay, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35(2022), 27730\u201327744.30 Vats and Nizam, et al.[122] Saket Ozarkar, Raj Chetwani, Sugam Devare, Sumeet Haryani, and Nupur Giri. 2020. AI for Accessibility: Virtual Assistant for Hearing Impaired. In2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT). 1\u20137. https://doi.org/10.1109/ICCCNT49239.2020.9225392[123] Subharun Pal. 2023. The Future of Large Language Models: A Futuristic Dissection on AI and Human Interaction. IJFMR-International Journal ForMultidisciplinary Research 5, 3 (2023).[124] SungYeon Park, MinJae Lee, JiHyuk Kang, Hahyeon Choi, Yoonah Park, Juhwan Cho, Adam Lee, and DongKyu Kim. 2024. VLAAD: Visionand Language Assistant for Autonomous Driving. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)Workshops. 980\u2013987.[125] Armin Danesh Pazho, Christopher Neff, Ghazal Alinezhad Noghre, Babak Rahimi Ardabili, Shanle Yao, Mohammadreza Baharani, and HamedTabkhi. 2023. Ancilia: Scalable Intelligent Video Surveillance for the Artificial Intelligence of Things. arXiv preprint arXiv:2301.03561 (2023).[126] Michael Pflanzer, Zach Traylor, Joseph B. Lyons, Veljko Dubljevi\u0107, and Chang S. Nam. 2022. Ethics in human\u2013AI teaming: principles and perspectives.AI and Ethics (2022), 1\u201319. https://api.semanticscholar.org/CorpusID:252422919[127] Joris Pries, Sandjai Bhulai, and Rob D. van der Mei. 2023. Active pairwise distance learning for efficient labeling of large datasets by human experts.Applied Intelligence 53 (2023), 24689 \u2013 24708. https://api.semanticscholar.org/CorpusID:260307431[128] Zheng Qingxiao, Tang Yiliu, Liu Yiren, Liu Weizi, and Huang Yun. 2023. UX Research on Conversational Human-AI Interaction: A LiteratureReview of the ACM Digital Library. arXiv preprint arXiv (2023). Accessed: 2023-11-28.[129] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, JackClark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From Natural Language Supervision. In Proceedings of the38th International Conference on Machine Learning (Proceedings of Machine Learning Research, Vol. 139), Marina Meila and Tong Zhang (Eds.). PMLR,8748\u20138763. https://proceedings.mlr.press/v139/radford21a.html[130] Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 2023. Direct preference optimization:Your language model is secretly a reward model. arXiv preprint arXiv:2305.18290 (2023).[131] Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 2023. Direct preference optimization:Your language model is secretly a reward model. arXiv preprint arXiv:2305.18290 (2023).[132] Charvi Rastogi, Marco Tulio Ribeiro, Nicholas King, Harsha Nori, and Saleema Amershi. 2023. Supporting human-AI collaboration in auditingLLM with LLMs. In Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society. 913\u2013926.[133] Rowena Rodrigues. 2020. Legal and human rights issues of AI: Gaps, challenges and vulnerabilities. Journal of Responsible Technology (2020).[134] Stuart J. Russell, Peter Norvig, Ming-Wei Chang, Jacob Devlin, Anca Dragan, David Forsyth, Ian Goodfellow, Jitendra Malik, Vikash Mansinghka,Judea Pearl, and Michael J Wooldridge. 2021. Artificial Intelligence: A Modern Approach. Prentice Hall.[135] Eduardo Salas, Carolyn Prince, David P Baker, and Lisa Shrestha. 2017. Situation awareness in team performance: Implications for measurementand training. Human Factors 37 (2017).[136] SP Samyuktha, P Kavitha, VA Kshaya, P Shalini, and R Ramya. 2022. A survey on cyber security meets artificial intelligence: AI\u2013driven cybersecurity. Journal of Cognitive Human-Computer Interaction 2, 2 (2022), 50\u201355.[137] Glorin Sebastian. 2023. Privacy and Data Protection in ChatGPT and Other AI Chatbots: Strategies for Securing User Information. Available atSSRN 4454761 (2023).[138] Burr Settles. 2009. Active Learning Literature Survey. Department of Computer Sciences, University of Wisconsin-Madison.[139] Shahin Sharifi Noorian, Sihang Qiu, Ujwal Gadiraju, Jie Yang, and Alessandro Bozzon. 2022. What Should You Know? A Human-In-the-LoopApproach to Unknown Unknowns Characterization in Image Recognition. In Proceedings of the ACM Web Conference 2022 (Virtual Event, Lyon,France) (WWW \u201922). Association for Computing Machinery, New York, NY, USA, 882\u2013892. https://doi.org/10.1145/3485447.3512040[140] Ashish Sharma, Inna W Lin, Adam S Miner, David C Atkins, and Tim Althoff. 2023. Human-AI collaboration enables more empathic conversationsin text-based peer-to-peer mental health support. Nature Machine Intelligence 5, 1 (2023), 46\u201357.[141] Sabina Leonelli Silvia Milano, Joshua A. McGrane. 2023. Large language models challenge the future of higher education. Nature MachineIntelligence (2023).[142] Adam Sobieszek and Tadeusz Price. 2022. Playing games with AIs: the limits of GPT-3 and similar large language models. Minds and Machines 32,2 (2022), 341\u2013364.[143] B.C. Stahl, A. Andreou, P. Brey, T. Hatzakis, A. Kirichenko, K.Macnish, S. Laulh\u00e9 Shaelou, A. Patel, M. Ryan, andD.Wright. 2021. Artificial intelligencefor human flourishing \u2013 Beyond principles for machine learning. Journal of Business Research (2021). https://doi.org/10.1016/j.jbusres.2020.11.030[144] Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. 1999. Policy gradient methods for reinforcement learning with functionapproximation. Advances in neural information processing systems 12 (1999).[145] Nintendo Switch. 2017. Mariokart 8 Deluxe. Video game.[146] Aaquib Tabrez, Matthew Luebbers, and Bradley Hayes. 2020. A Survey of Mental Modeling Techniques in Human\u2013Robot Teaming. Current RoboticsReports 1 (12 2020). https://doi.org/10.1007/s43154-020-00019-0[147] Atieh Taheri, Mohammad Izadi, Gururaj Shriram, Negar Rostamzadeh, and Shaun Kane. 2023. Breaking Barriers to Creative Expression: Co-Designing and Implementing an Accessible Text-to-Image Interface. arXiv preprint arXiv:2309.02402 (2023).[148] Ekenobi ThankGod Chinonso. 2023. The impact of chatGPT on privacy and data protection laws. Available at SSRN: https://ssrn.com/abstract=4556181(2023).A Survey on Human-AI Teaming with Large Pre-Trained Models 31[149] Surendrabikram Thapa and Surabhi Adhikari. 2023. ChatGPT, bard, and large language models for biomedical research: opportunities and pitfalls.Annals of Biomedical Engineering 51, 12 (2023), 2647\u20132651.[150] Graham Todd, Sam Earle, Muhammad Umair Nasir, Michael Cerny Green, and Julian Togelius. 2023. Level Generation Through Large LanguageModels. In Proceedings of the 18th International Conference on the Foundations of Digital Games. 1\u20138.[151] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, EricHambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient FoundationLanguage Models. arXiv preprint arXiv:2302.13971 (2023). arXiv:2302.13971 [cs.CL][152] Adaku Uchendu, Jooyoung Lee, Hua Shen, Thai Le, Dongwon Lee, et al. 2023. Does Human Collaboration Enhance the Accuracy of IdentifyingLLM-Generated Deepfake Texts?. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing. 163\u2013174.[153] Imdad Ullah, Najm Hassan, Sukhpal Singh Gill, Basem Suleiman, Tariq Ahamed Ahanger, Zawar Shah, Junaid Qadir, and Salil S Kanhere. 2023.Privacy preserving large language models: ChatGPT case study based vision and framework. arXiv preprint arXiv:2310.12523 (2023).[154] Karel van den Bosch, Tjeerd Schoonderwoerd, Romy Blankendaal, and Mark Neerincx. 2019. Six challenges for human-AI Co-learning. In AdaptiveInstructional Systems: First International Conference, AIS 2019, Held as Part of the 21st HCI International Conference, HCII 2019, Orlando, FL, USA, July26\u201331, 2019, Proceedings 21. Springer, 572\u2013589.[155] Kurt VanLehn. 2011. The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring systems. Educational psychologist46, 4 (2011), 197\u2013221.[156] Susanna V\u00e4rtinen, Perttu H\u00e4m\u00e4l\u00e4inen, and Christian Guckelsberger. 2022. Generating role-playing game quests with GPT language models. IEEETransactions on Games (2022).[157] Veniamin Veselovsky, Manoel Horta Ribeiro, Philip Cozzolino, Andrew Gordon, David Rothschild, and Robert West. 2023. Prevalence and preventionof large language model use in crowd work. arXiv preprint arXiv:2310.15683 abs/2310.15683 (2023). https://api.semanticscholar.org/CorpusID:264439231[158] Emmanuelle Walkowiak and Trent MacDonald. 2023. Generative AI and the Workforce: What Are the Risks? Available at SSRN (2023).[159] Dylan Walsh. 2023. Legal issues presented by generative AI. https://mitsloan.mit.edu/ideas-made-to-matter/legal-issues-presented-generative-ai.Accessed: 2024-02-28.[160] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray.2019. Human-AI collaboration in data science: Exploring data scientists\u2019 perceptions of automated AI. Proceedings of the ACM on human-computerinteraction 3, CSCW (2019), 1\u201324.[161] Rose Wang and Dorottya Demszky. 2023. Is ChatGPT a Good Teacher Coach? Measuring Zero-Shot Performance For Scoring and ProvidingActionable Insights on Classroom Instruction. In 18th Workshop on Innovative Use of NLP for Building Educational Applications.[162] Tsun-Hsuan Wang, Alaa Maalouf, Wei Xiao, Yutong Ban, Alexander Amini, Guy Rosman, Sertac Karaman, and Daniela Rus. 2023. Drive anywhere:Generalizable end-to-end autonomous driving with multi-modal foundation models. arXiv preprint arXiv:2310.17642 (2023).[163] Yifei Wang. 2023. The Large Language Model (LLM) Paradox: Job Creation and Loss in the Age of Advanced AI. TechRxiv Preprint. Available atTechRxiv: [URL].[164] Yixuan Wang, Ruochen Jiao, Chengtian Lang, Sinong Simon Zhan, Chao Huang, Zhaoran Wang, Zhuoran Yang, and Qi Zhu. 2023. EmpoweringAutonomous Driving with Large Language Models: A Safety Perspective. arXiv preprint arXiv:2312.00812 (2023).[165] JasonWei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and Denny Zhou. 2022. Chain of Thought PromptingElicits Reasoning in Large Language Models. arXiv preprint arXiv:2201.11903 (2022). https://api.semanticscholar.org/CorpusID:246411621[166] Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, et al. 2023.Zero-shot information extraction via chatting with ChatGPT. arXiv preprint arXiv:2302.10205 (2023).[167] Justin D. Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I. Ross, Fernando Martinez, Mayank Agarwal, and Kartik Talamadupula.2021. Perfection Not Required? Human-AI Partnerships in Code Translation. In 26th International Conference on Intelligent User Interfaces (CollegeStation, TX, USA) (IUI \u201921). Association for Computing Machinery, New York, NY, USA, 402\u2013412. https://doi.org/10.1145/3397481.3450656[168] Feng Wen, Zixuan Zhang, Tianyiyi He, and Chengkuo Lee. 2021. AI enabled sign language recognition and VR space bidirectional communicationusing triboelectric smart glove. Nature Communications 12 (09 2021), 5378. https://doi.org/10.1038/s41467-021-25637-w[169] Licheng Wen, Xuemeng Yang, Daocheng Fu, Xiaofeng Wang, Pinlong Cai, Xin Li, Tao Ma, Yingxuan Li, Linran Xu, Dengke Shang, Zheng Zhu,Shaoyan Sun, Yeqi Bai, Xinyu Cai, Min Dou, Shuanglu Hu, Botian Shi, and Yu Qiao. 2023. On the Road with GPT-4V(ision): Early Explorations ofVisual-Language Model on Autonomous Driving. arXiv preprint arXiv:2311.05332 (2023).[170] Elizabeth Whitaker, Ethan Trewhitt, Matthew Holtsinger, Christopher Hale, Elizabeth Veinott, Chris Argenta, and Richard Catrambone. 2013. Theeffectiveness of intelligent tutoring on training in a video game. In 2013 IEEE International Games Innovation Conference (IGIC). IEEE, 267\u2013274.[171] Jess Whittlestone, Rune Nyrup, Anna Alexandrova, and Stephen Cave. 2019. The role and limits of principles in AI ethics: Towards a focus ontensions. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society. 195\u2013200.[172] Allison Woodruff, Renee Shelby, Patrick Gage Kelley, Steven Rousso-Schindler, Jamila Smith-Loud, and Lauren Wilcox. 2023. How KnowledgeWorkers Think Generative AI Will (Not) Transform Their Industries. arXiv preprint arXiv:2310.06778 (2023).[173] Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022. AI Chains: Transparent and Controllable Human-AI Interaction by Chaining LargeLanguage Model Prompts. In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems (New Orleans, LA, USA) (CHI \u201922).Association for Computing Machinery, New York, NY, USA, Article 385, 22 pages. https://doi.org/10.1145/3491102.351758232 Vats and Nizam, et al.[174] Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, and Yang Liu. 2023. Exploring large language models forcommunication games: An empirical study on werewolf. arXiv preprint arXiv:2309.04658 (2023).[175] Yi Yang, Qingwen Zhang, Ci Li, Daniel Sim\u00f5es Marta, Nazre Batool, and John Folkesson. 2024. Human-Centric Autonomous Systems With LLMsfor User Command Reasoning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshops. 988\u2013994.[176] Bingsheng Yao, Ishan Jindal, Lucian Popa, Yannis Katsis, Sayan Ghosh, Lihong He, Yuxuan Lu, Shashank Srivastava, Yunyao Li, James Hendler,and Dakuo Wang. 2023. Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-LearningArchitecture. In Findings of the Association for Computational Linguistics: EMNLP 2023, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Associationfor Computational Linguistics, Singapore, 11629\u201311643. https://doi.org/10.18653/v1/2023.findings-emnlp.778[177] Chunyong Yin, Biao Zhou, Zhichao Yin, and Jin Wang. 2019. Local privacy protection classification based on human-centric computing. Human-centric Computing and Information Sciences 9 (2019), 1\u201314. https://doi.org/10.1186/s13673-019-0195-4[178] Lihan Zha, Yuchen Cui, Li-Heng Lin, Minae Kwon, Montse Gonzalez Arenas, Andy Zeng, Fei Xia, and Dorsa Sadigh. 2023. Distilling and RetrievingGeneralizable Knowledge for Robot Manipulation via Language Corrections. ArXiv abs/2311.10678 (2023). https://api.semanticscholar.org/CorpusID:265281528[179] Rui Zhang, Wen Duan, Christopher Flathmann, Nathan McNeese, Guo Freeman, and Alyssa Williams. 2023. Investigating AI Teammate Communi-cation Strategies and Their Impact in Human-AI Teams For Effective Teamwork. Proceedings of the ACM on Human-Computer Interaction 7 (2023),1\u201331. https://doi.org/10.1145/3610072[180] Rui Zhang, Nathan J McNeese, Guo Freeman, and Geoff Musick. 2021. \"An ideal human\" expectations of AI teammates in human-AI teaming.Proceedings of the ACM on Human-Computer Interaction 4, CSCW3 (2021), 1\u201325.[181] Jianlong Zhou and Fang Chen. 2019. Towards trustworthy human-AI teaming under uncertainty. In IJCAI 2019 workshop on explainable AI (XAI).[182] Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2019. Fine-tuninglanguage models from human preferences. arXiv preprint arXiv:1909.08593 (2019).",
      "id": 164485113,
      "identifiers": [
        {
          "identifier": "2403.04931",
          "type": "ARXIV_ID"
        },
        {
          "identifier": "oai:arxiv.org:2403.04931",
          "type": "OAI_ID"
        },
        {
          "identifier": "634231744",
          "type": "CORE_ID"
        }
      ],
      "title": "A Survey on Human-AI Teaming with Large Pre-Trained Models",
      "language": {
        "code": "en",
        "name": "English"
      },
      "magId": null,
      "oaiIds": [
        "oai:arxiv.org:2403.04931"
      ],
      "publishedDate": "2024-06-26T01:00:00",
      "publisher": "",
      "pubmedId": null,
      "references": [],
      "sourceFulltextUrls": [
        "http://arxiv.org/abs/2403.04931"
      ],
      "updatedDate": "2025-01-04T02:35:55",
      "yearPublished": 2024,
      "journals": [],
      "links": [
        {
          "type": "download",
          "url": "http://arxiv.org/abs/2403.04931"
        },
        {
          "type": "display",
          "url": "https://core.ac.uk/works/164485113"
        }
      ]
    }
  ],
  "searchId": "5729c88da55a2f4aaade9e385f403df4"
}