{
  "source_markdown_file": "sources/4.1.8-elicit-results/phase-2-targeted-queries/markdown_papers/3.1.2-industry-academia-collaborative/Towards_an_AI_Assistant_for_Power_Grid_Operators.md",
  "title": "Towards an AI Assistant for Power Grid Operators",
  "doi": "10.3233/FAIA220191",
  "extracted_contexts": {
    "organizations_companies": [
      "acm transactions on interactive intelligent systems",
      "adapting existing ai assistant framework and guidelines to power",
      "aim at fully autonomous systems",
      "and apply to different industrial systems",
      "and coordination to support the ongoing energy",
      "and evaluation of human machine systems",
      "and for power systems",
      "and recommendation systems",
      "applied energy",
      "as well as already available materials in power",
      "assistant for power",
      "based solutions",
      "bridge university",
      "but such systems",
      "centered design of complex systems",
      "cently been developed for power",
      "chi conference on human factors in computing systems",
      "decision support systems",
      "electric power systems",
      "energy systems",
      "erators of critical systems",
      "eventually providing him with diagnostics or even recommendations on solutions",
      "expert systems",
      "expertise in the electric",
      "extended abstracts on human factors in computing systems",
      "for critical systems",
      "framework for trustworthy machine learning in power systems",
      "from alphago to power",
      "guided machine learning for power",
      "how do humans decide under wind power",
      "hybrid systems",
      "ieee",
      "ieee intelligent systems",
      "ieee power and energy",
      "in power",
      "in proceedings of the sigchi conference on human factors in computing systems",
      "intelligence into interactive systems",
      "international conference on autonomous agents and multiagent systems",
      "international journal of electrical power",
      "interpreting atypical conditions in systems",
      "introducing machine learning for power",
      "journal of modern power systems and clean energy",
      "knowledge graph construction and application of power",
      "machine systems",
      "merous power",
      "national conference on systems",
      "national institute",
      "neural information processing systems",
      "ntowards an ai assistant for power",
      "optimization of computational budget for power",
      "or even use battery storage today to change the power",
      "oxford university",
      "perspectives on future power system control centers for energy",
      "physical systems",
      "power grids are becoming more complex to operate in the digital age given the current energy",
      "recent developments in machine learning for energy systems",
      "recent survey in power",
      "related to human behavior and cognition beyond the usual situation awareness focus in power systems",
      "security constraint optimal power",
      "sistant based on the concept of hypervision and bidirectional interactions for power",
      "situation awareness in power systems",
      "so decisions need to consider the full underlying planning problem of power",
      "survey of visualization methods for power",
      "the changing practices of energy",
      "the future role of human operators in highly automated electric power systems",
      "they can modify the line connectivity on the grid to reroute power",
      "they mostly manually explore solutions",
      "time energy",
      "time from control rooms to optimize the power",
      "tion systems",
      "tonomous systems",
      "towards an ai assistant for power",
      "user to reach novel solutions",
      "usual solutions",
      "what an assistant should look like in the case of power systems",
      "when considering industrial systems",
      "when powering assistance systems",
      "which notably used power",
      "while human systems",
      "year now given the energy"
    ],
    "technologies_systems": [
      "ai",
      "ecosystem",
      "ml",
      "ngrid"
    ],
    "practical_challenges": [
      "communication is key. system 1 works on a. marot et al. / towards an ai assistant for power grid operators 83\\n\\n---\\n\\n### page 6\\n\\nlearned representations of reality, not directly on reality itself, meaning that situations can be interpreted differently. hence, reference representations should at least be shared in some form between agents to properly communicate, as with language. not an easy task knowing that, for instance, in language, common words can sometimes have different meanings between people, highlighting not always properly shared representations [46]. finally, we should resist the temptation of developing an anthropomorphic assistant [47], i.e. not mechanically mimicking humans and human-human interactions. we aim at augmenting the operator, not replacing him, by recognizing the complementary dif- ferences between humans and computers [13], and leveraging them for humans. these motivate the need for design guidelines, which we will de\ufb01ne in sections 5 and 6, includ- ing carefully-crafted human-machine interactions [48], or interpretable [49], explainable [50] and trustworthy [51] ai. we aim at offering operators high control level despite increasing grid automation without compromising reliability and safety [52]. 4. de\ufb01ning an arti\ufb01cial assistant for power grid operators we de\ufb01ne an assistant as an arti\ufb01cial agent helping on a subset of user daily tasks, with the \ufb01nal goal of increasing task ef\ufb01ciency while still developing operator skills. 4.1. assistant: balancing assistance, user control and automation we \ufb01rst explain how the concept of assistant articulates with assistance functions and is distinct from a completely autonomous system. assistance functions help users with domain-speci\ufb01c tasks, for example, by alerting them when relevant information arrives. situation awareness [8,3,7] offers, in that sense, advanced assistance functions. other similar industrial sectors evoke those functions through different autonomy levels [53,54,55]. we here re\ufb02ect on the grades of automation (goa) de\ufb01nition in public transport [56,54]. goa1 and goa2 offer assistance functions as discussed previously, but without much consideration for hmi. goa3 and goa4 are targeting autonomy through automation. it highlights that many \ufb01elds such as autonomous driving [53] aim at fully autonomous systems. they diverge from our goal of augmenting operators through an assistant. while being conceptually closer to goa2, we move away from the usual au- tomation typical of system engineering, to be more operator centric. an assistant, as we illustrate in fig.1a and later discuss, is yet another level whose goal is to offer the right balance between user control and autonomy [57] for enhanced decision-making. it certainly has assistance functions at its core, but most importantly also engages actively with the user. it offers a uni\ufb01ed interface and allows for dynamic bidirectional interaction with the user to cooperate ef\ufb01ciently on task completion and with others. the responsibility of system management still ultimately falls on the op- erators of critical systems. while some tasks could eventually be automated away, it is paramount to avoid pitfalls such as operator deskilling (see section 3.4), often due to the \u201cout-of-the-loop\u201d effect [3]. assistants should let operators remain in control, which re- quires more than automation supervision [58], and help reinforce their expertise, as em- phasized in section 4.3. finally, unlike goa framework, getting a teamwork perspective is important, by considering the interactions between control room operators, to foster proper coordination and to allow for observability, predictability and directability [59]. we now focus on core building blocks in creating such assistants, namely hypervi- sion and bidirectional interaction. applied ai bricks examples are found in section 6.3. a. marot et al. / towards an ai assistant for power grid operators 84\\n\\n---\\n\\n### page 7\\n\\n(a) the grid operator ai assistant (b) supervision to hypervision figure 1. (a) the grid operator ai assistant relies on hypervision interface represented as a blue bus, as well as underlying bidirectional interaction and ai components (see section 6.3) running altogether in a coordinated and modular fashion. multiple operator/assistant pairs can also coordinate and collaborate through it. zoom- ing in, assistant system 1 type block helps in usual tasks or situations, exploiting core knowledge and intuition learnt. right block is more dynamic and interactive, hence more bidirectional, to assist in situations that require more reasoning, focus, deliberation or exploration by operators in a system 2 type fashion. continuous revision is important to update shared representations. (b) supervision to hypervision in 1b allows moving away from alarm monitoring over many applications on screens (colored squares), to refocus the operator on task comple- tion on a uni\ufb01ed contextualized single interface (mixed colors of background apps merged information). 4.2. hypervision: smart interface & information management today\u2019s supervision leaves to the user the cognitive load to prioritize, organize, and link every displayed information and alarms consistently before considering any decision. it can be regarded as a fragmented ecosystem from an operator\u2019s viewpoint. while it has been manageable for up to ten applications, it becomes impractical with always more information and uncoordinated applications to control under heterogeneous formats. su- pervision gives access to the user to every information available without much more pro- cessing. however, it does not help deal with the information overload and \u201clack of mean- ing\u201d problems (see 3.2) that need to be tackled for improved decision-making: it dilutes the operator\u2019s attention. let\u2019s recall that humans can mainly focus on one task at a time, with a limited working memory space of few information chunks to manipulate [60]. to be effective at continuous decision-making, it is often important to focus on the highest priority task at a time, and present only the most relevant information to it. yet, pausing on one task, dealing with another, and eventually completing the previous one should remain be possible. in that regard, we propose to rely on an \u201chypervision\u201d frame- work to bring the right information at the right time to the right person [1] while keeping track of user progress for each task. it helps overcome multiple biases, such as both in- formation bias and anchoring bias, by taking advantage of them rather than being in\ufb02u- enced by them. hypervision as presented in [1] relies on the de\ufb01nition of tasks created by processing and synthesizing the necessary information. those tasks do not have to be only-real time. indeed, they are still preferably the ones anticipated to be completed or con\ufb01gured ahead of time thanks to forecast, hence de\ufb01ning an expected trajectory that might be adapted along the way. reaching this higher level of information enables the assistant to establish a simpli\ufb01ed but relevant dialogue with the operator, eventually providing him with diagnostics or even recommendations on solutions. hence, hypervi- a. marot et al. / towards an ai assistant for power grid operators 85\\n\\n---\\n\\n### page 8\\n\\nsion\u2019s goal is to help refocus the operator on task completion rather than alarm monitor- ing, as illustrated in \ufb01gure 1b. while the assistant could instantiate tasks for anticipated risks by the system and help in prioritizing them, the operator should remain free to cre- ate, modify or prioritize some himself. this manual editing is also important to correct overtime any selection bias that could have been introduced by automatic prioritization, among others. finally, such tasks can be easily shared and completed between operators, allowing for easier team workload management [33]. these create the basis for more ad- vanced and effective bidirectional interaction under shared representations of tasks [57] thanks to which users and assistants could work in teams to achieve a common objective. 4.3. bidirectional interaction put in the spotlight in the 80\u2019s, expert systems developed with ai under prede\ufb01ned rules raised concerns about its practicality for human users in terms of human-machine inter- action. lucy suchman [61] shed light on their ineffectiveness, mostly attributed to the lack of well-designed interaction and learning loops beyond knowledge retrieval. she noted that plans, similarly to prede\ufb01ned rules, are not prescriptive and not something to follow exactly, because everything eventually depends on circumstances and contingen- cies. plans should rather be seen as heuristic and available resources for actions that help focus one\u2019s attention while abstracting the details. but they should get updated through interaction to take proper decisions. in the end, interfaces should not draw a dry delimi- tation with their user but re-con\ufb01gure themselves and conform with him. research [62] has shown an increased ef\ufb01ciency in human-ai coupling when both agents were able to initiate and respond to interaction. these were historically mostly unidirectional, the assistant either asking a prede\ufb01ned set of questions to build its context representation or the user asking to perform some prede\ufb01ned tasks. such badly designed assistants such as clippy [63] could in the end disrupt the user, making it inef\ufb01cient and frustrating. in a bidirectional relationship, the interaction is collaborative, with neither the system nor the user in control of the whole interaction [57]. the assistant is capable of interacting with the latter to re\ufb01ne its context representation (e.g. ask for a clari\ufb01cation when ambiguities arise), thus improving its ef\ufb01ciency when asked to perform a speci\ufb01c task. a good example of such bidirectional interaction is found in [48], where interac- tion between load-carrying robots and their human partners is learnt over time, resulting in better task completion through operator improvement and per-user adaptation of the robot\u2019s behavior. further approaches let an assistant learn how and when to defer to an expert [64] when in doubt, or conversely let a user interactively learn about the weak- nesses and strengths of the assistant under sources of uncertainties [65]. an assistant can also gently challenge or guide a user to reach novel solutions and build knowledge alto- gether [66,67]. ultimately a user would like to grasp the underlying assistant model [68], to know what the model captured, what he can do with it and how to direct or correct it. interpretability is at play more than post-hoc explanations [69]. in that regard, prospec- tive design [12,70] through interaction and exploration should prove effective, removing the need for the assistant to always explain himself to the operator. an after-operations review process could prove useful for strengthening the relationship [71]. these advances show that creating true human-computer partnerships [72] based on the concepts of discoverability, appropriability and expressivity become a reality as well-demonstrated in [73]. this calls for more academic and industrial collaboration like the \u201ccockpit and bidirectional assistant\u201d project [74] for critical systems. a. marot et al. / towards an ai assistant for power grid operators 86\\n\\n---\\n\\n### page 9\\n\\n5. featured function for effective assistant support after de\ufb01ning what an assistant should look like in the case of power systems, we now propose to specify how it should proceed when interacting with a user. to do so, we build upon the human-ai guidelines de\ufb01ned by amershi et al. [75] to feature import functions for such assistants. as these guidelines were initially de\ufb01ned from studying consumer products, we highlight some additional speci\ufb01city when considering industrial systems. show contextually relevant information at the right time - grid operators evolve in a time-constrained environment where having the right information at the right time is paramount. for instance, power lines reconnected after a routine outage operation for maintenance should be noti\ufb01ed as soon as possible to increase grid robustness. an assis- tant should engage in interaction when the context allows it, taking into account when possible the operator\u2019s mental availability and current task, and the expected impact of the interaction. task prioritization is also a cornerstone of good grid management, and users should be provided with high granularity, curated task details for fast criticality as- sessment. all of the above-mentioned concerns call for ef\ufb01cient knowledge management and representation, as instantiated by our hypervision system de\ufb01ned in 4.2. scope services and inform the user when in doubt - doubt can happen when the assistant is uncertain about the user\u2019s goal, but also in our case because of assistant model limitations (imperfect grid simulator) or uncertainties in the system (poor weather forecast). operators are often dealing with variability, be it when anticipating potential hazards due to volatile renewable energies or exploring the effects of preventive actions. let\u2019s zoom on the \u201canticipation & forecasts\u201d slot of \ufb01g. 1a. when facing uncer- tainty, for example when provided with a highly volatile wind forecast, the operator can \ufb01rst simply indicate his intention of monitoring more stable, aggregated regional fore- casts and let the assistant switch to a higher resolution as operations shift closer to real- time and more precise weather information arrives. this example also shows that uncer- tainties when providing assistance should be jointly presented with their probable causes (missing data, poor forecast...), to help decision-making and reinforce operator trust. support ef\ufb01cient invocation and dismissal - the number of actions an operator can do in a time window is limited. interacting with an assistant has to be straightforward. verbosity should be kept to a minimum, and function of the operator context. in tense situations (e.g. volatile renewable production), the assistant should initiate interactions more frugally, be more succinct, and support faster dismissal. knowing how to adapt interactions is not straightforward, as it involves capturing a lot of implicit contextual hints, and getting operator feedback through dialog should play a major role. take into account and learn from user behavior and feedback - grid operators are well-trained experts, capable of evaluating the assistant\u2019s answers and providing feed- back. thus, to ensure continuous performance improvement (fig. 1a), the latter must be able to learn from users, for instance by understanding that additional context needs to be considered alongside a speci\ufb01c action, or remembering that a line is under mainte- nance during a user-provided period. remembering recent interactions is paramount to user acceptance (nobody likes repeating requests) and capturing user context. moreover, each operator has a personal decision-making style, some relying on nu- merous power-\ufb02ow simulations to assess a situation, others relying on their expertise. a good assistant should adjust to these user-speci\ufb01c pro\ufb01les. convey the consequences of user actions - not only should an assistant avoid oper- ator deskilling for what they do great, but also should it reinforce user expertise through a. marot et al. / towards an ai assistant for power grid operators 87\\n\\n---\\n\\n### page 10\\n\\ninteraction. assistants providing debrie\ufb01ng or online comparative feedback on different action strategies in time would tremendously speed up the way operators acquire expe- rience by mobilizing their deliberative thinking process (s2 in section 3), and yield bet- ter grid management. as what kpis should be tracked is task-dependent, the operator is also involved in this bidirectional dialog. logically, interpretability and explainability are inseparable from building this successful human-ai hybridization (\ufb01g. 1a). 6. guidelines for developing, implementing and testing an assistant designing an assistant in practice might still seem complex beyond the discussed frame- work and principles. we devise here some pragmatic guidelines to start simple on com- mon but modular ground, listing some already available building blocks as well. 6.1. grounded design considerations tasks and visualizations as shared representations in smart grids, functions have been presented in [76,77,1] and tasks described at a high level in [3,26] or through a detailed example [36]. in other industrial sectors such as aeronautics [11], tasks in pro- cesses have been codi\ufb01ed more precisely at a granular level with ontologies [78] or con- ceptual designs from human-computer design [11], which gives the operator a clearer framework to work and coordinate with, as for the assistant. a task is \ufb01rst de\ufb01ned by the problem to solve speci\ufb01cally, such as a safety problem - a line overload, its priority and the residual time to complete it. it should contain relevant context to understand the root of the problem, what might be already known about it, re- cent related events or tasks, as well as the persons involved. building on causal and coun- terfactual models [79] is desirable. a task should further come with suggestions about available actions, and their expected effectiveness. it should \ufb01nally retain a decision for completion and meta-attributes about it. structuring tasks this way would allow shared representations [57] between the operator and the assistant. task categories and attributes should be more exhaustively drawn through future works. eventually, comprehensive activity studies involving multiple tasks in time [11] should be run. also, we suggest to start studying tasks in regular situations and gradually increas- ing the number of needed bidirectional interactions, before considering worst-case sce- narios. to operators, it should prove useful to start experimenting on the most routine but sometimes time-consuming tasks with often low added value [80]. that way, building trust in the \ufb01rst place should be easier while still helping ease their cognitive load. additionally, powerful and interactive visualizations are a common and much ap- preciated approach for operators to support shared representations and task completion. they are useful companions of an assistant. a recent survey in power grids advocates for such new developments [81]. effective superimposed forecasted and current system state visualization [82], dynamic and temporal network exploration [83,84], and high- dimensional event-based visualizations [85] could prove bene\ufb01cial in that regard. simple situational use case sandbox we offer a simple interesting use case to highlight key dif\ufb01culties in daily grid management through the interplay of preventive and correc- tive decisions under uncertainty. it makes us think about the operator-agent interaction. an operator starts monitoring a two-area grid at 7:00am. forecasts show 2 issues: \u2022 an incident in area 1 could happen around 9:00am and would lead to some over- loads, with three available corrective actions after simulations. a. marot et al. / towards an ai assistant for power grid operators 88\\n\\n---\\n\\n### page 11\\n\\n\u2022 another such incident in area 2 could happen around 8:30am with only one pre- ventive action available. this leaves only a couple of minutes to execute it or not. figure 2. a simple scenario where incidents are forecasted in multiple parts of a grid, and several remedial actions (green dot) with different setup duration (blue arrow) are possible. a couple of questions arise on the best strategy to follow: \u2022 which decisions have priority? it seems that a preventive action on area 2 should be urgently taken, but maybe the forecast isn\u2019t that reliable yet. \u2022 when should we implement actions? waiting for the last simulation at 8:00am in area 1 shows that the forecasted problem disappeared which is the best option. \u2022 how does applying a preventive action on area 2 re\ufb02ect on area 1? would it lead to a less secure grid state? what coordination is required? maybe there\u2019s a new outage operation in this area that isn\u2019t yet taken into account by the simulation. \u2022 which of the three corrective actions in area 1 should be taken? the operator has to mediate between economical, practical and safety arguments, each with a degree of uncertainty over an activation horizon. our objective here is not to provide any viable solution, but rather to demonstrate that grid operators are confronted with complex decisions even on apparently simple cases, in which context-dependent trade-offs always have to be made. future works could build a library of such canonical cases to be studied in the community. 6.2. uni\ufb01ed interface & data collection as an industrial stack the hypervision framework relies on a generic single interface that should be able to integrate any kind of tasks, and apply to different industrial systems for instance. an ex- ample of an existing framework is the open-source operator fabric [86]. it could be used both by industrial and researchers as a uni\ufb01ed interface for decision-making processes across teams. such a framework is also a cornerstone to digitalize the decision-making process, centralize every necessary information, hence capitalize on them. this historical data collection is essential for continuous improvement, experiments, as well as for cre- ating datasets from which ai can learn recommendations. data should get labeled and its quality properly monitored. these developments should create a necessary technical stack or data platform for an assistant, to overcome challenges in deploying ai [87,88]. 6.3. power system ai modules for assistant functions recent surveys list interesting developments of ai for climate change [89] and for power systems more speci\ufb01cally [90], [91]. for an assistant, ai can today be used to make cor- a. marot et al. / towards an ai assistant for power grid operators 89\\n\\n---\\n\\n### page 12\\n\\nrective action recommendations to an operator through adaptive interpretable expert sys- tem [23], imitation learning [22] or reinforcement learning on robustness, adaptability or trust dimensions [92,93] which are key in human-centered ai [52]. it can learn from user behaviour and help convey the consequences of the operator\u2019s action by compari- son. exhaustive risk assessment [94] also helps in prioritizing tasks. further, automatic hierarchical and contextual representations of the grid [95] enable scope services and give greater \ufb02exibility to convey the right context and interpret a situation. [96] also lets an ai learn interpretable and physically-consistent contextual indicators associated with a particular operator\u2019s task or help build knowledge graphs [97]. finally, [98,99,100] let operators explore interactively and iteratively historical explainable factors across similar situations and decisions for augmenting and keeping up-to-date the system knowledge and proper labels. this should all be carefully developed within a trustworthy framework [101]. this is an illustrative sample of today\u2019s ai potential [102,103] to provide effective assistance functions and interactions which needs to be developed further. 6.4. assistant evaluation & development of shared benchmarks as for now, there is not yet a standard testing protocol to evaluate ai assistants. how- ever, we could draw insights from other domains such as interpretable machine-learning [49], explainable ai [104,105], or interactive visualization [106]. as done in [49], we could come to structured step-by-step experimental practices to evaluate candidate assis- tants on incrementally dif\ufb01cult tasks. moreover, several virtual-assistant (va) related studies have also tried to de\ufb01ne custom evaluation criteria. in [107], authors compare their va against both a simpler interactive data-exploration scheme and a non-interactive solution-search. they assess the use of their assistant on three factors: performance with task-speci\ufb01c metrics; human-learning using questions and tests at the end of each task; usability for example using system usability scale [108]. during this evaluation biases, over-reliance and deskilling (from sections 3.2 and 3.4) can be addressed. because of con\ufb01dentiality issue",
      "concerns about",
      "data\\n\\n- **original pdf:** `marot2020_towards_an_ai_assistant_for_power_grid_operators_doi_10-3233_faia220191.pdf`\\n- **title:** towards an ai assistant for power grid operators\\n- **doi:** 10.3233/faia220191\\n- **authors:** antoine marot, alexandre rozier, matthieu dussartre, laure crochepierre, benjamin donnot\\n- **year:** 2020\\n- **abstract:**\\nnone\\n\\n- **markdown conversion date:** 2025-06-03t13:44:16.002919\\n- **total pages (pdf):** 17\\n---\\n\\n## full text content (extracted from pdf)\\n\\n### page 1\\n\\ntowards an ai assistant for power grid operators antoine marot a, alexandre rozier a, matthieu dussartre a, laure crochepierre a and benjamin donnot a arte, r&d and ai lab, france abstract. power grids are becoming more complex to operate in the digital age given the current energy transition to cope with climate change. as a result, real- time decision-making is getting more challenging as the human operator has to deal with more information, more uncertainty, more applications, and more coordina- tion. while supervision has been primarily used to help them make decisions over the last decades, it cannot reasonably scale up anymore. there is a great need for rethinking the human-machine interface under more uni\ufb01ed and interactive frame- works. taking advantage of the latest developments in human-machine interface and arti\ufb01cial intelligence, we expose our vision of a new assistant framework re- lying on an hypervision interface and greater bidirectional interaction. we review the known principles of decision-making driving our assistant design alongside its supporting assistance functions. we \ufb01nally share some guidelines to make progress towards the development of such an assistant. keywords. arti\ufb01cial intelligence, assistant, power grid, hypervision 1. introduction from the beginning, power grids have been complex arti\ufb01cial systems. at a time of en- ergy transition, complexity keeps rising given the advent of intermittent renewable en- ergies over a more interconnected european grid. operators are facing aging grids, with slower grid asset developments due to decreasing social acceptability. operators hence need to operate a system closer to its limits while dealing with greater uncertainty and in- creasing grid automation [1] inducing complex cyber-physical dynamics [2]. while there could be a temptation to develop a fully autonomous grid to cope with that complexity, it falls short for such large critical system operations. indeed, coordination, responsibility, accountability, and explainability are a must when operating such a system and can only be reasonably achieved by humans today: human operators remain key players [3]. historically, control rooms have tackled grid evolution dynamics by gradually adding more applications and screens. while incrementally growing a monitoring alarm- driven management system has worked until now, we are today struggling to maintain effective decision-making at a new scale of complexity, essentially in terms of manage- able cognitive load for human operators, who should remain at the center of decisions [1]. in that regard, human-machine interfaces (hmi) have been identi\ufb01ed as a risk fac- tor for human error [4], and should now be considered more closely. in addition, several decades of research in psychology [5] and neuroscience [6] have shed light on the human decision-making process and its limits, which could in turn lead to improving it. lately, several works have proposed situation awareness frameworks [7,8,9] to help augment the operator\u2019s comprehension of safety-critical situations. in addition to better information processing, it is also urgent to rethink the operator\u2019s human-machine inter- hhai2022: augmenting human intellect s. schlobach et al. (eds.) \u00a9 2022 the authors and ios press. this article is published online with open access by ios press and distributed under the terms of the creative commons attribution non-commercial license 4.0 (cc by-nc 4.0). doi:10.3233/faia220191 79\\n\\n---\\n\\n### page 2\\n\\nface [7] and interaction to assist the operator\u2019s regular real-time decision-making. rather than having operators adapt to the machine through a technology-centered system en- gineering design, machines and operators could co-adapt [10] following a more human centered-design [11,12] approach, possibly rooted in the older concept of man-computer symbiosis [13]. in terms of interfaces, we have seen tremendous innovations in other domains, especially in consumer products such as smartphones, connected homes, social networks, search engines, and recommendation systems. they have been well-adopted for ergonomically providing the most relevant information to the user, mostly on sin- gle screens, while dealing in the background with vast amounts of information. in the future, the webstrates [14] concept might enable very adaptive, evolving, personal and consistent interfaces by sharing media ubiquitously through devices and applications. today\u2019s interfaces have also been made possible thanks to the latest developments in arti\ufb01cial intelligence (ai), machine learning (ml) in particular. these advances en- abled deeper and more practical large-scale real-time information processing, as in com- puter vision [15], image understanding [16], natural language processing [17], and rec- ommendations [18]. this shows a shift towards more advanced hmi, through the con- cept of assistants. assistants were found useful to both improve single-user performance and group collaboration on a common task [19], help chess players develop their playing skills [20], or help programmers write code [21]. in power grids, the notion of an ai assistant was used in [22,23] and listed as an opportunity to tackle climate change [24]. nevertheless, pitfalls should be closely investigated, analogous to the in\ufb02uential \u201cironies of automation\u201c, which notably used power grids as an introductory example [25]. in this paper, we present the future design of operator ai-infused assistant given the latest developments in hmi, ai, and decision-making science. our contributions lie in: \u2022 establishing links between these different domains and our application scenarios to push towards appropriate solution design while being aware of pitfalls; \u2022 broadening the perspective to other research \ufb01elds related to human behavior and cognition beyond the usual situation awareness focus in power systems [3,8]; \u2022 adapting existing ai assistant framework and guidelines to power grid speci\ufb01city; \u2022 proposing hypervision interface as an effective hybrid decision-making enabler. in the following, we \ufb01rst describe our industrial use case. after reviewing decision- making considerations in human and ai, we de\ufb01ne our assistant concept highlighting some speci\ufb01city for grid operators, and propose some guidelines for further development. 2. use case description 2.1. today\u2019s operations today grid operators operate in real-time from control rooms to optimize the power \ufb02ows on electrical lines, handle maintenance with planned outages or new equipment integra- tion on the grid, and most importantly, avoid blackouts because of congestion. more de- tails about their role and tasks can be found in [3]. they are highly trained engineers as their job requires studies, planning, and adaptable decision-making rather than simply reproducing pre-established event management scenarios. they operate based on simula- tion tools, real-time and forecasted data, but yet with little decision-making support tools such as assistants. when they feel they need to solve a problem, they mostly manually explore solutions and validate their decision in their simulation tool. they can modify the line connectivity on the grid to reroute power \ufb02ows, but also modify some produc- a. marot et al. / towards an ai assistant for power grid operators 80\\n\\n---\\n\\n### page 3\\n\\ntion, limit consumption by a few percent, or even use battery storage today to change the power \ufb02ows on the grid. this is a large set of possible \ufb02exibilities among which they have to identify the effective ones in a given context. day-ahead planning services give insights on the upcoming trends and possible actions to start considering if some prob- lem occurs, in addition to outage planning. there then exists an intra-day established work\ufb02ow with 5-minute time-step forecast resolution over a few hours\u2019 horizons. but this requires a lot of supervision, a lot of manual entries and manual simulations. they operate mainly with experience to determine relevant remedial actions. as the variability on the grid is increasing a lot with shifting dynamics and behav- iors even within a year now given the energy transition, usual solutions might not work anymore in all or new contexts. operators will have to adapt more quickly, leveraging human \ufb02exibility if given a proper work environment [26]. as it can take months today for an operator to gain the necessary knowledge on a different system through extensive training and manual studies, new assistance is needed, as much as improved performance evaluation [27]. also, while some actions can be leveraged curatively once a problem occurs, others have to be taken preventively before it is too late to implement them given operational constraints, in particular when using batteries or redispatching. several op- erators also act on the same interconnected grid at the same time, and this requires some coordination not always easily achieved despite common grid representations. 2.2. current limitations today and assistant need the current \u201csupervise everything\u201d approach on dozens of screens cannot scale anymore to take critical decisions as the complexity rises: operators become overwhelmed by in- formation without many insights on what to do and any recommendations for it. the volume of data to consider only gets increasing by 2 to 3 orders of magnitude to keep the ability to predict and anticipate in a more stochastic and constrained system. there is hence a need to help operators identify and prioritize tasks while displaying relevant information and recommendations only for those tasks, with ideally a single interface as- sistant. in particular, usual approaches from operational research [28,29] don\u2019t leverage very well available historical data, whereas current data-driven approaches could provide a welcome speed-up. they don\u2019t integrate operator experience and preferred thought pro- cess, hence limiting their acceptability. new research is emerging to better integrate hu- man decision-making [30]. finally, the current work\ufb02ow only considers snapshot-based solutions, not sequential decisions over a time horizon, thus putting the burden of the anticipation and evaluation of action long-term consequences on the operator alone. as the grid gets pushed towards its limits, decisions become more numerous and a lot more interdependent. solutions should be effective over a time horizon, not only at one given time, and be implemented with the right anticipation given their effective acti- vation time: switching line connectivity is quick but starting production can take hours. so decisions need to consider the full underlying planning problem of power grid oper- ations (as illustrated in section 6.1). better real-time operation planning assistance could also help anticipate the workload and level it up across operators in a given control room. an assistant could hence help augment the operator\u2019s decision-making capability [1] to address : (a) more rapidly evolving and changing system environment; (b) more numerous, complex, and coordinated decisions to make; (c) more uncertainty to consider and more anticipation needed; (d) information overload and fragmented work environ- ment; (e) human operator cognitive load saturation. it would eventually help limit the a. marot et al. / towards an ai assistant for power grid operators 81\\n\\n---\\n\\n### page 4\\n\\ngrid operational cost to a few percent increase rather than a 2-fold one. the ambition is to use at least twice as much \ufb02exibility as of today, i.e. to use them more frequently and with more diversity [31]. it would also facilitate workload [32] management across teams for improved coordination [33] through a shared information and task management system. it should however not hinder responsibility and accountability, making clear who is in charge and providing necessary interpretability for operators to make explanations. 3. human-ai dynamics in decision-making 3.1. human decision-making human decision-making is a matter of attention and executive control [6]. taking proper decisions \ufb01rst involves paying attention to the right information in the environment and making sense of it. it further implies selecting relevant actions while inhibiting inappro- priate ones and eventually executing one in a timely manner. following dual-process the- ory in the psychology of human reasoning [5], already successfully applied to domains such as medical decision-making [34], we can describe two underlying imaginary op- erating and cooperative agents, called system 1 (s1) and system 2 (s2). s1 is the fast intuitive and heuristic agent while s2 is the slow and reasoning agent. s2 is the one re- sponsible for decisions assisted by s1 which continuously and automatically provides him predictions for action. s2 usually just lazily accepts s1 proposal in usual situations without more thinking, resulting in successful, quick and cognitively effortless decisions. when unusual, s2 can develop more explicit conscious thinking, beyond s1 predictions, to deliberate and come up with novel and acceptable decisions while cognitively costly. young operators will rely more heavily on s2 and can hence struggle to take any good decision on time for several situations that still appear complex and unusual to them. as they are very focused on trying to make sense of it, they have narrow attention and might miss important new information. as they learn overtime through appropriate training and feedback to become expert, climbing through the expertise ladder [35], their intuitive s1 grows for that \ufb01eld of expertise. this enables them to make good and quick decisions even more often with ease. for an expert operator, it has become a lot easier to operate a system intuitively, being able to make more decisions as well as decisions in more dif\ufb01cult situations [36]. however, the downside can be overcon\ufb01dence, overlooking unusual information that would require more deliberation from s2. 3.2. human biases and desirable assistance because it relies on fast heuristics and mostly jumps to conclusions, system 1 indeed introduces several potential biases which can lead to human errors, hence limiting the effectiveness of human decision-making. cognitive biases are summarized in the cogni- tive bias codex [37] and classi\ufb01ed through 4 problems they are trying to circumvent: a limited memory, the need to act fast, the information overload and a lack of meaning. among possibly damaging biases, we can more speci\ufb01cally list: \u2022 anchoring bias: be over-reliant on the \ufb01rst piece of information we see. \u2022 con\ufb01rmation bias: paying more attention to information con\ufb01rming our beliefs. \u2022 overcon\ufb01dence bias: greater risk-taking if too con\ufb01dent about one\u2019s abilities. \u2022 information bias: tendency to seek information when it does not affect action (more information is not always better). \u2022 availability heuristic: overestimate the importance of information that is available. a. marot et al. / towards an ai assistant for power grid operators 82\\n\\n---\\n\\n### page 5\\n\\n\u2022 ostrich effect: ignore dangerous or negative information. \u2022 outcome bias: judge a decision based on the outcome rather than how it was made. an assistant should hence help the operator avoid biases through assistance in: \u2022 augmenting his memory, knowledge retrieval and keeping track of latest events. \u2022 better information \ufb01ltering or highlighting, enhancing attention focus. \u2022 contextualizing a situation and giving feedback. \u2022 making recommendations, possibly handling some tasks or alerting on risks. let\u2019s now consider what ai in its latest developments could bring in that regard. 3.3. ai potential for assistance the recent deep learning revolution demonstrated some impressive practical abilities of ai by being able to digest a lot of information, memorize large historical datasets, and learn by imitation to infer quickly effective actions in context. turing-award yoshua bengio recently described current deep-learning ai as a s1 kind of intelligence [38], while missing s2 reasoning. this type of ai is presented as advanced pattern matching and recognition machines like s1 [5], being coined as arti\ufb01cial intuition [39]. it however lacks the ability to reason about causality [40], hence lacking understanding and com- mon sense. yet human and ai can be seen as complementary heterogeneous intelligence that could achieve a superior outcome when co-adapting [10] and developing hybrid in- telligence [41] or human-centered ai [12]. this is best exempli\ufb01ed by kasparov\u2019s \u201ccen- taur chess\u201c concept [42], where humans play alongside machines to reach superior per- formances. when powering assistance systems, ai seems capable of overcoming some previously mentioned human limitations by enhancing s1 operator\u2019s ability, whose s2 remains in charge of \ufb01nal decisions. some initial assistance for s2 can nonetheless be considered through explanations or counterfactual reasoning if a simulator exists. 3.4. pitfalls of human-machine hybridization as we have seen in the previous section, human-ai partnerships show many promises. but such systems must be carefully designed, as numerous shortcomings might arise. we can make the analogy to \u201dironies or myth of automation\u201d [25,43] which warns that operators should ultimately be more skilled than less skilled, and less loaded than more loaded to deal with the most dif\ufb01cult new and complex situations. amongst many short- comings mentioned in [44], over-reliance and deskilling are one of the most damaging for control rooms. as of today, operators have a deep knowledge of their grid area, both in terms of infrastructure and electrical phenomena. adding an automatic system with persuasive recommendations could lead the operating staff to rely too heavily on the system, progressively losing their expertise, with potentially catastrophic consequences when it fails. overcon\ufb01dence should not be a trade-off with over-reliance, and opera- tors should have the opportunity to keep developing their skills and cognitive strategies through regular training and manual problem-solving [25]. additionally, an assistant could misunderstand user intent, and hinder his actions in an example of perverse instantiation [45]. these limitations arise from the fact that, while human systems 1 and 2 are fully integrated into a single cognitive ensemble, ai and humans are separated entities, where communication is key. system 1 works on a. marot et al. / towards an ai assistant for power grid operators 83\\n\\n---\\n\\n### page 6\\n\\nlearned representations of reality, not directly on reality itself, meaning that situations can be interpreted differently. hence, reference representations should at least be shared in some form between agents to properly communicate, as with language. not an easy task knowing that, for instance, in language, common words can sometimes have different meanings between people, highlighting not always properly shared representations [46]. finally, we should resist the temptation of developing an anthropomorphic assistant [47], i.e. not mechanically mimicking humans and human-human interactions. we aim at augmenting the operator, not replacing him, by recognizing the complementary dif- ferences between humans and computers [13], and leveraging them for humans. these motivate the need for design guidelines, which we will de\ufb01ne in sections 5 and 6, includ- ing carefully-crafted human-machine interactions [48], or interpretable [49], explainable [50] and trustworthy [51] ai. we aim at offering operators high control level despite increasing grid automation without compromising reliability and safety [52]. 4. de\ufb01ning an arti\ufb01cial assistant for power grid operators we de\ufb01ne an assistant as an arti\ufb01cial agent helping on a subset of user daily tasks, with the \ufb01nal goal of increasing task ef\ufb01ciency while still developing operator skills. 4.1. assistant: balancing assistance, user control and automation we \ufb01rst explain how the concept of assistant articulates with assistance functions and is distinct from a completely autonomous system. assistance functions help users with domain-speci\ufb01c tasks, for example, by alerting them when relevant information arrives. situation awareness [8,3,7] offers, in that sense, advanced assistance functions. other similar industrial sectors evoke those functions through different autonomy levels [53,54,55]. we here re\ufb02ect on the grades of automation (goa) de\ufb01nition in public transport [56,54]. goa1 and goa2 offer assistance functions as discussed previously, but without much consideration for hmi. goa3 and goa4 are targeting autonomy through automation. it highlights that many \ufb01elds such as autonomous driving [53] aim at fully autonomous systems. they diverge from our goal of augmenting operators through an assistant. while being conceptually closer to goa2, we move away from the usual au- tomation typical of system engineering, to be more operator centric. an assistant, as we illustrate in fig.1a and later discuss, is yet another level whose goal is to offer the right balance between user control and autonomy [57] for enhanced decision-making. it certainly has assistance functions at its core, but most importantly also engages actively with the user. it offers a uni\ufb01ed interface and allows for dynamic bidirectional interaction with the user to cooperate ef\ufb01ciently on task completion and with others. the responsibility of system management still ultimately falls on the op- erators of critical systems. while some tasks could eventually be automated away, it is paramount to avoid pitfalls such as operator deskilling (see section 3.4), often due to the \u201cout-of-the-loop\u201d effect [3]. assistants should let operators remain in control, which re- quires more than automation supervision [58], and help reinforce their expertise, as em- phasized in section 4.3. finally, unlike goa framework, getting a teamwork perspective is important, by considering the interactions between control room operators, to foster proper coordination and to allow for observability, predictability and directability [59]. we now focus on core building blocks in creating such assistants, namely hypervi- sion and bidirectional interaction. applied ai bricks examples are found in section 6.3. a. marot et al. / towards an ai assistant for power grid operators 84\\n\\n---\\n\\n### page 7\\n\\n(a) the grid operator ai assistant (b) supervision to hypervision figure 1. (a) the grid operator ai assistant relies on hypervision interface represented as a blue bus, as well as underlying bidirectional interaction and ai components (see section 6.3) running altogether in a coordinated and modular fashion. multiple operator/assistant pairs can also coordinate and collaborate through it. zoom- ing in, assistant system 1 type block helps in usual tasks or situations, exploiting core knowledge and intuition learnt. right block is more dynamic and interactive, hence more bidirectional, to assist in situations that require more reasoning, focus, deliberation or exploration by operators in a system 2 type fashion. continuous revision is important to update shared representations. (b) supervision to hypervision in 1b allows moving away from alarm monitoring over many applications on screens (colored squares), to refocus the operator on task comple- tion on a uni\ufb01ed contextualized single interface (mixed colors of background apps merged information). 4.2. hypervision: smart interface & information management today\u2019s supervision leaves to the user the cognitive load to prioritize, organize, and link every displayed information and alarms consistently before considering any decision. it can be regarded as a fragmented ecosystem from an operator\u2019s viewpoint. while it has been manageable for up to ten applications, it becomes impractical with always more information and uncoordinated applications to control under heterogeneous formats. su- pervision gives access to the user to every information available without much more pro- cessing. however, it does not help deal with the information overload and \u201clack of mean- ing\u201d problems (see 3.2) that need to be tackled for improved decision-making: it dilutes the operator\u2019s attention. let\u2019s recall that humans can mainly focus on one task at a time, with a limited working memory space of few information chunks to manipulate [60]. to be effective at continuous decision-making, it is often important to focus on the highest priority task at a time, and present only the most relevant information to it. yet, pausing on one task, dealing with another, and eventually completing the previous one should remain be possible. in that regard, we propose to rely on an \u201chypervision\u201d frame- work to bring the right information at the right time to the right person [1] while keeping track of user progress for each task. it helps overcome multiple biases, such as both in- formation bias and anchoring bias, by taking advantage of them rather than being in\ufb02u- enced by them. hypervision as presented in [1] relies on the de\ufb01nition of tasks created by processing and synthesizing the necessary information. those tasks do not have to be only-real time. indeed, they are still preferably the ones anticipated to be completed or con\ufb01gured ahead of time thanks to forecast, hence de\ufb01ning an expected trajectory that might be adapted along the way. reaching this higher level of information enables the assistant to establish a simpli\ufb01ed but relevant dialogue with the operator, eventually providing him with diagnostics or even recommendations on solutions. hence, hypervi- a. marot et al. / towards an ai assistant for power grid operators 85\\n\\n---\\n\\n### page 8\\n\\nsion\u2019s goal is to help refocus the operator on task completion rather than alarm monitor- ing, as illustrated in \ufb01gure 1b. while the assistant could instantiate tasks for anticipated risks by the system and help in prioritizing them, the operator should remain free to cre- ate, modify or prioritize some himself. this manual editing is also important to correct overtime any selection bias that could have been introduced by automatic prioritization, among others. finally, such tasks can be easily shared and completed between operators, allowing for easier team workload management [33]. these create the basis for more ad- vanced and effective bidirectional interaction under shared representations of tasks [57] thanks to which users and assistants could work in teams to achieve a common objective. 4.3. bidirectional interaction put in the spotlight in the 80\u2019s, expert systems developed with ai under prede\ufb01ned rules raised concerns about its practicality for human users in terms of human-machine inter- action. lucy suchman [61] shed light on their ineffectiveness, mostly attributed to the lack of well-designed interaction and learning loops beyond knowledge retrieval. she noted that plans, similarly to prede\ufb01ned rules, are not prescriptive and not something to follow exactly, because everything eventually depends on circumstances and contingen- cies. plans should rather be seen as heuristic and available resources for actions that help focus one\u2019s attention while abstracting the details. but they should get updated through interaction to take proper decisions. in the end, interfaces should not draw a dry delimi- tation with their user but re-con\ufb01gure themselves and conform with him. research [62] has shown an increased ef\ufb01ciency in human-ai coupling when both agents were able to initiate and respond to interaction. these were historically mostly unidirectional, the assistant either asking a prede\ufb01ned set of questions to build its context representation or the user asking to perform some prede\ufb01ned tasks. such badly designed assistants such as clippy [63] could in the end disrupt the user, making it inef\ufb01cient and frustrating. in a bidirectional relationship, the interaction is collaborative, with neither the system nor the user in control of the whole interaction [57]. the assistant is capable of interacting with the latter to re\ufb01ne its context representation (e.g. ask for a clari\ufb01cation when ambiguities arise), thus improving its ef\ufb01ciency when asked to perform a speci\ufb01c task. a good example of such bidirectional interaction is found in [48], where interac- tion between load-carrying robots and their human partners is learnt over time, resulting in better task completion through operator improvement and per-user adaptation of the robot\u2019s behavior. further approaches let an assistant learn how and when to defer to an expert [64] when in doubt, or conversely let a user interactively learn about the weak- nesses and strengths of the assistant under sources of uncertainties [65]. an assistant can also gently challenge or guide a user to reach novel solutions and build knowledge alto- gether [66,67]. ultimately a user would like to grasp the underlying assistant model [68], to know what the model captured, what he can do with it and how to direct or correct it. interpretability is at play more than post-hoc explanations [69]. in that regard, prospec- tive design [12,70] through interaction and exploration should prove effective, removing the need for the assistant to always explain himself to the operator. an after-operations review process could prove useful for strengthening the relationship [71]. these advances show that creating true human-computer partnerships [72] based on the concepts of discoverability, appropriability and expressivity become a reality as well-demonstrated in [73]. this calls for more academic and industrial collaboration like the \u201ccockpit and bidirectional assistant\u201d project [74] for critical systems. a. marot et al. / towards an ai assistant for power grid operators 86\\n\\n---\\n\\n### page 9\\n\\n5. featured function for effective assistant support after de\ufb01ning what an assistant should look like in the case of power systems, we now propose to specify how it should proceed when interacting with a user. to do so, we build upon the human-ai guidelines de\ufb01ned by amershi et al. [75] to feature import functions for such assistants. as these guidelines were initially de\ufb01ned from studying consumer products, we highlight some additional speci\ufb01city when considering industrial systems. show contextually relevant information at the right time - grid operators evolve in a time-constrained environment where having the right information at the right time is paramount. for instance, power lines reconnected after a routine outage operation for maintenance should be noti\ufb01ed as soon as possible to increase grid robustness. an assis- tant should engage in interaction when the context allows it, taking into account when possible the operator\u2019s mental availability and current task, and the expected impact of the interaction. task prioritization is also a cornerstone of good grid management, and users should be provided with high granularity, curated task details for fast criticality as- sessment. all of the above-mentioned concerns call for ef\ufb01cient knowledge management and representation, as instantiated by our hypervision system de\ufb01ned in 4.2. scope services and inform the user when in doubt - doubt can happen when the assistant is uncertain about the user\u2019s goal, but also in our case because of assistant model limitations (imperfect grid simulator) or uncertainties in the system (poor weather forecast). operators are often dealing with variability, be it when anticipating potential hazards due to volatile renewable energies or exploring the effects of preventive actions. let\u2019s zoom on the \u201canticipation & forecasts\u201d slot of \ufb01g. 1a. when facing uncer- tainty, for example when provided with a highly volatile wind forecast, the operator can \ufb01rst simply indicate his intention of monitoring more stable, aggregated regional fore- casts and let the assistant switch to a higher resolution as operations shift closer to real- time and more precise weather information arrives. this example also shows that uncer- tainties when providing assistance should be jointly presented with their probable causes (missing data, poor forecast...), to help decision-making and reinforce operator trust. support ef\ufb01cient invocation and dismissal - the number of actions an operator can do in a time window is limited. interacting with an assistant has to be straightforward. verbosity should be kept to a minimum, and function of the operator context. in tense situations (e.g. volatile renewable production), the assistant should initiate interactions more frugally, be more succinct, and support faster dismissal. knowing how to adapt interactions is not straightforward, as it involves capturing a lot of implicit contextual hints, and getting operator feedback through dialog should play a major role. take into account and learn from user behavior and feedback - grid operators are well-trained experts, capable of evaluating the assistant\u2019s answers and providing feed- back. thus, to ensure continuous performance improvement (fig. 1a), the latter must be able to learn from users, for instance by understanding that additional context needs to be considered alongside a speci\ufb01c action, or remembering that a line is under mainte- nance during a user-provided period. remembering recent interactions is paramount to user acceptance (nobody likes repeating requests) and capturing user context. moreover, each operator has a personal decision-making style, some relying on nu- merous power-\ufb02ow simulations to assess a situation, others relying on their expertise. a good assistant should adjust to these user-speci\ufb01c pro\ufb01les. convey the consequences of user actions - not only should an assistant avoid oper- ator deskilling for what they do great, but also should it reinforce user expertise through a. marot et al. / towards an ai assistant for power grid operators 87\\n\\n---\\n\\n### page 10\\n\\ninteraction. assistants providing debrie\ufb01ng or online comparative feedback on different action strategies in time would tremendously speed up the way operators acquire expe- rience by mobilizing their deliberative thinking process (s2 in section 3), and yield bet- ter grid management. as what kpis should be tracked is task-dependent, the operator is also involved in this bidirectional dialog. logically, interpretability and explainability are inseparable from building this successful human-ai hybridization (\ufb01g. 1a). 6. guidelines for developing, implementing and testing an assistant designing an assistant in practice might still seem complex beyond the discussed frame- work and principles. we devise here some pragmatic guidelines to start simple on com- mon but modular ground, listing some already available building blocks as well. 6.1. grounded design considerations tasks and visualizations as shared representations in smart grids, functions have been presented in [76,77,1] and tasks described at a high level in [3,26] or through a detailed example [36]. in other industrial sectors such as aeronautics [11], tasks in pro- cesses have been codi\ufb01ed more precisely at a granular level with ontologies [78] or con- ceptual designs from human-computer design [11], which gives the operator a clearer framework to work and coordinate with, as for the assistant. a task is \ufb01rst de\ufb01ned by the problem to solve speci\ufb01cally, such as a safety problem - a line overload, its priority and the residual time to complete it. it should contain relevant context to understand the root of the problem, what might be already known about it, re- cent related events or tasks, as well as the persons involved. building on causal and coun- terfactual models [79] is desirable. a task should further come with suggestions about available actions, and their expected effectiveness. it should \ufb01nally retain a decision for completion and meta-attributes about it. structuring tasks this way would allow shared representations [57] between the operator and the assistant. task categories and attributes should be more exhaustively drawn through future works. eventually, comprehensive activity studies involving multiple tasks in time [11] should be run. also, we suggest to start studying tasks in regular situations and gradually increas- ing the number of needed bidirectional interactions, before considering worst-case sce- narios. to operators, it should prove useful to start experimenting on the most routine but sometimes time-consuming tasks with often low added value [80]. that way, building trust in the \ufb01rst place should be easier while still helping ease their cognitive load. additionally, powerful and interactive visualizations are a common and much ap- preciated approach for operators to support shared representations and task completion. they are useful companions of an assistant. a recent survey in power grids advocates for such new developments [81]. effective superimposed forecasted and current system state visualization [82], dynamic and temporal network exploration [83,84], and high- dimensional event-based visualizations [85] could prove bene\ufb01cial in that regard. simple situational use case sandbox we offer a simple interesting use case to highlight key dif\ufb01culties in daily grid management through the interplay of preventive and correc- tive decisions under uncertainty. it makes us think about the operator-agent interaction. an operator starts monitoring a two-area grid at 7:00am. forecasts show 2 issues: \u2022 an incident in area 1 could happen around 9:00am and would lead to some over- loads, with three available corrective actions after simulations. a. marot et al. / towards an ai assistant for power grid operators 88\\n\\n---\\n\\n### page 11\\n\\n\u2022 another such incident in area 2 could happen around 8:30am with only one pre- ventive action available. this leaves only a couple of minutes to execute it or not. figure 2. a simple scenario where incidents are forecasted in multiple parts of a grid, and several remedial actions (green dot) with different setup duration (blue arrow) are possible. a couple of questions arise on the best strategy to follow: \u2022 which decisions have priority? it seems that a preventive action on area 2 should be urgently taken, but maybe the forecast isn\u2019t that reliable yet. \u2022 when should we implement actions? waiting for the last simulation at 8:00am in area 1 shows that the forecasted problem disappeared which is the best option. \u2022 how does applying a preventive action on area 2 re\ufb02ect on area 1? would it lead to a less secure grid state? what coordination is required? maybe there\u2019s a new outage operation in this area that isn\u2019t yet taken into account by the simulation. \u2022 which of the three corrective actions in area 1 should be taken? the operator has to mediate between economical, practical and safety arguments, each with a degree of uncertainty over an activation horizon. our objective here is not to provide any viable solution, but rather to demonstrate that grid operators are confronted with complex decisions even on apparently simple cases, in which context-dependent trade-offs always have to be made. future works could build a library of such canonical cases to be studied in the community. 6.2. uni\ufb01ed interface & data collection as an industrial stack the hypervision framework relies on a generic single interface that should be able to integrate any kind of tasks, and apply to different industrial systems for instance. an ex- ample of an existing framework is the open-source operator fabric [86]. it could be used both by industrial and researchers as a uni\ufb01ed interface for decision-making processes across teams. such a framework is also a cornerstone to digitalize the decision-making process, centralize every necessary information, hence capitalize on them. this historical data collection is essential for continuous improvement, experiments, as well as for cre- ating datasets from which ai can learn recommendations. data should get labeled and its quality",
      "human error",
      "lack of",
      "problem of"
    ],
    "commercial_solutions_vendors": [
      "acm transactions on interactive intelligent systems",
      "adapting existing ai assistant framework and guidelines to power",
      "aim at fully autonomous systems",
      "and apply to different industrial systems",
      "and coordination to support the ongoing energy",
      "and evaluation of human machine systems",
      "and for power systems",
      "and recommendation systems",
      "applied energy",
      "as well as already available materials in power",
      "assistant for power",
      "based solutions",
      "bridge university",
      "but such systems",
      "centered design of complex systems",
      "cently been developed for power",
      "chi conference on human factors in computing systems",
      "decision support systems",
      "electric power systems",
      "energy systems",
      "erators of critical systems",
      "eventually providing him with diagnostics or even recommendations on solutions",
      "expert systems",
      "expertise in the electric",
      "extended abstracts on human factors in computing systems",
      "for critical systems",
      "framework for trustworthy machine learning in power systems",
      "from alphago to power",
      "guided machine learning for power",
      "how do humans decide under wind power",
      "hybrid systems",
      "ieee",
      "ieee intelligent systems",
      "ieee power and energy",
      "in power",
      "in proceedings of the sigchi conference on human factors in computing systems",
      "intelligence into interactive systems",
      "international conference on autonomous agents and multiagent systems",
      "international journal of electrical power",
      "interpreting atypical conditions in systems",
      "introducing machine learning for power",
      "journal of modern power systems and clean energy",
      "knowledge graph construction and application of power",
      "machine systems",
      "merous power",
      "national conference on systems",
      "national institute",
      "neural information processing systems",
      "ntowards an ai assistant for power",
      "optimization of computational budget for power",
      "or even use battery storage today to change the power",
      "oxford university",
      "perspectives on future power system control centers for energy",
      "physical systems",
      "power grids are becoming more complex to operate in the digital age given the current energy",
      "recent developments in machine learning for energy systems",
      "recent survey in power",
      "related to human behavior and cognition beyond the usual situation awareness focus in power systems",
      "security constraint optimal power",
      "sistant based on the concept of hypervision and bidirectional interactions for power",
      "situation awareness in power systems",
      "so decisions need to consider the full underlying planning problem of power",
      "survey of visualization methods for power",
      "the changing practices of energy",
      "the future role of human operators in highly automated electric power systems",
      "they can modify the line connectivity on the grid to reroute power",
      "they mostly manually explore solutions",
      "time energy",
      "time from control rooms to optimize the power",
      "tion systems",
      "tonomous systems",
      "towards an ai assistant for power",
      "user to reach novel solutions",
      "usual solutions",
      "what an assistant should look like in the case of power systems",
      "when considering industrial systems",
      "when powering assistance systems",
      "which notably used power",
      "while human systems",
      "year now given the energy"
    ],
    "standards_protocols": [],
    "keywords_phrases": [
      "agent",
      "agents",
      "automation",
      "battery",
      "communication",
      "control room",
      "coordination",
      "grid",
      "human factors",
      "operator",
      "protocol",
      "renewable",
      "storage",
      "wind"
    ]
  },
  "keywords_phrases": []
}